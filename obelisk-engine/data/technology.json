{
  "updated_at": "2026-01-28T07:26:57.379Z",
  "clusters": [
    {
      "id": "cluster_36",
      "coverage": 3,
      "updated_at": "Tue, 27 Jan 2026 23:52:34 +0000",
      "title": "Mark Zuckerberg was initially opposed to parental controls for AI chatbots, according to legal filing",
      "neutral_headline": "Meta blocks links to ICE List, a Wiki that names agents",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/mark-zuckerberg-was-initially-opposed-to-parental-controls-for-ai-chatbots-according-to-legal-filing-230110214.html",
          "published_at": "Tue, 27 Jan 2026 23:52:34 +0000",
          "title": "Mark Zuckerberg was initially opposed to parental controls for AI chatbots, according to legal filing",
          "standfirst": "Meta has faced some serious questions about how it allows its underage users to interact with AI-powered chatbots. Most recently, internal communications obtained by the New Mexico Attorney General's Office revealed that although Meta CEO Mark Zuckerberg was opposed to the chatbots having \"explicit\" conversations with minors, he also rejected the idea of placing parental controls on the feature. Reuters reported that in an exchange between two unnamed Meta employees, one wrote that we \"pushed hard for parental controls to turn GenAI off – but GenAI leadership pushed back stating Mark decision.” In its statement to the publication, Meta accused the New Mexico Attorney General of \"cherry picking documents to paint a flawed and inaccurate picture.\" New Mexico is suing Meta on charges that the company “failed to stem the tide of damaging sexual material and sexual propositions delivered to children;” the case is scheduled to go to trial in February. Despite only being available for a brief time, Meta's chatbots have already accumulated quite a history of behavior that veers into offensive if not outright illegal. In April 2025, The Wall Street Journal released an investigation that found Meta's chatbots could engage in fantasy sex conversations with minors, or could be directed to mimic a minor and engage in sexual conversation. The report claimed that Zuckerberg had wanted looser guards implemented around Meta's chatbots, but a spokesperson denied that the company had overlooked protections for children and teens. Internal review documents revealed in August 2025 detailed several hypothetical situations of what chatbot behaviors would be permitted, and the lines between sensual and sexual seemed pretty hazy. The document also permitted the chatbots to argue racist concepts. At the time, a representative told Engadget that the offending passages were hypotheticals rather than actual policy, which doesn't really seem like much of an improvement, and that they were removed from the document. Despite the multiple instances of questionable use of the chatbots, Meta only decided to suspend teen accounts' access to them last week. The company said it is temporarily removing access while it develops the parental controls that Zuckerberg had allegedly rejected using.\"Parents have long been able to see if their teens have been chatting with AIs on Instagram, and in October we announced our plans to go further, building new tools to give parents more control over their teens’ experiences with AI characters,\" a representative from Meta said. \"Last week we once again reinforced our commitment to delivering on our promise of parental controls for AI, pausing teen access to AI characters completely until the updated version is ready.\"New Mexico filed this lawsuit against Meta in December 2023 on claims that the company's platforms failed to protect minors from harassment by adults. Internal documents revealed early on in that complaint revealed that 100,000 child users were harassed daily on Meta's services.Update, January 27, 2025, 6:52PM ET: Added statement from Meta spokesperson.Update, January 27, 2025, 6:15PM ET: Corrected misstated timeline of the New Mexico lawsuit, which was filed in December 2023, not December 2024.This article originally appeared on Engadget at https://www.engadget.com/social-media/mark-zuckerberg-was-initially-opposed-to-parental-controls-for-ai-chatbots-according-to-legal-filing-230110214.html?src=rss",
          "content": "Meta has faced some serious questions about how it allows its underage users to interact with AI-powered chatbots. Most recently, internal communications obtained by the New Mexico Attorney General's Office revealed that although Meta CEO Mark Zuckerberg was opposed to the chatbots having \"explicit\" conversations with minors, he also rejected the idea of placing parental controls on the feature. Reuters reported that in an exchange between two unnamed Meta employees, one wrote that we \"pushed hard for parental controls to turn GenAI off – but GenAI leadership pushed back stating Mark decision.” In its statement to the publication, Meta accused the New Mexico Attorney General of \"cherry picking documents to paint a flawed and inaccurate picture.\" New Mexico is suing Meta on charges that the company “failed to stem the tide of damaging sexual material and sexual propositions delivered to children;” the case is scheduled to go to trial in February. Despite only being available for a brief time, Meta's chatbots have already accumulated quite a history of behavior that veers into offensive if not outright illegal. In April 2025, The Wall Street Journal released an investigation that found Meta's chatbots could engage in fantasy sex conversations with minors, or could be directed to mimic a minor and engage in sexual conversation. The report claimed that Zuckerberg had wanted looser guards implemented around Meta's chatbots, but a spokesperson denied that the company had overlooked protections for children and teens. Internal review documents revealed in August 2025 detailed several hypothetical situations of what chatbot behaviors would be permitted, and the lines between sensual and sexual seemed pretty hazy. The document also permitted the chatbots to argue racist concepts. At the time, a representative told Engadget that the offending passages were hypotheticals rather than actual policy, which doesn't really seem like much of an improvement, and that they were removed from the document. Despite the multiple instances of questionable use of the chatbots, Meta only decided to suspend teen accounts' access to them last week. The company said it is temporarily removing access while it develops the parental controls that Zuckerberg had allegedly rejected using.\"Parents have long been able to see if their teens have been chatting with AIs on Instagram, and in October we announced our plans to go further, building new tools to give parents more control over their teens’ experiences with AI characters,\" a representative from Meta said. \"Last week we once again reinforced our commitment to delivering on our promise of parental controls for AI, pausing teen access to AI characters completely until the updated version is ready.\"New Mexico filed this lawsuit against Meta in December 2023 on claims that the company's platforms failed to protect minors from harassment by adults. Internal documents revealed early on in that complaint revealed that 100,000 child users were harassed daily on Meta's services.Update, January 27, 2025, 6:52PM ET: Added statement from Meta spokesperson.Update, January 27, 2025, 6:15PM ET: Corrected misstated timeline of the New Mexico lawsuit, which was filed in December 2023, not December 2024.This article originally appeared on Engadget at https://www.engadget.com/social-media/mark-zuckerberg-was-initially-opposed-to-parental-controls-for-ai-chatbots-according-to-legal-filing-230110214.html?src=rss",
          "feed_position": 0
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/meta-blocks-links-to-ice-list-a-wiki-that-names-agents-231410653.html",
          "published_at": "Tue, 27 Jan 2026 23:14:10 +0000",
          "title": "Meta blocks links to ICE List, a Wiki that names agents",
          "standfirst": "Meta has started blocking links to ICE List, a website that compiles information about incidents involving Immigrations and Customs Enforcement (ICE) and Border Patrol agents, and lists thousands of their employees' names. It seems that the latter detail is what caused Meta to take action in a move that was first reported by Wired. ICE List is a crowdsourced Wiki that describes itself as \"an independently maintained public documentation project focused on immigration-enforcement activity\" in the US. \"Its purpose is to record, organize, and preserve verifiable information about enforcement actions, agents, facilities, vehicles, and related incidents that would otherwise remain fragmented, difficult to access, or undocumented,\" its website states.Along with notable incidents, the website also lists the names of individual agents associated with ICE, CBP and other DHS agencies. According to Wired, the website's creators said much of that information had come from a \"leak,\" though it appears to be based largely on public LinkedIn profiles. As Wired notes:The site went viral earlier this month when it claimed to have uploaded a leaked list of 4,500 DHS employees to its site, but a WIRED analysis found that the list relied heavily on information the employees shared publicly about themselves on sites such as LinkedIn.Links to ICE List have been spreading widely for several weeks, including on Meta's platforms. There are numerous links to the website on Threads, some of which go back several weeks. Now though, clicking on previously-shared links instead results in a message that the link can't be opened. Users who try to share new links on Threads or Facebook also see error messages. \"Posts that look like spam according to our Community Guidelines are blocked on Facebook and can't be edited,\" the notice says. When reached for comment, a Meta spokesperson pointed to the company's privacy policy barring the disclosure of personally identifiable information (PII). The company didn't address why it chose to start blocking the website after several weeks, or whether it considers public LinkedIn profiles to be in violation of its rules against doxxing. It is, however, not the first time Meta has opted to remove users' posts tracking information about ICE actions. The social network previously took down a Facebook group that tracked ICE sightings in Chicago after pressure from the Justice Department. Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.This article originally appeared on Engadget at https://www.engadget.com/social-media/meta-blocks-links-to-ice-list-a-wiki-that-names-agents-231410653.html?src=rss",
          "content": "Meta has started blocking links to ICE List, a website that compiles information about incidents involving Immigrations and Customs Enforcement (ICE) and Border Patrol agents, and lists thousands of their employees' names. It seems that the latter detail is what caused Meta to take action in a move that was first reported by Wired. ICE List is a crowdsourced Wiki that describes itself as \"an independently maintained public documentation project focused on immigration-enforcement activity\" in the US. \"Its purpose is to record, organize, and preserve verifiable information about enforcement actions, agents, facilities, vehicles, and related incidents that would otherwise remain fragmented, difficult to access, or undocumented,\" its website states.Along with notable incidents, the website also lists the names of individual agents associated with ICE, CBP and other DHS agencies. According to Wired, the website's creators said much of that information had come from a \"leak,\" though it appears to be based largely on public LinkedIn profiles. As Wired notes:The site went viral earlier this month when it claimed to have uploaded a leaked list of 4,500 DHS employees to its site, but a WIRED analysis found that the list relied heavily on information the employees shared publicly about themselves on sites such as LinkedIn.Links to ICE List have been spreading widely for several weeks, including on Meta's platforms. There are numerous links to the website on Threads, some of which go back several weeks. Now though, clicking on previously-shared links instead results in a message that the link can't be opened. Users who try to share new links on Threads or Facebook also see error messages. \"Posts that look like spam according to our Community Guidelines are blocked on Facebook and can't be edited,\" the notice says. When reached for comment, a Meta spokesperson pointed to the company's privacy policy barring the disclosure of personally identifiable information (PII). The company didn't address why it chose to start blocking the website after several weeks, or whether it considers public LinkedIn profiles to be in violation of its rules against doxxing. It is, however, not the first time Meta has opted to remove users' posts tracking information about ICE actions. The social network previously took down a Facebook group that tracked ICE sightings in Chicago after pressure from the Justice Department. Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.This article originally appeared on Engadget at https://www.engadget.com/social-media/meta-blocks-links-to-ice-list-a-wiki-that-names-agents-231410653.html?src=rss",
          "feed_position": 1
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/tier-1-soc-work-becoming-code-architectural-decisions-hours-minutes-response",
          "published_at": "Tue, 27 Jan 2026 22:30:00 GMT",
          "title": "SOC teams are automating triage — but 40% will fail without governance boundaries",
          "standfirst": "The average enterprise SOC receives 10,000 alerts per day. Each requires 20 to 40 minutes to investigate properly, but even fully staffed teams can only handle 22% of them. More than 60% of security teams have admitted to ignoring alerts that later proved critical.Running an efficient SOC has never been harder, and now the work itself is changing. Tier-1 analyst tasks — like triage, enrichment, and escalation — are becoming software functions, and more SOC teams are turning to supervised AI agents to handle the volume. Human analysts are shifting their priorities to investigate, review, and make edge-case decisions. Response times are being reduced.Not integrating human insight and intuition comes with a high cost, however. Gartner predicts over 40% of agentic AI projects will be canceled by the end of 2027, with the main drivers being unclear business value and inadequate governance. Getting change management right and making sure generative AI doesn’t become a chaos agent in the SOC are even more important. Why the legacy SOC model needs to change Burnout is so severe in many SOCs today that senior analysts are considering career changes. Legacy SOCs that have multiple systems that deliver conflicting alerts, and the many systems that can’t talk to each other at all, are making the job a recipe for burnout, and the talent pipeline cannot refill faster than burnout empties it. CrowdStrike&#x27;s 2025 Global Threat Report documents breakout times as fast as 51 seconds and found 79% of intrusions are now malware-free. Attackers rely on identity abuse, credential theft, and living-off-the-land techniques instead. Manual triage built for hourly response cycles cannot compete.As Matthew Sharp, CISO at Xactly, told CSO Online: \"Adversaries are already using AI to attack at machine speed. Organizations can&#x27;t defend against AI-driven attacks with human-speed responses.\"How bounded autonomy compresses response timesSOC deployments that compress response times share a common pattern: bounded autonomy. AI agents handle triage and enrichment automatically, but humans approve containment actions when severity is high. This division of labor processes alert volume at machine speed while keeping human judgment on decisions that carry operational risk.Graph-based detection changes how defenders see the network. Traditional SIEMs show isolated events. Graph databases show relationships between those events, letting AI agents trace attack paths instead of triaging alerts one at a time. A suspicious login looks different when the system understands that the account is two hops from the domain controller.Speed gains are measurable. AI compresses threat investigation timeframes while increasing accuracy against senior analyst decisions. Separate deployments show AI-driven triage achieving over 98% agreement with human expert decisions while cutting manual workloads by more than 40 hours per week. Speed means nothing if accuracy drops.ServiceNow and Ivanti signal broader shift to agentic IT operationsGartner predicts that multi-agent AI in threat detection will rise from 5% to 70% of implementations by 2028. ServiceNow spent approximately $12 billion on security acquisitions in 2025 alone. Ivanti, which compressed a three-year kernel-hardening roadmap into 18 months when nation-state attackers validated the urgency, announced agentic AI capabilities for IT service management, bringing the bounded-autonomy model reshaping SOCs to the service desk. Customer preview launches in Q1, with general availability later in 2026.The workloads breaking SOCs are breaking service desks, too. Robert Hanson, CIO at Grand Bank, faced the same constraint security leaders know well. \"We can deliver 24/7 support while freeing our service desk to focus on complex challenges,\" Hanson said. Continuous coverage without proportional headcount. That outcome is driving adoption across financial services, healthcare, and government.Three governance boundaries for bounded autonomyBounded autonomy requires explicit governance boundaries. Teams should specify three things: which alert categories agents can act on autonomously, which require human review regardless of confidence score, and which escalation paths apply when certainty falls below threshold. High-severity incidents require human approval before containment.Having governance in place before deploying AI across SOCs is critical if any organization is going to get the time and containment benefits this latest generation of tools has to offer. When adversaries weaponize AI and actively mine CVE vulnerabilities faster than defenders respond, autonomous detection becomes the new table stakes for staying resilient in a zero-trust world.The path forward for security leadersTeams should start with workflows where failure is recoverable. Three workflows consume 60% of analyst time while contributing minimal investigative value: phishing triage (missed escalations can be caught in secondary review), password reset automation (low blast radius), and known-bad indicator matching (deterministic logic). Automate these first, then validate accuracy against human decisions for 30 days.",
          "content": "The average enterprise SOC receives 10,000 alerts per day. Each requires 20 to 40 minutes to investigate properly, but even fully staffed teams can only handle 22% of them. More than 60% of security teams have admitted to ignoring alerts that later proved critical.Running an efficient SOC has never been harder, and now the work itself is changing. Tier-1 analyst tasks — like triage, enrichment, and escalation — are becoming software functions, and more SOC teams are turning to supervised AI agents to handle the volume. Human analysts are shifting their priorities to investigate, review, and make edge-case decisions. Response times are being reduced.Not integrating human insight and intuition comes with a high cost, however. Gartner predicts over 40% of agentic AI projects will be canceled by the end of 2027, with the main drivers being unclear business value and inadequate governance. Getting change management right and making sure generative AI doesn’t become a chaos agent in the SOC are even more important. Why the legacy SOC model needs to change Burnout is so severe in many SOCs today that senior analysts are considering career changes. Legacy SOCs that have multiple systems that deliver conflicting alerts, and the many systems that can’t talk to each other at all, are making the job a recipe for burnout, and the talent pipeline cannot refill faster than burnout empties it. CrowdStrike&#x27;s 2025 Global Threat Report documents breakout times as fast as 51 seconds and found 79% of intrusions are now malware-free. Attackers rely on identity abuse, credential theft, and living-off-the-land techniques instead. Manual triage built for hourly response cycles cannot compete.As Matthew Sharp, CISO at Xactly, told CSO Online: \"Adversaries are already using AI to attack at machine speed. Organizations can&#x27;t defend against AI-driven attacks with human-speed responses.\"How bounded autonomy compresses response timesSOC deployments that compress response times share a common pattern: bounded autonomy. AI agents handle triage and enrichment automatically, but humans approve containment actions when severity is high. This division of labor processes alert volume at machine speed while keeping human judgment on decisions that carry operational risk.Graph-based detection changes how defenders see the network. Traditional SIEMs show isolated events. Graph databases show relationships between those events, letting AI agents trace attack paths instead of triaging alerts one at a time. A suspicious login looks different when the system understands that the account is two hops from the domain controller.Speed gains are measurable. AI compresses threat investigation timeframes while increasing accuracy against senior analyst decisions. Separate deployments show AI-driven triage achieving over 98% agreement with human expert decisions while cutting manual workloads by more than 40 hours per week. Speed means nothing if accuracy drops.ServiceNow and Ivanti signal broader shift to agentic IT operationsGartner predicts that multi-agent AI in threat detection will rise from 5% to 70% of implementations by 2028. ServiceNow spent approximately $12 billion on security acquisitions in 2025 alone. Ivanti, which compressed a three-year kernel-hardening roadmap into 18 months when nation-state attackers validated the urgency, announced agentic AI capabilities for IT service management, bringing the bounded-autonomy model reshaping SOCs to the service desk. Customer preview launches in Q1, with general availability later in 2026.The workloads breaking SOCs are breaking service desks, too. Robert Hanson, CIO at Grand Bank, faced the same constraint security leaders know well. \"We can deliver 24/7 support while freeing our service desk to focus on complex challenges,\" Hanson said. Continuous coverage without proportional headcount. That outcome is driving adoption across financial services, healthcare, and government.Three governance boundaries for bounded autonomyBounded autonomy requires explicit governance boundaries. Teams should specify three things: which alert categories agents can act on autonomously, which require human review regardless of confidence score, and which escalation paths apply when certainty falls below threshold. High-severity incidents require human approval before containment.Having governance in place before deploying AI across SOCs is critical if any organization is going to get the time and containment benefits this latest generation of tools has to offer. When adversaries weaponize AI and actively mine CVE vulnerabilities faster than defenders respond, autonomous detection becomes the new table stakes for staying resilient in a zero-trust world.The path forward for security leadersTeams should start with workflows where failure is recoverable. Three workflows consume 60% of analyst time while contributing minimal investigative value: phishing triage (missed escalations can be caught in secondary review), password reset automation (low blast radius), and known-bad indicator matching (deterministic logic). Automate these first, then validate accuracy against human decisions for 30 days.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1kE7n0Y35usP0AVocbHTSc/bcd1013573ca6fa9d72977ba8f33cf4a/hero_image.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/apple-and-google-reportedly-still-offer-dozens-of-ai-nudify-apps-192712446.html",
          "published_at": "Tue, 27 Jan 2026 19:27:12 +0000",
          "title": "Apple and Google reportedly still offer dozens of AI ‘nudify’ apps",
          "standfirst": "A recent investigation by an online advocacy organization called the Tech Transparency Project (TTP) found that the Apple App Store and Google Play Store are rife with so-called \"nudify\" apps. These are AI applications that create nonconsensual and sexualized images, which is a clear violation of both companies' store policies. All told, the investigation found 55 of this type of app in the Google Play Store and 47 in the Apple App Store. Both platforms also still offer access to xAI's Grok, which is likely the most famous nonconsensual deepfake maker in the world. \"Apple and Google are supposed to be vetting the apps in their stores. But they've been offering dozens of apps that can be used to show people with minimal or no clothing—making them ripe for abuse,” said Michelle Kuppersmith, an executive director at the nonprofit that runs TTP. The apps identified by the report have been collectively downloaded over 700 million times and generated more than $117 million in revenue. Google and Apple get a cut of this money. Some of the apps were even approved for children, with Apple listing apps for kids as young as 4+ or 9+ and Google listing for ages 13+. Yet all of them appear to be in direct violation of company policy—even for adult users. pic.twitter.com/bShqEYMpIL— Tech Transparency Project (@TTP_updates) January 27, 2026 Many of the apps named in the investigation are rated as suitable for teens and children. DreamFace, for instance, is rated suitable for ages 13 and up in the Google Play Store and ages nine and up in the Apple App Store. Both companies have responded to the investigation. Apple says it has removed 24 apps from its store, according to a report by CNBC. However, that falls shy of the 47 apps discovered by TTP researchers. A Google spokesperson has said the company suspended several apps referenced in the report for violating store policies, but declined to say how many apps it has removed. This report comes after Elon Musk's Grok was found to be generating sexualized images of both women and children. All told, the AI chatbot generated around three million sexualized images and 22,000 that involved children over a period of 11 days. Representatives from the company haven't really responded to these allegations, except to send an automated email to journalists that read \"Legacy Media Lies.\" Musk has also stated that he is \"not aware of any naked underage images generated by Grok. Literally zero.\" We take action against illegal content on X, including Child Sexual Abuse Material (CSAM), by removing it, permanently suspending accounts, and working with local governments and law enforcement as necessary.Anyone using or prompting Grok to make illegal content will suffer the… https://t.co/93kiIBTCYO— Safety (@Safety) January 4, 2026 X's safety account did post that \"anyone using or prompting Grok to make illegal content will suffer the same consequences as if they upload illegal content.\" Grok has proven to be more forthcoming than actual humans at the company, as the chatbot apologized for creating sexualized images of minors.This article originally appeared on Engadget at https://www.engadget.com/ai/apple-and-google-reportedly-still-offer-dozens-of-ai-nudify-apps-192712446.html?src=rss",
          "content": "A recent investigation by an online advocacy organization called the Tech Transparency Project (TTP) found that the Apple App Store and Google Play Store are rife with so-called \"nudify\" apps. These are AI applications that create nonconsensual and sexualized images, which is a clear violation of both companies' store policies. All told, the investigation found 55 of this type of app in the Google Play Store and 47 in the Apple App Store. Both platforms also still offer access to xAI's Grok, which is likely the most famous nonconsensual deepfake maker in the world. \"Apple and Google are supposed to be vetting the apps in their stores. But they've been offering dozens of apps that can be used to show people with minimal or no clothing—making them ripe for abuse,” said Michelle Kuppersmith, an executive director at the nonprofit that runs TTP. The apps identified by the report have been collectively downloaded over 700 million times and generated more than $117 million in revenue. Google and Apple get a cut of this money. Some of the apps were even approved for children, with Apple listing apps for kids as young as 4+ or 9+ and Google listing for ages 13+. Yet all of them appear to be in direct violation of company policy—even for adult users. pic.twitter.com/bShqEYMpIL— Tech Transparency Project (@TTP_updates) January 27, 2026 Many of the apps named in the investigation are rated as suitable for teens and children. DreamFace, for instance, is rated suitable for ages 13 and up in the Google Play Store and ages nine and up in the Apple App Store. Both companies have responded to the investigation. Apple says it has removed 24 apps from its store, according to a report by CNBC. However, that falls shy of the 47 apps discovered by TTP researchers. A Google spokesperson has said the company suspended several apps referenced in the report for violating store policies, but declined to say how many apps it has removed. This report comes after Elon Musk's Grok was found to be generating sexualized images of both women and children. All told, the AI chatbot generated around three million sexualized images and 22,000 that involved children over a period of 11 days. Representatives from the company haven't really responded to these allegations, except to send an automated email to journalists that read \"Legacy Media Lies.\" Musk has also stated that he is \"not aware of any naked underage images generated by Grok. Literally zero.\" We take action against illegal content on X, including Child Sexual Abuse Material (CSAM), by removing it, permanently suspending accounts, and working with local governments and law enforcement as necessary.Anyone using or prompting Grok to make illegal content will suffer the… https://t.co/93kiIBTCYO— Safety (@Safety) January 4, 2026 X's safety account did post that \"anyone using or prompting Grok to make illegal content will suffer the same consequences as if they upload illegal content.\" Grok has proven to be more forthcoming than actual humans at the company, as the chatbot apologized for creating sexualized images of minors.This article originally appeared on Engadget at https://www.engadget.com/ai/apple-and-google-reportedly-still-offer-dozens-of-ai-nudify-apps-192712446.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/tiktok-settles-to-avoid-major-social-media-addiction-lawsuit-183943927.html",
          "published_at": "Tue, 27 Jan 2026 18:39:43 +0000",
          "title": "TikTok settles to avoid major social media addiction lawsuit",
          "standfirst": "TikTok has reached a settlement in a closely-watched lawsuit over social media addiction, narrowly avoiding a trial that's scheduled to begin jury selection Tuesday. Terms of the deal, which was reported by The New York Times, weren't disclosed. TikTok's settlement comes about one week after Snap reached a settlement in the same case. The trial is expected to move forward in Los Angeles with Meta and YouTube as the only defendants. Mark Lanier, a lawyer for the plaintiff, said in a statement to NYT that they were \"pleased\" with the settlement and that it was \"a good resolution.\" TikTok didn't immediately respond to a request for comment. The trial stems from a 2023 lawsuit brought by a California woman known in court documents as \"K.G.M.\" She sued Meta, Snap, TikTok and YouTube and alleged that their platforms were addictive and had harmed her as a child. The judge in the case previously ordered the companies' executives, including Mark Zuckerberg and Adam Mosseri, to testify. YouTube's top exec, Neal Mohan, is also likely to testify, according to The New York Times. The lawsuit is the first among several high-profile cases against social media companies to go to trial this year. Meta is expected to head to court in New Mexico in early February in a case brought by the state's attorney general, who has alleged that Facebook and Instagram have facilitated harm to children. TikTok and Snap are collectively facing more than a dozen other trials in California courts this year.This article originally appeared on Engadget at https://www.engadget.com/social-media/tiktok-settles-to-avoid-major-social-media-addiction-lawsuit-183943927.html?src=rss",
          "content": "TikTok has reached a settlement in a closely-watched lawsuit over social media addiction, narrowly avoiding a trial that's scheduled to begin jury selection Tuesday. Terms of the deal, which was reported by The New York Times, weren't disclosed. TikTok's settlement comes about one week after Snap reached a settlement in the same case. The trial is expected to move forward in Los Angeles with Meta and YouTube as the only defendants. Mark Lanier, a lawyer for the plaintiff, said in a statement to NYT that they were \"pleased\" with the settlement and that it was \"a good resolution.\" TikTok didn't immediately respond to a request for comment. The trial stems from a 2023 lawsuit brought by a California woman known in court documents as \"K.G.M.\" She sued Meta, Snap, TikTok and YouTube and alleged that their platforms were addictive and had harmed her as a child. The judge in the case previously ordered the companies' executives, including Mark Zuckerberg and Adam Mosseri, to testify. YouTube's top exec, Neal Mohan, is also likely to testify, according to The New York Times. The lawsuit is the first among several high-profile cases against social media companies to go to trial this year. Meta is expected to head to court in New Mexico in early February in a case brought by the state's attorney general, who has alleged that Facebook and Instagram have facilitated harm to children. TikTok and Snap are collectively facing more than a dozen other trials in California courts this year.This article originally appeared on Engadget at https://www.engadget.com/social-media/tiktok-settles-to-avoid-major-social-media-addiction-lawsuit-183943927.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-everything-we-think-the-company-will-unveil-130000218.html",
          "published_at": "Tue, 27 Jan 2026 17:02:39 +0000",
          "title": "Samsung Galaxy Unpacked 2026: Everything we think the company will unveil",
          "standfirst": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company is expected to host its first Galaxy Unpacked of the year in February to introduce the Galaxy S26 lineup.Engadget will be covering Galaxy Unpacked live, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for an official invite, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. That info came on January 27, when the company announced the TriFold would be available in the US on January 30, for a whopping $2,900. Considering we’ve already seen the device in person at CES 2026 and people are most likely to have had a chance to look at, if not buy the foldable for themselves by the time Unpacked rolls around, we don’t expect Samsung to spend too much time dwelling on it, if at all.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.Update, January 27 2026, 11:55AM ET: This story has been updated to reflect the latest news around the Galaxy Z TriFold’s price and availability in the US.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-everything-we-think-the-company-will-unveil-130000218.html?src=rss",
          "content": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company is expected to host its first Galaxy Unpacked of the year in February to introduce the Galaxy S26 lineup.Engadget will be covering Galaxy Unpacked live, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for an official invite, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. That info came on January 27, when the company announced the TriFold would be available in the US on January 30, for a whopping $2,900. Considering we’ve already seen the device in person at CES 2026 and people are most likely to have had a chance to look at, if not buy the foldable for themselves by the time Unpacked rolls around, we don’t expect Samsung to spend too much time dwelling on it, if at all.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.Update, January 27 2026, 11:55AM ET: This story has been updated to reflect the latest news around the Galaxy Z TriFold’s price and availability in the US.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-everything-we-think-the-company-will-unveil-130000218.html?src=rss",
          "feed_position": 15,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-01/59db82d0-d8d0-11ef-babd-deb856accfc5"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/contextual-ai-launches-agent-composer-to-turn-enterprise-rag-into-production",
          "published_at": "Tue, 27 Jan 2026 17:00:00 GMT",
          "title": "Contextual AI launches Agent Composer to turn enterprise RAG into production-ready AI agents",
          "standfirst": "In the race to bring artificial intelligence into the enterprise, a small but well-funded startup is making a bold claim: The problem holding back AI adoption in complex industries has never been the models themselves.Contextual AI, a two-and-a-half-year-old company backed by investors including Bezos Expeditions and Bain Capital Ventures, on Monday unveiled Agent Composer, a platform designed to help engineers in aerospace, semiconductor manufacturing, and other technically demanding fields build AI agents that can automate the kind of knowledge-intensive work that has long resisted automation.The announcement arrives at a pivotal moment for enterprise AI. Four years after ChatGPT ignited a frenzy of corporate AI initiatives, many organizations remain stuck in pilot programs, struggling to move experimental projects into full-scale production. Chief financial officers and business unit leaders are growing impatient with internal efforts that have consumed millions of dollars but delivered limited returns.Douwe Kiela, Contextual AI&#x27;s chief executive, believes the industry has been focused on the wrong bottleneck. \"The model is almost commoditized at this point,\" Kiela said in an interview with VentureBeat. \"The bottleneck is context — can the AI actually access your proprietary docs, specs, and institutional knowledge? That&#x27;s the problem we solve.\"Why enterprise AI keeps failing, and what retrieval-augmented generation was supposed to fixTo understand what Contextual AI is attempting, it helps to understand a concept that has become central to modern AI development: retrieval-augmented generation, or RAG.When large language models like those from OpenAI, Google, or Anthropic generate responses, they draw on knowledge embedded during training. But that knowledge has a cutoff date, and it cannot include the proprietary documents, engineering specifications, and institutional knowledge that make up the lifeblood of most enterprises.RAG systems attempt to solve this by retrieving relevant documents from a company&#x27;s own databases and feeding them to the model alongside the user&#x27;s question. The model can then ground its response in actual company data rather than relying solely on its training.Kiela helped pioneer this approach during his time as a research scientist at Facebook AI Research and later as head of research at Hugging Face, the influential open-source AI company. He holds a Ph.D. from Cambridge and serves as an adjunct professor in symbolic systems at Stanford University.But early RAG systems, Kiela acknowledges, were crude.\"Early RAG was pretty crude — grab an off-the-shelf retriever, connect it to a generator, hope for the best,\" he said. \"Errors compounded through the pipeline. Hallucinations were common because the generator wasn&#x27;t trained to stay grounded.\"When Kiela founded Contextual AI in June 2023, he set out to solve these problems systematically. The company developed what it calls a \"unified context layer\" — a set of tools that sit between a company&#x27;s data and its AI models, ensuring that the right information reaches the model in the right format at the right time.The approach has earned recognition. According to a Google Cloud case study, Contextual AI achieved the highest performance on Google&#x27;s FACTS benchmark for grounded, hallucination-resistant results. The company fine-tuned Meta&#x27;s open-source Llama models on Google Cloud&#x27;s Vertex AI platform, focusing specifically on reducing the tendency of AI systems to invent information.Inside Agent Composer, the platform that promises to turn complex engineering workflows into minutes of workAgent Composer extends Contextual AI&#x27;s existing platform with orchestration capabilities — the ability to coordinate multiple AI tools across multiple steps to complete complex workflows.The platform offers three ways to create AI agents. Users can start with pre-built agents designed for common technical workflows like root cause analysis or compliance checking. They can describe a workflow in natural language and let the system automatically generate a working agent architecture. Or they can build from scratch using a visual drag-and-drop interface that requires no coding.What distinguishes Agent Composer from competing approaches, the company says, is its hybrid architecture. Teams can combine strict, deterministic rules for high-stakes steps — compliance checks, data validation, approval gates — with dynamic reasoning for exploratory analysis.\"For highly critical workflows, users can choose completely deterministic steps to control agent behavior and avoid uncertainty,\" Kiela said.The platform also includes what the company calls \"one-click agent optimization,\" which takes user feedback and automatically adjusts agent performance. Every step of an agent&#x27;s reasoning process can be audited, and responses come with sentence-level citations showing exactly where information originated in source documents.From eight hours to 20 minutes: what early customers say about the platform&#x27;s real-world performanceContextual AI says early customers have reported significant efficiency gains, though the company acknowledges these figures come from customer self-reporting rather than independent verification.\"These come directly from customer evals, which are approximations of real-world workflows,\" Kiela said. \"The numbers are self-reported by our customers as they describe the before-and-after scenario of adopting Contextual AI.\"The claimed results are nonetheless striking. An advanced manufacturer reduced root-cause analysis from eight hours to 20 minutes by automating sensor data parsing and log correlation. A specialty chemicals company reduced product research from hours to minutes using agents that search patents and regulatory databases. A test equipment maker now generates test code in minutes instead of days.Keith Schaub, vice president of technology and strategy at Advantest, a semiconductor test equipment company, offered an endorsement. \"Contextual AI has been an important part of our AI transformation efforts,\" Schaub said. \"The technology has been rolled out to multiple teams across Advantest and select end customers, saving meaningful time across tasks ranging from test code generation to customer engineering workflows.\"The company&#x27;s other customers include Qualcomm, the semiconductor giant; ShipBob, a tech-enabled logistics provider that claims to have achieved 60 times faster issue resolution; and Nvidia, the chip maker whose graphics processors power most AI systems.The eternal enterprise dilemma: should companies build their own AI systems or buy off the shelf?Perhaps the biggest challenge Contextual AI faces is not competing products but the instinct among engineering organizations to build their own solutions.\"The biggest objection is &#x27;we&#x27;ll build it ourselves,&#x27;\" Kiela acknowledged. \"Some teams try. It sounds exciting to do, but is exceptionally hard to do this well at scale. Many of our customers started with DIY, and found themselves still debugging retrieval pipelines instead of solving actual problems 12-18 months later.\"The alternative — off-the-shelf point solutions — presents its own problems, the company argues. Such tools deploy quickly but often prove inflexible and difficult to customize for specific use cases.Agent Composer attempts to occupy a middle ground, offering a platform approach that combines pre-built components with extensive customization options. The system supports models from OpenAI, Anthropic, and Google, as well as Contextual AI&#x27;s own Grounded Language Model, which was specifically trained to stay faithful to retrieved content.Pricing starts at $50 per month for self-serve usage, with custom enterprise pricing for larger deployments.\"The justification to CFOs is really about increasing productivity and getting them to production faster with their AI initiatives,\" Kiela said. \"Every technical team is struggling to hire top engineering talent, so making their existing teams more productive is a huge priority in these industries.\"The road ahead: multi-agent coordination, write actions, and the race to build compound AI systemsLooking ahead, Kiela outlined three priorities for the coming year: workflow automation with actual write actions across enterprise systems rather than just reading and analyzing; better coordination among multiple specialized agents working together; and faster specialization through automatic learning from production feedback.\"The compound effect matters here,\" he said. \"Every document you ingest, every feedback loop you close, those improvements stack up. Companies building this infrastructure now are going to be hard to catch.\"The enterprise AI market remains fiercely competitive, with offerings from major cloud providers, established software vendors, and scores of startups all chasing the same customers. Whether Contextual AI&#x27;s bet on context over models will pay off depends on whether enterprises come to share Kiela&#x27;s view that the foundation model wars matter less than the infrastructure that surrounds them.But there is a certain irony in the company&#x27;s positioning. For years, the AI industry has fixated on building ever-larger, ever-more-powerful models — pouring billions into the race for artificial general intelligence. Contextual AI is making a quieter argument: that for most real-world work, the magic isn&#x27;t in the model. It&#x27;s in knowing where to look.",
          "content": "In the race to bring artificial intelligence into the enterprise, a small but well-funded startup is making a bold claim: The problem holding back AI adoption in complex industries has never been the models themselves.Contextual AI, a two-and-a-half-year-old company backed by investors including Bezos Expeditions and Bain Capital Ventures, on Monday unveiled Agent Composer, a platform designed to help engineers in aerospace, semiconductor manufacturing, and other technically demanding fields build AI agents that can automate the kind of knowledge-intensive work that has long resisted automation.The announcement arrives at a pivotal moment for enterprise AI. Four years after ChatGPT ignited a frenzy of corporate AI initiatives, many organizations remain stuck in pilot programs, struggling to move experimental projects into full-scale production. Chief financial officers and business unit leaders are growing impatient with internal efforts that have consumed millions of dollars but delivered limited returns.Douwe Kiela, Contextual AI&#x27;s chief executive, believes the industry has been focused on the wrong bottleneck. \"The model is almost commoditized at this point,\" Kiela said in an interview with VentureBeat. \"The bottleneck is context — can the AI actually access your proprietary docs, specs, and institutional knowledge? That&#x27;s the problem we solve.\"Why enterprise AI keeps failing, and what retrieval-augmented generation was supposed to fixTo understand what Contextual AI is attempting, it helps to understand a concept that has become central to modern AI development: retrieval-augmented generation, or RAG.When large language models like those from OpenAI, Google, or Anthropic generate responses, they draw on knowledge embedded during training. But that knowledge has a cutoff date, and it cannot include the proprietary documents, engineering specifications, and institutional knowledge that make up the lifeblood of most enterprises.RAG systems attempt to solve this by retrieving relevant documents from a company&#x27;s own databases and feeding them to the model alongside the user&#x27;s question. The model can then ground its response in actual company data rather than relying solely on its training.Kiela helped pioneer this approach during his time as a research scientist at Facebook AI Research and later as head of research at Hugging Face, the influential open-source AI company. He holds a Ph.D. from Cambridge and serves as an adjunct professor in symbolic systems at Stanford University.But early RAG systems, Kiela acknowledges, were crude.\"Early RAG was pretty crude — grab an off-the-shelf retriever, connect it to a generator, hope for the best,\" he said. \"Errors compounded through the pipeline. Hallucinations were common because the generator wasn&#x27;t trained to stay grounded.\"When Kiela founded Contextual AI in June 2023, he set out to solve these problems systematically. The company developed what it calls a \"unified context layer\" — a set of tools that sit between a company&#x27;s data and its AI models, ensuring that the right information reaches the model in the right format at the right time.The approach has earned recognition. According to a Google Cloud case study, Contextual AI achieved the highest performance on Google&#x27;s FACTS benchmark for grounded, hallucination-resistant results. The company fine-tuned Meta&#x27;s open-source Llama models on Google Cloud&#x27;s Vertex AI platform, focusing specifically on reducing the tendency of AI systems to invent information.Inside Agent Composer, the platform that promises to turn complex engineering workflows into minutes of workAgent Composer extends Contextual AI&#x27;s existing platform with orchestration capabilities — the ability to coordinate multiple AI tools across multiple steps to complete complex workflows.The platform offers three ways to create AI agents. Users can start with pre-built agents designed for common technical workflows like root cause analysis or compliance checking. They can describe a workflow in natural language and let the system automatically generate a working agent architecture. Or they can build from scratch using a visual drag-and-drop interface that requires no coding.What distinguishes Agent Composer from competing approaches, the company says, is its hybrid architecture. Teams can combine strict, deterministic rules for high-stakes steps — compliance checks, data validation, approval gates — with dynamic reasoning for exploratory analysis.\"For highly critical workflows, users can choose completely deterministic steps to control agent behavior and avoid uncertainty,\" Kiela said.The platform also includes what the company calls \"one-click agent optimization,\" which takes user feedback and automatically adjusts agent performance. Every step of an agent&#x27;s reasoning process can be audited, and responses come with sentence-level citations showing exactly where information originated in source documents.From eight hours to 20 minutes: what early customers say about the platform&#x27;s real-world performanceContextual AI says early customers have reported significant efficiency gains, though the company acknowledges these figures come from customer self-reporting rather than independent verification.\"These come directly from customer evals, which are approximations of real-world workflows,\" Kiela said. \"The numbers are self-reported by our customers as they describe the before-and-after scenario of adopting Contextual AI.\"The claimed results are nonetheless striking. An advanced manufacturer reduced root-cause analysis from eight hours to 20 minutes by automating sensor data parsing and log correlation. A specialty chemicals company reduced product research from hours to minutes using agents that search patents and regulatory databases. A test equipment maker now generates test code in minutes instead of days.Keith Schaub, vice president of technology and strategy at Advantest, a semiconductor test equipment company, offered an endorsement. \"Contextual AI has been an important part of our AI transformation efforts,\" Schaub said. \"The technology has been rolled out to multiple teams across Advantest and select end customers, saving meaningful time across tasks ranging from test code generation to customer engineering workflows.\"The company&#x27;s other customers include Qualcomm, the semiconductor giant; ShipBob, a tech-enabled logistics provider that claims to have achieved 60 times faster issue resolution; and Nvidia, the chip maker whose graphics processors power most AI systems.The eternal enterprise dilemma: should companies build their own AI systems or buy off the shelf?Perhaps the biggest challenge Contextual AI faces is not competing products but the instinct among engineering organizations to build their own solutions.\"The biggest objection is &#x27;we&#x27;ll build it ourselves,&#x27;\" Kiela acknowledged. \"Some teams try. It sounds exciting to do, but is exceptionally hard to do this well at scale. Many of our customers started with DIY, and found themselves still debugging retrieval pipelines instead of solving actual problems 12-18 months later.\"The alternative — off-the-shelf point solutions — presents its own problems, the company argues. Such tools deploy quickly but often prove inflexible and difficult to customize for specific use cases.Agent Composer attempts to occupy a middle ground, offering a platform approach that combines pre-built components with extensive customization options. The system supports models from OpenAI, Anthropic, and Google, as well as Contextual AI&#x27;s own Grounded Language Model, which was specifically trained to stay faithful to retrieved content.Pricing starts at $50 per month for self-serve usage, with custom enterprise pricing for larger deployments.\"The justification to CFOs is really about increasing productivity and getting them to production faster with their AI initiatives,\" Kiela said. \"Every technical team is struggling to hire top engineering talent, so making their existing teams more productive is a huge priority in these industries.\"The road ahead: multi-agent coordination, write actions, and the race to build compound AI systemsLooking ahead, Kiela outlined three priorities for the coming year: workflow automation with actual write actions across enterprise systems rather than just reading and analyzing; better coordination among multiple specialized agents working together; and faster specialization through automatic learning from production feedback.\"The compound effect matters here,\" he said. \"Every document you ingest, every feedback loop you close, those improvements stack up. Companies building this infrastructure now are going to be hard to catch.\"The enterprise AI market remains fiercely competitive, with offerings from major cloud providers, established software vendors, and scores of startups all chasing the same customers. Whether Contextual AI&#x27;s bet on context over models will pay off depends on whether enterprises come to share Kiela&#x27;s view that the foundation model wars matter less than the infrastructure that surrounds them.But there is a certain irony in the company&#x27;s positioning. For years, the AI industry has fixated on building ever-larger, ever-more-powerful models — pouring billions into the race for artificial general intelligence. Contextual AI is making a quieter argument: that for most real-world work, the magic isn&#x27;t in the model. It&#x27;s in knowing where to look.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7D559riIdBmeyKqcnnt73u/33667b9af12adb4a7ed7f7c87101c5c1/nuneybits_Vector_art_of_document_stack_magnetic_lines_a4a86f34-d8c7-47e7-bc59-919b7ecc4208-1.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/a-tiktok-us-power-outage-caused-a-cascading-systems-failure-leading-to-multiple-bugs-173426490.html",
          "published_at": "Tue, 27 Jan 2026 16:23:13 +0000",
          "title": "A TikTok US power outage caused a 'cascading systems failure' leading to multiple bugs",
          "standfirst": "If your TikTok feed has felt a little off lately, it's not just you. TikTok says is still working to fix its service in the US following a power outage at one of its data centers that's caused “multiple bugs” in the app. TikTok users have reported problems logging in and uploading videos, as well as strange behavior from the \"for you\" algorithm. Creators have also noticed that new uploads are seemingly getting o views or likes and that in-app earnings have disappeared.\"Since yesterday we’ve been working to restore our services following a power outage at a U.S. data center impacting TikTok and other apps we operate,\" the company wrote in a statement Monday. \"We're working with our data center partner to stabilize our service. We're sorry for this disruption and hope to resolve it soon.\"Since yesterday we’ve been working to restore our services following a power outage at a U.S. data center impacting TikTok and other apps we operate. We're working with our data center partner to stabilize our service. We're sorry for this disruption and hope to resolve it soon.— TikTok USDS Joint Venture (@tiktokusdsjv) January 26, 2026In a subsequent update several hours later, the company said that the power outage had caused a “cascading systems failure” that is still affecting the app and leading to “multiple bugs,” including those affecting view counts and load times. “Creators may temporarily see ‘0’ views or likes on videos, and your earnings may look like they're missing,” the company wrote in an update on X. “This is a display error caused by server timeouts; your actual data and engagement are safe.”An update on our work to restore and stabilize TikTok. pic.twitter.com/PZzsuFeZmj— TikTok USDS Joint Venture (@tiktokusdsjv) January 26, 2026The statement didn’t directly address reported issues with the app’s recommendation algorithm. Since Sunday, users have reported seeing a wave of generic videos flood their feeds, which are typically hyper-personalized. Other users have reported seeing the same few videos repeated over and over again. About a day after the issues started, TikTok said that it had made “significant progress” in recovering from the issues it was facing, but that US users still may “have some technical issues,” specifically when posting new videos. We've made significant progress in recovering our U.S. infrastructure with our U.S. data center partner. However, the U.S. user experience may still have some technical issues, including when posting new content. We're committed to bringing TikTok back to its full capacity as…— TikTok USDS Joint Venture (@tiktokusdsjv) January 27, 2026 The issues come just days after TikTok finalized a deal to spin off its US business into a separate entity largely controlled by US investors. That timing hasn't gone unnoticed by users, many of whom are already suspicious of the company pushing a terms of service and privacy policy in the hours after the deal was finalized. The problems affecting the app's recommendation algorithm have also raised questions about TikTok USDS Joint Venture's plans to \"retrain\" TikTok's central feature.Update, January 26, 2026, 7:18PM ET: This post has been updated to include additional information from TikTok about the outage and bugs affecting users.Update, January 27, 2026, 11:22AM ET: Added TikTok’s latest statement about recovering from the issues that have hit US users.This article originally appeared on Engadget at https://www.engadget.com/social-media/a-tiktok-us-power-outage-caused-a-cascading-systems-failure-leading-to-multiple-bugs-173426490.html?src=rss",
          "content": "If your TikTok feed has felt a little off lately, it's not just you. TikTok says is still working to fix its service in the US following a power outage at one of its data centers that's caused “multiple bugs” in the app. TikTok users have reported problems logging in and uploading videos, as well as strange behavior from the \"for you\" algorithm. Creators have also noticed that new uploads are seemingly getting o views or likes and that in-app earnings have disappeared.\"Since yesterday we’ve been working to restore our services following a power outage at a U.S. data center impacting TikTok and other apps we operate,\" the company wrote in a statement Monday. \"We're working with our data center partner to stabilize our service. We're sorry for this disruption and hope to resolve it soon.\"Since yesterday we’ve been working to restore our services following a power outage at a U.S. data center impacting TikTok and other apps we operate. We're working with our data center partner to stabilize our service. We're sorry for this disruption and hope to resolve it soon.— TikTok USDS Joint Venture (@tiktokusdsjv) January 26, 2026In a subsequent update several hours later, the company said that the power outage had caused a “cascading systems failure” that is still affecting the app and leading to “multiple bugs,” including those affecting view counts and load times. “Creators may temporarily see ‘0’ views or likes on videos, and your earnings may look like they're missing,” the company wrote in an update on X. “This is a display error caused by server timeouts; your actual data and engagement are safe.”An update on our work to restore and stabilize TikTok. pic.twitter.com/PZzsuFeZmj— TikTok USDS Joint Venture (@tiktokusdsjv) January 26, 2026The statement didn’t directly address reported issues with the app’s recommendation algorithm. Since Sunday, users have reported seeing a wave of generic videos flood their feeds, which are typically hyper-personalized. Other users have reported seeing the same few videos repeated over and over again. About a day after the issues started, TikTok said that it had made “significant progress” in recovering from the issues it was facing, but that US users still may “have some technical issues,” specifically when posting new videos. We've made significant progress in recovering our U.S. infrastructure with our U.S. data center partner. However, the U.S. user experience may still have some technical issues, including when posting new content. We're committed to bringing TikTok back to its full capacity as…— TikTok USDS Joint Venture (@tiktokusdsjv) January 27, 2026 The issues come just days after TikTok finalized a deal to spin off its US business into a separate entity largely controlled by US investors. That timing hasn't gone unnoticed by users, many of whom are already suspicious of the company pushing a terms of service and privacy policy in the hours after the deal was finalized. The problems affecting the app's recommendation algorithm have also raised questions about TikTok USDS Joint Venture's plans to \"retrain\" TikTok's central feature.Update, January 26, 2026, 7:18PM ET: This post has been updated to include additional information from TikTok about the outage and bugs affecting users.Update, January 27, 2026, 11:22AM ET: Added TikTok’s latest statement about recovering from the issues that have hit US users.This article originally appeared on Engadget at https://www.engadget.com/social-media/a-tiktok-us-power-outage-caused-a-cascading-systems-failure-leading-to-multiple-bugs-173426490.html?src=rss",
          "feed_position": 19
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/moonshot-ai-debuts-kimi-k2-5-most-powerful-open-source-llm-beating-opus-4-5",
          "published_at": "Tue, 27 Jan 2026 15:55:00 GMT",
          "title": "How Moonshot's Kimi K2.5 helps AI builders spin up agent swarms easier than ever",
          "standfirst": "Chinese company Moonshot AI upgraded its open-sourced Kimi K2 model, transforming it into a coding and vision model with an architecture that supports an agent swarm orchestration. The new model, Moonshot Kimi K2.5, is a good option for enterprises that want agents that can automatically pass off actions instead of having a framework be a central decision-maker.The company characterized Kimi K2.5 as an “all-in-one model” that supports both visual and text inputs, letting users leverage the model for more visual coding projects.Moonshot did not publicly disclose K2.5’s parameter count, but the Kimi K2 model that it&#x27;s based on, had 1 trillion total parameters and 32 billion activated parameters thanks to its mixture-of-experts architecture.This is the latest open-source model to offer an alternative to the more closed options from Google, OpenAI, and Anthropic, and it outperforms them on key metrics including agentic workflows, coding, and vision. On the Humanity’s Last Exam (HLE) benchmark, Kimi K2.5 scored 50.2% (with tools), surpassing OpenAI’s GPT-5.2 (xhigh) and Claude Opus 4.5. It also achieved 76.8% on SWE-bench Verified, cementing its status as a top-tier coding model, though GPT-5.2 and Opus 4.5 overtake it here at 80 and 80.9, respectively. Moonshot said in a press release that it&#x27;s seen a 170% increase in users between September and November for Kimi K2 and Kimi K2 Thinking, which was released in early November. Agent swarm and built-in orchestrationMoonshot aims to leverage self-directed agents and the agent swarm paradigm built into Kimi K2.5. Agent swarm has been touted as the next frontier in enterprise AI development and agent-based systems. It has attracted significant attention in the past few months. For enterprises, this means that if they build agent ecosystems with Kimi K2.5, they can expect to scale more efficiently. But instead of scaling “up” or growing model sizes to create larger agents, it’s betting on making more agents that can essentially orchestrate themselves. Kimi K2.5 “creates and coordinates a swarm of specialized agents working in parallel.” The company compared it to a beehive where each agent performs a task while contributing to a common goal. The model learns to self-direct up to 100 sub-agents and can execute parallel workflows of up to 1,500 tool calls.“Benchmarks only tell half the story. Moonshot AI believes AGI should ultimately be evaluated by its ability to complete real-world tasks efficiently under real-world time constraints. The real metric they care about is: how much of your day did AI actually give back to you? Running in parallel substantially reduces the time needed for a complex task — tasks that required days of work now can be accomplished in minutes,” the company said.Enterprises considering their orchestration strategies have begun looking at agentic platforms where agents communicate and pass off tasks, rather than following a rigid orchestration framework that dictates when an action is completed. While Kimi K2.5 may offer a compelling option for organizations that want to use this form of orchestration, some may feel more comfortable avoiding agent-based orchestration baked into the model and instead using a different platform to differentiate the model training from the agentic task. This is because enterprises often want more flexibility in which models make up their agents, so they can build an ecosystem of agents that tap LLMs that work best for specific actions. Some agent platforms, such as Salesforce, AWS Bedrock, and IBM, offer separate observability, management, and monitoring tools that help users orchestrate AI agents built with different models and enable them to work together. Multimodal coding and visual debuggingThe model lets users code visual layouts, including user interfaces and interactions. It reasons over images and videos to understand tasks encoded in visual inputs. For example, K2.5 can reconstruct a website’s code simply by analyzing a video recording of the site in action, translating visual cues into interactive layouts and animations.“Interfaces, layouts, and interactions that are difficult to describe precisely in language can be communicated through screenshots or screen recordings, which the model can interpret and turn into fully functional websites. This enables a new class of vibe coding experiences,” Moonshot said.This capability is integrated into Kimi Code, a new terminal-based tool that works with IDEs like VSCode and Cursor. It supports \"autonomous visual debugging,\" where the model visually inspects its own output — such as a rendered web page — references documentation, and iterates on the code to fix layout shifts or aesthetic errors without human intervention.Unlike other multimodal models that can create and understand images, Kimi K2.5 can build frontend interactions for websites with visuals, not just the code behind them.API pricingMoonshot AI has aggressively priced the K2.5 API to compete with major U.S. labs, offering significant reductions compared to its previous K2 Turbo model.Input: 60 cents per million tokens (a 47.8% decrease).Cached Input: 10 cents per million tokens (a 33.3% decrease).Output: $3 per million tokens (a 62.5% decrease).The low cost of cached inputs ($0.10/M tokens) is particularly relevant for the \"Agent Swarm\" features, which often require maintaining large context windows across multiple sub-agents and extensive tool usage.Modified MIT licenseWhile Kimi K2.5 is open-sourced, it is released under a Modified MIT License that includes a specific clause targeting \"hyperscale\" commercial users.The license grants standard permissions to use, copy, modify, and sell the software. However, it stipulates that if the software or any derivative work is used for a commercial product or service that has more than 100 million monthly active users (MAU) or more than $20 million USD in monthly revenue, the entity must prominently display \"Kimi K2.5\" on the user interface. This clause ensures that while the model remains free and open for the vast majority of the developer community and startups, major tech giants cannot white-label Moonshot’s technology without providing visible attribution.It&#x27;s not full \"open source\" but it is better than Meta&#x27;s similar Llama Licensing terms for its \"open source\" family of models, which required those companies with 700 million or more monthly users to obtain a special enterprise license from the company. What it means for modern enterprise AI buildersFor the practitioners defining the modern AI stack — from LLM decision-makers optimizing deployment cycles to AI orchestration leaders setting up agents and AI-powered automated business processes — Kimi K2.5 represents a fundamental shift in leverage. By embedding swarm orchestration directly into the model, Moonshot AI effectively hands these resource-constrained builders a synthetic workforce, allowing a single engineer to direct a hundred autonomous sub-agents as easily as a single prompt. This \"scale-out\" architecture directly addresses data decision-makers&#x27; dilemma of balancing complex pipelines with limited headcount, while the slashed pricing structure transforms high-context data processing from a budget-breaking luxury into a routine commodity. Ultimately, K2.5 suggests a future where the primary constraint on an engineering team is no longer the number of hands on keyboards, but the ability of its leaders to choreograph a swarm.",
          "content": "Chinese company Moonshot AI upgraded its open-sourced Kimi K2 model, transforming it into a coding and vision model with an architecture that supports an agent swarm orchestration. The new model, Moonshot Kimi K2.5, is a good option for enterprises that want agents that can automatically pass off actions instead of having a framework be a central decision-maker.The company characterized Kimi K2.5 as an “all-in-one model” that supports both visual and text inputs, letting users leverage the model for more visual coding projects.Moonshot did not publicly disclose K2.5’s parameter count, but the Kimi K2 model that it&#x27;s based on, had 1 trillion total parameters and 32 billion activated parameters thanks to its mixture-of-experts architecture.This is the latest open-source model to offer an alternative to the more closed options from Google, OpenAI, and Anthropic, and it outperforms them on key metrics including agentic workflows, coding, and vision. On the Humanity’s Last Exam (HLE) benchmark, Kimi K2.5 scored 50.2% (with tools), surpassing OpenAI’s GPT-5.2 (xhigh) and Claude Opus 4.5. It also achieved 76.8% on SWE-bench Verified, cementing its status as a top-tier coding model, though GPT-5.2 and Opus 4.5 overtake it here at 80 and 80.9, respectively. Moonshot said in a press release that it&#x27;s seen a 170% increase in users between September and November for Kimi K2 and Kimi K2 Thinking, which was released in early November. Agent swarm and built-in orchestrationMoonshot aims to leverage self-directed agents and the agent swarm paradigm built into Kimi K2.5. Agent swarm has been touted as the next frontier in enterprise AI development and agent-based systems. It has attracted significant attention in the past few months. For enterprises, this means that if they build agent ecosystems with Kimi K2.5, they can expect to scale more efficiently. But instead of scaling “up” or growing model sizes to create larger agents, it’s betting on making more agents that can essentially orchestrate themselves. Kimi K2.5 “creates and coordinates a swarm of specialized agents working in parallel.” The company compared it to a beehive where each agent performs a task while contributing to a common goal. The model learns to self-direct up to 100 sub-agents and can execute parallel workflows of up to 1,500 tool calls.“Benchmarks only tell half the story. Moonshot AI believes AGI should ultimately be evaluated by its ability to complete real-world tasks efficiently under real-world time constraints. The real metric they care about is: how much of your day did AI actually give back to you? Running in parallel substantially reduces the time needed for a complex task — tasks that required days of work now can be accomplished in minutes,” the company said.Enterprises considering their orchestration strategies have begun looking at agentic platforms where agents communicate and pass off tasks, rather than following a rigid orchestration framework that dictates when an action is completed. While Kimi K2.5 may offer a compelling option for organizations that want to use this form of orchestration, some may feel more comfortable avoiding agent-based orchestration baked into the model and instead using a different platform to differentiate the model training from the agentic task. This is because enterprises often want more flexibility in which models make up their agents, so they can build an ecosystem of agents that tap LLMs that work best for specific actions. Some agent platforms, such as Salesforce, AWS Bedrock, and IBM, offer separate observability, management, and monitoring tools that help users orchestrate AI agents built with different models and enable them to work together. Multimodal coding and visual debuggingThe model lets users code visual layouts, including user interfaces and interactions. It reasons over images and videos to understand tasks encoded in visual inputs. For example, K2.5 can reconstruct a website’s code simply by analyzing a video recording of the site in action, translating visual cues into interactive layouts and animations.“Interfaces, layouts, and interactions that are difficult to describe precisely in language can be communicated through screenshots or screen recordings, which the model can interpret and turn into fully functional websites. This enables a new class of vibe coding experiences,” Moonshot said.This capability is integrated into Kimi Code, a new terminal-based tool that works with IDEs like VSCode and Cursor. It supports \"autonomous visual debugging,\" where the model visually inspects its own output — such as a rendered web page — references documentation, and iterates on the code to fix layout shifts or aesthetic errors without human intervention.Unlike other multimodal models that can create and understand images, Kimi K2.5 can build frontend interactions for websites with visuals, not just the code behind them.API pricingMoonshot AI has aggressively priced the K2.5 API to compete with major U.S. labs, offering significant reductions compared to its previous K2 Turbo model.Input: 60 cents per million tokens (a 47.8% decrease).Cached Input: 10 cents per million tokens (a 33.3% decrease).Output: $3 per million tokens (a 62.5% decrease).The low cost of cached inputs ($0.10/M tokens) is particularly relevant for the \"Agent Swarm\" features, which often require maintaining large context windows across multiple sub-agents and extensive tool usage.Modified MIT licenseWhile Kimi K2.5 is open-sourced, it is released under a Modified MIT License that includes a specific clause targeting \"hyperscale\" commercial users.The license grants standard permissions to use, copy, modify, and sell the software. However, it stipulates that if the software or any derivative work is used for a commercial product or service that has more than 100 million monthly active users (MAU) or more than $20 million USD in monthly revenue, the entity must prominently display \"Kimi K2.5\" on the user interface. This clause ensures that while the model remains free and open for the vast majority of the developer community and startups, major tech giants cannot white-label Moonshot’s technology without providing visible attribution.It&#x27;s not full \"open source\" but it is better than Meta&#x27;s similar Llama Licensing terms for its \"open source\" family of models, which required those companies with 700 million or more monthly users to obtain a special enterprise license from the company. What it means for modern enterprise AI buildersFor the practitioners defining the modern AI stack — from LLM decision-makers optimizing deployment cycles to AI orchestration leaders setting up agents and AI-powered automated business processes — Kimi K2.5 represents a fundamental shift in leverage. By embedding swarm orchestration directly into the model, Moonshot AI effectively hands these resource-constrained builders a synthetic workforce, allowing a single engineer to direct a hundred autonomous sub-agents as easily as a single prompt. This \"scale-out\" architecture directly addresses data decision-makers&#x27; dilemma of balancing complex pipelines with limited headcount, while the slashed pricing structure transforms high-context data processing from a budget-breaking luxury into a routine commodity. Ultimately, K2.5 suggests a future where the primary constraint on an engineering team is no longer the number of hands on keyboards, but the ability of its leaders to choreograph a swarm.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2iLBE9v5t6ejW8f0hnUwvC/c66e705f844eeb77e5ad5e4d4da8e775/Carl_Franzen_gradient_geometric_mod_1960s_vintage_retro_saul_ba_b2455727-7fcd-4130-9e74-681903b5456b.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/a-european-ai-challenger-goes-after-github-copilot-mistral-launches-vibe-2-0",
          "published_at": "Tue, 27 Jan 2026 15:00:00 GMT",
          "title": "A European AI challenger goes after GitHub Copilot: Mistral launches Vibe 2.0",
          "standfirst": "Mistral AI, the French artificial intelligence company that has positioned itself as Europe&#x27;s leading challenger to American AI giants, announced on Tuesday the general availability of Mistral Vibe 2.0, a significant upgrade to its terminal-based coding agent that’s the startup&#x27;s most aggressive push yet into the competitive AI-assisted software development market.The release is a pivotal moment for the Paris-based company, which is transitioning its developer tools from a free testing phase to a commercial product integrated with its paid subscription plans. The move comes just days after Mistral CEO Arthur Mensch told Bloomberg Television at the World Economic Forum in Davos that the company expects to cross €1 billion in revenue by the end of 2026 — a projection that would still leave it far behind American competitors but would cement its position as Europe&#x27;s preeminent AI firm.\"The announcement is more of an upgrade and general availability,\" Timothée Lacroix, cofounder of Mistral, said in an exclusive interview with VentureBeat. \"We produced Devstral 2 in December, and we released at the time a first version of Vibe. Everything was free and in testing. Now we have finalized and improved the CLI, and we are moving Mistral Vibe to a paid plan that&#x27;s bundled with our Le Chat plans.\"Why legacy enterprise code is AI&#x27;s blind spotMistral Vibe 2.0 arrives as technology executives across industries grapple with a fundamental tension: the promise of AI-powered coding tools is immense, but the most capable models are controlled by a handful of American companies — OpenAI, Anthropic, and Google — whose closed-source approaches leave enterprises with limited control over their most sensitive intellectual property.Mistral is betting that its open-source approach, combined with deep customization capabilities, will appeal to organizations wary of sending proprietary code to third-party providers. The strategy targets a specific pain point that Lacroix says plagues enterprises with legacy systems.\"The code bases that large enterprise work with are large and have been built upon years and years, and they haven&#x27;t seen the web,\" Lacroix explained. \"They potentially rely on large libraries or large domain-specific languages that are unknown to typical language models. And so what we&#x27;re able to do with the Vibe CLI and our models is to go and customize them to a customer&#x27;s code base and its specific IP to get an improved experience.\"This customization capability addresses a limitation that has frustrated many enterprise technology leaders: general-purpose AI coding assistants trained on public code repositories often struggle with proprietary frameworks, internal coding conventions, and domain-specific languages that exist only within corporate walls. A bank&#x27;s internal trading system, a manufacturer&#x27;s proprietary control software, or a pharmaceutical company&#x27;s research pipeline may rely on decades of accumulated code written in conventions that no public AI model has ever encountered.Custom subagents and clarification prompts give developers more controlThe updated Vibe CLI introduces several features designed to give developers more granular control over how the AI agent operates. Custom subagents allow organizations to build specialized AI agents for targeted tasks—such as deployment scripts, pull request reviews, or test generation—that can be invoked on demand rather than relying on a single general-purpose assistant.Multi-choice clarifications are a departure from the behavior of many AI coding tools that attempt to infer developer intent when instructions are ambiguous. Instead, Vibe 2.0 prompts users with options before taking action, reducing the risk of unwanted code changes. Slash-command skills enable developers to load preconfigured workflows for common tasks like deploying, linting, or generating documentation through simple commands. Unified agent modes allow teams to configure custom operational modes that combine specific tools, permissions, and behaviors, enabling developers to switch contexts without switching between different applications. The tool also now ships with continuous updates through the command line, eliminating the need for manual version management.Mistral Vibe 2.0 is available through two subscription tiers. The Le Chat Pro plan costs $14.99 per month and provides full access to the Vibe CLI and Devstral 2, the underlying model that powers the agent, with students receiving a 50 percent discount. The Le Chat Team plan, priced at $24.99 per seat per month, adds unified billing, administrative controls, and priority support for organizations. Both plans include generous usage allowances for sustained development work, with the option to continue beyond limits through pay-as-you-go pricing at API rates. The underlying Devstral 2 model, which previously was offered free through Mistral&#x27;s API during a testing period, now moves to paid access with input pricing of $0.40 per million tokens and output pricing of $2.00 per million tokens.Smaller, denser models challenge the bigger-is-better assumptionThe Devstral 2 model family that powers Vibe CLI is Mistral&#x27;s bet that smaller, more efficient models can compete with — and in some cases outperform — the massive systems built by better-funded American rivals. Devstral 2, a 123-billion-parameter dense transformer, achieves 72.2 percent on SWE-bench Verified, a widely used benchmark for evaluating AI systems&#x27; ability to solve real-world software engineering problems.Perhaps more significant for enterprise deployment, the model is roughly five times smaller than DeepSeek V3.2 and eight times smaller than Kimi K2 — Chinese models that have drawn attention for matching American AI systems at a fraction of the cost. The smaller Devstral 2 Small, at 24 billion parameters, can run on consumer hardware including laptops.\"Those two models are dense, which makes it also—I mean, the small one is something that can run on a laptop, really, which is great if you&#x27;re working on the train,\" Lacroix noted. \"But the fact that the larger one is also dense is interesting for on-prem or more resource-constrained usage, where it&#x27;s easier to get efficient use of a dense model rather than large mixture of experts, and it requires smaller hardware to start.\"The distinction between dense and mixture-of-experts architectures is technically significant. While mixture-of-experts models can theoretically offer more capability per compute dollar by activating only portions of their parameters for any given task, they require more complex infrastructure to deploy efficiently. Dense models, by contrast, activate all parameters for every computation but are more straightforward to run on conventional hardware — a meaningful consideration for enterprises that want to deploy AI systems on their own infrastructure rather than relying on cloud providers.Banks and defense contractors want AI that never leaves their wallsFor regulated industries — particularly financial services, healthcare, and defense — the question of where AI models run and who has access to the data they process is not merely technical but existential. Banks cannot send proprietary trading algorithms to external AI providers. Healthcare organizations face strict regulations about patient data. Defense contractors operate under security clearances that prohibit sharing sensitive information with foreign entities.Lacroix suggests that the on-premises deployment capability, while important, is secondary to a more fundamental concern about ownership and control. \"The fact that it&#x27;s on-prem, I think, is less relevant than the fact that it&#x27;s owned by the company and that it&#x27;s on wherever they feel safe moving that data — like they&#x27;re not shipping the entire code base to a third party,\" he said. \"I think that&#x27;s important.\"This framing positions Mistral not merely as a vendor of AI tools but as a partner in building proprietary AI capabilities that become strategic assets for client organizations. \"When we work with a company to then customize them and potentially fine-tune them or continue pre-training them, then they become assets to that company, and they are their own competitive advantage, really,\" Lacroix explained.Mistral has actively cultivated relationships with governments to underscore this positioning. The company serves defense ministries in Europe and Southeast Asia, both directly and through defense contractors. At Davos, Mensch described AI as critical not only to economic sovereignty but to \"strategic sovereignty,\" noting that autonomous systems like drones require AI capabilities and that deterrence in this domain is increasingly important.Mistral&#x27;s CEO dismisses the idea that China lags in artificial intelligenceMistral&#x27;s positioning as a European alternative to American AI giants takes on added significance amid rising geopolitical tensions. At the World Economic Forum, Mensch was characteristically blunt about the competitive landscape, dismissing claims that Chinese AI development lags the United States as a \"fairy tale.\"\"China is not behind the West,\" Mensch said in his Bloomberg Television interview. The capabilities of China&#x27;s open-source technology, he added, are \"probably stressing the CEOs in the U.S.\"The comments reflect a broader anxiety in the AI industry about the durability of American technological leadership. Chinese companies including DeepSeek and Alibaba have released open-source models that match or exceed many American systems, often at dramatically lower costs. For Mistral, this competitive pressure validates its strategy of focusing on efficiency and customization rather than attempting to match the massive training runs of better-capitalized American rivals.European Commission digital chief Henna Virkkunen, also speaking at Davos, underscored the strategic importance of technological sovereignty. \"It&#x27;s so important that we are not dependent on one country or one company when it comes to some very critical fields of our economy or society,\" she said.For American enterprise customers, Lacroix suggests that Mistral&#x27;s European identity and government relationships need not be a concern — and may even be an advantage. \"One of the benefits when working as we do, like with open weights, and especially when deploying on customers&#x27; premises and giving them control, is that the wider geopolitics don&#x27;t necessarily matter that much,\" he said. \"I think the benefits of the open-source scene is that it gives you confidence that you know what you&#x27;re using, and you&#x27;re in total control of it.\"From model maker to enterprise platform signals a strategic pivotMistral&#x27;s transition from a pure model company to what Lacroix describes as \"a full enterprise platform around developing AI applications\" reflects a broader maturation in the AI industry. The realization that model weights alone do not capture the full value of AI systems has pushed companies across the sector toward more integrated offerings.\"We don&#x27;t think the only value we provide is in the model,\" Lacroix said. \"We started as a models company. We are now building a full enterprise platform around developing AI applications. We have a part of our company that provides services to integrate deeply. And so the way we make money, and I guess the question behind this is the value that is core to Mistral, is that full-stack solution to getting to the ROI of AI.\"This full-stack approach includes fine-tuning on internal languages and domain-specific languages, reinforcement learning with customer-specific environments, and end-to-end code modernization services that can migrate entire codebases to modern technology stacks. Mistral says it already delivers these solutions to some of the world&#x27;s largest organizations in finance, defense, and infrastructure.The revenue milestone Mensch projected at Davos — crossing €1 billion by year&#x27;s end — would represent remarkable growth for a company founded in 2023. But it would still leave Mistral far behind American competitors whose valuations stretch into the hundreds of billions. OpenAI, now reportedly valued at more than $150 billion, and Anthropic, valued at approximately $60 billion, operate at a scale that Mistral cannot match through organic growth alone. To close the gap, Mistral is looking at acquisitions. \"We are in the process of looking at a few opportunities,\" Mensch said at Davos, though he declined to specify target business areas or geographic regions. The company&#x27;s September fundraise brought in €1.7 billion, with Dutch semiconductor equipment giant ASML joining as a key investor, valuing Mistral at €11.7 billion.The coding assistant wars are just getting startedLooking beyond the immediate product announcement, Lacroix sees the current generation of AI coding tools as a transitional phase toward more autonomous software development. \"For a few tasks, it&#x27;s already becoming the default entry point — like if I want to prototype something, or if I want to quickly iterate on an idea. I think it&#x27;s already faster,\" he said. \"What I see today is there is still some story that needs to happen on how you do the work asynchronously and in a way where it&#x27;s easy to orchestrate several tasks and several improvements on the same code base in a flow that feels natural.\"The current experience, he suggests, does not yet feel like having \"your own team of developers that can really 10x yourself.\" But he expects rapid improvement, driven by abundant training data and intense industry interest. Perhaps more ambitiously, Lacroix sees the file-manipulation and tool-calling capabilities built for coding as applicable far beyond software development. \"What I&#x27;m really excited about is the use of these tools outside of coding,\" he said. \"The really strong realization is you now have an agent that is great at working with a file system, that can edit information and that expands its context a lot, and it&#x27;s really great at using all sorts of tools. Those tools don&#x27;t need to be necessarily related to coding, really.\"For chief technology officers and engineering leaders evaluating AI coding tools, Mistral&#x27;s announcement crystallizes the strategic choice now facing enterprises: accept the convenience and raw capability of closed-source American models, or bet on the flexibility and control of open-source alternatives that can be customized and deployed behind corporate firewalls. Human evaluations comparing Devstral 2 against Claude Sonnet 4.5 showed that Anthropic&#x27;s model was \"significantly preferred,\" according to Mistral&#x27;s own benchmarking — an acknowledgment that closed-source leaders retain advantages that efficiency and customization cannot fully offset.But Lacroix is betting that for enterprises with proprietary code, legacy systems, and regulatory constraints, customization will matter more than raw performance on public benchmarks. \"The point is that you can now get all of this vibe coding disruption and goodness in an environment where customization is needed, which was difficult before,\" he said. \"And that&#x27;s, I think, the main point that we&#x27;re making with this announcement.\"The AI coding wars, in other words, are no longer just about which model writes the best code. They&#x27;re about who gets to own the model that understands yours.",
          "content": "Mistral AI, the French artificial intelligence company that has positioned itself as Europe&#x27;s leading challenger to American AI giants, announced on Tuesday the general availability of Mistral Vibe 2.0, a significant upgrade to its terminal-based coding agent that’s the startup&#x27;s most aggressive push yet into the competitive AI-assisted software development market.The release is a pivotal moment for the Paris-based company, which is transitioning its developer tools from a free testing phase to a commercial product integrated with its paid subscription plans. The move comes just days after Mistral CEO Arthur Mensch told Bloomberg Television at the World Economic Forum in Davos that the company expects to cross €1 billion in revenue by the end of 2026 — a projection that would still leave it far behind American competitors but would cement its position as Europe&#x27;s preeminent AI firm.\"The announcement is more of an upgrade and general availability,\" Timothée Lacroix, cofounder of Mistral, said in an exclusive interview with VentureBeat. \"We produced Devstral 2 in December, and we released at the time a first version of Vibe. Everything was free and in testing. Now we have finalized and improved the CLI, and we are moving Mistral Vibe to a paid plan that&#x27;s bundled with our Le Chat plans.\"Why legacy enterprise code is AI&#x27;s blind spotMistral Vibe 2.0 arrives as technology executives across industries grapple with a fundamental tension: the promise of AI-powered coding tools is immense, but the most capable models are controlled by a handful of American companies — OpenAI, Anthropic, and Google — whose closed-source approaches leave enterprises with limited control over their most sensitive intellectual property.Mistral is betting that its open-source approach, combined with deep customization capabilities, will appeal to organizations wary of sending proprietary code to third-party providers. The strategy targets a specific pain point that Lacroix says plagues enterprises with legacy systems.\"The code bases that large enterprise work with are large and have been built upon years and years, and they haven&#x27;t seen the web,\" Lacroix explained. \"They potentially rely on large libraries or large domain-specific languages that are unknown to typical language models. And so what we&#x27;re able to do with the Vibe CLI and our models is to go and customize them to a customer&#x27;s code base and its specific IP to get an improved experience.\"This customization capability addresses a limitation that has frustrated many enterprise technology leaders: general-purpose AI coding assistants trained on public code repositories often struggle with proprietary frameworks, internal coding conventions, and domain-specific languages that exist only within corporate walls. A bank&#x27;s internal trading system, a manufacturer&#x27;s proprietary control software, or a pharmaceutical company&#x27;s research pipeline may rely on decades of accumulated code written in conventions that no public AI model has ever encountered.Custom subagents and clarification prompts give developers more controlThe updated Vibe CLI introduces several features designed to give developers more granular control over how the AI agent operates. Custom subagents allow organizations to build specialized AI agents for targeted tasks—such as deployment scripts, pull request reviews, or test generation—that can be invoked on demand rather than relying on a single general-purpose assistant.Multi-choice clarifications are a departure from the behavior of many AI coding tools that attempt to infer developer intent when instructions are ambiguous. Instead, Vibe 2.0 prompts users with options before taking action, reducing the risk of unwanted code changes. Slash-command skills enable developers to load preconfigured workflows for common tasks like deploying, linting, or generating documentation through simple commands. Unified agent modes allow teams to configure custom operational modes that combine specific tools, permissions, and behaviors, enabling developers to switch contexts without switching between different applications. The tool also now ships with continuous updates through the command line, eliminating the need for manual version management.Mistral Vibe 2.0 is available through two subscription tiers. The Le Chat Pro plan costs $14.99 per month and provides full access to the Vibe CLI and Devstral 2, the underlying model that powers the agent, with students receiving a 50 percent discount. The Le Chat Team plan, priced at $24.99 per seat per month, adds unified billing, administrative controls, and priority support for organizations. Both plans include generous usage allowances for sustained development work, with the option to continue beyond limits through pay-as-you-go pricing at API rates. The underlying Devstral 2 model, which previously was offered free through Mistral&#x27;s API during a testing period, now moves to paid access with input pricing of $0.40 per million tokens and output pricing of $2.00 per million tokens.Smaller, denser models challenge the bigger-is-better assumptionThe Devstral 2 model family that powers Vibe CLI is Mistral&#x27;s bet that smaller, more efficient models can compete with — and in some cases outperform — the massive systems built by better-funded American rivals. Devstral 2, a 123-billion-parameter dense transformer, achieves 72.2 percent on SWE-bench Verified, a widely used benchmark for evaluating AI systems&#x27; ability to solve real-world software engineering problems.Perhaps more significant for enterprise deployment, the model is roughly five times smaller than DeepSeek V3.2 and eight times smaller than Kimi K2 — Chinese models that have drawn attention for matching American AI systems at a fraction of the cost. The smaller Devstral 2 Small, at 24 billion parameters, can run on consumer hardware including laptops.\"Those two models are dense, which makes it also—I mean, the small one is something that can run on a laptop, really, which is great if you&#x27;re working on the train,\" Lacroix noted. \"But the fact that the larger one is also dense is interesting for on-prem or more resource-constrained usage, where it&#x27;s easier to get efficient use of a dense model rather than large mixture of experts, and it requires smaller hardware to start.\"The distinction between dense and mixture-of-experts architectures is technically significant. While mixture-of-experts models can theoretically offer more capability per compute dollar by activating only portions of their parameters for any given task, they require more complex infrastructure to deploy efficiently. Dense models, by contrast, activate all parameters for every computation but are more straightforward to run on conventional hardware — a meaningful consideration for enterprises that want to deploy AI systems on their own infrastructure rather than relying on cloud providers.Banks and defense contractors want AI that never leaves their wallsFor regulated industries — particularly financial services, healthcare, and defense — the question of where AI models run and who has access to the data they process is not merely technical but existential. Banks cannot send proprietary trading algorithms to external AI providers. Healthcare organizations face strict regulations about patient data. Defense contractors operate under security clearances that prohibit sharing sensitive information with foreign entities.Lacroix suggests that the on-premises deployment capability, while important, is secondary to a more fundamental concern about ownership and control. \"The fact that it&#x27;s on-prem, I think, is less relevant than the fact that it&#x27;s owned by the company and that it&#x27;s on wherever they feel safe moving that data — like they&#x27;re not shipping the entire code base to a third party,\" he said. \"I think that&#x27;s important.\"This framing positions Mistral not merely as a vendor of AI tools but as a partner in building proprietary AI capabilities that become strategic assets for client organizations. \"When we work with a company to then customize them and potentially fine-tune them or continue pre-training them, then they become assets to that company, and they are their own competitive advantage, really,\" Lacroix explained.Mistral has actively cultivated relationships with governments to underscore this positioning. The company serves defense ministries in Europe and Southeast Asia, both directly and through defense contractors. At Davos, Mensch described AI as critical not only to economic sovereignty but to \"strategic sovereignty,\" noting that autonomous systems like drones require AI capabilities and that deterrence in this domain is increasingly important.Mistral&#x27;s CEO dismisses the idea that China lags in artificial intelligenceMistral&#x27;s positioning as a European alternative to American AI giants takes on added significance amid rising geopolitical tensions. At the World Economic Forum, Mensch was characteristically blunt about the competitive landscape, dismissing claims that Chinese AI development lags the United States as a \"fairy tale.\"\"China is not behind the West,\" Mensch said in his Bloomberg Television interview. The capabilities of China&#x27;s open-source technology, he added, are \"probably stressing the CEOs in the U.S.\"The comments reflect a broader anxiety in the AI industry about the durability of American technological leadership. Chinese companies including DeepSeek and Alibaba have released open-source models that match or exceed many American systems, often at dramatically lower costs. For Mistral, this competitive pressure validates its strategy of focusing on efficiency and customization rather than attempting to match the massive training runs of better-capitalized American rivals.European Commission digital chief Henna Virkkunen, also speaking at Davos, underscored the strategic importance of technological sovereignty. \"It&#x27;s so important that we are not dependent on one country or one company when it comes to some very critical fields of our economy or society,\" she said.For American enterprise customers, Lacroix suggests that Mistral&#x27;s European identity and government relationships need not be a concern — and may even be an advantage. \"One of the benefits when working as we do, like with open weights, and especially when deploying on customers&#x27; premises and giving them control, is that the wider geopolitics don&#x27;t necessarily matter that much,\" he said. \"I think the benefits of the open-source scene is that it gives you confidence that you know what you&#x27;re using, and you&#x27;re in total control of it.\"From model maker to enterprise platform signals a strategic pivotMistral&#x27;s transition from a pure model company to what Lacroix describes as \"a full enterprise platform around developing AI applications\" reflects a broader maturation in the AI industry. The realization that model weights alone do not capture the full value of AI systems has pushed companies across the sector toward more integrated offerings.\"We don&#x27;t think the only value we provide is in the model,\" Lacroix said. \"We started as a models company. We are now building a full enterprise platform around developing AI applications. We have a part of our company that provides services to integrate deeply. And so the way we make money, and I guess the question behind this is the value that is core to Mistral, is that full-stack solution to getting to the ROI of AI.\"This full-stack approach includes fine-tuning on internal languages and domain-specific languages, reinforcement learning with customer-specific environments, and end-to-end code modernization services that can migrate entire codebases to modern technology stacks. Mistral says it already delivers these solutions to some of the world&#x27;s largest organizations in finance, defense, and infrastructure.The revenue milestone Mensch projected at Davos — crossing €1 billion by year&#x27;s end — would represent remarkable growth for a company founded in 2023. But it would still leave Mistral far behind American competitors whose valuations stretch into the hundreds of billions. OpenAI, now reportedly valued at more than $150 billion, and Anthropic, valued at approximately $60 billion, operate at a scale that Mistral cannot match through organic growth alone. To close the gap, Mistral is looking at acquisitions. \"We are in the process of looking at a few opportunities,\" Mensch said at Davos, though he declined to specify target business areas or geographic regions. The company&#x27;s September fundraise brought in €1.7 billion, with Dutch semiconductor equipment giant ASML joining as a key investor, valuing Mistral at €11.7 billion.The coding assistant wars are just getting startedLooking beyond the immediate product announcement, Lacroix sees the current generation of AI coding tools as a transitional phase toward more autonomous software development. \"For a few tasks, it&#x27;s already becoming the default entry point — like if I want to prototype something, or if I want to quickly iterate on an idea. I think it&#x27;s already faster,\" he said. \"What I see today is there is still some story that needs to happen on how you do the work asynchronously and in a way where it&#x27;s easy to orchestrate several tasks and several improvements on the same code base in a flow that feels natural.\"The current experience, he suggests, does not yet feel like having \"your own team of developers that can really 10x yourself.\" But he expects rapid improvement, driven by abundant training data and intense industry interest. Perhaps more ambitiously, Lacroix sees the file-manipulation and tool-calling capabilities built for coding as applicable far beyond software development. \"What I&#x27;m really excited about is the use of these tools outside of coding,\" he said. \"The really strong realization is you now have an agent that is great at working with a file system, that can edit information and that expands its context a lot, and it&#x27;s really great at using all sorts of tools. Those tools don&#x27;t need to be necessarily related to coding, really.\"For chief technology officers and engineering leaders evaluating AI coding tools, Mistral&#x27;s announcement crystallizes the strategic choice now facing enterprises: accept the convenience and raw capability of closed-source American models, or bet on the flexibility and control of open-source alternatives that can be customized and deployed behind corporate firewalls. Human evaluations comparing Devstral 2 against Claude Sonnet 4.5 showed that Anthropic&#x27;s model was \"significantly preferred,\" according to Mistral&#x27;s own benchmarking — an acknowledgment that closed-source leaders retain advantages that efficiency and customization cannot fully offset.But Lacroix is betting that for enterprises with proprietary code, legacy systems, and regulatory constraints, customization will matter more than raw performance on public benchmarks. \"The point is that you can now get all of this vibe coding disruption and goodness in an environment where customization is needed, which was difficult before,\" he said. \"And that&#x27;s, I think, the main point that we&#x27;re making with this announcement.\"The AI coding wars, in other words, are no longer just about which model writes the best code. They&#x27;re about who gets to own the model that understands yours.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3YLcY3tgbv5EFx2N4c7ozJ/6bf2e3964aa31954df08fac31fe0ca11/nuneybits_Vector_art_of_bold_orange_gradient_background_giant_w_de5ae005-57bc-4419-99b6-35be2ec9522f.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/theorem-wants-to-stop-ai-written-bugs-before-they-ship-and-just-raised-usd6m",
          "published_at": "Tue, 27 Jan 2026 14:00:00 GMT",
          "title": "Theorem wants to stop AI-written bugs before they ship — and just raised $6M to do it",
          "standfirst": "As artificial intelligence reshapes software development, a small startup is betting that the industry&#x27;s next big bottleneck won&#x27;t be writing code — it will be trusting it.Theorem, a San Francisco-based company that emerged from Y Combinator&#x27;s Spring 2025 batch, announced Tuesday it has raised $6 million in seed funding to build automated tools that verify the correctness of AI-generated software. Khosla Ventures led the round, with participation from Y Combinator, e14, SAIF, Halcyon, and angel investors including Blake Borgesson, co-founder of Recursion Pharmaceuticals, and Arthur Breitman, co-founder of blockchain platform Tezos.The investment arrives at a pivotal moment. AI coding assistants from companies like GitHub, Amazon, and Google now generate billions of lines of code annually. Enterprise adoption is accelerating. But the ability to verify that AI-written software actually works as intended has not kept pace — creating what Theorem&#x27;s founders describe as a widening \"oversight gap\" that threatens critical infrastructure from financial systems to power grids.\"We&#x27;re already there,\" said Jason Gross, Theorem&#x27;s co-founder, when we asked whether AI-generated code is outpacing human review capacity. \"If you asked me to review 60,000 lines of code, I wouldn&#x27;t know how to do it.\"Why AI is writing code faster than humans can verify itTheorem&#x27;s core technology combines formal verification — a mathematical technique that proves software behaves exactly as specified — with AI models trained to generate and check proofs automatically. The approach transforms a process that historically required years of PhD-level engineering into something the company claims can be completed in weeks or even days.Formal verification has existed for decades but remained confined to the most mission-critical applications: avionics systems, nuclear reactor controls, and cryptographic protocols. The technique&#x27;s prohibitive cost — often requiring eight lines of mathematical proof for every single line of code — made it impractical for mainstream software development.Gross knows this firsthand. Before founding Theorem, he earned his PhD at MIT working on verified cryptography code that now powers the HTTPS security protocol protecting trillions of internet connections daily. That project, by his estimate, consumed fifteen person-years of labor.\"Nobody prefers to have incorrect code,\" Gross said. \"Software verification has just not been economical before. Proofs used to be written by PhD-level engineers. Now, AI writes all of it.\"How formal verification catches the bugs that traditional testing missesTheorem&#x27;s system operates on a principle Gross calls \"fractional proof decomposition.\" Rather than exhaustively testing every possible behavior — computationally infeasible for complex software — the technology allocates verification resources proportionally to the importance of each code component.The approach recently identified a bug that slipped past testing at Anthropic, the AI safety company behind the Claude chatbot. Gross said the technique helps developers \"catch their bugs now without expending a lot of compute.\"In a recent technical demonstration called SFBench, Theorem used AI to translate 1,276 problems from Rocq (a formal proof assistant) to Lean (another verification language), then automatically proved each translation equivalent to the original. The company estimates a human team would have required approximately 2.7 person-years to complete the same work.\"Everyone can run agents in parallel, but we are also able to run them sequentially,\" Gross explained, noting that Theorem&#x27;s architecture handles interdependent code — where solutions build on each other across dozens of files — that trips up conventional AI coding agents limited by context windows.How one company turned a 1,500-page specification into 16,000 lines of trusted codeThe startup is already working with customers in AI research labs, electronic design automation, and GPU-accelerated computing. One case study illustrates the technology&#x27;s practical value.A customer came to Theorem with a 1,500-page PDF specification and a legacy software implementation plagued by memory leaks, crashes, and other elusive bugs. Their most urgent problem: improving performance from 10 megabits per second to 1 gigabit per second — a 100-fold increase — without introducing additional errors.Theorem&#x27;s system generated 16,000 lines of production code, which the customer deployed without ever manually reviewing it. The confidence came from a compact executable specification — a few hundred lines that generalized the massive PDF document — paired with an equivalence-checking harness that verified the new implementation matched the intended behavior.\"Now they have a production-grade parser operating at 1 Gbps that they can deploy with the confidence that no information is lost during parsing,\" Gross said.The security risks lurking in AI-generated software for critical infrastructureThe funding announcement arrives as policymakers and technologists increasingly scrutinize the reliability of AI systems embedded in critical infrastructure. Software already controls financial markets, medical devices, transportation networks, and electrical grids. AI is accelerating how quickly that software evolves — and how easily subtle bugs can propagate.Gross frames the challenge in security terms. As AI makes it cheaper to find and exploit vulnerabilities, defenders need what he calls \"asymmetric defense\" — protection that scales without proportional increases in resources.\"Software security is a delicate offense-defense balance,\" he said. \"With AI hacking, the cost of hacking a system is falling sharply. The only viable solution is asymmetric defense. If we want a software security solution that can last for more than a few generations of model improvements, it will be via verification.\"Asked whether regulators should mandate formal verification for AI-generated code in critical systems, Gross offered a pointed response: \"Now that formal verification is cheap enough, it might be considered gross negligence to not use it for guarantees about critical systems.\"What separates Theorem from other AI code verification startupsTheorem enters a market where numerous startups and research labs are exploring the intersection of AI and formal verification. The company&#x27;s differentiation, Gross argues, lies in its singular focus on scaling software oversight rather than applying verification to mathematics or other domains.\"Our tools are useful for systems engineering teams, working close to the metal, who need correctness guarantees before merging changes,\" he said.The founding team reflects that technical orientation. Gross brings deep expertise in programming language theory and a track record of deploying verified code into production at scale. Co-founder Rajashree Agrawal, a machine learning research engineer, focuses on training the AI models that power the verification pipeline.\"We&#x27;re working on formal program reasoning so that everyone can oversee not just the work of an average software-engineer-level AI, but really harness the capabilities of a Linus Torvalds-level AI,\" Agrawal said, referencing the legendary creator of Linux.The race to verify AI code before it controls everythingTheorem plans to use the funding to expand its team, increase compute resources for training verification models, and push into new industries including robotics, renewable energy, cryptocurrency, and drug synthesis. The company currently employs four people.The startup&#x27;s emergence signals a shift in how enterprise technology leaders may need to evaluate AI coding tools. The first wave of AI-assisted development promised productivity gains — more code, faster. Theorem is wagering that the next wave will demand something different: mathematical proof that speed doesn&#x27;t come at the cost of safety.Gross frames the stakes in stark terms. AI systems are improving exponentially. If that trajectory holds, he believes superhuman software engineering is inevitable — capable of designing systems more complex than anything humans have ever built.\"And without a radically different economics of oversight,\" he said, \"we will end up deploying systems we don&#x27;t control.\"The machines are writing the code. Now someone has to check their work.",
          "content": "As artificial intelligence reshapes software development, a small startup is betting that the industry&#x27;s next big bottleneck won&#x27;t be writing code — it will be trusting it.Theorem, a San Francisco-based company that emerged from Y Combinator&#x27;s Spring 2025 batch, announced Tuesday it has raised $6 million in seed funding to build automated tools that verify the correctness of AI-generated software. Khosla Ventures led the round, with participation from Y Combinator, e14, SAIF, Halcyon, and angel investors including Blake Borgesson, co-founder of Recursion Pharmaceuticals, and Arthur Breitman, co-founder of blockchain platform Tezos.The investment arrives at a pivotal moment. AI coding assistants from companies like GitHub, Amazon, and Google now generate billions of lines of code annually. Enterprise adoption is accelerating. But the ability to verify that AI-written software actually works as intended has not kept pace — creating what Theorem&#x27;s founders describe as a widening \"oversight gap\" that threatens critical infrastructure from financial systems to power grids.\"We&#x27;re already there,\" said Jason Gross, Theorem&#x27;s co-founder, when we asked whether AI-generated code is outpacing human review capacity. \"If you asked me to review 60,000 lines of code, I wouldn&#x27;t know how to do it.\"Why AI is writing code faster than humans can verify itTheorem&#x27;s core technology combines formal verification — a mathematical technique that proves software behaves exactly as specified — with AI models trained to generate and check proofs automatically. The approach transforms a process that historically required years of PhD-level engineering into something the company claims can be completed in weeks or even days.Formal verification has existed for decades but remained confined to the most mission-critical applications: avionics systems, nuclear reactor controls, and cryptographic protocols. The technique&#x27;s prohibitive cost — often requiring eight lines of mathematical proof for every single line of code — made it impractical for mainstream software development.Gross knows this firsthand. Before founding Theorem, he earned his PhD at MIT working on verified cryptography code that now powers the HTTPS security protocol protecting trillions of internet connections daily. That project, by his estimate, consumed fifteen person-years of labor.\"Nobody prefers to have incorrect code,\" Gross said. \"Software verification has just not been economical before. Proofs used to be written by PhD-level engineers. Now, AI writes all of it.\"How formal verification catches the bugs that traditional testing missesTheorem&#x27;s system operates on a principle Gross calls \"fractional proof decomposition.\" Rather than exhaustively testing every possible behavior — computationally infeasible for complex software — the technology allocates verification resources proportionally to the importance of each code component.The approach recently identified a bug that slipped past testing at Anthropic, the AI safety company behind the Claude chatbot. Gross said the technique helps developers \"catch their bugs now without expending a lot of compute.\"In a recent technical demonstration called SFBench, Theorem used AI to translate 1,276 problems from Rocq (a formal proof assistant) to Lean (another verification language), then automatically proved each translation equivalent to the original. The company estimates a human team would have required approximately 2.7 person-years to complete the same work.\"Everyone can run agents in parallel, but we are also able to run them sequentially,\" Gross explained, noting that Theorem&#x27;s architecture handles interdependent code — where solutions build on each other across dozens of files — that trips up conventional AI coding agents limited by context windows.How one company turned a 1,500-page specification into 16,000 lines of trusted codeThe startup is already working with customers in AI research labs, electronic design automation, and GPU-accelerated computing. One case study illustrates the technology&#x27;s practical value.A customer came to Theorem with a 1,500-page PDF specification and a legacy software implementation plagued by memory leaks, crashes, and other elusive bugs. Their most urgent problem: improving performance from 10 megabits per second to 1 gigabit per second — a 100-fold increase — without introducing additional errors.Theorem&#x27;s system generated 16,000 lines of production code, which the customer deployed without ever manually reviewing it. The confidence came from a compact executable specification — a few hundred lines that generalized the massive PDF document — paired with an equivalence-checking harness that verified the new implementation matched the intended behavior.\"Now they have a production-grade parser operating at 1 Gbps that they can deploy with the confidence that no information is lost during parsing,\" Gross said.The security risks lurking in AI-generated software for critical infrastructureThe funding announcement arrives as policymakers and technologists increasingly scrutinize the reliability of AI systems embedded in critical infrastructure. Software already controls financial markets, medical devices, transportation networks, and electrical grids. AI is accelerating how quickly that software evolves — and how easily subtle bugs can propagate.Gross frames the challenge in security terms. As AI makes it cheaper to find and exploit vulnerabilities, defenders need what he calls \"asymmetric defense\" — protection that scales without proportional increases in resources.\"Software security is a delicate offense-defense balance,\" he said. \"With AI hacking, the cost of hacking a system is falling sharply. The only viable solution is asymmetric defense. If we want a software security solution that can last for more than a few generations of model improvements, it will be via verification.\"Asked whether regulators should mandate formal verification for AI-generated code in critical systems, Gross offered a pointed response: \"Now that formal verification is cheap enough, it might be considered gross negligence to not use it for guarantees about critical systems.\"What separates Theorem from other AI code verification startupsTheorem enters a market where numerous startups and research labs are exploring the intersection of AI and formal verification. The company&#x27;s differentiation, Gross argues, lies in its singular focus on scaling software oversight rather than applying verification to mathematics or other domains.\"Our tools are useful for systems engineering teams, working close to the metal, who need correctness guarantees before merging changes,\" he said.The founding team reflects that technical orientation. Gross brings deep expertise in programming language theory and a track record of deploying verified code into production at scale. Co-founder Rajashree Agrawal, a machine learning research engineer, focuses on training the AI models that power the verification pipeline.\"We&#x27;re working on formal program reasoning so that everyone can oversee not just the work of an average software-engineer-level AI, but really harness the capabilities of a Linus Torvalds-level AI,\" Agrawal said, referencing the legendary creator of Linux.The race to verify AI code before it controls everythingTheorem plans to use the funding to expand its team, increase compute resources for training verification models, and push into new industries including robotics, renewable energy, cryptocurrency, and drug synthesis. The company currently employs four people.The startup&#x27;s emergence signals a shift in how enterprise technology leaders may need to evaluate AI coding tools. The first wave of AI-assisted development promised productivity gains — more code, faster. Theorem is wagering that the next wave will demand something different: mathematical proof that speed doesn&#x27;t come at the cost of safety.Gross frames the stakes in stark terms. AI systems are improving exponentially. If that trajectory holds, he believes superhuman software engineering is inevitable — capable of designing systems more complex than anything humans have ever built.\"And without a radically different economics of oversight,\" he said, \"we will end up deploying systems we don&#x27;t control.\"The machines are writing the code. Now someone has to check their work.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/AaLRYlzfTq1F0uIlf6yiA/8c830d173f9cc1b67265e2014c32423d/nuneybits_Vector_art_of_a_theorem_d13adafe-eed8-484b-be4f-7bca5a0bba53.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/california-will-investigate-tiktoks-alleged-censorship-of-anti-trump-posts-130000558.html",
          "published_at": "Tue, 27 Jan 2026 13:00:00 +0000",
          "title": "California will investigate TikTok's alleged censorship of anti-Trump posts",
          "standfirst": "California Governor Gavin Newsom has announced that his office is investigating whether TikTok is truly censoring content critical of Trump, days after ByteDance finalized a deal to spin off its business in the US. Newsom made the announcement in response to a post on X, claiming that you can no longer send messages in the app with the word “Epstein” in it. Newsom’s office, in a separate post, said it was able to independently confirm instances wherein TikTok suppressed content critical of President Donald Trump. The governor’s office told Politico that it tried to send a direct message with the word “Epstein” in it and got a warning that it could not be sent because it may violate TikTok’s community guidelines. Newsom’s team is now “launching a review of this conduct and is calling on the California Department of Justice to determine whether it violates California law.”If you’ll recall, ByteDance finalized a deal for a new US entity just as TikTok was about to be banned in the US. ByteDance only owns 19.9 percent of the new entity called the TikTok USDS Joint Venture, while the new investors own 80 percent. Oracle, Silver Lake and Emirati fund MGX have a 15 percent stake each. The US business will now retrain TikTok’s algorithm on US data and will also be in charge of content moderation. After the US entity’s announcement, users started complaining about technical issues affecting TikTok’s recommendation algorithm and other features. Some claimed that they had difficulties posting videos about ICE over the weekend. TikTok blamed its issues, including bugs, slower loading times and timed-out uploads, on a power outage at one of its US data centers. It said it’s now working to restore its services. It’s time to investigate. I am launching a review into whether TikTok is violating state law by censoring Trump-critical content. https://t.co/AZ2mWW68xa— Governor Gavin Newsom (@CAgovernor) January 27, 2026 This article originally appeared on Engadget at https://www.engadget.com/big-tech/california-will-investigate-tiktoks-alleged-censorship-of-anti-trump-posts-130000558.html?src=rss",
          "content": "California Governor Gavin Newsom has announced that his office is investigating whether TikTok is truly censoring content critical of Trump, days after ByteDance finalized a deal to spin off its business in the US. Newsom made the announcement in response to a post on X, claiming that you can no longer send messages in the app with the word “Epstein” in it. Newsom’s office, in a separate post, said it was able to independently confirm instances wherein TikTok suppressed content critical of President Donald Trump. The governor’s office told Politico that it tried to send a direct message with the word “Epstein” in it and got a warning that it could not be sent because it may violate TikTok’s community guidelines. Newsom’s team is now “launching a review of this conduct and is calling on the California Department of Justice to determine whether it violates California law.”If you’ll recall, ByteDance finalized a deal for a new US entity just as TikTok was about to be banned in the US. ByteDance only owns 19.9 percent of the new entity called the TikTok USDS Joint Venture, while the new investors own 80 percent. Oracle, Silver Lake and Emirati fund MGX have a 15 percent stake each. The US business will now retrain TikTok’s algorithm on US data and will also be in charge of content moderation. After the US entity’s announcement, users started complaining about technical issues affecting TikTok’s recommendation algorithm and other features. Some claimed that they had difficulties posting videos about ICE over the weekend. TikTok blamed its issues, including bugs, slower loading times and timed-out uploads, on a power outage at one of its US data centers. It said it’s now working to restore its services. It’s time to investigate. I am launching a review into whether TikTok is violating state law by censoring Trump-critical content. https://t.co/AZ2mWW68xa— Governor Gavin Newsom (@CAgovernor) January 27, 2026 This article originally appeared on Engadget at https://www.engadget.com/big-tech/california-will-investigate-tiktoks-alleged-censorship-of-anti-trump-posts-130000558.html?src=rss",
          "feed_position": 27
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-apples-new-louder-high-precision-airtag-120500942.html",
          "published_at": "Tue, 27 Jan 2026 12:05:00 +0000",
          "title": "The Morning After: Apple's new louder, high-precision AirTag",
          "standfirst": "Between the new Macs, iPhones and rumored AI gadgets, Apple surprised us with an upgraded, second-generation AirTag. It has Apple’s latest Ultra Wideband chip — the same one used in the iPhone 17 lineup and the Apple Watch Ultra 3. It also uses Precision Finding to reach items up to 50 percent further away than the previous AirTag model. This feature will now work with any Apple Watch Series 9, Ultra 2 or newer.TMAAppleApple says the new tag is 50 percent louder and features a “distinctive new chime.” So you can show off that you’ve got the new kind of AirTag. Sadly, there’s still no keyring hole, so you might want to invest in a holder… with a keyring. There are cheaper options than Apple’s leather version, fortunately. I personally like Elevation Lab’s AirTag Wallet Holder.— Mat SmithThe biggest tech stories.Watch the new trailer for The Super Mario Galaxy Movie, now with YoshiThe best winter tech to help get you through the coldest months People are uninstalling TikTok and downloading an indie competitorResident Evil Requiem gives series fans the best of both action and survival horrorWith its two protagonists, the game alternates between gory action and tension.TMACapcomCapcom is attempting a delicate balancing act with Resident Evil Requiem. The ninth mainline entry seems to split between the gory action of Resident Evil 4 and the claustrophobic dread of Resident Evil 7. After a four-hour hands-on, the distinction is clear: Leon Kennedy handles the heavy lifting with (mostly) violence, while newcomer Grace navigates a high-stakes game of cat-and-mouse in a hospital filled with zombies and other monstrosities.Requiem introduces “nuanced” zombies who retain fragments of their past lives — think blind patients or territorial chefs you can distract. Continue reading.A TikTok US power outage caused a ‘cascading systems failure’There were a lot of bugs.TikTok says it’s still working to fix the “multiple bugs” in its US service following a power outage at one of its data centers. Users are having issues logging in and uploading videos and are seeing strange behavior from the “for you” algorithm. Some creators have also noticed that new uploads seem to be getting no views or likes.The company released a statement yesterday saying a power outage had caused a “cascading systems failure” that is still affecting the app. The statement, however, didn’t address reported issues with the app’s recommendation algorithm. Since Sunday, users have reported seeing a wave of generic videos flood their feeds, which are usually hyper-personalized to the user.Continue reading.Apple may have its Gemini-powered Siri ready by FebruaryIt will reportedly show off the revamped Siri in ‘the second half of February.’According to Bloomberg’s Mark Gurman, Apple plans to reveal its new Siri in “the second half of February,” demonstrating some new Gemini-powered capabilities — whatever they may be. After this, Gurman said the new Siri will be available in iOS 26.4, which is also slated to enter beta testing in February before its public release in March or early April. It’s been a long time coming; Apple teased its next-gen Siri back at WWDC 2024, but it’s still not made it to devices.Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-apples-new-louder-high-precision-airtag-120500942.html?src=rss",
          "content": "Between the new Macs, iPhones and rumored AI gadgets, Apple surprised us with an upgraded, second-generation AirTag. It has Apple’s latest Ultra Wideband chip — the same one used in the iPhone 17 lineup and the Apple Watch Ultra 3. It also uses Precision Finding to reach items up to 50 percent further away than the previous AirTag model. This feature will now work with any Apple Watch Series 9, Ultra 2 or newer.TMAAppleApple says the new tag is 50 percent louder and features a “distinctive new chime.” So you can show off that you’ve got the new kind of AirTag. Sadly, there’s still no keyring hole, so you might want to invest in a holder… with a keyring. There are cheaper options than Apple’s leather version, fortunately. I personally like Elevation Lab’s AirTag Wallet Holder.— Mat SmithThe biggest tech stories.Watch the new trailer for The Super Mario Galaxy Movie, now with YoshiThe best winter tech to help get you through the coldest months People are uninstalling TikTok and downloading an indie competitorResident Evil Requiem gives series fans the best of both action and survival horrorWith its two protagonists, the game alternates between gory action and tension.TMACapcomCapcom is attempting a delicate balancing act with Resident Evil Requiem. The ninth mainline entry seems to split between the gory action of Resident Evil 4 and the claustrophobic dread of Resident Evil 7. After a four-hour hands-on, the distinction is clear: Leon Kennedy handles the heavy lifting with (mostly) violence, while newcomer Grace navigates a high-stakes game of cat-and-mouse in a hospital filled with zombies and other monstrosities.Requiem introduces “nuanced” zombies who retain fragments of their past lives — think blind patients or territorial chefs you can distract. Continue reading.A TikTok US power outage caused a ‘cascading systems failure’There were a lot of bugs.TikTok says it’s still working to fix the “multiple bugs” in its US service following a power outage at one of its data centers. Users are having issues logging in and uploading videos and are seeing strange behavior from the “for you” algorithm. Some creators have also noticed that new uploads seem to be getting no views or likes.The company released a statement yesterday saying a power outage had caused a “cascading systems failure” that is still affecting the app. The statement, however, didn’t address reported issues with the app’s recommendation algorithm. Since Sunday, users have reported seeing a wave of generic videos flood their feeds, which are usually hyper-personalized to the user.Continue reading.Apple may have its Gemini-powered Siri ready by FebruaryIt will reportedly show off the revamped Siri in ‘the second half of February.’According to Bloomberg’s Mark Gurman, Apple plans to reveal its new Siri in “the second half of February,” demonstrating some new Gemini-powered capabilities — whatever they may be. After this, Gurman said the new Siri will be available in iOS 26.4, which is also slated to enter beta testing in February before its public release in March or early April. It’s been a long time coming; Apple teased its next-gen Siri back at WWDC 2024, but it’s still not made it to devices.Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-apples-new-louder-high-precision-airtag-120500942.html?src=rss",
          "feed_position": 28,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Untitled-1_2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html",
          "published_at": "Tue, 27 Jan 2026 08:01:26 +0000",
          "title": "The best wireless earbuds for 2026",
          "standfirst": "Wireless earbuds are now the default option for everyday listening, whether you’re heading out for a commute, fitting in a workout or just watching videos at home. The best wireless earbuds combine reliable connectivity, comfortable fits and sound quality that holds up across music, calls and podcasts, all without the hassle of cables. Most are small enough to disappear into a pocket and pair quickly with phones, tablets and laptops.What sets one pair apart from another often comes down to priorities. Some earbuds lean heavily on active noise cancellation, while others focus on long battery life, compact charging cases or lower prices. Features like water resistance, customizable controls and app support can also make a real difference day to day. This guide breaks down the best wireless earbuds available now to help you find the right match for how you listen. Best wireless earbuds of 2026 What to look for in the best wireless earbuds When it comes to shopping for earphones, the first thing to consider is design or wear style. Do you prefer a semi-open fit like AirPods or do you want something that completely closes off your ears? If you’re shopping for earbuds with active noise cancellation, you'll want the latter, but a case can be made for the former if you want to wear them all day or frequent places where you need to be tuned in to the ambient sounds. The overall shape of earbuds can determine whether you get a comfortable fit, so can the size and weight, so you’ll want to consider all that before deciding. And remember: audio companies aren’t perfect, so despite lots of research, the earbud shape they decided on may not fit you well. Don’t be afraid to return ill-fitting earbuds for something that’s more comfortable. As wireless earbuds have become the norm, they’re now more reliable for basic things like consistent Bluetooth connectivity. Companies are still in a race to pack as much as they can into increasingly smaller designs. This typically means a longer list of features on the more premium sets of earbuds with basic functionality on the cheapest models. Carefully consider what you can’t live without when selecting your next earbuds, and make sure key items like automatic pausing and multipoint connectivity are on the spec sheet. You’ll also want to investigate the volume and touch controls as you’ll often have to sacrifice access to something else to make that adjustment via on-board taps or swipes. Some earbuds even offer app settings to tweak the audio profiles or firmware updates to improve performance over time. For those in the Apple ecosystem, features like auto-pairing with devices, especially with AirPods Pro 3, can be an added advantage, while Android users may want to look for models that offer similar cross-device functionality. When it comes to battery life, the average set of earbuds lasts about five hours on a single charge. You can find sets that last longer, but this is likely enough to get you through a work day if you’re docking the buds during lunch or the occasional meeting. You’ll want to check on how many extra charges are available via the case and if it supports wireless charging. Companies will also make lofty claims about call quality on wireless earbuds. Despite lots of promises, the reality is most earbuds still leave you sounding like you’re on speakerphone. There are some sets that deliver, but don’t get your hopes up unless reviews confirm the claims. Sound can be subjective, so we recommend trying before you buy if at all possible. This is especially true if you're an audiophile. We understand this isn’t easy when most of us do a lot of shopping online, but trying on a set of earbuds and listening to them for a few minutes can save you from an expensive case of buyer's remorse. If a store doesn’t allow a quick demo, most retailers have return policies that will let you take earbuds back you don’t like. Of course, you have to be willing to temporarily part with funds in order to do this. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all earbuds support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you, especially if you plan to use them for playback of high-quality audio. How we test wireless earbuds The primary way we test earbuds is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for earbuds is typically less than a full day, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). To judge audio quality, we listen to a range of genres, noting any differences in the sound profile across the styles. We also test at both low and high volumes to check for consistency in the tuning. To assess call quality, we’ll record audio samples with the earbuds’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the earbuds we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older buds. Ditto for the closest competition for each new set of earbuds that we review. Other wireless Bluetooth earbuds we tested Sony WF-C710N The WF-C710N is a set of compact and comfy earbuds that offer several of Sony’s best features. While the ANC performance is above average for this price ($120), sound quality isn’t as good as the company’s slightly more expensive options. Battery life fell below stated figures and call performance isn’t good enough to use these buds for work. Beats Powerbeats Pro 2 The newest version of the Powerbeats Pro have an improved, comfortable design, balanced bass and new H2 chips and a heart rate sensor inside. But heart rate support is currently limited on iOS. Samsung Galaxy Buds 3 The Galaxy Buds 3 combine ANC with an open-type design, which renders the noise-blocking abilities of the earbuds mostly useless. Still, there’s great low-end tone with ample bass when a track demands it. There are also lots of handy features, most of which require a Samsung phone. But at this price, there are better options from Google, Beats and Sony Sennheiser Momentum Sport I really like the overall shape of the Momentum Sport earbuds. They’re more comfortable than the Momentum True Wireless 4 and fit in my ears better. What’s more, the body temperature and heart rate sensors work well, sending those stats to a variety of apps. However, that sport-tracking feature works best with Polar’s app and devices, so there’s that consideration. Also, the audio quality and ANC performance isn’t as good as the MTW4, and these earbuds are pricey. Beats Solo Buds There’s a lot to like about the Solo Buds for $80. For me, the primary perk is they’re very comfortable to wear for long periods of time thanks to some thoughtful design considerations. You only get the basics here in terms of features and, as expected, the overall sound quality isn’t as good as the pricier models in the Beats lineup. You will get 18 hours of battery life though, since the company nixed the battery in the case and beefed up the listening time in the buds themselves. Bose Ultra Open Earbuds Bose created something very unique for this set of earbuds that allows you to stay in-tune with the world while listening to audio content. The clip-on design is very comfortable, but sound quality suffers due to the open-type fit, especially when it comes to bass and spatial audio. Audio-Technica ATH-TWX7 These stick buds have a compact design that’s comfortable to wear and the warm sound profile is great at times. However, overall audio performance is inconsistent and there’s no automatic pausing. Master & Dynamic MW09 Retooled audio, better ambient sound mode and reliable multipoint Bluetooth are the best things the MW09 has to offer. They’re expensive though, and you can find better ANC performance elsewhere. Wireless earbud FAQs What is considered good battery life for true wireless earbuds? Most wireless earbuds will last five hours on a single charge, at the least. You can find some pairs that have even better battery life, lasting between six and eight hours before they need more juice. All of the best wireless earbuds come with a charging case, which will provide additional hours of battery life — but you'll have to return each bud to the case in order to charge them up. Is sound quality better on headphones or earbuds? Comparing sound quality on earbuds and headphones is a bit like comparing apples and oranges. There are a lot of variables to consider and the differences in components make a direct comparison difficult. Personally, I prefer the audio quality from over-ear headphones, but I can tell you the sound from earbuds like Sennheiser’s Momentum True Wireless 3 is also outstanding. Which wireless earbuds have the longest battery life? With new models coming out all the time, tracking the hours of battery life for each this can be difficult to keep tabs on. The longest-lasting earbuds we’ve reviewed are Audio-Technica’s ATH-CKS5TW. The company states they last 15 hours, but the app was still showing 40 percent at that mark during our tests. The only downside is these earbuds debuted in 2019 and both technology and features have improved since. In terms of current models, Master & Dynamic’s MW08 offers 12 hours of use on a charge with ANC off (10 with ANC on) and JBL has multiple options with 10-hour batteries. What wireless earbuds are waterproof? There are plenty of options these days when it comes to increased water resistance. To determine the level of protection, you’ll want to look for an IP (ingress protection) rating. The first number indicates intrusion protection from things like dust. The second number is the level of moisture protection and you’ll want to make sure that figure is 7 or higher. At this water-resistance rating, earbuds can withstand full immersion for up to 30 minutes in depths up to one meter (3.28 feet). If either of the IP numbers is an X, that means it doesn’t have any special protection. For example, a pair of wireless earbuds that are IPX7 wouldn’t be built to avoid dust intrusion, but they would be ok if you dropped them in shallow water. Which earbuds stay in ears the best? A secure fit can vary wildly from person to person. All of our ears are different, so audio companies are designing their products to fit the most people they can with a single shape. This is why AirPods will easily fall out for some but stay put for others. Design touches like wing tips or fins typically come on fitness models and those elements can help keep things in place. You’ll likely just have to try earbuds on, and if they don’t fit well return them. What wireless earbuds work with PS5? PlayStation 5 doesn’t support Bluetooth audio without an adapter or dongle. Even Sony’s own gaming headsets come with a transmitter that connects to the console. There are universal options that allow you to use any headphones, headset or earbuds with a PS5. Once you have one, plug it into a USB port on the console and pair your earbuds with it. Recent updates January 2026: Updated to ensure our top picks have remained the same. September 2025: Updated to add AirPods Pro 3 to our top picks. May 2025: Updated to ensure top picks and buying advice remain accurate. March 2025: Updated the top pick for the best sounding wireless earbuds - runner up. January 2025: Updated the top pick for best sounding wireless earbuds.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html?src=rss",
          "content": "Wireless earbuds are now the default option for everyday listening, whether you’re heading out for a commute, fitting in a workout or just watching videos at home. The best wireless earbuds combine reliable connectivity, comfortable fits and sound quality that holds up across music, calls and podcasts, all without the hassle of cables. Most are small enough to disappear into a pocket and pair quickly with phones, tablets and laptops.What sets one pair apart from another often comes down to priorities. Some earbuds lean heavily on active noise cancellation, while others focus on long battery life, compact charging cases or lower prices. Features like water resistance, customizable controls and app support can also make a real difference day to day. This guide breaks down the best wireless earbuds available now to help you find the right match for how you listen. Best wireless earbuds of 2026 What to look for in the best wireless earbuds When it comes to shopping for earphones, the first thing to consider is design or wear style. Do you prefer a semi-open fit like AirPods or do you want something that completely closes off your ears? If you’re shopping for earbuds with active noise cancellation, you'll want the latter, but a case can be made for the former if you want to wear them all day or frequent places where you need to be tuned in to the ambient sounds. The overall shape of earbuds can determine whether you get a comfortable fit, so can the size and weight, so you’ll want to consider all that before deciding. And remember: audio companies aren’t perfect, so despite lots of research, the earbud shape they decided on may not fit you well. Don’t be afraid to return ill-fitting earbuds for something that’s more comfortable. As wireless earbuds have become the norm, they’re now more reliable for basic things like consistent Bluetooth connectivity. Companies are still in a race to pack as much as they can into increasingly smaller designs. This typically means a longer list of features on the more premium sets of earbuds with basic functionality on the cheapest models. Carefully consider what you can’t live without when selecting your next earbuds, and make sure key items like automatic pausing and multipoint connectivity are on the spec sheet. You’ll also want to investigate the volume and touch controls as you’ll often have to sacrifice access to something else to make that adjustment via on-board taps or swipes. Some earbuds even offer app settings to tweak the audio profiles or firmware updates to improve performance over time. For those in the Apple ecosystem, features like auto-pairing with devices, especially with AirPods Pro 3, can be an added advantage, while Android users may want to look for models that offer similar cross-device functionality. When it comes to battery life, the average set of earbuds lasts about five hours on a single charge. You can find sets that last longer, but this is likely enough to get you through a work day if you’re docking the buds during lunch or the occasional meeting. You’ll want to check on how many extra charges are available via the case and if it supports wireless charging. Companies will also make lofty claims about call quality on wireless earbuds. Despite lots of promises, the reality is most earbuds still leave you sounding like you’re on speakerphone. There are some sets that deliver, but don’t get your hopes up unless reviews confirm the claims. Sound can be subjective, so we recommend trying before you buy if at all possible. This is especially true if you're an audiophile. We understand this isn’t easy when most of us do a lot of shopping online, but trying on a set of earbuds and listening to them for a few minutes can save you from an expensive case of buyer's remorse. If a store doesn’t allow a quick demo, most retailers have return policies that will let you take earbuds back you don’t like. Of course, you have to be willing to temporarily part with funds in order to do this. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all earbuds support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you, especially if you plan to use them for playback of high-quality audio. How we test wireless earbuds The primary way we test earbuds is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for earbuds is typically less than a full day, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). To judge audio quality, we listen to a range of genres, noting any differences in the sound profile across the styles. We also test at both low and high volumes to check for consistency in the tuning. To assess call quality, we’ll record audio samples with the earbuds’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the earbuds we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older buds. Ditto for the closest competition for each new set of earbuds that we review. Other wireless Bluetooth earbuds we tested Sony WF-C710N The WF-C710N is a set of compact and comfy earbuds that offer several of Sony’s best features. While the ANC performance is above average for this price ($120), sound quality isn’t as good as the company’s slightly more expensive options. Battery life fell below stated figures and call performance isn’t good enough to use these buds for work. Beats Powerbeats Pro 2 The newest version of the Powerbeats Pro have an improved, comfortable design, balanced bass and new H2 chips and a heart rate sensor inside. But heart rate support is currently limited on iOS. Samsung Galaxy Buds 3 The Galaxy Buds 3 combine ANC with an open-type design, which renders the noise-blocking abilities of the earbuds mostly useless. Still, there’s great low-end tone with ample bass when a track demands it. There are also lots of handy features, most of which require a Samsung phone. But at this price, there are better options from Google, Beats and Sony Sennheiser Momentum Sport I really like the overall shape of the Momentum Sport earbuds. They’re more comfortable than the Momentum True Wireless 4 and fit in my ears better. What’s more, the body temperature and heart rate sensors work well, sending those stats to a variety of apps. However, that sport-tracking feature works best with Polar’s app and devices, so there’s that consideration. Also, the audio quality and ANC performance isn’t as good as the MTW4, and these earbuds are pricey. Beats Solo Buds There’s a lot to like about the Solo Buds for $80. For me, the primary perk is they’re very comfortable to wear for long periods of time thanks to some thoughtful design considerations. You only get the basics here in terms of features and, as expected, the overall sound quality isn’t as good as the pricier models in the Beats lineup. You will get 18 hours of battery life though, since the company nixed the battery in the case and beefed up the listening time in the buds themselves. Bose Ultra Open Earbuds Bose created something very unique for this set of earbuds that allows you to stay in-tune with the world while listening to audio content. The clip-on design is very comfortable, but sound quality suffers due to the open-type fit, especially when it comes to bass and spatial audio. Audio-Technica ATH-TWX7 These stick buds have a compact design that’s comfortable to wear and the warm sound profile is great at times. However, overall audio performance is inconsistent and there’s no automatic pausing. Master & Dynamic MW09 Retooled audio, better ambient sound mode and reliable multipoint Bluetooth are the best things the MW09 has to offer. They’re expensive though, and you can find better ANC performance elsewhere. Wireless earbud FAQs What is considered good battery life for true wireless earbuds? Most wireless earbuds will last five hours on a single charge, at the least. You can find some pairs that have even better battery life, lasting between six and eight hours before they need more juice. All of the best wireless earbuds come with a charging case, which will provide additional hours of battery life — but you'll have to return each bud to the case in order to charge them up. Is sound quality better on headphones or earbuds? Comparing sound quality on earbuds and headphones is a bit like comparing apples and oranges. There are a lot of variables to consider and the differences in components make a direct comparison difficult. Personally, I prefer the audio quality from over-ear headphones, but I can tell you the sound from earbuds like Sennheiser’s Momentum True Wireless 3 is also outstanding. Which wireless earbuds have the longest battery life? With new models coming out all the time, tracking the hours of battery life for each this can be difficult to keep tabs on. The longest-lasting earbuds we’ve reviewed are Audio-Technica’s ATH-CKS5TW. The company states they last 15 hours, but the app was still showing 40 percent at that mark during our tests. The only downside is these earbuds debuted in 2019 and both technology and features have improved since. In terms of current models, Master & Dynamic’s MW08 offers 12 hours of use on a charge with ANC off (10 with ANC on) and JBL has multiple options with 10-hour batteries. What wireless earbuds are waterproof? There are plenty of options these days when it comes to increased water resistance. To determine the level of protection, you’ll want to look for an IP (ingress protection) rating. The first number indicates intrusion protection from things like dust. The second number is the level of moisture protection and you’ll want to make sure that figure is 7 or higher. At this water-resistance rating, earbuds can withstand full immersion for up to 30 minutes in depths up to one meter (3.28 feet). If either of the IP numbers is an X, that means it doesn’t have any special protection. For example, a pair of wireless earbuds that are IPX7 wouldn’t be built to avoid dust intrusion, but they would be ok if you dropped them in shallow water. Which earbuds stay in ears the best? A secure fit can vary wildly from person to person. All of our ears are different, so audio companies are designing their products to fit the most people they can with a single shape. This is why AirPods will easily fall out for some but stay put for others. Design touches like wing tips or fins typically come on fitness models and those elements can help keep things in place. You’ll likely just have to try earbuds on, and if they don’t fit well return them. What wireless earbuds work with PS5? PlayStation 5 doesn’t support Bluetooth audio without an adapter or dongle. Even Sony’s own gaming headsets come with a transmitter that connects to the console. There are universal options that allow you to use any headphones, headset or earbuds with a PS5. Once you have one, plug it into a USB port on the console and pair your earbuds with it. Recent updates January 2026: Updated to ensure our top picks have remained the same. September 2025: Updated to add AirPods Pro 3 to our top picks. May 2025: Updated to ensure top picks and buying advice remain accurate. March 2025: Updated the top pick for the best sounding wireless earbuds - runner up. January 2025: Updated the top pick for best sounding wireless earbuds.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2026/jan/27/gavin-newsom-tiktok-content-critical-of-trump",
          "published_at": "Tue, 27 Jan 2026 05:00:25 GMT",
          "title": "California governor Gavin Newsom accuses TikTok of suppressing content critical of Trump",
          "standfirst": "Newsom launched a review of the platform, despite TikTok saying a systems failure was responsible for the issueCalifornia governor Gavin Newsom has accused TikTok of suppressing content critical of president Donald Trump, as he launched a review of the platform’s content moderation practices to determine if they violated state law, even as the platform blamed a systems failure for the issues.The step comes after TikTok’s Chinese owner, ByteDance, said last week it had finalised a deal to set up a majority US-owned joint venture that will secure US data, to avoid a US ban on the short video app used by more than 200 million Americans. Continue reading...",
          "content": "Newsom launched a review of the platform, despite TikTok saying a systems failure was responsible for the issueCalifornia governor Gavin Newsom has accused TikTok of suppressing content critical of president Donald Trump, as he launched a review of the platform’s content moderation practices to determine if they violated state law, even as the platform blamed a systems failure for the issues.The step comes after TikTok’s Chinese owner, ByteDance, said last week it had finalised a deal to set up a majority US-owned joint venture that will secure US data, to avoid a US ban on the short video app used by more than 200 million Americans. Continue reading...",
          "feed_position": 3
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/the-ai-visualization-tech-stack-from-2d-to-holograms",
          "published_at": "Tue, 27 Jan 2026 05:00:00 GMT",
          "title": "The AI visualization tech stack: From 2D to holograms",
          "standfirst": "Presented by Avalon HolographicsThe pace of AI continues to be staggering. From simple pattern recognition systems to large language models (LLMs), and now as we move into the physical AI reality, the power of these systems continues to improve our lives. But humans always need to be in the loop. We need to see the data, interact with it, and identify the simulation-to-reality gaps; we need to help these systems help us. Spatial computing has traditionally been in the realm of human understanding; we now share this space with AI. Understanding the different ways humans should interact with 3D data helps guide the medium where we can get the best from AI. 1. The 2D screen: the precision desktopThe 2D screen has been the reliable workhorse since spatial computing started and continues to be the primary interface, with most professional work still happening here. For a developer training a model or a single user doing 3D modeling, the 2D screen is great for the individual contributor. However, using a 2D screen forces a “3D-to-2D” mental translation, where the user has to keep the model in their mind, rotating, zooming, and interacting with this specific corner of the spatial world. The cognitive load of this mental model can cause the brain to work overtime to understand it. 2. VR: the immersive workspaceVR offers that first jump beyond 2D. By completely immersing yourself in the 3D world, you gain a capability that is accessible and effective. When training a robotic system, being in the place of the autonomous system, helping that system by showing the human movement and training the system, VR is the place to be. But you are inherently by yourself. Even with avatars, you’ve lost touch with reality; only the digital world exists. 3. AR: the expert in your earAR was supposed to be a potential fix, but in reality, AR goes down a different road. AR is the angel on your shoulder, or more specifically, in your ears and eyes, giving you helpful guidance. Turn left here, rotate that bolt. What’s the history of this castle? AR is the king of instructional guidance. It’s always there to give you helpful tips. But it is inherently just for you; only you can see what’s in your AR headset. 4. Holograms: The collaborative spaceHolograms, specifically light field holograms, are the pinnacle of the visualization stack. They do what nothing else can do: recreate the digital object as if it were real, making it visible in the real world for all to see. Holograms provide glasses-free, 3D visualization of digital twins for everyone to see simultaneously and are visible to the naked eye. The value of holographic systems becomes compelling where shared spatial understanding materially changes outcomes.The power of the shared physical contextThe true value of the holographic display in the era of physical AI lies in the ability to solve the referential ambiguity problem. In a holographic environment, the light rays are physically reconstructed. Multiple people look at the same reconstruction from individual perspectives; if I point at a joint in a humanoid robot, a cancerous tumour, cover versus concealment, there’s no ambiguity about what I am pointing at. Everyone knows EXACTLY what I’m pointing at. This shared experience, where I can see you, your full reaction, and you can see mine, creates a level of trust that no other medium can match. Further, there’s no onboarding friction with a hologram. No special equipment is required — simply walk into the light field and you see the hologram. There’s none of the discomfort or isolation that comes with wearable devices. Everyone can see the hologram together, immediately. When to choose hologramsThere are many situations where humans need to act with spatial intelligence. When alone, individual mediums like screens and AR/VR are great solutions and should be the first choice. But when there are high stakes, when discussion, collaboration, and trust between people are paramount, nothing can approach the value that holographics bring to the table.The first use cases are those in which the consequences of a bad decision are life-threatening, typically in medical and defence applications. The cognitive load and side effects of individual solutions are too much to accept in these situations. But physical AI is quickly encroaching into these high-consequence areas. Autonomous systems are driving our cars, running our factories, and are moving into these high-consequence areas that already demand human-in-the-loop decisions. Holograms allow teams to use their own spatial reasoning to identify simulation-to-reality gaps that may be invisible in other mediums. The future of the visualization stackLooking forward, we are nearing the end of the 2D screen. As holographic light field technology matures, we will see a fundamental and inevitable shift towards holography. The 2D monitor will eventually be relegated to the same status as the typewriter. AR and VR will likely settle into niche roles — AR for field service utility and VR for deep solitary immersion. Holographic light field displays will become our primary interface to the digital world, because seeing 3D naturally is what humans have evolved to do. Wally Haas is president of Avalon Holographics.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Avalon HolographicsThe pace of AI continues to be staggering. From simple pattern recognition systems to large language models (LLMs), and now as we move into the physical AI reality, the power of these systems continues to improve our lives. But humans always need to be in the loop. We need to see the data, interact with it, and identify the simulation-to-reality gaps; we need to help these systems help us. Spatial computing has traditionally been in the realm of human understanding; we now share this space with AI. Understanding the different ways humans should interact with 3D data helps guide the medium where we can get the best from AI. 1. The 2D screen: the precision desktopThe 2D screen has been the reliable workhorse since spatial computing started and continues to be the primary interface, with most professional work still happening here. For a developer training a model or a single user doing 3D modeling, the 2D screen is great for the individual contributor. However, using a 2D screen forces a “3D-to-2D” mental translation, where the user has to keep the model in their mind, rotating, zooming, and interacting with this specific corner of the spatial world. The cognitive load of this mental model can cause the brain to work overtime to understand it. 2. VR: the immersive workspaceVR offers that first jump beyond 2D. By completely immersing yourself in the 3D world, you gain a capability that is accessible and effective. When training a robotic system, being in the place of the autonomous system, helping that system by showing the human movement and training the system, VR is the place to be. But you are inherently by yourself. Even with avatars, you’ve lost touch with reality; only the digital world exists. 3. AR: the expert in your earAR was supposed to be a potential fix, but in reality, AR goes down a different road. AR is the angel on your shoulder, or more specifically, in your ears and eyes, giving you helpful guidance. Turn left here, rotate that bolt. What’s the history of this castle? AR is the king of instructional guidance. It’s always there to give you helpful tips. But it is inherently just for you; only you can see what’s in your AR headset. 4. Holograms: The collaborative spaceHolograms, specifically light field holograms, are the pinnacle of the visualization stack. They do what nothing else can do: recreate the digital object as if it were real, making it visible in the real world for all to see. Holograms provide glasses-free, 3D visualization of digital twins for everyone to see simultaneously and are visible to the naked eye. The value of holographic systems becomes compelling where shared spatial understanding materially changes outcomes.The power of the shared physical contextThe true value of the holographic display in the era of physical AI lies in the ability to solve the referential ambiguity problem. In a holographic environment, the light rays are physically reconstructed. Multiple people look at the same reconstruction from individual perspectives; if I point at a joint in a humanoid robot, a cancerous tumour, cover versus concealment, there’s no ambiguity about what I am pointing at. Everyone knows EXACTLY what I’m pointing at. This shared experience, where I can see you, your full reaction, and you can see mine, creates a level of trust that no other medium can match. Further, there’s no onboarding friction with a hologram. No special equipment is required — simply walk into the light field and you see the hologram. There’s none of the discomfort or isolation that comes with wearable devices. Everyone can see the hologram together, immediately. When to choose hologramsThere are many situations where humans need to act with spatial intelligence. When alone, individual mediums like screens and AR/VR are great solutions and should be the first choice. But when there are high stakes, when discussion, collaboration, and trust between people are paramount, nothing can approach the value that holographics bring to the table.The first use cases are those in which the consequences of a bad decision are life-threatening, typically in medical and defence applications. The cognitive load and side effects of individual solutions are too much to accept in these situations. But physical AI is quickly encroaching into these high-consequence areas. Autonomous systems are driving our cars, running our factories, and are moving into these high-consequence areas that already demand human-in-the-loop decisions. Holograms allow teams to use their own spatial reasoning to identify simulation-to-reality gaps that may be invisible in other mediums. The future of the visualization stackLooking forward, we are nearing the end of the 2D screen. As holographic light field technology matures, we will see a fundamental and inevitable shift towards holography. The 2D monitor will eventually be relegated to the same status as the typewriter. AR and VR will likely settle into niche roles — AR for field service utility and VR for deep solitary immersion. Holographic light field displays will become our primary interface to the digital world, because seeing 3D naturally is what humans have evolved to do. Wally Haas is president of Avalon Holographics.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6lTN08cArcOGzKoBEQBLQD/caba6c9ba1258122ac160613a06f7181/VB_Title_Image.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/mcp-shipped-without-authentication-clawdbot-shows-why-thats-a-problem",
          "published_at": "Tue, 27 Jan 2026 00:30:00 GMT",
          "title": "MCP shipped without authentication. Clawdbot shows why that's a problem.",
          "standfirst": "Model Context Protocol has a security problem that won&#x27;t go away.When VentureBeat first reported on MCP&#x27;s vulnerabilities last October, the data was already alarming. Pynt&#x27;s research showed that deploying just 10 MCP plug-ins creates a 92% probability of exploitation — with meaningful risk even from a single plug-in.The core flaw hasn&#x27;t changed: MCP shipped without mandatory authentication. Authorization frameworks arrived six months after widespread deployment. As Merritt Baer, chief security officer at Enkrypt AI, warned at the time: \"MCP is shipping with the same mistake we&#x27;ve seen in every major protocol rollout: insecure defaults. If we don&#x27;t build authentication and least privilege in from day one, we&#x27;ll be cleaning up breaches for the next decade.\"Three months later, the cleanup has already begun — and it&#x27;s worse than expected.Clawdbot changed the threat model. The viral personal AI assistant that can clear inboxes and write code overnight runs entirely on MCP. Every developer who spun up a Clawdbot on a VPS without reading the security docs just exposed their company to the protocol&#x27;s full attack surface.Itamar Golan saw it coming. He sold Prompt Security to SentinelOne for an estimated $250 million last year. This week, he posted a warning on X: \"Disaster is coming. Thousands of Clawdbots are live right now on VPSs … with open ports to the internet … and zero authentication. This is going to get ugly.\"He&#x27;s not exaggerating. When Knostic scanned the internet, they found 1,862 MCP servers exposed with no authentication. They tested 119. Every server responded without requiring credentials.Anything Clawdbot can automate, attackers can weaponize.Three CVEs are exposing the same architectural flawThe vulnerabilities aren&#x27;t edge cases. They&#x27;re direct consequences of MCP&#x27;s design decisions. Here’s a brief description of the workflows that expose each of the following CVEs:CVE-2025-49596 (CVSS 9.4): Anthropic’s MCP Inspector exposed unauthenticated access between its web UI and proxy server, allowing full system compromise via a malicious webpage.CVE-2025-6514 (CVSS 9.6): Command injection in mcp-remote, an OAuth proxy with 437,000 downloads, enabled attackers to take over systems by connecting to a malicious MCP server.CVE-2025-52882 (CVSS 8.8): Popular Claude Code extensions exposed unauthenticated WebSocket servers, enabling arbitrary file access and code execution.Three critical vulnerabilities in six months. Three different attack vectors. One root cause: MCP&#x27;s authentication was always optional, and developers treated optional as unnecessary.The attack surface keeps expandingEquixly recently analyzed popular MCP implementations and also found several vulnerabilities: 43% contained command injection flaws, 30% permitted unrestricted URL fetching, and 22% leaked files outside intended directories. Forrester analyst Jeff Pollard described the risk in a blog post: \"From a security perspective, it looks like a very effective way to drop a new and very powerful actor into your environment with zero guardrails.\"That&#x27;s not an exaggeration. An MCP server with shell access can be weaponized for lateral movement, credential theft, and ransomware deployment, all triggered by a prompt injection hidden in a document the AI was asked to process.Known vulnerabilities, deferred fixesSecurity researcher Johann Rehberger disclosed a file exfiltration vulnerability last October. Prompt injection could trick AI agents into transmitting sensitive files to attacker accounts. Anthropic launched Cowork this month; it expands MCP-based agents to a broader, less security-aware audience. Same vulnerability, and this time it&#x27;s immediately exploitable. PromptArmor demonstrated a malicious document that manipulated the agent into uploading sensitive financial data.Anthropic&#x27;s mitigation guidance: Users should watch for \"suspicious actions that may indicate prompt injection.\"a16z partner Olivia Moore spent a weekend using Clawdbot and captured the disconnect: \"You&#x27;re giving an AI agent access to your accounts. It can read your messages, send texts on your behalf, access your files, and execute code on your machine. You need to actually understand what you&#x27;re authorizing.\"Most users don&#x27;t. Most developers don&#x27;t either. And MCP&#x27;s design never required them to.Five actions for security leadersInventory your MCP exposure now. Traditional endpoint detection sees node or Python processes started by legitimate applications. It doesn&#x27;t flag them as threats. You need tooling that identifies MCP servers specifically. Treat authentication as mandatory. The MCP specification recommends OAuth 2.1. The SDK includes no built-in authentication. Every MCP server touching production systems needs auth enforced at deployment, not after the incident.Restrict network exposure. Bind MCP servers to localhost unless remote access is explicitly required and authenticated. The 1,862 exposed servers Knostic found suggest most exposures are accidental. Assume prompt injection attacks are coming and will be successful. MCP servers inherit the blast radius of the tools they wrap. Server wraps cloud credentials, filesystems, or deployment pipelines? Design access controls assuming the agent will be compromised.Force human approval for high-risk actions. Require explicit confirmation before agents send external email, delete data, or access sensitive information. Treat the agent like a fast but literal junior employee who will do exactly what you say, including things you didn&#x27;t mean.The governance gap is wide openSecurity vendors moved early to monetize MCP risk, but most enterprises didn’t move nearly as fast.Clawdbot adoption exploded in Q4 2025. Most 2026 security roadmaps have zero AI agent controls. The gap between developer enthusiasm and security governance is measured in months. The window for attackers is wide open.Golan is right. This is going to get ugly. The question is whether organizations will secure their MCP exposure before someone else exploits it.",
          "content": "Model Context Protocol has a security problem that won&#x27;t go away.When VentureBeat first reported on MCP&#x27;s vulnerabilities last October, the data was already alarming. Pynt&#x27;s research showed that deploying just 10 MCP plug-ins creates a 92% probability of exploitation — with meaningful risk even from a single plug-in.The core flaw hasn&#x27;t changed: MCP shipped without mandatory authentication. Authorization frameworks arrived six months after widespread deployment. As Merritt Baer, chief security officer at Enkrypt AI, warned at the time: \"MCP is shipping with the same mistake we&#x27;ve seen in every major protocol rollout: insecure defaults. If we don&#x27;t build authentication and least privilege in from day one, we&#x27;ll be cleaning up breaches for the next decade.\"Three months later, the cleanup has already begun — and it&#x27;s worse than expected.Clawdbot changed the threat model. The viral personal AI assistant that can clear inboxes and write code overnight runs entirely on MCP. Every developer who spun up a Clawdbot on a VPS without reading the security docs just exposed their company to the protocol&#x27;s full attack surface.Itamar Golan saw it coming. He sold Prompt Security to SentinelOne for an estimated $250 million last year. This week, he posted a warning on X: \"Disaster is coming. Thousands of Clawdbots are live right now on VPSs … with open ports to the internet … and zero authentication. This is going to get ugly.\"He&#x27;s not exaggerating. When Knostic scanned the internet, they found 1,862 MCP servers exposed with no authentication. They tested 119. Every server responded without requiring credentials.Anything Clawdbot can automate, attackers can weaponize.Three CVEs are exposing the same architectural flawThe vulnerabilities aren&#x27;t edge cases. They&#x27;re direct consequences of MCP&#x27;s design decisions. Here’s a brief description of the workflows that expose each of the following CVEs:CVE-2025-49596 (CVSS 9.4): Anthropic’s MCP Inspector exposed unauthenticated access between its web UI and proxy server, allowing full system compromise via a malicious webpage.CVE-2025-6514 (CVSS 9.6): Command injection in mcp-remote, an OAuth proxy with 437,000 downloads, enabled attackers to take over systems by connecting to a malicious MCP server.CVE-2025-52882 (CVSS 8.8): Popular Claude Code extensions exposed unauthenticated WebSocket servers, enabling arbitrary file access and code execution.Three critical vulnerabilities in six months. Three different attack vectors. One root cause: MCP&#x27;s authentication was always optional, and developers treated optional as unnecessary.The attack surface keeps expandingEquixly recently analyzed popular MCP implementations and also found several vulnerabilities: 43% contained command injection flaws, 30% permitted unrestricted URL fetching, and 22% leaked files outside intended directories. Forrester analyst Jeff Pollard described the risk in a blog post: \"From a security perspective, it looks like a very effective way to drop a new and very powerful actor into your environment with zero guardrails.\"That&#x27;s not an exaggeration. An MCP server with shell access can be weaponized for lateral movement, credential theft, and ransomware deployment, all triggered by a prompt injection hidden in a document the AI was asked to process.Known vulnerabilities, deferred fixesSecurity researcher Johann Rehberger disclosed a file exfiltration vulnerability last October. Prompt injection could trick AI agents into transmitting sensitive files to attacker accounts. Anthropic launched Cowork this month; it expands MCP-based agents to a broader, less security-aware audience. Same vulnerability, and this time it&#x27;s immediately exploitable. PromptArmor demonstrated a malicious document that manipulated the agent into uploading sensitive financial data.Anthropic&#x27;s mitigation guidance: Users should watch for \"suspicious actions that may indicate prompt injection.\"a16z partner Olivia Moore spent a weekend using Clawdbot and captured the disconnect: \"You&#x27;re giving an AI agent access to your accounts. It can read your messages, send texts on your behalf, access your files, and execute code on your machine. You need to actually understand what you&#x27;re authorizing.\"Most users don&#x27;t. Most developers don&#x27;t either. And MCP&#x27;s design never required them to.Five actions for security leadersInventory your MCP exposure now. Traditional endpoint detection sees node or Python processes started by legitimate applications. It doesn&#x27;t flag them as threats. You need tooling that identifies MCP servers specifically. Treat authentication as mandatory. The MCP specification recommends OAuth 2.1. The SDK includes no built-in authentication. Every MCP server touching production systems needs auth enforced at deployment, not after the incident.Restrict network exposure. Bind MCP servers to localhost unless remote access is explicitly required and authenticated. The 1,862 exposed servers Knostic found suggest most exposures are accidental. Assume prompt injection attacks are coming and will be successful. MCP servers inherit the blast radius of the tools they wrap. Server wraps cloud credentials, filesystems, or deployment pipelines? Design access controls assuming the agent will be compromised.Force human approval for high-risk actions. Require explicit confirmation before agents send external email, delete data, or access sensitive information. Treat the agent like a fast but literal junior employee who will do exactly what you say, including things you didn&#x27;t mean.The governance gap is wide openSecurity vendors moved early to monetize MCP risk, but most enterprises didn’t move nearly as fast.Clawdbot adoption exploded in Q4 2025. Most 2026 security roadmaps have zero AI agent controls. The gap between developer enthusiasm and security governance is measured in months. The window for attackers is wide open.Golan is right. This is going to get ugly. The question is whether organizations will secure their MCP exposure before someone else exploits it.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3bkJOPIyWcL3MD20sP4ZT8/74ebf0c216dcfefb690df6a5971f0bbf/2026-01-26_14-51-12.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/people-are-uninstalling-tiktok-and-downloading-an-indie-competitor-233345222.html",
          "published_at": "Mon, 26 Jan 2026 23:33:45 +0000",
          "title": "People are uninstalling TikTok and downloading an indie competitor",
          "standfirst": "TikTok's newly formed US entity is off to a very bumpy start. As the app continues to face technical issues affecting the recommendation algorithm, view counts and other features, TikTok is also seeing a wave of frustrated users uninstalling it, according to new data.Analytics firm Sensor Tower, which tracks downloads and other app store-related metrics, told CNBC that there has been a 150 percent rise in uninstalls of the TikTok app in the United States compared with the last three months. An analyst at Sensor Tower told Engadget that TikTok's US daily active users (DAUs) have increased about 2 percent in the same time period, and are flat week-over-week. TikTok has blamed a power outage at a data center for “multiple bugs,” including those affecting view counts and load times. The company hasn't said when users can expect a fix.At the same time, an independent app called UpScrolled has seen a surge in interest over the last few days. The app is currently the ninth most-downloaded app in the US App Store and the second most popular social app (Meta's Threads is currently in the number one spot for social apps). The app has also reached the top five in the UK and Australian app stores. In the United States, its sudden popularity seems to be closely tied to recent changes at TikTok. UpScrolled has seen 41,000 total downloads between Thursday (the day the US joint venture was formalized) and Saturday, according to estimates from App Figures. The app, which was first released last June, has been downloaded about 140,000 times between Apple and Google's app stores, according to App Figures. Prior to last Thursday, the app was averaging less than 500 downloads a day, according to the company. The rapid increase in downloads has apparently caused some issues for the company which asked users to \"bear with us\" on Monday.Well, this is new...You showed up so fast our servers tapped out. Frustrating? Yes. Emotional? Also yes.We're a tiny team building what Big Tech stopped being. Right now we're scaling on caffeine to keep up with what YOU started.Bear with us. We're on it. pic.twitter.com/OAlYcN6t5q— UpScrolled (@realUpScrolled) January 26, 2026Created by an Australian developer, UpScrolled looks a bit like Instagram. Users can share photos and shortform videos. The app defaults to a chronological \"following\" feed, though it does also recommend content to users. The app is \"privately funded by its founder, Issam Hijazi, together with a small group of individual investors who share our mission and values,\" according to an FAQ on UpScrolled's website. It currently has no ads, though the company says it \"probably\" will in the future. This isn't the first time turmoil at TikTok has benefitted a previously little-known app. Chinese app RedNote briefly became the top app in the United States early last year as TikTok faced a potential ban. RedNote's popularity proved to be short-lived, though, as the 2025 TikTok \"ban\" ended up lasting only a couple of hours. But with new owners at TikTok and growing frustration over technical issues with the app, there could be an opportunity for a new shortform video service that's not controlled by a huge corporation. And that's what UpScrolled seems to be betting on. \"Too often, users are left uncertain about whether their voices will be heard or quietly suppressed,\" the company writes on its website. \"UpScrolled changes that by ensuring every post has a fair chance to be seen, creating an environment that is authentic, unfiltered, and equitable for all.\"Update, January 26, 2026, 4:28PM PT: This post was updated to reflect the latest details from TikTok about the ongoing issues affecting the US version of the app.This article originally appeared on Engadget at https://www.engadget.com/social-media/people-are-uninstalling-tiktok-and-downloading-an-indie-competitor-233345222.html?src=rss",
          "content": "TikTok's newly formed US entity is off to a very bumpy start. As the app continues to face technical issues affecting the recommendation algorithm, view counts and other features, TikTok is also seeing a wave of frustrated users uninstalling it, according to new data.Analytics firm Sensor Tower, which tracks downloads and other app store-related metrics, told CNBC that there has been a 150 percent rise in uninstalls of the TikTok app in the United States compared with the last three months. An analyst at Sensor Tower told Engadget that TikTok's US daily active users (DAUs) have increased about 2 percent in the same time period, and are flat week-over-week. TikTok has blamed a power outage at a data center for “multiple bugs,” including those affecting view counts and load times. The company hasn't said when users can expect a fix.At the same time, an independent app called UpScrolled has seen a surge in interest over the last few days. The app is currently the ninth most-downloaded app in the US App Store and the second most popular social app (Meta's Threads is currently in the number one spot for social apps). The app has also reached the top five in the UK and Australian app stores. In the United States, its sudden popularity seems to be closely tied to recent changes at TikTok. UpScrolled has seen 41,000 total downloads between Thursday (the day the US joint venture was formalized) and Saturday, according to estimates from App Figures. The app, which was first released last June, has been downloaded about 140,000 times between Apple and Google's app stores, according to App Figures. Prior to last Thursday, the app was averaging less than 500 downloads a day, according to the company. The rapid increase in downloads has apparently caused some issues for the company which asked users to \"bear with us\" on Monday.Well, this is new...You showed up so fast our servers tapped out. Frustrating? Yes. Emotional? Also yes.We're a tiny team building what Big Tech stopped being. Right now we're scaling on caffeine to keep up with what YOU started.Bear with us. We're on it. pic.twitter.com/OAlYcN6t5q— UpScrolled (@realUpScrolled) January 26, 2026Created by an Australian developer, UpScrolled looks a bit like Instagram. Users can share photos and shortform videos. The app defaults to a chronological \"following\" feed, though it does also recommend content to users. The app is \"privately funded by its founder, Issam Hijazi, together with a small group of individual investors who share our mission and values,\" according to an FAQ on UpScrolled's website. It currently has no ads, though the company says it \"probably\" will in the future. This isn't the first time turmoil at TikTok has benefitted a previously little-known app. Chinese app RedNote briefly became the top app in the United States early last year as TikTok faced a potential ban. RedNote's popularity proved to be short-lived, though, as the 2025 TikTok \"ban\" ended up lasting only a couple of hours. But with new owners at TikTok and growing frustration over technical issues with the app, there could be an opportunity for a new shortform video service that's not controlled by a huge corporation. And that's what UpScrolled seems to be betting on. \"Too often, users are left uncertain about whether their voices will be heard or quietly suppressed,\" the company writes on its website. \"UpScrolled changes that by ensuring every post has a fair chance to be seen, creating an environment that is authentic, unfiltered, and equitable for all.\"Update, January 26, 2026, 4:28PM PT: This post was updated to reflect the latest details from TikTok about the ongoing issues affecting the US version of the app.This article originally appeared on Engadget at https://www.engadget.com/social-media/people-are-uninstalling-tiktok-and-downloading-an-indie-competitor-233345222.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/how-to-generate-ai-images-using-chatgpt-120000560.html",
          "published_at": "Mon, 26 Jan 2026 18:05:00 +0000",
          "title": "How to generate AI images using ChatGPT",
          "standfirst": "Since March 2025, ChatGPT has been capable of generating images. Following a period where it briefly wasn't available to free users, you now don't even pay for one of OpenAI's subscriptions to use this feature. And while making images inside of ChatGPT is easy, there are some nuances worth explaining. For example, did you know you can ask ChatGPT to edit photos you've taken? It's more powerful than you might think. Here’s everything you need to know about generating AI images with ChatGPT. How to create images with ChatGPT using text prompts To begin making an image in ChatGPT, you can start by typing in the prompt bar. Igor Bonifacic for EngadgetYou can start generating images in ChatGPT simply by typing in the prompt bar what you want to see. There's no need to overthink things; as long as you have some version of \"generate an image\" followed by a description of your idea, ChatGPT will do the rest. Depending on the complexity of the prompt and whether you pay for ChatGPT, it may take a minute or two for the chatbot to complete your image request. Sometimes the process can take longer if OpenAI's servers are experiencing greater traffic than usual.At the end of last year, OpenAI updated the model powering image generation to make it faster, as well as better at rendering text and following instructions. At the same time, it added a dedicated \"Images\" section to ChatGPT's sidebar. Here you can see all the images you've made, alongside sample prompts and suggestions for styles to try out, making it a great place to start if you've never used an image generator before. How to create images with ChatGPT using existing photosYou can also upload images to ChatGPT.Igor Bonifacic for EngadgetIn addition to generating images from text prompts, ChatGPT can modify existing photos or images you upload. This is my preferred way of making images with ChatGPT; I don't need to describe the composition, I can use an existing one to guide the chatbot. To use an existing image as a starting point for a new generation, follow these steps: Tap the \"+\" icon, located to the left of the prompt bar. Select Add photos & files. Select the image you want ChatGPT to edit. If uploading an image from your phone, you'll first need to grant ChatGPT access to your camera roll. Write a prompt describing the changes you want. If generating from the Images section, tap \"Add photos\" instead.Keep in mind any photos you upload to OpenAI's servers may be used by the company to train future models. You can opt out of allowing your data to be used for training by following these steps: Open the sidebar menu. On mobile, tap the two lines on the top left of the interface; on desktop, click instead on the OpenAI logo.Tap your name to access account settings. Tap Data controls.Toggle off Improve the model for everyone. How to edit the images ChatGPT generatesChatGPT gives you a few different ways to edit images.Igor Bonifacic for EngadgetIf you're unhappy with ChatGPT's output, you have two options. You can either prompt it to create an entirely new image, or edit parts of the picture it just generated. As always, the process for both involves simply typing what you want in the prompt bar. On mobile, OpenAI gives users a few different ways of accomplishing the same task.To generate an entirely new image: Tap the three dots icon below the image ChatGPT created. Select Retry. To edit part of an existing image generation: Tap the image ChatGPT created. Tap Select area.Use your finger to mask the section of the image you want ChatGPT to tweak. The slider on the left allows you to adjust the size of the masking brush. On desktop, masking is also available if you click on an image and then click on the paintbrush icon on the top right. Describe what you want ChatGPT to add, remove or replace through the prompt bar.ChatGPT can also blend one of your photos with an image it has generated. To do this: Tap an image ChatGPT created.Tap Blend in a photo.Upload the photo you wish Like all AI systems, ChatGPT is non-deterministic, meaning even if you prompt it in the same way multiple times, it won't generate the exact same response each time. Tips to create better images with ChatGPTThe best advice I can offer is to be specific when prompting ChatGPT. The more detail you can provide when describing what you want from it, the better the results. And remember: ChatGPT can hallucinate — as you may have noticed from one of the example pictures I included above. In the image of the tortoiseshell cat, not only is the tortie not sitting on the window sill as instructed, it's sitting on a table that doesn't make much sense. So, most of all, be patient. Prompting an AI model is not exact science, and it can take a few tries before it creates the result you want. FAQsHow do you access ChatGPT?ChatGPT is available on the web, desktop and mobile. To access it on your computer, open your preferred browser and navigate to chatgpt.com. OpenAI also offers dedicated Mac and Windows apps you can download from the company's website. On iOS and Android, you'll need to download the ChatGPT app from either the App Store or Google Play before you can start using the chatbot. Since ChatGPT runs on OpenAI's servers, as long as you can access the chatbot, you'll be able to use it to create images no matter the age of your phone or computer. Can ChatGPT generate images for free? Yes, ChatGPT can generate images for free, as long as you create an OpenAI account. However, there is a daily rate cap and GPT-5 will take longer to make a free image. Following March 27, 2025, OpenAI briefly limited free users to three image generations per day. The company has since relaxed that restriction, though it doesn't list a specific limit on its website. In my experience, you'll be able to generate about six to seven images every 24 hours.OpenAI offers three different subscription plans, each with their own set of image generation perks. ChatGPT Go, which costs $8 per month, offers \"more image creation.\" ChatGPT Plus, which costs $20 per month, offers \"expanded and faster image creation.\"ChatGPT Pro, which costs $200 per month, offers \"unlimited and faster image creation.\" Note: ChatGPT Go will be included in OpenAI's forthcoming ads pilot, which will see the company display sponsored content alongside organic responses from ChatGPT. The company does not plan to display ads to Plus and Pro users. Can ChatGPT generate an existing photo? No. For copyright reasons, ChatGPT can't replicate photos or exact real world events. For example, when I asked it to recreate the photo of Zinedine Zidane's iconic 2006 World Cup headbutt, ChatGPT refused. \"I can make an artistic reinterpretation inspired by the emotion or energy of that moment — for example, a stylized painting showing the tension and intensity of competition, without depicting real individuals,\" it told me. This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-generate-ai-images-using-chatgpt-120000560.html?src=rss",
          "content": "Since March 2025, ChatGPT has been capable of generating images. Following a period where it briefly wasn't available to free users, you now don't even pay for one of OpenAI's subscriptions to use this feature. And while making images inside of ChatGPT is easy, there are some nuances worth explaining. For example, did you know you can ask ChatGPT to edit photos you've taken? It's more powerful than you might think. Here’s everything you need to know about generating AI images with ChatGPT. How to create images with ChatGPT using text prompts To begin making an image in ChatGPT, you can start by typing in the prompt bar. Igor Bonifacic for EngadgetYou can start generating images in ChatGPT simply by typing in the prompt bar what you want to see. There's no need to overthink things; as long as you have some version of \"generate an image\" followed by a description of your idea, ChatGPT will do the rest. Depending on the complexity of the prompt and whether you pay for ChatGPT, it may take a minute or two for the chatbot to complete your image request. Sometimes the process can take longer if OpenAI's servers are experiencing greater traffic than usual.At the end of last year, OpenAI updated the model powering image generation to make it faster, as well as better at rendering text and following instructions. At the same time, it added a dedicated \"Images\" section to ChatGPT's sidebar. Here you can see all the images you've made, alongside sample prompts and suggestions for styles to try out, making it a great place to start if you've never used an image generator before. How to create images with ChatGPT using existing photosYou can also upload images to ChatGPT.Igor Bonifacic for EngadgetIn addition to generating images from text prompts, ChatGPT can modify existing photos or images you upload. This is my preferred way of making images with ChatGPT; I don't need to describe the composition, I can use an existing one to guide the chatbot. To use an existing image as a starting point for a new generation, follow these steps: Tap the \"+\" icon, located to the left of the prompt bar. Select Add photos & files. Select the image you want ChatGPT to edit. If uploading an image from your phone, you'll first need to grant ChatGPT access to your camera roll. Write a prompt describing the changes you want. If generating from the Images section, tap \"Add photos\" instead.Keep in mind any photos you upload to OpenAI's servers may be used by the company to train future models. You can opt out of allowing your data to be used for training by following these steps: Open the sidebar menu. On mobile, tap the two lines on the top left of the interface; on desktop, click instead on the OpenAI logo.Tap your name to access account settings. Tap Data controls.Toggle off Improve the model for everyone. How to edit the images ChatGPT generatesChatGPT gives you a few different ways to edit images.Igor Bonifacic for EngadgetIf you're unhappy with ChatGPT's output, you have two options. You can either prompt it to create an entirely new image, or edit parts of the picture it just generated. As always, the process for both involves simply typing what you want in the prompt bar. On mobile, OpenAI gives users a few different ways of accomplishing the same task.To generate an entirely new image: Tap the three dots icon below the image ChatGPT created. Select Retry. To edit part of an existing image generation: Tap the image ChatGPT created. Tap Select area.Use your finger to mask the section of the image you want ChatGPT to tweak. The slider on the left allows you to adjust the size of the masking brush. On desktop, masking is also available if you click on an image and then click on the paintbrush icon on the top right. Describe what you want ChatGPT to add, remove or replace through the prompt bar.ChatGPT can also blend one of your photos with an image it has generated. To do this: Tap an image ChatGPT created.Tap Blend in a photo.Upload the photo you wish Like all AI systems, ChatGPT is non-deterministic, meaning even if you prompt it in the same way multiple times, it won't generate the exact same response each time. Tips to create better images with ChatGPTThe best advice I can offer is to be specific when prompting ChatGPT. The more detail you can provide when describing what you want from it, the better the results. And remember: ChatGPT can hallucinate — as you may have noticed from one of the example pictures I included above. In the image of the tortoiseshell cat, not only is the tortie not sitting on the window sill as instructed, it's sitting on a table that doesn't make much sense. So, most of all, be patient. Prompting an AI model is not exact science, and it can take a few tries before it creates the result you want. FAQsHow do you access ChatGPT?ChatGPT is available on the web, desktop and mobile. To access it on your computer, open your preferred browser and navigate to chatgpt.com. OpenAI also offers dedicated Mac and Windows apps you can download from the company's website. On iOS and Android, you'll need to download the ChatGPT app from either the App Store or Google Play before you can start using the chatbot. Since ChatGPT runs on OpenAI's servers, as long as you can access the chatbot, you'll be able to use it to create images no matter the age of your phone or computer. Can ChatGPT generate images for free? Yes, ChatGPT can generate images for free, as long as you create an OpenAI account. However, there is a daily rate cap and GPT-5 will take longer to make a free image. Following March 27, 2025, OpenAI briefly limited free users to three image generations per day. The company has since relaxed that restriction, though it doesn't list a specific limit on its website. In my experience, you'll be able to generate about six to seven images every 24 hours.OpenAI offers three different subscription plans, each with their own set of image generation perks. ChatGPT Go, which costs $8 per month, offers \"more image creation.\" ChatGPT Plus, which costs $20 per month, offers \"expanded and faster image creation.\"ChatGPT Pro, which costs $200 per month, offers \"unlimited and faster image creation.\" Note: ChatGPT Go will be included in OpenAI's forthcoming ads pilot, which will see the company display sponsored content alongside organic responses from ChatGPT. The company does not plan to display ads to Plus and Pro users. Can ChatGPT generate an existing photo? No. For copyright reasons, ChatGPT can't replicate photos or exact real world events. For example, when I asked it to recreate the photo of Zinedine Zidane's iconic 2006 World Cup headbutt, ChatGPT refused. \"I can make an artistic reinterpretation inspired by the emotion or energy of that moment — for example, a stylized painting showing the tension and intensity of competition, without depicting real individuals,\" it told me. This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-generate-ai-images-using-chatgpt-120000560.html?src=rss",
          "feed_position": 35,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/chatgpt-how-to-3.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/trump-admin-reportedly-plans-to-use-ai-to-write-federal-regulations-175155111.html",
          "published_at": "Mon, 26 Jan 2026 17:51:56 +0000",
          "title": "Trump admin reportedly plans to use AI to write federal regulations",
          "standfirst": "The Trump administration is planning on using Google Gemini to draft important federal regulations, as reported by ProPublica. This is starting with the Department of Transportation, according to interviews with agency staffers. Regulations created by the DOT help keep us safe when traveling. The plan was initially presented to DOT staffers last month, with agency attorney Daniel Cohen writing to colleagues about AI's \"potential to revolutionize the way we draft rulemakings.\" Gregory Zerzan, the agency's general counsel, has indicated that President Donald Trump is \"very excited by this initiative\" and that DOT will be \"the first agency that is fully enabled to use AI to draft rules.\" This does suggest a pilot program of sorts, with eventual plans to bring AI to other departments. NEW: The Trump administration is planning to use AI to write federal regulations despite the risk of hallucinations.“We don't even need a very good rule,” @USDOT’s top lawyer said of the plan, per meeting notes reviewed by ProPublica. “We want good enough.” 🧵 pic.twitter.com/YKGvmlkMCt— Jesse Coburn (@Jesse_Coburn) January 26, 2026 Oddly, Zerzan doesn't seem that interested in high-quality regulations. ProPublica received transcripts of a meeting in which he declared that \"we don't need the perfect rule on XYZ. We don't even need a very good rule on XYZ.\" He went on to say that \"we want good enough\" and that \"we're flooding the zone.\" Let me remind you that DOT regulates the safety standards of commercial aircraft, along with rules involving the transport of hazardous materials and driver qualifications. The agency's rules touch on every aspect of transportation safety. Why would the federal government rely on a new technology that's notorious for making mistakes? AI “hallucinations” eg false/made-up info now becoming a problem in scientific publications. Kudos to @alexcdot et al on building an AI hallucination detector and finding that certain journals/authors have used LLMs to generate papers that also made it through peer review. Here’s… pic.twitter.com/i4Be1lS8xq— Daphne Zohar (@daphnezohar) January 22, 2026 The answer is speed. Writing and revising complex federal regulations can take months, but Google Gemini can spit something out in minutes. A DOT employee giving a presentation on the program suggested that many parts of these regulations are just \"word salad\" anyways, so AI should be able to do just fine. \"It shouldn’t take you more than 20 minutes to get a draft rule out of Gemini,\" Zerzan said. The plan is to compress the timeline in which transportation regulations are written and reviewed. The department has already used AI to draft an unpublished Federal Aviation Administration rule. Federal agencies have used AI for years, but not to actually write regulations. It's primarily been used for the purpose of translating documents, analyzing data and categorizing public comments. Trump, however, is a huge proponent of the technology. He has released multiple executive orders in support of AI and once shared an AI-created video in which he flew a fighter jet and dropped what appears to be feces on American citizens. Skeptics say that large language models like Gemini shouldn't be in charge of drafting complicated and consequential regulations that impact millions of everyday Americans. Mistakes could lead to lawsuits and even injuries and deaths. Mike Horton, DOT’s former acting chief artificial intelligence officer, said using Gemini to draft regulations was like “having a high school intern that’s doing your rulemaking.” He also said that agency leaders under Trump \"want to go fast and break things, but going fast and breaking things means people are going to get hurt.\" \"Just because these tools can produce a lot of words doesn’t mean that those words add up to a high-quality government decision,” said Bridget Dooling, a professor at Ohio State University who studies administrative law. “It’s so tempting to try to figure out how to use these tools, and I think it would make sense to try. But I think it should be done with a lot of skepticism.\" DOT has experienced a net loss of more than 4,000 employees since Trump started his second term. This includes over 100 attorneys.This article originally appeared on Engadget at https://www.engadget.com/ai/trump-admin-reportedly-plans-to-use-ai-to-write-federal-regulations-175155111.html?src=rss",
          "content": "The Trump administration is planning on using Google Gemini to draft important federal regulations, as reported by ProPublica. This is starting with the Department of Transportation, according to interviews with agency staffers. Regulations created by the DOT help keep us safe when traveling. The plan was initially presented to DOT staffers last month, with agency attorney Daniel Cohen writing to colleagues about AI's \"potential to revolutionize the way we draft rulemakings.\" Gregory Zerzan, the agency's general counsel, has indicated that President Donald Trump is \"very excited by this initiative\" and that DOT will be \"the first agency that is fully enabled to use AI to draft rules.\" This does suggest a pilot program of sorts, with eventual plans to bring AI to other departments. NEW: The Trump administration is planning to use AI to write federal regulations despite the risk of hallucinations.“We don't even need a very good rule,” @USDOT’s top lawyer said of the plan, per meeting notes reviewed by ProPublica. “We want good enough.” 🧵 pic.twitter.com/YKGvmlkMCt— Jesse Coburn (@Jesse_Coburn) January 26, 2026 Oddly, Zerzan doesn't seem that interested in high-quality regulations. ProPublica received transcripts of a meeting in which he declared that \"we don't need the perfect rule on XYZ. We don't even need a very good rule on XYZ.\" He went on to say that \"we want good enough\" and that \"we're flooding the zone.\" Let me remind you that DOT regulates the safety standards of commercial aircraft, along with rules involving the transport of hazardous materials and driver qualifications. The agency's rules touch on every aspect of transportation safety. Why would the federal government rely on a new technology that's notorious for making mistakes? AI “hallucinations” eg false/made-up info now becoming a problem in scientific publications. Kudos to @alexcdot et al on building an AI hallucination detector and finding that certain journals/authors have used LLMs to generate papers that also made it through peer review. Here’s… pic.twitter.com/i4Be1lS8xq— Daphne Zohar (@daphnezohar) January 22, 2026 The answer is speed. Writing and revising complex federal regulations can take months, but Google Gemini can spit something out in minutes. A DOT employee giving a presentation on the program suggested that many parts of these regulations are just \"word salad\" anyways, so AI should be able to do just fine. \"It shouldn’t take you more than 20 minutes to get a draft rule out of Gemini,\" Zerzan said. The plan is to compress the timeline in which transportation regulations are written and reviewed. The department has already used AI to draft an unpublished Federal Aviation Administration rule. Federal agencies have used AI for years, but not to actually write regulations. It's primarily been used for the purpose of translating documents, analyzing data and categorizing public comments. Trump, however, is a huge proponent of the technology. He has released multiple executive orders in support of AI and once shared an AI-created video in which he flew a fighter jet and dropped what appears to be feces on American citizens. Skeptics say that large language models like Gemini shouldn't be in charge of drafting complicated and consequential regulations that impact millions of everyday Americans. Mistakes could lead to lawsuits and even injuries and deaths. Mike Horton, DOT’s former acting chief artificial intelligence officer, said using Gemini to draft regulations was like “having a high school intern that’s doing your rulemaking.” He also said that agency leaders under Trump \"want to go fast and break things, but going fast and breaking things means people are going to get hurt.\" \"Just because these tools can produce a lot of words doesn’t mean that those words add up to a high-quality government decision,” said Bridget Dooling, a professor at Ohio State University who studies administrative law. “It’s so tempting to try to figure out how to use these tools, and I think it would make sense to try. But I think it should be done with a lot of skepticism.\" DOT has experienced a net loss of more than 4,000 employees since Trump started his second term. This includes over 100 attorneys.This article originally appeared on Engadget at https://www.engadget.com/ai/trump-admin-reportedly-plans-to-use-ai-to-write-federal-regulations-175155111.html?src=rss",
          "feed_position": 37
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/apples-new-airtag-still-doesnt-have-a-keyring-hole-150540254.html",
          "published_at": "Mon, 26 Jan 2026 15:05:40 +0000",
          "title": "Apple's new AirTag still doesn't have a keyring hole",
          "standfirst": "Apple has launched its next-generation AirTag for $29 and brought a slew of new features along with it. But, first, it's important to get this out of the way: The new AirTag still doesn't have a keyring hole, so you'll still need a case or secure pocket. Once you get over that, the new Apple AirTag does offer some nice improvements. For starters, it's now powered by Apple's second-generation Ultra Wideband chip — the same one used in the iPhone 17 lineup and for the Apple Watch Ultra 3. It also uses Precision Finding to reach items up to 50 percent further away than the previous AirTag model. This feature will now work with any Apple Watch Series 9, Ultra 2 or a later iteration of either. The new AirTag is also 50 percent louder than before and has what Apple calls a \"distinctive new chime.\" It still uses the Find My network to bounce off other Bluetooth users and locate the AirTag. Apple Launched in 2021, Apple's AirTag has long stood as our favorite Bluetooth tracker for iPhones. It's convenience within the Find My app is a big help and almost makes up for the fact that it doesn't have a key ring — almost. This article originally appeared on Engadget at https://www.engadget.com/wearables/apples-new-airtag-still-doesnt-have-a-keyring-hole-150540254.html?src=rss",
          "content": "Apple has launched its next-generation AirTag for $29 and brought a slew of new features along with it. But, first, it's important to get this out of the way: The new AirTag still doesn't have a keyring hole, so you'll still need a case or secure pocket. Once you get over that, the new Apple AirTag does offer some nice improvements. For starters, it's now powered by Apple's second-generation Ultra Wideband chip — the same one used in the iPhone 17 lineup and for the Apple Watch Ultra 3. It also uses Precision Finding to reach items up to 50 percent further away than the previous AirTag model. This feature will now work with any Apple Watch Series 9, Ultra 2 or a later iteration of either. The new AirTag is also 50 percent louder than before and has what Apple calls a \"distinctive new chime.\" It still uses the Find My network to bounce off other Bluetooth users and locate the AirTag. Apple Launched in 2021, Apple's AirTag has long stood as our favorite Bluetooth tracker for iPhones. It's convenience within the Find My app is a big help and almost makes up for the fact that it doesn't have a key ring — almost. This article originally appeared on Engadget at https://www.engadget.com/wearables/apples-new-airtag-still-doesnt-have-a-keyring-hole-150540254.html?src=rss",
          "feed_position": 43,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/a0306be0-fac3-11f0-bf75-60455910936b"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/resident-evil-requiem-preview-150000849.html",
          "published_at": "Mon, 26 Jan 2026 15:00:00 +0000",
          "title": "Resident Evil Requiem gives series fans the best of both action and survival horror",
          "standfirst": "The ninth mainline Resident Evil is trying to split the difference between the series’ action-heavy entries and the stress-inducing hide-and-seek episodes. During a four-hour playthrough of some early parts of Resident Evil Requiem, I spent time with both of the two main characters, Grace and series mainstay Leon. They offer distinctly different playstyles, talents, strengths, and weaknesses. While it isn't an entirely new premise for the survival horror series (in the original, playing as Chris Redfield offered more challenge than playing as Jill Valentine) it’s never been this pronounced. I started playing as Leon, entering a medical facility he seemed to have been invited to. With a cavernous main hall, it feels like yet another iconic Resident Evil hub, immediately reminding me of Raccoon City's Police Precinct and even the original's cavernous manor. Wings to explore? Check. Suspiciously quiet and empty central area that will almost definitely get overrun by zombies at some point? Probably.Both Grace and Leon’s parts can be played in either third- or first-person perspective, though Leon’s segments seem better suited to the third-person view, since there's just a lot more shooting. Grace's segments were tense and demanded my full attention, more akin to Resident Evil 7. During this early part of the game, there is a lot of hiding, plenty of ammo conservation and a lot more learning from dumb mistakes. The parts of the game I played with Leon reminded me more of Resident Evil 4 (or 5 or 6 – but let’s gloss over those).Once you take control of him, Leon is immediately attacked and has to fend off roughly 15 infected doctors, nurses and patients. It’s a significant tone shift from Grace skulking around the facility, hiding behind plants and sometimes just hoping for the best. Leon faces off against a chainsaw-wielding doctor zombie. Best cut that arm off.CapcomLeon, fortunately, arrives with several weapons, including a new melee option, a hatchet. Using this, he can make targeted attacks to lop off limbs and aim at the head to deliver more damage. At least on these basic zombies, I found relentless slashing more effective than more targeted efforts – I’m sure future enemies will demand more… nuanced approaches. A later enemy must be decapitated to kill it. After a set number of swings, you will need to retreat and sharpen the blade, which adds to the jeopardy while not disrupting the chaos. The hatchet can even be used to parry attacks – if you get the timing down. Leon even gets to wield a chainsaw during this initial encounter, but only after claiming it from one particularly industrious zombie that seemed to find it inside a hospital. It was crucial to both disarm this zombie and grab the chainsaw before another corpse could take a turn on it. However, just because the chainsaw gets dropped doesn’t mean it’s turned off. I suffered significant damage when I repeatedly rushed into the spinning power tool. The zombies in Requiem are also a little more nuanced compared to previous games – if a zombie can have nuance. While nearly all of the zombies will attack you on sight, they can be distracted or delayed based on the person they were before they turned. For example, the chef zombie (a hardy, bigger zombie than the ones you’ve come across until that point) will only chase you around his kitchen. Step out into the corridor and he’ll leave you alone. Elsewhere, a zombie (attached to an IV, cute) has his eyes bandaged and will react aggressively to any noise. I used this to my advantage, hurling an empty bottle at another zombie who stood nearby. The IV zombie killed him immediately. Another time, a senior exec who’s been turned is firing an employee of his… by killing them, moaning “You’re fired” as he does so. This little vignette gave me enough time to dim the lights and hide when he left his office. In Requiem, players are expected to exploit individual zombie behaviors to outmaneuver them. It’s also a welcome dose of humor to the survival horror series, reminding me a little of the camp moments in Dead Rising, another zombie-centric Capcom series. Leon doesn’t have to strategize quite as much, arriving with a particularly powerful handgun, the Requiem, that he eventually passes over to Grace. This is capable of stopping pretty much (but not all) enemies you come across, although it initially comes with only a single bullet, so you really have to make it count. During a set-piece battle against a towering, swollen former patient, I got to test Requiem’s action-horror controls under pressure. Leon finds a shotgun and has to flank (and outrun) his “hungry” attacker. The environment in the rafters of the building is designed so it’s easy to figure out where you need to go and how to stop the giant zombie from cornering you. Ammo, at least during this fight, was scattered around, which was a relief after struggling to find bullets during Grace’s segment.Despite the lack of traditional weapons, Grace eventually finds a blood injector (and its companion blood analysis system). These turn into Requiem’s crafting system. Powered by literal buckets and puddles of blood (you have to draw up infected blood from certain parts of the environment and enemies), samples can be combined with scraps, herbs and more to create high-powered first-aid shots, injectable explosive blood, ammunition and a lot of other things. Analysing different blood types (and solving some light puzzles) adds further crafting options. Oh he's not going to help you.CapcomDuring the preview, the infected blood injector was exclusively for Grace’s use. It’ll be intriguing if only one character gets to benefit from the crafting system, although Capcom teased customizable weapons for Leon, which might better suit his playstyle. Grace might also be handicapped by the typewriter save system popularized in the first few RE games. This could mean you’ll only be able to save if you have an ink ribbon on you, a very stressful part of inventory management early on in the series — she really can’t catch a break. However, it appears to be adjustable in difficulty settings. According to Capcom’s Resident Evil showcase last week, infected blood will apparently play a strong role in Requiem, touching on both Leon’s past (he’s apparently suffering from a mystery ailment) and the circumstances surrounding the death of Grace's mother. And it wouldn’t be a Resident Evil game with mystery, buckets of blood, and a pulpy villain. Capcom has primed another fascinating villain with Requiem’s Dr. Gideon, a former Umbrella virologist who was seemingly written for an actor to go full camp baddie – if the doctor’s hooded snakeskin trenchcoat wasn’t a giveaway. Resident Evil Requiem will be released on February 27, 2026 for PC, PS5 and Xbox Series X|S.This article originally appeared on Engadget at https://www.engadget.com/gaming/resident-evil-requiem-preview-150000849.html?src=rss",
          "content": "The ninth mainline Resident Evil is trying to split the difference between the series’ action-heavy entries and the stress-inducing hide-and-seek episodes. During a four-hour playthrough of some early parts of Resident Evil Requiem, I spent time with both of the two main characters, Grace and series mainstay Leon. They offer distinctly different playstyles, talents, strengths, and weaknesses. While it isn't an entirely new premise for the survival horror series (in the original, playing as Chris Redfield offered more challenge than playing as Jill Valentine) it’s never been this pronounced. I started playing as Leon, entering a medical facility he seemed to have been invited to. With a cavernous main hall, it feels like yet another iconic Resident Evil hub, immediately reminding me of Raccoon City's Police Precinct and even the original's cavernous manor. Wings to explore? Check. Suspiciously quiet and empty central area that will almost definitely get overrun by zombies at some point? Probably.Both Grace and Leon’s parts can be played in either third- or first-person perspective, though Leon’s segments seem better suited to the third-person view, since there's just a lot more shooting. Grace's segments were tense and demanded my full attention, more akin to Resident Evil 7. During this early part of the game, there is a lot of hiding, plenty of ammo conservation and a lot more learning from dumb mistakes. The parts of the game I played with Leon reminded me more of Resident Evil 4 (or 5 or 6 – but let’s gloss over those).Once you take control of him, Leon is immediately attacked and has to fend off roughly 15 infected doctors, nurses and patients. It’s a significant tone shift from Grace skulking around the facility, hiding behind plants and sometimes just hoping for the best. Leon faces off against a chainsaw-wielding doctor zombie. Best cut that arm off.CapcomLeon, fortunately, arrives with several weapons, including a new melee option, a hatchet. Using this, he can make targeted attacks to lop off limbs and aim at the head to deliver more damage. At least on these basic zombies, I found relentless slashing more effective than more targeted efforts – I’m sure future enemies will demand more… nuanced approaches. A later enemy must be decapitated to kill it. After a set number of swings, you will need to retreat and sharpen the blade, which adds to the jeopardy while not disrupting the chaos. The hatchet can even be used to parry attacks – if you get the timing down. Leon even gets to wield a chainsaw during this initial encounter, but only after claiming it from one particularly industrious zombie that seemed to find it inside a hospital. It was crucial to both disarm this zombie and grab the chainsaw before another corpse could take a turn on it. However, just because the chainsaw gets dropped doesn’t mean it’s turned off. I suffered significant damage when I repeatedly rushed into the spinning power tool. The zombies in Requiem are also a little more nuanced compared to previous games – if a zombie can have nuance. While nearly all of the zombies will attack you on sight, they can be distracted or delayed based on the person they were before they turned. For example, the chef zombie (a hardy, bigger zombie than the ones you’ve come across until that point) will only chase you around his kitchen. Step out into the corridor and he’ll leave you alone. Elsewhere, a zombie (attached to an IV, cute) has his eyes bandaged and will react aggressively to any noise. I used this to my advantage, hurling an empty bottle at another zombie who stood nearby. The IV zombie killed him immediately. Another time, a senior exec who’s been turned is firing an employee of his… by killing them, moaning “You’re fired” as he does so. This little vignette gave me enough time to dim the lights and hide when he left his office. In Requiem, players are expected to exploit individual zombie behaviors to outmaneuver them. It’s also a welcome dose of humor to the survival horror series, reminding me a little of the camp moments in Dead Rising, another zombie-centric Capcom series. Leon doesn’t have to strategize quite as much, arriving with a particularly powerful handgun, the Requiem, that he eventually passes over to Grace. This is capable of stopping pretty much (but not all) enemies you come across, although it initially comes with only a single bullet, so you really have to make it count. During a set-piece battle against a towering, swollen former patient, I got to test Requiem’s action-horror controls under pressure. Leon finds a shotgun and has to flank (and outrun) his “hungry” attacker. The environment in the rafters of the building is designed so it’s easy to figure out where you need to go and how to stop the giant zombie from cornering you. Ammo, at least during this fight, was scattered around, which was a relief after struggling to find bullets during Grace’s segment.Despite the lack of traditional weapons, Grace eventually finds a blood injector (and its companion blood analysis system). These turn into Requiem’s crafting system. Powered by literal buckets and puddles of blood (you have to draw up infected blood from certain parts of the environment and enemies), samples can be combined with scraps, herbs and more to create high-powered first-aid shots, injectable explosive blood, ammunition and a lot of other things. Analysing different blood types (and solving some light puzzles) adds further crafting options. Oh he's not going to help you.CapcomDuring the preview, the infected blood injector was exclusively for Grace’s use. It’ll be intriguing if only one character gets to benefit from the crafting system, although Capcom teased customizable weapons for Leon, which might better suit his playstyle. Grace might also be handicapped by the typewriter save system popularized in the first few RE games. This could mean you’ll only be able to save if you have an ink ribbon on you, a very stressful part of inventory management early on in the series — she really can’t catch a break. However, it appears to be adjustable in difficulty settings. According to Capcom’s Resident Evil showcase last week, infected blood will apparently play a strong role in Requiem, touching on both Leon’s past (he’s apparently suffering from a mystery ailment) and the circumstances surrounding the death of Grace's mother. And it wouldn’t be a Resident Evil game with mystery, buckets of blood, and a pulpy villain. Capcom has primed another fascinating villain with Requiem’s Dr. Gideon, a former Umbrella virologist who was seemingly written for an actor to go full camp baddie – if the doctor’s hooded snakeskin trenchcoat wasn’t a giveaway. Resident Evil Requiem will be released on February 27, 2026 for PC, PS5 and Xbox Series X|S.This article originally appeared on Engadget at https://www.engadget.com/gaming/resident-evil-requiem-preview-150000849.html?src=rss",
          "feed_position": 44,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/requiem1_2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/the-eu-is-investigating-grok-and-x-over-potentially-illegal-deepfakes-134506678.html",
          "published_at": "Mon, 26 Jan 2026 13:45:06 +0000",
          "title": "The EU is investigating Grok and X over potentially illegal deepfakes",
          "standfirst": "Europe is probing Elon Musk’s X for failing to take action to prevent the spread of AI-generated sexually explicit images including child sexual abuse material (CSAM), regulators said in a press release. The European Commission’s investigation could result in “further enforcement steps” against X, not long after it levied a $140 million fine against the platform.“Sexual deepfakes of women and children are a violent, unacceptable form of degradation. With this investigation, we will determine whether X has met its legal obligations under the DSA [Digital Services Act], or whether it treated rights of European citizens — including those of women and children — as collateral damage of its service,” said the Commission’s executive VP, Henna Virkkunen in a statement.The EU said that it will assess whether X took measures to reduce risks around the dissemination of illegal content when it deployed Grok onto the platform. Those risks include manipulated sexually explicit images including content that may amount to CSAM. “These risks seem to have materialized, exposing citizens in the EU to serious harm,” the Commission stated.On top of the new inquiry, the EC is also expanding its 2023 investigation of X over its recommendation algorithm and tools used to prevent the spread of illicit content.CBS News found that, as of Monday morning, Grok was still able to generate undressed images of individuals. X previously claimed this ability had been removed for both free and paid users. The investigation is coming at a delicate time for Europe, which is already in the Trump administration’s crosshairs over its scrutiny of American tech companies. And the EU would also be going up against Musk, who is the owner and has the biggest megaphone on X. After X was hit with a 120 million euro ($140 million fine) for breaching Europe’s Digital Services Act, Musk called the EU “the fourth Reich” and said in a post on X that it should be “abolished.”In response to the inquiry, X reiterated previous comments it has made about Grok. “We remain committed to making X a safe platform for everyone and continue to have zero tolerance for any forms of child sexual exploitation, nonconsensual nudity and unwanted sexual content,” a spokesperson told The New York Times.Update, January 26 2026, 11:42AM ET: Added additional coverage from CBS.This article originally appeared on Engadget at https://www.engadget.com/ai/the-eu-is-investigating-grok-and-x-over-potentially-illegal-deepfakes-134506678.html?src=rss",
          "content": "Europe is probing Elon Musk’s X for failing to take action to prevent the spread of AI-generated sexually explicit images including child sexual abuse material (CSAM), regulators said in a press release. The European Commission’s investigation could result in “further enforcement steps” against X, not long after it levied a $140 million fine against the platform.“Sexual deepfakes of women and children are a violent, unacceptable form of degradation. With this investigation, we will determine whether X has met its legal obligations under the DSA [Digital Services Act], or whether it treated rights of European citizens — including those of women and children — as collateral damage of its service,” said the Commission’s executive VP, Henna Virkkunen in a statement.The EU said that it will assess whether X took measures to reduce risks around the dissemination of illegal content when it deployed Grok onto the platform. Those risks include manipulated sexually explicit images including content that may amount to CSAM. “These risks seem to have materialized, exposing citizens in the EU to serious harm,” the Commission stated.On top of the new inquiry, the EC is also expanding its 2023 investigation of X over its recommendation algorithm and tools used to prevent the spread of illicit content.CBS News found that, as of Monday morning, Grok was still able to generate undressed images of individuals. X previously claimed this ability had been removed for both free and paid users. The investigation is coming at a delicate time for Europe, which is already in the Trump administration’s crosshairs over its scrutiny of American tech companies. And the EU would also be going up against Musk, who is the owner and has the biggest megaphone on X. After X was hit with a 120 million euro ($140 million fine) for breaching Europe’s Digital Services Act, Musk called the EU “the fourth Reich” and said in a post on X that it should be “abolished.”In response to the inquiry, X reiterated previous comments it has made about Grok. “We remain committed to making X a safe platform for everyone and continue to have zero tolerance for any forms of child sexual exploitation, nonconsensual nudity and unwanted sexual content,” a spokesperson told The New York Times.Update, January 26 2026, 11:42AM ET: Added additional coverage from CBS.This article originally appeared on Engadget at https://www.engadget.com/ai/the-eu-is-investigating-grok-and-x-over-potentially-illegal-deepfakes-134506678.html?src=rss",
          "feed_position": 45
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/1kE7n0Y35usP0AVocbHTSc/bcd1013573ca6fa9d72977ba8f33cf4a/hero_image.jpg?w=300&q=30",
      "popularity_score": 3012.4268394444443
    },
    {
      "id": "cluster_25",
      "coverage": 2,
      "updated_at": "Wed, 28 Jan 2026 01:30:40 GMT",
      "title": "I finally tested a Windows laptop with Intel's Panther Lake chip - and the hype is justified",
      "neutral_headline": "Intel’s Panther Lake Chips Aren’t Just Good—They Beat Apple's M5",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/asus-expertbook-ultra-b9-review/",
          "published_at": "Wed, 28 Jan 2026 01:30:40 GMT",
          "title": "I finally tested a Windows laptop with Intel's Panther Lake chip - and the hype is justified",
          "standfirst": "Asus' ExpertBook Ultra B9 is as ultraportable as it is powerful, with Intel's latest chipset and a stunning OLED display.",
          "content": "Asus' ExpertBook Ultra B9 is as ultraportable as it is powerful, with Intel's latest chipset and a stunning OLED display.",
          "feed_position": 4
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/intel-panther-lake-core-ultra-series-3-review/",
          "published_at": "Tue, 27 Jan 2026 08:00:00 +0000",
          "title": "Intel’s Panther Lake Chips Aren’t Just Good—They Beat Apple's M5",
          "standfirst": "I’ve tested two new laptops powered by Panther Lake—pitting them head-to-head against laptops with Apple Silicon—and Intel has finally scored a much-needed win with the Core Ultra Series 3.",
          "content": "I’ve tested two new laptops powered by Panther Lake—pitting them head-to-head against laptops with Apple Silicon—and Intel has finally scored a much-needed win with the Core Ultra Series 3.",
          "feed_position": 21,
          "image_url": "https://media.wired.com/photos/697528429b8f104baf32f567/master/pass/panther-lake-top.JPG"
        }
      ],
      "featured_image": "https://media.wired.com/photos/697528429b8f104baf32f567/master/pass/panther-lake-top.JPG",
      "popularity_score": 2014.0618394444446
    },
    {
      "id": "cluster_69",
      "coverage": 2,
      "updated_at": "Tue, 27 Jan 2026 18:31:01 +0000",
      "title": "New Data Shows Robotaxis Competing on Price—and Speed",
      "neutral_headline": "New Data Shows Robotaxis Competing on Price—and Speed",
      "items": [
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/new-data-shows-robotaxis-competing-on-price-and-speed/",
          "published_at": "Tue, 27 Jan 2026 18:31:01 +0000",
          "title": "New Data Shows Robotaxis Competing on Price—and Speed",
          "standfirst": "Research from the ride-hail aggregator Obi finds Waymo is starting to edge up on Uber and Lyft in San Francisco. Tesla, which operates a ride-hail service with human drivers, is winning the price wars.",
          "content": "Research from the ride-hail aggregator Obi finds Waymo is starting to edge up on Uber and Lyft in San Francisco. Tesla, which operates a ride-hail service with human drivers, is winning the price wars.",
          "feed_position": 8,
          "image_url": "https://media.wired.com/photos/6977dbe2cb39a1d690c2ed10/master/pass/gear-waymo-2071908008.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/27/the-price-gap-between-waymo-and-uber-is-narrowing/",
          "published_at": "Tue, 27 Jan 2026 17:43:19 +0000",
          "title": "The price gap between Waymo and Uber is narrowing",
          "standfirst": "A trip in a Waymo robotaxi still costs more, on average, than a comparable ride in a human-driven Uber or a Lyft. But that gap is narrowing, according to new data published Tuesday by Obi, a company that aggregates real-time pricing and pickup times across multiple ride-hailing services.",
          "content": "A trip in a Waymo robotaxi still costs more, on average, than a comparable ride in a human-driven Uber or a Lyft. But that gap is narrowing, according to new data published Tuesday by Obi, a company that aggregates real-time pricing and pickup times across multiple ride-hailing services.",
          "feed_position": 14
        }
      ],
      "featured_image": "https://media.wired.com/photos/6977dbe2cb39a1d690c2ed10/master/pass/gear-waymo-2071908008.jpg",
      "popularity_score": 2007.0676727777777
    },
    {
      "id": "cluster_87",
      "coverage": 2,
      "updated_at": "Tue, 27 Jan 2026 17:41:44 +0000",
      "title": "WhatsApp introduces an advanced security mode to protect against hackers",
      "neutral_headline": "WhatsApp introduces an advanced security mode to protect against hackers",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/whatsapp-introduces-an-advanced-security-mode-to-protect-against-hackers-174144598.html",
          "published_at": "Tue, 27 Jan 2026 17:41:44 +0000",
          "title": "WhatsApp introduces an advanced security mode to protect against hackers",
          "standfirst": "Meta's WhatsApp just introduced something called Strict Account Settings, a tool \"that further protects your account from highly sophisticated cyber attacks.\" This is a one-click button in the settings that automatically initiates a series of defenses. So what does it do? It blocks media and attachments from unknown senders, disables link previews and silences calls from unknown senders. This results in a more restrictive experience, but hopefully a safer one. The company says this isn't necessarily for regular users, as conversations are already protected by end-to-end encryption. Instead, this is being pitched as a tool for \"journalists or public-facing figures\" that \"may need extreme safeguards against rare and highly sophisticated cyberattacks.\" Strict Account Settings will be rolling out globally in the coming weeks. Users will find the tool in the Privacy settings. WhatsApp is just the latest tech platform to offer enhanced security tools for high-risk users. Apple introduced Lockdown Mode back in 2022 and Android introduced its Advanced Protection Mode last year.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/whatsapp-introduces-an-advanced-security-mode-to-protect-against-hackers-174144598.html?src=rss",
          "content": "Meta's WhatsApp just introduced something called Strict Account Settings, a tool \"that further protects your account from highly sophisticated cyber attacks.\" This is a one-click button in the settings that automatically initiates a series of defenses. So what does it do? It blocks media and attachments from unknown senders, disables link previews and silences calls from unknown senders. This results in a more restrictive experience, but hopefully a safer one. The company says this isn't necessarily for regular users, as conversations are already protected by end-to-end encryption. Instead, this is being pitched as a tool for \"journalists or public-facing figures\" that \"may need extreme safeguards against rare and highly sophisticated cyberattacks.\" Strict Account Settings will be rolling out globally in the coming weeks. Users will find the tool in the Privacy settings. WhatsApp is just the latest tech platform to offer enhanced security tools for high-risk users. Apple introduced Lockdown Mode back in 2022 and Android introduced its Advanced Protection Mode last year.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/whatsapp-introduces-an-advanced-security-mode-to-protect-against-hackers-174144598.html?src=rss",
          "feed_position": 13
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/27/whatsapp-is-rolling-out-a-new-stricter-security-setting-to-protect-users-from-cyber-attacts/",
          "published_at": "Tue, 27 Jan 2026 17:24:22 +0000",
          "title": "WhatsApp is rolling out a new stricter security setting to protect users from cyberattacks",
          "standfirst": "Strict Account Settings adds restrictions like automatically blocking media and attachments from unknown senders, and silencing calls from unknown numbers.",
          "content": "Strict Account Settings adds restrictions like automatically blocking media and attachments from unknown senders, and silencing calls from unknown numbers.",
          "feed_position": 17
        }
      ],
      "popularity_score": 2006.246283888889
    },
    {
      "id": "cluster_38",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 23:28:02 +0000",
      "title": "Dozens of CDC vaccination databases have been frozen under RFK Jr.",
      "neutral_headline": "Dozens of CDC vaccination databases have been frozen under RFK Jr.",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/rfk-jr-lets-cdc-vaccination-data-rot-dozens-of-databases-frozen/",
          "published_at": "Tue, 27 Jan 2026 23:28:02 +0000",
          "title": "Dozens of CDC vaccination databases have been frozen under RFK Jr.",
          "standfirst": "Anti-vaccine Kennedy may be \"enacting a self-fulfilling prophecy,\" expert says.",
          "content": "Nearly half of the databases that public health officials at the Centers for Disease Control and Prevention were updating on a monthly basis have been frozen without notice or explanation, according to a study published in the Annals of Internal Medicine. The study—led by Janet Freilich, a law expert at Boston University, and Jeremy Jacobs, a medical professor at Vanderbilt University—examined the status of all CDC databases, finding a total of 82 that had, as of early 2025, been receiving updates at least monthly. But, of those 82, only 44 were still being regularly updated as of October 2025, with 38 (46 percent) having their updates paused without public notice or explanation. Examining the databases' content, it appeared that vaccination data was most affected by the stealth data freezes. Of the 38 outdated databases, 33 (87 percent) included data related to vaccination. In contrast, none of the 44 still-updated databases relate to vaccination. Other frozen databases included data on infectious disease burden, such as data on hospitalizations from respiratory syncytial virus (RSV).Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/GettyImages-2201503706-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/GettyImages-2201503706-1152x648.jpg",
      "popularity_score": 345.01795055555556
    },
    {
      "id": "cluster_42",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 22:34:40 +0000",
      "title": "There's a rash of scam spam coming from a real Microsoft address",
      "neutral_headline": "There's a rash of scam spam coming from a real Microsoft address",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2026/01/theres-a-rash-of-scam-spam-coming-from-a-real-microsoft-address/",
          "published_at": "Tue, 27 Jan 2026 22:34:40 +0000",
          "title": "There's a rash of scam spam coming from a real Microsoft address",
          "standfirst": "Abusing Microsoft's reputation may make scam harder to spot.",
          "content": "There are reports that a legitimate Microsoft email address—which Microsoft explicitly says customers should add to their allow list—is delivering scam spam. The emails originate from no-reply-powerbi@microsoft.com, an address tied to Power BI. The Microsoft platform provides analytics and business intelligence from various sources that can be integrated into a single dashboard. Microsoft documentation says that the address is used to send subscription emails to mail-enabled security groups. To prevent spam filters from blocking the address, the company advises users to add it to allow lists. From Microsoft, with malice According to an Ars reader, the address on Tuesday sent her an email claiming (falsely) that a $399 charge had been made to her. It provided a phone number to call to dispute the transaction. A man who answered a call asking to cancel the sale directed me to download and install a remote access application, presumably so he could then take control of my Mac or Windows machine (Linux wasn’t allowed). The email, captured in the two screenshots below, looked like this:Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-engineering-scam-call-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-engineering-scam-call-1152x648.jpg",
      "popularity_score": 336.1285061111111
    },
    {
      "id": "cluster_39",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 23:17:17 +0000",
      "title": "TikTok users “absolutely justified” for fearing MAGA makeover, experts say",
      "neutral_headline": "TikTok users “absolutely justified” for fearing MAGA makeover, experts say",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/tiktok-claimed-bugs-blocked-anti-ice-videos-epstein-mentions-experts-call-bs/",
          "published_at": "Tue, 27 Jan 2026 23:17:17 +0000",
          "title": "TikTok users “absolutely justified” for fearing MAGA makeover, experts say",
          "standfirst": "TikTok’s tech issues abound as censorship fears drive users to delete app.",
          "content": "TikTok wants users to believe that errors blocking uploads of anti-ICE videos or direct messages mentioning Jeffrey Epstein are due to technical errors—not the platform seemingly shifting to censor content critical of Donald Trump after he hand-picked the US owners who took over the app last week. However, experts say that TikTok users' censorship fears are justified, whether the bugs are to blame or not. Ioana Literat, an associate professor of technology, media, and learning at Teachers College, Columbia University, has studied TikTok's politics since the app first shot to popularity in the US in 2018. She told Ars that \"users' fears are absolutely justified\" and explained why the \"bugs\" explanation is \"insufficient.\"Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/tik-tok-maga-hat-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/tik-tok-maga-hat-1152x648.jpg",
      "popularity_score": 334.8387838888889
    },
    {
      "id": "cluster_51",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 21:15:51 +0000",
      "title": "Supreme Court to decide how 1988 videotape privacy law applies to online video",
      "neutral_headline": "Supreme Court to decide how 1988 videotape privacy law applies to online video",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/supreme-court-to-decide-how-1988-videotape-privacy-law-applies-to-online-video/",
          "published_at": "Tue, 27 Jan 2026 21:15:51 +0000",
          "title": "Supreme Court to decide how 1988 videotape privacy law applies to online video",
          "standfirst": "Salazar v. Paramount hinges on video privacy law's definition of \"consumer.\"",
          "content": "The Supreme Court is taking up a case on whether Paramount violated the 1988 Video Privacy Protection Act (VPPA) by disclosing a user's viewing history to Facebook. The case, Michael Salazar v. Paramount Global, hinges on the law's definition of the word \"consumer.\" Salazar filed a class action against Paramount in 2022, alleging that it \"violated the VPPA by disclosing his personally identifiable information to Facebook without consent,\" Salazar's petition to the Supreme Court said. Salazar had signed up for an online newsletter through 247Sports.com, a site owned by Paramount, and had to provide his email address in the process. Salazar then used 247Sports.com to view videos while logged in to his Facebook account. \"As a result, Paramount disclosed his personally identifiable information—including his Facebook ID and which videos he watched—to Facebook,\" the petition said. \"The disclosures occurred automatically because of the Facebook Pixel Paramount installed on its website. Facebook and Paramount then used this information to create and display targeted advertising, which increased their revenues.\"Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/videocassette-1152x648-1769547628.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/videocassette-1152x648-1769547628.jpg",
      "popularity_score": 322.814895
    },
    {
      "id": "cluster_52",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 21:05:17 +0000",
      "title": "A WB-57 pilot just made a heroic landing in Houston after its landing gear failed",
      "neutral_headline": "A WB-57 pilot just made a heroic landing in Houston after its landing gear failed",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/one-of-nasas-three-wb-57-aircraft-just-did-a-belly-landing-in-houston/",
          "published_at": "Tue, 27 Jan 2026 21:05:17 +0000",
          "title": "A WB-57 pilot just made a heroic landing in Houston after its landing gear failed",
          "standfirst": "\"A thorough investigation will be conducted by NASA into the cause.\"",
          "content": "One of NASA's three large WB-57 aircraft made an emergency landing at Ellington Field on Tuesday morning in southeastern Houston. Video captured by KHOU 11 television showed the aircraft touching down on the runway without its landing gear extended. The pilot then maintains control of the vehicle as it slides down the runway, slowing the aircraft through friction. The crew was not harmed, NASA spokesperson Bethany Stevens said. WB-57 landing. \"Today, a mechanical issue with one of NASA’s WB-57s resulted in a gear-up landing at Ellington Field,\" she said. \"Response to the incident is ongoing, and all crew are safe at this time. As with any incident, a thorough investigation will be conducted by NASA into the cause. NASA will transparently update the public as we gather more information.\"Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2015/11/wb5715-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2015/11/wb5715-1152x648.jpg",
      "popularity_score": 317.6387838888889
    },
    {
      "id": "cluster_67",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 18:37:32 +0000",
      "title": "LG's new subscription program charges up to £277 per month to rent a TV",
      "neutral_headline": "LG's new subscription program charges up to £277 per month to rent a TV",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/lgs-new-subscription-program-charges-up-to-277-per-month-to-rent-a-tv/",
          "published_at": "Tue, 27 Jan 2026 18:37:32 +0000",
          "title": "LG's new subscription program charges up to £277 per month to rent a TV",
          "standfirst": "Significant discounts come with committing to 1- to 3-year rental periods.",
          "content": "LG has launched a subscription program in the UK that allows people to make monthly payments in order to rent LG TVs, soundbars, monitors, and speakers. LG Flex customers can sign up for one-, two-, or three-year subscriptions to get lower monthly payments. “At the end of your subscription, you can apply for a free upgrade, keep paying monthly, or return your device,” the LG Flex website says. Subscribers will have to pay a £50 (about $69) fee for a “full removal service,” including dismounting and packaging, of rental TVs.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/TV_OLED83B5PUA_brilliant-lg-oled-picture_features_900x600.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/TV_OLED83B5PUA_brilliant-lg-oled-picture_features_900x600.jpg",
      "popularity_score": 290.17628388888886
    },
    {
      "id": "cluster_76",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 18:07:46 +0000",
      "title": "“IG is a drug”: Internal messages may doom Meta at social media addiction trial",
      "neutral_headline": "“IG is a drug”: Internal messages may doom Meta at social media addiction trial",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/tiktok-settles-hours-before-landmark-social-media-addiction-trial-starts/",
          "published_at": "Tue, 27 Jan 2026 18:07:46 +0000",
          "title": "“IG is a drug”: Internal messages may doom Meta at social media addiction trial",
          "standfirst": "A loss could cost social media companies billions and force changes on platforms.",
          "content": "Anxiety, depression, eating disorders, and death. These can be the consequences for vulnerable kids who get addicted to social media, according to more than 1,000 personal injury lawsuits that seek to punish Meta and other platforms for allegedly prioritizing profits while downplaying child safety risks for years. Social media companies have faced scrutiny before, with congressional hearings forcing CEOs to apologize, but until now, they've never had to convince a jury that they aren't liable for harming kids. This week, the first high-profile lawsuit—considered a \"bellwether\" case that could set meaningful precedent in the hundreds of other complaints—goes to trial. That lawsuit documents the case of a 19-year-old, K.G.M, who hopes the jury will agree that Meta and YouTube caused psychological harm by designing features like infinite scroll and autoplay to push her down a path that she alleged triggered depression, anxiety, self-harm, and suicidality.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1967879006-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1967879006-1024x648.jpg",
      "popularity_score": 279.6801727777778
    },
    {
      "id": "cluster_92",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 17:00:58 +0000",
      "title": "AI Overviews gets upgraded to Gemini 3 with a dash of AI Mode",
      "neutral_headline": "AI Overviews gets upgraded to Gemini 3 with a dash of AI Mode",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/01/ai-overviews-gets-upgraded-to-gemini-3-with-a-dash-of-ai-mode/",
          "published_at": "Tue, 27 Jan 2026 17:00:58 +0000",
          "title": "AI Overviews gets upgraded to Gemini 3 with a dash of AI Mode",
          "standfirst": "AI Overviews may get it right more often with the move to Gemini 3.",
          "content": "It can be hard sometimes to keep up with the deluge of generative AI in Google products. Even if you try to avoid it all, there are some features that still manage to get in your face. Case in point: AI Overviews. This AI-powered search experience has a reputation for getting things wrong, but you may notice some improvements soon. Google says AI Overviews is being upgraded to the latest Gemini 3 models with a more conversational bent. In just the last year, Google has radically expanded the number of searches on which you get an AI Overview at the top. Today, the chatbot will almost always have an answer for your query, which has relied mostly on models in Google's Gemini 2.5 family. There was nothing wrong with Gemini 2.5 as generative AI models go, but Gemini 3 is a little better by every metric. There are, of course, multiple versions of Gemini 3, and Google doesn't like to be specific about which ones appear in your searches. What Google does say is that AI Overviews chooses the right model for the job. So if you're searching for something simple for which there are a lot of valid sources, AI Overviews may manifest something like Gemini 3 Flash without running through a ton of reasoning tokens. For a complex \"long tail\" query, it could step up the thinking or move to Gemini 3 Pro (for paying subscribers).Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-1152x648.png",
      "popularity_score": 273.56683944444444
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 17:37:58 +0000",
      "title": "Australian plumber is a YouTube sensation",
      "neutral_headline": "Australian plumber is a YouTube sensation",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/australian-plumber-is-a-youtube-sensation/",
          "published_at": "Tue, 27 Jan 2026 17:37:58 +0000",
          "title": "Australian plumber is a YouTube sensation",
          "standfirst": "Bruce of Drain Cleaning Australia wants everyone to share his deep abiding love for a free-flowing drain.",
          "content": "Warning: Unclogging a restaurant's grease trap is not for the faint of heart. Large swathes of the US were blanketed in snow and ice over the weekend, and what better way to spend a snow day than going down a YouTube rabbit hole? Everyone has their favorite oddity: ASMR, jazzy pop song covers, cooking channels, or what have you. But DIY enthusiasts in particular are missing out if they're not watching Drain Cleaning Australia, featuring an Australian plumber known only as Bruce as he goes about his daily business of shooting high-powered water jets into stubborn clogged drainage systems. It's \"the YouTube channel you never knew you needed.\" And it's done so well that he's now launched a second channel, Bruce the Plumber. I stumbled upon the Drain Cleaning Australia channel via Amy Poehler's Good Hang podcast episode with Kate McKinnon, who is a big fan and does a dead-on delivery of Bruce's trademark lines (\"You little rippah!\"). Bruce never appears in his videos, apart from his hands and the occasional shadow as he films various challenging jobs with his intrepid smartphone. He seems to have struck a good balance between online popularity and protecting his personal privacy. (Bruce did not respond to our interview request. It's okay, mate, we know all those drains Down Under aren't going to unclog themselves.) Armed with his trusty collection of jet nozzles and \"Mister Plungey,\" Bruce has removed all manner of nasty things from drains over the years: masses of human hair from shower drains; tree roots; plastic bags and other refuse that somehow found their way into drainage systems; and the less said about the many clogged toilets, the better.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/draincleaning1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/draincleaning1-1152x648.jpg",
      "popularity_score": 266.1835061111111
    },
    {
      "id": "cluster_100",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 16:16:32 +0000",
      "title": "Volvo invented the three-point seat belt 67 years ago; now it has improved it",
      "neutral_headline": "Volvo invented the three-point seat belt 67 years ago; now it has improved it",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/how-volvos-new-adaptive-seat-belts-will-reduce-injuries-during-a-crash/",
          "published_at": "Tue, 27 Jan 2026 16:16:32 +0000",
          "title": "Volvo invented the three-point seat belt 67 years ago; now it has improved it",
          "standfirst": "The EX60 senses a passenger's size and weight, determining how much force to use.",
          "content": "Volvo provided flights from Austin, Texas, to Stockholm, Sweden, and accommodation so Ars could learn about its new seatbelt. Ars does not accept paid editorial content. With the launch of its all-new, all-electric EX60, Volvo has put lessons learned from the EX30 and EX90 to use. The EX60 is built on Volvo’s new SPA3 platform, made only for battery-electric vehicles. It boasts up to 400 miles (643 km) of range, with fast-charging capabilities Volvo says add 173 miles (278 km) in 10 minutes. Mega casting reduces the number of parts of the rear floor from 100-plus to one piece crafted of aluminum alloy, reducing complexities and weld points. Inside the cabin, however, the real achievement is Volvo’s new multi-adaptive safety belt. Volvo has a history with the modern three-point safety belt, which was perfected by in-house engineer Nils Bohlin in 1959 before the patent was shared with the world. Today at the Volvo Cars Safety Center lab, at least one brand-new Volvo is crashed every day in the name of science. The goal: to test not just how well its vehicles are protecting passengers but what the next frontier is in safety technology. Senior Safety Technical Leader Mikael Ljung Aust is a driving behavior specialist with 20 years under his belt at Volvo. He says it’s easy to optimize testing toward one person or one test point and come up with a good result. However, both from the behavioral perspective and from physics, people are different. What’s not different, he points out, is how people drive.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/436-F-Seat-With-B-Pillar-Final-short-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/436-F-Seat-With-B-Pillar-Final-short-1152x648.jpg",
      "popularity_score": 247.8262838888889
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 20:18:02 +0000",
      "title": "Apple's AirTag 2 is easier to find thanks to new chip",
      "neutral_headline": "Apple's AirTag 2 is easier to find thanks to new chip",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/apple-introduces-new-airtag-with-better-range-and-a-louder-speaker/",
          "published_at": "Mon, 26 Jan 2026 20:18:02 +0000",
          "title": "Apple's AirTag 2 is easier to find thanks to new chip",
          "standfirst": "This is the first major upgrade since Apple introduced AirTags five years ago.",
          "content": "Apple is introducing a new version of its AirTag tracking device—simply dubbed \"the new AirTag\"—and claims it offers substantial improvements thanks to a new Bluetooth chip. The original AirTag came out five years ago now, and it became popular in a variety of contexts. There were some problems, though—there was real concern about unwanted tracking and stalking with the devices, based on real stories of it being used for that. The company gradually introduced new features and protections against that, getting it to a much better place. This new version is focused on making the device more effective in general. Thanks to the inclusion of the second-generation Ultra Wideband chip (the same one found in other recently released Apple devices like the iPhone 17), Apple says the new AirTag can work with the Precision Finding feature in the Find My app to direct users to the AirTag (and whatever lost item it's stored with or attached to) from up to 50 percent farther away.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-2-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-2-1152x648.png",
      "popularity_score": 160
    },
    {
      "id": "cluster_102",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 15:49:53 +0000",
      "title": "Apple patches ancient iOS versions to keep iMessage, FaceTime, other services working",
      "neutral_headline": "Apple patches ancient iOS versions to keep iMessage, FaceTime, other services working",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/apple-patches-ancient-ios-versions-to-keep-imessage-facetime-other-services-working/",
          "published_at": "Tue, 27 Jan 2026 15:49:53 +0000",
          "title": "Apple patches ancient iOS versions to keep iMessage, FaceTime, other services working",
          "standfirst": "Apple renews certificates for old iOS versions to keep the lights on longer.",
          "content": "When Apple stops supporting older iPhones and iPads with the latest version of iOS or iPadOS, it usually isn't the end of the line—Apple keeps releasing new security-only patches for those devices for another year or two, keeping them usable while their hardware is still reasonably capable. Once those updates dry up, it's rare for Apple to revisit those older operating systems, but the company does sometimes make exceptions. That was the case yesterday, when the company released a batch of updates for long-retired iOS and iPadOS versions that otherwise hadn't seen a new patch in months or years. Those updates include iOS 12.5.8, available for devices as old as 2013's iPhone 5S and 2014's iPhone 6; iOS 15.8.6, available for devices like the iPhone 6S, iPhone 7, and iPad Air 2; and iOS 16.7.13, available for devices like the iPhone 8 and iPhone X. Both iOS 15 and iOS 16 were last patched in mid-2025, but iOS 12's last patch was released in January 2023.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/IMG_0205-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/IMG_0205-1152x648.jpg",
      "popularity_score": 149.38211722222223
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 23:05:17 +0000",
      "title": "OpenAI spills technical details about how its AI coding agent works",
      "neutral_headline": "OpenAI spills technical details about how its AI coding agent works",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/openai-spills-technical-details-about-how-its-ai-coding-agent-works/",
          "published_at": "Mon, 26 Jan 2026 23:05:17 +0000",
          "title": "OpenAI spills technical details about how its AI coding agent works",
          "standfirst": "Unusually detailed post explains how OpenAI handles the Codex agent loop.",
          "content": "On Friday, OpenAI engineer Michael Bolin published a detailed technical breakdown of how the company's Codex CLI coding agent works internally, offering developers insight into AI coding tools that can write code, run tests, and fix bugs with human supervision. It complements our article in December on how AI agents work by filling in technical details on how OpenAI implements its \"agentic loop.\" AI coding agents are having something of a \"ChatGPT moment,\" where Claude Code with Opus 4.5 and Codex with GPT-5.2 have reached a new level of usefulness for rapidly coding up prototypes, interfaces, and churning out boilerplate code. The timing of OpenAI's post details the design philosophy behind Codex just as AI agents are becoming more practical tools for everyday work. These tools aren't perfect and remain controversial for some software developers. While OpenAI has previously told Ars Technica that it uses Codex as a coding tool to help develop the Codex product itself, we also discovered, through hands-on experience, that these tools can be astonishingly fast at simple tasks but remain brittle beyond their training data and require human oversight for production work. The rough framework of a project tends to come fast and feels magical, but filling in the details involves tedious debugging and workarounds for limitations the agent cannot overcome on its own.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/coding_robots_agents-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/coding_robots_agents-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 20:13:47 +0000",
      "title": "“Wildly irresponsible”: DOT's use of AI to draft safety rules sparks concerns",
      "neutral_headline": "“Wildly irresponsible”: DOT's use of AI to draft safety rules sparks concerns",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/wildly-irresponsible-dots-use-of-ai-to-draft-safety-rules-sparks-concerns/",
          "published_at": "Mon, 26 Jan 2026 20:13:47 +0000",
          "title": "“Wildly irresponsible”: DOT's use of AI to draft safety rules sparks concerns",
          "standfirst": "Staffers warn DOT's use of Gemini to draft rules could cause injuries and deaths.",
          "content": "The US Department of Transportation apparently thinks it's a good idea to use artificial intelligence to draft rules impacting the safety of airplanes, cars, and pipelines, a ProPublica investigation revealed Monday. It could be a problem if DOT becomes the first agency to use AI to draft rules, ProPublica pointed out, since AI is known to confidently get things wrong and hallucinate fabricated information. Staffers fear that any failure to catch AI errors could result in flawed laws, leading to lawsuits, injuries, or even deaths in the transportation system. But the DOT's top lawyer, Gregory Zerzan, isn't worried about that, December meeting notes revealed, because the point isn't for AI to be perfect. It's for AI to help speed up the rulemaking process, so that rules that take weeks or months to draft can instead be written within 30 days. According to Zerzan, DOT's preferred tool, Google Gemini, can draft rules in under 30 minutes.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1438737819-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1438737819-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_108",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 14:16:32 +0000",
      "title": "As data from space spikes, an innovative ground station company seeks to cash in",
      "neutral_headline": "As data from space spikes, an innovative ground station company seeks to cash in",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/as-data-from-space-spikes-an-innovative-ground-station-company-seeks-to-cash-in/",
          "published_at": "Tue, 27 Jan 2026 14:16:32 +0000",
          "title": "As data from space spikes, an innovative ground station company seeks to cash in",
          "standfirst": "\"That's why we're here, that's why we're building what we're building.\"",
          "content": "A company that seeks to disrupt the way in which data from space is received and transmitted has found some key investors and customers. On Tuesday morning Northwood Space announced that it has closed a $100 million Series B round of funding to support a rapid ramp-up in the deployment of its phased-array radar system, known as Portal. The company also said it has received a $49.8 million contract from the US Space Force to augment the Satellite Control Network, which provides telemetry and tracking for the military's satellites. \"We made our last fundraise announcement in April of 2025, so less than a year, but there's been a lot of activity and progress on the Northwood side that reflects the importance of ground as an enabler for pushing forward more capable missions on shorter timelines,\" said Bridgit Mendler, co-founder and CEO of Northwood, during a media roundtable. \"That's why we're here, that's why we're building what we're building, is because we believe that there's a lot of important capability in space that needs to be built faster, and the way to do that is through a vertically integrated ground network.\"Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/2405e3f23bdc3b88ca609d0a228cb64fe0761063-3840x2160-1.avif"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/2405e3f23bdc3b88ca609d0a228cb64fe0761063-3840x2160-1.avif",
      "popularity_score": 143.8262838888889
    },
    {
      "id": "cluster_133",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 21:02:26 +0000",
      "title": "Why has Microsoft been routing example.com traffic to a company in Japan?",
      "neutral_headline": "Why has Microsoft been routing example.com traffic to a company in Japan",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2026/01/odd-anomaly-caused-microsofts-network-to-mishandle-example-com-traffic/",
          "published_at": "Mon, 26 Jan 2026 21:02:26 +0000",
          "title": "Why has Microsoft been routing example.com traffic to a company in Japan?",
          "standfirst": "Company's autodiscover caused users' test credentials to be sent outside Microsoft networks.",
          "content": "From the Department of Bizarre Anomalies: Microsoft has suppressed an unexplained anomaly on its network that was routing traffic destined to example.com—a domain reserved for testing purposes—to a maker of electronics cables located in Japan. Under the RFC2606—an official standard maintained by the Internet Engineering Task Force—example.com isn't obtainable by any party. Instead it resolves to IP addresses assigned to Internet Assiged Names Authority. The designation is intended to prevent third parties from being bombarded with traffic when developers, penetration testers, and others need a domain for testing or discussing technical issues. Instead of naming an Internet-routable domain, they are to choose example.com or two others, example.net and example.org. Misconfig gone, but is it fixed? Output from the terminal command cURL shows that devices inside Azure and other Microsoft networks have been routing some traffic to subdomains of sei.co.jp, a domain belonging to Sumitomo Electric. Most of the resulting text is exactly what’s expected. The exception is the JSON-based response. Here’s the JSON output from Friday:Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/08/error-message-1000x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/08/error-message-1000x648.jpg",
      "popularity_score": 140
    },
    {
      "id": "cluster_103",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 15:42:04 +0000",
      "title": "Trade wars muzzle allied talks on Trump's Golden Dome missile shield",
      "neutral_headline": "Trade wars muzzle allied talks on Trump's Golden Dome missile shield",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/trade-wars-muzzle-allied-talks-on-trumps-golden-dome-missile-shield/",
          "published_at": "Tue, 27 Jan 2026 15:42:04 +0000",
          "title": "Trade wars muzzle allied talks on Trump's Golden Dome missile shield",
          "standfirst": "“International partners, I have not been allowed to talk to yet because of the trade wars.\"",
          "content": "Gen. Michael Guetlein, the senior officer in charge of the US military's planned Golden Dome missile defense shield, has laid out an audacious schedule for deploying a network of space-based sensors and interceptors by the end of President Donald Trump's term in the White House. The three-year timeline is aggressive, with little margin for error in the event of budget or technological setbacks. The shield is designed to defend the US homeland against a range of long-range weapons, including intercontinental ballistic missiles (ICBMs), cruise missiles, and newer threats like hypersonic weapons and drones. \"By the summer of '28, we will be able to defend the entire nation against ballistic missiles, as well as other generation aerial threats, and we will continue to grow that architecture through 2035,\" Guetlein said Friday in a presentation to representatives from the US defense industry.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2216141394-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2216141394-1152x648.jpg",
      "popularity_score": 137.25183944444444
    },
    {
      "id": "cluster_105",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 15:17:13 +0000",
      "title": "Why NASA, IMSA, and tech companies are teaming up on tech transfer",
      "neutral_headline": "Why NASA, IMSA, and tech companies are teaming up on tech transfer",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/why-nasa-imsa-and-tech-companies-are-teaming-up-on-tech-transfer/",
          "published_at": "Tue, 27 Jan 2026 15:17:13 +0000",
          "title": "Why NASA, IMSA, and tech companies are teaming up on tech transfer",
          "standfirst": "IMSA Labs will use the vast amount of race car data collected during a race to improve simulations.",
          "content": "IMSA provided accommodation so Ars could attend its symposium and the Rolex 24. Ars does not accept paid editorial content. DAYTONA BEACH, Fla.—The annual 24-hour race that kicks off the American racing season took place this past weekend at Daytona International Speedway. Each year, the crowd gets bigger and bigger, drawn in large part by the hybrid prototypes that contest the GTP class for overall victory. After Formula 1, these are some of the most complex, sophisticated race cars ever to turn a wheel—and it doesn't hurt that they look extremely cool, too. But yet again, endurance racing wants to offer more than just entertainment. A large number of automotive technologies or safety features that we mostly take for granted today made their way into road cars from the race track. Seatbelts, rear-view mirrors, turbocharged engines, aerodynamics, direct-injection engines, dual-clutch gearboxes, and more owe their existence to competition. Although direct examples of racing technology transfer in the mid-21st century seem less common than the intangible benefits gained when a bunch of motorsports-trained engineers have lunch every day with their road car colleagues. That is starting to change, though, and now the domain is in simulation. Vast amounts of data are generated during the course of a race—each of the 11 GTP cars that raced at Daytona collects 1,600 different channels of data from onboard sensors, with nearly as many on the GTD machines that are based on road-going cars like Porsche's 911 or Chevrolet's Corvette. With 60 cars running for 24 hours—and that's just the first race of the year—that's a heck of a lot of high-quality data being generated, and now IMSA wants to leverage that to help automotive and technology companies develop better simulation tools, with the creation of IMSA Labs.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2257524943-1152x648-1769523242.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2257524943-1152x648-1769523242.jpg",
      "popularity_score": 136.83767277777778
    },
    {
      "id": "cluster_107",
      "coverage": 1,
      "updated_at": "Tue, 27 Jan 2026 14:48:01 +0000",
      "title": "Meet the mysterious electrides",
      "neutral_headline": "Meet the mysterious electrides",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/meet-the-mysterious-electrides/",
          "published_at": "Tue, 27 Jan 2026 14:48:01 +0000",
          "title": "Meet the mysterious electrides",
          "standfirst": "These chemical oddities may explain why Earth seems to be deficient in certain elements.",
          "content": "For close to a century, geoscientists have pondered a mystery: Where did Earth’s lighter elements go? Compared to amounts in the Sun and in some meteorites, Earth has less hydrogen, carbon, nitrogen, and sulfur, as well as noble gases like helium—in some cases, more than 99 percent less. Some of the disparity is explained by losses to the solar system as our planet formed. But researchers have long suspected that something else was going on too. Recently, a team of scientists reported a possible explanation—that the elements are hiding deep in the solid inner core of Earth. At its super-high pressure—360 gigapascals, 3.6 million times atmospheric pressure—the iron there behaves strangely, becoming an electride: a little-known form of the metal that can suck up lighter elements.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/earthcore-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/earthcore-1152x648.jpg",
      "popularity_score": 133.3510061111111
    },
    {
      "id": "cluster_132",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 21:31:13 +0000",
      "title": "Doctors face-palm as RFK Jr.’s top vaccine advisor questions need for polio shot",
      "neutral_headline": "Doctors face-palm as RFK Jr.’s top vaccine advisor questions need for polio shot",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/do-we-really-need-polio-shots-deep-thoughts-by-rfk-jr-advisor-get-dragged/",
          "published_at": "Mon, 26 Jan 2026 21:31:13 +0000",
          "title": "Doctors face-palm as RFK Jr.’s top vaccine advisor questions need for polio shot",
          "standfirst": "Kirk Milhoan's comments come as federal vaccine policy slides to insignificance.",
          "content": "The chair of a federal vaccine advisory panel under anti-vaccine Health Secretary Robert F. Kennedy Jr. made his stance clear on vaccines in a podcast last week—and that stance was so alarming that the American Medical Association was compelled to respond with a scathing statement. Kirk Milhoan, who was named chair of the Advisory Committee on Immunization Practices for the Centers for Disease Control and Prevention in December, appeared on the aptly named podcast \"Why Should I Trust You.\" In the hour-long interview, Milhoan made a wide range of comments that have concerned medical experts and raised eyebrows. Early into the discussion, Milhoan, a pediatric cardiologist, declared, \"I don't like established science,\" and that \"science is what I observe.\" He lambasted the evidence-based methodology that previous ACIP panels used to carefully and transparently craft vaccine policy.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2235571142-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2235571142-1152x648.jpg",
      "popularity_score": 133
    }
  ]
}