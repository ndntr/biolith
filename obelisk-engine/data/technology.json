{
  "updated_at": "2025-10-15T03:36:38.062Z",
  "clusters": [
    {
      "id": "cluster_9",
      "coverage": 3,
      "updated_at": "Tue, 14 Oct 2025 19:15:01 -0400",
      "title": "Samsung schedules a \"Worlds Wide Open\" Galaxy event on October 21 at 10pm ET, where it will provide more information about its Project Moohan headset (Jay Peters/The Verge)",
      "neutral_headline": "Samsung to reveal details of Project Moohan headset",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251014/p40#a251014p40",
          "published_at": "Tue, 14 Oct 2025 19:15:01 -0400",
          "title": "Samsung schedules a \"Worlds Wide Open\" Galaxy event on October 21 at 10pm ET, where it will provide more information about its Project Moohan headset (Jay Peters/The Verge)",
          "standfirst": "Jay Peters / The Verge: Samsung schedules a &ldquo;Worlds Wide Open&rdquo; Galaxy event on October 21 at 10pm ET, where it will provide more information about its Project Moohan headset &mdash; It's nearly time to learn a lot more about the Project Moohan headset. &hellip; Samsung is finally about to reveal more details &hellip;",
          "content": "Jay Peters / The Verge: Samsung schedules a &ldquo;Worlds Wide Open&rdquo; Galaxy event on October 21 at 10pm ET, where it will provide more information about its Project Moohan headset &mdash; It's nearly time to learn a lot more about the Project Moohan headset. &hellip; Samsung is finally about to reveal more details &hellip;",
          "feed_position": 6,
          "image_url": "http://www.techmeme.com/251014/i40.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/799607/samsung-galaxy-event-project-moohan-android-xr-event-date-worlds-wide-open",
          "published_at": "2025-10-14T19:00:51-04:00",
          "title": "Samsung officially teases Moohan headset launch for next week",
          "standfirst": "Samsung is finally about to reveal more details about its Project Moohan mixed reality headset. The company just announced a new “Worlds Wide Open” Galaxy event that will take place on October 21st at 10PM ET, where it’s promising to reveal details about the device. The headset will run on Android XR, a new mixed [&#8230;]",
          "content": "Samsung is finally about to reveal more details about its Project Moohan mixed reality headset. The company just announced a new “Worlds Wide Open” Galaxy event that will take place on October 21st at 10PM ET, where it’s promising to reveal details about the device. The headset will run on Android XR, a new mixed reality platform developed by Samsung, Google, and Qualcomm, and Samsung says that it is “designed to scale across form factors, bringing AI to the center of immersive, everyday experiences.” My colleague Victoria Song initially got to try the headset and Android XR in late 2024, and nearly a year later, it seems Samsung is ready for the headset’s full launch. “Project Moohan is the groundbreaking first product built for the open and scalable Android XR platform, and it seamlessly blends everyday utility with immersive new experiences,” Samsung says. “This is where the true potential of XR comes alive, unlocking a whole new dimension of possibilities.” The event is being announced as Apple is reportedly close to launching a new version of its Vision Pro headset that’s powered by a faster chip. A headset that looks to be a new Vision Pro has also appeared in FCC filings. But Apple may be starting to look beyond headsets toward a new type of product; it has apparently sidelined work on a lighter version of the Vision Pro to prioritize development on smart glasses instead. Update, October 14th: Added details from Samsung.",
          "feed_position": 0
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/samsung-will-introduce-its-android-xr-headset-at-a-galaxy-event-on-october-21-230000605.html",
          "published_at": "Tue, 14 Oct 2025 23:00:00 +0000",
          "title": "Samsung will introduce its Android XR headset at a Galaxy event on October 21",
          "standfirst": "Samsung is back with another event this fall, which it has dubbed Worlds Wide Open. The company said that it will use this opportunity to officially unveil its Android XR headset, internally known as Project Moohan. The livestreamed event will take place on Tuesday, October 21 at 10PM ET and you can watch either on Samsung's website or on its YouTube channel. It's possible that Samsung always anticipated having an event next week, but it's also possible that the company's hand was forced after a big leak last week disclosed several notable details about Project Moohan. According to the leaks, the headset's official name will be Samsung Galaxy XR and it is the first commercial product to leverage the Android XR platform for augmented reality. We knew Samsung was aiming to release this headset sometime this year, so it's very likely we'll learn both the release date and the price during Worlds Wide Open. This article originally appeared on Engadget at https://www.engadget.com/samsung-will-introduce-its-android-xr-headset-at-a-galaxy-event-on-october-21-230000605.html?src=rss",
          "content": "Samsung is back with another event this fall, which it has dubbed Worlds Wide Open. The company said that it will use this opportunity to officially unveil its Android XR headset, internally known as Project Moohan. The livestreamed event will take place on Tuesday, October 21 at 10PM ET and you can watch either on Samsung's website or on its YouTube channel. It's possible that Samsung always anticipated having an event next week, but it's also possible that the company's hand was forced after a big leak last week disclosed several notable details about Project Moohan. According to the leaks, the headset's official name will be Samsung Galaxy XR and it is the first commercial product to leverage the Android XR platform for augmented reality. We knew Samsung was aiming to release this headset sometime this year, so it's very likely we'll learn both the release date and the price during Worlds Wide Open. This article originally appeared on Engadget at https://www.engadget.com/samsung-will-introduce-its-android-xr-headset-at-a-galaxy-event-on-october-21-230000605.html?src=rss",
          "feed_position": 0
        }
      ],
      "featured_image": "http://www.techmeme.com/251014/i40.jpg",
      "popularity_score": 3015.639705,
      "ai_summary": [
        "Samsung will host a \"Worlds Wide Open\" event on October 21 at 10 PM ET.",
        "The event will provide more information about the Project Moohan mixed reality headset.",
        "The headset is expected to run on Android XR, a new mixed reality platform.",
        "Leaks suggest the headset's official name will be Samsung Galaxy XR.",
        "The event may reveal the release date and price of the new headset."
      ]
    },
    {
      "id": "cluster_20",
      "coverage": 3,
      "updated_at": "Tue, 14 Oct 2025 21:40:00 +0000",
      "title": "A New Attack Lets Hackers Steal 2-Factor Authentication Codes From Android Phones",
      "neutral_headline": "Android exploit steals 2FA codes and private messages",
      "items": [
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/a-new-attack-lets-hackers-steal-2-factor-authentication-codes-from-android-phones/",
          "published_at": "Tue, 14 Oct 2025 21:40:00 +0000",
          "title": "A New Attack Lets Hackers Steal 2-Factor Authentication Codes From Android Phones",
          "standfirst": "The malicious app required to make a “Pixnapping” attack work requires no permissions.",
          "content": "The malicious app required to make a “Pixnapping” attack work requires no permissions.",
          "feed_position": 1,
          "image_url": "https://media.wired.com/photos/68eea04bb966a95f54c9f532/master/pass/GettyImages-1816802439.jpg"
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/this-new-android-exploit-can-steal-everything-on-your-screen-even-2fa-codes/",
          "published_at": "Tue, 14 Oct 2025 17:46:00 GMT",
          "title": "This new Android exploit can steal everything on your screen - even 2FA codes",
          "standfirst": "Pixnapping begins when a victim unknowingly installs a malicious app on their Google or Samsung phone.",
          "content": "Pixnapping begins when a victim unknowingly installs a malicious app on their Google or Samsung phone.",
          "feed_position": 17
        },
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/no-fix-yet-for-attack-that-lets-hackers-pluck-2fa-codes-from-android-phones/",
          "published_at": "Mon, 13 Oct 2025 21:36:35 +0000",
          "title": "Hackers can steal 2FA codes and private messages from Android phones",
          "standfirst": "Malicious app required to make \"Pixnapping\" attack work requires no permissions.",
          "content": "Android devices are vulnerable to a new attack that can covertly steal two-factor authentication codes, location timelines, and other private data in less than 30 seconds. The new attack, named Pixnapping by the team of academic researchers who devised it, requires a victim to first install a malicious app on an Android phone or tablet. The app, which requires no system permissions, can then effectively read data that any other installed app displays on the screen. Pixnapping has been demonstrated on Google Pixel phones and the Samsung Galaxy S25 phone and likely could be modified to work on other models with additional work. Google released mitigations last month, but the researchers said a modified version of the attack works even when the update is installed. Like taking a screenshot Pixnapping attacks begin with the malicious app invoking Android programming interfaces that cause the authenticator or other targeted apps to send sensitive information to the device screen. The malicious app then runs graphical operations on individual pixels of interest to the attacker. Pixnapping then exploits a side channel that allows the malicious app to map the pixels at those coordinates to letters, numbers, or shapes.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/01/008-family-galaxy-s25ultra-titaniumsilverblue-s25plus-navy-s25-icyblue-1152x648.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/68eea04bb966a95f54c9f532/master/pass/GettyImages-1816802439.jpg",
      "popularity_score": 3014.056093888889,
      "ai_summary": [
        "A new \"Pixnapping\" attack can steal data from Android phones.",
        "The malicious app needed for the attack requires no special permissions.",
        "Victims unknowingly install the malicious app on their devices.",
        "The exploit can steal everything on the screen, including 2FA codes.",
        "The attack can compromise sensitive information on affected devices."
      ]
    },
    {
      "id": "cluster_13",
      "coverage": 2,
      "updated_at": "Tue, 14 Oct 2025 22:27:00 GMT",
      "title": "EAGLET boosts AI agent performance on longer-horizon tasks by generating custom plans",
      "neutral_headline": "EAGLET improves AI agent performance on long tasks",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/eaglet-boosts-ai-agent-performance-on-longer-horizon-tasks-by-generating",
          "published_at": "Tue, 14 Oct 2025 22:27:00 GMT",
          "title": "EAGLET boosts AI agent performance on longer-horizon tasks by generating custom plans",
          "standfirst": "2025 was supposed to be the year of \"AI agents,\" according to Nvidia CEO Jensen Huang, and other AI industry personnel. And it has been, in many ways, with numerous leading AI model providers such as OpenAI, Google, and even Chinese competitors like Alibaba releasing fine-tuned AI models or applications designed to focus on a narrow set of tasks, such as web search and report writing. But one big hurdle to a future of highly performant, reliable, AI agents remains: getting them to stay on task when the task extends over a number of steps. Third-party benchmark tests show even the most powerful AI models experience higher failure rates the more steps they take to complete a task, and the longer time they spend on it (exceeding hours). A new academic framework called EAGLET proposes a practical and efficient method to improve long-horizon task performance in LLM-based agents — without the need for manual data labeling or retraining. Developed by researchers from Tsinghua University, Peking University, DeepLang AI, and the University of Illinois Urbana-Champaign, EAGLET offers a \"global planner\" that can be integrated into existing agent workflows to reduce hallucinations and improve task efficiency.EAGLET is a fine-tuned language model that interprets task instructions — typically provided as prompts by the user or the agent&#x27;s operating environment — and generates a high-level plan for the agent (powered by its own LLM). It does not intervene during execution, but its up-front guidance helps reduce planning errors and improve task completion rates.Addressing the Planning Problem in Long-Horizon AgentsMany LLM-based agents struggle with long-horizon tasks because they rely on reactive, step-by-step reasoning. This approach often leads to trial-and-error behavior, planning hallucinations, and inefficient trajectories. EAGLET tackles this limitation by introducing a global planning module that works alongside the executor agent. Instead of blending planning and action generation in a single model, EAGLET separates them, enabling more coherent, task-level strategies.A Two-Stage Training Pipeline with No Human AnnotationsEAGLET’s planner is trained using a two-stage process that requires no human-written plans or annotations. The first stage involves generating synthetic plans with high-capability LLMs, such as GPT-5 and DeepSeek-V3.1-Think. These plans are then filtered using a novel strategy called homologous consensus filtering, which retains only those that improve task performance for both expert and novice executor agents. In the second stage, a rule-based reinforcement learning process further refines the planner, using a custom-designed reward function to assess how much each plan helps multiple agents succeed.Introducing the Executor Capability Gain Reward (ECGR)One of EAGLET’s key innovations is the Executor Capability Gain Reward (ECGR). This reward measures the value of a generated plan by checking whether it helps both high- and low-capability agents complete tasks more successfully and with fewer steps. It also includes a decay factor to favor shorter, more efficient task trajectories. This approach avoids over-rewarding plans that are only useful to already-competent agents and promotes more generalizable planning guidance.Compatible with Existing Agents and ModelsThe EAGLET planner is designed to be modular and \"plug-and-play,\" meaning it can be inserted into existing agent pipelines without requiring executor retraining. In evaluations, the planner boosted performance across a variety of foundational models, including GPT-4.1, GPT-5, Llama-3.1, and Qwen2.5. It also proved effective regardless of prompting strategy, working well with standard ReAct-style prompts as well as approaches like Reflexion.State-of-the-Art Performance Across BenchmarksEAGLET was tested on three widely used benchmarks for long-horizon agent tasks: ScienceWorld, which simulates scientific experiments in a text-based lab environment; ALFWorld, which tasks agents with completing household activities through natural language in a simulated home setting; and WebShop, which evaluates goal-driven behavior in a realistic online shopping interface.Across all three, executor agents equipped with EAGLET outperformed their non-planning counterparts and other planning baselines, including MPO and KnowAgent. In experiments with the open source Llama-3.1-8B-Instruct model, EAGLET boosted average performance from 39.5 to 59.4, a +19.9 point gain across tasks. On ScienceWorld unseen scenarios, it raised performance from 42.2 to 61.6. In ALFWorld seen scenarios, EAGLET improved outcomes from 22.9 to 54.3, a more than 2.3× increase in performance.Even stronger gains were seen with more capable models. For instance, GPT-4.1 improved from 75.5 to 82.2 average score with EAGLET, and GPT-5 rose from 84.5 to 88.1, despite already being strong performers. In some benchmarks, performance gains were as high as +11.8 points, such as when combining EAGLET with the ETO executor method on ALFWorld unseen tasks.Compared to other planning baselines like MPO, EAGLET consistently delivered higher task completion rates. For example, on ALFWorld unseen tasks with GPT-4.1, MPO achieved 79.1, while EAGLET scored 83.6—a +4.5 point advantage.Additionally, the paper reports that agents using EAGLET complete tasks in fewer steps on average. With GPT-4.1 as executor, average step count dropped from 13.0 (no planner) to 11.1 (EAGLET). With GPT-5, it dropped from 11.4 to 9.4, supporting the claim of improved execution efficiency.Efficiency Gains in Training and ExecutionCompared to RL-based methods like GiGPO, which can require hundreds of training iterations, EAGLET achieved better or comparable results with roughly one-eighth the training effort. This efficiency also carries over into execution: agents using EAGLET typically needed fewer steps to complete tasks. This translates into reduced inference time and compute cost in production scenarios.No Public Code—YetAs of the version submitted to arXiv, the authors have not released an open-source implementation of EAGLET. It is unclear if or when the code will be released, under what license, or how it will be maintained, which may limit the near-term utility of the framework for enterprise deployment. VentureBeat has reached out to the authors to clarify these points and will update this piece when we hear back.Enterprise Deployment Questions RemainWhile the planner is described as plug-and-play, it remains unclear whether EAGLET can be easily integrated into popular enterprise agent frameworks such as LangChain or AutoGen, or if it requires a custom stack to support plan-execute separation. Similarly, the training setup leverages multiple executor agents, which may be difficult to replicate in enterprise environments with limited model access. VentureBeat has asked the researchers whether the homologous consensus filtering method can be adapted for teams that only have access to one executor model or limited compute resources.EAGLET’s authors report success across model types and sizes, but it is not yet known what the minimal viable model scale is for practical deployment. For example, can enterprise teams use the planner effectively with sub-10B parameter open models in latency-sensitive environments? Additionally, the framework may offer industry-specific value in domains like customer support or IT automation, but it remains to be seen how easily the planner can be fine-tuned or customized for such verticals.Real-Time vs. Pre-Generated PlanningAnother open question is how EAGLET is best deployed in practice. Should the planner operate in real-time alongside executors within a loop, or is it better used offline to pre-generate global plans for known task types? Each approach has implications for latency, cost, and operational complexity. VentureBeat has posed this question to the authors and will report any insights that emerge.Strategic Tradeoffs for Enterprise TeamsFor technical leaders at medium-to-large enterprises, EAGLET represents a compelling proof of concept for improving the reliability and efficiency of LLM agents. But without public tooling or implementation guidelines, the framework still presents a build-versus-wait decision. Enterprises must weigh the potential gains in task performance and efficiency against the costs of reproducing or approximating the training process in-house.Potential Use Cases in Enterprise SettingsFor enterprises developing agentic AI systems—especially in environments requiring stepwise planning, such as IT automation, customer support, or online interactions—EAGLET offers a template for how to incorporate planning without retraining. Its ability to guide both open- and closed-source models, along with its efficient training method, may make it an appealing starting point for teams seeking to improve agent performance with minimal overhead.",
          "content": "2025 was supposed to be the year of \"AI agents,\" according to Nvidia CEO Jensen Huang, and other AI industry personnel. And it has been, in many ways, with numerous leading AI model providers such as OpenAI, Google, and even Chinese competitors like Alibaba releasing fine-tuned AI models or applications designed to focus on a narrow set of tasks, such as web search and report writing. But one big hurdle to a future of highly performant, reliable, AI agents remains: getting them to stay on task when the task extends over a number of steps. Third-party benchmark tests show even the most powerful AI models experience higher failure rates the more steps they take to complete a task, and the longer time they spend on it (exceeding hours). A new academic framework called EAGLET proposes a practical and efficient method to improve long-horizon task performance in LLM-based agents — without the need for manual data labeling or retraining. Developed by researchers from Tsinghua University, Peking University, DeepLang AI, and the University of Illinois Urbana-Champaign, EAGLET offers a \"global planner\" that can be integrated into existing agent workflows to reduce hallucinations and improve task efficiency.EAGLET is a fine-tuned language model that interprets task instructions — typically provided as prompts by the user or the agent&#x27;s operating environment — and generates a high-level plan for the agent (powered by its own LLM). It does not intervene during execution, but its up-front guidance helps reduce planning errors and improve task completion rates.Addressing the Planning Problem in Long-Horizon AgentsMany LLM-based agents struggle with long-horizon tasks because they rely on reactive, step-by-step reasoning. This approach often leads to trial-and-error behavior, planning hallucinations, and inefficient trajectories. EAGLET tackles this limitation by introducing a global planning module that works alongside the executor agent. Instead of blending planning and action generation in a single model, EAGLET separates them, enabling more coherent, task-level strategies.A Two-Stage Training Pipeline with No Human AnnotationsEAGLET’s planner is trained using a two-stage process that requires no human-written plans or annotations. The first stage involves generating synthetic plans with high-capability LLMs, such as GPT-5 and DeepSeek-V3.1-Think. These plans are then filtered using a novel strategy called homologous consensus filtering, which retains only those that improve task performance for both expert and novice executor agents. In the second stage, a rule-based reinforcement learning process further refines the planner, using a custom-designed reward function to assess how much each plan helps multiple agents succeed.Introducing the Executor Capability Gain Reward (ECGR)One of EAGLET’s key innovations is the Executor Capability Gain Reward (ECGR). This reward measures the value of a generated plan by checking whether it helps both high- and low-capability agents complete tasks more successfully and with fewer steps. It also includes a decay factor to favor shorter, more efficient task trajectories. This approach avoids over-rewarding plans that are only useful to already-competent agents and promotes more generalizable planning guidance.Compatible with Existing Agents and ModelsThe EAGLET planner is designed to be modular and \"plug-and-play,\" meaning it can be inserted into existing agent pipelines without requiring executor retraining. In evaluations, the planner boosted performance across a variety of foundational models, including GPT-4.1, GPT-5, Llama-3.1, and Qwen2.5. It also proved effective regardless of prompting strategy, working well with standard ReAct-style prompts as well as approaches like Reflexion.State-of-the-Art Performance Across BenchmarksEAGLET was tested on three widely used benchmarks for long-horizon agent tasks: ScienceWorld, which simulates scientific experiments in a text-based lab environment; ALFWorld, which tasks agents with completing household activities through natural language in a simulated home setting; and WebShop, which evaluates goal-driven behavior in a realistic online shopping interface.Across all three, executor agents equipped with EAGLET outperformed their non-planning counterparts and other planning baselines, including MPO and KnowAgent. In experiments with the open source Llama-3.1-8B-Instruct model, EAGLET boosted average performance from 39.5 to 59.4, a +19.9 point gain across tasks. On ScienceWorld unseen scenarios, it raised performance from 42.2 to 61.6. In ALFWorld seen scenarios, EAGLET improved outcomes from 22.9 to 54.3, a more than 2.3× increase in performance.Even stronger gains were seen with more capable models. For instance, GPT-4.1 improved from 75.5 to 82.2 average score with EAGLET, and GPT-5 rose from 84.5 to 88.1, despite already being strong performers. In some benchmarks, performance gains were as high as +11.8 points, such as when combining EAGLET with the ETO executor method on ALFWorld unseen tasks.Compared to other planning baselines like MPO, EAGLET consistently delivered higher task completion rates. For example, on ALFWorld unseen tasks with GPT-4.1, MPO achieved 79.1, while EAGLET scored 83.6—a +4.5 point advantage.Additionally, the paper reports that agents using EAGLET complete tasks in fewer steps on average. With GPT-4.1 as executor, average step count dropped from 13.0 (no planner) to 11.1 (EAGLET). With GPT-5, it dropped from 11.4 to 9.4, supporting the claim of improved execution efficiency.Efficiency Gains in Training and ExecutionCompared to RL-based methods like GiGPO, which can require hundreds of training iterations, EAGLET achieved better or comparable results with roughly one-eighth the training effort. This efficiency also carries over into execution: agents using EAGLET typically needed fewer steps to complete tasks. This translates into reduced inference time and compute cost in production scenarios.No Public Code—YetAs of the version submitted to arXiv, the authors have not released an open-source implementation of EAGLET. It is unclear if or when the code will be released, under what license, or how it will be maintained, which may limit the near-term utility of the framework for enterprise deployment. VentureBeat has reached out to the authors to clarify these points and will update this piece when we hear back.Enterprise Deployment Questions RemainWhile the planner is described as plug-and-play, it remains unclear whether EAGLET can be easily integrated into popular enterprise agent frameworks such as LangChain or AutoGen, or if it requires a custom stack to support plan-execute separation. Similarly, the training setup leverages multiple executor agents, which may be difficult to replicate in enterprise environments with limited model access. VentureBeat has asked the researchers whether the homologous consensus filtering method can be adapted for teams that only have access to one executor model or limited compute resources.EAGLET’s authors report success across model types and sizes, but it is not yet known what the minimal viable model scale is for practical deployment. For example, can enterprise teams use the planner effectively with sub-10B parameter open models in latency-sensitive environments? Additionally, the framework may offer industry-specific value in domains like customer support or IT automation, but it remains to be seen how easily the planner can be fine-tuned or customized for such verticals.Real-Time vs. Pre-Generated PlanningAnother open question is how EAGLET is best deployed in practice. Should the planner operate in real-time alongside executors within a loop, or is it better used offline to pre-generate global plans for known task types? Each approach has implications for latency, cost, and operational complexity. VentureBeat has posed this question to the authors and will report any insights that emerge.Strategic Tradeoffs for Enterprise TeamsFor technical leaders at medium-to-large enterprises, EAGLET represents a compelling proof of concept for improving the reliability and efficiency of LLM agents. But without public tooling or implementation guidelines, the framework still presents a build-versus-wait decision. Enterprises must weigh the potential gains in task performance and efficiency against the costs of reproducing or approximating the training process in-house.Potential Use Cases in Enterprise SettingsFor enterprises developing agentic AI systems—especially in environments requiring stepwise planning, such as IT automation, customer support, or online interactions—EAGLET offers a template for how to incorporate planning without retraining. Its ability to guide both open- and closed-source models, along with its efficient training method, may make it an appealing starting point for teams seeking to improve agent performance with minimal overhead.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1FsFs77cl1uzCE3JPEBnrk/7541c62def835191ff404046af4030c7/cfr0z3n_graphic_novel_hyper_detailed_close_up_on_a_cybernetic_b_9624e28f-5392-4c92-a115-0520c6058152.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/openai-forms-advisory-council-on-wellbeing-and-ai-183815365.html",
          "published_at": "Tue, 14 Oct 2025 18:38:15 +0000",
          "title": "OpenAI forms advisory council on wellbeing and AI",
          "standfirst": "OpenAI announced today that it is creating an advisory council centered on its users' mental and emotional wellness. The Expert Council on Well-being and AI comprises eight researchers and experts on the intersection of technology and mental health. Some of the members were experts that OpenAI consulted as it developed parental controls. Topics of safety and protecting younger users have become more of a talking point for all artificial intelligence companies, including OpenAI, after lawsuits questioned their complicity in multiple cases where teenagers committed suicide after sharing their plans with AI chatbots.This move sounds like a wise addition, but the effectiveness of any advisor hinges on listening to their insights. We've seen other tech companies establish and then utterly ignore their advisory councils; Meta is one of the notable recent examples. And the announcement from OpenAI even acknowledges that its new council has no real power to guide its operations: \"We remain responsible for the decisions we make, but we’ll continue learning from this council, the Global Physician Network, policymakers, and more, as we build advanced AI systems in ways that support people’s well-being.\" It may become clearer how seriously OpenAI is taking this effort when it starts to disagree with the council, whether the company is genuinely committed to mitigating the serious risks of AI or whether this is a smoke and mirrors attempt to paper over its issues.This article originally appeared on Engadget at https://www.engadget.com/openai-forms-advisory-council-on-wellbeing-and-ai-183815365.html?src=rss",
          "content": "OpenAI announced today that it is creating an advisory council centered on its users' mental and emotional wellness. The Expert Council on Well-being and AI comprises eight researchers and experts on the intersection of technology and mental health. Some of the members were experts that OpenAI consulted as it developed parental controls. Topics of safety and protecting younger users have become more of a talking point for all artificial intelligence companies, including OpenAI, after lawsuits questioned their complicity in multiple cases where teenagers committed suicide after sharing their plans with AI chatbots.This move sounds like a wise addition, but the effectiveness of any advisor hinges on listening to their insights. We've seen other tech companies establish and then utterly ignore their advisory councils; Meta is one of the notable recent examples. And the announcement from OpenAI even acknowledges that its new council has no real power to guide its operations: \"We remain responsible for the decisions we make, but we’ll continue learning from this council, the Global Physician Network, policymakers, and more, as we build advanced AI systems in ways that support people’s well-being.\" It may become clearer how seriously OpenAI is taking this effort when it starts to disagree with the council, whether the company is genuinely committed to mitigating the serious risks of AI or whether this is a smoke and mirrors attempt to paper over its issues.This article originally appeared on Engadget at https://www.engadget.com/openai-forms-advisory-council-on-wellbeing-and-ai-183815365.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openai-will-let-adults-use-chatgpt-for-erotica-starting-in-december-182417583.html",
          "published_at": "Tue, 14 Oct 2025 18:24:17 +0000",
          "title": "OpenAI will let adults use ChatGPT for erotica starting in December",
          "standfirst": "OpenAI plans to open the floodgates to more adult uses of ChatGPT starting in December, according to a new post from CEO Sam Altman. The company announced that it would add parental controls and automatic age detection features in September, and it seems like a benefit of sorting out children from adults is an ability to offer more freedom in what ChatGPT can show users. \"In December, as we roll out age-gating more fully and as part of our 'treat adult users like adults' principle, we will allow even more, like erotica for verified adults,\" Altman says. Some avid ChatGPT users already regularly manipulate the chatbot to engage in NSFW conversations, but Altman's announcement sounds more like tacit approval from OpenAI that those use-cases are okay. We made ChatGPT pretty restrictive to make sure we were being careful with mental health issues. We realize this made it less useful/enjoyable to many users who had no mental health problems, but given the seriousness of the issue we wanted to get this right.Now that we have…— Sam Altman (@sama) October 14, 2025 The company signaled something similar during its DevDay 2025 announcements, when its new guidelines for developers creating apps for ChatGPT shared that \"support for mature (18+) experiences will arrive once appropriate age verification and controls are in place.\" After December, it sounds like adult interactions with ChatGPT or apps the chatbot can access are fair game. All of these changes are being made in the shadow of disturbing stories of the seemingly negative influence ChatGPT can have on users, including the death of 16-year old Adam Raine, who allegedly used ChatGPT to plan his own suicide. Reducing the chatbot's sycophantic qualities with the release of GPT-5 was one of the ways OpenAI tried to address the mental health impacts of ChatGPT, along with built-in notifications to remind users to take breaks. It's hard to definitively say whether these tweaks have made a difference, but combined with age-gating, it's clear OpenAI feels comfortable giving its chatbot a longer leash.This article originally appeared on Engadget at https://www.engadget.com/ai/openai-will-let-adults-use-chatgpt-for-erotica-starting-in-december-182417583.html?src=rss",
          "content": "OpenAI plans to open the floodgates to more adult uses of ChatGPT starting in December, according to a new post from CEO Sam Altman. The company announced that it would add parental controls and automatic age detection features in September, and it seems like a benefit of sorting out children from adults is an ability to offer more freedom in what ChatGPT can show users. \"In December, as we roll out age-gating more fully and as part of our 'treat adult users like adults' principle, we will allow even more, like erotica for verified adults,\" Altman says. Some avid ChatGPT users already regularly manipulate the chatbot to engage in NSFW conversations, but Altman's announcement sounds more like tacit approval from OpenAI that those use-cases are okay. We made ChatGPT pretty restrictive to make sure we were being careful with mental health issues. We realize this made it less useful/enjoyable to many users who had no mental health problems, but given the seriousness of the issue we wanted to get this right.Now that we have…— Sam Altman (@sama) October 14, 2025 The company signaled something similar during its DevDay 2025 announcements, when its new guidelines for developers creating apps for ChatGPT shared that \"support for mature (18+) experiences will arrive once appropriate age verification and controls are in place.\" After December, it sounds like adult interactions with ChatGPT or apps the chatbot can access are fair game. All of these changes are being made in the shadow of disturbing stories of the seemingly negative influence ChatGPT can have on users, including the death of 16-year old Adam Raine, who allegedly used ChatGPT to plan his own suicide. Reducing the chatbot's sycophantic qualities with the release of GPT-5 was one of the ways OpenAI tried to address the mental health impacts of ChatGPT, along with built-in notifications to remind users to take breaks. It's hard to definitively say whether these tweaks have made a difference, but combined with age-gating, it's clear OpenAI feels comfortable giving its chatbot a longer leash.This article originally appeared on Engadget at https://www.engadget.com/ai/openai-will-let-adults-use-chatgpt-for-erotica-starting-in-december-182417583.html?src=rss",
          "feed_position": 8
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/x-experiments-with-showing-more-information-about-profiles-to-fight-inauthentic-engagement-172500501.html",
          "published_at": "Tue, 14 Oct 2025 17:25:00 +0000",
          "title": "X experiments with showing more information about profiles to fight inauthentic engagement",
          "standfirst": "X has long been a hotbed for fake accounts, bots and other scammy behavior. Many of those dynamics have been exacerbated by the rise of paid verification, which boosts the visibility of anyone who pays for a subscription. Now, the company is running a small experiment that could help users better identify potentially suspicious accounts.The service is starting to test a new \"about this account\" feature that will provide details about when an account joined the platform, where the person running it is based, how many times the username has been changed and how the account is connected to X. The feature is a lot like the \"page transparency\" information on Facebook, which provides similar details about when a given page was created and where the people running it are based. \"When you read content on X, you should be able to verify its authenticity,\" X's head of product, Nikita Bier, shared in a post about the change. \"This is critical to getting a pulse on important issues happening in the world.\" If fully rolled out, this type of feature could help people on X understand a lot of common scams and other deceptive behavior on the platform. For example, scammers often change the handle of a recently compromised account in order to trick an account's existing followers. And understanding the location of an account could help users root out people lying about their identity. However, it sounds like it could be some time before the feature is implemented in a way that could be broadly useful. Bier said that initially X will show this info on \"a handful of profiles of X team members\" — most of whom already have an official \"X\" badge on their profiles — in order to get feedback on the change.This article originally appeared on Engadget at https://www.engadget.com/social-media/x-experiments-with-showing-more-information-about-profiles-to-fight-inauthentic-engagement-172500501.html?src=rss",
          "content": "X has long been a hotbed for fake accounts, bots and other scammy behavior. Many of those dynamics have been exacerbated by the rise of paid verification, which boosts the visibility of anyone who pays for a subscription. Now, the company is running a small experiment that could help users better identify potentially suspicious accounts.The service is starting to test a new \"about this account\" feature that will provide details about when an account joined the platform, where the person running it is based, how many times the username has been changed and how the account is connected to X. The feature is a lot like the \"page transparency\" information on Facebook, which provides similar details about when a given page was created and where the people running it are based. \"When you read content on X, you should be able to verify its authenticity,\" X's head of product, Nikita Bier, shared in a post about the change. \"This is critical to getting a pulse on important issues happening in the world.\" If fully rolled out, this type of feature could help people on X understand a lot of common scams and other deceptive behavior on the platform. For example, scammers often change the handle of a recently compromised account in order to trick an account's existing followers. And understanding the location of an account could help users root out people lying about their identity. However, it sounds like it could be some time before the feature is implemented in a way that could be broadly useful. Bier said that initially X will show this info on \"a handful of profiles of X team members\" — most of whom already have an official \"X\" badge on their profiles — in order to get feedback on the change.This article originally appeared on Engadget at https://www.engadget.com/social-media/x-experiments-with-showing-more-information-about-profiles-to-fight-inauthentic-engagement-172500501.html?src=rss",
          "feed_position": 11
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/music/spotifys-managed-accounts-will-help-keep-your-kids-from-wrecking-your-music-taste-profile-154406843.html",
          "published_at": "Tue, 14 Oct 2025 15:44:06 +0000",
          "title": "Spotify's managed accounts will help keep your kids from wrecking your music taste profile",
          "standfirst": "Spotify has introduced a new \"managed accounts\" feature aimed at younger listeners. Initially piloted last year and launching in seven new markets, including the US, today, it allows parents and guardians with a Spotify Premium Family plan to allocate their children a dedicated profile with their own personalized recommendations and custom playlists. The idea is that the adults can filter out explicit content, limit the playback of certain artists and hide video playback features, including Canvas, should they want to. Users on this profile can’t use interactivity features like Messages either. Perhaps most importantly of all for some, a managed account also ensures that your personal Wrapped results at the end of the year aren’t dominated by whatever TikTok-viral songs the kids have been obsessively playing on repeat for months — and they won't mess with your Discover Weekly algorithm either. Spotify's 'Exclude from your Taste Profile' feature already offers a way of keeping the nonsense your kids might be listening to away from your own recommended content, but this feels like a cleaner option for families. Standard Spotify Premium features like daylist and the aforementioned Discover Weekly remain available to someone using a managed account, making it a better option for kids becoming interested in music (they may even have gotten hooked on a band you’ve been listening to in the car) than the Spotify Kids app, which is very much designed for the 'Baby Shark' devotees. It’s probably helpful to think of a managed account as a bridge between that and an unrestricted Premium account where all the music in the world is at your fingertips. To set up a managed account, the plan owner has to go into their account settings within the Spotify app and select \"Add a Member,\" followed by selecting \"Add a listener aged under 13.\" The app will provide further instructions from there. As a reminder, a Spotify Premium Family plan is required to set up a managed account. This currently costs $20 per month.This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/spotifys-managed-accounts-will-help-keep-your-kids-from-wrecking-your-music-taste-profile-154406843.html?src=rss",
          "content": "Spotify has introduced a new \"managed accounts\" feature aimed at younger listeners. Initially piloted last year and launching in seven new markets, including the US, today, it allows parents and guardians with a Spotify Premium Family plan to allocate their children a dedicated profile with their own personalized recommendations and custom playlists. The idea is that the adults can filter out explicit content, limit the playback of certain artists and hide video playback features, including Canvas, should they want to. Users on this profile can’t use interactivity features like Messages either. Perhaps most importantly of all for some, a managed account also ensures that your personal Wrapped results at the end of the year aren’t dominated by whatever TikTok-viral songs the kids have been obsessively playing on repeat for months — and they won't mess with your Discover Weekly algorithm either. Spotify's 'Exclude from your Taste Profile' feature already offers a way of keeping the nonsense your kids might be listening to away from your own recommended content, but this feels like a cleaner option for families. Standard Spotify Premium features like daylist and the aforementioned Discover Weekly remain available to someone using a managed account, making it a better option for kids becoming interested in music (they may even have gotten hooked on a band you’ve been listening to in the car) than the Spotify Kids app, which is very much designed for the 'Baby Shark' devotees. It’s probably helpful to think of a managed account as a bridge between that and an unrestricted Premium account where all the music in the world is at your fingertips. To set up a managed account, the plan owner has to go into their account settings within the Spotify app and select \"Add a Member,\" followed by selecting \"Add a listener aged under 13.\" The app will provide further instructions from there. As a reminder, a Spotify Premium Family plan is required to set up a managed account. This currently costs $20 per month.This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/spotifys-managed-accounts-will-help-keep-your-kids-from-wrecking-your-music-taste-profile-154406843.html?src=rss",
          "feed_position": 13
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/windows-10-support-ends-today-but-heres-how-to-get-an-extra-year-for-free-125118540.html",
          "published_at": "Tue, 14 Oct 2025 13:37:23 +0000",
          "title": "Windows 10 support ends today, but here's how to get an extra year for free",
          "standfirst": "You'll get access to Windows 10 a little longer by doing this. (Getty Images) If you're still running Windows 10 on your PC, we've got some news for you. As of today, Microsoft is moving the software to \"end of life\" status. The good news: Windows 10 PCs will still continue to work after today. The bad news: they'll stop getting important security updates by default. That leaves you with three options if you want to make sure your computer remains secure: You can choose to upgrade to Windows 11 for free if your computer is compatible. You can buy a new PC that already has Windows 11 pre-installed (or opt for an alternative, like a Mac or a Chromebook). Forget about Windows 11 right now and sign up for the Extended Security Updates (ESU), which lets you kick the can down the road for a year. Option three is pretty easy — and can now be done for free in many cases — so we'll focus on that one here. We'll walk you through the steps of keeping Windows 10 on your PC… for now, at least. How to sign up for Windows 10 Extended Security Updates on your computer We can question Microsoft's motives for killing off Windows 10, even though it works perfectly well on most older PCs. But without those periodic security updates, your PC will become increasingly susceptible to malware with each passing week. To that end, enrolling in Extended Security Updates (ESU) will give you another year of using Windows 10 securely. At one point, Microsoft suggested the 12-month extension would require a $30 fee. While that's still an option, there's now a free path for Windows 10 users in the US. Here's how to make it happen. Step 1: Make sure your PC is up to date You can find out if your computer is up-to-date by going into your Settings > System > About, then scroll down to see what version you're running. If not, you'll want to make sure you also install all the Windows 10 updates available. Step 2: Make sure you're using an administrator account If you share a computer with multiple people in your household, make sure you're signed in to the administrator account. Typically, it's the first account created on the computer. You'll know it's the right one when you see \"Administrator\" under the name. (You can double-check under Settings > Your Info.) Step 3: Verify if your PC is eligible to upgrade to Windows 11 (or not) If you see an option to upgrade to Windows 11, just do that. It's free and it keeps you in the Windows loop. Otherwise, continue following the steps below so you can keep your computer safe with security updates. Step 4: Enroll in Extended Security Updates Sign up for ESU by selecting Update & Security from the Settings menu. Click the \"Enroll Now\" sign-up link, as pictured below. Again, you may see an option to download Windows 11 if your computer meets the requirements (again, definitely do that if you see it). Find out if you need to update your computer. (Screenshot/Engadget) If you're not seeing the \"Enroll now\" link, you probably need to update and install the latest Windows 10 updates (as noted above). By enrolling in Extended Security Updates, you'll have another year before you need to upgrade to Windows 11. (Screenshots/Engadget) Step 5: Choose your upgrade method Next up is choosing how you want to enroll, and you have a few options. The easiest way is to back up your PC settings. It's free, but it takes a little bit of time since you'll need to back up your data. Again, you'll need to use your administrator account to get started. Back up your PC before you enroll in ESU. (ExplainingComputers via YouTube) That said, the free option here comes with two catches, at least for users in the US. (European users will get the free option with no strings attached.) The first is that you'll be linking your Windows login to Microsoft's cloud-based online service. Most users have likely already done this (if they're using CoPilot, Office 365, GamePass, OneDrive or one of Microsoft's other various online services). But if you've specifically opted for a local login to Windows, the price you're paying for this \"free\" extension is joining the cloud-connected Microsoft universe. The other potential issue is that the free backup only applies to the first 5 GB of storage. Anything more, and you’ll need to pay up for Microsoft's OneDrive services. But thankfully, you can turn off anything you don't want to back up by going to Settings > OneDrive and toggling off options like Documents, Pictures and Videos to get in under the free threshold to start. Once you're signed in, a window will pop up that says \"Add this device to receive Extended Security Updates.\" Click Add Device to enroll it. Click Done. A note: Thanks to YouTube's Explaining Computers channel, where we grabbed the screenshot above (since our test PC was already signed up for cloud backups, and didn't provide the splash screen to choose options). You can watch their full video if you'd like a deeper dive into the process. That's it, you're done! (Until next year) You've got 12 more months to figure out an alternative upgrade path to Windows 11. If anything changes next year, we'll update this story with what your next steps are. You did it right if you see this window. (Screenshot/Engadget) This article originally appeared on Engadget at https://www.engadget.com/computing/windows-10-support-ends-today-but-heres-how-to-get-an-extra-year-for-free-125118540.html?src=rss",
          "content": "You'll get access to Windows 10 a little longer by doing this. (Getty Images) If you're still running Windows 10 on your PC, we've got some news for you. As of today, Microsoft is moving the software to \"end of life\" status. The good news: Windows 10 PCs will still continue to work after today. The bad news: they'll stop getting important security updates by default. That leaves you with three options if you want to make sure your computer remains secure: You can choose to upgrade to Windows 11 for free if your computer is compatible. You can buy a new PC that already has Windows 11 pre-installed (or opt for an alternative, like a Mac or a Chromebook). Forget about Windows 11 right now and sign up for the Extended Security Updates (ESU), which lets you kick the can down the road for a year. Option three is pretty easy — and can now be done for free in many cases — so we'll focus on that one here. We'll walk you through the steps of keeping Windows 10 on your PC… for now, at least. How to sign up for Windows 10 Extended Security Updates on your computer We can question Microsoft's motives for killing off Windows 10, even though it works perfectly well on most older PCs. But without those periodic security updates, your PC will become increasingly susceptible to malware with each passing week. To that end, enrolling in Extended Security Updates (ESU) will give you another year of using Windows 10 securely. At one point, Microsoft suggested the 12-month extension would require a $30 fee. While that's still an option, there's now a free path for Windows 10 users in the US. Here's how to make it happen. Step 1: Make sure your PC is up to date You can find out if your computer is up-to-date by going into your Settings > System > About, then scroll down to see what version you're running. If not, you'll want to make sure you also install all the Windows 10 updates available. Step 2: Make sure you're using an administrator account If you share a computer with multiple people in your household, make sure you're signed in to the administrator account. Typically, it's the first account created on the computer. You'll know it's the right one when you see \"Administrator\" under the name. (You can double-check under Settings > Your Info.) Step 3: Verify if your PC is eligible to upgrade to Windows 11 (or not) If you see an option to upgrade to Windows 11, just do that. It's free and it keeps you in the Windows loop. Otherwise, continue following the steps below so you can keep your computer safe with security updates. Step 4: Enroll in Extended Security Updates Sign up for ESU by selecting Update & Security from the Settings menu. Click the \"Enroll Now\" sign-up link, as pictured below. Again, you may see an option to download Windows 11 if your computer meets the requirements (again, definitely do that if you see it). Find out if you need to update your computer. (Screenshot/Engadget) If you're not seeing the \"Enroll now\" link, you probably need to update and install the latest Windows 10 updates (as noted above). By enrolling in Extended Security Updates, you'll have another year before you need to upgrade to Windows 11. (Screenshots/Engadget) Step 5: Choose your upgrade method Next up is choosing how you want to enroll, and you have a few options. The easiest way is to back up your PC settings. It's free, but it takes a little bit of time since you'll need to back up your data. Again, you'll need to use your administrator account to get started. Back up your PC before you enroll in ESU. (ExplainingComputers via YouTube) That said, the free option here comes with two catches, at least for users in the US. (European users will get the free option with no strings attached.) The first is that you'll be linking your Windows login to Microsoft's cloud-based online service. Most users have likely already done this (if they're using CoPilot, Office 365, GamePass, OneDrive or one of Microsoft's other various online services). But if you've specifically opted for a local login to Windows, the price you're paying for this \"free\" extension is joining the cloud-connected Microsoft universe. The other potential issue is that the free backup only applies to the first 5 GB of storage. Anything more, and you’ll need to pay up for Microsoft's OneDrive services. But thankfully, you can turn off anything you don't want to back up by going to Settings > OneDrive and toggling off options like Documents, Pictures and Videos to get in under the free threshold to start. Once you're signed in, a window will pop up that says \"Add this device to receive Extended Security Updates.\" Click Add Device to enroll it. Click Done. A note: Thanks to YouTube's Explaining Computers channel, where we grabbed the screenshot above (since our test PC was already signed up for cloud backups, and didn't provide the splash screen to choose options). You can watch their full video if you'd like a deeper dive into the process. That's it, you're done! (Until next year) You've got 12 more months to figure out an alternative upgrade path to Windows 11. If anything changes next year, we'll update this story with what your next steps are. You did it right if you see this window. (Screenshot/Engadget) This article originally appeared on Engadget at https://www.engadget.com/computing/windows-10-support-ends-today-but-heres-how-to-get-an-extra-year-for-free-125118540.html?src=rss",
          "feed_position": 14,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c836b6e0-a60d-11f0-aff0-71a091f199fd"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/tv-movies/tivo-has-discontinued-its-dvr-boxes-123037999.html",
          "published_at": "Tue, 14 Oct 2025 12:30:37 +0000",
          "title": "TiVo has discontinued its DVR boxes",
          "standfirst": "TiVo has confirmed that it has stopped selling its DVR set-top boxes, marking the end of an era that changed how we watch television forever. As first reported earlier this month by Cord Cutters News, TiVo Corporation quietly pulled its once-groundbreaking digital video recorder from its website. Holding company Xperi later confirmed that the listing was removed on October 1. “I can confirm that as of October 1, 2025, TiVo stopped selling physical DVR products, including hardware and accessories, both online and through agents,” a TiVo spokesperson confirmed to PCMag. “TiVo no longer manufactures hardware, and our remaining inventory is now depleted, though we will continue to offer support for the products going forward.” The TiVo box revolutionized television upon its launch in 1999, allowing viewers to pause, rewind and record live television. There was a time when you would just miss the start of a show if you weren’t punctual, and you’d have to sync grabbing a snack with a commercial during the big game. You also had to actually watch the commercials, something that is unfortunately making a comeback with an increase in ad-supported streaming. The DVR pioneer is now a software company. It has been producing TiVo OS almost exclusively in the European market since 2022, though the smart TV OS premiered in the US this year via Sharp. “The Sharp Smart TV Powered by TiVo” launched as a 55-inch QLED display with 4K resolution and HDR support. TiVo OS functions like many other television operating systems, aggregating streaming services and offering its own library of free and paid content. TiVo will still offer customer support for its now-discontinued boxes, which bodes well for customers who have purchased a lifetime plan.This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/tivo-has-discontinued-its-dvr-boxes-123037999.html?src=rss",
          "content": "TiVo has confirmed that it has stopped selling its DVR set-top boxes, marking the end of an era that changed how we watch television forever. As first reported earlier this month by Cord Cutters News, TiVo Corporation quietly pulled its once-groundbreaking digital video recorder from its website. Holding company Xperi later confirmed that the listing was removed on October 1. “I can confirm that as of October 1, 2025, TiVo stopped selling physical DVR products, including hardware and accessories, both online and through agents,” a TiVo spokesperson confirmed to PCMag. “TiVo no longer manufactures hardware, and our remaining inventory is now depleted, though we will continue to offer support for the products going forward.” The TiVo box revolutionized television upon its launch in 1999, allowing viewers to pause, rewind and record live television. There was a time when you would just miss the start of a show if you weren’t punctual, and you’d have to sync grabbing a snack with a commercial during the big game. You also had to actually watch the commercials, something that is unfortunately making a comeback with an increase in ad-supported streaming. The DVR pioneer is now a software company. It has been producing TiVo OS almost exclusively in the European market since 2022, though the smart TV OS premiered in the US this year via Sharp. “The Sharp Smart TV Powered by TiVo” launched as a 55-inch QLED display with 4K resolution and HDR support. TiVo OS functions like many other television operating systems, aggregating streaming services and offering its own library of free and paid content. TiVo will still offer customer support for its now-discontinued boxes, which bodes well for customers who have purchased a lifetime plan.This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/tivo-has-discontinued-its-dvr-boxes-123037999.html?src=rss",
          "feed_position": 18
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/instagram-makes-teen-accounts-more-restrictive-120000653.html",
          "published_at": "Tue, 14 Oct 2025 12:00:00 +0000",
          "title": "Instagram makes 'teen accounts' more restrictive",
          "standfirst": "Instagram is tightening the settings on its \"teen accounts\" to add new limits on what kids on the platform are able to see. Older teens will also no longer be able to opt out of the default stricter settings without parental approval. Meta first introduced teen accounts for Instagram a year ago, when it began automatically moving teens into the more locked-down accounts that come with stricter privacy settings and parental controls. The company recently rolled out the accounts for teens on Facebook and Messenger too, and has used AI tools to detect teens that are lying about their age. While teen accounts are meant to address long-running criticism about Meta's handling of teen safety on its apps, the measures have been widely criticized as not going far enough to protect the company's most vulnerable users. A recent report from safety advocates at Heat Initiative found that \"young teen users today continue to be recommended or exposed to unsafe content and unwanted messages at alarmingly high rates while using Instagram Teen Accounts.\" (Meta called the report \"deeply subjective.\") Now, Meta is locking down teen accounts even more. With the latest changes, teens will no longer be able to follow or see content from accounts that \"regularly share age-inappropriate content\" or that seem \"age-inappropriate\" based on their bio or username. Meta says it will also block these accounts from appearing in teens' recommendations or in search results in the app. Instagram will also block a \"a wider range of mature search terms\" for teens, including words like \"alcohol,” \"gore,\" and intentional misspellings of these words, which is a common tactic to avoid Instagram's filters. And, even if an account a teen already follows shares a post that goes against these rules, teens should be prevented from seeing it, even if it's sent to their DMs.Instagram will block teens from searching for more term associated with inappropriate content,.MetaWhile these changes may seem like Meta once again filling somewhat obvious gaps in its safety features, the company says the revamp is meant to make the content teens encounter on Instagram more like a PG-13 movie. \"Just like you might see some suggestive content or hear some strong language in a PG-13 movie, teens may occasionally see something like that on Instagram - but we’re going to keep doing all we can to keep those instances as rare as possible,\" the company explained in a blog post.That's a somewhat confusing analogy as there's a fairly wide spectrum of what might appear in a PG-13 movie. Meta also says that some of its rules for teens are more restrictive than what teens might see in a PG-13 movie. For example, the app aims to prevent teens from seeing any kind of \"sexually suggestive\" content or images of \"near nudity\" even though that type of content might appear in movies rated for 13-year-olds. For parents that want even tighter restrictions, Instagram is also adding a new \"limited content\" setting that filters \"even more\" content from teens' view (Meta didn't explain what exactly would be restricted). The setting also prevents teens from accessing any comments on the platform, either on their own posts or other users'. Finally, Meta is testing a new reporting feature for parents that use Instagram's parental control settings to monitor their teens' use of the app. With the feature, parents can flag specific posts they feel are inappropriate to trigger a review by Meta. Meta says the latest changes will be rolling out \"gradually\" to teen accounts in the US, UK, Canada and Australia to start and that it will eventually \"add additional age-appropriate content protections for teens on Facebook.\" This article originally appeared on Engadget at https://www.engadget.com/social-media/instagram-makes-teen-accounts-more-restrictive-120000653.html?src=rss",
          "content": "Instagram is tightening the settings on its \"teen accounts\" to add new limits on what kids on the platform are able to see. Older teens will also no longer be able to opt out of the default stricter settings without parental approval. Meta first introduced teen accounts for Instagram a year ago, when it began automatically moving teens into the more locked-down accounts that come with stricter privacy settings and parental controls. The company recently rolled out the accounts for teens on Facebook and Messenger too, and has used AI tools to detect teens that are lying about their age. While teen accounts are meant to address long-running criticism about Meta's handling of teen safety on its apps, the measures have been widely criticized as not going far enough to protect the company's most vulnerable users. A recent report from safety advocates at Heat Initiative found that \"young teen users today continue to be recommended or exposed to unsafe content and unwanted messages at alarmingly high rates while using Instagram Teen Accounts.\" (Meta called the report \"deeply subjective.\") Now, Meta is locking down teen accounts even more. With the latest changes, teens will no longer be able to follow or see content from accounts that \"regularly share age-inappropriate content\" or that seem \"age-inappropriate\" based on their bio or username. Meta says it will also block these accounts from appearing in teens' recommendations or in search results in the app. Instagram will also block a \"a wider range of mature search terms\" for teens, including words like \"alcohol,” \"gore,\" and intentional misspellings of these words, which is a common tactic to avoid Instagram's filters. And, even if an account a teen already follows shares a post that goes against these rules, teens should be prevented from seeing it, even if it's sent to their DMs.Instagram will block teens from searching for more term associated with inappropriate content,.MetaWhile these changes may seem like Meta once again filling somewhat obvious gaps in its safety features, the company says the revamp is meant to make the content teens encounter on Instagram more like a PG-13 movie. \"Just like you might see some suggestive content or hear some strong language in a PG-13 movie, teens may occasionally see something like that on Instagram - but we’re going to keep doing all we can to keep those instances as rare as possible,\" the company explained in a blog post.That's a somewhat confusing analogy as there's a fairly wide spectrum of what might appear in a PG-13 movie. Meta also says that some of its rules for teens are more restrictive than what teens might see in a PG-13 movie. For example, the app aims to prevent teens from seeing any kind of \"sexually suggestive\" content or images of \"near nudity\" even though that type of content might appear in movies rated for 13-year-olds. For parents that want even tighter restrictions, Instagram is also adding a new \"limited content\" setting that filters \"even more\" content from teens' view (Meta didn't explain what exactly would be restricted). The setting also prevents teens from accessing any comments on the platform, either on their own posts or other users'. Finally, Meta is testing a new reporting feature for parents that use Instagram's parental control settings to monitor their teens' use of the app. With the feature, parents can flag specific posts they feel are inappropriate to trigger a review by Meta. Meta says the latest changes will be rolling out \"gradually\" to teen accounts in the US, UK, Canada and Australia to start and that it will eventually \"add additional age-appropriate content protections for teens on Facebook.\" This article originally appeared on Engadget at https://www.engadget.com/social-media/instagram-makes-teen-accounts-more-restrictive-120000653.html?src=rss",
          "feed_position": 21,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/image005.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-111557774.html",
          "published_at": "Tue, 14 Oct 2025 11:15:57 +0000",
          "title": "The Morning After: It’s the end for Windows 10",
          "standfirst": "After more than a decade of service, Microsoft is declaring the end of Windows 10’s usable life. If your machine still uses it, rest assured it’ll continue to work, but you won’t see any more software and security updates. If your machine is compatible, you’ll be able to upgrade to Windows 11 for free, or this can provide the justification you need to buy a new machine. But there’s also a way to keep your status quo without the additional stress, at least for the next year. It’s possible to sign up to Microsoft’s Extended Security updates program, giving you an extra year of software and security patches. It won’t cost you any money, but you will be expected to sign up to Microsoft’s cloud services. If you’d like to keep Windows 10 running and safe, you can head over to our comprehensive guide on what to do. And, if you’re ready to upgrade, check out our guide on the best Windows laptops to choose your next purchase. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed Another Game Freak leak claims to show the Pokémon roadmap Anbernic’s modern-day Nintendo DS dupe is cheaper than the original The FCC is trying to make it easier for internet providers to charge hidden fees It’s comically evil, really. The FCC has outlined a plan to once again allow ISPs to charge hidden fees, making it easier to rip off consumers. It follows a complaint from those poor carriers that believe it’s far too hard to be required to tell customers what it is they’re charging for. I bet that’s loads of fun for all of the FCC employees who went into public service in the hope of actually serving the public. Continue Reading. Apple TV+ is now just Apple TV I’m in the minority, but I think that’s a good shout. Devindra Hardawar for Engadget Apple is dropping the + from the name of its TV subscription service. That’s a smart piece of branding, since everyone just calls it Apple TV anyway. But it does muddy the waters, given Apple’s set top box is also called Apple TV. But, as someone who reviews Apple TV shows and irritates editors by forgetting the plus sign, this will make my (and their) lives a lot easier. Continue Reading. The first products with Apple’s M5 chip could make their debut this week The rumor mill suggests we’ll see them in a few days. Apple Apple is reportedly gearing up to announce a series of updated devices, each one packing its new A5 chip. Bloomberg claims the company will announce new MacBook Pros, Pad Pros and an updated Vision Pro online over a period of days. If so, it would be mirroring the release pattern from last year, when an updated product was launched online each day across a week. Rumors suggest we’ll only get the vanilla A5 versions this fall, with the higher-end versions of the silicon not arriving until the start of next year. Continue Reading. A long-lost Ratchet and Clank mobile game has been found Clone Home was a successor to Going Mobile. The Golden Bolt Ratchet & Clank superfans have unearthed a fairly substantial gem after a years-long search: a finished but essentially unreleased mobile title from 2006. Clone Home was the sequel to Going Mobile developed for mobile phones running Java from those halcyon pre-iPhone days. It was axed shortly before launch, but a few copies did find their way into the ether, which enabled YouTuber The Golden Bolt to show it off to the world. Continue Reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111557774.html?src=rss",
          "content": "After more than a decade of service, Microsoft is declaring the end of Windows 10’s usable life. If your machine still uses it, rest assured it’ll continue to work, but you won’t see any more software and security updates. If your machine is compatible, you’ll be able to upgrade to Windows 11 for free, or this can provide the justification you need to buy a new machine. But there’s also a way to keep your status quo without the additional stress, at least for the next year. It’s possible to sign up to Microsoft’s Extended Security updates program, giving you an extra year of software and security patches. It won’t cost you any money, but you will be expected to sign up to Microsoft’s cloud services. If you’d like to keep Windows 10 running and safe, you can head over to our comprehensive guide on what to do. And, if you’re ready to upgrade, check out our guide on the best Windows laptops to choose your next purchase. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed Another Game Freak leak claims to show the Pokémon roadmap Anbernic’s modern-day Nintendo DS dupe is cheaper than the original The FCC is trying to make it easier for internet providers to charge hidden fees It’s comically evil, really. The FCC has outlined a plan to once again allow ISPs to charge hidden fees, making it easier to rip off consumers. It follows a complaint from those poor carriers that believe it’s far too hard to be required to tell customers what it is they’re charging for. I bet that’s loads of fun for all of the FCC employees who went into public service in the hope of actually serving the public. Continue Reading. Apple TV+ is now just Apple TV I’m in the minority, but I think that’s a good shout. Devindra Hardawar for Engadget Apple is dropping the + from the name of its TV subscription service. That’s a smart piece of branding, since everyone just calls it Apple TV anyway. But it does muddy the waters, given Apple’s set top box is also called Apple TV. But, as someone who reviews Apple TV shows and irritates editors by forgetting the plus sign, this will make my (and their) lives a lot easier. Continue Reading. The first products with Apple’s M5 chip could make their debut this week The rumor mill suggests we’ll see them in a few days. Apple Apple is reportedly gearing up to announce a series of updated devices, each one packing its new A5 chip. Bloomberg claims the company will announce new MacBook Pros, Pad Pros and an updated Vision Pro online over a period of days. If so, it would be mirroring the release pattern from last year, when an updated product was launched online each day across a week. Rumors suggest we’ll only get the vanilla A5 versions this fall, with the higher-end versions of the silicon not arriving until the start of next year. Continue Reading. A long-lost Ratchet and Clank mobile game has been found Clone Home was a successor to Going Mobile. The Golden Bolt Ratchet & Clank superfans have unearthed a fairly substantial gem after a years-long search: a finished but essentially unreleased mobile title from 2006. Clone Home was the sequel to Going Mobile developed for mobile phones running Java from those halcyon pre-iPhone days. It was axed shortly before launch, but a few copies did find their way into the ether, which enabled YouTuber The Golden Bolt to show it off to the world. Continue Reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111557774.html?src=rss",
          "feed_position": 22,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/8a2cfc30-a8e0-11f0-9f7a-a1a711d9ca27"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/best-macbook-140032524.html",
          "published_at": "Tue, 14 Oct 2025 09:01:26 +0000",
          "title": "The best MacBook for 2025: Which Apple laptop should you buy?",
          "standfirst": "There wasn’t much Mac-related news at Apple’s latest to-do (to be expected at an iPhone event), aside from the announcement that macOS 26 would be available to the public on September 15. Historically, we’ve seen new Mac hardware in October and then again in spring. But as of right now, there are just two MacBooks in Apple’s lineup: MacBook Air models with the M4 chip and MacBook Pro models with the M4 chip. Within those two options lie a handful of choices, including chip type, screen size, storage capacity and more. This guide will help you suss out the Apple terminology and explain the options so you can pick the best MacBook configuration for your needs. Table of contents Best MacBooks for 2025 What about budget MacBooks? Factors to consider when buying a MacBook MacBooks specs comparison chart Best MacBook FAQs Best MacBooks for 2025 What about budget MacBooks? Historically, Apple kept the previous year’s MacBook Air in its lineup as a sort of budget option. But the company took a different approach with the release of the M4 MacBook Air. Instead of continuing to sell the older model, Apple discontinued the M3 Air and gave its newest computer a $100 price cut. Now, if you can even find a brand new M3 MacBook Air (typically from retailers like Amazon or B&H), it’s often more expensive than the M4 version. During sales like Amazon Prime Day, we’ve seen the newest M4 Air go for as little as $799. That effectively makes our overall pick a budget pick as well. Of course, $800 isn’t exactly a small investment either for college students or others on a budget. Especially when you can find some decent PCs for under $500. If you’re looking to save even more on a MacBook, we recommend checking out refurbished options directly from Apple, or even third party sellers like BackMarket. There are a few guidelines to keep in mind, which we go over in our refurbished guide, but mainly, you’ll want to shop from a reputable source that has a stated process and offers at least a year-long warranty. Using your old gear as a trade-in will bring down your final cost as well. Factors to consider when buying a MacBook Compared to PCs, Apple computers tend to have more streamlined specifications. The company has long been known for this simplicity, and the M-series “system-on-a-chip” condenses things even further. Prior to the M1 chip, Apple used Intel chips in its laptop and desktop computers. The M2 and M3 generations followed that first chip and currently sells MacBooks equipped with M4-series chips. You’ll find the standard M4 processor in the Air and the base-model Pro and the upgraded M4 Max and M4 Pro chips as options for the MacBook Pro (currently there is no M4 Ultra chip, as there was with the M3 series in the Mac Studio). All M-series chips combine, among other technologies, the CPU, graphics card and unified memory (RAM). Apple’s Neural Engine is included too, which is a specialized group of processor cores that handles machine learning tasks such as image analysis and voice recognition. While a unified chip means you have fewer decisions to make when picking a MacBook, there are still a few factors to consider, including specs like the number of CPU cores, amount of RAM, storage capacity, screen size, and, obviously, price. The finish color may be a minor consideration, but it's worth pointing out that the Pro comes in just two colors (Silver or Space Black) but the Air comes in four hues (Midnight, Starlight, Sky Blue and Silver). CPU cores The lowest-specced chip in a current-lineup MacBook is the standard M4 chip, which is found in all models of the MacBook Air and the base model MacBook Pro 14-inch. That chip houses a 10-core CPU and either an 8- or 10-core GPU. In total, there are three versions of the M4 chip: standard M4, M4 Pro and M4 Max (which are each a step up from their predecessors, the M3, M3 Pro and M3 Max chips). The burliest chip, the M4 Max is built with either a 14- or 16-core CPU and a 32- or 40-core GPU. Cores are, in essence, smaller processing units that can handle different tasks simultaneously. Having more of them translates to the computer being able to run multiple programs and applications at once, while also smoothly processing demanding tasks like video and photo editing and high-level gaming. In short, more cores allow for more advanced computing and better performance. But if your processing power needs fall below professional-level gaming and cinematic video and audio editing, getting the highest number of cores is likely overkill — and after all, more cores equals higher cost and more power usage. Photo by Devindra Hardawar/Engadget RAM Your options for RAM, or in Apple’s terminology, unified memory, varies, but with the switch to the M4 chip in all laptops, the lowest amount of RAM you can get is now 16GB. That’s a necessary spec-bump to accommodate the tech world’s favorite feature of the moment: AI or, in this case, Apple Intelligence (still AI, but Cupertino’s version). The M4 Pro chip has 24 or 48GB memory options, while the M4 Max chip supports 48, 64 or a whopping 128GB of RAM. You’ve likely heard the analogy comparing memory to the amount of workspace available on a literal desktop surface, whereas storage is the amount of drawers you have to store projects to work on later. The larger the worktop surface, the more projects you can work on at once. The bigger the drawers, the more you can save for later. In addition to supporting Apple Intelligence, more RAM is ideal for people who plan to work in multiple apps at once. And the more demanding each program is, the more RAM will be required. Extra memory can also come in handy if you’re the type who likes to have infinite numbers of tabs open on your browser. If your daily workflow doesn’t involve simultaneously using a vast number of memory-intensive programs, you can save yourself money and buy the RAM configuration that you’re most likely to actually use. For a long time, Apple continued to offer MacBooks with just 8GB of RAM, and we recommended upgrading to at least 16GB of RAM. With this being the standard today, grabbing a base model should be fine for most non-pro-level users. One thing to note is that, unlike most PCs, the RAM in a MacBook is not user-upgradable since it’s tied into the system-on-a-chip. If you think you might end up needing more memory, you should go for the spec upgrade up front. Storage capacity (SSD) Storage options range from 256GB of SSD for the base-model MacBook Air and 8TB of storage for the MacBook Pros with the M4 Max chip. If you want to rotate between a long roster of game titles or keep lots of high-res videos on hand, you’ll want more storage. If you’re mostly working with browser- and cloud-based applications, you can get away with a smaller-capacity configuration. That said, we recommend springing for 512GB of storage or more, if it’s within your budget. You’ll quickly feel the limits of a 256GB machine as it ages since the operating system alone takes up a good portion of that space. Having 1TB will feel even roomier and allow for more data storage over the life of your laptop. When Apple announced the iPhone 15, the company also announced new iCloud+ storage storage plans, with subscriptions that allow up to 12TB of storage shared among your iOS and MacOS devices. You could also transfer files to an external storage device. But if you don’t want to pay for a monthly subscription and prefer the convenience of having immediate access to your files, it’s best to get the highest amount of storage space your budget allows for at the outset. Screen size The MacBook Air comes in 13- or 15-inch sizes. Pro models have either 14- or 16-inch screens. A two-inch delta may not seem like much but, as Engadget’s Nathan Ingraham noted when he reviewed the then-new 15-inch M2-powered MacBook Air, a larger screen \"makes a surprising difference.” That’s especially true if you plan to use your laptop as an all-day productivity machine and won’t be using an external monitor. More space means you can more clearly view side-by-side windows and have a more immersive experience when watching shows or gaming. But screen size is one of the main factors influencing weight. The 13-inch MacBook Air M4 weighs 2.7 pounds, whereas the top-end 16-inch MacBook Pro with the Max chip weighs 4.7 pounds. If you plan to travel a lot or swap your work locations regularly, a smaller screen will make life easier in the long run. All MacBooks feature IPS LCD panels (in-plane switching, liquid crystal display), which Apple markets as Retina displays. The MacBook Air M4 has a Liquid Retina display and the Pro models have Liquid Retina XDR displays. “Liquid” refers to the way the lighted portion of the display “flows” within the contours of the screen, filling the rounded corners and curving around the camera notch. “XDR” is what Apple calls HDR (high dynamic range). You also get the option of a standard or nano-texture display on the MacBook Pro. The glass, which reduces glare and is also available on the Studio Display, iMac and iPad Pro, comes with a $150 price increase, but if you really don’t like reflections on your screen, it could be worth it. Compared to most other laptops, MacBook displays are notably bright, sharp and lush. But one feature worth pointing out is another Apple marketing term: ProMotion. It’s the company’s term to describe a screen with a higher, 120Hz refresh rate, which results in smoother scrolling and more fluid-looking graphics. Only MacBook Pros offer ProMotion; the Air maxes out at 60Hz, which is perfectly fine for everyday browsing and typical workdays. But if you want buttery-smooth motion from your display, you’ll have to shell out more money for an upgrade. Operating systems Software considerations won’t make much of a difference when deciding between MacBook models — all come with macOS installed. But if you’re switching from, say, a Windows PC, the operating system may be something to factor into your decision — though it’s probably less of an issue than it once was. Now that so much of the work we do on our computers is browser- and cloud-based, the learning curve between the two platforms isn’t as steep. Apps and programs like Gmail perform similarly regardless of what computer you’re using. Apple machines have historically had more limited support of AAA gaming titles, but even that is changing with more AAA games and better graphics coming to Macs. As for macOS, it’s getting better too. With macOS Tahoe 26, the Spotlight function is more advanced, making it easier to find apps and perform tasks straight from your keyboard. The software also implements Apple's unifying Liquid Glass design for a modern look that looks consistent across iOS and iPad devices. New enhanced iPhone continuity features also make MacBooks and the handset work better together. A revamped Shortcuts app is more powerful as well, giving users custom automations that leverage Apple Intelligence (the company’s own AI). Price When Apple announced the MacBook Air M4, it also delivered a bit of refreshing news: The latest model now starts $100 cheaper than the previous generation. So now, the least expensive MacBook is the 13-inch, M4-powered Air with 16GB of RAM and 256GB of storage for $999. Alternatively, you can spend up to $7,349 for the 16-inch MacBook Pro M4 Max with the nano-texture glass, 128GB of RAM and 8TB of storage. Chip type, screen size, memory and storage capacity all influence the final price, which is why guides like this can help you determine just what you need (and what you don’t) so you can get the most cost-effective machine for you. AppleCare is another cost to consider. The extended warranty plan from Apple covers repairs from accidents and offers free battery replacement and starts at $3.50 per month or $35 per year for MacBooks. We recommend the MacBook Air M4 for most people, and thanks to that $100 price cut, it’s also a good budget option. If you want something even cheaper, we recommend looking at refurbished M-series models from Apple. We think the 14- or 16-inch MacBook Pros are best for professionals. If you have extra money to spare once you’ve picked your machine, we recommend upgrading to at least 512GB of storage to make your machine as future-proof as possible. Of course, if you're just after the M4 chip and want the cheapest route to get it, you might consider the M4 Mac mini, which starts at $599 (though you'll have to supply the screen, mouse and keyboard). Best MacBooks spec comparison chart Product Superlative Tested configuration Tested battery life Rated battery life Apple MacBook Air M4 (13-inch) Best MacBook overall Apple M4, 16GB RAM, 256GB SSD 18.25 hours Up to 18 hours Apple MacBook Pro M4 (14-inch) Best MacBook for creatives Apple M4, 16GB RAM, 512GB SSD 34.25 hours Up to 22 hours Best MacBook FAQs What's the difference between MacBook Air and Pro? Both the MacBook Air and Pro models come with the M4 chip. MBP models have the option of more powerful M4 Pro or M4 Max chips. The Pro has a higher resolution screen with a higher peak brightness that supports up to 120Hz adaptive refresh rates and XDR (extreme dynamic range). The battery life on most Pro models is longer than on the Air models as well. Pro models also have more ports and more speakers. In short, the MacBook Air is aimed at everyday users looking for good productivity and entertainment capabilities, while Pro models are aimed at professionals who need a high-performance computer. What's the difference between macOS and Windows? MacOS is the operating system developed by Apple and used in all of its desktop and laptop computers. It can only be found in hardware made by Apple including MacBooks and iMacs. Microsoft’s Windows operating system can be found in the company’s own Surface laptops as well as computers made by a wide array of manufacturers, like Acer, Asus, Dell and Razer.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-macbook-140032524.html?src=rss",
          "content": "There wasn’t much Mac-related news at Apple’s latest to-do (to be expected at an iPhone event), aside from the announcement that macOS 26 would be available to the public on September 15. Historically, we’ve seen new Mac hardware in October and then again in spring. But as of right now, there are just two MacBooks in Apple’s lineup: MacBook Air models with the M4 chip and MacBook Pro models with the M4 chip. Within those two options lie a handful of choices, including chip type, screen size, storage capacity and more. This guide will help you suss out the Apple terminology and explain the options so you can pick the best MacBook configuration for your needs. Table of contents Best MacBooks for 2025 What about budget MacBooks? Factors to consider when buying a MacBook MacBooks specs comparison chart Best MacBook FAQs Best MacBooks for 2025 What about budget MacBooks? Historically, Apple kept the previous year’s MacBook Air in its lineup as a sort of budget option. But the company took a different approach with the release of the M4 MacBook Air. Instead of continuing to sell the older model, Apple discontinued the M3 Air and gave its newest computer a $100 price cut. Now, if you can even find a brand new M3 MacBook Air (typically from retailers like Amazon or B&H), it’s often more expensive than the M4 version. During sales like Amazon Prime Day, we’ve seen the newest M4 Air go for as little as $799. That effectively makes our overall pick a budget pick as well. Of course, $800 isn’t exactly a small investment either for college students or others on a budget. Especially when you can find some decent PCs for under $500. If you’re looking to save even more on a MacBook, we recommend checking out refurbished options directly from Apple, or even third party sellers like BackMarket. There are a few guidelines to keep in mind, which we go over in our refurbished guide, but mainly, you’ll want to shop from a reputable source that has a stated process and offers at least a year-long warranty. Using your old gear as a trade-in will bring down your final cost as well. Factors to consider when buying a MacBook Compared to PCs, Apple computers tend to have more streamlined specifications. The company has long been known for this simplicity, and the M-series “system-on-a-chip” condenses things even further. Prior to the M1 chip, Apple used Intel chips in its laptop and desktop computers. The M2 and M3 generations followed that first chip and currently sells MacBooks equipped with M4-series chips. You’ll find the standard M4 processor in the Air and the base-model Pro and the upgraded M4 Max and M4 Pro chips as options for the MacBook Pro (currently there is no M4 Ultra chip, as there was with the M3 series in the Mac Studio). All M-series chips combine, among other technologies, the CPU, graphics card and unified memory (RAM). Apple’s Neural Engine is included too, which is a specialized group of processor cores that handles machine learning tasks such as image analysis and voice recognition. While a unified chip means you have fewer decisions to make when picking a MacBook, there are still a few factors to consider, including specs like the number of CPU cores, amount of RAM, storage capacity, screen size, and, obviously, price. The finish color may be a minor consideration, but it's worth pointing out that the Pro comes in just two colors (Silver or Space Black) but the Air comes in four hues (Midnight, Starlight, Sky Blue and Silver). CPU cores The lowest-specced chip in a current-lineup MacBook is the standard M4 chip, which is found in all models of the MacBook Air and the base model MacBook Pro 14-inch. That chip houses a 10-core CPU and either an 8- or 10-core GPU. In total, there are three versions of the M4 chip: standard M4, M4 Pro and M4 Max (which are each a step up from their predecessors, the M3, M3 Pro and M3 Max chips). The burliest chip, the M4 Max is built with either a 14- or 16-core CPU and a 32- or 40-core GPU. Cores are, in essence, smaller processing units that can handle different tasks simultaneously. Having more of them translates to the computer being able to run multiple programs and applications at once, while also smoothly processing demanding tasks like video and photo editing and high-level gaming. In short, more cores allow for more advanced computing and better performance. But if your processing power needs fall below professional-level gaming and cinematic video and audio editing, getting the highest number of cores is likely overkill — and after all, more cores equals higher cost and more power usage. Photo by Devindra Hardawar/Engadget RAM Your options for RAM, or in Apple’s terminology, unified memory, varies, but with the switch to the M4 chip in all laptops, the lowest amount of RAM you can get is now 16GB. That’s a necessary spec-bump to accommodate the tech world’s favorite feature of the moment: AI or, in this case, Apple Intelligence (still AI, but Cupertino’s version). The M4 Pro chip has 24 or 48GB memory options, while the M4 Max chip supports 48, 64 or a whopping 128GB of RAM. You’ve likely heard the analogy comparing memory to the amount of workspace available on a literal desktop surface, whereas storage is the amount of drawers you have to store projects to work on later. The larger the worktop surface, the more projects you can work on at once. The bigger the drawers, the more you can save for later. In addition to supporting Apple Intelligence, more RAM is ideal for people who plan to work in multiple apps at once. And the more demanding each program is, the more RAM will be required. Extra memory can also come in handy if you’re the type who likes to have infinite numbers of tabs open on your browser. If your daily workflow doesn’t involve simultaneously using a vast number of memory-intensive programs, you can save yourself money and buy the RAM configuration that you’re most likely to actually use. For a long time, Apple continued to offer MacBooks with just 8GB of RAM, and we recommended upgrading to at least 16GB of RAM. With this being the standard today, grabbing a base model should be fine for most non-pro-level users. One thing to note is that, unlike most PCs, the RAM in a MacBook is not user-upgradable since it’s tied into the system-on-a-chip. If you think you might end up needing more memory, you should go for the spec upgrade up front. Storage capacity (SSD) Storage options range from 256GB of SSD for the base-model MacBook Air and 8TB of storage for the MacBook Pros with the M4 Max chip. If you want to rotate between a long roster of game titles or keep lots of high-res videos on hand, you’ll want more storage. If you’re mostly working with browser- and cloud-based applications, you can get away with a smaller-capacity configuration. That said, we recommend springing for 512GB of storage or more, if it’s within your budget. You’ll quickly feel the limits of a 256GB machine as it ages since the operating system alone takes up a good portion of that space. Having 1TB will feel even roomier and allow for more data storage over the life of your laptop. When Apple announced the iPhone 15, the company also announced new iCloud+ storage storage plans, with subscriptions that allow up to 12TB of storage shared among your iOS and MacOS devices. You could also transfer files to an external storage device. But if you don’t want to pay for a monthly subscription and prefer the convenience of having immediate access to your files, it’s best to get the highest amount of storage space your budget allows for at the outset. Screen size The MacBook Air comes in 13- or 15-inch sizes. Pro models have either 14- or 16-inch screens. A two-inch delta may not seem like much but, as Engadget’s Nathan Ingraham noted when he reviewed the then-new 15-inch M2-powered MacBook Air, a larger screen \"makes a surprising difference.” That’s especially true if you plan to use your laptop as an all-day productivity machine and won’t be using an external monitor. More space means you can more clearly view side-by-side windows and have a more immersive experience when watching shows or gaming. But screen size is one of the main factors influencing weight. The 13-inch MacBook Air M4 weighs 2.7 pounds, whereas the top-end 16-inch MacBook Pro with the Max chip weighs 4.7 pounds. If you plan to travel a lot or swap your work locations regularly, a smaller screen will make life easier in the long run. All MacBooks feature IPS LCD panels (in-plane switching, liquid crystal display), which Apple markets as Retina displays. The MacBook Air M4 has a Liquid Retina display and the Pro models have Liquid Retina XDR displays. “Liquid” refers to the way the lighted portion of the display “flows” within the contours of the screen, filling the rounded corners and curving around the camera notch. “XDR” is what Apple calls HDR (high dynamic range). You also get the option of a standard or nano-texture display on the MacBook Pro. The glass, which reduces glare and is also available on the Studio Display, iMac and iPad Pro, comes with a $150 price increase, but if you really don’t like reflections on your screen, it could be worth it. Compared to most other laptops, MacBook displays are notably bright, sharp and lush. But one feature worth pointing out is another Apple marketing term: ProMotion. It’s the company’s term to describe a screen with a higher, 120Hz refresh rate, which results in smoother scrolling and more fluid-looking graphics. Only MacBook Pros offer ProMotion; the Air maxes out at 60Hz, which is perfectly fine for everyday browsing and typical workdays. But if you want buttery-smooth motion from your display, you’ll have to shell out more money for an upgrade. Operating systems Software considerations won’t make much of a difference when deciding between MacBook models — all come with macOS installed. But if you’re switching from, say, a Windows PC, the operating system may be something to factor into your decision — though it’s probably less of an issue than it once was. Now that so much of the work we do on our computers is browser- and cloud-based, the learning curve between the two platforms isn’t as steep. Apps and programs like Gmail perform similarly regardless of what computer you’re using. Apple machines have historically had more limited support of AAA gaming titles, but even that is changing with more AAA games and better graphics coming to Macs. As for macOS, it’s getting better too. With macOS Tahoe 26, the Spotlight function is more advanced, making it easier to find apps and perform tasks straight from your keyboard. The software also implements Apple's unifying Liquid Glass design for a modern look that looks consistent across iOS and iPad devices. New enhanced iPhone continuity features also make MacBooks and the handset work better together. A revamped Shortcuts app is more powerful as well, giving users custom automations that leverage Apple Intelligence (the company’s own AI). Price When Apple announced the MacBook Air M4, it also delivered a bit of refreshing news: The latest model now starts $100 cheaper than the previous generation. So now, the least expensive MacBook is the 13-inch, M4-powered Air with 16GB of RAM and 256GB of storage for $999. Alternatively, you can spend up to $7,349 for the 16-inch MacBook Pro M4 Max with the nano-texture glass, 128GB of RAM and 8TB of storage. Chip type, screen size, memory and storage capacity all influence the final price, which is why guides like this can help you determine just what you need (and what you don’t) so you can get the most cost-effective machine for you. AppleCare is another cost to consider. The extended warranty plan from Apple covers repairs from accidents and offers free battery replacement and starts at $3.50 per month or $35 per year for MacBooks. We recommend the MacBook Air M4 for most people, and thanks to that $100 price cut, it’s also a good budget option. If you want something even cheaper, we recommend looking at refurbished M-series models from Apple. We think the 14- or 16-inch MacBook Pros are best for professionals. If you have extra money to spare once you’ve picked your machine, we recommend upgrading to at least 512GB of storage to make your machine as future-proof as possible. Of course, if you're just after the M4 chip and want the cheapest route to get it, you might consider the M4 Mac mini, which starts at $599 (though you'll have to supply the screen, mouse and keyboard). Best MacBooks spec comparison chart Product Superlative Tested configuration Tested battery life Rated battery life Apple MacBook Air M4 (13-inch) Best MacBook overall Apple M4, 16GB RAM, 256GB SSD 18.25 hours Up to 18 hours Apple MacBook Pro M4 (14-inch) Best MacBook for creatives Apple M4, 16GB RAM, 512GB SSD 34.25 hours Up to 22 hours Best MacBook FAQs What's the difference between MacBook Air and Pro? Both the MacBook Air and Pro models come with the M4 chip. MBP models have the option of more powerful M4 Pro or M4 Max chips. The Pro has a higher resolution screen with a higher peak brightness that supports up to 120Hz adaptive refresh rates and XDR (extreme dynamic range). The battery life on most Pro models is longer than on the Air models as well. Pro models also have more ports and more speakers. In short, the MacBook Air is aimed at everyday users looking for good productivity and entertainment capabilities, while Pro models are aimed at professionals who need a high-performance computer. What's the difference between macOS and Windows? MacOS is the operating system developed by Apple and used in all of its desktop and laptop computers. It can only be found in hardware made by Apple including MacBooks and iMacs. Microsoft’s Windows operating system can be found in the company’s own Surface laptops as well as computers made by a wide array of manufacturers, like Acer, Asus, Dell and Razer.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-macbook-140032524.html?src=rss",
          "feed_position": 23,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-11/e536a1d0-7c1e-11ee-9e77-9ea8e142b078"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/visa-just-launched-a-protocol-to-secure-the-ai-shopping-boom-heres-what-it",
          "published_at": "Tue, 14 Oct 2025 07:00:00 GMT",
          "title": "Visa just launched a protocol to secure the AI shopping boom — here’s what it means for merchants",
          "standfirst": "Visa is introducing a new security framework designed to solve one of the thorniest problems emerging in artificial intelligence-powered commerce: how retailers can tell the difference between legitimate AI shopping assistants and the malicious bots that plague their websites.The payments giant unveiled its Trusted Agent Protocol on Tuesday, establishing what it describes as foundational infrastructure for \"agentic commerce\" — a term for the rapidly growing practice of consumers delegating shopping tasks to AI agents that can search products, compare prices, and complete purchases autonomously.The protocol enables merchants to cryptographically verify that an AI agent browsing their site is authorized and trustworthy, rather than a bot designed to scrape pricing data, test stolen credit cards, or carry out other fraudulent activities.The launch comes as AI-driven traffic to U.S. retail websites has exploded by more than 4,700% over the past year, according to data from Adobe cited by Visa. That dramatic surge has created an acute challenge for merchants whose existing bot detection systems — designed to block automated traffic — now risk accidentally blocking legitimate AI shoppers along with bad actors.\"Merchants need additional tools that provide them with greater insight and transparency into agentic commerce activities to ensure they can participate safely,\" said Rubail Birwadker, Visa&#x27;s Global Head of Growth, in an exclusive interview with VentureBeat. \"Without common standards, potential risks include ecosystem fragmentation and the proliferation of closed loop models.\"The stakes are substantial. While 85% of shoppers who have used AI to shop report improved experiences, merchants face the prospect of either turning away legitimate AI-powered customers or exposing themselves to sophisticated bot attacks. Visa&#x27;s own data shows the company prevented $40 billion in fraudulent activity between October 2022 and September 2023, nearly double the previous year, much of it involving AI-powered enumeration attacks where bots systematically test combinations of card numbers until finding valid credentials.Inside the cryptographic handshake: How Visa verifies AI shopping agentsVisa&#x27;s Trusted Agent Protocol operates through what Birwadker describes as a \"cryptographic trust handshake\" between merchants and approved AI agents. The system works in three steps:First, AI agents must be approved and onboarded through Visa&#x27;s Intelligent Commerce program, where they undergo vetting to meet trust and reliability standards. Each approved agent receives a unique digital signature key — essentially a cryptographic credential that proves its identity.When an approved agent visits a merchant&#x27;s website, it creates a digital signature using its key and transmits three categories of information: Agent Intent (indicating the agent is trusted and intends to retrieve product details or make a purchase), Consumer Recognition (data showing whether the underlying consumer has an existing account with the merchant), and Payment Information (optional payment data to support checkout).Merchants or their infrastructure providers, such as content delivery networks, then validate these digital signatures against Visa&#x27;s registry of approved agents. \"Upon proper validation of these fields, the merchant can confirm the signature is a trusted agent,\" Birwadker explained.Crucially, Visa designed the protocol to require minimal changes to existing merchant infrastructure. Built on the HTTP Message Signature standard and aligned with Web Both Auth, the protocol works with existing web infrastructure without requiring merchants to overhaul their checkout pages. \"This is no-code functionality,\" Birwadker emphasized, though merchants may need to integrate with Visa&#x27;s Developer Center to access the verification system.The race for AI commerce standards: Visa faces competition from Google, OpenAI, and StripeVisa developed the protocol in collaboration with Cloudflare, the web infrastructure and security company that already provides bot management services to millions of websites. The partnership reflects Visa&#x27;s recognition that solving bot verification requires cooperation across the entire web stack, not just the payments layer.\"Trusted Agent Protocol supplements traditional bot management by providing merchants insights that enable agentic commerce,\" Birwadker said. \"Agents are providing additional context they otherwise would not, including what it intends to do, who the underlying consumer is, and payment information.\"The protocol arrives as multiple technology giants race to establish competing standards for AI commerce. Google recently introduced its Agent Protocol for Payments (AP2), while OpenAI and Stripe have discussed their own approaches to enabling AI agents to make purchases. Microsoft, Shopify, Adyen, Ant International, Checkout.com, Cybersource, Elavon, Fiserv, Nuvei, and Worldpay provided feedback during Trusted Agent Protocol&#x27;s development, according to Visa.When asked how Visa&#x27;s protocol relates to these competing efforts, Birwadker struck a collaborative tone. \"Both Google&#x27;s AP2 and Visa&#x27;s Trusted Agent Protocol are working toward the same goal of building trust in agent-initiated payments,\" he said. \"We are engaged with Google, OpenAI, and Stripe and are looking to create compatibility across the ecosystem.\"Visa says it is working with global standards bodies including the Internet Engineering Task Force (IETF), OpenID Foundation, and EMVCo to ensure the protocol can eventually become interoperable with other emerging standards. \"While these specifications apply to the Visa network in this initial phase, enabling agents to safely and securely act on a consumer&#x27;s behalf requires an open, ecosystem-wide approach,\" Birwadker noted.Who pays when AI agents go rogue? Unanswered questions about liability and authorizationThe protocol raises important questions about authorization and liability when AI agents make purchases on behalf of consumers. If an agent completes an unauthorized transaction — perhaps misunderstanding a user&#x27;s intent or exceeding its delegated authority — who bears responsibility?Birwadker emphasized that the protocol helps merchants \"leverage this information to enable experiences tied to existing consumer relationships and more secure checkout,\" but he did not provide specific details about how disputes would be handled when agents make unauthorized purchases. Visa&#x27;s existing fraud protection and chargeback systems would presumably apply, though the company has not yet published detailed guidance on agent-initiated transaction disputes.The protocol also places Visa in the position of gatekeeper for the emerging agentic commerce ecosystem. Because Visa determines which AI agents get approved for the Intelligent Commerce program and receive cryptographic credentials, the company effectively controls which agents merchants can easily trust. \"Agents are approved and onboarded through the Visa Intelligent Commerce program, ensuring they meet our standards for trust and reliability,\" Birwadker said, though he did not detail the specific criteria agents must meet or whether Visa charges fees for approval.This gatekeeping role could prove contentious, particularly if Visa&#x27;s approval process favors large technology companies over startups, or if the company faces pressure to block agents from competitors or politically controversial entities. Visa declined to provide details about how many agents it has approved so far or how long the vetting process typically takes.Visa&#x27;s legal battles and the long road to merchant adoptionThe protocol launch comes at a complex moment for Visa, which continues to navigate significant legal and regulatory challenges even as its core business remains robust. The company&#x27;s latest earnings report for the third quarter of fiscal year 2025 showed a 10% increase in net revenues to $9.2 billion, driven by resilient consumer spending and strong growth in cross-border transaction volume. For the full fiscal year ending September 30, 2024, Visa processed 289 billion transactions, with a total payments volume of $15.2 trillion. However, the company&#x27;s legal headwinds have intensified. In July 2025, a federal judge rejected a landmark $30 billion settlement that Visa and Mastercard had reached with merchants over long-disputed credit card swipe fees, sending the parties back to the negotiating table and extending the long-running legal battle.Simultaneously, Visa remains under investigation by the Department of Justice over its rules for routing debit card transactions, with regulators scrutinizing whether the company&#x27;s practices unlawfully limit merchant choice and stifle competition. These domestic challenges are mirrored abroad, where European regulators have continued their own antitrust investigations into the fee structures of both Visa and its primary competitor, Mastercard.Against this backdrop of regulatory pressure, Birwadker acknowledged that adoption of the Trusted Agent Protocol will take time. \"As agentic commerce continues to rise, we recognize that consumer trust is still in its early stages,\" he said. \"That&#x27;s why our focus through 2025 is on building foundational credibility and demonstrating real-world value.\"The protocol is available immediately in Visa&#x27;s Developer Center and on GitHub, with agent onboarding already active and merchant integration resources available. But Birwadker declined to provide specific targets for how many merchants might adopt the protocol by the end of 2026. \"Adoption is aligned with the momentum we&#x27;re already seeing,\" he said. \"The launch of our protocol marks another big step — it&#x27;s not just a technical milestone, but a signal that the industry is beginning to unify.\"Industry analysts say merchant adoption will likely depend on how quickly agentic commerce grows as a percentage of overall e-commerce. While AI-driven traffic has surged dramatically, much of that consists of agents browsing and researching rather than completing purchases. If AI agents begin accounting for a significant share of completed transactions, merchants will face stronger incentives to adopt verification systems like Visa&#x27;s protocol.From fraud detection to AI gatekeeping: Visa&#x27;s $10 billion bet on artificial intelligenceVisa&#x27;s move reflects broader strategic bets on AI across the financial services industry. The company has invested $10 billion in technology over the past five years to reduce fraud and increase network security, with AI and machine learning central to those efforts. Visa&#x27;s fraud detection system analyzes over 500 different attributes for each transaction, using AI models to assign real-time risk scores to the 300 billion annual transactions flowing through its network.\"Every single one of those transactions has been processed by AI,\" James Mirfin, Visa&#x27;s global head of risk and identity solutions, said in a July 2024 CNBC interview discussing the company&#x27;s fraud prevention efforts. \"If you see a new type of fraud happening, our model will see that, it will catch it, it will score those transactions as high risk and then our customers can decide not to approve those transactions.\"The company has also moved aggressively into new payment territories beyond its core card business. In January 2025, Visa partnered with Elon Musk&#x27;s X (formerly Twitter) to provide the infrastructure for a digital wallet and peer-to-peer payment service called the X Money Account, competing with services like Venmo and Zelle. That deal marked Visa&#x27;s first major partnership in the social media payments space and reflected the company&#x27;s recognition that payment flows are increasingly happening outside traditional e-commerce channels.The agentic commerce protocol represents an extension of this strategy — an attempt to ensure Visa remains central to payment flows even as the mechanics of shopping shift from direct human interaction to AI intermediation. Jack Forestell, Visa&#x27;s Chief Product & Strategy Officer, framed the protocol in expansive terms: \"We believe the entire payments ecosystem has a responsibility to ensure sellers trust AI agents with the same confidence they place in their most valued customers and networks.\"The coming battle for control of AI shoppingThe real test for Visa&#x27;s protocol won&#x27;t be technical — it will be political. As AI agents become a larger force in retail, whoever controls the verification infrastructure controls access to hundreds of billions of dollars in commerce. Visa&#x27;s position as gatekeeper gives it enormous leverage, but also makes it a target.Merchants chafing under Visa&#x27;s existing fee structure and facing multiple antitrust investigations may resist ceding even more power to the payments giant. Competitors like Google and OpenAI, each with their own ambitions in commerce, have little incentive to let Visa dictate standards. Regulators already scrutinizing Visa&#x27;s market dominance will surely examine whether its agent approval process unfairly advantages certain players.And there&#x27;s a deeper question lurking beneath the technical specifications and corporate partnerships: In an economy increasingly mediated by AI, who decides which algorithms get to spend our money? Visa is making an aggressive bid to be that arbiter, wrapping its answer in the language of security and interoperability. Whether merchants, consumers, and regulators accept that proposition will determine not just the fate of the Trusted Agent Protocol, but the structure of AI-powered commerce itself.For now, Visa is moving forward with the confidence of a company that has weathered disruption before. But in the emerging world of agentic commerce, being too trusted might prove just as dangerous as not being trusted enough.",
          "content": "Visa is introducing a new security framework designed to solve one of the thorniest problems emerging in artificial intelligence-powered commerce: how retailers can tell the difference between legitimate AI shopping assistants and the malicious bots that plague their websites.The payments giant unveiled its Trusted Agent Protocol on Tuesday, establishing what it describes as foundational infrastructure for \"agentic commerce\" — a term for the rapidly growing practice of consumers delegating shopping tasks to AI agents that can search products, compare prices, and complete purchases autonomously.The protocol enables merchants to cryptographically verify that an AI agent browsing their site is authorized and trustworthy, rather than a bot designed to scrape pricing data, test stolen credit cards, or carry out other fraudulent activities.The launch comes as AI-driven traffic to U.S. retail websites has exploded by more than 4,700% over the past year, according to data from Adobe cited by Visa. That dramatic surge has created an acute challenge for merchants whose existing bot detection systems — designed to block automated traffic — now risk accidentally blocking legitimate AI shoppers along with bad actors.\"Merchants need additional tools that provide them with greater insight and transparency into agentic commerce activities to ensure they can participate safely,\" said Rubail Birwadker, Visa&#x27;s Global Head of Growth, in an exclusive interview with VentureBeat. \"Without common standards, potential risks include ecosystem fragmentation and the proliferation of closed loop models.\"The stakes are substantial. While 85% of shoppers who have used AI to shop report improved experiences, merchants face the prospect of either turning away legitimate AI-powered customers or exposing themselves to sophisticated bot attacks. Visa&#x27;s own data shows the company prevented $40 billion in fraudulent activity between October 2022 and September 2023, nearly double the previous year, much of it involving AI-powered enumeration attacks where bots systematically test combinations of card numbers until finding valid credentials.Inside the cryptographic handshake: How Visa verifies AI shopping agentsVisa&#x27;s Trusted Agent Protocol operates through what Birwadker describes as a \"cryptographic trust handshake\" between merchants and approved AI agents. The system works in three steps:First, AI agents must be approved and onboarded through Visa&#x27;s Intelligent Commerce program, where they undergo vetting to meet trust and reliability standards. Each approved agent receives a unique digital signature key — essentially a cryptographic credential that proves its identity.When an approved agent visits a merchant&#x27;s website, it creates a digital signature using its key and transmits three categories of information: Agent Intent (indicating the agent is trusted and intends to retrieve product details or make a purchase), Consumer Recognition (data showing whether the underlying consumer has an existing account with the merchant), and Payment Information (optional payment data to support checkout).Merchants or their infrastructure providers, such as content delivery networks, then validate these digital signatures against Visa&#x27;s registry of approved agents. \"Upon proper validation of these fields, the merchant can confirm the signature is a trusted agent,\" Birwadker explained.Crucially, Visa designed the protocol to require minimal changes to existing merchant infrastructure. Built on the HTTP Message Signature standard and aligned with Web Both Auth, the protocol works with existing web infrastructure without requiring merchants to overhaul their checkout pages. \"This is no-code functionality,\" Birwadker emphasized, though merchants may need to integrate with Visa&#x27;s Developer Center to access the verification system.The race for AI commerce standards: Visa faces competition from Google, OpenAI, and StripeVisa developed the protocol in collaboration with Cloudflare, the web infrastructure and security company that already provides bot management services to millions of websites. The partnership reflects Visa&#x27;s recognition that solving bot verification requires cooperation across the entire web stack, not just the payments layer.\"Trusted Agent Protocol supplements traditional bot management by providing merchants insights that enable agentic commerce,\" Birwadker said. \"Agents are providing additional context they otherwise would not, including what it intends to do, who the underlying consumer is, and payment information.\"The protocol arrives as multiple technology giants race to establish competing standards for AI commerce. Google recently introduced its Agent Protocol for Payments (AP2), while OpenAI and Stripe have discussed their own approaches to enabling AI agents to make purchases. Microsoft, Shopify, Adyen, Ant International, Checkout.com, Cybersource, Elavon, Fiserv, Nuvei, and Worldpay provided feedback during Trusted Agent Protocol&#x27;s development, according to Visa.When asked how Visa&#x27;s protocol relates to these competing efforts, Birwadker struck a collaborative tone. \"Both Google&#x27;s AP2 and Visa&#x27;s Trusted Agent Protocol are working toward the same goal of building trust in agent-initiated payments,\" he said. \"We are engaged with Google, OpenAI, and Stripe and are looking to create compatibility across the ecosystem.\"Visa says it is working with global standards bodies including the Internet Engineering Task Force (IETF), OpenID Foundation, and EMVCo to ensure the protocol can eventually become interoperable with other emerging standards. \"While these specifications apply to the Visa network in this initial phase, enabling agents to safely and securely act on a consumer&#x27;s behalf requires an open, ecosystem-wide approach,\" Birwadker noted.Who pays when AI agents go rogue? Unanswered questions about liability and authorizationThe protocol raises important questions about authorization and liability when AI agents make purchases on behalf of consumers. If an agent completes an unauthorized transaction — perhaps misunderstanding a user&#x27;s intent or exceeding its delegated authority — who bears responsibility?Birwadker emphasized that the protocol helps merchants \"leverage this information to enable experiences tied to existing consumer relationships and more secure checkout,\" but he did not provide specific details about how disputes would be handled when agents make unauthorized purchases. Visa&#x27;s existing fraud protection and chargeback systems would presumably apply, though the company has not yet published detailed guidance on agent-initiated transaction disputes.The protocol also places Visa in the position of gatekeeper for the emerging agentic commerce ecosystem. Because Visa determines which AI agents get approved for the Intelligent Commerce program and receive cryptographic credentials, the company effectively controls which agents merchants can easily trust. \"Agents are approved and onboarded through the Visa Intelligent Commerce program, ensuring they meet our standards for trust and reliability,\" Birwadker said, though he did not detail the specific criteria agents must meet or whether Visa charges fees for approval.This gatekeeping role could prove contentious, particularly if Visa&#x27;s approval process favors large technology companies over startups, or if the company faces pressure to block agents from competitors or politically controversial entities. Visa declined to provide details about how many agents it has approved so far or how long the vetting process typically takes.Visa&#x27;s legal battles and the long road to merchant adoptionThe protocol launch comes at a complex moment for Visa, which continues to navigate significant legal and regulatory challenges even as its core business remains robust. The company&#x27;s latest earnings report for the third quarter of fiscal year 2025 showed a 10% increase in net revenues to $9.2 billion, driven by resilient consumer spending and strong growth in cross-border transaction volume. For the full fiscal year ending September 30, 2024, Visa processed 289 billion transactions, with a total payments volume of $15.2 trillion. However, the company&#x27;s legal headwinds have intensified. In July 2025, a federal judge rejected a landmark $30 billion settlement that Visa and Mastercard had reached with merchants over long-disputed credit card swipe fees, sending the parties back to the negotiating table and extending the long-running legal battle.Simultaneously, Visa remains under investigation by the Department of Justice over its rules for routing debit card transactions, with regulators scrutinizing whether the company&#x27;s practices unlawfully limit merchant choice and stifle competition. These domestic challenges are mirrored abroad, where European regulators have continued their own antitrust investigations into the fee structures of both Visa and its primary competitor, Mastercard.Against this backdrop of regulatory pressure, Birwadker acknowledged that adoption of the Trusted Agent Protocol will take time. \"As agentic commerce continues to rise, we recognize that consumer trust is still in its early stages,\" he said. \"That&#x27;s why our focus through 2025 is on building foundational credibility and demonstrating real-world value.\"The protocol is available immediately in Visa&#x27;s Developer Center and on GitHub, with agent onboarding already active and merchant integration resources available. But Birwadker declined to provide specific targets for how many merchants might adopt the protocol by the end of 2026. \"Adoption is aligned with the momentum we&#x27;re already seeing,\" he said. \"The launch of our protocol marks another big step — it&#x27;s not just a technical milestone, but a signal that the industry is beginning to unify.\"Industry analysts say merchant adoption will likely depend on how quickly agentic commerce grows as a percentage of overall e-commerce. While AI-driven traffic has surged dramatically, much of that consists of agents browsing and researching rather than completing purchases. If AI agents begin accounting for a significant share of completed transactions, merchants will face stronger incentives to adopt verification systems like Visa&#x27;s protocol.From fraud detection to AI gatekeeping: Visa&#x27;s $10 billion bet on artificial intelligenceVisa&#x27;s move reflects broader strategic bets on AI across the financial services industry. The company has invested $10 billion in technology over the past five years to reduce fraud and increase network security, with AI and machine learning central to those efforts. Visa&#x27;s fraud detection system analyzes over 500 different attributes for each transaction, using AI models to assign real-time risk scores to the 300 billion annual transactions flowing through its network.\"Every single one of those transactions has been processed by AI,\" James Mirfin, Visa&#x27;s global head of risk and identity solutions, said in a July 2024 CNBC interview discussing the company&#x27;s fraud prevention efforts. \"If you see a new type of fraud happening, our model will see that, it will catch it, it will score those transactions as high risk and then our customers can decide not to approve those transactions.\"The company has also moved aggressively into new payment territories beyond its core card business. In January 2025, Visa partnered with Elon Musk&#x27;s X (formerly Twitter) to provide the infrastructure for a digital wallet and peer-to-peer payment service called the X Money Account, competing with services like Venmo and Zelle. That deal marked Visa&#x27;s first major partnership in the social media payments space and reflected the company&#x27;s recognition that payment flows are increasingly happening outside traditional e-commerce channels.The agentic commerce protocol represents an extension of this strategy — an attempt to ensure Visa remains central to payment flows even as the mechanics of shopping shift from direct human interaction to AI intermediation. Jack Forestell, Visa&#x27;s Chief Product & Strategy Officer, framed the protocol in expansive terms: \"We believe the entire payments ecosystem has a responsibility to ensure sellers trust AI agents with the same confidence they place in their most valued customers and networks.\"The coming battle for control of AI shoppingThe real test for Visa&#x27;s protocol won&#x27;t be technical — it will be political. As AI agents become a larger force in retail, whoever controls the verification infrastructure controls access to hundreds of billions of dollars in commerce. Visa&#x27;s position as gatekeeper gives it enormous leverage, but also makes it a target.Merchants chafing under Visa&#x27;s existing fee structure and facing multiple antitrust investigations may resist ceding even more power to the payments giant. Competitors like Google and OpenAI, each with their own ambitions in commerce, have little incentive to let Visa dictate standards. Regulators already scrutinizing Visa&#x27;s market dominance will surely examine whether its agent approval process unfairly advantages certain players.And there&#x27;s a deeper question lurking beneath the technical specifications and corporate partnerships: In an economy increasingly mediated by AI, who decides which algorithms get to spend our money? Visa is making an aggressive bid to be that arbiter, wrapping its answer in the language of security and interoperability. Whether merchants, consumers, and regulators accept that proposition will determine not just the fate of the Trusted Agent Protocol, but the structure of AI-powered commerce itself.For now, Visa is moving forward with the confidence of a company that has weathered disruption before. But in the emerging world of agentic commerce, being too trusted might prove just as dangerous as not being trusted enough.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4TWzzYHcsJXmxU7VYnIlKV/896cc598ae137fe841c13309d6aae3df/nuneybits_Vector_art_of_a_Visa_credit_card_c3c9580a-d8ce-4402-9763-bd56dc26549e.webp"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/uk-regulator-fines-4chan-for-ignoring-online-safety-act-demands-045026169.html",
          "published_at": "Tue, 14 Oct 2025 04:50:26 +0000",
          "title": "UK regulator fines 4chan for ignoring Online Safety Act demands",
          "standfirst": "Ofcom has slapped 4chan with a £20,000 ($26,700) fine for failing to comply with the internet and telecommunications regulator's request for information under the UK's Online Safety Act of 2023. The regulator has released an update for 11 of the investigations it opened after the first of its online safety codes became enforceable in March this year. Apparently, 4chan has ignored its requests for a copy of its illegal harms risk assessment and to provide information about its qualifying worldwide revenue. This is the first fine Ofcom has handed down under the new law, which was designed to prevent children from accessing harmful content online and which has prompted websites like Reddit and X to put up age verification measures. When the regulator launch its probe into 4chan in June, it said it received complaints about illegal content on the anonymous online board. It doesn't exactly come as a surprise that 4chan refuses to give the regulator information about the risks of illegal content on its website: Back in August, the service filed a lawsuit against Ofcom, arguing that the enforcement of the UK's Online Safety Act violates Americans' freedom of speech. \"This fine is a clear warning to those who fail to remove illegal content or protect children from harmful material,\" said Liz Kendall, the UK Secretary of State for Science, Innovation and Technology. The regulator is also imposing an additional penalty of £100 ($133) per day on 4chan until it complies with its requests for information. Ofcom has announced the results of other investigations, as well, such as finding \"serious compliance concerns\" with two file-sharing services that have now deployed an automated tool that can detect and quickly remove uploads with child sexual abuse material (CSAM). Four other file-sharing services that were also under investigation for CSAM chose to geoblock access from UK IP addresses instead, so the regulator closed their cases. This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/uk-regulator-fines-4chan-for-ignoring-online-safety-act-demands-045026169.html?src=rss",
          "content": "Ofcom has slapped 4chan with a £20,000 ($26,700) fine for failing to comply with the internet and telecommunications regulator's request for information under the UK's Online Safety Act of 2023. The regulator has released an update for 11 of the investigations it opened after the first of its online safety codes became enforceable in March this year. Apparently, 4chan has ignored its requests for a copy of its illegal harms risk assessment and to provide information about its qualifying worldwide revenue. This is the first fine Ofcom has handed down under the new law, which was designed to prevent children from accessing harmful content online and which has prompted websites like Reddit and X to put up age verification measures. When the regulator launch its probe into 4chan in June, it said it received complaints about illegal content on the anonymous online board. It doesn't exactly come as a surprise that 4chan refuses to give the regulator information about the risks of illegal content on its website: Back in August, the service filed a lawsuit against Ofcom, arguing that the enforcement of the UK's Online Safety Act violates Americans' freedom of speech. \"This fine is a clear warning to those who fail to remove illegal content or protect children from harmful material,\" said Liz Kendall, the UK Secretary of State for Science, Innovation and Technology. The regulator is also imposing an additional penalty of £100 ($133) per day on 4chan until it complies with its requests for information. Ofcom has announced the results of other investigations, as well, such as finding \"serious compliance concerns\" with two file-sharing services that have now deployed an automated tool that can detect and quickly remove uploads with child sexual abuse material (CSAM). Four other file-sharing services that were also under investigation for CSAM chose to geoblock access from UK IP addresses instead, so the regulator closed their cases. This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/uk-regulator-fines-4chan-for-ignoring-online-safety-act-demands-045026169.html?src=rss",
          "feed_position": 24
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/energy/how-rose-rock-bridge-is-building-the-future-of-energy-in-tulsa-oklahoma",
          "published_at": "Tue, 14 Oct 2025 04:00:00 GMT",
          "title": "How Rose Rock Bridge is building the future of energy in Tulsa, Oklahoma",
          "standfirst": "Presented by Tulsa Innovation LabsTulsa was once called \"the oil capital of the world,” and since its launch in 2022, Rose Rock Bridge (RRB), a Tulsa-based non-profit startup incubator led by Tulsa Innovation Labs, has been capitalizing on this heritage, aiming to source and support emerging technologies targeting the energy sector. To create a tech economy that becomes foundational to the future of the sustainable energy industry, and competes on the world stage, they&#x27;re marrying the expertise and industry that already exists in Tulsa with promising entrepreneurial talent. \"Places like Tulsa, we’re tailor-made for tech excellence,\" says Jennifer Hankins, managing director, Tulsa Innovation Labs. \"Our legacy as an oil and gas leader means we know how to build things, and we know how to capture big industries, and we&#x27;re positioned to be a leader in energy innovation.\"RRB, in partnership with major stakeholders, is helping put the region&#x27;s strong corporate, academic, and workforce resources in the hands of innovative, early-stage startups developing the next-generation solutions that are solving pressing energy industry problems and opening up new markets. \"We&#x27;re building the next generation of big energy companies that tackle global challenges in a way that&#x27;s authentic to Tulsa&#x27;s local expertise, and not one that feels more extractive to it,\" she adds. \"RRB has already accelerated 33 companies, initiated 22 active pilots with industry partners, and secured 11 customer contracts, resulting in over $50 million in funding raised by its member companies. What sets the Rose Rock Bridge Showcase apartRRB&#x27;s Rose Rock Bridge Showcase is a showcase and pitch competition presented in partnership with four local energy industry partners: Williams, ONEOK, Devon Energy, and Helmerich and Payne. These partners identify white space problems they&#x27;re aiming to solve — this year, low carbon natural gas solutions — and RRB finds the startups that can solve them. From a competitive pool of more than 50 applications, fourteen companies are selected to pitch for pilot opportunities and potential investment from leading Oklahoma energy companies. While most pitch competitions are seen as pathways to venture capital, the RRB model is designed to accelerate commercialization; instead of vying for funding alone, these companies are competing for the chance to put their technology into practice, Hankins explains.\"What sets the winners apart is the way they&#x27;re solving big challenges with game-changing ideas in the energy space,\" Hankins says. \"But above and beyond just a great idea, it has to be an idea that’s commercial. We can say that our companies have already demonstrated the technology. They’ve already validated it. They’ve secured a big customer, gained traction, are on the path to secure follow-on funding. Those are things that hold back most startups, and our program brings all of those three things together to accelerate commercialization.\" Each startup receives $100,000 in non-dilutive funding to grow their business in Tulsa, along with support services and pilot opportunities through industry partners, equipping them with both the resources and real-world experience needed for long-term market integration — and a solid foothold in Tulsa.This year&#x27;s cohort is comprised of companies that are driving innovation in low carbon natural gas through technologies that enhance operations, control and reduce emissions, and turn waste from energy production into valuable materials:Eigen ControlDeveloping artificial intelligence/machine learning-assisted Raman Spectroscopy for real-time chemical analysis, which helps energy providers process their product more efficiently.Erdin Guma, Eigen ControlKinitics AutomationIncreasing the reliability of equipment while reducing methane emissions with spring-loaded electric valve actuatorsDean Pick, Kinitics AutomationLukera EnergyConverting wastewater and stranded gas into clean methanolBrian Worfolk, Lukera EnergyPike Robotics Making hazardous, high-risk environments safer with robotic inspection platforms.Connor Crawford, Pike RoboticsEmbedding global innovation in the Tulsa market\"We talk a lot about stickiness,\" Hankins says. \"Tulsa Innovation Labs, in addition to the Rose Rock Bridge initiative, is really focused on creating that supportive ecosystem in the region.\"For example, ensuring these companies have lab space if necessary, connecting them to university partners to sharpen research and development, and helping them establish relationships and follow-on funding with other energy-related funds, and embedding them into the Tulsa energy tech landscape. The RRB entrepreneur in residence and executive in residence offer in-depth mentoring as well.\"I call it polishing the startups,\" Hankins explains. \"You go through our program, get a pilot, get insight from the corporate perspective. That’s probably the highest value. But along the way, all the support to help you operationalize your company and your idea faster. We’re going to find a way that you’ll leave our program more ready to get to market, whether that be through some of those auxiliary supports, or we’re going to make sure that direct connection to the customer happens.\"Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Tulsa Innovation LabsTulsa was once called \"the oil capital of the world,” and since its launch in 2022, Rose Rock Bridge (RRB), a Tulsa-based non-profit startup incubator led by Tulsa Innovation Labs, has been capitalizing on this heritage, aiming to source and support emerging technologies targeting the energy sector. To create a tech economy that becomes foundational to the future of the sustainable energy industry, and competes on the world stage, they&#x27;re marrying the expertise and industry that already exists in Tulsa with promising entrepreneurial talent. \"Places like Tulsa, we’re tailor-made for tech excellence,\" says Jennifer Hankins, managing director, Tulsa Innovation Labs. \"Our legacy as an oil and gas leader means we know how to build things, and we know how to capture big industries, and we&#x27;re positioned to be a leader in energy innovation.\"RRB, in partnership with major stakeholders, is helping put the region&#x27;s strong corporate, academic, and workforce resources in the hands of innovative, early-stage startups developing the next-generation solutions that are solving pressing energy industry problems and opening up new markets. \"We&#x27;re building the next generation of big energy companies that tackle global challenges in a way that&#x27;s authentic to Tulsa&#x27;s local expertise, and not one that feels more extractive to it,\" she adds. \"RRB has already accelerated 33 companies, initiated 22 active pilots with industry partners, and secured 11 customer contracts, resulting in over $50 million in funding raised by its member companies. What sets the Rose Rock Bridge Showcase apartRRB&#x27;s Rose Rock Bridge Showcase is a showcase and pitch competition presented in partnership with four local energy industry partners: Williams, ONEOK, Devon Energy, and Helmerich and Payne. These partners identify white space problems they&#x27;re aiming to solve — this year, low carbon natural gas solutions — and RRB finds the startups that can solve them. From a competitive pool of more than 50 applications, fourteen companies are selected to pitch for pilot opportunities and potential investment from leading Oklahoma energy companies. While most pitch competitions are seen as pathways to venture capital, the RRB model is designed to accelerate commercialization; instead of vying for funding alone, these companies are competing for the chance to put their technology into practice, Hankins explains.\"What sets the winners apart is the way they&#x27;re solving big challenges with game-changing ideas in the energy space,\" Hankins says. \"But above and beyond just a great idea, it has to be an idea that’s commercial. We can say that our companies have already demonstrated the technology. They’ve already validated it. They’ve secured a big customer, gained traction, are on the path to secure follow-on funding. Those are things that hold back most startups, and our program brings all of those three things together to accelerate commercialization.\" Each startup receives $100,000 in non-dilutive funding to grow their business in Tulsa, along with support services and pilot opportunities through industry partners, equipping them with both the resources and real-world experience needed for long-term market integration — and a solid foothold in Tulsa.This year&#x27;s cohort is comprised of companies that are driving innovation in low carbon natural gas through technologies that enhance operations, control and reduce emissions, and turn waste from energy production into valuable materials:Eigen ControlDeveloping artificial intelligence/machine learning-assisted Raman Spectroscopy for real-time chemical analysis, which helps energy providers process their product more efficiently.Erdin Guma, Eigen ControlKinitics AutomationIncreasing the reliability of equipment while reducing methane emissions with spring-loaded electric valve actuatorsDean Pick, Kinitics AutomationLukera EnergyConverting wastewater and stranded gas into clean methanolBrian Worfolk, Lukera EnergyPike Robotics Making hazardous, high-risk environments safer with robotic inspection platforms.Connor Crawford, Pike RoboticsEmbedding global innovation in the Tulsa market\"We talk a lot about stickiness,\" Hankins says. \"Tulsa Innovation Labs, in addition to the Rose Rock Bridge initiative, is really focused on creating that supportive ecosystem in the region.\"For example, ensuring these companies have lab space if necessary, connecting them to university partners to sharpen research and development, and helping them establish relationships and follow-on funding with other energy-related funds, and embedding them into the Tulsa energy tech landscape. The RRB entrepreneur in residence and executive in residence offer in-depth mentoring as well.\"I call it polishing the startups,\" Hankins explains. \"You go through our program, get a pilot, get insight from the corporate perspective. That’s probably the highest value. But along the way, all the support to help you operationalize your company and your idea faster. We’re going to find a way that you’ll leave our program more ready to get to market, whether that be through some of those auxiliary supports, or we’re going to make sure that direct connection to the customer happens.\"Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4CvrYLswHJAPv6hA7Y9OEv/05b317701dbf8dd1141e164e77e67446/RRB_VB_Images.final.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/self-improving-language-models-are-becoming-reality-with-mits-updated-seal",
          "published_at": "Mon, 13 Oct 2025 22:51:00 GMT",
          "title": "Self-improving language models are becoming reality with MIT's updated SEAL technique",
          "standfirst": "Researchers at the Massachusetts Institute of Technology (MIT) are gaining renewed attention for developing and open sourcing a technique that allows large language models (LLMs) — like those underpinning ChatGPT and most modern AI chatbots — to improve themselves by generating synthetic data to fine-tune upon. The technique, known as SEAL (Self-Adapting LLMs), was first described in a paper published back in June and covered by VentureBeat at the time.A significantly expanded and updated version of the paper was released last month, as well as open source code posted on Github (under an MIT License, allowing for commercial and enterprise usage), and is making new waves among AI power users on the social network X this week.SEAL allows LLMs to autonomously generate and apply their own fine-tuning strategies. Unlike conventional models that rely on fixed external data and human-crafted optimization pipelines, SEAL enables models to evolve by producing their own synthetic training data and corresponding optimization directives.The development comes from a team affiliated with MIT’s Improbable AI Lab, including Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, and Pulkit Agrawal. Their research was recently presented at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025).Background: From “Beyond Static AI” to Self-Adaptive SystemsEarlier this year, VentureBeat first reported on SEAL as an early-stage framework that allowed language models to generate and train on their own synthetic data — a potential remedy for the stagnation of pretrained models once deployed. At that stage, SEAL was framed as a proof-of-concept that could let enterprise AI agents continuously learn in dynamic environments without manual retraining.Since then, the research has advanced considerably. The new version expands on the prior framework by demonstrating that SEAL’s self-adaptation ability scales with model size, integrates reinforcement learning more effectively to reduce catastrophic forgetting, and formalizes SEAL’s dual-loop structure (inner supervised fine-tuning and outer reinforcement optimization) for reproducibility. The updated paper also introduces evaluations across different prompting formats, improved stability during learning cycles, and a discussion of practical deployment challenges at inference time.Addressing the Limitations of Static ModelsWhile LLMs have demonstrated remarkable capabilities in text generation and understanding, their adaptation to new tasks or knowledge is often manual, brittle, or dependent on context. SEAL challenges this status quo by equipping models with the ability to generate what the authors call “self-edits” — natural language outputs that specify how the model should update its weights.These self-edits may take the form of reformulated information, logical implications, or tool configurations for augmentation and training. Once generated, the model fine-tunes itself based on these edits. The process is guided by reinforcement learning, where the reward signal comes from improved performance on a downstream task.The design mimics how human learners might rephrase or reorganize study materials to better internalize information. This restructuring of knowledge before assimilation serves as a key advantage over models that passively consume new data “as-is.”Performance Across TasksSEAL has been tested across two main domains: knowledge incorporation and few-shot learning.In the knowledge incorporation setting, the researchers evaluated how well a model could internalize new factual content from passages similar to those in the SQuAD dataset, a benchmark reading comprehension dataset introduced by Stanford University in 2016, consisting of over 100,000 crowd-sourced question–answer pairs based on Wikipedia articles (Rajpurkar et al., 2016). Rather than fine-tuning directly on passage text, the model generated synthetic implications of the passage and then fine-tuned on them. After two rounds of reinforcement learning, the model improved question-answering accuracy from 33.5% to 47.0% on a no-context version of SQuAD — surpassing results obtained using synthetic data generated by GPT-4.1.In the few-shot learning setting, SEAL was evaluated using a subset of the ARC benchmark, where tasks require reasoning from only a few examples. Here, SEAL generated self-edits specifying data augmentations and hyperparameters. After reinforcement learning, the success rate in correctly solving held-out tasks jumped to 72.5%, up from 20% using self-edits generated without reinforcement learning. Models that relied solely on in-context learning without any adaptation scored 0%.Technical FrameworkSEAL operates using a two-loop structure: an inner loop performs supervised fine-tuning based on the self-edit, while an outer loop uses reinforcement learning to refine the policy that generates those self-edits.The reinforcement learning algorithm used is based on ReSTEM, which combines sampling with filtered behavior cloning. During training, only self-edits that lead to performance improvements are reinforced. This approach effectively teaches the model which kinds of edits are most beneficial for learning.For efficiency, SEAL applies LoRA-based fine-tuning rather than full parameter updates, enabling rapid experimentation and low-cost adaptation.Strengths and LimitationsThe researchers report that SEAL can produce high-utility training data with minimal supervision, outperforming even large external models like GPT-4.1 in specific tasks. They also demonstrate that SEAL generalizes beyond its original setup: it continues to perform well when scaling from single-pass updates to multi-document continued pretraining scenarios.However, the framework is not without limitations. One issue is catastrophic forgetting, where updates to incorporate new information can degrade performance on previously learned tasks. In response to this concern, co-author Jyo Pari told VentureBeat via email that reinforcement learning (RL) appears to mitigate forgetting more effectively than standard supervised fine-tuning (SFT), citing a recent paper on the topic. He added that combining this insight with SEAL could lead to new variants where SEAL learns not just training data, but reward functions.Another challenge is computational overhead: evaluating each self-edit requires fine-tuning and performance testing, which can take 30–45 seconds per edit — significantly more than standard reinforcement learning tasks. As Jyo explained, “Training SEAL is non-trivial because it requires 2 loops of optimization, an outer RL one and an inner SFT one. At inference time, updating model weights will also require new systems infrastructure.” He emphasized the need for future research into deployment systems as a critical path to making SEAL practical.Additionally, SEAL’s current design assumes the presence of paired tasks and reference answers for every context, limiting its direct applicability to unlabeled corpora. However, Jyo clarified that as long as there is a downstream task with a computable reward, SEAL can be trained to adapt accordingly—even in safety-critical domains. In principle, a SEAL-trained model could learn to avoid training on harmful or malicious inputs if guided by the appropriate reward signal.AI Community ReactionsThe AI research and builder community has reacted with a mix of excitement and speculation to the SEAL paper. On X, formerly Twitter, several prominent AI-focused accounts weighed in on the potential impact.User @VraserX, a self-described educator and AI enthusiast, called SEAL “the birth of continuous self-learning AI” and predicted that models like OpenAI&#x27;s GPT-6 could adopt similar architecture. In their words, SEAL represents “the end of the frozen-weights era,” ushering in systems that evolve as the world around them changes. They highlighted SEAL&#x27;s ability to form persistent memories, repair knowledge, and learn from real-time data, comparing it to a foundational step toward models that don’t just use information but absorb it.Meanwhile, @alex_prompter, co-founder of an AI-powered marketing venture, framed SEAL as a leap toward models that literally rewrite themselves. “MIT just built an AI that can rewrite its own code to get smarter,” he wrote. Citing the paper’s key results — a 40% boost in factual recall and outperforming GPT-4.1 using self-generated data — he described the findings as confirmation that “LLMs that finetune themselves are no longer sci-fi.”The enthusiasm reflects a broader appetite in the AI space for models that can evolve without constant retraining or human oversight — particularly in rapidly changing domains or personalized use cases.Future Directions and Open QuestionsIn response to questions about scaling SEAL to larger models and tasks, Jyo pointed to experiments (Appendix B.7) showing that as model size increases, so does their self-adaptation ability. He compared this to students improving their study techniques over time — larger models are simply better at generating useful self-edits.When asked whether SEAL generalizes to new prompting styles, he confirmed it does, citing Table 10 in the paper. However, he also acknowledged that the team has not yet tested SEAL’s ability to transfer across entirely new domains or model architectures. “SEAL is an initial work showcasing the possibilities,” he said. “But it requires much more testing.” He added that generalization may improve as SEAL is trained on a broader distribution of tasks.Interestingly, the team found that only a few reinforcement learning steps already led to measurable performance gains. “This is exciting,” Jyo noted, “because it means that with more compute, we could hopefully get even more improvements.” He suggested future experiments could explore more advanced reinforcement learning methods beyond ReSTEM, such as Group Relative Policy Optimization (GRPO).Toward More Adaptive and Agentic ModelsSEAL represents a step toward models that can autonomously improve over time, both by integrating new knowledge and by reconfiguring how they learn. The authors envision future extensions where SEAL could assist in self-pretraining, continual learning, and the development of agentic systems — models that interact with evolving environments and adapt incrementally.In such settings, a model could use SEAL to synthesize weight updates after each interaction, gradually internalizing behaviors or insights. This could reduce the need for repeated supervision and manual intervention, particularly in data-constrained or specialized domains.As public web text becomes saturated and further scaling of LLMs becomes bottlenecked by data availability, self-directed approaches like SEAL could play a critical role in pushing the boundaries of what LLMs can achieve.You can access the SEAL project, including code and further documentation, at: https://jyopari.github.io/posts/seal",
          "content": "Researchers at the Massachusetts Institute of Technology (MIT) are gaining renewed attention for developing and open sourcing a technique that allows large language models (LLMs) — like those underpinning ChatGPT and most modern AI chatbots — to improve themselves by generating synthetic data to fine-tune upon. The technique, known as SEAL (Self-Adapting LLMs), was first described in a paper published back in June and covered by VentureBeat at the time.A significantly expanded and updated version of the paper was released last month, as well as open source code posted on Github (under an MIT License, allowing for commercial and enterprise usage), and is making new waves among AI power users on the social network X this week.SEAL allows LLMs to autonomously generate and apply their own fine-tuning strategies. Unlike conventional models that rely on fixed external data and human-crafted optimization pipelines, SEAL enables models to evolve by producing their own synthetic training data and corresponding optimization directives.The development comes from a team affiliated with MIT’s Improbable AI Lab, including Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, and Pulkit Agrawal. Their research was recently presented at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025).Background: From “Beyond Static AI” to Self-Adaptive SystemsEarlier this year, VentureBeat first reported on SEAL as an early-stage framework that allowed language models to generate and train on their own synthetic data — a potential remedy for the stagnation of pretrained models once deployed. At that stage, SEAL was framed as a proof-of-concept that could let enterprise AI agents continuously learn in dynamic environments without manual retraining.Since then, the research has advanced considerably. The new version expands on the prior framework by demonstrating that SEAL’s self-adaptation ability scales with model size, integrates reinforcement learning more effectively to reduce catastrophic forgetting, and formalizes SEAL’s dual-loop structure (inner supervised fine-tuning and outer reinforcement optimization) for reproducibility. The updated paper also introduces evaluations across different prompting formats, improved stability during learning cycles, and a discussion of practical deployment challenges at inference time.Addressing the Limitations of Static ModelsWhile LLMs have demonstrated remarkable capabilities in text generation and understanding, their adaptation to new tasks or knowledge is often manual, brittle, or dependent on context. SEAL challenges this status quo by equipping models with the ability to generate what the authors call “self-edits” — natural language outputs that specify how the model should update its weights.These self-edits may take the form of reformulated information, logical implications, or tool configurations for augmentation and training. Once generated, the model fine-tunes itself based on these edits. The process is guided by reinforcement learning, where the reward signal comes from improved performance on a downstream task.The design mimics how human learners might rephrase or reorganize study materials to better internalize information. This restructuring of knowledge before assimilation serves as a key advantage over models that passively consume new data “as-is.”Performance Across TasksSEAL has been tested across two main domains: knowledge incorporation and few-shot learning.In the knowledge incorporation setting, the researchers evaluated how well a model could internalize new factual content from passages similar to those in the SQuAD dataset, a benchmark reading comprehension dataset introduced by Stanford University in 2016, consisting of over 100,000 crowd-sourced question–answer pairs based on Wikipedia articles (Rajpurkar et al., 2016). Rather than fine-tuning directly on passage text, the model generated synthetic implications of the passage and then fine-tuned on them. After two rounds of reinforcement learning, the model improved question-answering accuracy from 33.5% to 47.0% on a no-context version of SQuAD — surpassing results obtained using synthetic data generated by GPT-4.1.In the few-shot learning setting, SEAL was evaluated using a subset of the ARC benchmark, where tasks require reasoning from only a few examples. Here, SEAL generated self-edits specifying data augmentations and hyperparameters. After reinforcement learning, the success rate in correctly solving held-out tasks jumped to 72.5%, up from 20% using self-edits generated without reinforcement learning. Models that relied solely on in-context learning without any adaptation scored 0%.Technical FrameworkSEAL operates using a two-loop structure: an inner loop performs supervised fine-tuning based on the self-edit, while an outer loop uses reinforcement learning to refine the policy that generates those self-edits.The reinforcement learning algorithm used is based on ReSTEM, which combines sampling with filtered behavior cloning. During training, only self-edits that lead to performance improvements are reinforced. This approach effectively teaches the model which kinds of edits are most beneficial for learning.For efficiency, SEAL applies LoRA-based fine-tuning rather than full parameter updates, enabling rapid experimentation and low-cost adaptation.Strengths and LimitationsThe researchers report that SEAL can produce high-utility training data with minimal supervision, outperforming even large external models like GPT-4.1 in specific tasks. They also demonstrate that SEAL generalizes beyond its original setup: it continues to perform well when scaling from single-pass updates to multi-document continued pretraining scenarios.However, the framework is not without limitations. One issue is catastrophic forgetting, where updates to incorporate new information can degrade performance on previously learned tasks. In response to this concern, co-author Jyo Pari told VentureBeat via email that reinforcement learning (RL) appears to mitigate forgetting more effectively than standard supervised fine-tuning (SFT), citing a recent paper on the topic. He added that combining this insight with SEAL could lead to new variants where SEAL learns not just training data, but reward functions.Another challenge is computational overhead: evaluating each self-edit requires fine-tuning and performance testing, which can take 30–45 seconds per edit — significantly more than standard reinforcement learning tasks. As Jyo explained, “Training SEAL is non-trivial because it requires 2 loops of optimization, an outer RL one and an inner SFT one. At inference time, updating model weights will also require new systems infrastructure.” He emphasized the need for future research into deployment systems as a critical path to making SEAL practical.Additionally, SEAL’s current design assumes the presence of paired tasks and reference answers for every context, limiting its direct applicability to unlabeled corpora. However, Jyo clarified that as long as there is a downstream task with a computable reward, SEAL can be trained to adapt accordingly—even in safety-critical domains. In principle, a SEAL-trained model could learn to avoid training on harmful or malicious inputs if guided by the appropriate reward signal.AI Community ReactionsThe AI research and builder community has reacted with a mix of excitement and speculation to the SEAL paper. On X, formerly Twitter, several prominent AI-focused accounts weighed in on the potential impact.User @VraserX, a self-described educator and AI enthusiast, called SEAL “the birth of continuous self-learning AI” and predicted that models like OpenAI&#x27;s GPT-6 could adopt similar architecture. In their words, SEAL represents “the end of the frozen-weights era,” ushering in systems that evolve as the world around them changes. They highlighted SEAL&#x27;s ability to form persistent memories, repair knowledge, and learn from real-time data, comparing it to a foundational step toward models that don’t just use information but absorb it.Meanwhile, @alex_prompter, co-founder of an AI-powered marketing venture, framed SEAL as a leap toward models that literally rewrite themselves. “MIT just built an AI that can rewrite its own code to get smarter,” he wrote. Citing the paper’s key results — a 40% boost in factual recall and outperforming GPT-4.1 using self-generated data — he described the findings as confirmation that “LLMs that finetune themselves are no longer sci-fi.”The enthusiasm reflects a broader appetite in the AI space for models that can evolve without constant retraining or human oversight — particularly in rapidly changing domains or personalized use cases.Future Directions and Open QuestionsIn response to questions about scaling SEAL to larger models and tasks, Jyo pointed to experiments (Appendix B.7) showing that as model size increases, so does their self-adaptation ability. He compared this to students improving their study techniques over time — larger models are simply better at generating useful self-edits.When asked whether SEAL generalizes to new prompting styles, he confirmed it does, citing Table 10 in the paper. However, he also acknowledged that the team has not yet tested SEAL’s ability to transfer across entirely new domains or model architectures. “SEAL is an initial work showcasing the possibilities,” he said. “But it requires much more testing.” He added that generalization may improve as SEAL is trained on a broader distribution of tasks.Interestingly, the team found that only a few reinforcement learning steps already led to measurable performance gains. “This is exciting,” Jyo noted, “because it means that with more compute, we could hopefully get even more improvements.” He suggested future experiments could explore more advanced reinforcement learning methods beyond ReSTEM, such as Group Relative Policy Optimization (GRPO).Toward More Adaptive and Agentic ModelsSEAL represents a step toward models that can autonomously improve over time, both by integrating new knowledge and by reconfiguring how they learn. The authors envision future extensions where SEAL could assist in self-pretraining, continual learning, and the development of agentic systems — models that interact with evolving environments and adapt incrementally.In such settings, a model could use SEAL to synthesize weight updates after each interaction, gradually internalizing behaviors or insights. This could reduce the need for repeated supervision and manual intervention, particularly in data-constrained or specialized domains.As public web text becomes saturated and further scaling of LLMs becomes bottlenecked by data availability, self-directed approaches like SEAL could play a critical role in pushing the boundaries of what LLMs can achieve.You can access the SEAL project, including code and further documentation, at: https://jyopari.github.io/posts/seal",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4816Y0YfsXKIENLGFsuaG6/a4620bd99d25c8fe32ab054bd16ff390/cfr0z3n_a_cybernetic_seal_looks_up_with_cute_alert_eyes_under_a_a6f43d56-7792-4d4f-bc1e-18b6dd2f5e4e.png"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/researchers-find-that-retraining-only-small-parts-of-ai-models-can-cut-costs",
          "published_at": "Mon, 13 Oct 2025 22:39:00 GMT",
          "title": "Researchers find that retraining only small parts of AI models can cut costs and prevent forgetting",
          "standfirst": "Enterprises often find that when they fine-tune models, one effective approach to making a large language model (LLM) fit for purpose and grounded in data is to have the model lose some of its abilities. After fine-tuning, some models “forget” how to perform certain tasks or other tasks they already learned. Research from the University of Illinois Urbana-Champaign proposes a new method for retraining models that avoids “catastrophic forgetting,” in which the model loses some of its prior knowledge. The paper focuses on two specific LLMs that generate responses from images: LLaVA and Qwen 2.5-VL.The approach encourages enterprises to retrain only narrow parts of an LLM to avoid retraining the entire model and incurring a significant increase in compute costs. The team claims that catastrophic forgetting isn’t true memory loss, but rather a side effect of bias drift. “Training a new LMM can cost millions of dollars, weeks of time, and emit hundreds of tons of CO2, so finding ways to more efficiently and effectively update existing models is a pressing concern,” the team wrote in the paper. “Guided by this result, we explore tuning recipes that preserve learning while limiting output shift.”The researchers focused on a multi-layer perceptron (MLP), the model&#x27;s internal decision-making component. Catastrophic forgetting The researchers wanted first to verify the existence and the cause of catastrophic forgetting in models. To do this, they created a set of target tasks for the models to complete. The models were then fine-tuned and evaluated to determine whether they led to substantial forgetting. But as the process went on, the researchers found that the models were recovering some of their abilities. “We also noticed a surprising result, that the model performance would drop significantly in held out benchmarks after training on the counting task, it would mostly recover on PathVQA, another specialized task that is not well represented in the benchmarks,” they said. “Meanwhile, while performing the forgetting mitigation experiments, we also tried separately tuning only the self-attention projection (SA Proj) or MLP layers, motivated by the finding that tuning only the LLM was generally better than tuning the full model. This led to another very surprising result – that tuning only self-attention projection layers led to very good learning of the target tasks with no drop in performance in held out tasks, even after training all five target tasks in a sequence.”The researchers said they believe that “what looks like forgetting or interference after fine-tuning on a narrow target task is actually bias in the output distribution due to the task distribution shift.”Narrow retrainingThat finding turned out to be the key to the experiment. The researchers noted that tuning the MLP increases the likelihood of “outputting numeric tokens and a highly correlated drop in held out task accuracy.” What it showed is that a model forgetting some of its knowledge is only temporary and not a long-term matter. “To avoid biasing the output distribution, we tune the MLP up/gating projections while keeping the down projection frozen, and find that it achieves similar learning to full MLP tuning with little forgetting,” the researchers said. This allows for a more straightforward and more reproducible method for fine-tuning a model. By focusing on a narrow segment of the model, rather than a wholesale retraining, enterprises can cut compute costs. It also allows better control of output drift. However, the research focuses only on two models, specifically those dealing with vision and language. The researchers noted that due to limited resources, they are unable to try the experiment with other models.Their findings, however, can be extended to other LLMs, especially for different modalities.",
          "content": "Enterprises often find that when they fine-tune models, one effective approach to making a large language model (LLM) fit for purpose and grounded in data is to have the model lose some of its abilities. After fine-tuning, some models “forget” how to perform certain tasks or other tasks they already learned. Research from the University of Illinois Urbana-Champaign proposes a new method for retraining models that avoids “catastrophic forgetting,” in which the model loses some of its prior knowledge. The paper focuses on two specific LLMs that generate responses from images: LLaVA and Qwen 2.5-VL.The approach encourages enterprises to retrain only narrow parts of an LLM to avoid retraining the entire model and incurring a significant increase in compute costs. The team claims that catastrophic forgetting isn’t true memory loss, but rather a side effect of bias drift. “Training a new LMM can cost millions of dollars, weeks of time, and emit hundreds of tons of CO2, so finding ways to more efficiently and effectively update existing models is a pressing concern,” the team wrote in the paper. “Guided by this result, we explore tuning recipes that preserve learning while limiting output shift.”The researchers focused on a multi-layer perceptron (MLP), the model&#x27;s internal decision-making component. Catastrophic forgetting The researchers wanted first to verify the existence and the cause of catastrophic forgetting in models. To do this, they created a set of target tasks for the models to complete. The models were then fine-tuned and evaluated to determine whether they led to substantial forgetting. But as the process went on, the researchers found that the models were recovering some of their abilities. “We also noticed a surprising result, that the model performance would drop significantly in held out benchmarks after training on the counting task, it would mostly recover on PathVQA, another specialized task that is not well represented in the benchmarks,” they said. “Meanwhile, while performing the forgetting mitigation experiments, we also tried separately tuning only the self-attention projection (SA Proj) or MLP layers, motivated by the finding that tuning only the LLM was generally better than tuning the full model. This led to another very surprising result – that tuning only self-attention projection layers led to very good learning of the target tasks with no drop in performance in held out tasks, even after training all five target tasks in a sequence.”The researchers said they believe that “what looks like forgetting or interference after fine-tuning on a narrow target task is actually bias in the output distribution due to the task distribution shift.”Narrow retrainingThat finding turned out to be the key to the experiment. The researchers noted that tuning the MLP increases the likelihood of “outputting numeric tokens and a highly correlated drop in held out task accuracy.” What it showed is that a model forgetting some of its knowledge is only temporary and not a long-term matter. “To avoid biasing the output distribution, we tune the MLP up/gating projections while keeping the down projection frozen, and find that it achieves similar learning to full MLP tuning with little forgetting,” the researchers said. This allows for a more straightforward and more reproducible method for fine-tuning a model. By focusing on a narrow segment of the model, rather than a wholesale retraining, enterprises can cut compute costs. It also allows better control of output drift. However, the research focuses only on two models, specifically those dealing with vision and language. The researchers noted that due to limited resources, they are unable to try the experiment with other models.Their findings, however, can be extended to other LLMs, especially for different modalities.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/wvhlzgUGzNikEzmtJxvNB/ed69fb909b090e1e7e6b81ff61abf8b0/crimedy7_illustration_of_a_sculptor_creating_a_robot_from_a_p_501bf165-0b44-4bb1-9608-1025a42400b7_1.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/apple-tv-is-now-just-apple-tv-200644609.html",
          "published_at": "Mon, 13 Oct 2025 20:06:44 +0000",
          "title": "Apple TV+ is now just Apple TV",
          "standfirst": "It’s been an interesting few months in the realm of streaming service branding. Warner Bros. Discovery reverted Max back to HBO Max after a baffling decision to trim the name in the first place. Disney made Hulu the \"global general entertainment brand\" on Disney+ when it rebranded the Star hub on the service. Now Apple would like you to know that it’s changing the name of its streaming service too. Going forward, Apple TV+ is now just Apple TV.The company revealed the news in very lowkey fashion, at the end of a press release about when its F1 movie will land on Apple TV, the streaming service with a monthly subscription (December 12, FYI). “Apple TV+ is now simply Apple TV, with a vibrant new identity,” the company said without elaborating.Apple does like to keep things clean, and shearing off the plus sign is one way of doing that. But oversimplification can cause greater confusion. As Apple states in its own press release, “Apple TV is available on the Apple TV app” and “For a limited time, customers who purchase and activate a new iPhone, iPad, Apple TV or Mac can enjoy three months of Apple TV for free.” Did no one at Apple’s (generally very effective) marketing team spot the problem with this? Buying Apple TV to get free Apple TV sounds like a recursive capitalist fever dream that will never end.As it stands, you can turn on your Apple TV device to open the Apple TV app to watch Apple TV. There are lots of things in the Apple TV app that aren’t actually Apple TV shows or movies and you may have to pay for those separately. The press release also states that you can watch F1 right now if you buy it on Apple TV through the Apple TV app, so you don’t have to wait for the film to make its “global streaming debut” on Apple TV. What a mess.Apple hasn’t fully rolled out the change yet, as there are still plenty of references to “Apple TV+” on the streaming service’s website. It’s still referred to as Apple TV+ on the TV app’s listing on the App Store too. I’m interested to see how confusing things really get if, in the coming months, Apple reveals a refreshed Apple TV. You know, that device you can use to watch Apple TV.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/apple-tv-is-now-just-apple-tv-200644609.html?src=rss",
          "content": "It’s been an interesting few months in the realm of streaming service branding. Warner Bros. Discovery reverted Max back to HBO Max after a baffling decision to trim the name in the first place. Disney made Hulu the \"global general entertainment brand\" on Disney+ when it rebranded the Star hub on the service. Now Apple would like you to know that it’s changing the name of its streaming service too. Going forward, Apple TV+ is now just Apple TV.The company revealed the news in very lowkey fashion, at the end of a press release about when its F1 movie will land on Apple TV, the streaming service with a monthly subscription (December 12, FYI). “Apple TV+ is now simply Apple TV, with a vibrant new identity,” the company said without elaborating.Apple does like to keep things clean, and shearing off the plus sign is one way of doing that. But oversimplification can cause greater confusion. As Apple states in its own press release, “Apple TV is available on the Apple TV app” and “For a limited time, customers who purchase and activate a new iPhone, iPad, Apple TV or Mac can enjoy three months of Apple TV for free.” Did no one at Apple’s (generally very effective) marketing team spot the problem with this? Buying Apple TV to get free Apple TV sounds like a recursive capitalist fever dream that will never end.As it stands, you can turn on your Apple TV device to open the Apple TV app to watch Apple TV. There are lots of things in the Apple TV app that aren’t actually Apple TV shows or movies and you may have to pay for those separately. The press release also states that you can watch F1 right now if you buy it on Apple TV through the Apple TV app, so you don’t have to wait for the film to make its “global streaming debut” on Apple TV. What a mess.Apple hasn’t fully rolled out the change yet, as there are still plenty of references to “Apple TV+” on the streaming service’s website. It’s still referred to as Apple TV+ on the TV app’s listing on the App Store too. I’m interested to see how confusing things really get if, in the coming months, Apple reveals a refreshed Apple TV. You know, that device you can use to watch Apple TV.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/apple-tv-is-now-just-apple-tv-200644609.html?src=rss",
          "feed_position": 28
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/california-enacts-age-gate-law-for-app-stores-172802711.html",
          "published_at": "Mon, 13 Oct 2025 17:28:02 +0000",
          "title": "California enacts age-gate law for app stores",
          "standfirst": "California has become the latest state to age-gate app stores and operating systems. AB 1043 is one of several internet regulation bills that Governor Gavin Newsom signed into law on Monday, including ones related to social media warning labels, chatbots and deepfake pornography. The State Assembly passed AB 1043 with a 58-0 vote in September. The legislation received backing from notable tech companies such as Google, OpenAI, Meta, Snap and Pinterest. The companies claimed the bill offered a more balanced approach to age verification, with more privacy protection, than laws passed in other states.Unlike with legislation in Utah and Texas, children will still be able to download apps without their parents' consent. The law doesn't require people to upload photo IDs either. Instead, the idea is that a parent will enter their child's age while setting up a device for them — so it’s more of an age gate than age verification. The operating system and/or app store will place the user into one of four age categories (under 13, 13-16, 16-18 or adult) and make that information available to app developers. Enacting AB 1043 means that California is joining the likes of Utah, Texas and Louisiana in mandating that app stores carry out age verification (the UK has a broad age verification law in place too). Apple has detailed how it plans to comply with the Texas law, which takes effect on January 1, 2026. The California legislation takes effect one year later.AB 56, another bill Newsom signed Monday, will force social media services to display warning labels that inform kids and teens about the risks of using such platforms. These messages will appear the first time the user opens an app each day, then after three hours of total use and once an hour thereafter. This law will take effect on January 1, 2027 as well.Elsewhere, California will require AI chatbots to have guardrails in place to prevent self-harm content from appearing and direct users who express suicidal ideation to crisis services. Platforms will need to inform the Department of Public Health about how they're addressing self-harm and to share details on how often they display crisis center prevention notifications.The legislation is coming into force after lawsuits were filed against OpenAI and Character AI in relation to teen suicides. OpenAI last month announced plans to automatically identify teen ChatGPT users and restrict their usage of the chatbot.In addition, SB 243 prohibits chatbots from being marketed as health care professionals. Chatbots will need to make it clear to users that they aren't interacting with a person when they're using such services, and instead they’re receiving artificially generated responses. Chatbot providers will need to remind minors of this at least every three hours. Newsom also signed a bill concerning deepfake pornography into law. AB 621 includes steeper potential penalties for \"third parties who knowingly facilitate or aid in the distribution of nonconsensual sexually explicit material.\" The legislation allows victims to seek up to $250,000 per \"malicious violation\" of the law.In the US, the National Suicide Prevention Lifeline is 1-800-273-8255 or you can simply dial 988. Crisis Text Line can be reached by texting HOME to 741741 (US), CONNECT to 686868 (Canada) or SHOUT to 85258 (UK). Wikipedia maintains a list of crisis lines for people outside of those countries.This article originally appeared on Engadget at https://www.engadget.com/california-enacts-age-gate-law-for-app-stores-172802711.html?src=rss",
          "content": "California has become the latest state to age-gate app stores and operating systems. AB 1043 is one of several internet regulation bills that Governor Gavin Newsom signed into law on Monday, including ones related to social media warning labels, chatbots and deepfake pornography. The State Assembly passed AB 1043 with a 58-0 vote in September. The legislation received backing from notable tech companies such as Google, OpenAI, Meta, Snap and Pinterest. The companies claimed the bill offered a more balanced approach to age verification, with more privacy protection, than laws passed in other states.Unlike with legislation in Utah and Texas, children will still be able to download apps without their parents' consent. The law doesn't require people to upload photo IDs either. Instead, the idea is that a parent will enter their child's age while setting up a device for them — so it’s more of an age gate than age verification. The operating system and/or app store will place the user into one of four age categories (under 13, 13-16, 16-18 or adult) and make that information available to app developers. Enacting AB 1043 means that California is joining the likes of Utah, Texas and Louisiana in mandating that app stores carry out age verification (the UK has a broad age verification law in place too). Apple has detailed how it plans to comply with the Texas law, which takes effect on January 1, 2026. The California legislation takes effect one year later.AB 56, another bill Newsom signed Monday, will force social media services to display warning labels that inform kids and teens about the risks of using such platforms. These messages will appear the first time the user opens an app each day, then after three hours of total use and once an hour thereafter. This law will take effect on January 1, 2027 as well.Elsewhere, California will require AI chatbots to have guardrails in place to prevent self-harm content from appearing and direct users who express suicidal ideation to crisis services. Platforms will need to inform the Department of Public Health about how they're addressing self-harm and to share details on how often they display crisis center prevention notifications.The legislation is coming into force after lawsuits were filed against OpenAI and Character AI in relation to teen suicides. OpenAI last month announced plans to automatically identify teen ChatGPT users and restrict their usage of the chatbot.In addition, SB 243 prohibits chatbots from being marketed as health care professionals. Chatbots will need to make it clear to users that they aren't interacting with a person when they're using such services, and instead they’re receiving artificially generated responses. Chatbot providers will need to remind minors of this at least every three hours. Newsom also signed a bill concerning deepfake pornography into law. AB 621 includes steeper potential penalties for \"third parties who knowingly facilitate or aid in the distribution of nonconsensual sexually explicit material.\" The legislation allows victims to seek up to $250,000 per \"malicious violation\" of the law.In the US, the National Suicide Prevention Lifeline is 1-800-273-8255 or you can simply dial 988. Crisis Text Line can be reached by texting HOME to 741741 (US), CONNECT to 686868 (Canada) or SHOUT to 85258 (UK). Wikipedia maintains a list of crisis lines for people outside of those countries.This article originally appeared on Engadget at https://www.engadget.com/california-enacts-age-gate-law-for-app-stores-172802711.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/this-new-ai-technique-creates-digital-twin-consumers-and-it-could-kill-the",
          "published_at": "Mon, 13 Oct 2025 13:00:00 GMT",
          "title": "This new AI technique creates ‘digital twin’ consumers, and it could kill the traditional survey industry",
          "standfirst": "A new research paper quietly published last week outlines a breakthrough method that allows large language models (LLMs) to simulate human consumer behavior with startling accuracy, a development that could reshape the multi-billion-dollar market research industry. The technique promises to create armies of synthetic consumers who can provide not just realistic product ratings, but also the qualitative reasoning behind them, at a scale and speed currently unattainable.For years, companies have sought to use AI for market research, but have been stymied by a fundamental flaw: when asked to provide a numerical rating on a scale of 1 to 5, LLMs produce unrealistic and poorly distributed responses. A new paper, \"LLMs Reproduce Human Purchase Intent via Semantic Similarity Elicitation of Likert Ratings,\" submitted to the pre-print server arXiv on October 9th proposes an elegant solution that sidesteps this problem entirely.The international team of researchers, led by Benjamin F. Maier, developed a method they call semantic similarity rating (SSR). Instead of asking an LLM for a number, SSR prompts the model for a rich, textual opinion on a product. This text is then converted into a numerical vector — an \"embedding\" — and its similarity is measured against a set of pre-defined reference statements. For example, a response of \"I would absolutely buy this, it&#x27;s exactly what I&#x27;m looking for\" would be semantically closer to the reference statement for a \"5\" rating than to the statement for a \"1.\"The results are striking. Tested against a massive real-world dataset from a leading personal care corporation — comprising 57 product surveys and 9,300 human responses — the SSR method achieved 90% of human test-retest reliability. Crucially, the distribution of AI-generated ratings was statistically almost indistinguishable from the human panel. The authors state, \"This framework enables scalable consumer research simulations while preserving traditional survey metrics and interpretability.\"A timely solution as AI threatens survey integrityThis development arrives at a critical time, as the integrity of traditional online survey panels is increasingly under threat from AI. A 2024 analysis from the Stanford Graduate School of Business highlighted a growing problem of human survey-takers using chatbots to generate their answers. These AI-generated responses were found to be \"suspiciously nice,\" overly verbose, and lacking the \"snark\" and authenticity of genuine human feedback, leading to what researchers called a \"homogenization\" of data that could mask serious issues like discrimination or product flaws.Maier&#x27;s research offers a starkly different approach: instead of fighting to purge contaminated data, it creates a controlled environment for generating high-fidelity synthetic data from the ground up.\"What we&#x27;re seeing is a pivot from defense to offense,\" said one analyst not affiliated with the study. \"The Stanford paper showed the chaos of uncontrolled AI polluting human datasets. This new paper shows the order and utility of controlled AI creating its own datasets. For a Chief Data Officer, this is the difference between cleaning a contaminated well and tapping into a fresh spring.\"From text to intent: The technical leap behind the synthetic consumerThe technical validity of the new method hinges on the quality of the text embeddings, a concept explored in a 2022 paper in EPJ Data Science. That research argued for a rigorous \"construct validity\" framework to ensure that text embeddings — the numerical representations of text — truly \"measure what they are supposed to.\" The success of the SSR method suggests its embeddings effectively capture the nuances of purchase intent. For this new technique to be widely adopted, enterprises will need to be confident that the underlying models are not just generating plausible text, but are mapping that text to scores in a way that is robust and meaningful.The approach also represents a significant leap from prior research, which has largely focused on using text embeddings to analyze and predict ratings from existing online reviews. A 2022 study, for example, evaluated the performance of models like BERT and word2vec in predicting review scores on retail sites, finding that newer models like BERT performed better for general use. The new research moves beyond analyzing existing data to generating novel, predictive insights before a product even hits the market.The dawn of the digital focus groupFor technical decision-makers, the implications are profound. The ability to spin up a \"digital twin\" of a target consumer segment and test product concepts, ad copy, or packaging variations in a matter of hours could drastically accelerate innovation cycles. As the paper notes, these synthetic respondents also provide \"rich qualitative feedback explaining their ratings,\" offering a treasure trove of data for product development that is both scalable and interpretable. While the era of human-only focus groups is far from over, this research provides the most compelling evidence yet that their synthetic counterparts are ready for business.But the business case extends beyond speed and scale. Consider the economics: a traditional survey panel for a national product launch might cost tens of thousands of dollars and take weeks to field. An SSR-based simulation could deliver comparable insights in a fraction of the time, at a fraction of the cost, and with the ability to iterate instantly based on findings. For companies in fast-moving consumer goods categories — where the window between concept and shelf can determine market leadership — this velocity advantage could be decisive.There are, of course, caveats. The method was validated on personal care products; its performance on complex B2B purchasing decisions, luxury goods, or culturally specific products remains unproven. And while the paper demonstrates that SSR can replicate aggregate human behavior, it does not claim to predict individual consumer choices. The technique works at the population level, not the person level — a distinction that matters greatly for applications like personalized marketing.Yet even with these limitations, the research is a watershed. While the era of human-only focus groups is far from over, this paper provides the most compelling evidence yet that their synthetic counterparts are ready for business. The question is no longer whether AI can simulate consumer sentiment, but whether enterprises can move fast enough to capitalize on it before their competitors do.",
          "content": "A new research paper quietly published last week outlines a breakthrough method that allows large language models (LLMs) to simulate human consumer behavior with startling accuracy, a development that could reshape the multi-billion-dollar market research industry. The technique promises to create armies of synthetic consumers who can provide not just realistic product ratings, but also the qualitative reasoning behind them, at a scale and speed currently unattainable.For years, companies have sought to use AI for market research, but have been stymied by a fundamental flaw: when asked to provide a numerical rating on a scale of 1 to 5, LLMs produce unrealistic and poorly distributed responses. A new paper, \"LLMs Reproduce Human Purchase Intent via Semantic Similarity Elicitation of Likert Ratings,\" submitted to the pre-print server arXiv on October 9th proposes an elegant solution that sidesteps this problem entirely.The international team of researchers, led by Benjamin F. Maier, developed a method they call semantic similarity rating (SSR). Instead of asking an LLM for a number, SSR prompts the model for a rich, textual opinion on a product. This text is then converted into a numerical vector — an \"embedding\" — and its similarity is measured against a set of pre-defined reference statements. For example, a response of \"I would absolutely buy this, it&#x27;s exactly what I&#x27;m looking for\" would be semantically closer to the reference statement for a \"5\" rating than to the statement for a \"1.\"The results are striking. Tested against a massive real-world dataset from a leading personal care corporation — comprising 57 product surveys and 9,300 human responses — the SSR method achieved 90% of human test-retest reliability. Crucially, the distribution of AI-generated ratings was statistically almost indistinguishable from the human panel. The authors state, \"This framework enables scalable consumer research simulations while preserving traditional survey metrics and interpretability.\"A timely solution as AI threatens survey integrityThis development arrives at a critical time, as the integrity of traditional online survey panels is increasingly under threat from AI. A 2024 analysis from the Stanford Graduate School of Business highlighted a growing problem of human survey-takers using chatbots to generate their answers. These AI-generated responses were found to be \"suspiciously nice,\" overly verbose, and lacking the \"snark\" and authenticity of genuine human feedback, leading to what researchers called a \"homogenization\" of data that could mask serious issues like discrimination or product flaws.Maier&#x27;s research offers a starkly different approach: instead of fighting to purge contaminated data, it creates a controlled environment for generating high-fidelity synthetic data from the ground up.\"What we&#x27;re seeing is a pivot from defense to offense,\" said one analyst not affiliated with the study. \"The Stanford paper showed the chaos of uncontrolled AI polluting human datasets. This new paper shows the order and utility of controlled AI creating its own datasets. For a Chief Data Officer, this is the difference between cleaning a contaminated well and tapping into a fresh spring.\"From text to intent: The technical leap behind the synthetic consumerThe technical validity of the new method hinges on the quality of the text embeddings, a concept explored in a 2022 paper in EPJ Data Science. That research argued for a rigorous \"construct validity\" framework to ensure that text embeddings — the numerical representations of text — truly \"measure what they are supposed to.\" The success of the SSR method suggests its embeddings effectively capture the nuances of purchase intent. For this new technique to be widely adopted, enterprises will need to be confident that the underlying models are not just generating plausible text, but are mapping that text to scores in a way that is robust and meaningful.The approach also represents a significant leap from prior research, which has largely focused on using text embeddings to analyze and predict ratings from existing online reviews. A 2022 study, for example, evaluated the performance of models like BERT and word2vec in predicting review scores on retail sites, finding that newer models like BERT performed better for general use. The new research moves beyond analyzing existing data to generating novel, predictive insights before a product even hits the market.The dawn of the digital focus groupFor technical decision-makers, the implications are profound. The ability to spin up a \"digital twin\" of a target consumer segment and test product concepts, ad copy, or packaging variations in a matter of hours could drastically accelerate innovation cycles. As the paper notes, these synthetic respondents also provide \"rich qualitative feedback explaining their ratings,\" offering a treasure trove of data for product development that is both scalable and interpretable. While the era of human-only focus groups is far from over, this research provides the most compelling evidence yet that their synthetic counterparts are ready for business.But the business case extends beyond speed and scale. Consider the economics: a traditional survey panel for a national product launch might cost tens of thousands of dollars and take weeks to field. An SSR-based simulation could deliver comparable insights in a fraction of the time, at a fraction of the cost, and with the ability to iterate instantly based on findings. For companies in fast-moving consumer goods categories — where the window between concept and shelf can determine market leadership — this velocity advantage could be decisive.There are, of course, caveats. The method was validated on personal care products; its performance on complex B2B purchasing decisions, luxury goods, or culturally specific products remains unproven. And while the paper demonstrates that SSR can replicate aggregate human behavior, it does not claim to predict individual consumer choices. The technique works at the population level, not the person level — a distinction that matters greatly for applications like personalized marketing.Yet even with these limitations, the research is a watershed. While the era of human-only focus groups is far from over, this paper provides the most compelling evidence yet that their synthetic counterparts are ready for business. The question is no longer whether AI can simulate consumer sentiment, but whether enterprises can move fast enough to capitalize on it before their competitors do.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/51ORdJ4l6mg6ZSTkJpGFOw/85fa4483c879359d1872778236f4fc20/nuneybits_Vector_art_of_AI_shopper_silhouette_e82a806b-f70d-4b1d-9418-71b2ffd65ea4.webp"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/salesforce-bets-on-ai-agents-to-fix-what-it-calls-a-usd7-billion-problem-in",
          "published_at": "Mon, 13 Oct 2025 12:00:00 GMT",
          "title": "Salesforce bets on AI 'agents' to fix what it calls a $7 billion problem in enterprise software",
          "standfirst": "As 50,000 attendees descend on Salesforce&#x27;s Dreamforce conference this week, the enterprise software giant is making its most aggressive bet yet on artificial intelligence agents, positioning itself as the antidote to what it calls an industry-wide \"pilot purgatory\" where 95% of enterprise AI projects never reach production.The company on Monday launched Agentforce 360, a sweeping reimagination of its entire product portfolio designed to transform businesses into what it calls \"agentic enterprises\" — organizations where AI agents work alongside humans to handle up to 40% of work across sales, service, marketing, and operations.\"We are truly in the agentic AI era, and I think it&#x27;s probably the biggest revolution, the biggest transition in technology I&#x27;ve ever experienced in my career,\" said Parker Harris, Salesforce&#x27;s co-founder and chief technology officer, during a recent press briefing. \"In the future, 40% of the work in the Fortune 1000 is probably going to be done by AI, and it&#x27;s going to be humans and AI actually working together.\"The announcement comes at a pivotal moment for Salesforce, which has deployed more than 12,000 AI agent implementations over the past year while building what Harris called a \"$7 billion business\" around its AI platform. Yet the launch also arrives amid unusual turbulence, as CEO Marc Benioff faces fierce backlash for recent comments supporting President Trump and suggesting National Guard troops should patrol San Francisco streets.Why 95% of enterprise AI projects never launchThe stakes are enormous. While companies have rushed to experiment with AI following ChatGPT&#x27;s emergence two years ago, most enterprise deployments have stalled before reaching production, according to recent MIT research that Salesforce executives cited extensively.\"Customers have invested a lot in AI, but they&#x27;re not getting the value,\" said Srini Tallapragada, Salesforce&#x27;s president and chief engineering and customer success officer. \"95% of enterprise AI pilots fail before production. It&#x27;s not because of lack of intent. People want to do this. Everybody understands the power of the technology. But why is it so hard?\"The answer, according to Tallapragada, is that AI tools remain disconnected from enterprise workflows, data, and governance systems. \"You&#x27;re writing prompts, prompts, you&#x27;re getting frustrated because the context is not there,\" he said, describing what he called a \"prompt doom loop.\"Salesforce&#x27;s solution is a deeply integrated platform connecting what it calls four ingredients: the Agentforce 360 agent platform, Data 360 for unified data access, Customer 360 apps containing business logic, and Slack as the \"conversational interface\" where humans and agents collaborate.Slack becomes the front door to SalesforcePerhaps the most significant strategic shift is the elevation of Slack — acquired by Salesforce in 2019 for $27.7 billion — as the primary interface for Salesforce itself. The company is effectively reimagining its traditional Lightning interface around Slack channels, where sales deals, service cases, and data insights will surface conversationally rather than through forms and dashboards.\"Imagine that you maybe don&#x27;t log into Salesforce, you don&#x27;t see Salesforce, but it&#x27;s there. It&#x27;s coming to you in Slack, because that&#x27;s where you&#x27;re getting your work done,\" Harris explained.The strategy includes embedding Salesforce&#x27;s Agentforce agents for sales, IT service, HR service, and analytics directly into Slack, alongside a completely rebuilt Slackbot that acts as a personal AI companion. The company is also launching \"Channel Expert,\" an always-on agent that provides instant answers from channel conversations.To enable third-party AI tools to access Slack&#x27;s conversational data, Salesforce is releasing a Real-Time Search API and Model Context Protocol server. Partners including OpenAI, Anthropic, Google, Perplexity, Writer, Dropbox, Notion, and Cursor are building agents that will live natively in Slack.\"The best way to see the power of the platform is through the AI apps and agents already being built,\" Rob Seaman, a Salesforce executive, said during a technical briefing, citing examples of startups \"achieving tens of thousands of customers that have it installed in 120 days or less.\"Voice and IT service take aim at new marketsBeyond Slack integration, Salesforce announced major expansions into voice-based interactions and employee service. Agentforce Voice, now generally available, transforms traditional IVR systems into natural conversations that can update CRM records, trigger workflows, and seamlessly hand off to human agents.The IT Service offering represents Salesforce&#x27;s most direct challenge to ServiceNow, the market leader. Mudhu Sudhakar, who joined Salesforce two months ago as senior vice president for IT and HR Service, positioned the product as a fundamental reimagining of employee support.\"Legacy IT service management is very portals, forms, tickets focused, manual process,\" Sudhakar said. \"What we had a few key tenets: conversation first and agent first, really focused on having a conversational experience for the people requesting the support and for the people providing the support.\"The IT Service platform includes what Salesforce describes as 25+ specialized agents and 100+ pre-built workflows and connectors that can handle everything from password resets to complex incident management.Early customers report dramatic efficiency gainsCustomer results suggest the approach is gaining traction. Reddit reduced average support resolution time from 8.9 minutes to 1.4 minutes — an 84% improvement — while deflecting 46% of cases entirely to AI agents. \"This efficiency has allowed us to provide on-demand help for complex tasks and boost advertiser satisfaction scores by 20%,\" said John Thompson, Reddit&#x27;s VP of sales strategy and operations, in a statement.Engine, a travel management company, reduced average handle time by 15%, saving over $2 million annually. OpenTable resolved 70% of restaurant and diner inquiries autonomously. And 1-800Accountant achieved a 90% case deflection rate during the critical tax week period.Salesforce&#x27;s own internal deployments may be most telling. Tallapragada&#x27;s customer success organization now handles 1.8 million AI-powered conversations weekly, with metrics published at help.salesforce.com showing how many agents answer versus escalating to humans.Even more significantly, Salesforce has deployed AI-powered sales development representatives to follow up on leads that would previously have gone uncontacted due to cost constraints. \"Now, Agentforce has an SDR which is doing thousands of leads following up,\" Tallapragada explained. The company also increased proactive customer outreach by 40% by shifting staff from reactive support.The trust layer problem enterprises can&#x27;t ignoreGiven enterprise concerns about AI reliability, Salesforce has invested heavily in what it calls the \"trust layer\" — audit trails, compliance checks, and observability tools that let organizations monitor agent behavior at scale.\"You should think of an agent as a human. Digital labor. You need to manage performance just like a human. And you need these audit trails,\" Tallapragada explained.The company encountered this challenge firsthand when its own agent deployment scaled. \"When we started at Agentforce at Salesforce, we would track every message, which is great until 1,000, 3,000,\" Tallapragada said. \"Once you have a million chats, there&#x27;s no human, we cannot do it.\"The platform now includes \"Agentforce Grid\" for searching across millions of conversations to identify and fix problematic patterns. The company also introduced Agent Script, a new scripting language that allows developers to define precise guardrails and deterministic controls for agent behavior.Data infrastructure gets a major upgradeUnderlying the agent capabilities is significant infrastructure investment. Salesforce&#x27;s Data 360 includes \"Intelligent Context,\" which automatically extracts structured information from unstructured content like PDFs, diagrams, and flowcharts using what the company describes as \"AI-powered unstructured data pipelines.\"The company is also collaborating with Databricks, dbt Labs, and Snowflake on the \"Universal Semantic Interchange,\" an attempt to standardize how different platforms define business metrics. The pending $8 billion acquisition of Informatica, expected to close soon, will expand metadata management capabilities across the enterprise.The competitive landscape keeps intensifyingSalesforce&#x27;s aggressive AI agent push comes as virtually every major enterprise software vendor pursues similar strategies. Microsoft has embedded Copilot across its product line, Google offers agent capabilities through Vertex AI and Gemini, and ServiceNow has launched its own agentic offerings.When asked how Salesforce&#x27;s announcement compared to OpenAI&#x27;s recent releases, Tallapragada emphasized that customers will use multiple AI tools simultaneously. \"Most of the time I&#x27;m seeing they&#x27;re using OpenAI, they&#x27;re using Gemini, they&#x27;re using Anthropic, just like Salesforce, we use all three,\" he said.The real differentiation, executives argued, lies not in the AI models but in the integration with business processes and data. Harris framed the competition in terms familiar from Salesforce&#x27;s founding: \"26 years ago, we just said, let&#x27;s make Salesforce automation as easy as buying a book on Amazon.com. We&#x27;re doing that same thing. We want to make agentic AI as easy as buying a book on Amazon.\"The company&#x27;s customer success stories are impressive but remain a small fraction of its customer base. With 150,000 Salesforce customers and one million Slack customers, the 12,000 Agentforce deployments represent roughly 8% penetration — strong for a one-year-old product line, but hardly ubiquitous.The company&#x27;s stock, down roughly 28% year to date with a Relative Strength rating of just 15, suggests investors remain skeptical. This week&#x27;s Dreamforce demonstrations — and the months of customer deployments that follow — will begin to provide answers to whether Salesforce can finally move enterprise AI from pilots to production at scale, or whether the \"$7 billion business\" remains more aspiration than reality.",
          "content": "As 50,000 attendees descend on Salesforce&#x27;s Dreamforce conference this week, the enterprise software giant is making its most aggressive bet yet on artificial intelligence agents, positioning itself as the antidote to what it calls an industry-wide \"pilot purgatory\" where 95% of enterprise AI projects never reach production.The company on Monday launched Agentforce 360, a sweeping reimagination of its entire product portfolio designed to transform businesses into what it calls \"agentic enterprises\" — organizations where AI agents work alongside humans to handle up to 40% of work across sales, service, marketing, and operations.\"We are truly in the agentic AI era, and I think it&#x27;s probably the biggest revolution, the biggest transition in technology I&#x27;ve ever experienced in my career,\" said Parker Harris, Salesforce&#x27;s co-founder and chief technology officer, during a recent press briefing. \"In the future, 40% of the work in the Fortune 1000 is probably going to be done by AI, and it&#x27;s going to be humans and AI actually working together.\"The announcement comes at a pivotal moment for Salesforce, which has deployed more than 12,000 AI agent implementations over the past year while building what Harris called a \"$7 billion business\" around its AI platform. Yet the launch also arrives amid unusual turbulence, as CEO Marc Benioff faces fierce backlash for recent comments supporting President Trump and suggesting National Guard troops should patrol San Francisco streets.Why 95% of enterprise AI projects never launchThe stakes are enormous. While companies have rushed to experiment with AI following ChatGPT&#x27;s emergence two years ago, most enterprise deployments have stalled before reaching production, according to recent MIT research that Salesforce executives cited extensively.\"Customers have invested a lot in AI, but they&#x27;re not getting the value,\" said Srini Tallapragada, Salesforce&#x27;s president and chief engineering and customer success officer. \"95% of enterprise AI pilots fail before production. It&#x27;s not because of lack of intent. People want to do this. Everybody understands the power of the technology. But why is it so hard?\"The answer, according to Tallapragada, is that AI tools remain disconnected from enterprise workflows, data, and governance systems. \"You&#x27;re writing prompts, prompts, you&#x27;re getting frustrated because the context is not there,\" he said, describing what he called a \"prompt doom loop.\"Salesforce&#x27;s solution is a deeply integrated platform connecting what it calls four ingredients: the Agentforce 360 agent platform, Data 360 for unified data access, Customer 360 apps containing business logic, and Slack as the \"conversational interface\" where humans and agents collaborate.Slack becomes the front door to SalesforcePerhaps the most significant strategic shift is the elevation of Slack — acquired by Salesforce in 2019 for $27.7 billion — as the primary interface for Salesforce itself. The company is effectively reimagining its traditional Lightning interface around Slack channels, where sales deals, service cases, and data insights will surface conversationally rather than through forms and dashboards.\"Imagine that you maybe don&#x27;t log into Salesforce, you don&#x27;t see Salesforce, but it&#x27;s there. It&#x27;s coming to you in Slack, because that&#x27;s where you&#x27;re getting your work done,\" Harris explained.The strategy includes embedding Salesforce&#x27;s Agentforce agents for sales, IT service, HR service, and analytics directly into Slack, alongside a completely rebuilt Slackbot that acts as a personal AI companion. The company is also launching \"Channel Expert,\" an always-on agent that provides instant answers from channel conversations.To enable third-party AI tools to access Slack&#x27;s conversational data, Salesforce is releasing a Real-Time Search API and Model Context Protocol server. Partners including OpenAI, Anthropic, Google, Perplexity, Writer, Dropbox, Notion, and Cursor are building agents that will live natively in Slack.\"The best way to see the power of the platform is through the AI apps and agents already being built,\" Rob Seaman, a Salesforce executive, said during a technical briefing, citing examples of startups \"achieving tens of thousands of customers that have it installed in 120 days or less.\"Voice and IT service take aim at new marketsBeyond Slack integration, Salesforce announced major expansions into voice-based interactions and employee service. Agentforce Voice, now generally available, transforms traditional IVR systems into natural conversations that can update CRM records, trigger workflows, and seamlessly hand off to human agents.The IT Service offering represents Salesforce&#x27;s most direct challenge to ServiceNow, the market leader. Mudhu Sudhakar, who joined Salesforce two months ago as senior vice president for IT and HR Service, positioned the product as a fundamental reimagining of employee support.\"Legacy IT service management is very portals, forms, tickets focused, manual process,\" Sudhakar said. \"What we had a few key tenets: conversation first and agent first, really focused on having a conversational experience for the people requesting the support and for the people providing the support.\"The IT Service platform includes what Salesforce describes as 25+ specialized agents and 100+ pre-built workflows and connectors that can handle everything from password resets to complex incident management.Early customers report dramatic efficiency gainsCustomer results suggest the approach is gaining traction. Reddit reduced average support resolution time from 8.9 minutes to 1.4 minutes — an 84% improvement — while deflecting 46% of cases entirely to AI agents. \"This efficiency has allowed us to provide on-demand help for complex tasks and boost advertiser satisfaction scores by 20%,\" said John Thompson, Reddit&#x27;s VP of sales strategy and operations, in a statement.Engine, a travel management company, reduced average handle time by 15%, saving over $2 million annually. OpenTable resolved 70% of restaurant and diner inquiries autonomously. And 1-800Accountant achieved a 90% case deflection rate during the critical tax week period.Salesforce&#x27;s own internal deployments may be most telling. Tallapragada&#x27;s customer success organization now handles 1.8 million AI-powered conversations weekly, with metrics published at help.salesforce.com showing how many agents answer versus escalating to humans.Even more significantly, Salesforce has deployed AI-powered sales development representatives to follow up on leads that would previously have gone uncontacted due to cost constraints. \"Now, Agentforce has an SDR which is doing thousands of leads following up,\" Tallapragada explained. The company also increased proactive customer outreach by 40% by shifting staff from reactive support.The trust layer problem enterprises can&#x27;t ignoreGiven enterprise concerns about AI reliability, Salesforce has invested heavily in what it calls the \"trust layer\" — audit trails, compliance checks, and observability tools that let organizations monitor agent behavior at scale.\"You should think of an agent as a human. Digital labor. You need to manage performance just like a human. And you need these audit trails,\" Tallapragada explained.The company encountered this challenge firsthand when its own agent deployment scaled. \"When we started at Agentforce at Salesforce, we would track every message, which is great until 1,000, 3,000,\" Tallapragada said. \"Once you have a million chats, there&#x27;s no human, we cannot do it.\"The platform now includes \"Agentforce Grid\" for searching across millions of conversations to identify and fix problematic patterns. The company also introduced Agent Script, a new scripting language that allows developers to define precise guardrails and deterministic controls for agent behavior.Data infrastructure gets a major upgradeUnderlying the agent capabilities is significant infrastructure investment. Salesforce&#x27;s Data 360 includes \"Intelligent Context,\" which automatically extracts structured information from unstructured content like PDFs, diagrams, and flowcharts using what the company describes as \"AI-powered unstructured data pipelines.\"The company is also collaborating with Databricks, dbt Labs, and Snowflake on the \"Universal Semantic Interchange,\" an attempt to standardize how different platforms define business metrics. The pending $8 billion acquisition of Informatica, expected to close soon, will expand metadata management capabilities across the enterprise.The competitive landscape keeps intensifyingSalesforce&#x27;s aggressive AI agent push comes as virtually every major enterprise software vendor pursues similar strategies. Microsoft has embedded Copilot across its product line, Google offers agent capabilities through Vertex AI and Gemini, and ServiceNow has launched its own agentic offerings.When asked how Salesforce&#x27;s announcement compared to OpenAI&#x27;s recent releases, Tallapragada emphasized that customers will use multiple AI tools simultaneously. \"Most of the time I&#x27;m seeing they&#x27;re using OpenAI, they&#x27;re using Gemini, they&#x27;re using Anthropic, just like Salesforce, we use all three,\" he said.The real differentiation, executives argued, lies not in the AI models but in the integration with business processes and data. Harris framed the competition in terms familiar from Salesforce&#x27;s founding: \"26 years ago, we just said, let&#x27;s make Salesforce automation as easy as buying a book on Amazon.com. We&#x27;re doing that same thing. We want to make agentic AI as easy as buying a book on Amazon.\"The company&#x27;s customer success stories are impressive but remain a small fraction of its customer base. With 150,000 Salesforce customers and one million Slack customers, the 12,000 Agentforce deployments represent roughly 8% penetration — strong for a one-year-old product line, but hardly ubiquitous.The company&#x27;s stock, down roughly 28% year to date with a Relative Strength rating of just 15, suggests investors remain skeptical. This week&#x27;s Dreamforce demonstrations — and the months of customer deployments that follow — will begin to provide answers to whether Salesforce can finally move enterprise AI from pilots to production at scale, or whether the \"$7 billion business\" remains more aspiration than reality.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4ElJnVoqNF5EdTdQ2qbc94/6c61cde31557a66a34fdfbbfaa9e57ed/nuneybits_Vector_art_of_businessperson_guiding_robot_f1c9b0fc-59ad-455c-b635-5551c598aa7b.webp"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/best-smart-led-light-bulbs-143022856.html",
          "published_at": "Mon, 13 Oct 2025 09:00:36 +0000",
          "title": "The best smart LED light bulbs for 2025",
          "standfirst": "Smart LED light bulbs are one of the easiest ways to get into the IoT space. These smart lighting solutions let you control your home’s illumination from your phone and other connected devices, and in addition to that practicality, they also inject some fun into your space. Color-changing bulbs have a plethora of RGB options for you to customize the lighting mood for your next movie night, date night or game day, or you can opt for cozy warm white light when you need to unwind at the end of a long day.It goes without saying that many of these smart LED light bulbs work with Amazon’s Alexa and the Google Assistant, so if you already have a smart home setup in the works, you can find one that fits into your chosen ecosystem. And arguably the best thing about these devices is that they can fit into any budget; affordable and advanced options have flooded the space over the past few years. We’ve tested out a bunch of smart lights over the years, and these are our current favorites. Table of contents Best smart lights for 2025 Other smart bulbs we tested What to look for in smart light bulbs Smart light bulb FAQs Best smart lights for 2025 Other smart bulbs we’ve tested Nanoleaf Smarter Kit While we’ve recommended Nanoleaf’s Smarter Kits in guides in the past, they’re a bit more niche than other smart lights on this list. They’re best for adding flare to your living room or game-streaming setup as they come in different shapes like hexagons and triangles and can sync with music. In addition to different colors, light animations and schedules, Nanoleaf’s Smart Kits also support Amazon Alexa and Google Assistant voice commands. What to look for in smart light bulbs Connectivity (To hub or not to hub) One of the biggest appeals of smart lighting solutions is being able to control them from your phone. Most of them are able to do so by connecting to it via Wi-Fi or Bluetooth, or via an external hub, which handles the connection for them. Bluetooth connectivity limits the range in which you’ll be able to control the light, so it’s only best for a limited number of bulbs and ones you don’t expect to control when you’re away. Wi-Fi color-changing bulbs are easy to set up and can be cheaper overall since they don’t require a hub to connect them. However, having something like a central Zigbee hub can make your whole system more reliable since its connection is separate from your home’s network. For that reason, hub-based bulbs tend to be more expandable, so we mainly recommend those if you want to eventually have dozens of smart lights around your home. White or color? Most color-changing bulbs you’ll find today are “white and color” bulbs, meaning they can glow in vibrant RGB color-options like blues, pinks, greens and everything in between, as well as shine with different temperatures of white. But there are some white-only bulbs out there, and they are often a bit more affordable than their color counterparts. While we recommend springing for the white-and-color devices, if you’d prefer white only, make sure you’re getting a bulb that can span the color temperature spectrum (typically from about 2000 to 5000 Kelvin), offering you various levels of cool and warm white light. App features One of the perks of smart lighting solutions is the amount of control you have over them thanks to their various app-control capabilities. Most companion apps let you do things like set lighting schedules and timers, group individual lights into room designations and create your own custom light “scenes” with different RGB options. But we have seen other features that aren’t as ubiquitous like vacation mode for automatically turning lights on and off to enhance your home security, and sync with media, which changes the colors of lights depending on the music you’re listening to or the game you’re currently live-streaming. Smart home compatibility If you use a smart assistant like Amazon’s Alexa or the Google Assistant regularly, make sure the smart lights or smart switches work with your favorite. All of the bulbs we tested supported both Amazon’s and Google’s virtual assistants, allowing you to use voice commands to turn lights on and off, dim them with a virtual dimmer and more. The wildcard here is Siri and Apple’s HomeKit; while numerous smart bulbs have added HomeKit support, not all lights are compatible with Apple’s smart home system. Expandability We alluded to this above, but you’ll want to consider how many smart lights you eventually want in your home. Some brands and lighting systems are easier to expand than others, and we generally recommend going for hub-based bulbs if you plan on putting smart lights in every room in your home. If you’re only looking to deck out your home office or living room with some fancy color-changing bulbs, Wi-Fi options should serve you well. Thankfully, these are some of the most affordable smart home devices you can get, so even if you don’t have a clear answer to this question now, you can reconsider your options down the line if you do decide to outfit your home with multiple smart bulbs. Smart light bulb FAQs What’s the best smart light bulb for Alexa? There is no best smart light bulb for Alexa. Amazon doesn’t make its own smart bulbs (like it does for smart plugs and thermostats), but rather there are dozens of smart lights made by third-parties that work with Alexa — including all of the ones we tested. Before picking the best smart light bulb for you, make sure to check the voice assistants that the contenders support. You’ll find that most smart light bulbs available today work with Amazon’s Alexa and the Google Assistant, and plenty of them also have support for Apple’s Siri and HomeKit. Can you put a smart bulb in any lamp? Smart light bulbs can go into most modern light fixtures — but just like regular bulbs, they need to be the right shape/size for the fixture. A standard A19 smart light bulb should work properly in most table, floor and other lamps. If you have a fixture that takes a specific type of bulb, look for smart bulbs that will fit properly. Do smart light bulbs use electricity when off? Smart light bulbs do use a negligible amount of electricity when their fixtures are turned off. This is due to the fact that the smart bulb needs to stay in constant contact with your home’s internet connection or Bluetooth in order to work properly. However, their energy-saving benefits usually outweigh the small amount of power they consume even while turned off.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-smart-led-light-bulbs-143022856.html?src=rss",
          "content": "Smart LED light bulbs are one of the easiest ways to get into the IoT space. These smart lighting solutions let you control your home’s illumination from your phone and other connected devices, and in addition to that practicality, they also inject some fun into your space. Color-changing bulbs have a plethora of RGB options for you to customize the lighting mood for your next movie night, date night or game day, or you can opt for cozy warm white light when you need to unwind at the end of a long day.It goes without saying that many of these smart LED light bulbs work with Amazon’s Alexa and the Google Assistant, so if you already have a smart home setup in the works, you can find one that fits into your chosen ecosystem. And arguably the best thing about these devices is that they can fit into any budget; affordable and advanced options have flooded the space over the past few years. We’ve tested out a bunch of smart lights over the years, and these are our current favorites. Table of contents Best smart lights for 2025 Other smart bulbs we tested What to look for in smart light bulbs Smart light bulb FAQs Best smart lights for 2025 Other smart bulbs we’ve tested Nanoleaf Smarter Kit While we’ve recommended Nanoleaf’s Smarter Kits in guides in the past, they’re a bit more niche than other smart lights on this list. They’re best for adding flare to your living room or game-streaming setup as they come in different shapes like hexagons and triangles and can sync with music. In addition to different colors, light animations and schedules, Nanoleaf’s Smart Kits also support Amazon Alexa and Google Assistant voice commands. What to look for in smart light bulbs Connectivity (To hub or not to hub) One of the biggest appeals of smart lighting solutions is being able to control them from your phone. Most of them are able to do so by connecting to it via Wi-Fi or Bluetooth, or via an external hub, which handles the connection for them. Bluetooth connectivity limits the range in which you’ll be able to control the light, so it’s only best for a limited number of bulbs and ones you don’t expect to control when you’re away. Wi-Fi color-changing bulbs are easy to set up and can be cheaper overall since they don’t require a hub to connect them. However, having something like a central Zigbee hub can make your whole system more reliable since its connection is separate from your home’s network. For that reason, hub-based bulbs tend to be more expandable, so we mainly recommend those if you want to eventually have dozens of smart lights around your home. White or color? Most color-changing bulbs you’ll find today are “white and color” bulbs, meaning they can glow in vibrant RGB color-options like blues, pinks, greens and everything in between, as well as shine with different temperatures of white. But there are some white-only bulbs out there, and they are often a bit more affordable than their color counterparts. While we recommend springing for the white-and-color devices, if you’d prefer white only, make sure you’re getting a bulb that can span the color temperature spectrum (typically from about 2000 to 5000 Kelvin), offering you various levels of cool and warm white light. App features One of the perks of smart lighting solutions is the amount of control you have over them thanks to their various app-control capabilities. Most companion apps let you do things like set lighting schedules and timers, group individual lights into room designations and create your own custom light “scenes” with different RGB options. But we have seen other features that aren’t as ubiquitous like vacation mode for automatically turning lights on and off to enhance your home security, and sync with media, which changes the colors of lights depending on the music you’re listening to or the game you’re currently live-streaming. Smart home compatibility If you use a smart assistant like Amazon’s Alexa or the Google Assistant regularly, make sure the smart lights or smart switches work with your favorite. All of the bulbs we tested supported both Amazon’s and Google’s virtual assistants, allowing you to use voice commands to turn lights on and off, dim them with a virtual dimmer and more. The wildcard here is Siri and Apple’s HomeKit; while numerous smart bulbs have added HomeKit support, not all lights are compatible with Apple’s smart home system. Expandability We alluded to this above, but you’ll want to consider how many smart lights you eventually want in your home. Some brands and lighting systems are easier to expand than others, and we generally recommend going for hub-based bulbs if you plan on putting smart lights in every room in your home. If you’re only looking to deck out your home office or living room with some fancy color-changing bulbs, Wi-Fi options should serve you well. Thankfully, these are some of the most affordable smart home devices you can get, so even if you don’t have a clear answer to this question now, you can reconsider your options down the line if you do decide to outfit your home with multiple smart bulbs. Smart light bulb FAQs What’s the best smart light bulb for Alexa? There is no best smart light bulb for Alexa. Amazon doesn’t make its own smart bulbs (like it does for smart plugs and thermostats), but rather there are dozens of smart lights made by third-parties that work with Alexa — including all of the ones we tested. Before picking the best smart light bulb for you, make sure to check the voice assistants that the contenders support. You’ll find that most smart light bulbs available today work with Amazon’s Alexa and the Google Assistant, and plenty of them also have support for Apple’s Siri and HomeKit. Can you put a smart bulb in any lamp? Smart light bulbs can go into most modern light fixtures — but just like regular bulbs, they need to be the right shape/size for the fixture. A standard A19 smart light bulb should work properly in most table, floor and other lamps. If you have a fixture that takes a specific type of bulb, look for smart bulbs that will fit properly. Do smart light bulbs use electricity when off? Smart light bulbs do use a negligible amount of electricity when their fixtures are turned off. This is due to the fact that the smart bulb needs to stay in constant contact with your home’s internet connection or Bluetooth in order to work properly. However, their energy-saving benefits usually outweigh the small amount of power they consume even while turned off.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-smart-led-light-bulbs-143022856.html?src=rss",
          "feed_position": 39
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/breaking-the-bottleneck-why-ai-demands-an-ssd-first-future",
          "published_at": "Mon, 13 Oct 2025 04:00:00 GMT",
          "title": "Breaking the bottleneck: Why AI demands an SSD-first future",
          "standfirst": "Presented by SolidigmAs AI adoption surges, data centers face a critical bottleneck in storage — and traditional HDDs are at the center of it. Data that once sat idle as cold archives is now being pulled into frequent use to build more accurate models and deliver better inference results. This shift from cold data to warm data demands low-latency, high-throughput storage that can handle parallel computations. HDDs will remain the workhorse for low-cost cold storage, but without rethinking their role, the high-capacity storage layer risks becoming the weakest link in the AI factory.\"Modern AI workloads, combined with data center constraints, have created new challenges for HDDs,\" says Jeff Janukowicz, research vice president at IDC. \"While HDD suppliers are addressing data storage growth by offering larger drives, this often comes at the expense of slower performance. As a result, the concept of &#x27;nearline SSDs&#x27; is becoming an increasingly relevant topic of discussion within the industry.\" Today, AI operators need to maximize GPU utilization, manage network-attached storage efficiently, and scale compute — all while cutting costs on increasingly scarce power and space. In an environment where every watt and every square inch counts, says Roger Corell, senior director of AI and leadership marketing at Solidigm, success requires more than a technical refresh. It calls for a deeper realignment.“It speaks to the tectonic shift in the value of data for AI,” Corell says. “That’s where high-capacity SSDs come into play. Along with capacity, they bring performance and efficiency -- enabling exabyte-scale storage pipelines to keep pace with the relentless pace of data set size. All of that consumes power and space, so we need to do it as efficiently as possible to enable more GPU scale in this constrained environment.”High-capacity SSDs aren’t just displacing HDDs — they’re removing one of the biggest bottlenecks on the AI factory floor. By delivering massive gains in performance, efficiency, and density, SSDs free up the power and space needed to push GPU scale further. It’s less a storage upgrade than a structural shift in how data infrastructure is designed for the AI era.HDDs vs. SDDs: More than just a hardware refreshHDDs have impressive mechanical designs, but they&#x27;re made up of many moving parts that at scale use more energy, take up more space, and fail at a higher rate than solid state drives. The reliance on spinning platters and mechanical read/write heads inherently limits Input/Output Operations Per Second (IOPS), creating bottlenecks for AI workloads that demand low latency, high concurrency, and sustained throughput. HDDs also struggle with latency-sensitive tasks, as the physical act of seeking data introduces mechanical delays unsuited for real-time AI inference and training. Moreover, their power and cooling requirements increase significantly under frequent and intensive data access, reducing efficiency as data scales and warms.In contrast, the SSD-based VAST storage solution reduces energy usage by ~$1M a year, and in an AI environment where every watt matters, this is a huge advantage for SSDs. To demonstrate, Solidigm and VAST Data completed a study examining the economics of data storage at exabyte scale — a quadrillion bytes, or a billion gigabytes, with an analysis of storage power consumption versus HDDs over a 10-year period. As a starting reference point, you’d need four 30TB HDDs to equal the capacity of a single 122TB Solidigm SSD. After factoring in VAST’s data reduction techniques made possible by the superior performance of SSDs, the exabyte solution comprises 3,738 Solidigm SSDs vs over 40,000 high-capacity HDDs. The study found that the SSD-based VAST solution consumes 77% less storage energy. Minimizing data center footprints\"We’re shipping 122-terabyte drives to some of the top OEMs and leading AI cloud service providers in the world,\" Corell says. \"When you compare an all-122TB SSD to hybrid HDD + TLC SSD configuration, they&#x27;re getting a nine-to-one savings in data center footprint. And yes, it’s important in these massive data centers that are building their own nuclear reactors and signing hefty power purchase agreements with renewable energy providers, but it’s increasingly important as you get to the regional data centers, the local data centers, and all the way out to your edge deployments where space can come at a premium.\"That nine-to-one savings goes beyond space and power — it lets organizations fit infrastructure into previously unavailable spaces, expand GPU scale, or build smaller footprints.\"If you’re given X amount of land and Y amount of power, you’re going to use it. You’re AI\" Corell explains, “where every watt and square inch counts, so why not use it in the most efficient way? Get the most efficient storage possible on the planet and enable greater GPU scale within that envelope that you have to fit in. On an ongoing basis, it’s going to save you operational cost as well. You have 90 percent fewer storage bays to maintain, and the cost associated with that is gone.\"Another often-overlooked element, the (much) larger physical footprint of data stored on mechanical HDDs results in a greater construction materials footprint. Collectively, concrete and steel production accounts for over 15% of global greenhouse gas emissions. By reducing the physical footprint of storage, high-capacity SSDs can help reduce embodied concrete and steel-based emissions by more than 80% compared to HDDs. And in the last phase of the sustainability life cycle, which is drive end-of-life, there will be 90% percent fewer drives to disposition. . Reshaping cold and archival storage strategiesThe move to SDD isn&#x27;t just a storage upgrade; it&#x27;s a fundamental realignment of data infrastructure strategy in the AI era, and it&#x27;s picking up speed.\"Big hyperscalers are looking to wring the most out of their existing infrastructure, doing unnatural acts, if you will, with HDDs like overprovisioning them to near 90% to try to wring out as many IOPS per terabyte as possible, but they’re beginning to come around,\" Corell says. \"Once they turn to a modern all high-capacity storage infrastructure, the industry at large will be on that trajectory. Plus, we&#x27;re starting to see these lessons learned on the value of modern storage in AI applied to other segments as well, such as big data analytics, HPC, and many more.\"While all-flash solutions are being embraced almost universally, there will always be a place for HDDs, he adds. HDDs will persist in usages like archival, cold storage, and scenarios where pure cost per gigabyte concerns outweigh the need for real-time access. But as the token economy heats up and enterprises realize value in monetizing data, the warm and warming data segments will continue to grow. Solving power challenges of the futureNow in its 4th generation, with more than 122 cumulative exabytes shipped to date, Solidigm’s QLC (Quad-Level Cell) technology has led the industry in balancing higher drive capacities with cost efficiency.\"We don’t think of storage as just storing bits and bytes. We think about how we can develop these amazing drives that are able to deliver benefits at a solution level,\" Corell says. \"The shining star on that is our recently launched, E1.S, designed specifically for dense and efficient storage in direct attach storage configurations for the next-generation fanless GPU server.\"The Solidigm D7-PS1010 E1.S is a breakthrough, the industry’s first eSSD with single-sided direct-to-chip liquid cooling technology. Solidigm worked with NVIDIA to address the dual challenges of heat management and cost efficiency, while delivering the high performance required for demanding AI workloads. \"We’re rapidly moving to an environment where all critical IT components will be direct-to-chip liquid-cooled on the direct attach side,\" he says. \"I think the market needs to be looking at their approach to cooling, because power limitations, power challenges are not going to abate in my lifetime, at least. They need to be applying a neocloud mindset to how they’re architecting the most efficient infrastructure.\"Increasingly complex inference is pushing against a memory wall, which makes storage architecture a front-line design challenge, not an afterthought. High-capacity SSDs, paired with liquid cooling and efficient design, are emerging as the only path to meet AI’s escalating demands. The mandate now is to build infrastructure not just for efficiency, but for storage that can efficiently scale as data grows. The organizations that realign storage now will be the ones able to scale AI tomorrow.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by SolidigmAs AI adoption surges, data centers face a critical bottleneck in storage — and traditional HDDs are at the center of it. Data that once sat idle as cold archives is now being pulled into frequent use to build more accurate models and deliver better inference results. This shift from cold data to warm data demands low-latency, high-throughput storage that can handle parallel computations. HDDs will remain the workhorse for low-cost cold storage, but without rethinking their role, the high-capacity storage layer risks becoming the weakest link in the AI factory.\"Modern AI workloads, combined with data center constraints, have created new challenges for HDDs,\" says Jeff Janukowicz, research vice president at IDC. \"While HDD suppliers are addressing data storage growth by offering larger drives, this often comes at the expense of slower performance. As a result, the concept of &#x27;nearline SSDs&#x27; is becoming an increasingly relevant topic of discussion within the industry.\" Today, AI operators need to maximize GPU utilization, manage network-attached storage efficiently, and scale compute — all while cutting costs on increasingly scarce power and space. In an environment where every watt and every square inch counts, says Roger Corell, senior director of AI and leadership marketing at Solidigm, success requires more than a technical refresh. It calls for a deeper realignment.“It speaks to the tectonic shift in the value of data for AI,” Corell says. “That’s where high-capacity SSDs come into play. Along with capacity, they bring performance and efficiency -- enabling exabyte-scale storage pipelines to keep pace with the relentless pace of data set size. All of that consumes power and space, so we need to do it as efficiently as possible to enable more GPU scale in this constrained environment.”High-capacity SSDs aren’t just displacing HDDs — they’re removing one of the biggest bottlenecks on the AI factory floor. By delivering massive gains in performance, efficiency, and density, SSDs free up the power and space needed to push GPU scale further. It’s less a storage upgrade than a structural shift in how data infrastructure is designed for the AI era.HDDs vs. SDDs: More than just a hardware refreshHDDs have impressive mechanical designs, but they&#x27;re made up of many moving parts that at scale use more energy, take up more space, and fail at a higher rate than solid state drives. The reliance on spinning platters and mechanical read/write heads inherently limits Input/Output Operations Per Second (IOPS), creating bottlenecks for AI workloads that demand low latency, high concurrency, and sustained throughput. HDDs also struggle with latency-sensitive tasks, as the physical act of seeking data introduces mechanical delays unsuited for real-time AI inference and training. Moreover, their power and cooling requirements increase significantly under frequent and intensive data access, reducing efficiency as data scales and warms.In contrast, the SSD-based VAST storage solution reduces energy usage by ~$1M a year, and in an AI environment where every watt matters, this is a huge advantage for SSDs. To demonstrate, Solidigm and VAST Data completed a study examining the economics of data storage at exabyte scale — a quadrillion bytes, or a billion gigabytes, with an analysis of storage power consumption versus HDDs over a 10-year period. As a starting reference point, you’d need four 30TB HDDs to equal the capacity of a single 122TB Solidigm SSD. After factoring in VAST’s data reduction techniques made possible by the superior performance of SSDs, the exabyte solution comprises 3,738 Solidigm SSDs vs over 40,000 high-capacity HDDs. The study found that the SSD-based VAST solution consumes 77% less storage energy. Minimizing data center footprints\"We’re shipping 122-terabyte drives to some of the top OEMs and leading AI cloud service providers in the world,\" Corell says. \"When you compare an all-122TB SSD to hybrid HDD + TLC SSD configuration, they&#x27;re getting a nine-to-one savings in data center footprint. And yes, it’s important in these massive data centers that are building their own nuclear reactors and signing hefty power purchase agreements with renewable energy providers, but it’s increasingly important as you get to the regional data centers, the local data centers, and all the way out to your edge deployments where space can come at a premium.\"That nine-to-one savings goes beyond space and power — it lets organizations fit infrastructure into previously unavailable spaces, expand GPU scale, or build smaller footprints.\"If you’re given X amount of land and Y amount of power, you’re going to use it. You’re AI\" Corell explains, “where every watt and square inch counts, so why not use it in the most efficient way? Get the most efficient storage possible on the planet and enable greater GPU scale within that envelope that you have to fit in. On an ongoing basis, it’s going to save you operational cost as well. You have 90 percent fewer storage bays to maintain, and the cost associated with that is gone.\"Another often-overlooked element, the (much) larger physical footprint of data stored on mechanical HDDs results in a greater construction materials footprint. Collectively, concrete and steel production accounts for over 15% of global greenhouse gas emissions. By reducing the physical footprint of storage, high-capacity SSDs can help reduce embodied concrete and steel-based emissions by more than 80% compared to HDDs. And in the last phase of the sustainability life cycle, which is drive end-of-life, there will be 90% percent fewer drives to disposition. . Reshaping cold and archival storage strategiesThe move to SDD isn&#x27;t just a storage upgrade; it&#x27;s a fundamental realignment of data infrastructure strategy in the AI era, and it&#x27;s picking up speed.\"Big hyperscalers are looking to wring the most out of their existing infrastructure, doing unnatural acts, if you will, with HDDs like overprovisioning them to near 90% to try to wring out as many IOPS per terabyte as possible, but they’re beginning to come around,\" Corell says. \"Once they turn to a modern all high-capacity storage infrastructure, the industry at large will be on that trajectory. Plus, we&#x27;re starting to see these lessons learned on the value of modern storage in AI applied to other segments as well, such as big data analytics, HPC, and many more.\"While all-flash solutions are being embraced almost universally, there will always be a place for HDDs, he adds. HDDs will persist in usages like archival, cold storage, and scenarios where pure cost per gigabyte concerns outweigh the need for real-time access. But as the token economy heats up and enterprises realize value in monetizing data, the warm and warming data segments will continue to grow. Solving power challenges of the futureNow in its 4th generation, with more than 122 cumulative exabytes shipped to date, Solidigm’s QLC (Quad-Level Cell) technology has led the industry in balancing higher drive capacities with cost efficiency.\"We don’t think of storage as just storing bits and bytes. We think about how we can develop these amazing drives that are able to deliver benefits at a solution level,\" Corell says. \"The shining star on that is our recently launched, E1.S, designed specifically for dense and efficient storage in direct attach storage configurations for the next-generation fanless GPU server.\"The Solidigm D7-PS1010 E1.S is a breakthrough, the industry’s first eSSD with single-sided direct-to-chip liquid cooling technology. Solidigm worked with NVIDIA to address the dual challenges of heat management and cost efficiency, while delivering the high performance required for demanding AI workloads. \"We’re rapidly moving to an environment where all critical IT components will be direct-to-chip liquid-cooled on the direct attach side,\" he says. \"I think the market needs to be looking at their approach to cooling, because power limitations, power challenges are not going to abate in my lifetime, at least. They need to be applying a neocloud mindset to how they’re architecting the most efficient infrastructure.\"Increasingly complex inference is pushing against a memory wall, which makes storage architecture a front-line design challenge, not an afterthought. High-capacity SSDs, paired with liquid cooling and efficient design, are emerging as the only path to meet AI’s escalating demands. The mandate now is to build infrastructure not just for efficiency, but for storage that can efficiently scale as data grows. The organizations that realign storage now will be the ones able to scale AI tomorrow.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 7,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4rRjfWe1S9u2XgvoKASwHM/ddafa77e43acdade763516ae3aa9a5fe/Solidigm_2.png"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/1FsFs77cl1uzCE3JPEBnrk/7541c62def835191ff404046af4030c7/cfr0z3n_graphic_novel_hyper_detailed_close_up_on_a_cybernetic_b_9624e28f-5392-4c92-a115-0520c6058152.png",
      "popularity_score": 2014.8394272222222,
      "ai_summary": [
        "EAGLET is a framework to improve AI agent performance on long-horizon tasks.",
        "It uses a \"global planner\" to reduce hallucinations and improve efficiency.",
        "The framework was developed by researchers from multiple universities.",
        "EAGLET generates a high-level plan based on task instructions.",
        "It helps agents stay on task and reduces planning errors."
      ]
    },
    {
      "id": "cluster_15",
      "coverage": 2,
      "updated_at": "2025-10-14T18:19:06-04:00",
      "title": "Netflix is making a big bet on video podcasts",
      "neutral_headline": "Netflix partners with Spotify for video podcast distribution",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/799582/netflix-spotify-video-podcast-deal",
          "published_at": "2025-10-14T18:19:06-04:00",
          "title": "Netflix is making a big bet on video podcasts",
          "standfirst": "Netflix is no longer just a home for TV shows, movies, documentaries, and live WWE matches — soon, you’ll be able to stream video podcasts, too. The streaming giant announced on Tuesday that it’s partnering with Spotify’s podcast studio and The Ringer to offer 16 series on its platform, including The Bill Simmons Podcast, Conspiracy [&#8230;]",
          "content": "Netflix is no longer just a home for TV shows, movies, documentaries, and live WWE matches — soon, you’ll be able to stream video podcasts, too. The streaming giant announced on Tuesday that it’s partnering with Spotify’s podcast studio and The Ringer to offer 16 series on its platform, including The Bill Simmons Podcast, Conspiracy Theories, as well as The Ringer’s shows on the NFL, NBA, Fantasy Football, and F1. The podcasts will appear on Netflix in the US starting in 2026 before expanding to other countries. As part of the deal, the shows won’t appear “in their entirety” on YouTube, according to a report from The New York Times. Not only is YouTube Netflix’s biggest rival, it also tops Spotify and Apple Music as the most popular podcast streaming platform, raking in more than 1 billion listeners each month. Video podcasts, which show hosts during their conversations, are becoming increasingly popular as creators try to expand their reach across social media. Netflix won’t show commercial breaks for this first round of video podcasts, but Spotify’s ads within the podcasts will remain, the Times reports. The streaming service already produces several podcasts about its shows, like You Cannot Make This Up, Skip Intro, and We Have the Receipts, which also appear on YouTube. In April, Netflix co-CEO Ted Sarandos hinted at bringing podcasts to the platform during an earnings call, saying, “As the popularity of video podcasts grow, I suspect you&#8217;ll see some of them find their way to Netflix.” It sounds like Spotify has more plans to expand the reach of its podcasts, too, as the company says it aims to “bring similar opportunities to a wider range of creators” in the future. You can view the full list of podcasts coming to Netflix on the company’s website.",
          "feed_position": 1
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/14/spotifys-video-podcasts-are-coming-to-netflix-next-year/",
          "published_at": "Tue, 14 Oct 2025 18:00:00 +0000",
          "title": "Spotify partners with Netflix for video podcast distribution deal",
          "standfirst": "Spotify is partnering with Netflix to bring select video podcasts to the streaming platform starting in early 2026. The deal will feature curated shows from Spotify Studios and The Ringer, expanding later to include more genres. The move reflects Spotify’s growing focus on video as a key driver for engagement and ad revenue, with video podcast consumption now growing 20 times faster than audio-only content.",
          "content": "Spotify is partnering with Netflix to bring select video podcasts to the streaming platform starting in early 2026. The deal will feature curated shows from Spotify Studios and The Ringer, expanding later to include more genres. The move reflects Spotify’s growing focus on video as a key driver for engagement and ad revenue, with video podcast consumption now growing 20 times faster than audio-only content.",
          "feed_position": 4
        }
      ],
      "popularity_score": 2014.7077605555555,
      "ai_summary": [
        "Netflix will begin streaming video podcasts in partnership with Spotify.",
        "The deal will feature shows from Spotify Studios and The Ringer.",
        "The partnership is set to begin in early 2026.",
        "Spotify is focusing on video as a driver for engagement and revenue.",
        "Video podcast consumption is growing much faster than audio-only content."
      ]
    },
    {
      "id": "cluster_25",
      "coverage": 2,
      "updated_at": "Tue, 14 Oct 2025 20:51:51 +0000",
      "title": "Sam Altman says ChatGPT will soon allow erotica for adult users",
      "neutral_headline": "Sam Altman says ChatGPT will soon allow erotica for adult users",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/14/sam-altman-says-chatgpt-will-soon-allow-erotica-for-adult-users/",
          "published_at": "Tue, 14 Oct 2025 20:51:51 +0000",
          "title": "Sam Altman says ChatGPT will soon allow erotica for adult users",
          "standfirst": "OpenAI says it will soon roll back some of ChatGPT's safeguards, and even allow the chatbot to engage in erotica for adult users.",
          "content": "OpenAI says it will soon roll back some of ChatGPT's safeguards, and even allow the chatbot to engage in erotica for adult users.",
          "feed_position": 1
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/799312/openai-chatgpt-erotica-sam-altman-verified-adults",
          "published_at": "2025-10-14T13:45:34-04:00",
          "title": "Sam Altman says ChatGPT will soon sext with verified adults",
          "standfirst": "OpenAI will soon allow “erotica” for ChatGPT users who verify their age on the platform. In an X post on Tuesday, OpenAI CEO Sam Altman said the company will add support for mature conversations when it launches age-gating in December. “As we roll out age-gating more fully and as part of our ‘treat adult users [&#8230;]",
          "content": "OpenAI will soon allow “erotica” for ChatGPT users who verify their age on the platform. In an X post on Tuesday, OpenAI CEO Sam Altman said the company will add support for mature conversations when it launches age-gating in December. “As we roll out age-gating more fully and as part of our ‘treat adult users like adults’ principle, we will allow even more, like erotica for verified adults,” Altman writes. Earlier this month, OpenAI hinted at allowing developers to create “mature” ChatGPT apps after it implements the “appropriate age verification and controls.” OpenAI isn’t the only company dipping into erotica, as Elon Musk’s xAI previously launched flirty AI companions, which appear as 3D anime models in the Grok app. Along with the addition of “erotica”, OpenAI also plans on launching a new version of ChatGPT that “behaves more like what people liked about 4o.” Just one day after making GPT-5 the default model powering ChatGPT, OpenAI brought back GPT-4o as an option after people complained the new model was less personable. Altman said OpenAI made ChatGPT “pretty restrictive to make sure we were being careful with mental health issues,” adding that the company realized this change made the chatbot “less useful/enjoyable to many users who had no mental health problems.” OpenAI has since launched tools to “better detect” when a user is in mental distress. OpenAI also announced the formation of a council on “well-being and AI” to help shape OpenAI’s response to “complex or sensitive” scenarios. The council is comprised of a team of eight researchers and experts who study the impact of technology and AI on mental health. But, as Ars Technica points out, it doesn’t include any suicide prevention experts, many of whom recently called on OpenAI to roll out additional safeguards for users with suicidal thoughts. “Now that we have been able to mitigate the serious mental health issues and have new tools, we are going to be able to safely relax the restrictions in most cases,” Altman writes in his post on X.",
          "feed_position": 7
        }
      ],
      "popularity_score": 2013.2535938888889,
      "ai_summary": [
        "OpenAI will soon allow \"erotica\" for ChatGPT users who verify their age.",
        "The company will add support for mature conversations in December.",
        "Age-gating will be implemented to restrict access to adult content.",
        "The move is part of OpenAI's efforts to treat adult users differently.",
        "The change reflects a shift in ChatGPT's content policies."
      ]
    },
    {
      "id": "cluster_28",
      "coverage": 2,
      "updated_at": "Tue, 14 Oct 2025 20:44:02 +0000",
      "title": "Trump admin pressured Facebook into removing ICE-tracking group",
      "neutral_headline": "Facebook removes ICE-tracking page after US government outreach",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/trump-admin-pressured-facebook-into-removing-ice-tracking-group/",
          "published_at": "Tue, 14 Oct 2025 20:44:02 +0000",
          "title": "Trump admin pressured Facebook into removing ICE-tracking group",
          "standfirst": "Pam Bondi claims Facebook group was used to “dox and target” ICE agents",
          "content": "Attorney General Pam Bondi today said that Facebook removed an ICE-tracking group after \"outreach\" from the Department of Justice. \"Today following outreach from @thejusticedept, Facebook removed a large group page that was being used to dox and target @ICEgov agents in Chicago,\" Bondi wrote in an X post. Bondi alleged that a \"wave of violence against ICE has been driven by online apps and social media campaigns designed to put ICE officers at risk just for doing their jobs.\" She added that the DOJ \"will continue engaging tech companies to eliminate platforms where radicals can incite imminent violence against federal law enforcement.\" When contacted by Ars, Facebook owner Meta said the group \"was removed for violating our policies against coordinated harm.\" Meta didn't describe any specific violation but directed us to a policy against \"coordinating harm and promoting crime,\" which includes a prohibition against \"outing the undercover status of law enforcement, military, or security personnel.\"Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/zuckerberg-trump-1152x648-1760473002.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/policy/799473/facebook-meta-ice-jawboning",
          "published_at": "2025-10-14T16:42:01-04:00",
          "title": "Facebook removes ICE-tracking page after US government ‘outreach’",
          "standfirst": "Meta has removed a Facebook page dedicated to tracking Immigration and Customs Enforcement (ICE) action in Chicago after the Justice Department got involved.&#160; Attorney General Pam Bondi wrote on X Tuesday that Facebook had taken down an unnamed “large group page that was being used to dox and target” ICE agents after outreach from the [&#8230;]",
          "content": "Meta has removed a Facebook page dedicated to tracking Immigration and Customs Enforcement (ICE) action in Chicago after the Justice Department got involved. Attorney General Pam Bondi wrote on X Tuesday that Facebook had taken down an unnamed “large group page that was being used to dox and target” ICE agents after outreach from the DOJ. Meta spokesperson Andy Stone confirmed the group, which he did not identify, “was removed for violating our policies against coordinated harm.” Its removal follows Apple and Google blocking ICE-tracking apps, also following government demands. The DOJ declined to comment beyond Bondi’s post, and ICE did not immediately respond to a request for comment about whether specific credible threats were made to ICE agents on the page. The DOJ appears to have taken action after Laura Loomer, a right-wing influencer who has led several campaigns against federal workers she deems disloyal to Trump, posted about a Facebook group called “ICE Sighting- Chicagoland” that she claimed “is providing location updates on ICE raids and ICE agent locations in the Chicago area.” While neither the DOJ nor Meta confirmed the name of the group taken down, Loomer claimed a DOJ source told her the agency had seen her post and contacted Meta about such pages. As President Donald Trump has ramped up immigration enforcement across the country, including through more aggressive tactics like workplace raids, several tools and community groups have popped up to alert people to ICE’s presence in their area. The ICEBlock app used to anonymously report ICE sightings rose to the top of Apple’s app store this summer before it was similarly removed by Apple after the DOJ reached out, with Bondi claiming it was “designed to put ICE agents at risk just for doing their jobs.” ICEBlock developer Joshua Aaron told Fox News Digital it was “patently false” that the app “served to harm law enforcement officers.” Bondi’s statement raises questions about whether the government engaged in illegal jawboning As private sector businesses, Apple and Meta can generally legally remove groups or apps as they see fit. But Bondi’s statement raises questions about whether the government engaged in illegal jawboning, or pressuring private actors to take down legal speech. It’s not clear precisely what the DOJ said to platforms that prompted them to take action, or whether Meta might have removed the page even without government intervention. But the administration has recently suggested that a broad range of speech might constitute actionable support for domestic terrorism and pledged to crack down on it. The incident is particularly notable since President Donald Trump and other Republicans have repeatedly characterized the Biden administration’s outreach to tech platforms over covid and voting misinformation as censorship, slamming the government’s role in flagging posts they labeled harmful to voting engagement or public health. Conservative state AGs sued the administration in a case that went all the way to the Supreme Court, which did not find a “concrete link” between the platforms’ removal decisions and the government’s communication with the tech executives. There’s also little direct evidence that ICE-tracking tools have led to violence. The administration amped up pressure after claiming that a shooter at a Dallas field office in September used tracking apps, but it’s unclear what, if any, role they played in the attack (which led to the deaths of two detainees and no ICE officers). ICE agents have experienced more assaults as their presence in American communities has increased, but to a far lower degree than the government has claimed, a recent National Public Radio report found.",
          "feed_position": 4
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/zuckerberg-trump-1152x648-1760473002.jpg",
      "popularity_score": 2013.123316111111,
      "ai_summary": [
        "Meta removed a Facebook page tracking Immigration and Customs Enforcement.",
        "The page was allegedly used to \"dox and target\" ICE agents.",
        "The Justice Department contacted Facebook regarding the page.",
        "Attorney General Pam Bondi confirmed the page's removal.",
        "The page's removal followed government intervention."
      ]
    },
    {
      "id": "cluster_38",
      "coverage": 2,
      "updated_at": "Tue, 14 Oct 2025 16:00:50 -0400",
      "title": "Microsoft officially ends support for Windows 10, which runs on ~40% of Windows PCs per Statcounter; users can enroll in an Extended Security Updates program (Andrew Cunningham/Ars Technica)",
      "neutral_headline": "Microsoft officially ends support for Windows 10, which runs on ~40% of Windows PCs per Statcounter; users can enroll in an Extended Security Updates program",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251014/p34#a251014p34",
          "published_at": "Tue, 14 Oct 2025 16:00:50 -0400",
          "title": "Microsoft officially ends support for Windows 10, which runs on ~40% of Windows PCs per Statcounter; users can enroll in an Extended Security Updates program (Andrew Cunningham/Ars Technica)",
          "standfirst": "Andrew Cunningham / Ars Technica: Microsoft officially ends support for Windows 10, which runs on ~40% of Windows PCs per Statcounter; users can enroll in an Extended Security Updates program &mdash; End users can get an extra year of security updates relatively easily. &mdash; Today is the official end-of-support date for Microsoft's Windows 10.",
          "content": "Andrew Cunningham / Ars Technica: Microsoft officially ends support for Windows 10, which runs on ~40% of Windows PCs per Statcounter; users can enroll in an Extended Security Updates program &mdash; End users can get an extra year of security updates relatively easily. &mdash; Today is the official end-of-support date for Microsoft's Windows 10.",
          "feed_position": 12,
          "image_url": "http://www.techmeme.com/251014/i34.jpg"
        },
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/windows-10-support-ends-today-but-its-just-the-first-of-many-deaths/",
          "published_at": "Tue, 14 Oct 2025 14:58:23 +0000",
          "title": "Windows 10 support “ends” today, but it’s just the first of many deaths",
          "standfirst": "End users can get an extra year of security updates relatively easily.",
          "content": "Today is the official end-of-support date for Microsoft's Windows 10. That doesn't mean these PCs will suddenly stop working, but if you don't take action, it does mean your PC has received its last regular security patches and that Microsoft is washing its hands of technical support. This end-of-support date comes about a decade after the initial release of Windows 10, which is typical for most Windows versions. But it comes just four years after Windows 10 was replaced by Windows 11, a version with stricter system requirements that left many older-but-still-functional PCs with no officially supported upgrade path. As a result, Windows 10 still runs on roughly 40 percent of the world's Windows PCs (or around a third of US-based PCs), according to StatCounter data. But this end-of-support date also isn't set in stone. Home users with Windows 10 PCs can enroll in Microsoft's Extended Security Updates (ESU) program, which extends the support timeline by another year. We've published directions for how to do this here—while you do need one of the Microsoft accounts that the company is always pushing, it's relatively trivial to enroll in the ESU program for free.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/10/win10-wallpaper-1152x648.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/251014/i34.jpg",
      "popularity_score": 2012.403316111111,
      "ai_summary": [
        "Microsoft officially ended support for Windows 10 today.",
        "Approximately 40% of Windows PCs still run Windows 10.",
        "Users can enroll in an Extended Security Updates program.",
        "The program provides an extra year of security updates.",
        "Today marks the official end-of-support date for Windows 10."
      ]
    },
    {
      "id": "cluster_51",
      "coverage": 2,
      "updated_at": "Tue, 14 Oct 2025 18:44:10 +0000",
      "title": "Do You Really Have to Stop Using Windows 10?",
      "neutral_headline": "Windows 10 support ends, users have options",
      "items": [
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/do-you-really-have-to-stop-using-windows-10/",
          "published_at": "Tue, 14 Oct 2025 18:44:10 +0000",
          "title": "Do You Really Have to Stop Using Windows 10?",
          "standfirst": "Microsoft has stopped supporting the operating system. If you’re still running Windows 10, here are your options.",
          "content": "Microsoft has stopped supporting the operating system. If you’re still running Windows 10, here are your options.",
          "feed_position": 4,
          "image_url": "https://media.wired.com/photos/681cd21fc603f12b08e4fb28/master/pass/windows-10-byebye-gear-1237969700.jpg"
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/windows-10-pc-cant-be-upgraded-you-have-5-options-and-must-act-now/",
          "published_at": "Tue, 14 Oct 2025 18:38:00 GMT",
          "title": "Windows 10 PC can't be upgraded? You have 5 options - and must act now",
          "standfirst": "Microsoft has officially ended support for its most popular OS ever. Here's what to do with your Windows 10 PCs that fail Microsoft's Windows 11 compatibility tests.",
          "content": "Microsoft has officially ended support for its most popular OS ever. Here's what to do with your Windows 10 PCs that fail Microsoft's Windows 11 compatibility tests.",
          "feed_position": 12
        }
      ],
      "featured_image": "https://media.wired.com/photos/681cd21fc603f12b08e4fb28/master/pass/windows-10-byebye-gear-1237969700.jpg",
      "popularity_score": 2011.1255383333332,
      "ai_summary": [
        "Microsoft has ended support for the Windows 10 operating system.",
        "Users still running Windows 10 have several options available.",
        "Options include upgrading to Windows 11 or using alternatives.",
        "Users must act now to address the end of support.",
        "Microsoft has officially ended support for its most popular OS."
      ]
    },
    {
      "id": "cluster_56",
      "coverage": 2,
      "updated_at": "Tue, 14 Oct 2025 18:16:21 GMT",
      "title": "Try Google's Nano Banana image generator in Search and NotebookLM - here's how",
      "neutral_headline": "Google's AI image editor expands to Search and NotebookLM",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/try-googles-nano-banana-image-generator-in-search-and-notebooklm-heres-how/",
          "published_at": "Tue, 14 Oct 2025 18:16:21 GMT",
          "title": "Try Google's Nano Banana image generator in Search and NotebookLM - here's how",
          "standfirst": "Google's AI image editor is coming to a new lineup of applications.",
          "content": "Google's AI image editor is coming to a new lineup of applications.",
          "feed_position": 15
        },
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/10/googles-nano-banana-ai-image-editor-is-coming-to-search-photos-and-notebooklm/",
          "published_at": "Mon, 13 Oct 2025 19:52:23 +0000",
          "title": "Google’s Photoshop-killer AI model is coming to search, Photos, and NotebookLM",
          "standfirst": "After more than 5 billion AI image edits, Nano Banana is expanding.",
          "content": "Google began experimenting with conversational image editing earlier this year in the dev-focused AI studio, but the feature didn't remain experimental for long. Over the summer, Google rolled out the \"Nano Banana\" image-editing model in Gemini 2.5 Flash. You can use this feature to modify images with just a prompt, and now you don't even need to go to Gemini to use it. Google says Nano Banana is now coming to search, Google Photos, and NotebookLM. The AI image editor is coming to search via Lens and AI Mode. For Lens, you can simply open the app (iOS and Android) and snap a photo to get started. When the rollout is complete, you'll see a \"Create\" button at the bottom, with a banana icon. Tap that to enter a prompt, telling the AI how you'd like the photo changed. When you begin an edit in Lens, the Google app will display the results and offer the chance for follow-up edits in the AI Mode interface. Google is always looking for more ways to get people plugged into its conversational search bot, so there's also a separate way to access Nano Banana there. Simply select the \"Create image\" tool and enter your prompt to create an image. You can then continue the conversation to have Nano Banana change the image.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/BananaLens-2096x1182.width-2200.format-webp-copy-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/BananaLens-2096x1182.width-2200.format-webp-copy-1152x648.jpg",
      "popularity_score": 2010.6619272222222,
      "ai_summary": [
        "Google's AI image editor, Nano Banana, is expanding its availability.",
        "It will be integrated into Google Search, Photos, and NotebookLM.",
        "The tool has been used for over 5 billion AI image edits.",
        "Users can now access the image editor in new applications.",
        "The expansion provides more access to Google's AI image tools."
      ]
    },
    {
      "id": "cluster_22",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 21:17:49 +0000",
      "title": "NATO boss mocks Russian navy, which is on the hunt for Red October “the nearest mechanic”",
      "neutral_headline": "NATO boss mocks Russian navy, which is on the hunt for Red October “the nearest mechanic”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/nato-boss-mocks-russian-navy-which-is-on-the-hunt-for-red-october-the-nearest-mechanic/",
          "published_at": "Tue, 14 Oct 2025 21:17:49 +0000",
          "title": "NATO boss mocks Russian navy, which is on the hunt for Red October “the nearest mechanic”",
          "standfirst": "A Russian sub surfaces off of Western Europe. Is it damaged?",
          "content": "When one of its Kilo-class, diesel-electric submarines recently surfaced off the coast of France, Russia denied that there was a problem with the vessel. The sub was simply surfacing to comply with maritime transit rules governing the English Channel, the Kremlin said—Russia being, of course, a noted follower of international law. But social media accounts historically linked to Russian security forces suggested a far more serious problem on the submarine Novorossiysk. According to The Maritime Executive, \"Rumors began to circulate on well-informed social media channels that the Novorossiysk had suffered a fuel leak. They suggested the vessel lacked onboard capabilities and was forced to surface to empty flooded compartments. Some reports said it was a dangerous fuel leak aboard the vessel, which was commissioned in 2012.\" France 24 quoted further social media reports as saying, \"The submarine has neither the spare parts nor the qualified specialists onboard to fix the malfunction,\" and it \"now poses an explosion hazard.\"Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/french-ships-shadows-russian-sub-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/french-ships-shadows-russian-sub-1152x648.jpg",
      "popularity_score": 346.6863716666667,
      "ai_summary": [
        "A Russian submarine surfaced off the coast of Western Europe.",
        "The submarine's condition is currently unknown.",
        "The incident has drawn mockery from NATO officials.",
        "The Russian navy is reportedly seeking assistance.",
        "The situation raises questions about the submarine's status."
      ]
    },
    {
      "id": "cluster_24",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 21:01:50 +0000",
      "title": "Feds seize $15 billion from alleged forced labor scam built on “human suffering”",
      "neutral_headline": "Feds seize $15 billion from alleged forced labor scam",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/feds-seize-15-billion-from-alleged-forced-labor-scam-built-on-human-suffering/",
          "published_at": "Tue, 14 Oct 2025 21:01:50 +0000",
          "title": "Feds seize $15 billion from alleged forced labor scam built on “human suffering”",
          "standfirst": "Scams like this one net billions from well-educated victims.",
          "content": "Federal prosecutors have seized $15 billion from the alleged kingpin of an operation that used imprisoned laborers to trick unsuspecting people into making investments in phony funds, often after spending months faking romantic relationships with the victims. Such \"pig butchering\" scams have operated for years. They typically work when members of the operation initiate conversations with people on social media and then spend months messaging them. Often, the scammers pose as attractive individuals who feign romantic interest for the victim. Forced labor, phone farms, and human suffering Eventually, conversations turn to phony investment funds with the end goal of convincing the victim to transfer large amounts of bitcoin. In many cases, the scammers are trafficked and held against their will in compounds surrounded by fences and barbed wire.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bitcoin-romance-pig-butchering-scam-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bitcoin-romance-pig-butchering-scam-1152x648.jpg",
      "popularity_score": 336.41998277777776,
      "ai_summary": [
        "Federal authorities seized $15 billion in a forced labor scam.",
        "The scam allegedly exploited human suffering for profit.",
        "Scams like this one target well-educated victims.",
        "The seized funds represent a significant amount of money.",
        "The case highlights the scale of such fraudulent activities."
      ]
    },
    {
      "id": "cluster_53",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 18:24:53 +0000",
      "title": "Google will let Gemini schedule meetings for you in Gmail",
      "neutral_headline": "Google will let Gemini schedule meetings for you in Gmail",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/10/gemini-can-now-help-schedule-meetings-in-gmail/",
          "published_at": "Tue, 14 Oct 2025 18:24:53 +0000",
          "title": "Google will let Gemini schedule meetings for you in Gmail",
          "standfirst": "Help Me Schedule creates a meeting widget based on the context of your message.",
          "content": "Meetings can be a real drain on productivity, but a new Gmail feature might at least cut down on the time you spend scheduling them. The company has announced \"Help Me Schedule\" is coming to Gmail, leveraging Gemini AI to recognize when you want to schedule a meeting and offering possible meeting times for the email recipient to choose. The new meeting feature is reminiscent of Magic Cue on Google's latest Pixel phones. As you type emails, Gmail will be able to recognize when you are planning a meeting. A Help Me Schedule button will appear in the toolbar. Upon clicking, Google's AI will swing into action and find possible meeting times that match the context of your message and are available in your calendar. When you engage with Help me schedule, the AI generates an in-line meeting widget for your message. The recipient can select the time that works for them, and that's it—the meeting is scheduled for both parties. What about meetings with more than one invitee? Google says the feature won't support groups at launch.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg",
      "popularity_score": 330.8041494444444,
      "ai_summary": [
        "Google will integrate meeting scheduling into Gmail using Gemini.",
        "The \"Help Me Schedule\" feature will be context-aware.",
        "It will create a meeting widget based on message content.",
        "The feature aims to simplify meeting arrangements.",
        "The integration will streamline scheduling processes."
      ]
    },
    {
      "id": "cluster_39",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 19:58:38 +0000",
      "title": "DirecTV screensavers will show AI-generated ads with your face in 2026",
      "neutral_headline": "DirecTV screensavers will show AI-generated ads with your face in 2026",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/directv-screensavers-will-show-ai-generated-ads-with-your-face-in-2026/",
          "published_at": "Tue, 14 Oct 2025 19:58:38 +0000",
          "title": "DirecTV screensavers will show AI-generated ads with your face in 2026",
          "standfirst": "Like other companies with streaming businesses, DirecTV is leaning into ads more.",
          "content": "As if DirecTV doesn't have enough trouble keeping customers, the satellite TV provider's streaming devices will show AI-generated screensaver ads next year, according to an announcement today from partnering ads company Glance. People who use either of DirecTV’s two Gemini streaming devices will start seeing the ads “in early 2026,” per the announcement. DirecTV’s Gemini Air is an Android TV-powered USB device that people can plug into a TV for access to live TV channels, as well as streaming apps. Gemini Air doesn’t require a DirecTV satellite connection, and DirecTV gives all of its Internet customers the device. DirecTV first started selling Gemini devices in 2023, when it launched a separate Gemini set-top box that connects through DirecTV satellite setups. DirecTV made an agreement with Glance to show AI-generated content and ads on Gemini devices' screensavers. Currently, Gemini devices show Google wallpapers as screensavers, which are on by default. When the new screensavers launch, Glance's AI content will show if the TV is idle for 10 minutes, The Verge reported.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GEMINI-AIR_0-1152x648-1760468257.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GEMINI-AIR_0-1152x648-1760468257.jpg",
      "popularity_score": 330.3666494444444,
      "ai_summary": [
        "DirecTV will incorporate AI-generated ads into screensavers.",
        "The ads will feature personalized content, including user faces.",
        "The change is planned for implementation in 2026.",
        "DirecTV is increasing its focus on advertising revenue.",
        "The move reflects a trend toward personalized advertising."
      ]
    },
    {
      "id": "cluster_66",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 17:00:40 +0000",
      "title": "OpenAI unveils “wellness” council; suicide prevention expert not included",
      "neutral_headline": "OpenAI unveils “wellness” council; suicide prevention expert not included",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/openai-unveils-wellness-council-suicide-prevention-expert-not-included/",
          "published_at": "Tue, 14 Oct 2025 17:00:40 +0000",
          "title": "OpenAI unveils “wellness” council; suicide prevention expert not included",
          "standfirst": "OpenAI reveals which experts are steering ChatGPT mental health upgrades.",
          "content": "Ever since a lawsuit accused ChatGPT of becoming a teen's \"suicide coach,\" OpenAI has been scrambling to make its chatbot safer. Today, the AI firm unveiled the experts it hired to help make ChatGPT a healthier option for all users. In a press release, OpenAI explained its Expert Council on Wellness and AI started taking form after OpenAI began informally consulting with experts on parental controls earlier this year. Now it's been formalized, bringing together eight \"leading researchers and experts with decades of experience studying how technology affects our emotions, motivation, and mental health\" to help steer ChatGPT updates. One priority was finding \"several council members with backgrounds in understanding how to build technology that supports healthy youth development,\" OpenAI said, \"because teens use ChatGPT differently than adults.\"Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2207496721-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2207496721-1152x648.jpg",
      "popularity_score": 313.4005383333333,
      "ai_summary": [
        "OpenAI has established a \"wellness\" council.",
        "The council will guide ChatGPT's mental health upgrades.",
        "A suicide prevention expert is not included in the council.",
        "The council's composition has raised some concerns.",
        "The council's role is to oversee mental health features."
      ]
    },
    {
      "id": "cluster_67",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 16:58:21 +0000",
      "title": "Nvidia sells tiny new computer that puts big AI on your desktop",
      "neutral_headline": "Nvidia sells tiny new computer that puts big AI on your desktop",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/nvidia-sells-tiny-new-computer-that-puts-big-ai-on-your-desktop/",
          "published_at": "Tue, 14 Oct 2025 16:58:21 +0000",
          "title": "Nvidia sells tiny new computer that puts big AI on your desktop",
          "standfirst": "The 1 petaflop DGX Spark system runs AI models with 200 billion parameters locally for $4K.",
          "content": "On Tuesday, Nvidia announced it will begin taking orders for the DGX Spark, a $4,000 desktop AI computer that wraps one petaflop of computing performance and 128GB of unified memory into a form factor small enough to sit on a desk. Its biggest selling point is likely its large integrated memory that can run larger AI models than consumer GPUs. Nvidia will begin taking orders for the DGX Spark on Wednesday, October 15, through its website, with systems also available from manufacturing partners and select US retail stores. The DGX Spark, which Nvidia previewed as \"Project DIGITS\" in January and formally named in May, represents Nvidia's attempt to create a new category of desktop computer workstation specifically for AI development.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/dgx_spark-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/dgx_spark-1152x648.jpg",
      "popularity_score": 297.3619272222222,
      "ai_summary": [
        "Nvidia is selling a new compact computer system.",
        "The DGX Spark system runs AI models locally.",
        "It can run AI models with 200 billion parameters.",
        "The system offers 1 petaflop of computing power.",
        "The system costs approximately $4,000."
      ]
    },
    {
      "id": "cluster_78",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 15:16:15 +0000",
      "title": "GM’s EV push will cost it $1.6 billion in Q3 with end of the tax credit",
      "neutral_headline": "General Motors EV push costs $1.6 billion due to tax credit changes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/gms-ev-push-will-cost-it-1-6-billion-in-q3-with-end-of-the-tax-credit/",
          "published_at": "Tue, 14 Oct 2025 15:16:15 +0000",
          "title": "GM’s EV push will cost it $1.6 billion in Q3 with end of the tax credit",
          "standfirst": "With EV demand predicted to plummet, GM has rejiggered its production plans.",
          "content": "The prospects of continued electric vehicle adoption in the US are in an odd place. As promised, the Trump administration and its congressional Republican allies killed off as many of the clean energy and EV incentives as they could after taking power in January. Ironically, though, the end of the clean vehicle tax credit on September 30 actually spurred the sales of EVs, as customers rushed to dealerships to take advantage of the soon-to-disappear $7,500 credit. Predictions for EV sales going forward aren't so rosy, and automakers are reacting by adjusting their product portfolio plans. Today, General Motors revealed that will result in a $1.6 billion hit to its balance sheet when it reports its Q3 results late this month, according to its 8-K. Q3 was a decent one for GM, with sales up 8 percent year on year and up 10 percent for the year to date. GM EV sales look even better: up 104 percent for the year to date compared to the first nine months of 2024, with nearly 145,000 electric Cadillacs, Chevrolets, and GMCs finding homes.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2165725341-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2165725341-1152x648.jpg",
      "popularity_score": 276.66026055555557,
      "ai_summary": [
        "General Motors expects a $1.6 billion loss in the third quarter due to the end of the tax credit.",
        "The company is adjusting production plans due to predicted declines in electric vehicle demand.",
        "This financial impact reflects the changing landscape of the electric vehicle market.",
        "General Motors is adapting its strategies to navigate the evolving industry dynamics.",
        "The company's adjustments are a response to shifts in consumer behavior and policy."
      ]
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 13:51:00 +0000",
      "title": "OpenAI wants to stop ChatGPT from validating users’ political views",
      "neutral_headline": "OpenAI aims to prevent ChatGPT from validating user political views",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/openai-wants-to-stop-chatgpt-from-validating-users-political-views/",
          "published_at": "Tue, 14 Oct 2025 13:51:00 +0000",
          "title": "OpenAI wants to stop ChatGPT from validating users’ political views",
          "standfirst": "New paper reveals reducing \"bias\" means making ChatGPT stop mirroring users' political language.",
          "content": "\"ChatGPT shouldn't have political bias in any direction.\" That's OpenAI's stated goal in a new research paper released Thursday about measuring and reducing political bias in its AI models. The company says that \"people use ChatGPT as a tool to learn and explore ideas\" and argues \"that only works if they trust ChatGPT to be objective.\" But a closer reading of OpenAI's paper reveals something different from what the company's framing of objectivity suggests. The company never actually defines what it means by \"bias.\" And its evaluation axes show that it's focused on stopping ChatGPT from several behaviors: acting like it has personal political opinions, amplifying users' emotional political language, and providing one-sided coverage of contested topics.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/political_fracture_1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/political_fracture_1-1152x648.jpg",
      "popularity_score": 264.2394272222222,
      "ai_summary": [
        "OpenAI seeks to reduce bias in ChatGPT, according to a new research paper.",
        "The goal is to stop the chatbot from mirroring users' political language.",
        "This initiative aims to make the AI less susceptible to reinforcing user biases.",
        "The project focuses on refining the AI's responses to political queries.",
        "The research explores methods to moderate the AI's political alignment."
      ]
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 15:33:42 +0000",
      "title": "Hans Koenigsmann, who investigated all of SpaceX’s rocket failures, is going to space",
      "neutral_headline": "SpaceX rocket failure investigator Hans Koenigsmann to experience spaceflight",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/one-of-spacexs-earliest-employees-is-going-to-space-via-blue-origin/",
          "published_at": "Mon, 13 Oct 2025 15:33:42 +0000",
          "title": "Hans Koenigsmann, who investigated all of SpaceX’s rocket failures, is going to space",
          "standfirst": "\"I've always been interested to experience Max Q from the inside.\"",
          "content": "Hans Koenigsmann is one of SpaceX's earliest, longest-tenured, and most-revered employees. When Elon Musk started the company in 2002, he was joined by two other \"founding\" employees, Tom Mueller in propulsion and Chris Thompson in structures. Koenigsmann was the next hire, brought on to develop avionics for the Falcon 1 rocket. Koenigsmann remained at the company for two decades before leaving SpaceX in late 2021. During that time, he transitioned from avionics to lead mission assurance and safety while also spearheading every major failure investigation of the Falcon 9 rocket. He was a beloved leader and mentor for his employees within the company's demanding culture.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-621034912-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-621034912-1024x648.jpg",
      "popularity_score": 156,
      "ai_summary": [
        "Hans Koenigsmann, who investigated SpaceX rocket failures, will go to space.",
        "Koenigsmann expressed interest in experiencing Max Q from the inside.",
        "He previously played a crucial role in understanding rocket failures.",
        "His upcoming flight represents a personal milestone and career shift.",
        "Koenigsmann's experience will provide a unique perspective on spaceflight."
      ]
    },
    {
      "id": "cluster_123",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 17:16:56 +0000",
      "title": "Apple’s streaming service gets harder to tell apart from its streaming app, box",
      "neutral_headline": "Apple streamlines streaming services by dropping the \"+",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/apple/2025/10/apple-tv-streaming-service-is-renamed-to-just-apple-tv/",
          "published_at": "Mon, 13 Oct 2025 17:16:56 +0000",
          "title": "Apple’s streaming service gets harder to tell apart from its streaming app, box",
          "standfirst": "Apple unifies its remaining streaming offerings by dropping the \"+\".",
          "content": "Apple has lightly rebranded its video-on-demand streaming service. The Netflix rival that has brought us critically acclaimed shows and movies like Slow Horses and The Lost Bus has gone from Apple TV+ to Apple TV. Apple announced the name change today in a press release that was primarily about the film F1: The Movie coming to its streaming service on December 12. Unlike previous announcements, however, today’s release referred to the streaming service as Apple TV, instead of Apple TV+. The announcement reads: Apple TV+ is now simply Apple TV, with a vibrant new identity. Apple didn’t specify how its streaming service’s “identity” has changed at all. As of this writing, accessing Apple’s streaming service via a browser or smart TV app still shows the original Apple TV+ branding.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/12/sever2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/12/sever2-1152x648.jpg",
      "popularity_score": 145,
      "ai_summary": [
        "Apple is unifying its streaming offerings by removing the \"+\".",
        "This change aims to simplify the user experience across its platforms.",
        "The move consolidates Apple's streaming services into a single entity.",
        "The adjustment affects how users access Apple's streaming content.",
        "This simplification streamlines the presentation of Apple's streaming services."
      ]
    },
    {
      "id": "cluster_105",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 07:05:16 +0000",
      "title": "SpaceX finally got exactly what it needed from Starship V2",
      "neutral_headline": "SpaceX achieves goals with Starship V2, plans Version 3 for next year",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/after-year-of-hardships-spacexs-starship-finally-flirts-with-perfection/",
          "published_at": "Tue, 14 Oct 2025 07:05:16 +0000",
          "title": "SpaceX finally got exactly what it needed from Starship V2",
          "standfirst": "This was the last flight of SpaceX's second-gen Starship design. Version 3 arrives next year.",
          "content": "SpaceX closed a troubled but instructive chapter in its Starship rocket program Monday with a near-perfect test flight that carried the stainless steel spacecraft halfway around the world from South Texas to the Indian Ocean. The rocket's 33 methane-fueled Raptor engines roared to life at 6:23 pm CDT (7:23 pm EDT; 23:23 UTC), throttling up to generate some 16.7 million pounds of thrust, by large measure more powerful than any rocket before Starship. Moments later, the 404-foot-tall (123.1-meter) rocket began a vertical climb away from SpaceX's test site in Starbase, Texas, near the US-Mexico border. From then on, the rocket executed its flight plan like clockwork. This was arguably SpaceX's most successful Starship test flight to date. The only flight with a similar claim occurred one year ago Monday, when the company caught the rocket's Super Heavy booster back at the launch pad after soaring to the uppermost fringes of the atmosphere. But that flight didn't accomplish as much in space.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starshipflight11recap1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starshipflight11recap1-1152x648.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "SpaceX achieved its objectives with the Starship V2 design.",
        "The second-generation Starship design completed its final flight.",
        "Version 3 of Starship is scheduled to arrive next year.",
        "This marks a transition to the next iteration of the Starship program.",
        "The company is progressing towards future Starship development phases."
      ]
    },
    {
      "id": "cluster_125",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 16:15:53 +0000",
      "title": "Why Signal’s post-quantum makeover is an amazing engineering achievement",
      "neutral_headline": "Signal's post-quantum makeover represents engineering achievement",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/why-signals-post-quantum-makeover-is-an-amazing-engineering-achievement/",
          "published_at": "Mon, 13 Oct 2025 16:15:53 +0000",
          "title": "Why Signal’s post-quantum makeover is an amazing engineering achievement",
          "standfirst": "New design sets a high standard for post-quantum readiness.",
          "content": "The encryption protecting communications against criminal and nation-state snooping is under threat. As private industry and governments get closer to building useful quantum computers, the algorithms protecting Bitcoin wallets, encrypted web visits, and other sensitive secrets will be useless. No one doubts the day will come, but as the now-common joke in cryptography circles observes, experts have been forecasting this cryptocalypse will arrive in the next 15 to 30 years for the past 30 years. The uncertainty has created something of an existential dilemma: Should network architects spend the billions of dollars required to wean themselves off quantum-vulnerable algorithms now, or should they prioritize their limited security budgets fighting more immediate threats such as ransomware and espionage attacks? Given the expense and no clear deadline, it’s little wonder that less than half of all TLS connections made inside the Cloudflare network and only 18 percent of Fortune 500 networks support quantum-resistant TLS connections. It's all but certain that many fewer organizations still are supporting quantum-ready encryption in less prominent protocols. Triumph of the cypherpunks One exception to the industry-wide lethargy is the engineering team that designs the Signal Protocol, the open source engine that powers the world’s most robust and resilient form of end-to-end encryption for multiple private chat apps, most notably the Signal Messenger. Eleven days ago, the nonprofit entity that develops the protocol, Signal Messenger LLC, published a 5,900-word write-up describing its latest updates that bring Signal a significant step toward being fully quantum-resistant.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/signal-quantum-security-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/signal-quantum-security-1152x648.jpg",
      "popularity_score": 139,
      "ai_summary": [
        "Signal's new design sets a high standard for post-quantum readiness.",
        "The post-quantum makeover is considered an amazing engineering achievement.",
        "This upgrade enhances the security of the messaging platform.",
        "The design addresses potential threats from quantum computing.",
        "Signal's approach provides a model for other secure communication platforms."
      ]
    },
    {
      "id": "cluster_119",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 19:27:10 +0000",
      "title": "Starship’s elementary era ends today with mega-rocket’s 11th test flight",
      "neutral_headline": "Starship's elementary era ends with eleventh test flight",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/starships-elementary-era-ends-today-with-mega-rockets-11th-test-flight/",
          "published_at": "Mon, 13 Oct 2025 19:27:10 +0000",
          "title": "Starship’s elementary era ends today with mega-rocket’s 11th test flight",
          "standfirst": "\"The final phase of Starship’s trajectory on Flight 11 includes a dynamic banking maneuver.\"",
          "content": "SpaceX is set to launch the 11th full-scale test flight of the company's Starship rocket Monday evening, with hopes of capping a tumultuous year with a successful one-hour voyage from South Texas to the Indian Ocean. Liftoff of the Super Heavy booster with the Starship upper stage is scheduled for 6:15 pm CDT (7:15 pm EDT; 23:15 UTC). SpaceX has a 75-minute window to launch Monday. You can watch a livestream of the flight here. SpaceX's control team, positioned a couple of miles away from the launch pad at Starbase, Texas, will oversee the loading of more than 10.5 million pounds of super-cold methane and liquid oxygen into the two-stage rocket beginning about an hour before liftoff. In the final minutes of the countdown, the world's largest rocket will undergo a steering check, and the launch director will give a final \"go\" for launch.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starshipflight11pre1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starshipflight11pre1-1152x648.jpg",
      "popularity_score": 138,
      "ai_summary": [
        "Starship's elementary era concludes with the mega-rocket's eleventh test flight.",
        "The final phase includes a dynamic banking maneuver.",
        "This flight represents a significant step in the Starship program.",
        "The maneuver is part of the trajectory of Flight 11.",
        "The test flight is a key milestone in Starship's development."
      ]
    },
    {
      "id": "cluster_116",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 20:48:21 +0000",
      "title": "Measles outbreak in SC sends 150 unvaccinated kids into 21-day quarantine",
      "neutral_headline": "Measles outbreak in South Carolina quarantines unvaccinated children",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/over-150-unvaccinated-kids-quarantined-for-21-days-in-sc-measles-outbreak/",
          "published_at": "Mon, 13 Oct 2025 20:48:21 +0000",
          "title": "Measles outbreak in SC sends 150 unvaccinated kids into 21-day quarantine",
          "standfirst": "The outbreak includes at least seven confirmed cases, but some are clearly being missed.",
          "content": "Health officials in South Carolina are warning that the highly infectious measles virus is spreading undetected in communities in the northern part of the state, specifically Spartanburg and Greenville counties. Last week, officials in Greenville identified an eighth measles case that is potentially linked to the outbreak. Seven outbreak cases had been confirmed since September 25 in neighboring Spartanburg, where transmission was identified in two schools: Fairforest Elementary and Global Academy, a public charter school. Across those two schools, at least 153 unvaccinated children were exposed to the virus and have been put in a 21-day quarantine, during which they are barred from attending school, state officials said in a press conference. Twenty-one days is the maximum incubation period, spanning from when a person is exposed to when they would develop a rash if infected.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-2152300024-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-2152300024-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "A measles outbreak in South Carolina led to quarantine for 150 unvaccinated children.",
        "The outbreak includes at least seven confirmed cases.",
        "Some cases are likely being missed in the current count.",
        "The quarantine aims to contain the spread of the disease.",
        "The outbreak highlights the importance of vaccination."
      ]
    },
    {
      "id": "cluster_120",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 18:52:06 +0000",
      "title": "To shield kids, California hikes fake nude fines to $250K max",
      "neutral_headline": "California increases fines for fake nude images of children",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/to-shield-kids-california-hikes-fake-nude-fines-to-250k-max/",
          "published_at": "Mon, 13 Oct 2025 18:52:06 +0000",
          "title": "To shield kids, California hikes fake nude fines to $250K max",
          "standfirst": "California cracks down on AI as child safety concerns grow.",
          "content": "California is cracking down on AI technology deemed too harmful for kids, attacking two increasingly notorious child safety fronts: companion bots and deepfake pornography. On Monday, Governor Gavin Newsom signed the first-ever US law regulating companion bots after several teen suicides sparked lawsuits. Moving forward, California will require any companion bot platforms—including ChatGPT, Grok, Character.AI, and the like—to create and make public \"protocols to identify and address users’ suicidal ideation or expressions of self-harm.\"Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "California is increasing fines for creating fake nude images of children.",
        "The maximum fine is now $250,000.",
        "The state is responding to growing child safety concerns related to AI.",
        "The legislation aims to deter the use of AI for harmful purposes.",
        "The increased fines reflect the seriousness of the issue."
      ]
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 15:49:12 +0000",
      "title": "4chan fined $26K for refusing to assess risks under UK Online Safety Act",
      "neutral_headline": "4chan faces fine for not assessing risks under UK Online Safety Act",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/4chan-fined-26k-for-refusing-to-assess-risks-under-uk-online-safety-act/",
          "published_at": "Mon, 13 Oct 2025 15:49:12 +0000",
          "title": "4chan fined $26K for refusing to assess risks under UK Online Safety Act",
          "standfirst": "4chan fine may test if US will intervene to block UK’s Online Safety Act.",
          "content": "A battle over the United Kingdom's Online Safety Act (OSA) heated up Monday as UK regulator Ofcom fined the notorious image-hosting board 4chan about $26,000 for failing to provide a risk assessment detailing the potential harms of illegal content hosted on its forum. In a press release provided to Ars, Ofcom said 4chan refused to respond to two requests for information that the regulator considered \"routine.\" The first asked for the risk assessment and the second for 4chan's \"qualifying worldwide revenue.\" 4chan was anticipating the Monday fine, noting in a lawsuit—which was jointly filed with the online trolling forum Kiwi Farms in August and seeks to permanently enjoin Ofcom from enforcing OSA—that Ofcom had made it clear that because 4chan ignored Ofcom's emails, the fine was coming.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1814351886.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1814351886.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "4chan was fined $26,000 for refusing to assess risks under the UK Online Safety Act.",
        "The fine may test if the US will intervene to block the UK's act.",
        "The case raises questions about international cooperation on internet regulation.",
        "The UK's act aims to regulate online content and safety.",
        "The situation could set a precedent for online content regulation."
      ]
    }
  ]
}