{
  "updated_at": "2025-10-23T19:16:00.609Z",
  "clusters": [
    {
      "id": "cluster_9",
      "coverage": 4,
      "updated_at": "2025-10-23T14:44:23-04:00",
      "title": "Trump pardons disgraced Binance founder Changpeng Zhao",
      "neutral_headline": "Trump pardons disgraced Binance founder Changpeng Zhao",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/805523/trump-pardons-disgraced-binance-founder-changpeng-zhao",
          "published_at": "2025-10-23T14:44:23-04:00",
          "title": "Trump pardons disgraced Binance founder Changpeng Zhao",
          "standfirst": "Changpeng Zhao, the founder of crypto exchange Binance, was pardoned by President Trump today, according to the Wall Street Journal. The move comes after months of lobbying by the company and Zhao&#8217;s own efforts to boost the Trump family’s crypto venture, World Liberty Financial. In April of 2024, Zhao was sentenced to four months in [&#8230;]",
          "content": "Changpeng Zhao, former chief executive officer of Binance, arrives at federal court. Changpeng Zhao, the founder of crypto exchange Binance, was pardoned by President Trump today, according to the Wall Street Journal. The move comes after months of lobbying by the company and Zhao&#8217;s own efforts to boost the Trump family’s crypto venture, World Liberty Financial. In April of 2024, Zhao was sentenced to four months in prison after pleading guilty to charges that he and Binance had failed to adequately implement anti-money laundering protections. The company was also hit with a massive $4.3 billion fine as part of its settlement with the Department of Justice under the Biden administration. The department said that Binance had become a hub of criminal money laundering, facilitating “billions of dollars of unregulated cryptocurrency transactions,” including “nearly” $900 million in transactions between the US and Iran. The Trump White House, however, has been much more sympathetic to Binance’s plight and that of the crypto industry in general. In May, the SEC dropped its lawsuit against the company. And now, with a pardon in hand, the way has been paved for Zhao and Binance to potentially return to business in the US. The pardon will also end the DOJ’s monitoring of Binance, though a separate Treasury program is still on the books for now. In a statement to the Wall Street Journal, White House press secretary Karoline Leavitt said President Trump “exercised his constitutional authority by issuing a pardon for Mr. Zhao, who was prosecuted by the Biden Administration in their war on cryptocurrency… The Biden Administration’s war on crypto is over.” Zhao is just the latest in a long string of tech industry pardons from Trump. In January, he pardoned Ross Ulbricht, who ran the dark web marketplace Silk Road. He followed that in March by pardoning former Nikola CEO Trevor Milton, as well as BitMEX co-founders Arthur Hayes, Benjamin Dalo, and Samuel Reed. Trump was also once a critic of the crypto industry, but has since changed his tune as his family seeks to make millions in the market. Zhao remains an influential figure in the crypto scene, using his clout to boost World Liberty Financial and, apparently, holding talks with the Trump family about taking a financial stake in Binance. The Wall Street Journal even suggested that such a stake in the company could be contingent upon a pardon, which might raise more than a few eyebrows. As other wealthy tech CEOs have found out, sometimes it’s easy to buy a solution to your problems with the current administration.",
          "feed_position": 2
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/trump-pardons-cz-binance/",
          "published_at": "Thu, 23 Oct 2025 18:05:37 +0000",
          "title": "‘War on Crypto Is Over’: Donald Trump Pardons Binance Founder CZ",
          "standfirst": "After serving a federal prison sentence for violating anti-money-laundering laws and US sanctions, former crypto exchange CEO Changpeng Zhao has been pardoned by US president Donald Trump.",
          "content": "After serving a federal prison sentence for violating anti-money-laundering laws and US sanctions, former crypto exchange CEO Changpeng Zhao has been pardoned by US president Donald Trump.",
          "feed_position": 1,
          "image_url": "https://media.wired.com/photos/68fa4fd3c5809c60f31dd079/master/pass/Trump-Pardon-Binance-CEO-Business-2210816860.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/23/trump-pardons-binance-founder-changpeng-zhao/",
          "published_at": "Thu, 23 Oct 2025 16:41:18 +0000",
          "title": "Trump pardons Binance founder Changpeng Zhao",
          "standfirst": "Changpeng Zhao previously pleaded guilty to enabling money laundering while running the cryptocurrency exchange, and served four months in prison last year.",
          "content": "Changpeng Zhao previously pleaded guilty to enabling money laundering while running the cryptocurrency exchange, and served four months in prison last year.",
          "feed_position": 4
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251023/p27#a251023p27",
          "published_at": "Thu, 23 Oct 2025 11:21:35 -0400",
          "title": "President Trump pardons convicted Binance founder Changpeng Zhao, following months of efforts by Zhao to boost the Trump family's World Liberty Financial (Wall Street Journal)",
          "standfirst": "Wall Street Journal: President Trump pardons convicted Binance founder Changpeng Zhao, following months of efforts by Zhao to boost the Trump family's World Liberty Financial &mdash; Pardon follows months of efforts by Changpeng Zhao to boost Trump crypto company &mdash; President Trump has pardoned Changpeng Zhao &hellip;",
          "content": "Wall Street Journal: President Trump pardons convicted Binance founder Changpeng Zhao, following months of efforts by Zhao to boost the Trump family's World Liberty Financial &mdash; Pardon follows months of efforts by Changpeng Zhao to boost Trump crypto company &mdash; President Trump has pardoned Changpeng Zhao &hellip;",
          "feed_position": 14,
          "image_url": "http://www.techmeme.com/251023/i27.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/68fa4fd3c5809c60f31dd079/master/pass/Trump-Pardon-Binance-CEO-Business-2210816860.jpg",
      "popularity_score": 4019.4728866666665,
      "ai_summary": [
        "Changpeng Zhao, Binance founder, received a pardon from President Trump.",
        "Zhao was sentenced to four months in prison for money laundering violations.",
        "The pardon followed lobbying efforts by Binance and Zhao himself.",
        "Zhao sought to boost the Trump family's crypto venture, World Liberty Financial.",
        "Zhao previously pleaded guilty to enabling money laundering at Binance."
      ]
    },
    {
      "id": "cluster_0",
      "coverage": 2,
      "updated_at": "Thu, 23 Oct 2025 19:05:47 +0000",
      "title": "Leica's latest M camera drops the rangefinder in favor of an electronic viewfinder",
      "neutral_headline": "Leica M EV1 camera features electronic viewfinder",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/leicas-latest-m-camera-drops-the-rangefinder-in-favor-of-an-electronic-viewfinder-190547479.html",
          "published_at": "Thu, 23 Oct 2025 19:05:47 +0000",
          "title": "Leica's latest M camera drops the rangefinder in favor of an electronic viewfinder",
          "standfirst": "When you're trying to keep Leica's digital camera lineups straight, the M-System was always the one with optical rangefinder display (and high price tag). However. the company just upended that precedent with the M EV1, a 60MP mirrorless camera with a classic M design but an electronic viewfinder (EVF) in place of the rangefinder. It may upset purists, but it's a move that makes sense from a sales point of view. Leica's old-school film cameras used its M mount lens system and, in order to keep the bodies compact, didn't have reflex mirrors like SLRs. Instead, they used an optical rangefinder, which provides a weird, offset and inaccurate view of the scene. Leica kept the rangefinders when it launched its digital M cameras, even though it could have switched to an EVF. Leica In 2014, Leica launched a more modern mirrorless camera lineup with the new SL mount that did use electronic viewfinders. However, they have always lacked the cachet, compact size and gorgeous looks of the M-System, so don't appeal as much to well-heeled buyers that want the full Leica experience. Enter the M EV1, which looks exactly like you want a Leica to look but boots the rangefinder in favor of an EVF. \"Designed for both devoted Leica enthusiasts and those new to the M System, it makes capturing beautiful, intentional photographs easier than ever,\" the company wrote. Leica probably noticed buyers who wanted a pretty camera were drawn to the M series, but then put off by the wonky rangefinders. Handmade in German, the M EV1 is definitely beautiful, with the classic rounded rectangular M shape and a new diamond-patterned leatherette to give it a distinctive look compared to the rangefinder models. Leica also eliminated the dedicated ISO dial (the setting is now done via another control), which helped make it 1.62 ounces lighter than the M11-P. It has a new custom function lever that lets you activate focusing aids and digital zoom options while looking through the viewfinder. Leica That viewfinder is definitely a good one, with 5.76 million dots of resolution for a sharp view. The rear screen has a sharp 2.32-million-dot display, but is fixed in place and doesn't tilt. Otherwise, the M EV1 has similar specs to the M11-P. It has a high resolution 60MP sensor with support for 14-bit RAW images processed using Leica's excellent color science and burst speeds up to 4.5 fps. You can shoot with the mechanical shutter at up to 1/4000th and 1/16,000th in silent mode (flash sync is 1/180th). Focusing is strictly manual, with magnification and focus peaking assist functions. Naturally, it uses Leica's famous and tremendously expensive compact M mount lenses. There's no support for video. Though some features are old school, the M EV1 lets you connect to Leica's Fotos app via Bluetooth, Wi-Fi or a cable for quick sharing on social media and elsewhere. It also supports Leica's Content Credentials system that enables the origin and history of an image to be clearly traced to avoid copyright theft or AI spoofing. Other features include 64GB of built-in storage along with UHS-II SD card support, and a meager 237 shots on a battery charge when using the EVF. Seeing the price is always a fun experience with a new Leica camera, and the M EV1 doesn't disappoint. It's now on pre-order for $8,995 (black, body only) with shipping set for later this year. This article originally appeared on Engadget at https://www.engadget.com/cameras/leicas-latest-m-camera-drops-the-rangefinder-in-favor-of-an-electronic-viewfinder-190547479.html?src=rss",
          "content": "When you're trying to keep Leica's digital camera lineups straight, the M-System was always the one with optical rangefinder display (and high price tag). However. the company just upended that precedent with the M EV1, a 60MP mirrorless camera with a classic M design but an electronic viewfinder (EVF) in place of the rangefinder. It may upset purists, but it's a move that makes sense from a sales point of view. Leica's old-school film cameras used its M mount lens system and, in order to keep the bodies compact, didn't have reflex mirrors like SLRs. Instead, they used an optical rangefinder, which provides a weird, offset and inaccurate view of the scene. Leica kept the rangefinders when it launched its digital M cameras, even though it could have switched to an EVF. Leica In 2014, Leica launched a more modern mirrorless camera lineup with the new SL mount that did use electronic viewfinders. However, they have always lacked the cachet, compact size and gorgeous looks of the M-System, so don't appeal as much to well-heeled buyers that want the full Leica experience. Enter the M EV1, which looks exactly like you want a Leica to look but boots the rangefinder in favor of an EVF. \"Designed for both devoted Leica enthusiasts and those new to the M System, it makes capturing beautiful, intentional photographs easier than ever,\" the company wrote. Leica probably noticed buyers who wanted a pretty camera were drawn to the M series, but then put off by the wonky rangefinders. Handmade in German, the M EV1 is definitely beautiful, with the classic rounded rectangular M shape and a new diamond-patterned leatherette to give it a distinctive look compared to the rangefinder models. Leica also eliminated the dedicated ISO dial (the setting is now done via another control), which helped make it 1.62 ounces lighter than the M11-P. It has a new custom function lever that lets you activate focusing aids and digital zoom options while looking through the viewfinder. Leica That viewfinder is definitely a good one, with 5.76 million dots of resolution for a sharp view. The rear screen has a sharp 2.32-million-dot display, but is fixed in place and doesn't tilt. Otherwise, the M EV1 has similar specs to the M11-P. It has a high resolution 60MP sensor with support for 14-bit RAW images processed using Leica's excellent color science and burst speeds up to 4.5 fps. You can shoot with the mechanical shutter at up to 1/4000th and 1/16,000th in silent mode (flash sync is 1/180th). Focusing is strictly manual, with magnification and focus peaking assist functions. Naturally, it uses Leica's famous and tremendously expensive compact M mount lenses. There's no support for video. Though some features are old school, the M EV1 lets you connect to Leica's Fotos app via Bluetooth, Wi-Fi or a cable for quick sharing on social media and elsewhere. It also supports Leica's Content Credentials system that enables the origin and history of an image to be clearly traced to avoid copyright theft or AI spoofing. Other features include 64GB of built-in storage along with UHS-II SD card support, and a meager 237 shots on a battery charge when using the EVF. Seeing the price is always a fun experience with a new Leica camera, and the M EV1 doesn't disappoint. It's now on pre-order for $8,995 (black, body only) with shipping set for later this year. This article originally appeared on Engadget at https://www.engadget.com/cameras/leicas-latest-m-camera-drops-the-rangefinder-in-favor-of-an-electronic-viewfinder-190547479.html?src=rss",
          "feed_position": 0,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/ee8e2060-b041-11f0-bfd8-56b8b6c7bea8"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/best-macbook-140032524.html",
          "published_at": "Thu, 23 Oct 2025 19:01:26 +0000",
          "title": "The best MacBook for 2025: Which Apple laptop should you buy?",
          "standfirst": "Picking the best MacBook may seem like an easy decision. After all, Apple just makes two models: the MacBook Air and the MacBook Pro. But the available variations within those categories — screen size, chip type, capacity and more — deserve some consideration. You also may wonder what the real-world differences are between models and who they’re best for. To make things even more interesting, Apple keeps announcing new chips. The latest, the M5 came out October 15, and is now found in the base model, 14-inch MacBook Pro (as well as the iPad Pro and the Vision Pro). This guide breaks down Apple’s terminology, as well as all which upgrades make the most sense so you can get the best MacBook for what you want to do. Table of contents Best MacBooks for 2025 What about budget MacBooks? Factors to consider when buying a MacBook MacBooks specs comparison chart Best MacBook FAQs Best MacBooks for 2025 What about budget MacBooks? Historically, Apple kept the previous year’s MacBook Air in its lineup as a sort of budget option. But the company took a different approach with the release of the M4 MacBook Air. Instead of continuing to sell the older model, Apple discontinued the M3 Air and gave its newest computer a $100 price cut. Now, if you can even find a brand new M3 MacBook Air (typically from retailers like Amazon or B&H), it’s often more expensive than the M4 version. During sales like Amazon Prime Day, we’ve seen the newest M4 Air go for as little as $799. That effectively makes our overall pick a budget pick as well. Of course, $800 isn’t exactly a small investment either for college students or others on a budget. Especially when you can find some decent PCs for under $500. If you’re looking to save even more on a MacBook, we recommend checking out refurbished options directly from Apple, or even third party sellers like BackMarket. There are a few guidelines to keep in mind, which we go over in our refurbished guide, but mainly, you’ll want to shop from a reputable source that has a stated process and offers at least a year-long warranty. Using your old gear as a trade-in will bring down your final cost as well. Factors to consider when buying a MacBook Compared to PCs, Apple computers tend to have more streamlined specifications. The company has long been known for this simplicity, and the M-series “system-on-a-chip” condenses things even further. Prior to the M1 chip, Apple used Intel chips in its laptop and desktop computers. The M2 and M3 generations followed that first chip and currently, MacBooks come equipped with M4 and M5-series chips. You’ll find the standard M4 processor in the Air. The base-model 14-inch Pro now comes with either the latest M5 chip. Other Pro configurations have the M4 Max or the M4 Pro (currently there is no M4 Ultra chip, as there was with the M3 series in the Mac Studio). All M-series chips combine, among other technologies, the CPU, graphics card and unified memory (RAM). Apple’s Neural Engine is included too, which is a specialized group of processor cores that handles machine learning tasks such as image analysis and voice recognition. While a unified chip means you have fewer decisions to make when picking a MacBook, there are still a few factors to consider, including specs like the number of CPU cores, amount of RAM, storage capacity, screen size, and, obviously, price. The finish color may be a minor consideration, but it's worth pointing out that the Pro comes in just two colors (Silver or Space Black) but the Air comes in four hues (Midnight, Starlight, Sky Blue and Silver). CPU cores The lowest-specced chip in a current-lineup MacBook is the standard M4 chip, which is found in all models of the MacBook Air. That chip houses a 10-core CPU and either an 8- or 10-core GPU. The base-model MacBook Pro uses the latest M5 chip, but only on the 14-inch model. The upgraded versions of that laptop use the M4 Pro or M4 Max chips (which are a step up from their predecessors, the M3, M3 Pro and M3 Max chips). The M4 Max is the burliest chip and built with either a 14- or 16-core CPU and a 32- or 40-core GPU. Cores are, in essence, smaller processing units that can handle different tasks simultaneously. Having more of them translates to the computer being able to run multiple programs and applications at once, while also smoothly processing demanding tasks like video and photo editing and high-level gaming. In short, more cores allow for more advanced computing and better performance. But if your processing power needs fall below professional-level gaming and cinematic video and audio editing, getting the highest number of cores is likely overkill — and after all, more cores equals higher cost and more power usage. Photo by Devindra Hardawar/Engadget RAM Your options for RAM (or unified memory) varies, but when Apple switched to the M4 chip for the MacBook Air, the lowest amount of RAM you can get was bumped to 16GB. That’s a necessary jump to accommodate the tech world’s favorite feature of the moment: AI or, in this case, Apple Intelligence (still AI, but Cupertino’s version). The M4 Pro chip has 24 or 48GB memory options, while the M4 Max chip supports 48, 64 or a whopping 128GB of RAM. The M5 chip in the base-model MacBook Pro comes with a minimum of 16GB and can be configured to a maximum of 32GB of RAM.. You’ve likely heard the analogy comparing memory to the amount of workspace available on a literal desktop surface, whereas storage is the amount of drawers you have to store projects to work on later. The larger the worktop surface, the more projects you can work on at once. The bigger the drawers, the more you can save for later. In addition to supporting Apple Intelligence, more RAM is ideal for people who plan to work in multiple apps at once. And the more demanding each program is, the more RAM will be required. Extra memory can also come in handy if you’re the type who likes to have infinite numbers of tabs open on your browser. If your daily workflow doesn’t involve simultaneously using a vast number of memory-intensive programs, you can save yourself money and buy the RAM configuration that you’re most likely to actually use. For a long time, Apple continued to offer MacBooks with just 8GB of RAM, and we recommended upgrading to at least 16GB of RAM. With this being the standard today, grabbing a base model should be fine for most non-pro-level users. One thing to note is that, unlike most PCs, the RAM in a MacBook is not user-upgradable since it’s tied into the system-on-a-chip. If you think you might end up needing more memory, you should go for the spec upgrade up front. Storage capacity (SSD) Storage options range from 256GB of SSD for the base-model MacBook Air and 8TB of storage for the MacBook Pros with the M4 Max chip. If you want to rotate between a long roster of game titles or keep lots of high-res videos on hand, you’ll want more storage. If you’re mostly working with browser- and cloud-based applications, you can get away with a smaller-capacity configuration. That said, we recommend springing for 512GB of storage or more, if it’s within your budget. You’ll quickly feel the limits of a 256GB machine as it ages since the operating system alone takes up a good portion of that space. Having 1TB will feel even roomier and allow for more data storage over the life of your laptop. When Apple announced the iPhone 15, the company also announced new iCloud+ storage storage plans, with subscriptions that allow up to 12TB of storage shared among your iOS and MacOS devices. You could also transfer files to an external storage device. But if you don’t want to pay for a monthly subscription and prefer the convenience of having immediate access to your files, it’s best to get the highest amount of storage space your budget allows for at the outset. Screen size The MacBook Air comes in 13- or 15-inch sizes. Pro models have either 14- or 16-inch screens. A two-inch delta may not seem like much but, as Engadget’s Nathan Ingraham noted when he reviewed the then-new 15-inch M2-powered MacBook Air, a larger screen \"makes a surprising difference.” That’s especially true if you plan to use your laptop as an all-day productivity machine and won’t be using an external monitor. More space means you can more clearly view side-by-side windows and have a more immersive experience when watching shows or gaming. But screen size is one of the main factors influencing weight. The 13-inch MacBook Air M4 weighs 2.7 pounds, whereas the top-end 16-inch MacBook Pro with the Max chip weighs 4.7 pounds. If you plan to travel a lot or swap your work locations regularly, a smaller screen will make life easier in the long run. All MacBooks feature IPS LCD panels (in-plane switching, liquid crystal display), which Apple markets as Retina displays. The MacBook Air M4 has a Liquid Retina display and the Pro models have Liquid Retina XDR displays. “Liquid” refers to the way the lighted portion of the display “flows” within the contours of the screen, filling the rounded corners and curving around the camera notch. “XDR” is what Apple calls HDR (high dynamic range). You also get the option of a standard or nano-texture display on the MacBook Pro. The glass, which reduces glare and is also available on the Studio Display, iMac and iPad Pro, comes with a $150 price increase, but if you really don’t like reflections on your screen, it could be worth it. Compared to most other laptops, MacBook displays are notably bright, sharp and lush. But one feature worth pointing out is another Apple marketing term: ProMotion. It’s the company’s term to describe a screen with a higher, 120Hz refresh rate, which results in smoother scrolling and more fluid-looking graphics. Only MacBook Pros offer ProMotion; the Air maxes out at 60Hz, which is perfectly fine for everyday browsing and typical workdays. But if you want buttery-smooth motion from your display, you’ll have to shell out more money for an upgrade. Operating systems Software considerations won’t make much of a difference when deciding between MacBook models — all come with macOS installed. But if you’re switching from, say, a Windows PC, the operating system may be something to factor into your decision — though it’s probably less of an issue than it once was. Now that so much of the work we do on our computers is browser- and cloud-based, the learning curve between the two platforms isn’t as steep. Apps and programs like Gmail perform similarly regardless of what computer you’re using. Apple machines have historically had more limited support of AAA gaming titles, but even that is changing with more AAA games and better graphics coming to Macs. As for macOS, it’s getting better too. With macOS Tahoe 26, the Spotlight function is more advanced, making it easier to find apps and perform tasks straight from your keyboard. The software also implements Apple's unifying Liquid Glass design for a modern look that looks consistent across iOS and iPad devices. New enhanced iPhone continuity features also make MacBooks and the handset work better together. A revamped Shortcuts app is more powerful as well, giving users custom automations that leverage Apple Intelligence (the company’s own AI). Price When Apple announced the MacBook Air M4, it also delivered a bit of refreshing news: The latest model now starts $100 cheaper than the previous generation. So now, the least expensive MacBook is the 13-inch, M4-powered Air with 16GB of RAM and 256GB of storage for $999. Alternatively, you can spend up to $7,349 for the 16-inch MacBook Pro M4 Max with the nano-texture glass, 128GB of RAM and 8TB of storage. Chip type, screen size, memory and storage capacity all influence the final price, which is why guides like this can help you determine just what you need (and what you don’t) so you can get the most cost-effective machine for you. AppleCare is another cost to consider. The extended warranty plan from Apple covers repairs from accidents and offers free battery replacement and starts at $3.50 per month or $35 per year for MacBooks. We recommend the MacBook Air M4 for most people, and thanks to that $100 price cut, it’s also a good budget option. If you want something even cheaper, we recommend looking at refurbished M-series models from Apple. We think the 14-inch M5 or 16-inch M4 MacBook Pros are best for professionals. If you have extra money to spare once you’ve picked your machine, we recommend upgrading to at least 512GB of storage and 32GB of RAM to make your machine as future-proof as possible. Of course, if you're just after Apple’s silicon and want the cheapest route to get it, you might consider the M4 Mac mini, which starts at $599 (though you'll have to supply the screen, mouse and keyboard). Best MacBooks spec comparison chart Product Superlative Tested configuration Tested battery life Rated battery life Apple MacBook Air M4 (13-inch) Best MacBook overall Apple M4, 16GB RAM, 256GB SSD 18.25 hours Up to 18 hours Apple MacBook Pro M5 (14-inch) Best MacBook for creatives Apple M5, 32GB RAM, 512GB SSD 34.5 hours Up to 24 hours Best MacBook FAQs What's the difference between MacBook Air and Pro? The MacBook Air comes with the M4 chip. The 14-inch, base-model Pro comes with the M5 chip. MacBook Pro models have the option of more powerful M4 Pro or M4 Max chips. The Pro models have higher resolution screens with a higher peak brightness that supports up to 120Hz adaptive refresh rates and XDR (extreme dynamic range). The battery life on most Pro models is longer than on the Air models as well. Pro models also have more ports and more speakers. In short, the MacBook Air is aimed at everyday users looking for good productivity and entertainment capabilities, while Pro models are aimed at professionals who need a high-performance computer. What's the difference between macOS and Windows? MacOS is the operating system developed by Apple and used in all of its desktop and laptop computers. It can only be found in hardware made by Apple including MacBooks and iMacs. Microsoft’s Windows operating system can be found in the company’s own Surface laptops as well as computers made by a wide array of manufacturers, like Acer, Asus, Dell and Razer.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-macbook-140032524.html?src=rss",
          "content": "Picking the best MacBook may seem like an easy decision. After all, Apple just makes two models: the MacBook Air and the MacBook Pro. But the available variations within those categories — screen size, chip type, capacity and more — deserve some consideration. You also may wonder what the real-world differences are between models and who they’re best for. To make things even more interesting, Apple keeps announcing new chips. The latest, the M5 came out October 15, and is now found in the base model, 14-inch MacBook Pro (as well as the iPad Pro and the Vision Pro). This guide breaks down Apple’s terminology, as well as all which upgrades make the most sense so you can get the best MacBook for what you want to do. Table of contents Best MacBooks for 2025 What about budget MacBooks? Factors to consider when buying a MacBook MacBooks specs comparison chart Best MacBook FAQs Best MacBooks for 2025 What about budget MacBooks? Historically, Apple kept the previous year’s MacBook Air in its lineup as a sort of budget option. But the company took a different approach with the release of the M4 MacBook Air. Instead of continuing to sell the older model, Apple discontinued the M3 Air and gave its newest computer a $100 price cut. Now, if you can even find a brand new M3 MacBook Air (typically from retailers like Amazon or B&H), it’s often more expensive than the M4 version. During sales like Amazon Prime Day, we’ve seen the newest M4 Air go for as little as $799. That effectively makes our overall pick a budget pick as well. Of course, $800 isn’t exactly a small investment either for college students or others on a budget. Especially when you can find some decent PCs for under $500. If you’re looking to save even more on a MacBook, we recommend checking out refurbished options directly from Apple, or even third party sellers like BackMarket. There are a few guidelines to keep in mind, which we go over in our refurbished guide, but mainly, you’ll want to shop from a reputable source that has a stated process and offers at least a year-long warranty. Using your old gear as a trade-in will bring down your final cost as well. Factors to consider when buying a MacBook Compared to PCs, Apple computers tend to have more streamlined specifications. The company has long been known for this simplicity, and the M-series “system-on-a-chip” condenses things even further. Prior to the M1 chip, Apple used Intel chips in its laptop and desktop computers. The M2 and M3 generations followed that first chip and currently, MacBooks come equipped with M4 and M5-series chips. You’ll find the standard M4 processor in the Air. The base-model 14-inch Pro now comes with either the latest M5 chip. Other Pro configurations have the M4 Max or the M4 Pro (currently there is no M4 Ultra chip, as there was with the M3 series in the Mac Studio). All M-series chips combine, among other technologies, the CPU, graphics card and unified memory (RAM). Apple’s Neural Engine is included too, which is a specialized group of processor cores that handles machine learning tasks such as image analysis and voice recognition. While a unified chip means you have fewer decisions to make when picking a MacBook, there are still a few factors to consider, including specs like the number of CPU cores, amount of RAM, storage capacity, screen size, and, obviously, price. The finish color may be a minor consideration, but it's worth pointing out that the Pro comes in just two colors (Silver or Space Black) but the Air comes in four hues (Midnight, Starlight, Sky Blue and Silver). CPU cores The lowest-specced chip in a current-lineup MacBook is the standard M4 chip, which is found in all models of the MacBook Air. That chip houses a 10-core CPU and either an 8- or 10-core GPU. The base-model MacBook Pro uses the latest M5 chip, but only on the 14-inch model. The upgraded versions of that laptop use the M4 Pro or M4 Max chips (which are a step up from their predecessors, the M3, M3 Pro and M3 Max chips). The M4 Max is the burliest chip and built with either a 14- or 16-core CPU and a 32- or 40-core GPU. Cores are, in essence, smaller processing units that can handle different tasks simultaneously. Having more of them translates to the computer being able to run multiple programs and applications at once, while also smoothly processing demanding tasks like video and photo editing and high-level gaming. In short, more cores allow for more advanced computing and better performance. But if your processing power needs fall below professional-level gaming and cinematic video and audio editing, getting the highest number of cores is likely overkill — and after all, more cores equals higher cost and more power usage. Photo by Devindra Hardawar/Engadget RAM Your options for RAM (or unified memory) varies, but when Apple switched to the M4 chip for the MacBook Air, the lowest amount of RAM you can get was bumped to 16GB. That’s a necessary jump to accommodate the tech world’s favorite feature of the moment: AI or, in this case, Apple Intelligence (still AI, but Cupertino’s version). The M4 Pro chip has 24 or 48GB memory options, while the M4 Max chip supports 48, 64 or a whopping 128GB of RAM. The M5 chip in the base-model MacBook Pro comes with a minimum of 16GB and can be configured to a maximum of 32GB of RAM.. You’ve likely heard the analogy comparing memory to the amount of workspace available on a literal desktop surface, whereas storage is the amount of drawers you have to store projects to work on later. The larger the worktop surface, the more projects you can work on at once. The bigger the drawers, the more you can save for later. In addition to supporting Apple Intelligence, more RAM is ideal for people who plan to work in multiple apps at once. And the more demanding each program is, the more RAM will be required. Extra memory can also come in handy if you’re the type who likes to have infinite numbers of tabs open on your browser. If your daily workflow doesn’t involve simultaneously using a vast number of memory-intensive programs, you can save yourself money and buy the RAM configuration that you’re most likely to actually use. For a long time, Apple continued to offer MacBooks with just 8GB of RAM, and we recommended upgrading to at least 16GB of RAM. With this being the standard today, grabbing a base model should be fine for most non-pro-level users. One thing to note is that, unlike most PCs, the RAM in a MacBook is not user-upgradable since it’s tied into the system-on-a-chip. If you think you might end up needing more memory, you should go for the spec upgrade up front. Storage capacity (SSD) Storage options range from 256GB of SSD for the base-model MacBook Air and 8TB of storage for the MacBook Pros with the M4 Max chip. If you want to rotate between a long roster of game titles or keep lots of high-res videos on hand, you’ll want more storage. If you’re mostly working with browser- and cloud-based applications, you can get away with a smaller-capacity configuration. That said, we recommend springing for 512GB of storage or more, if it’s within your budget. You’ll quickly feel the limits of a 256GB machine as it ages since the operating system alone takes up a good portion of that space. Having 1TB will feel even roomier and allow for more data storage over the life of your laptop. When Apple announced the iPhone 15, the company also announced new iCloud+ storage storage plans, with subscriptions that allow up to 12TB of storage shared among your iOS and MacOS devices. You could also transfer files to an external storage device. But if you don’t want to pay for a monthly subscription and prefer the convenience of having immediate access to your files, it’s best to get the highest amount of storage space your budget allows for at the outset. Screen size The MacBook Air comes in 13- or 15-inch sizes. Pro models have either 14- or 16-inch screens. A two-inch delta may not seem like much but, as Engadget’s Nathan Ingraham noted when he reviewed the then-new 15-inch M2-powered MacBook Air, a larger screen \"makes a surprising difference.” That’s especially true if you plan to use your laptop as an all-day productivity machine and won’t be using an external monitor. More space means you can more clearly view side-by-side windows and have a more immersive experience when watching shows or gaming. But screen size is one of the main factors influencing weight. The 13-inch MacBook Air M4 weighs 2.7 pounds, whereas the top-end 16-inch MacBook Pro with the Max chip weighs 4.7 pounds. If you plan to travel a lot or swap your work locations regularly, a smaller screen will make life easier in the long run. All MacBooks feature IPS LCD panels (in-plane switching, liquid crystal display), which Apple markets as Retina displays. The MacBook Air M4 has a Liquid Retina display and the Pro models have Liquid Retina XDR displays. “Liquid” refers to the way the lighted portion of the display “flows” within the contours of the screen, filling the rounded corners and curving around the camera notch. “XDR” is what Apple calls HDR (high dynamic range). You also get the option of a standard or nano-texture display on the MacBook Pro. The glass, which reduces glare and is also available on the Studio Display, iMac and iPad Pro, comes with a $150 price increase, but if you really don’t like reflections on your screen, it could be worth it. Compared to most other laptops, MacBook displays are notably bright, sharp and lush. But one feature worth pointing out is another Apple marketing term: ProMotion. It’s the company’s term to describe a screen with a higher, 120Hz refresh rate, which results in smoother scrolling and more fluid-looking graphics. Only MacBook Pros offer ProMotion; the Air maxes out at 60Hz, which is perfectly fine for everyday browsing and typical workdays. But if you want buttery-smooth motion from your display, you’ll have to shell out more money for an upgrade. Operating systems Software considerations won’t make much of a difference when deciding between MacBook models — all come with macOS installed. But if you’re switching from, say, a Windows PC, the operating system may be something to factor into your decision — though it’s probably less of an issue than it once was. Now that so much of the work we do on our computers is browser- and cloud-based, the learning curve between the two platforms isn’t as steep. Apps and programs like Gmail perform similarly regardless of what computer you’re using. Apple machines have historically had more limited support of AAA gaming titles, but even that is changing with more AAA games and better graphics coming to Macs. As for macOS, it’s getting better too. With macOS Tahoe 26, the Spotlight function is more advanced, making it easier to find apps and perform tasks straight from your keyboard. The software also implements Apple's unifying Liquid Glass design for a modern look that looks consistent across iOS and iPad devices. New enhanced iPhone continuity features also make MacBooks and the handset work better together. A revamped Shortcuts app is more powerful as well, giving users custom automations that leverage Apple Intelligence (the company’s own AI). Price When Apple announced the MacBook Air M4, it also delivered a bit of refreshing news: The latest model now starts $100 cheaper than the previous generation. So now, the least expensive MacBook is the 13-inch, M4-powered Air with 16GB of RAM and 256GB of storage for $999. Alternatively, you can spend up to $7,349 for the 16-inch MacBook Pro M4 Max with the nano-texture glass, 128GB of RAM and 8TB of storage. Chip type, screen size, memory and storage capacity all influence the final price, which is why guides like this can help you determine just what you need (and what you don’t) so you can get the most cost-effective machine for you. AppleCare is another cost to consider. The extended warranty plan from Apple covers repairs from accidents and offers free battery replacement and starts at $3.50 per month or $35 per year for MacBooks. We recommend the MacBook Air M4 for most people, and thanks to that $100 price cut, it’s also a good budget option. If you want something even cheaper, we recommend looking at refurbished M-series models from Apple. We think the 14-inch M5 or 16-inch M4 MacBook Pros are best for professionals. If you have extra money to spare once you’ve picked your machine, we recommend upgrading to at least 512GB of storage and 32GB of RAM to make your machine as future-proof as possible. Of course, if you're just after Apple’s silicon and want the cheapest route to get it, you might consider the M4 Mac mini, which starts at $599 (though you'll have to supply the screen, mouse and keyboard). Best MacBooks spec comparison chart Product Superlative Tested configuration Tested battery life Rated battery life Apple MacBook Air M4 (13-inch) Best MacBook overall Apple M4, 16GB RAM, 256GB SSD 18.25 hours Up to 18 hours Apple MacBook Pro M5 (14-inch) Best MacBook for creatives Apple M5, 32GB RAM, 512GB SSD 34.5 hours Up to 24 hours Best MacBook FAQs What's the difference between MacBook Air and Pro? The MacBook Air comes with the M4 chip. The 14-inch, base-model Pro comes with the M5 chip. MacBook Pro models have the option of more powerful M4 Pro or M4 Max chips. The Pro models have higher resolution screens with a higher peak brightness that supports up to 120Hz adaptive refresh rates and XDR (extreme dynamic range). The battery life on most Pro models is longer than on the Air models as well. Pro models also have more ports and more speakers. In short, the MacBook Air is aimed at everyday users looking for good productivity and entertainment capabilities, while Pro models are aimed at professionals who need a high-performance computer. What's the difference between macOS and Windows? MacOS is the operating system developed by Apple and used in all of its desktop and laptop computers. It can only be found in hardware made by Apple including MacBooks and iMacs. Microsoft’s Windows operating system can be found in the company’s own Surface laptops as well as computers made by a wide array of manufacturers, like Acer, Asus, Dell and Razer.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-macbook-140032524.html?src=rss",
          "feed_position": 1,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-11/e536a1d0-7c1e-11ee-9e77-9ea8e142b078"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/microsoft-copilot-gets-12-big-updates-for-fall-including-new-ai-assistant",
          "published_at": "Thu, 23 Oct 2025 19:01:00 GMT",
          "title": "Microsoft Copilot gets 12 big updates for fall, including new AI assistant character Mico",
          "standfirst": "Microsoft today held a live announcement event online for its Copilot AI digital assistant, with Mustafa Suleyman, CEO of Microsoft&#x27;s AI division, and other presenters unveiling a new generation of features that deepen integration across Windows, Edge, and Microsoft 365, positioning the platform as a practical assistant for people during work and off-time, while allowing them to preserve control and safety of their data.The new Copilot 2025 Fall Update features also up the ante in terms of capabilities and the accessibility of generative AI assistance from Microsoft to users, so businesses relying on Microsoft products, and those who seek to offer complimentary or competing products, would do well to review them.Suleyman emphasized that the updates reflect a shift from hype to usefulness. “Technology should work in service of people, not the other way around,” he said. “Copilot is not just a product—it’s a promise that AI can be helpful, supportive, and deeply personal.”Intriguingly, the announcement also sought to shine a greater spotlight on Microsoft&#x27;s own homegrown AI models, as opposed to those of its partner and investment OpenAI, which previously powered the entire Copilot experience. Instead, Suleyman wrote today in a blog post: “At the foundation of it all is our strategy to put the best models to work for you – both those we build and those we don’t. Over the past few months, we have released in-house models like MAI-Voice-1, MAI-1-Preview and MAI-Vision-1, and are rapidly iterating.”Twelve Features That Redefine CopilotThe Fall Release consolidates Copilot’s identity around twelve key capabilities—each with potential to streamline organizational knowledge work, development, or support operations.Groups – Shared Copilot sessions where up to 32 participants can brainstorm, co-author, or plan simultaneously. For distributed teams, it effectively merges a meeting chat, task board, and generative workspace. Copilot maintains context, summarizes decisions, and tracks open actions. Imagine – A collaborative hub for creating and remixing AI-generated content. In an enterprise setting, Imagine enables rapid prototyping of visuals, marketing drafts, or training materials.Mico – A new character identity for Copilot that introduces expressive feedback and emotional expression in the form of a cute, amorphous blob. Echoing Microsoft’s historic character interfaces like Clippy (Office 97) or Cortana (2014), Mico serves as a unifying UX layer across modalities.Real Talk – A conversational mode that adapts to a user’s communication style and offers calibrated pushback — ending the sycophancy that some users have complained about with other AI models such as prior versions of OpenAI&#x27;s ChatGPT. For professionals, it allows Socratic problem-solving rather than passive answer generation, making Copilot more credible in technical collaboration.Memory & Personalization – Long-term contextual memory that lets Copilot recall key details—training plans, dates, goals—at the user’s direction.Connectors – Integration with OneDrive, Outlook, Gmail, Google Drive, and Google Calendar for natural-language search across accounts.Proactive Actions (Preview) – Context-based prompts and next-step suggestions derived from recent activity.Copilot for Health – Health information grounded in credible medical sources such as Harvard Health, with tools allowing users to locate and compare doctors.Learn Live – A Socratic, voice-driven tutoring experience using questions, visuals, and whiteboards.Copilot Mode in Edge – Converts Microsoft Edge into an “AI browser” that summarizes, compares, and executes web actions by voice.Copilot on Windows – Deep integration across Windows 11 PCs with “Hey Copilot” activation, Copilot Vision guidance, and quick access to files and apps.Copilot Pages and Copilot Search – A collaborative file canvas plus a unified search experience combining AI-generated, cited answers with standard web results.The Fall Release is immediately available in the United States, with rollout to the UK, Canada, and other markets in progress. Some functions—such as Groups, Journeys, and Copilot for Health—remain U.S.-only for now. Proactive Actions requires a Microsoft 365 Personal, Family, or Premium subscription.Together these updates illustrate Microsoft’s pivot from static productivity suites to contextual AI infrastructure, with the Copilot brand acting as the connective tissue across user roles.From Clippy to Mico: The Return of a Guided InterfaceOne of the most notable introductions is Mico, a small animated companion that is available within Copilot’s voice-enabled experiences, including the Copilot app on Windows, iOS, and Android, as well as in Study Mode and other conversational contexts. It serves as an optional visual companion that appears during interactive or voice-based sessions, rather than across all Copilot interfaces.Mico listens, reacts with expressions, and changes color to reflect tone and emotion — bringing a visual warmth to an AI assistant experience that has traditionally been text-heavy.Mico’s design recalls earlier eras of Microsoft’s history with character-based assistants. In the mid-1990s, Microsoft experimented with Microsoft Bob (1995), a software interface that used cartoon characters like a dog named Rover to guide users through everyday computing tasks. While innovative for its time, Bob was discontinued after a year due to performance and usability issues.A few years later came Clippy, the Office Assistant introduced in Microsoft Office 97. Officially known as “Clippit,” the animated paperclip would pop up to offer help and tips within Word and other Office applications. Clippy became widely recognized—sometimes humorously so—for interrupting users with unsolicited advice. Microsoft retired Clippy from Office in 2001, though the character remains a nostalgic symbol of early AI-driven assistance.More recently, Cortana, launched in 2014 as Microsoft’s digital voice assistant for Windows and mobile devices, aimed to provide natural-language interaction similar to Apple’s Siri or Amazon’s Alexa. Despite positive early reception, Cortana’s role diminished as Microsoft refocused on enterprise productivity and AI integration. The service was officially discontinued on Windows in 2023.Mico, by contrast, represents a modern reimagining of that tradition—combining the personality of early assistants with the intelligence and adaptability of contemporary AI models. Where Clippy offered canned responses, Mico listens, learns, and reflects a user’s mood in real time. The goal, as Suleyman framed it, is to create an AI that feels “helpful, supportive, and deeply personal.”Groups Are Microsoft&#x27;s Version of Claude and ChatGPT ProjectsDuring Microsoft’s launch video, product researcher Wendy described Groups as a transformative shift: “You can finally bring in other people directly to the conversation that you’re having with Copilot,” she said. “It’s the only place you can do this.”Up to 32 users can join a shared Copilot session, brainstorming, editing, or planning together while the AI manages logistics such as summarizing discussion threads, tallying votes, and splitting tasks. Participants can enter or exit sessions using a link, maintaining full visibility into ongoing work.Instead of a single user prompting an AI and later sharing results, Groups lets teams prompt and iterate together in one unified conversation. In some ways, it&#x27;s an answer to Anthropic’s Claude Projects and OpenAI’s ChatGPT Projects, both launched within the last year as tools to centralize team workspaces and shared AI context. Where Claude and ChatGPT Projects allow users to aggregate files, prompts, and conversations into a single container, Groups extends that model into real-time, multi-participant collaboration. Unlike Anthropic’s and OpenAI’s implementations, Groups is deeply embedded within Microsoft’s productivity environment. Like other Copilot experiences connected to Outlook and OneDrive, Groups operates within Microsoft’s enterprise identity framework, governed by Microsoft 365 and Entra ID (formerly Azure Active Directory) authentication and consent modelsThis means conversations, shared artifacts, and generated summaries are governed under the same compliance policies that already protect Outlook, Teams, and SharePoint data.Hours after the unveiling, OpenAI hit back against its own investor in the escalating AI competition between the \"frenemies\" by expanding its Shared Projects feature beyond its current Enterprise, Team, and Edu subscriber availability to users of its free, Plus, and Pro subscription tiers. Operational Impact for AI and Data TeamsMemory & Personalization and Connectors effectively extend a lightweight orchestration layer across Microsoft’s ecosystem. Instead of building separate context-stores or retrieval APIs, teams can leverage Copilot’s secure integration with OneDrive or SharePoint as a governed data backbone. A presenter explained that Copilot’s memory “naturally picks up on important details and remembers them long after you’ve had the conversation,” yet remains editable. For data engineers, Copilot Search and Connectors reduce friction in data discovery across multiple systems. Natural-language retrieval from internal and cloud repositories may lower the cost of knowledge management initiatives by consolidating search endpoints.For security directors, Copilot’s explicit consent requirements and on/off toggles in Edge and Windows help maintain data residency standards. The company reiterated during the livestream that Copilot “acts only with user permission and within organizational privacy controls.”Copilot Mode in Edge: The AI Browser for Research and AutomationCopilot Mode in Edge stands out for offering AI-assisted information workflows. The browser can now parse open tabs, summarize differences, and perform transactional steps.“Historically, browsers have been static—just endless clicking and tab-hopping,” said a presenter during Microsoft’s livestream. “We asked not how browsers should work, but how people work.”In practice, an analyst could prompt Edge to compare supplier documentation, extract structured data, and auto-fill procurement forms—all with consistent citation. Voice-only navigation enables accessibility and multitasking, while Journeys, a companion feature, organizes browsing sessions into storylines for later review.Copilot on Windows: The Operating System as an AI SurfaceIn Windows 11, Copilot now functions as an embedded assistant. With the wake-word “Hey Copilot,” users can initiate context-aware commands without leaving the desktop—drafting documentation, troubleshooting configuration issues, or summarizing system logs.A presenter described it as a “super assistant plugged into all your files and applications.” For enterprises standardizing on Windows 11, this positions Copilot as a native productivity layer rather than an add-on, reducing training friction and promoting secure, on-device reasoning.Copilot Vision, now in early deployment, adds visual comprehension. IT staff can capture a screen region and ask Copilot to interpret error messages, explain configuration options, or generate support tickets automatically. Combined with Copilot Pages, which supports up to twenty concurrent file uploads, this enables more efficient cross-document analysis for audits, RFPs, or code reviews.Leveraging MAI Models for Multimodal WorkflowsAt the foundation of these capabilities are Microsoft’s proprietary MAI-Voice-1, MAI-1 Preview, and MAI-Vision-1 models—trained in-house to handle text, voice, and visual inputs cohesively.For engineering teams managing LLM orchestration, this architecture introduces several potential efficiencies:Unified multimodal reasoning – Reduces the need for separate ASR (speech-to-text) and image-parsing services.Fine-tuning continuity – Because Microsoft owns the model stack, updates propagate across Copilot experiences without re-integration.Predictable latency and governance – In-house hosting under Azure compliance frameworks simplifies security certification for regulated industries.A presenter described the new stack as “the foundation for immersive, creative, and dynamic experiences that still respect enterprise boundaries.”A Strategic Pivot Toward Contextual AIFor years, Microsoft positioned Copilot primarily as a productivity companion. With the Fall 2025 release, it crosses into operational AI infrastructure—a set of extensible services for reasoning over data and processes.Suleyman described this evolution succinctly: “Judge an AI by how much it elevates human potential, not just by its own smarts.” For CIOs and technical leads, the elevation comes from efficiency and interoperability.Copilot now acts as:A connective interface linking files, communications, and cloud data.A reasoning agent capable of understanding context across sessions and modalities.A secure orchestration layer compatible with Microsoft’s compliance and identity framework.Suleyman’s insistence that “technology should work in service of people” now extends to organizations as well: technology that serves teams, not workloads; systems that adapt to enterprise context rather than demand it.",
          "content": "Microsoft today held a live announcement event online for its Copilot AI digital assistant, with Mustafa Suleyman, CEO of Microsoft&#x27;s AI division, and other presenters unveiling a new generation of features that deepen integration across Windows, Edge, and Microsoft 365, positioning the platform as a practical assistant for people during work and off-time, while allowing them to preserve control and safety of their data.The new Copilot 2025 Fall Update features also up the ante in terms of capabilities and the accessibility of generative AI assistance from Microsoft to users, so businesses relying on Microsoft products, and those who seek to offer complimentary or competing products, would do well to review them.Suleyman emphasized that the updates reflect a shift from hype to usefulness. “Technology should work in service of people, not the other way around,” he said. “Copilot is not just a product—it’s a promise that AI can be helpful, supportive, and deeply personal.”Intriguingly, the announcement also sought to shine a greater spotlight on Microsoft&#x27;s own homegrown AI models, as opposed to those of its partner and investment OpenAI, which previously powered the entire Copilot experience. Instead, Suleyman wrote today in a blog post: “At the foundation of it all is our strategy to put the best models to work for you – both those we build and those we don’t. Over the past few months, we have released in-house models like MAI-Voice-1, MAI-1-Preview and MAI-Vision-1, and are rapidly iterating.”Twelve Features That Redefine CopilotThe Fall Release consolidates Copilot’s identity around twelve key capabilities—each with potential to streamline organizational knowledge work, development, or support operations.Groups – Shared Copilot sessions where up to 32 participants can brainstorm, co-author, or plan simultaneously. For distributed teams, it effectively merges a meeting chat, task board, and generative workspace. Copilot maintains context, summarizes decisions, and tracks open actions. Imagine – A collaborative hub for creating and remixing AI-generated content. In an enterprise setting, Imagine enables rapid prototyping of visuals, marketing drafts, or training materials.Mico – A new character identity for Copilot that introduces expressive feedback and emotional expression in the form of a cute, amorphous blob. Echoing Microsoft’s historic character interfaces like Clippy (Office 97) or Cortana (2014), Mico serves as a unifying UX layer across modalities.Real Talk – A conversational mode that adapts to a user’s communication style and offers calibrated pushback — ending the sycophancy that some users have complained about with other AI models such as prior versions of OpenAI&#x27;s ChatGPT. For professionals, it allows Socratic problem-solving rather than passive answer generation, making Copilot more credible in technical collaboration.Memory & Personalization – Long-term contextual memory that lets Copilot recall key details—training plans, dates, goals—at the user’s direction.Connectors – Integration with OneDrive, Outlook, Gmail, Google Drive, and Google Calendar for natural-language search across accounts.Proactive Actions (Preview) – Context-based prompts and next-step suggestions derived from recent activity.Copilot for Health – Health information grounded in credible medical sources such as Harvard Health, with tools allowing users to locate and compare doctors.Learn Live – A Socratic, voice-driven tutoring experience using questions, visuals, and whiteboards.Copilot Mode in Edge – Converts Microsoft Edge into an “AI browser” that summarizes, compares, and executes web actions by voice.Copilot on Windows – Deep integration across Windows 11 PCs with “Hey Copilot” activation, Copilot Vision guidance, and quick access to files and apps.Copilot Pages and Copilot Search – A collaborative file canvas plus a unified search experience combining AI-generated, cited answers with standard web results.The Fall Release is immediately available in the United States, with rollout to the UK, Canada, and other markets in progress. Some functions—such as Groups, Journeys, and Copilot for Health—remain U.S.-only for now. Proactive Actions requires a Microsoft 365 Personal, Family, or Premium subscription.Together these updates illustrate Microsoft’s pivot from static productivity suites to contextual AI infrastructure, with the Copilot brand acting as the connective tissue across user roles.From Clippy to Mico: The Return of a Guided InterfaceOne of the most notable introductions is Mico, a small animated companion that is available within Copilot’s voice-enabled experiences, including the Copilot app on Windows, iOS, and Android, as well as in Study Mode and other conversational contexts. It serves as an optional visual companion that appears during interactive or voice-based sessions, rather than across all Copilot interfaces.Mico listens, reacts with expressions, and changes color to reflect tone and emotion — bringing a visual warmth to an AI assistant experience that has traditionally been text-heavy.Mico’s design recalls earlier eras of Microsoft’s history with character-based assistants. In the mid-1990s, Microsoft experimented with Microsoft Bob (1995), a software interface that used cartoon characters like a dog named Rover to guide users through everyday computing tasks. While innovative for its time, Bob was discontinued after a year due to performance and usability issues.A few years later came Clippy, the Office Assistant introduced in Microsoft Office 97. Officially known as “Clippit,” the animated paperclip would pop up to offer help and tips within Word and other Office applications. Clippy became widely recognized—sometimes humorously so—for interrupting users with unsolicited advice. Microsoft retired Clippy from Office in 2001, though the character remains a nostalgic symbol of early AI-driven assistance.More recently, Cortana, launched in 2014 as Microsoft’s digital voice assistant for Windows and mobile devices, aimed to provide natural-language interaction similar to Apple’s Siri or Amazon’s Alexa. Despite positive early reception, Cortana’s role diminished as Microsoft refocused on enterprise productivity and AI integration. The service was officially discontinued on Windows in 2023.Mico, by contrast, represents a modern reimagining of that tradition—combining the personality of early assistants with the intelligence and adaptability of contemporary AI models. Where Clippy offered canned responses, Mico listens, learns, and reflects a user’s mood in real time. The goal, as Suleyman framed it, is to create an AI that feels “helpful, supportive, and deeply personal.”Groups Are Microsoft&#x27;s Version of Claude and ChatGPT ProjectsDuring Microsoft’s launch video, product researcher Wendy described Groups as a transformative shift: “You can finally bring in other people directly to the conversation that you’re having with Copilot,” she said. “It’s the only place you can do this.”Up to 32 users can join a shared Copilot session, brainstorming, editing, or planning together while the AI manages logistics such as summarizing discussion threads, tallying votes, and splitting tasks. Participants can enter or exit sessions using a link, maintaining full visibility into ongoing work.Instead of a single user prompting an AI and later sharing results, Groups lets teams prompt and iterate together in one unified conversation. In some ways, it&#x27;s an answer to Anthropic’s Claude Projects and OpenAI’s ChatGPT Projects, both launched within the last year as tools to centralize team workspaces and shared AI context. Where Claude and ChatGPT Projects allow users to aggregate files, prompts, and conversations into a single container, Groups extends that model into real-time, multi-participant collaboration. Unlike Anthropic’s and OpenAI’s implementations, Groups is deeply embedded within Microsoft’s productivity environment. Like other Copilot experiences connected to Outlook and OneDrive, Groups operates within Microsoft’s enterprise identity framework, governed by Microsoft 365 and Entra ID (formerly Azure Active Directory) authentication and consent modelsThis means conversations, shared artifacts, and generated summaries are governed under the same compliance policies that already protect Outlook, Teams, and SharePoint data.Hours after the unveiling, OpenAI hit back against its own investor in the escalating AI competition between the \"frenemies\" by expanding its Shared Projects feature beyond its current Enterprise, Team, and Edu subscriber availability to users of its free, Plus, and Pro subscription tiers. Operational Impact for AI and Data TeamsMemory & Personalization and Connectors effectively extend a lightweight orchestration layer across Microsoft’s ecosystem. Instead of building separate context-stores or retrieval APIs, teams can leverage Copilot’s secure integration with OneDrive or SharePoint as a governed data backbone. A presenter explained that Copilot’s memory “naturally picks up on important details and remembers them long after you’ve had the conversation,” yet remains editable. For data engineers, Copilot Search and Connectors reduce friction in data discovery across multiple systems. Natural-language retrieval from internal and cloud repositories may lower the cost of knowledge management initiatives by consolidating search endpoints.For security directors, Copilot’s explicit consent requirements and on/off toggles in Edge and Windows help maintain data residency standards. The company reiterated during the livestream that Copilot “acts only with user permission and within organizational privacy controls.”Copilot Mode in Edge: The AI Browser for Research and AutomationCopilot Mode in Edge stands out for offering AI-assisted information workflows. The browser can now parse open tabs, summarize differences, and perform transactional steps.“Historically, browsers have been static—just endless clicking and tab-hopping,” said a presenter during Microsoft’s livestream. “We asked not how browsers should work, but how people work.”In practice, an analyst could prompt Edge to compare supplier documentation, extract structured data, and auto-fill procurement forms—all with consistent citation. Voice-only navigation enables accessibility and multitasking, while Journeys, a companion feature, organizes browsing sessions into storylines for later review.Copilot on Windows: The Operating System as an AI SurfaceIn Windows 11, Copilot now functions as an embedded assistant. With the wake-word “Hey Copilot,” users can initiate context-aware commands without leaving the desktop—drafting documentation, troubleshooting configuration issues, or summarizing system logs.A presenter described it as a “super assistant plugged into all your files and applications.” For enterprises standardizing on Windows 11, this positions Copilot as a native productivity layer rather than an add-on, reducing training friction and promoting secure, on-device reasoning.Copilot Vision, now in early deployment, adds visual comprehension. IT staff can capture a screen region and ask Copilot to interpret error messages, explain configuration options, or generate support tickets automatically. Combined with Copilot Pages, which supports up to twenty concurrent file uploads, this enables more efficient cross-document analysis for audits, RFPs, or code reviews.Leveraging MAI Models for Multimodal WorkflowsAt the foundation of these capabilities are Microsoft’s proprietary MAI-Voice-1, MAI-1 Preview, and MAI-Vision-1 models—trained in-house to handle text, voice, and visual inputs cohesively.For engineering teams managing LLM orchestration, this architecture introduces several potential efficiencies:Unified multimodal reasoning – Reduces the need for separate ASR (speech-to-text) and image-parsing services.Fine-tuning continuity – Because Microsoft owns the model stack, updates propagate across Copilot experiences without re-integration.Predictable latency and governance – In-house hosting under Azure compliance frameworks simplifies security certification for regulated industries.A presenter described the new stack as “the foundation for immersive, creative, and dynamic experiences that still respect enterprise boundaries.”A Strategic Pivot Toward Contextual AIFor years, Microsoft positioned Copilot primarily as a productivity companion. With the Fall 2025 release, it crosses into operational AI infrastructure—a set of extensible services for reasoning over data and processes.Suleyman described this evolution succinctly: “Judge an AI by how much it elevates human potential, not just by its own smarts.” For CIOs and technical leads, the elevation comes from efficiency and interoperability.Copilot now acts as:A connective interface linking files, communications, and cloud data.A reasoning agent capable of understanding context across sessions and modalities.A secure orchestration layer compatible with Microsoft’s compliance and identity framework.Suleyman’s insistence that “technology should work in service of people” now extends to organizations as well: technology that serves teams, not workloads; systems that adapt to enterprise context rather than demand it.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1Y044YCqXidwgzt8iDL4XH/2a45ab0dfe64db4d9371db86b1d0e5d2/cfr0z3n_flat_2D_illustration_mod_colorful_playful_whimsical_sty_715bb078-8762-43bc-93ec-ce95bb5d570d.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/mico-is-microsofts-clippy-for-the-ai-age-174524597.html",
          "published_at": "Thu, 23 Oct 2025 17:45:24 +0000",
          "title": "Mico is Microsoft's Clippy for the AI age",
          "standfirst": "What if Clippy were powered by AI? That seems to be the pitch behind Microsoft's new \"expressive, customizable and warm\" face of Copilot's voice mode. The friendly blob listens, reacts and changes color in response to user interactions. Microsoft sees Mico as an answer to what an \"AI companion\" looks like. The \"optional visual presence\" aims to listen and support without kissing ass. \"It will push back on you sometimes, but always respectfully,\" Microsoft AI CEO Mustafa Suleyman wrote in a blog post. But don't take my word for it. Get ready for the most exciting 39 seconds of your day, as you watch Mico silently spin and shift hues. Clippy — I mean, Mico — is also part of a new Copilot feature called Learn Live. The student-focused voice mode will have Mico act as a Socratic tutor that \"guides you through concepts instead of just giving answers.\" Its tools will include questions, visual cues and interactive whiteboards. The Verge reports that Mico is only available in the US, UK and Canada at launch. The character is now being enabled by default for Copilot's voice mode. But you can turn it off if talking to fictional characters isn't your thing.This article originally appeared on Engadget at https://www.engadget.com/ai/mico-is-microsofts-clippy-for-the-ai-age-174524597.html?src=rss",
          "content": "What if Clippy were powered by AI? That seems to be the pitch behind Microsoft's new \"expressive, customizable and warm\" face of Copilot's voice mode. The friendly blob listens, reacts and changes color in response to user interactions. Microsoft sees Mico as an answer to what an \"AI companion\" looks like. The \"optional visual presence\" aims to listen and support without kissing ass. \"It will push back on you sometimes, but always respectfully,\" Microsoft AI CEO Mustafa Suleyman wrote in a blog post. But don't take my word for it. Get ready for the most exciting 39 seconds of your day, as you watch Mico silently spin and shift hues. Clippy — I mean, Mico — is also part of a new Copilot feature called Learn Live. The student-focused voice mode will have Mico act as a Socratic tutor that \"guides you through concepts instead of just giving answers.\" Its tools will include questions, visual cues and interactive whiteboards. The Verge reports that Mico is only available in the US, UK and Canada at launch. The character is now being enabled by default for Copilot's voice mode. But you can turn it off if talking to fictional characters isn't your thing.This article originally appeared on Engadget at https://www.engadget.com/ai/mico-is-microsofts-clippy-for-the-ai-age-174524597.html?src=rss",
          "feed_position": 8
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/claude-can-now-compartmentalize-as-part-of-a-major-memory-upgrade-170000194.html",
          "published_at": "Thu, 23 Oct 2025 17:00:00 +0000",
          "title": "Claude can now compartmentalize as part of a major memory upgrade",
          "standfirst": "Back in August, Anthropic made Claude capable of remembering past conversations. With the update, people could reference specific chats, so that they wouldn't need to repeat themselves when revisiting a topic. Today, the company has begun out a new, enhanced memory feature set, with the included improvements coming to all paying users. Plenty of chatbots, including ChatGPT and Gemini, can remember past conversations, but Anthropic believes its implementation has a few legs up on the competition. For one, Claude will learn your preferences and work patterns over time, which Anthropic says will translate to the chatbot getting better at understanding how you work. Additionally, the company claims Claude is \"fully transparent\" about its memory, meaning users will see an \"actual synthesis\" of what it has recorded over time, instead of \"vague summaries.\" If you want to edit its memory, you can do so through conversation. At the same, Anthropic has made it easy to compartmentalize the data Claude collects. When using the Projects feature to group conversations together, the chatbot will create a distinct memory space for each grouping. In this way, information Claude has saved from your work conversations won't bleed over to your personal chats, for example. If you're coming from ChatGPT or Gemini, Anthropic has made it possible to import saved memories from those chatbots to Claude. You can also export any tidbits of context Claude saves to other AI platforms. Ahead of today's announcement, Anthropic notes it conducted extensive testing to determine if Claude's new capabilities would lead to greater sycophancy and more harmful conversations. \"Though this testing, we identified areas where Claude’s responses needed refinement and made targeted adjustments to how memory functions,\" the company said. \"These iterations helped us build and improve the memory feature in a way that allows Claude to provide helpful and safe responses to users.\" Max subscribers can enable Claude new memory capabilities starting today, with availability for Pro users to follow in the coming days. The feature is fully optional, and won't be turned on unless you toggle it through the settings menu.This article originally appeared on Engadget at https://www.engadget.com/ai/claude-can-now-compartmentalize-as-part-of-a-major-memory-upgrade-170000194.html?src=rss",
          "content": "Back in August, Anthropic made Claude capable of remembering past conversations. With the update, people could reference specific chats, so that they wouldn't need to repeat themselves when revisiting a topic. Today, the company has begun out a new, enhanced memory feature set, with the included improvements coming to all paying users. Plenty of chatbots, including ChatGPT and Gemini, can remember past conversations, but Anthropic believes its implementation has a few legs up on the competition. For one, Claude will learn your preferences and work patterns over time, which Anthropic says will translate to the chatbot getting better at understanding how you work. Additionally, the company claims Claude is \"fully transparent\" about its memory, meaning users will see an \"actual synthesis\" of what it has recorded over time, instead of \"vague summaries.\" If you want to edit its memory, you can do so through conversation. At the same, Anthropic has made it easy to compartmentalize the data Claude collects. When using the Projects feature to group conversations together, the chatbot will create a distinct memory space for each grouping. In this way, information Claude has saved from your work conversations won't bleed over to your personal chats, for example. If you're coming from ChatGPT or Gemini, Anthropic has made it possible to import saved memories from those chatbots to Claude. You can also export any tidbits of context Claude saves to other AI platforms. Ahead of today's announcement, Anthropic notes it conducted extensive testing to determine if Claude's new capabilities would lead to greater sycophancy and more harmful conversations. \"Though this testing, we identified areas where Claude’s responses needed refinement and made targeted adjustments to how memory functions,\" the company said. \"These iterations helped us build and improve the memory feature in a way that allows Claude to provide helpful and safe responses to users.\" Max subscribers can enable Claude new memory capabilities starting today, with availability for Pro users to follow in the coming days. The feature is fully optional, and won't be turned on unless you toggle it through the settings menu.This article originally appeared on Engadget at https://www.engadget.com/ai/claude-can-now-compartmentalize-as-part-of-a-major-memory-upgrade-170000194.html?src=rss",
          "feed_position": 11
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/amazon-calls-on-ai-once-again-with-its-new-help-me-decide-shopping-tool-164516673.html",
          "published_at": "Thu, 23 Oct 2025 16:45:16 +0000",
          "title": "Amazon calls on AI once again with its new ‘Help Me Decide’ shopping tool",
          "standfirst": "People are evidently never buying quite enough stuff from Amazon to keep the company entirely happy, and it's calling on AI once again to push indecisive shoppers into locking down the purchase they’ve been eyeing up. The new tool, which Amazon calls Help Me Decide, gives shoppers in the US personalized recommendations of products they should buy by analyzing their browsing history, searches and preferences. It’s designed to \"help\" customers who have been looking at a number of products in a particular category, such as wireless headphones, to decide which one best suits their needs. The Help Me Decide button will pop up on a product detail page when it detects that you’ve been browsing for a while without making a final choice. If you choose to tap for AI assistance, it will pull together all the information it can find on your relevant shopping history and recommend the product it deems the right choice for you. It also recommends an alternative upgrade pick and a similar product for those on a budget. Help Me Decide can also group together related searches. Amazon uses the example of the tool recommending an all-season tent for four people based on you previously looking for adult and kids’ sleeping bags that keep you warm, camping accessories and children’s hiking boots. The recommendation it chooses includes an explanation of why it’s the best pick for you based on its features and your previous purchases, and pulls in customer reviews to back it up. This suggests that how useful the recommendations are will ultimately come down to how much you take notice of customer reviews. When searching for products to recommend to you, Help Me Decide leverages Amazon's Bedrock and SageMaker machine learning platforms, as well as its OpenSearch tool, to marry up all the different factors it takes into consideration. It follows the introduction of the Interests tool earlier this year, which uses AI to generate shopping results based on your natural language prompts. Back In May, the company also started experimenting with AI-generated hosts that can summarise products for you before you buy them, again relying heavily on customer reviews for its information. Help Me Decide is live in the US now and can be found in the Amazon app (iOS and Android) and mobile browser. If you tap “Keep shopping for” it should show up, and will do the same on a product detail page after you’ve looked at a number of products in a related category.This article originally appeared on Engadget at https://www.engadget.com/ai/amazon-calls-on-ai-once-again-with-its-new-help-me-decide-shopping-tool-164516673.html?src=rss",
          "content": "People are evidently never buying quite enough stuff from Amazon to keep the company entirely happy, and it's calling on AI once again to push indecisive shoppers into locking down the purchase they’ve been eyeing up. The new tool, which Amazon calls Help Me Decide, gives shoppers in the US personalized recommendations of products they should buy by analyzing their browsing history, searches and preferences. It’s designed to \"help\" customers who have been looking at a number of products in a particular category, such as wireless headphones, to decide which one best suits their needs. The Help Me Decide button will pop up on a product detail page when it detects that you’ve been browsing for a while without making a final choice. If you choose to tap for AI assistance, it will pull together all the information it can find on your relevant shopping history and recommend the product it deems the right choice for you. It also recommends an alternative upgrade pick and a similar product for those on a budget. Help Me Decide can also group together related searches. Amazon uses the example of the tool recommending an all-season tent for four people based on you previously looking for adult and kids’ sleeping bags that keep you warm, camping accessories and children’s hiking boots. The recommendation it chooses includes an explanation of why it’s the best pick for you based on its features and your previous purchases, and pulls in customer reviews to back it up. This suggests that how useful the recommendations are will ultimately come down to how much you take notice of customer reviews. When searching for products to recommend to you, Help Me Decide leverages Amazon's Bedrock and SageMaker machine learning platforms, as well as its OpenSearch tool, to marry up all the different factors it takes into consideration. It follows the introduction of the Interests tool earlier this year, which uses AI to generate shopping results based on your natural language prompts. Back In May, the company also started experimenting with AI-generated hosts that can summarise products for you before you buy them, again relying heavily on customer reviews for its information. Help Me Decide is live in the US now and can be found in the Amazon app (iOS and Android) and mobile browser. If you tap “Keep shopping for” it should show up, and will do the same on a product detail page after you’ve looked at a number of products in a related category.This article originally appeared on Engadget at https://www.engadget.com/ai/amazon-calls-on-ai-once-again-with-its-new-help-me-decide-shopping-tool-164516673.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/microsoft-makes-edges-copilot-mode-a-bit-smarter-160031147.html",
          "published_at": "Thu, 23 Oct 2025 16:00:31 +0000",
          "title": "Microsoft makes Edge's Copilot Mode a bit smarter",
          "standfirst": "Apparently, web browsers are cool again. Two days after OpenAI launched its AI browser, Microsoft has some updates for its Edge's AI mode. (Fancy that!) Copilot Mode, introduced in July, now has several features that were teased at launch. First up: Copilot Actions, which is Microsoft's branding for AI-assisted, multi-step tasks. This feature is already available in the standard version of Copilot, but it's now being previewed for Edge's Copilot Mode. Microsoft's examples of Copilot Actions in Edge include unsubscribing from email newsletters or making a restaurant reservation. Another new (but previously announced) feature is Journeys. These are saved projects you can return to anytime. \"Remember that project you started a while back, but life got in the way?\" Microsoft's blog post asks. \"No need to bookmark all those tabs.\" For example, if you're researching starting a business, Copilot can recap articles you've read, suggest next steps and resurface a tutorial video you watched. Here's a video from when Microsoft teased Journeys in July. Along similar lines, another new Copilot Mode feature is the option to let the assistant access your browsing history. One example Microsoft gives is chatting with Copilot about a clothing item you checked out last week. Or, ask it for movie recommendations based on content you previously liked. Copilot requires explicit permission to access your private data for these new features. Microsoft's blog post stresses that your browser data is protected under the company's privacy statement and that Copilot \"only collects what's needed to improve your experience.\" The company also notes that you'll see clear visual cues so you know when Copilot is active. Still, these features require loads of private information to be useful. Don't grant those permissions without first giving it some serious thought. The new Copilot features are currently free in a US-only \"limited preview.\"This article originally appeared on Engadget at https://www.engadget.com/ai/microsoft-makes-edges-copilot-mode-a-bit-smarter-160031147.html?src=rss",
          "content": "Apparently, web browsers are cool again. Two days after OpenAI launched its AI browser, Microsoft has some updates for its Edge's AI mode. (Fancy that!) Copilot Mode, introduced in July, now has several features that were teased at launch. First up: Copilot Actions, which is Microsoft's branding for AI-assisted, multi-step tasks. This feature is already available in the standard version of Copilot, but it's now being previewed for Edge's Copilot Mode. Microsoft's examples of Copilot Actions in Edge include unsubscribing from email newsletters or making a restaurant reservation. Another new (but previously announced) feature is Journeys. These are saved projects you can return to anytime. \"Remember that project you started a while back, but life got in the way?\" Microsoft's blog post asks. \"No need to bookmark all those tabs.\" For example, if you're researching starting a business, Copilot can recap articles you've read, suggest next steps and resurface a tutorial video you watched. Here's a video from when Microsoft teased Journeys in July. Along similar lines, another new Copilot Mode feature is the option to let the assistant access your browsing history. One example Microsoft gives is chatting with Copilot about a clothing item you checked out last week. Or, ask it for movie recommendations based on content you previously liked. Copilot requires explicit permission to access your private data for these new features. Microsoft's blog post stresses that your browser data is protected under the company's privacy statement and that Copilot \"only collects what's needed to improve your experience.\" The company also notes that you'll see clear visual cues so you know when Copilot is active. Still, these features require loads of private information to be useful. Don't grant those permissions without first giving it some serious thought. The new Copilot features are currently free in a US-only \"limited preview.\"This article originally appeared on Engadget at https://www.engadget.com/ai/microsoft-makes-edges-copilot-mode-a-bit-smarter-160031147.html?src=rss",
          "feed_position": 14
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/baby-steps-isnt-done-with-maxi-boch-140000613.html",
          "published_at": "Thu, 23 Oct 2025 14:00:00 +0000",
          "title": "Baby Steps isn't done with Maxi Boch",
          "standfirst": "Maxi Boch isn’t done with Baby Steps. Boch has enjoyed a productive career in game development and she knows how it feels to be creatively finished with a project. She experienced it at various points with Rock Band, Dance Central, Fantasia: Music Evolved and Ape Out, but on Baby Steps’ launch day, done was not the vibe. “I've been in the industry for a long time; I shipped broken strumbars for Rock Band,” Boch told Engadget. “I know that things change over time in this world, and it's not to say that Baby Steps is not done. It's done. But whether I'm done with Baby Steps, this is a different story.” To make a long one short: Boch’s collaborators, Bennett Foddy and Gabe Cuzzillo, were ready and excited to ship the game before she was, and so they did. Baby Steps hit PC and PlayStation 5 on September 23, 2025 (following one strategic delay to avoid the Hollow Knight: Silksong release window). From the player’s side, Baby Steps feels like a finely honed experience. It’s a walking simulator that follows Nate, a manchild in a gray onesie, as he attempts to scale a mountain and symbolically escape his parents’ basement. The player controls Nate’s legs individually, lifting each knee and carefully placing one foot in front of the other, learning how to walk in the very literal sense. Baby Steps succeeds because of its mechanical precision, but it excels because of its irreverent tone, magically surreal setting and AAA levels of polish. The mountain is a mix of childhood memories and adult anxieties represented by giant chess pieces, rude graffiti, and a crew of drinking, smoking, anthropomorphic donkeys who wander the cliffs with their dicks swinging free. Improvised dialogue between Nate and the NPCs turns each cutscene into a comedy sketch, but his journey also includes shocking revelations of existential numbness. In Baby Steps, falling is just as much of a mechanic as walking. You will fall — dramatically, drastically, down crevasses that took hours to climb — and Nate will bounce and slide and eventually just lay there, mumbling to himself while his onesie fills with mud. And then you’ll pick him back up and start walking again. You’ll settle his steps into a soothing cadence. You’ll marvel at the way his sweat slowly saturates the material at the base of his spine, just above his bulbous butt. You’ll try to skip a cutscene and realize that in order to do so, you need to play a minigame with the X prompt. You’ll learn how to run. And somewhere along the way, you’ll remember what it feels like to just enjoy play. Baby StepsDevolver Digital As a former marching band member, I appreciate the sense of rhythm that’s built into Baby Steps, spurred by the animal sounds and natural-world musical cues that are tied to Nate’s footfall in specific areas. This is Boch’s area of expertise, and also the main reason she doesn’t feel finished with the game. Boch and her collaborators ended up using a slapdash mosaic of audio middleware and low-level software for Baby Steps, and a series of late-stage issues infused all of the songs in the game with incorrect samples. On launch day, the music and audio cues weren’t reacting as intended when Nate stepped, stumbled and fell. On September 23, the day that Baby Steps came out, Boch and I talked for an hour about its development process. Our conversation gently circled the topic of perseverance, the game’s core theme, but we only directly acknowledged it at minute 59. It’s not something you need to scream or repeat — tenacity is the obvious message in a game about climbing a mountain on wobbly feet — but it was fascinating to learn why Boch in particular was inspired to build a game about endurance. Making Baby Steps Boch, Foddy and Cuzzillo started working on Baby Steps right after they released Ape Out and cemented their names in the annals of frenetic, bloody and slightly silly indie history. Foddy was already known as the creator of QWOP, GIRP and Getting Over It, and Boch as the rhythmic and hardware mastermind behind the largest AAA music games of the mid-2000s. The trio worked out of Boch and Foddy’s shared office at the NYU Game Center, where they were instructors and Cuzzillo was finishing up a graduate degree with Ape Out as his final project. They began prototyping Baby Steps around March 2019. “At that point, I also started manifesting more symptoms of my chronic illness, and so I was in the midst of a period of an attempt at really intense reconditioning, which ultimately failed,” Boch said. “But when that period was over, I joined up with the crew again.” Boch lives with a trifecta of chronic illnesses: Ehlers-Danlos Syndrome, Postural Orthostatic Tachycardia Syndrome and Mast Cell Activation Syndrome. EDS is a connective tissue disorder that affects the entire body, and it can cause hypermobility, fatigue, vision issues, fragile skin and an increased risk of vascular ruptures. People with POTS experience an abnormally large increase in heart rate when changing posture, and MCAS is a disorder that releases excessive amounts of histamine and similar chemicals in the body, causing random and potentially life-threatening allergic reactions. It’s common for people with one of these diagnoses to also receive the others. “It’s been an incredible challenge,” Boch said. “I think, easily, the hardest thing I've had to deal with in my life. I think there's something very singular about each one of us, the three core members of this crew, and part of that is our ability to work fluidly across disciplines and the like. But another part of it is just a level of stick-to-it-iveness that my body has handily rejected, and so I'm in a fight with it all the time.” Baby StepsDevolver Digital Boch has an arsenal of specialized tools to help her create games, including ergonomic (and very expensive) keyboards and a pair of glasses that act as a mouse. “I have found that most of what game development is about and is oriented around is kind of hostile to those of us with poor fine-motor skills, and it's an odd thing to be experiencing alongside the making of a thing that is stridently difficult,” Boch said. “There's odd moments in it, where I have been going through physical therapy processes to retrain my actual walking, alongside working on this thing that is deconstructing walking. A very odd subset of feelings.” Boch said the hardest thing for her to contend with is the moment-to-moment unpredictability of her health. But by the fall of 2019, she was back in the office with Cuzzillo and Foddy, iterating on the ideas that would eventually become Baby Steps. Cuzzillo and Foddy were feeling slightly discouraged at this point: They were four or five ideas deep, messing around with a competitive, real-time strategy game or a SimCity type of experience, but nothing was quite right. Boch encouraged them to return to their ridiculous, mechanically-driven roots. “I think it started to become a lot clearer in everyone's mind when it started to take on aspects of Bennett’s work,” Boch said. “The first handful of years of Baby Steps’ development, we were all playing various sorts of roles. The work of VO direction, recording and narrative development was something we were all working on together. Some of the foundational narrative premise things are concepts that I brought to the table as ways to try and prop up some world around this character. Lots of tools building and infrastructural work and all of the foundational stuff that makes it possible for a team that's so tiny to make a thing that's so strong.” The Baby Steps crew shared a house in upstate New York during the first winter of the pandemic in 2020. They hiked together and worked on the game at one big folding table, enjoying the mountain air with their partners and each other. There were no strict roles on the game development side, with Boch, Cuzzillo and Foddy contributing to all aspects at once, including voice work. “Over time, there are aspects of the narrative development that became increasingly more personal to my collaborators,” Boch said. “And they started to feel more comfortable in a director-less environment in terms of coaxing naturalistic performances out of themselves, and so that work became more disjointed.” By the time they were recording voices and finding characters through improvisation in the sound booth, Boch happened to be in the early stages of transitioning. Vocal training and voice acting are a tricky mix, it turns out. “I kind of recognized what it was going to take to be doing voiceover performance myself in the midst of my early transition, and I made the call that it was not the right activity for me,” Boch said. “So my characters were cut — it was like one or two — and I endeavored to strike up some novel collaborations on the audio side.” For the past year and half in particular, Boch has been focused on all things audio in Baby Steps, as well as overseeing big-picture production tasks. She brought on a collaborator from the world of hardcore techno music, Jack Schlesinger, and he primarily handled system architecture details while Boch dealt with creative aspects. DJ Ashe Kilbourne and harpist Emily Hopkins rounded out the list of audio contributors. When she was able, Boch took an improvised sound kit into the wild and collected nature noises, and the team stitched together a reactive audio system using middleware and leftover bits of software from the Harmonix days. When Baby Steps’ dynamic audio kicks in, and the boops, chirps and thunks start layering on top of one another as Nate waddles along, it adds a delicious sense of hypnosis to the game. Unfortunately, the audio systems fell apart in the final weeks before launch. The VO was fine, but many of the sounds and beats weren’t populating in the right places at the proper times, and Boch’s vision wasn’t being clearly communicated day-one. “The foundations of game audio tooling are terrible,” Boch said. She continued, “The world of game audio, from my perspective, is a bunch of people who are sitting on top of a bunch of work they've done to write drivers to talk to consoles, and a bunch of work they've done to forge relationships with console manufacturers so that their audio technology will be licensed by the two major engines. But they're both trash. I will not endorse either one, and I will not say that either one is capable of doing the kind of work that I need done.” Since launch, the Baby Steps audio team has released patches addressing the sampling issues and adjusting dynamic audio cues across the game. An imminent update will introduce animals singing along with the songs, outdoor and indoor reverb simulations across all sounds, and other fixes. Boch has additional updates and surprises planned, including a Baby Steps Fi Beats livestream to showcase the game’s music on YouTube. By November, the audio team will be focused on composing. Baby Steps is only going to get more immersive as the audio improvements roll out. And if you listen closely, you’ll be able to hear Boch voicing a few small roles throughout the game. “I play, like, a baby and a hypothetical gay partner for Nate and a bunch of other random characters,” Boch said. “There's some cosmic sadness on my part, that the timing worked out in exactly the ways that it did. But I don't know, it's the cards you're dealt. It's important to do the thing that's true to you.” One glaring truth that shook out during the Baby Steps development process was the supremely close and infectious bond between Cuzzillo and Foddy. The game’s dialogue and cutscenes are composed of off-the-cuff conversations and rambling inside jokes between Cuzzillo and Foddy, and each of these moments is delightful in a chaotic kind of way. Like a classic comedy duo, these developers share an undeniable resonance. They’re even born on the same day and they have older brothers with the same birthday, two facts that Boch finds adorable. “I'm not a horoscope person at all, but they have a kind of cosmic level of synchronicity that they both acknowledge, but also are a little bit like, ‘What, this?’” Boch said. “They have plenty that they disagree about and plenty that they bicker about, but there's something about their orientations toward the world that's perplexing and generative. They are immensely talented folks.” Taking Baby Steps In the end, Cuzzillo and Foddy felt finished with Baby Steps before Boch. She didn’t want to hold their joy hostage, so the audio team made it work and they shipped the game on September 23, 2025, published by Devolver Digital. “That kind of dream-deferred shit is emotional torture, and so I had no interest in putting them through that, they had no interest in going through that,” Boch said. “It makes sense to me to be landing in the place that we are.” Baby StepsDevolver Digital I caught up with Boch three weeks after Baby Steps’ release date to see if she was feeling more done, now that the launch-day dust had settled. She said it was a hard question. “There is so much more that I am interested in exploring, and so much more that I have set up in terms of pins to knock down,” she said. “I think this is a struggle that highlights the inherent tension of trying to make art at this boundary between a fine art practice and a commercial art practice. I think that for the sake of the work, and for the sake of me and my team as artists, the tech I have built deserves to continue to be refined in a different context, one wherein sound is more paramount. That's where we're headed.” This is a tease of what’s next for Boch, even though she’s still finishing up Baby Steps. She’s planning on leaving NYU, spurred by the unpredictability of her health, but she’s not done making games. Her next one will be more personal. “It's important to me to share what I'm doing with people,” Boch said in September. “I think that there is not enough in the world of games that puts audio at its very center. I think that my personal ambitions and future ambitions are definitely leaning more in that direction by the day. I had a long time of needing to get some space from interactive audio as The Thing. Where my winds are blowing is in that direction.” Baby Steps exists in its current form because Boch and her teammates were able to adapt and endure. They were honest about what was working, what wasn’t and what could, and they leaned into the aspects that felt the most natural to them. Boch in particular set aside her ego, listened to her body, and took things day by day. You know, baby steps. “The process of transition is one that involves an enormous amount of self-reflection and a growing sense of self knowledge,” Boch said. “Ultimately, that process for me was kind of orthogonal to the storytelling of Baby Steps. There's a lot that comes from lived experience, and from commiserating and sharing that lived experience between Bennett and Gabe, and you can see that very clearly in the work. There's also just ways in which that process was illuminating to me in terms of inherent differences. There's an aspect of it that came alongside the necessity of slowing down, and then the subsequent necessity of staying inside that hit with my chronic illness and then Covid. There was a way in which I was more with myself at that moment than I’ve ever been.”This article originally appeared on Engadget at https://www.engadget.com/gaming/baby-steps-isnt-done-with-maxi-boch-140000613.html?src=rss",
          "content": "Maxi Boch isn’t done with Baby Steps. Boch has enjoyed a productive career in game development and she knows how it feels to be creatively finished with a project. She experienced it at various points with Rock Band, Dance Central, Fantasia: Music Evolved and Ape Out, but on Baby Steps’ launch day, done was not the vibe. “I've been in the industry for a long time; I shipped broken strumbars for Rock Band,” Boch told Engadget. “I know that things change over time in this world, and it's not to say that Baby Steps is not done. It's done. But whether I'm done with Baby Steps, this is a different story.” To make a long one short: Boch’s collaborators, Bennett Foddy and Gabe Cuzzillo, were ready and excited to ship the game before she was, and so they did. Baby Steps hit PC and PlayStation 5 on September 23, 2025 (following one strategic delay to avoid the Hollow Knight: Silksong release window). From the player’s side, Baby Steps feels like a finely honed experience. It’s a walking simulator that follows Nate, a manchild in a gray onesie, as he attempts to scale a mountain and symbolically escape his parents’ basement. The player controls Nate’s legs individually, lifting each knee and carefully placing one foot in front of the other, learning how to walk in the very literal sense. Baby Steps succeeds because of its mechanical precision, but it excels because of its irreverent tone, magically surreal setting and AAA levels of polish. The mountain is a mix of childhood memories and adult anxieties represented by giant chess pieces, rude graffiti, and a crew of drinking, smoking, anthropomorphic donkeys who wander the cliffs with their dicks swinging free. Improvised dialogue between Nate and the NPCs turns each cutscene into a comedy sketch, but his journey also includes shocking revelations of existential numbness. In Baby Steps, falling is just as much of a mechanic as walking. You will fall — dramatically, drastically, down crevasses that took hours to climb — and Nate will bounce and slide and eventually just lay there, mumbling to himself while his onesie fills with mud. And then you’ll pick him back up and start walking again. You’ll settle his steps into a soothing cadence. You’ll marvel at the way his sweat slowly saturates the material at the base of his spine, just above his bulbous butt. You’ll try to skip a cutscene and realize that in order to do so, you need to play a minigame with the X prompt. You’ll learn how to run. And somewhere along the way, you’ll remember what it feels like to just enjoy play. Baby StepsDevolver Digital As a former marching band member, I appreciate the sense of rhythm that’s built into Baby Steps, spurred by the animal sounds and natural-world musical cues that are tied to Nate’s footfall in specific areas. This is Boch’s area of expertise, and also the main reason she doesn’t feel finished with the game. Boch and her collaborators ended up using a slapdash mosaic of audio middleware and low-level software for Baby Steps, and a series of late-stage issues infused all of the songs in the game with incorrect samples. On launch day, the music and audio cues weren’t reacting as intended when Nate stepped, stumbled and fell. On September 23, the day that Baby Steps came out, Boch and I talked for an hour about its development process. Our conversation gently circled the topic of perseverance, the game’s core theme, but we only directly acknowledged it at minute 59. It’s not something you need to scream or repeat — tenacity is the obvious message in a game about climbing a mountain on wobbly feet — but it was fascinating to learn why Boch in particular was inspired to build a game about endurance. Making Baby Steps Boch, Foddy and Cuzzillo started working on Baby Steps right after they released Ape Out and cemented their names in the annals of frenetic, bloody and slightly silly indie history. Foddy was already known as the creator of QWOP, GIRP and Getting Over It, and Boch as the rhythmic and hardware mastermind behind the largest AAA music games of the mid-2000s. The trio worked out of Boch and Foddy’s shared office at the NYU Game Center, where they were instructors and Cuzzillo was finishing up a graduate degree with Ape Out as his final project. They began prototyping Baby Steps around March 2019. “At that point, I also started manifesting more symptoms of my chronic illness, and so I was in the midst of a period of an attempt at really intense reconditioning, which ultimately failed,” Boch said. “But when that period was over, I joined up with the crew again.” Boch lives with a trifecta of chronic illnesses: Ehlers-Danlos Syndrome, Postural Orthostatic Tachycardia Syndrome and Mast Cell Activation Syndrome. EDS is a connective tissue disorder that affects the entire body, and it can cause hypermobility, fatigue, vision issues, fragile skin and an increased risk of vascular ruptures. People with POTS experience an abnormally large increase in heart rate when changing posture, and MCAS is a disorder that releases excessive amounts of histamine and similar chemicals in the body, causing random and potentially life-threatening allergic reactions. It’s common for people with one of these diagnoses to also receive the others. “It’s been an incredible challenge,” Boch said. “I think, easily, the hardest thing I've had to deal with in my life. I think there's something very singular about each one of us, the three core members of this crew, and part of that is our ability to work fluidly across disciplines and the like. But another part of it is just a level of stick-to-it-iveness that my body has handily rejected, and so I'm in a fight with it all the time.” Baby StepsDevolver Digital Boch has an arsenal of specialized tools to help her create games, including ergonomic (and very expensive) keyboards and a pair of glasses that act as a mouse. “I have found that most of what game development is about and is oriented around is kind of hostile to those of us with poor fine-motor skills, and it's an odd thing to be experiencing alongside the making of a thing that is stridently difficult,” Boch said. “There's odd moments in it, where I have been going through physical therapy processes to retrain my actual walking, alongside working on this thing that is deconstructing walking. A very odd subset of feelings.” Boch said the hardest thing for her to contend with is the moment-to-moment unpredictability of her health. But by the fall of 2019, she was back in the office with Cuzzillo and Foddy, iterating on the ideas that would eventually become Baby Steps. Cuzzillo and Foddy were feeling slightly discouraged at this point: They were four or five ideas deep, messing around with a competitive, real-time strategy game or a SimCity type of experience, but nothing was quite right. Boch encouraged them to return to their ridiculous, mechanically-driven roots. “I think it started to become a lot clearer in everyone's mind when it started to take on aspects of Bennett’s work,” Boch said. “The first handful of years of Baby Steps’ development, we were all playing various sorts of roles. The work of VO direction, recording and narrative development was something we were all working on together. Some of the foundational narrative premise things are concepts that I brought to the table as ways to try and prop up some world around this character. Lots of tools building and infrastructural work and all of the foundational stuff that makes it possible for a team that's so tiny to make a thing that's so strong.” The Baby Steps crew shared a house in upstate New York during the first winter of the pandemic in 2020. They hiked together and worked on the game at one big folding table, enjoying the mountain air with their partners and each other. There were no strict roles on the game development side, with Boch, Cuzzillo and Foddy contributing to all aspects at once, including voice work. “Over time, there are aspects of the narrative development that became increasingly more personal to my collaborators,” Boch said. “And they started to feel more comfortable in a director-less environment in terms of coaxing naturalistic performances out of themselves, and so that work became more disjointed.” By the time they were recording voices and finding characters through improvisation in the sound booth, Boch happened to be in the early stages of transitioning. Vocal training and voice acting are a tricky mix, it turns out. “I kind of recognized what it was going to take to be doing voiceover performance myself in the midst of my early transition, and I made the call that it was not the right activity for me,” Boch said. “So my characters were cut — it was like one or two — and I endeavored to strike up some novel collaborations on the audio side.” For the past year and half in particular, Boch has been focused on all things audio in Baby Steps, as well as overseeing big-picture production tasks. She brought on a collaborator from the world of hardcore techno music, Jack Schlesinger, and he primarily handled system architecture details while Boch dealt with creative aspects. DJ Ashe Kilbourne and harpist Emily Hopkins rounded out the list of audio contributors. When she was able, Boch took an improvised sound kit into the wild and collected nature noises, and the team stitched together a reactive audio system using middleware and leftover bits of software from the Harmonix days. When Baby Steps’ dynamic audio kicks in, and the boops, chirps and thunks start layering on top of one another as Nate waddles along, it adds a delicious sense of hypnosis to the game. Unfortunately, the audio systems fell apart in the final weeks before launch. The VO was fine, but many of the sounds and beats weren’t populating in the right places at the proper times, and Boch’s vision wasn’t being clearly communicated day-one. “The foundations of game audio tooling are terrible,” Boch said. She continued, “The world of game audio, from my perspective, is a bunch of people who are sitting on top of a bunch of work they've done to write drivers to talk to consoles, and a bunch of work they've done to forge relationships with console manufacturers so that their audio technology will be licensed by the two major engines. But they're both trash. I will not endorse either one, and I will not say that either one is capable of doing the kind of work that I need done.” Since launch, the Baby Steps audio team has released patches addressing the sampling issues and adjusting dynamic audio cues across the game. An imminent update will introduce animals singing along with the songs, outdoor and indoor reverb simulations across all sounds, and other fixes. Boch has additional updates and surprises planned, including a Baby Steps Fi Beats livestream to showcase the game’s music on YouTube. By November, the audio team will be focused on composing. Baby Steps is only going to get more immersive as the audio improvements roll out. And if you listen closely, you’ll be able to hear Boch voicing a few small roles throughout the game. “I play, like, a baby and a hypothetical gay partner for Nate and a bunch of other random characters,” Boch said. “There's some cosmic sadness on my part, that the timing worked out in exactly the ways that it did. But I don't know, it's the cards you're dealt. It's important to do the thing that's true to you.” One glaring truth that shook out during the Baby Steps development process was the supremely close and infectious bond between Cuzzillo and Foddy. The game’s dialogue and cutscenes are composed of off-the-cuff conversations and rambling inside jokes between Cuzzillo and Foddy, and each of these moments is delightful in a chaotic kind of way. Like a classic comedy duo, these developers share an undeniable resonance. They’re even born on the same day and they have older brothers with the same birthday, two facts that Boch finds adorable. “I'm not a horoscope person at all, but they have a kind of cosmic level of synchronicity that they both acknowledge, but also are a little bit like, ‘What, this?’” Boch said. “They have plenty that they disagree about and plenty that they bicker about, but there's something about their orientations toward the world that's perplexing and generative. They are immensely talented folks.” Taking Baby Steps In the end, Cuzzillo and Foddy felt finished with Baby Steps before Boch. She didn’t want to hold their joy hostage, so the audio team made it work and they shipped the game on September 23, 2025, published by Devolver Digital. “That kind of dream-deferred shit is emotional torture, and so I had no interest in putting them through that, they had no interest in going through that,” Boch said. “It makes sense to me to be landing in the place that we are.” Baby StepsDevolver Digital I caught up with Boch three weeks after Baby Steps’ release date to see if she was feeling more done, now that the launch-day dust had settled. She said it was a hard question. “There is so much more that I am interested in exploring, and so much more that I have set up in terms of pins to knock down,” she said. “I think this is a struggle that highlights the inherent tension of trying to make art at this boundary between a fine art practice and a commercial art practice. I think that for the sake of the work, and for the sake of me and my team as artists, the tech I have built deserves to continue to be refined in a different context, one wherein sound is more paramount. That's where we're headed.” This is a tease of what’s next for Boch, even though she’s still finishing up Baby Steps. She’s planning on leaving NYU, spurred by the unpredictability of her health, but she’s not done making games. Her next one will be more personal. “It's important to me to share what I'm doing with people,” Boch said in September. “I think that there is not enough in the world of games that puts audio at its very center. I think that my personal ambitions and future ambitions are definitely leaning more in that direction by the day. I had a long time of needing to get some space from interactive audio as The Thing. Where my winds are blowing is in that direction.” Baby Steps exists in its current form because Boch and her teammates were able to adapt and endure. They were honest about what was working, what wasn’t and what could, and they leaned into the aspects that felt the most natural to them. Boch in particular set aside her ego, listened to her body, and took things day by day. You know, baby steps. “The process of transition is one that involves an enormous amount of self-reflection and a growing sense of self knowledge,” Boch said. “Ultimately, that process for me was kind of orthogonal to the storytelling of Baby Steps. There's a lot that comes from lived experience, and from commiserating and sharing that lived experience between Bennett and Gabe, and you can see that very clearly in the work. There's also just ways in which that process was illuminating to me in terms of inherent differences. There's an aspect of it that came alongside the necessity of slowing down, and then the subsequent necessity of staying inside that hit with my chronic illness and then Covid. There was a way in which I was more with myself at that moment than I’ve ever been.”This article originally appeared on Engadget at https://www.engadget.com/gaming/baby-steps-isnt-done-with-maxi-boch-140000613.html?src=rss",
          "feed_position": 19,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/ss_1e34e8a5237d66b978f5389924cfdfecdde60df0.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/ai-is-tearing-companies-apart-writer-ai-ceo-slams-fortune-500-leaders-for",
          "published_at": "Thu, 23 Oct 2025 13:02:00 GMT",
          "title": "‘AI is tearing companies apart’: Writer AI CEO slams Fortune 500 leaders for mismanaging tech",
          "standfirst": "May Habib, co-founder and CEO of Writer AI, delivered one of the bluntest assessments of corporate AI failures at the TED AI conference on Tuesday, revealing that nearly half of Fortune 500 executives believe artificial intelligence is actively damaging their organizations — and placing the blame squarely on leadership&#x27;s shoulders.The problem, according to Habib, isn&#x27;t the technology. It&#x27;s that business leaders are making a category error, treating AI transformation like previous technology rollouts and delegating it to IT departments. This approach, she warned, has led to \"billions of dollars spent on AI initiatives that are going nowhere.\"\"Earlier this year, we did a survey of 800 Fortune 500 C-suite executives,\" Habib told the audience of Silicon Valley executives and investors. \"42% of them said AI is tearing their company apart.\"The diagnosis challenges conventional wisdom about how enterprises should approach AI adoption. While most major companies have stood up AI task forces, appointed chief AI officers, or expanded IT budgets, Habib argues these moves reflect a fundamental misunderstanding of what AI represents: not another software tool, but a wholesale reorganization of how work gets done.\"There is something leaders are missing when they compare AI to just another tech tool,\" Habib said. \"This is not like giving accountants calculators or bankers Excel or designers Photoshop.\"Why the &#x27;old playbook&#x27; of delegating to IT departments is failing companiesHabib, whose company has spent five years building AI systems for Fortune 500 companies and logged two million miles visiting customer sites, said the pattern is consistent: \"When generative AI started showing up, we turned to the old playbook. We turned to IT and said, &#x27;Go figure this out.&#x27;\"That approach fails, she argued, because AI fundamentally changes the economics and organization of work itself. \"For 100 years, enterprises have been built around the idea that execution is expensive and hard,\" Habib said. \"The enterprise built complex org charts, complex processes, all to manage people doing stuff.\"AI inverts that model. \"Execution is going from scarce and expensive to programmatic, on-demand and abundant,\" she said. In this new paradigm, the bottleneck shifts from execution capacity to strategic design — a shift that requires business leaders, not IT departments, to drive transformation.\"With AI technology, it can no longer be centralized. It&#x27;s in every workflow, every business,\" Habib said. \"It is now the most important part of a business leader&#x27;s job. It cannot be delegated.\"The statement represents a direct challenge to how most large organizations have structured their AI initiatives, with centralized centers of excellence, dedicated AI teams, or IT-led implementations that business units are expected to adopt.A generational power shift is happening based on who understands AI workflow designHabib framed the shift in dramatic terms: \"A generational transfer of power is happening right now. It&#x27;s not about your age or how long you&#x27;ve been at a company. The generational transfer of power is about the nature of leadership itself.\"Traditional leadership, she argued, has been defined by the ability to manage complexity — big teams, big budgets, intricate processes. \"The identity of leaders at these companies, people like us, has been tied to old school power structures: control, hierarchy, how big our teams are, how big our budgets are. Our value is measured by the sheer amount of complexity we could manage,\" Habib said. \"Today we reward leaders for this. We promote leaders for this.\"AI makes that model obsolete. \"When I am able to 10x the output of my team or do things that could never be possible, work is no longer about the 1x,\" she said. \"Leadership is no longer about managing complex human execution.\"Instead, Habib outlined three fundamental shifts that define what she calls \"AI-first leaders\" — executives her company has worked with who have successfully deployed AI agents solving \"$100 million plus problems.\"The first shift: Taking a machete to enterprise complexityThe new leadership mandate, according to Habib, is \"taking a machete to the complexity that has calcified so many organizations.\" She pointed to the layers of friction that have accumulated in enterprises: \"Brilliant ideas dying in memos, the endless cycles of approvals, the death by 1,000 clicks, meetings about meetings — a death, by the way, that&#x27;s happening in 17 different browser tabs each for software that promises to be a single source of truth.\"Rather than accepting this complexity as inevitable, AI-first leaders redesign workflows from first principles. \"There are very few legacy systems that can&#x27;t be replaced in your organization, that won&#x27;t be replaced,\" Habib said. \"But they&#x27;re not going to be replaced by another monolithic piece of software. They can only be replaced by a business leader articulating business logic and getting that into an agentic system.\"She offered a concrete example: \"We have customers where it used to take them seven months to get a creative campaign — not even a product, a campaign. Now they can go from TikTok trend to digital shelf in 30 days. That is radical simplicity.\"The catch, she emphasized, is that CIOs can&#x27;t drive this transformation alone. \"Your CIO can&#x27;t help flatten your org chart. Only a business leader can look at workflows and say, &#x27;This part is necessary genius, this part is bureaucratic scar tissue that has to go.&#x27;\"The second shift: Managing the fear as career ladders disappearWhen AI handles execution, \"your humans are liberated to do what they&#x27;re amazing at: judgment, strategy, creativity,\" Habib explained. \"The old leadership playbook was about managing headcount. We managed people against revenue: one business development rep for every three account executives, one marketer for every five salespeople.\"But this liberation carries profound challenges that leaders must address directly. Habib acknowledged the elephant in the room that many executives avoid discussing: \"These changes are still frightening for people, even when it&#x27;s become unholy to talk about it.\" She&#x27;s witnessed the fear firsthand. \"It shows up as tears in an AI workshop when someone feels like their old skill set isn&#x27;t translated to the new.\"She introduced a term for a common form of resistance: \"productivity anchoring\" — when employees \"cling to the hard way of doing things because they feel productive, because their self-worth is tied to them, even when empirically AI can be better.\"The solution isn&#x27;t to look away. \"We have to design new pathways to impact, to show your people their value is not in executing a task. Their value is in orchestrating systems of execution, to ask the next great question,\" Habib said. She advocates replacing career \"ladders\" with \"lattices\" where \"people need to grow laterally, to expand sideways.\"She was candid about the disruption: \"The first rungs on our career ladders are indeed going away. I know because my company is automating them.\" But she insisted this creates opportunity for work that is \"more creative, more strategic, more driven by curiosity and impact — and I believe a lot more human than the jobs that they&#x27;re replacing.\"The third shift: When execution becomes free, ambition becomes the only bottleneckThe final shift is from optimization to creation. \"Before AI, we used to call it transformation when we took 12 steps and made them nine,\" Habib said. \"That&#x27;s optimizing the world as it is. We can now create a new world. That is the greenfield mindset.\"She challenged executives to identify assumptions their industries are built on that AI now disrupts. Writer&#x27;s customers, she said, are already seeing new categories of growth: treating every customer like their only customer, democratizing premium services to broader markets, and entering new markets at unprecedented speed because \"AI strips away the friction to access new channels.\"\"When execution is abundant, the only bottleneck is the scope of your own ambition,\" Habib declared.What this means for CIOs: Building the stadium while business leaders design the playsHabib didn&#x27;t leave IT leaders without a role — she redefined it. \"If tech is everyone&#x27;s job, you might be asking, what is mine?\" she addressed CIOs. \"Yours is to provide the mission critical infrastructure that makes this revolution possible.\"As tens or hundreds of thousands of AI agents operate at various levels of autonomy within organizations, \"governance becomes existential,\" she explained. \"The business leader&#x27;s job is to design the play, but you have to build the stadium, you have to write the rule book, and you have to make sure these plays can win at championship scale.\"The formulation suggests a partnership model: business leaders drive workflow redesign and strategic implementation while IT provides the infrastructure, governance frameworks, and security guardrails that make mass AI deployment safe and scalable. \"One can&#x27;t succeed without the other,\" Habib said.For CIOs and technical leaders, this represents a fundamental shift from gatekeeper to enabler. When business units deploy agents autonomously, IT faces governance challenges unlike anything in enterprise software history. Success requires genuine partnership between business and IT — neither can succeed alone, forcing cultural changes in how these functions collaborate.A real example: From multi-day scrambles to instant answers during a market crisisTo ground her arguments in concrete business impact, Habib described working with the chief client officer of a Fortune 500 wealth advisory firm during recent market volatility following tariff announcements.\"Their phone was ringing off the hook with customers trying to figure out their market exposure,\" she recounted. \"Every request kicked off a multi-day, multi-person scramble: a portfolio manager ran the show, an analyst pulled charts, a relationship manager built the PowerPoint, a compliance officer had to review everything for disclosures. And the leader in all this — she was forwarding emails and chasing updates. This is the top job: managing complexity.\"With an agentic AI system, the same work happens programmatically. \"A system of agents is able to assemble the answer faster than any number of people could have. No more midnight deck reviews. No more days on end\" of coordination, Habib said.This isn&#x27;t about marginal productivity gains — it&#x27;s about fundamentally different operating models where senior executives shift from managing coordination to designing intelligent systems.Why so many AI initiatives are failing despite massive investmentHabib&#x27;s arguments arrive as many enterprises face AI disillusionment. After initial excitement about generative AI, many companies have struggled to move beyond pilots and demonstrations to production deployments generating tangible business value.Her diagnosis — that leaders are delegating rather than driving transformation — aligns with growing evidence that organizational factors, not technical limitations, explain most failures. Companies often lack clarity on use cases, struggle with data preparation, or face internal resistance to workflow changes that AI requires.Perhaps the most striking aspect of Habib&#x27;s presentation was her willingness to acknowledge the human cost of AI transformation — and insist leaders address it rather than avoid it. \"Your job as a leader is to not look away from this fear. Your job is to face it with a plan,\" she told the audience.She described \"productivity anchoring\" as a form of \"self-sabotage\" where employees resist AI adoption because their identity and self-worth are tied to execution tasks AI can now perform. The phenomenon suggests that successful AI transformation requires not just technical and strategic changes but psychological and cultural work that many leaders may be unprepared for.Two challenges: Get your hands dirty, then reimagine everythingHabib closed by throwing down two gauntlets to her executive audience.\"First, a small one: get your hands dirty with agentic AI. Don&#x27;t delegate. Choose a process that you oversee and automate it. See the difference from managing a complex process to redesigning it for yourself.\"The second was more ambitious: \"Go back to your team and ask, what could we achieve if execution were free? What would work feel like, be like, look like if you&#x27;re unbound from the friction and process that slows us down today?\"She concluded: \"The tools for creation are in your hands. The mandate for leadership is on your shoulders. What will you build?\"For enterprise leaders accustomed to viewing AI as an IT initiative, Habib&#x27;s message is clear: that approach isn&#x27;t working, won&#x27;t work, and reflects a fundamental misunderstanding of what AI represents. Whether executives embrace her call to personally drive transformation — or continue delegating to IT departments — may determine which organizations thrive and which become cautionary tales.The statistic she opened with lingers uncomfortably: 42% of Fortune 500 C-suite executives say AI is tearing their companies apart. Habib&#x27;s diagnosis suggests they&#x27;re tearing themselves apart by clinging to organizational models designed for an era when execution was scarce. The cure she prescribes requires leaders to do something most find uncomfortable: stop managing complexity and start dismantling it.",
          "content": "May Habib, co-founder and CEO of Writer AI, delivered one of the bluntest assessments of corporate AI failures at the TED AI conference on Tuesday, revealing that nearly half of Fortune 500 executives believe artificial intelligence is actively damaging their organizations — and placing the blame squarely on leadership&#x27;s shoulders.The problem, according to Habib, isn&#x27;t the technology. It&#x27;s that business leaders are making a category error, treating AI transformation like previous technology rollouts and delegating it to IT departments. This approach, she warned, has led to \"billions of dollars spent on AI initiatives that are going nowhere.\"\"Earlier this year, we did a survey of 800 Fortune 500 C-suite executives,\" Habib told the audience of Silicon Valley executives and investors. \"42% of them said AI is tearing their company apart.\"The diagnosis challenges conventional wisdom about how enterprises should approach AI adoption. While most major companies have stood up AI task forces, appointed chief AI officers, or expanded IT budgets, Habib argues these moves reflect a fundamental misunderstanding of what AI represents: not another software tool, but a wholesale reorganization of how work gets done.\"There is something leaders are missing when they compare AI to just another tech tool,\" Habib said. \"This is not like giving accountants calculators or bankers Excel or designers Photoshop.\"Why the &#x27;old playbook&#x27; of delegating to IT departments is failing companiesHabib, whose company has spent five years building AI systems for Fortune 500 companies and logged two million miles visiting customer sites, said the pattern is consistent: \"When generative AI started showing up, we turned to the old playbook. We turned to IT and said, &#x27;Go figure this out.&#x27;\"That approach fails, she argued, because AI fundamentally changes the economics and organization of work itself. \"For 100 years, enterprises have been built around the idea that execution is expensive and hard,\" Habib said. \"The enterprise built complex org charts, complex processes, all to manage people doing stuff.\"AI inverts that model. \"Execution is going from scarce and expensive to programmatic, on-demand and abundant,\" she said. In this new paradigm, the bottleneck shifts from execution capacity to strategic design — a shift that requires business leaders, not IT departments, to drive transformation.\"With AI technology, it can no longer be centralized. It&#x27;s in every workflow, every business,\" Habib said. \"It is now the most important part of a business leader&#x27;s job. It cannot be delegated.\"The statement represents a direct challenge to how most large organizations have structured their AI initiatives, with centralized centers of excellence, dedicated AI teams, or IT-led implementations that business units are expected to adopt.A generational power shift is happening based on who understands AI workflow designHabib framed the shift in dramatic terms: \"A generational transfer of power is happening right now. It&#x27;s not about your age or how long you&#x27;ve been at a company. The generational transfer of power is about the nature of leadership itself.\"Traditional leadership, she argued, has been defined by the ability to manage complexity — big teams, big budgets, intricate processes. \"The identity of leaders at these companies, people like us, has been tied to old school power structures: control, hierarchy, how big our teams are, how big our budgets are. Our value is measured by the sheer amount of complexity we could manage,\" Habib said. \"Today we reward leaders for this. We promote leaders for this.\"AI makes that model obsolete. \"When I am able to 10x the output of my team or do things that could never be possible, work is no longer about the 1x,\" she said. \"Leadership is no longer about managing complex human execution.\"Instead, Habib outlined three fundamental shifts that define what she calls \"AI-first leaders\" — executives her company has worked with who have successfully deployed AI agents solving \"$100 million plus problems.\"The first shift: Taking a machete to enterprise complexityThe new leadership mandate, according to Habib, is \"taking a machete to the complexity that has calcified so many organizations.\" She pointed to the layers of friction that have accumulated in enterprises: \"Brilliant ideas dying in memos, the endless cycles of approvals, the death by 1,000 clicks, meetings about meetings — a death, by the way, that&#x27;s happening in 17 different browser tabs each for software that promises to be a single source of truth.\"Rather than accepting this complexity as inevitable, AI-first leaders redesign workflows from first principles. \"There are very few legacy systems that can&#x27;t be replaced in your organization, that won&#x27;t be replaced,\" Habib said. \"But they&#x27;re not going to be replaced by another monolithic piece of software. They can only be replaced by a business leader articulating business logic and getting that into an agentic system.\"She offered a concrete example: \"We have customers where it used to take them seven months to get a creative campaign — not even a product, a campaign. Now they can go from TikTok trend to digital shelf in 30 days. That is radical simplicity.\"The catch, she emphasized, is that CIOs can&#x27;t drive this transformation alone. \"Your CIO can&#x27;t help flatten your org chart. Only a business leader can look at workflows and say, &#x27;This part is necessary genius, this part is bureaucratic scar tissue that has to go.&#x27;\"The second shift: Managing the fear as career ladders disappearWhen AI handles execution, \"your humans are liberated to do what they&#x27;re amazing at: judgment, strategy, creativity,\" Habib explained. \"The old leadership playbook was about managing headcount. We managed people against revenue: one business development rep for every three account executives, one marketer for every five salespeople.\"But this liberation carries profound challenges that leaders must address directly. Habib acknowledged the elephant in the room that many executives avoid discussing: \"These changes are still frightening for people, even when it&#x27;s become unholy to talk about it.\" She&#x27;s witnessed the fear firsthand. \"It shows up as tears in an AI workshop when someone feels like their old skill set isn&#x27;t translated to the new.\"She introduced a term for a common form of resistance: \"productivity anchoring\" — when employees \"cling to the hard way of doing things because they feel productive, because their self-worth is tied to them, even when empirically AI can be better.\"The solution isn&#x27;t to look away. \"We have to design new pathways to impact, to show your people their value is not in executing a task. Their value is in orchestrating systems of execution, to ask the next great question,\" Habib said. She advocates replacing career \"ladders\" with \"lattices\" where \"people need to grow laterally, to expand sideways.\"She was candid about the disruption: \"The first rungs on our career ladders are indeed going away. I know because my company is automating them.\" But she insisted this creates opportunity for work that is \"more creative, more strategic, more driven by curiosity and impact — and I believe a lot more human than the jobs that they&#x27;re replacing.\"The third shift: When execution becomes free, ambition becomes the only bottleneckThe final shift is from optimization to creation. \"Before AI, we used to call it transformation when we took 12 steps and made them nine,\" Habib said. \"That&#x27;s optimizing the world as it is. We can now create a new world. That is the greenfield mindset.\"She challenged executives to identify assumptions their industries are built on that AI now disrupts. Writer&#x27;s customers, she said, are already seeing new categories of growth: treating every customer like their only customer, democratizing premium services to broader markets, and entering new markets at unprecedented speed because \"AI strips away the friction to access new channels.\"\"When execution is abundant, the only bottleneck is the scope of your own ambition,\" Habib declared.What this means for CIOs: Building the stadium while business leaders design the playsHabib didn&#x27;t leave IT leaders without a role — she redefined it. \"If tech is everyone&#x27;s job, you might be asking, what is mine?\" she addressed CIOs. \"Yours is to provide the mission critical infrastructure that makes this revolution possible.\"As tens or hundreds of thousands of AI agents operate at various levels of autonomy within organizations, \"governance becomes existential,\" she explained. \"The business leader&#x27;s job is to design the play, but you have to build the stadium, you have to write the rule book, and you have to make sure these plays can win at championship scale.\"The formulation suggests a partnership model: business leaders drive workflow redesign and strategic implementation while IT provides the infrastructure, governance frameworks, and security guardrails that make mass AI deployment safe and scalable. \"One can&#x27;t succeed without the other,\" Habib said.For CIOs and technical leaders, this represents a fundamental shift from gatekeeper to enabler. When business units deploy agents autonomously, IT faces governance challenges unlike anything in enterprise software history. Success requires genuine partnership between business and IT — neither can succeed alone, forcing cultural changes in how these functions collaborate.A real example: From multi-day scrambles to instant answers during a market crisisTo ground her arguments in concrete business impact, Habib described working with the chief client officer of a Fortune 500 wealth advisory firm during recent market volatility following tariff announcements.\"Their phone was ringing off the hook with customers trying to figure out their market exposure,\" she recounted. \"Every request kicked off a multi-day, multi-person scramble: a portfolio manager ran the show, an analyst pulled charts, a relationship manager built the PowerPoint, a compliance officer had to review everything for disclosures. And the leader in all this — she was forwarding emails and chasing updates. This is the top job: managing complexity.\"With an agentic AI system, the same work happens programmatically. \"A system of agents is able to assemble the answer faster than any number of people could have. No more midnight deck reviews. No more days on end\" of coordination, Habib said.This isn&#x27;t about marginal productivity gains — it&#x27;s about fundamentally different operating models where senior executives shift from managing coordination to designing intelligent systems.Why so many AI initiatives are failing despite massive investmentHabib&#x27;s arguments arrive as many enterprises face AI disillusionment. After initial excitement about generative AI, many companies have struggled to move beyond pilots and demonstrations to production deployments generating tangible business value.Her diagnosis — that leaders are delegating rather than driving transformation — aligns with growing evidence that organizational factors, not technical limitations, explain most failures. Companies often lack clarity on use cases, struggle with data preparation, or face internal resistance to workflow changes that AI requires.Perhaps the most striking aspect of Habib&#x27;s presentation was her willingness to acknowledge the human cost of AI transformation — and insist leaders address it rather than avoid it. \"Your job as a leader is to not look away from this fear. Your job is to face it with a plan,\" she told the audience.She described \"productivity anchoring\" as a form of \"self-sabotage\" where employees resist AI adoption because their identity and self-worth are tied to execution tasks AI can now perform. The phenomenon suggests that successful AI transformation requires not just technical and strategic changes but psychological and cultural work that many leaders may be unprepared for.Two challenges: Get your hands dirty, then reimagine everythingHabib closed by throwing down two gauntlets to her executive audience.\"First, a small one: get your hands dirty with agentic AI. Don&#x27;t delegate. Choose a process that you oversee and automate it. See the difference from managing a complex process to redesigning it for yourself.\"The second was more ambitious: \"Go back to your team and ask, what could we achieve if execution were free? What would work feel like, be like, look like if you&#x27;re unbound from the friction and process that slows us down today?\"She concluded: \"The tools for creation are in your hands. The mandate for leadership is on your shoulders. What will you build?\"For enterprise leaders accustomed to viewing AI as an IT initiative, Habib&#x27;s message is clear: that approach isn&#x27;t working, won&#x27;t work, and reflects a fundamental misunderstanding of what AI represents. Whether executives embrace her call to personally drive transformation — or continue delegating to IT departments — may determine which organizations thrive and which become cautionary tales.The statistic she opened with lingers uncomfortably: 42% of Fortune 500 C-suite executives say AI is tearing their companies apart. Habib&#x27;s diagnosis suggests they&#x27;re tearing themselves apart by clinging to organizational models designed for an era when execution was scarce. The cure she prescribes requires leaders to do something most find uncomfortable: stop managing complexity and start dismantling it.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4aHBNxyB2pkPhCFjBLoMOH/b09ae06e86fe5534666c4574c5de2bdb/nuneybits_Vector_art_of_company_fracturing_apart_433a69a5-4c41-4199-bf6a-51d8cd076379.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data-infrastructure/research-finds-that-77-of-data-engineers-have-heavier-workloads-despite-ai",
          "published_at": "Thu, 23 Oct 2025 13:00:00 GMT",
          "title": "Research finds that 77% of data engineers have heavier workloads despite AI tools: Here's why and what to do about it",
          "standfirst": "Data engineers should be working faster than ever. AI-powered tools promise to automate pipeline optimization, accelerate data integration and handle the repetitive grunt work that has defined the profession for decades.Yet, according to a new survey of 400 senior technology executives by MIT Technology Review Insights in partnership with Snowflake, 77% say their data engineering teams&#x27; workloads are getting heavier, not lighter.The culprit? The very AI tools meant to help are creating a new set of problems.While 83% of organizations have already deployed AI-based data engineering tools, 45% cite integration complexity as a top challenge. Another 38% are struggling with tool sprawl and fragmentation.\"Many data engineers are using one tool to collect data, one tool to process data and another to run analytics on that data,\" Chris Child, VP of product for data engineering at Snowflake, told VentureBeat. \"Using several tools along this data lifecycle introduces complexity, risk and increased infrastructure management, which data engineers can&#x27;t afford to take on.\"The result is a productivity paradox. AI tools are making individual tasks faster, but the proliferation of disconnected tools is making the overall system more complex to manage. For enterprises racing to deploy AI at scale, this fragmentation represents a critical bottleneck.From SQL queries to LLM pipelines: The daily workflow shiftThe survey found that data engineers spent an average of 19% of their time on AI projects two years ago. Today, that figure has jumped to 37%. Respondents expect it to hit 61% within two years.But what does that shift actually look like in practice?Child offered a concrete example. Previously, if the CFO of a company needed to make forecast predictions, they would tap the data engineering team to help build a system that correlates unstructured data like vendor contracts with structured data like revenue numbers into a static dashboard. Connecting these two worlds of different data types was extremely time-consuming and expensive, requiring lawyers to manually read through each document for key contract terms and upload that information into a database.Today, that same workflow looks radically different.\"Data engineers can use a tool like Snowflake Openflow to seamlessly bring the unstructured PDF contracts living in a source like Box, together with the structured financial figures into a single platform like Snowflake, making the data accessible to LLMs,\" Child said. \"What used to take hours of manual work is now near instantaneous.\"The shift isn&#x27;t just about speed. It&#x27;s about the nature of the work itself.Two years ago, a typical data engineer&#x27;s day consisted of tuning clusters, writing SQL transformations and ensuring data readiness for human analysts. Today, that same engineer is more likely to be debugging LLM-powered transformation pipelines and setting up governance rules for AI model workflows.\"Data engineers&#x27; core skill isn&#x27;t just coding,\" Child said. \"It&#x27;s orchestrating the data foundation and ensuring trust, context and governance so AI outputs are reliable.\"The tool stack problem: When help becomes hindranceHere&#x27;s where enterprises are getting stuck.The promise of AI-powered data tools is compelling: automate pipeline optimization, accelerate debugging, streamline integration. But in practice, many organizations are discovering that each new AI tool they add creates its own integration headaches.The survey data bears this out. While AI has led to improvements in output quantity (74% report increases) and quality (77% report improvements), those gains are being offset by the operational overhead of managing disconnected tools.\"The other problem we&#x27;re seeing is that AI tools often make it easy to build a prototype by stitching together several data sources with an out-of-the-box LLM,\" Child said. \"But then when you want to take that into production, you realize that you don&#x27;t have the data accessible and you don&#x27;t know what governance you need, so it becomes difficult to roll the tool out to your users.\"For technical decision-makers evaluating their data engineering stack right now, Child offered a clear framework. \"Teams should prioritize AI tools that accelerate productivity, while at the same time eliminate infrastructure and operational complexity,\" he said. \"This allows engineers to move their focus away from managing the &#x27;glue work&#x27; of data engineering and closer to business outcomes.\"The agentic AI deployment window: 12 months to get it rightThe survey revealed that 54% of organizations plan to deploy agentic AI within the next 12 months. Agentic AI refers to autonomous agents that can make decisions and take actions without human intervention. Another 20% have already begun doing so.For data engineering teams, agentic AI represents both an enormous opportunity and a significant risk. Done right, autonomous agents can handle repetitive tasks like detecting schema drift or debugging transformation errors. Done wrong, they can corrupt datasets or expose sensitive information.\"Data engineers must prioritize pipeline optimization and monitoring in order to truly deploy agentic AI at scale,\" Child said. \"It&#x27;s a low-risk, high-return starting point that allows agentic AI to safely automate repetitive tasks like detecting schema drift or debugging transformation errors when done correctly.\"But Child was emphatic about the guardrails that must be in place first.\"Before organizations let agents near production data, two safeguards must be in place: strong governance and lineage tracking, and active human oversight,\" he said. \"Agents must inherit fine-grained permissions and operate within an established governance framework.\"The risks of skipping those steps are real. \"Without proper lineage or access governance, an agent could unintentionally corrupt datasets or expose sensitive information,\" Child warned.The perception gap that&#x27;s costing enterprises AI successPerhaps the most striking finding in the survey is a disconnect at the C-suite level.While 80% of chief data officers and 82% of chief AI officers consider data engineers integral to business success, only 55% of CIOs share that view.\"This shows that the data-forward leaders are seeing data engineering&#x27;s strategic value, but we need to do more work to help the rest of the C-suite recognize that investing in a unified, scalable data foundation and the people helping drive this is an investment in AI success, not just IT operations,\" Child said.That perception gap has real consequences.Data engineers in the surveyed organizations are already influential in decisions about AI use-case feasibility (53% of respondents) and business units&#x27; use of AI models (56%). But if CIOs don&#x27;t recognize data engineers as strategic partners, they&#x27;re unlikely to give those teams the resources, authority or seat at the table they need to prevent the kinds of tool sprawl and integration problems the survey identified.The gap appears to correlate with visibility. Chief data officers and chief AI officers work directly with data engineering teams daily and understand the complexity of what they&#x27;re managing. CIOs, focused more broadly on infrastructure and operations, may not see the strategic architecture work that data engineers are increasingly doing.This disconnect also shows up in how different executives rate the challenges facing data engineering teams. Chief AI officers are significantly more likely than CIOs to agree that data engineers&#x27; workloads are becoming increasingly heavy (93% vs. 75%). They&#x27;re also more likely to recognize data engineers&#x27; influence on overall AI strategy.What data engineers need to learn nowThe survey identified three critical skills data engineers need to develop: AI expertise, business acumen and communication abilities.For an enterprise with a 20-person data engineering team, that presents a practical challenge. Do you hire for these skills, train existing engineers or restructure the team? Child&#x27;s answer suggested the priority should be business understanding.\"The most important skill right now is for data engineers to understand what is critical to their end business users and prioritize how they can make those questions easier and faster to answer,\" he said.The lesson for enterprises: Business context matters more than adding technical certifications. Child stressed that understanding the business impact of &#x27;why&#x27; data engineers are performing certain tasks will allow them to anticipate the needs of customers better, delivering value more immediately to the business. \"The organizations with data engineering teams that prioritize this business understanding will set themselves apart from competition.\"For enterprises looking to lead in AI, the solution to the data engineering productivity crisis isn&#x27;t more AI tools. The organizations that will move fastest are consolidating their tool stacks now, deploying governance infrastructure before agents go into production and elevating data engineers from support staff to strategic architects. The window is narrow. With 54% planning agentic AI deployment within 12 months and data engineers expected to spend 61% of their time on AI projects within two years, teams that haven&#x27;t addressed tool sprawl and governance gaps will find their AI initiatives stuck in permanent pilot mode.",
          "content": "Data engineers should be working faster than ever. AI-powered tools promise to automate pipeline optimization, accelerate data integration and handle the repetitive grunt work that has defined the profession for decades.Yet, according to a new survey of 400 senior technology executives by MIT Technology Review Insights in partnership with Snowflake, 77% say their data engineering teams&#x27; workloads are getting heavier, not lighter.The culprit? The very AI tools meant to help are creating a new set of problems.While 83% of organizations have already deployed AI-based data engineering tools, 45% cite integration complexity as a top challenge. Another 38% are struggling with tool sprawl and fragmentation.\"Many data engineers are using one tool to collect data, one tool to process data and another to run analytics on that data,\" Chris Child, VP of product for data engineering at Snowflake, told VentureBeat. \"Using several tools along this data lifecycle introduces complexity, risk and increased infrastructure management, which data engineers can&#x27;t afford to take on.\"The result is a productivity paradox. AI tools are making individual tasks faster, but the proliferation of disconnected tools is making the overall system more complex to manage. For enterprises racing to deploy AI at scale, this fragmentation represents a critical bottleneck.From SQL queries to LLM pipelines: The daily workflow shiftThe survey found that data engineers spent an average of 19% of their time on AI projects two years ago. Today, that figure has jumped to 37%. Respondents expect it to hit 61% within two years.But what does that shift actually look like in practice?Child offered a concrete example. Previously, if the CFO of a company needed to make forecast predictions, they would tap the data engineering team to help build a system that correlates unstructured data like vendor contracts with structured data like revenue numbers into a static dashboard. Connecting these two worlds of different data types was extremely time-consuming and expensive, requiring lawyers to manually read through each document for key contract terms and upload that information into a database.Today, that same workflow looks radically different.\"Data engineers can use a tool like Snowflake Openflow to seamlessly bring the unstructured PDF contracts living in a source like Box, together with the structured financial figures into a single platform like Snowflake, making the data accessible to LLMs,\" Child said. \"What used to take hours of manual work is now near instantaneous.\"The shift isn&#x27;t just about speed. It&#x27;s about the nature of the work itself.Two years ago, a typical data engineer&#x27;s day consisted of tuning clusters, writing SQL transformations and ensuring data readiness for human analysts. Today, that same engineer is more likely to be debugging LLM-powered transformation pipelines and setting up governance rules for AI model workflows.\"Data engineers&#x27; core skill isn&#x27;t just coding,\" Child said. \"It&#x27;s orchestrating the data foundation and ensuring trust, context and governance so AI outputs are reliable.\"The tool stack problem: When help becomes hindranceHere&#x27;s where enterprises are getting stuck.The promise of AI-powered data tools is compelling: automate pipeline optimization, accelerate debugging, streamline integration. But in practice, many organizations are discovering that each new AI tool they add creates its own integration headaches.The survey data bears this out. While AI has led to improvements in output quantity (74% report increases) and quality (77% report improvements), those gains are being offset by the operational overhead of managing disconnected tools.\"The other problem we&#x27;re seeing is that AI tools often make it easy to build a prototype by stitching together several data sources with an out-of-the-box LLM,\" Child said. \"But then when you want to take that into production, you realize that you don&#x27;t have the data accessible and you don&#x27;t know what governance you need, so it becomes difficult to roll the tool out to your users.\"For technical decision-makers evaluating their data engineering stack right now, Child offered a clear framework. \"Teams should prioritize AI tools that accelerate productivity, while at the same time eliminate infrastructure and operational complexity,\" he said. \"This allows engineers to move their focus away from managing the &#x27;glue work&#x27; of data engineering and closer to business outcomes.\"The agentic AI deployment window: 12 months to get it rightThe survey revealed that 54% of organizations plan to deploy agentic AI within the next 12 months. Agentic AI refers to autonomous agents that can make decisions and take actions without human intervention. Another 20% have already begun doing so.For data engineering teams, agentic AI represents both an enormous opportunity and a significant risk. Done right, autonomous agents can handle repetitive tasks like detecting schema drift or debugging transformation errors. Done wrong, they can corrupt datasets or expose sensitive information.\"Data engineers must prioritize pipeline optimization and monitoring in order to truly deploy agentic AI at scale,\" Child said. \"It&#x27;s a low-risk, high-return starting point that allows agentic AI to safely automate repetitive tasks like detecting schema drift or debugging transformation errors when done correctly.\"But Child was emphatic about the guardrails that must be in place first.\"Before organizations let agents near production data, two safeguards must be in place: strong governance and lineage tracking, and active human oversight,\" he said. \"Agents must inherit fine-grained permissions and operate within an established governance framework.\"The risks of skipping those steps are real. \"Without proper lineage or access governance, an agent could unintentionally corrupt datasets or expose sensitive information,\" Child warned.The perception gap that&#x27;s costing enterprises AI successPerhaps the most striking finding in the survey is a disconnect at the C-suite level.While 80% of chief data officers and 82% of chief AI officers consider data engineers integral to business success, only 55% of CIOs share that view.\"This shows that the data-forward leaders are seeing data engineering&#x27;s strategic value, but we need to do more work to help the rest of the C-suite recognize that investing in a unified, scalable data foundation and the people helping drive this is an investment in AI success, not just IT operations,\" Child said.That perception gap has real consequences.Data engineers in the surveyed organizations are already influential in decisions about AI use-case feasibility (53% of respondents) and business units&#x27; use of AI models (56%). But if CIOs don&#x27;t recognize data engineers as strategic partners, they&#x27;re unlikely to give those teams the resources, authority or seat at the table they need to prevent the kinds of tool sprawl and integration problems the survey identified.The gap appears to correlate with visibility. Chief data officers and chief AI officers work directly with data engineering teams daily and understand the complexity of what they&#x27;re managing. CIOs, focused more broadly on infrastructure and operations, may not see the strategic architecture work that data engineers are increasingly doing.This disconnect also shows up in how different executives rate the challenges facing data engineering teams. Chief AI officers are significantly more likely than CIOs to agree that data engineers&#x27; workloads are becoming increasingly heavy (93% vs. 75%). They&#x27;re also more likely to recognize data engineers&#x27; influence on overall AI strategy.What data engineers need to learn nowThe survey identified three critical skills data engineers need to develop: AI expertise, business acumen and communication abilities.For an enterprise with a 20-person data engineering team, that presents a practical challenge. Do you hire for these skills, train existing engineers or restructure the team? Child&#x27;s answer suggested the priority should be business understanding.\"The most important skill right now is for data engineers to understand what is critical to their end business users and prioritize how they can make those questions easier and faster to answer,\" he said.The lesson for enterprises: Business context matters more than adding technical certifications. Child stressed that understanding the business impact of &#x27;why&#x27; data engineers are performing certain tasks will allow them to anticipate the needs of customers better, delivering value more immediately to the business. \"The organizations with data engineering teams that prioritize this business understanding will set themselves apart from competition.\"For enterprises looking to lead in AI, the solution to the data engineering productivity crisis isn&#x27;t more AI tools. The organizations that will move fastest are consolidating their tool stacks now, deploying governance infrastructure before agents go into production and elevating data engineers from support staff to strategic architects. The window is narrow. With 54% planning agentic AI deployment within 12 months and data engineers expected to spend 61% of their time on AI projects within two years, teams that haven&#x27;t addressed tool sprawl and governance gaps will find their AI initiatives stuck in permanent pilot mode.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6c6tA8fZ29MNNDGLsHQgK9/78cecaac03eddd1b3bd5489771bd2e57/modern-data-engineer-smk.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/sakana-ais-cto-says-hes-absolutely-sick-of-transformers-the-tech-that-powers",
          "published_at": "Thu, 23 Oct 2025 13:00:00 GMT",
          "title": "Sakana AI's CTO says he's 'absolutely sick' of transformers, the tech that powers every major AI model",
          "standfirst": "In a striking act of self-critique, one of the architects of the transformer technology that powers ChatGPT, Claude, and virtually every major AI system told an audience of industry leaders this week that artificial intelligence research has become dangerously narrow — and that he&#x27;s moving on from his own creation.Llion Jones, who co-authored the seminal 2017 paper \"Attention Is All You Need\" and even coined the name \"transformer,\" delivered an unusually candid assessment at the TED AI conference in San Francisco on Tuesday: Despite unprecedented investment and talent flooding into AI, the field has calcified around a single architectural approach, potentially blinding researchers to the next major breakthrough.\"Despite the fact that there&#x27;s never been so much interest and resources and money and talent, this has somehow caused the narrowing of the research that we&#x27;re doing,\" Jones told the audience. The culprit, he argued, is the \"immense amount of pressure\" from investors demanding returns and researchers scrambling to stand out in an overcrowded field.The warning carries particular weight given Jones&#x27;s role in AI history. The transformer architecture he helped develop at Google has become the foundation of the generative AI boom, enabling systems that can write essays, generate images, and engage in human-like conversation. His paper has been cited more than 100,000 times, making it one of the most influential computer science publications of the century.Now, as CTO and co-founder of Tokyo-based Sakana AI, Jones is explicitly abandoning his own creation. \"I personally made a decision in the beginning of this year that I&#x27;m going to drastically reduce the amount of time that I spend on transformers,\" he said. \"I&#x27;m explicitly now exploring and looking for the next big thing.\"Why more AI funding has led to less creative research, according to a transformer pioneerJones painted a picture of an AI research community suffering from what he called a paradox: More resources have led to less creativity. He described researchers constantly checking whether they&#x27;ve been \"scooped\" by competitors working on identical ideas, and academics choosing safe, publishable projects over risky, potentially transformative ones.\"If you&#x27;re doing standard AI research right now, you kind of have to assume that there&#x27;s maybe three or four other groups doing something very similar, or maybe exactly the same,\" Jones said, describing an environment where \"unfortunately, this pressure damages the science, because people are rushing their papers, and it&#x27;s reducing the amount of creativity.\"He drew an analogy from AI itself — the \"exploration versus exploitation\" trade-off that governs how algorithms search for solutions. When a system exploits too much and explores too little, it finds mediocre local solutions while missing superior alternatives. \"We are almost certainly in that situation right now in the AI industry,\" Jones argued.The implications are sobering. Jones recalled the period just before transformers emerged, when researchers were endlessly tweaking recurrent neural networks — the previous dominant architecture — for incremental gains. Once transformers arrived, all that work suddenly seemed irrelevant. \"How much time do you think those researchers would have spent trying to improve the recurrent neural network if they knew something like transformers was around the corner?\" he asked.He worries the field is repeating that pattern. \"I&#x27;m worried that we&#x27;re in that situation right now where we&#x27;re just concentrating on one architecture and just permuting it and trying different things, where there might be a breakthrough just around the corner.\"How the &#x27;Attention is all you need&#x27; paper was born from freedom, not pressureTo underscore his point, Jones described the conditions that allowed transformers to emerge in the first place — a stark contrast to today&#x27;s environment. The project, he said, was \"very organic, bottom up,\" born from \"talking over lunch or scrawling randomly on the whiteboard in the office.\"Critically, \"we didn&#x27;t actually have a good idea, we had the freedom to actually spend time and go and work on it, and even more importantly, we didn&#x27;t have any pressure that was coming down from management,\" Jones recounted. \"No pressure to work on any particular project, publish a number of papers to push a certain metric up.\"That freedom, Jones suggested, is largely absent today. Even researchers recruited for astronomical salaries — \"literally a million dollars a year, in some cases\" — may not feel empowered to take risks. \"Do you think that when they start their new position they feel empowered to try their wild ideas and more speculative ideas, or do they feel immense pressure to prove their worth and once again, go for the low hanging fruit?\" he asked.Why one AI lab is betting that research freedom beats million-dollar salariesJones&#x27;s proposed solution is deliberately provocative: Turn up the \"explore dial\" and openly share findings, even at competitive cost. He acknowledged the irony of his position. \"It may sound a little controversial to hear one of the Transformers authors stand on stage and tell you that he&#x27;s absolutely sick of them, but it&#x27;s kind of fair enough, right? I&#x27;ve been working on them longer than anyone, with the possible exception of seven people.\"At Sakana AI, Jones said he&#x27;s attempting to recreate that pre-transformer environment, with nature-inspired research and minimal pressure to chase publications or compete directly with rivals. He offered researchers a mantra from engineer Brian Cheung: \"You should only do the research that wouldn&#x27;t happen if you weren&#x27;t doing it.\"One example is Sakana&#x27;s \"continuous thought machine,\" which incorporates brain-like synchronization into neural networks. An employee who pitched the idea told Jones he would have faced skepticism and pressure not to waste time at previous employers or academic positions. At Sakana, Jones gave him a week to explore. The project became successful enough to be spotlighted at NeurIPS, a major AI conference.Jones even suggested that freedom beats compensation in recruiting. \"It&#x27;s a really, really good way of getting talent,\" he said of the exploratory environment. \"Think about it, talented, intelligent people, ambitious people, will naturally seek out this kind of environment.\"The transformer&#x27;s success may be blocking AI&#x27;s next breakthroughPerhaps most provocatively, Jones suggested transformers may be victims of their own success. \"The fact that the current technology is so powerful and flexible... stopped us from looking for better,\" he said. \"It makes sense that if the current technology was worse, more people would be looking for better.\"He was careful to clarify that he&#x27;s not dismissing ongoing transformer research. \"There&#x27;s still plenty of very important work to be done on current technology and bringing a lot of value in the coming years,\" he said. \"I&#x27;m just saying that given the amount of talent and resources that we have currently, we can afford to do a lot more.\"His ultimate message was one of collaboration over competition. \"Genuinely, from my perspective, this is not a competition,\" Jones concluded. \"We all have the same goal. We all want to see this technology progress so that we can all benefit from it. So if we can all collectively turn up the explore dial and then openly share what we find, we can get to our goal much faster.\"The high stakes of AI&#x27;s exploration problemThe remarks arrive at a pivotal moment for artificial intelligence. The industry grapples with mounting evidence that simply building larger transformer models may be approaching diminishing returns. Leading researchers have begun openly discussing whether the current paradigm has fundamental limitations, with some suggesting that architectural innovations — not just scale — will be needed for continued progress toward more capable AI systems.Jones&#x27;s warning suggests that finding those innovations may require dismantling the very incentive structures that have driven AI&#x27;s recent boom. With tens of billions of dollars flowing into AI development annually and fierce competition among labs driving secrecy and rapid publication cycles, the exploratory research environment he described seems increasingly distant.Yet his insider perspective carries unusual weight. As someone who helped create the technology now dominating the field, Jones understands both what it takes to achieve breakthrough innovation and what the industry risks by abandoning that approach. His decision to walk away from transformers — the architecture that made his reputation — adds credibility to a message that might otherwise sound like contrarian positioning.Whether AI&#x27;s power players will heed the call remains uncertain. But Jones offered a pointed reminder of what&#x27;s at stake: The next transformer-scale breakthrough could be just around the corner, pursued by researchers with the freedom to explore. Or it could be languishing unexplored while thousands of researchers race to publish incremental improvements on architecture that, in Jones&#x27;s words, one of its creators is \"absolutely sick of.\"After all, he&#x27;s been working on transformers longer than almost anyone. He would know when it&#x27;s time to move on.",
          "content": "In a striking act of self-critique, one of the architects of the transformer technology that powers ChatGPT, Claude, and virtually every major AI system told an audience of industry leaders this week that artificial intelligence research has become dangerously narrow — and that he&#x27;s moving on from his own creation.Llion Jones, who co-authored the seminal 2017 paper \"Attention Is All You Need\" and even coined the name \"transformer,\" delivered an unusually candid assessment at the TED AI conference in San Francisco on Tuesday: Despite unprecedented investment and talent flooding into AI, the field has calcified around a single architectural approach, potentially blinding researchers to the next major breakthrough.\"Despite the fact that there&#x27;s never been so much interest and resources and money and talent, this has somehow caused the narrowing of the research that we&#x27;re doing,\" Jones told the audience. The culprit, he argued, is the \"immense amount of pressure\" from investors demanding returns and researchers scrambling to stand out in an overcrowded field.The warning carries particular weight given Jones&#x27;s role in AI history. The transformer architecture he helped develop at Google has become the foundation of the generative AI boom, enabling systems that can write essays, generate images, and engage in human-like conversation. His paper has been cited more than 100,000 times, making it one of the most influential computer science publications of the century.Now, as CTO and co-founder of Tokyo-based Sakana AI, Jones is explicitly abandoning his own creation. \"I personally made a decision in the beginning of this year that I&#x27;m going to drastically reduce the amount of time that I spend on transformers,\" he said. \"I&#x27;m explicitly now exploring and looking for the next big thing.\"Why more AI funding has led to less creative research, according to a transformer pioneerJones painted a picture of an AI research community suffering from what he called a paradox: More resources have led to less creativity. He described researchers constantly checking whether they&#x27;ve been \"scooped\" by competitors working on identical ideas, and academics choosing safe, publishable projects over risky, potentially transformative ones.\"If you&#x27;re doing standard AI research right now, you kind of have to assume that there&#x27;s maybe three or four other groups doing something very similar, or maybe exactly the same,\" Jones said, describing an environment where \"unfortunately, this pressure damages the science, because people are rushing their papers, and it&#x27;s reducing the amount of creativity.\"He drew an analogy from AI itself — the \"exploration versus exploitation\" trade-off that governs how algorithms search for solutions. When a system exploits too much and explores too little, it finds mediocre local solutions while missing superior alternatives. \"We are almost certainly in that situation right now in the AI industry,\" Jones argued.The implications are sobering. Jones recalled the period just before transformers emerged, when researchers were endlessly tweaking recurrent neural networks — the previous dominant architecture — for incremental gains. Once transformers arrived, all that work suddenly seemed irrelevant. \"How much time do you think those researchers would have spent trying to improve the recurrent neural network if they knew something like transformers was around the corner?\" he asked.He worries the field is repeating that pattern. \"I&#x27;m worried that we&#x27;re in that situation right now where we&#x27;re just concentrating on one architecture and just permuting it and trying different things, where there might be a breakthrough just around the corner.\"How the &#x27;Attention is all you need&#x27; paper was born from freedom, not pressureTo underscore his point, Jones described the conditions that allowed transformers to emerge in the first place — a stark contrast to today&#x27;s environment. The project, he said, was \"very organic, bottom up,\" born from \"talking over lunch or scrawling randomly on the whiteboard in the office.\"Critically, \"we didn&#x27;t actually have a good idea, we had the freedom to actually spend time and go and work on it, and even more importantly, we didn&#x27;t have any pressure that was coming down from management,\" Jones recounted. \"No pressure to work on any particular project, publish a number of papers to push a certain metric up.\"That freedom, Jones suggested, is largely absent today. Even researchers recruited for astronomical salaries — \"literally a million dollars a year, in some cases\" — may not feel empowered to take risks. \"Do you think that when they start their new position they feel empowered to try their wild ideas and more speculative ideas, or do they feel immense pressure to prove their worth and once again, go for the low hanging fruit?\" he asked.Why one AI lab is betting that research freedom beats million-dollar salariesJones&#x27;s proposed solution is deliberately provocative: Turn up the \"explore dial\" and openly share findings, even at competitive cost. He acknowledged the irony of his position. \"It may sound a little controversial to hear one of the Transformers authors stand on stage and tell you that he&#x27;s absolutely sick of them, but it&#x27;s kind of fair enough, right? I&#x27;ve been working on them longer than anyone, with the possible exception of seven people.\"At Sakana AI, Jones said he&#x27;s attempting to recreate that pre-transformer environment, with nature-inspired research and minimal pressure to chase publications or compete directly with rivals. He offered researchers a mantra from engineer Brian Cheung: \"You should only do the research that wouldn&#x27;t happen if you weren&#x27;t doing it.\"One example is Sakana&#x27;s \"continuous thought machine,\" which incorporates brain-like synchronization into neural networks. An employee who pitched the idea told Jones he would have faced skepticism and pressure not to waste time at previous employers or academic positions. At Sakana, Jones gave him a week to explore. The project became successful enough to be spotlighted at NeurIPS, a major AI conference.Jones even suggested that freedom beats compensation in recruiting. \"It&#x27;s a really, really good way of getting talent,\" he said of the exploratory environment. \"Think about it, talented, intelligent people, ambitious people, will naturally seek out this kind of environment.\"The transformer&#x27;s success may be blocking AI&#x27;s next breakthroughPerhaps most provocatively, Jones suggested transformers may be victims of their own success. \"The fact that the current technology is so powerful and flexible... stopped us from looking for better,\" he said. \"It makes sense that if the current technology was worse, more people would be looking for better.\"He was careful to clarify that he&#x27;s not dismissing ongoing transformer research. \"There&#x27;s still plenty of very important work to be done on current technology and bringing a lot of value in the coming years,\" he said. \"I&#x27;m just saying that given the amount of talent and resources that we have currently, we can afford to do a lot more.\"His ultimate message was one of collaboration over competition. \"Genuinely, from my perspective, this is not a competition,\" Jones concluded. \"We all have the same goal. We all want to see this technology progress so that we can all benefit from it. So if we can all collectively turn up the explore dial and then openly share what we find, we can get to our goal much faster.\"The high stakes of AI&#x27;s exploration problemThe remarks arrive at a pivotal moment for artificial intelligence. The industry grapples with mounting evidence that simply building larger transformer models may be approaching diminishing returns. Leading researchers have begun openly discussing whether the current paradigm has fundamental limitations, with some suggesting that architectural innovations — not just scale — will be needed for continued progress toward more capable AI systems.Jones&#x27;s warning suggests that finding those innovations may require dismantling the very incentive structures that have driven AI&#x27;s recent boom. With tens of billions of dollars flowing into AI development annually and fierce competition among labs driving secrecy and rapid publication cycles, the exploratory research environment he described seems increasingly distant.Yet his insider perspective carries unusual weight. As someone who helped create the technology now dominating the field, Jones understands both what it takes to achieve breakthrough innovation and what the industry risks by abandoning that approach. His decision to walk away from transformers — the architecture that made his reputation — adds credibility to a message that might otherwise sound like contrarian positioning.Whether AI&#x27;s power players will heed the call remains uncertain. But Jones offered a pointed reminder of what&#x27;s at stake: The next transformer-scale breakthrough could be just around the corner, pursued by researchers with the freedom to explore. Or it could be languishing unexplored while thousands of researchers race to publish incremental improvements on architecture that, in Jones&#x27;s words, one of its creators is \"absolutely sick of.\"After all, he&#x27;s been working on transformers longer than almost anyone. He would know when it&#x27;s time to move on.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/WSXBhFReMwh2HPn3P3k9E/f6352f008c9afddcbf6a4ff6148d7c96/nuneybits_Vector_art_of_a_koi_fish_with_scales_formed_from_algo_8e356867-71b0-4e3b-b5b1-87ac3e4c8013.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-streaming-service-deals-133028980.html",
          "published_at": "Thu, 23 Oct 2025 12:01:26 +0000",
          "title": "The best streaming deals: Save on Hulu + Live TV, Audible, Starz and more",
          "standfirst": "If you’ve been shocked by how much you spend on streaming services lately, you’re not alone. Companies like Netflix, Disney, Max and others have been consistently raising prices to the point where you may question if streaming is even worth it anymore. We at Engadget still think it is, but we also think you should be smart with your money — and that’s where streaming deals come in. Yes, it is possible to get discounts on services like Peacock and Paramount+, even if those deals aren’t as common as a sale on AirPods. If you’re looking to save money and still stream all of the content you want, Engadget can help by laying out the best streaming deals you can get right now, how you can save with bundles and everything you should know before paying for yet another streaming service. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Audible subscription (three months) for $3 ($42 off): From now through mid-December, you can get Amazon’s audiobook subscription for just a dollar a month for three months. Note that it will auto-renew at $15 per month after that, but you can cancel at any point. Starz (one year) for $30 ($40 off): Pay upfront for one year and you can get $40 off a Stars annual subscription. There's a month-to-month option too, which costs $5 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. DirecTV starting at $50/month for one month ($35 off): All of DirecTV's signature packages are $35 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Spotify Premium Individual (3 month) for $0 ($36 off): This is our favorite music streaming service for podcasts and social features. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing as of October 21, 2025, accounting for the latest price hike. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$/8month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "content": "If you’ve been shocked by how much you spend on streaming services lately, you’re not alone. Companies like Netflix, Disney, Max and others have been consistently raising prices to the point where you may question if streaming is even worth it anymore. We at Engadget still think it is, but we also think you should be smart with your money — and that’s where streaming deals come in. Yes, it is possible to get discounts on services like Peacock and Paramount+, even if those deals aren’t as common as a sale on AirPods. If you’re looking to save money and still stream all of the content you want, Engadget can help by laying out the best streaming deals you can get right now, how you can save with bundles and everything you should know before paying for yet another streaming service. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Audible subscription (three months) for $3 ($42 off): From now through mid-December, you can get Amazon’s audiobook subscription for just a dollar a month for three months. Note that it will auto-renew at $15 per month after that, but you can cancel at any point. Starz (one year) for $30 ($40 off): Pay upfront for one year and you can get $40 off a Stars annual subscription. There's a month-to-month option too, which costs $5 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. DirecTV starting at $50/month for one month ($35 off): All of DirecTV's signature packages are $35 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Spotify Premium Individual (3 month) for $0 ($36 off): This is our favorite music streaming service for podcasts and social features. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing as of October 21, 2025, accounting for the latest price hike. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$/8month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "feed_position": 26
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/samsungs-galaxy-xr-doesnt-give-me-much-hope-for-android-xr-110000129.html",
          "published_at": "Thu, 23 Oct 2025 11:00:00 +0000",
          "title": "Samsung's Galaxy XR doesn't give me much hope for Android XR",
          "standfirst": "So Samsung made a \"Vision Pro Lite.\" That was my immediate takeaway after this week's debut of the Galaxy XR, the first Android XR device to hit the market. While Samsung deserves credit for offering something close to the Vision Pro for nearly half the price, an $1,800 headset still won't get mainstream consumers rushing out the door to experience the wonders of mixed reality. And with the limited amount of content in Android XR at the moment, the Galaxy XR is in the same position as the Vision Pro: It's just a well-polished developer kit. The only logical reason to buy a Galaxy XR would be to test out apps for Android XR. If you just want to experience VR and dabble in a bit of augmented reality, you're better off spending that money on a gaming laptop and the excellent $500 Meta Quest 3. (The Meta Quest Pro, the company’s first high-end mixed reality device, was unceremoniously killed after launching at an eye-watering $1,500.) But even for developers, the Galaxy XR feels like it's lacking, well, vision. Samsung has done an admirable job of copying almost every aspect of the Vision Pro: The sleek ski goggle design, dual micro-OLED displays and hand gesture interaction powered by a slew of cameras and sensors. But while Apple positioned the Vision Pro as its first stab at spatial computing, an exciting new platform where we can use interactive apps in virtual space, Samsung and Google are basically just gunning to put Android on your face. There aren't many custom-built XR apps, aside from Google's offerings like Maps and Photos. (Something that also reminds me of the dearth of real tablet apps on Android.) And the ability to view 360-degree videos on YouTube has been a staple of every VR headset for the last decade — it's not exactly notable on something that costs $1,800. Samsung and Google also haven't said much about how they plan to elevate XR content. At least Apple is attempting to push the industry forward with its 8K Immersive Videos, which look sharper and more realistic than low-res 360-degree content.For the most part, it seems as if Google is treating Android XR as another way to force its Gemini AI on users. In its press release for the Galaxy XR, Samsung notes that it's \"introducing a new category of AI-native devices designed to deliver immersive experiences in a form factor optimized for multimodal AI.\" …What? In addition to being a crime against the English language, what the company is actually pitching is fairly simple: It's just launching a headset that can access AI features via camera and voice inputs. Who knows, maybe Gemini will make Android XR devices more capable down the line. But at the moment, all I'm seeing in the Galaxy XR is another Samsung device that's shamelessly aping Apple, from the virtual avatars to specific pinch gestures. And Google's history in VR and interactive content doesn't inspire much hope about Android XR. Don't forget how it completely abandoned Google Cardboard, the short-lived Daydream project and its hyped up Stadia cloud service. Stadia's death was particularly galling, since Google initially pitched it as a way to revolutionize the very world of gaming, only to let it fall on its face.There’s no doubt that Samsung, Apple and Meta have a ton of work left ahead in the world of XR. Samsung is at least closer to delivering something under $1,000, and Meta also recently launched the $800 Ray-Ban Display. But price is only one part of the problem. Purpose is another issue entirely. After living with the Vision Pro since its debut, I can tell that Apple is at least thinking a bit more deeply about what it’s like to wear a computer on your face. Just look at the upgrades its made around ultra-wide Mac mirroring, or the way Spatial Personas make it feel as if you’re working alongside other people. With Android XR, Google seems to just be making a more open Vision Pro.Honestly, it’s unclear if normal users will ever want to use any sort of XR headset regularly, no matter how cheap they get. The experience making these headsets could help Google, Apple and Meta develop future AR glasses, or eyewear that offer some sort of XR experience (Samsung already has something in the works with Warby Parker and Gentle Monster). But while Apple and Meta have broken new ground in XR, Google and Samsung just seem to be following in their footsteps.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsungs-galaxy-xr-doesnt-give-me-much-hope-for-android-xr-110000129.html?src=rss",
          "content": "So Samsung made a \"Vision Pro Lite.\" That was my immediate takeaway after this week's debut of the Galaxy XR, the first Android XR device to hit the market. While Samsung deserves credit for offering something close to the Vision Pro for nearly half the price, an $1,800 headset still won't get mainstream consumers rushing out the door to experience the wonders of mixed reality. And with the limited amount of content in Android XR at the moment, the Galaxy XR is in the same position as the Vision Pro: It's just a well-polished developer kit. The only logical reason to buy a Galaxy XR would be to test out apps for Android XR. If you just want to experience VR and dabble in a bit of augmented reality, you're better off spending that money on a gaming laptop and the excellent $500 Meta Quest 3. (The Meta Quest Pro, the company’s first high-end mixed reality device, was unceremoniously killed after launching at an eye-watering $1,500.) But even for developers, the Galaxy XR feels like it's lacking, well, vision. Samsung has done an admirable job of copying almost every aspect of the Vision Pro: The sleek ski goggle design, dual micro-OLED displays and hand gesture interaction powered by a slew of cameras and sensors. But while Apple positioned the Vision Pro as its first stab at spatial computing, an exciting new platform where we can use interactive apps in virtual space, Samsung and Google are basically just gunning to put Android on your face. There aren't many custom-built XR apps, aside from Google's offerings like Maps and Photos. (Something that also reminds me of the dearth of real tablet apps on Android.) And the ability to view 360-degree videos on YouTube has been a staple of every VR headset for the last decade — it's not exactly notable on something that costs $1,800. Samsung and Google also haven't said much about how they plan to elevate XR content. At least Apple is attempting to push the industry forward with its 8K Immersive Videos, which look sharper and more realistic than low-res 360-degree content.For the most part, it seems as if Google is treating Android XR as another way to force its Gemini AI on users. In its press release for the Galaxy XR, Samsung notes that it's \"introducing a new category of AI-native devices designed to deliver immersive experiences in a form factor optimized for multimodal AI.\" …What? In addition to being a crime against the English language, what the company is actually pitching is fairly simple: It's just launching a headset that can access AI features via camera and voice inputs. Who knows, maybe Gemini will make Android XR devices more capable down the line. But at the moment, all I'm seeing in the Galaxy XR is another Samsung device that's shamelessly aping Apple, from the virtual avatars to specific pinch gestures. And Google's history in VR and interactive content doesn't inspire much hope about Android XR. Don't forget how it completely abandoned Google Cardboard, the short-lived Daydream project and its hyped up Stadia cloud service. Stadia's death was particularly galling, since Google initially pitched it as a way to revolutionize the very world of gaming, only to let it fall on its face.There’s no doubt that Samsung, Apple and Meta have a ton of work left ahead in the world of XR. Samsung is at least closer to delivering something under $1,000, and Meta also recently launched the $800 Ray-Ban Display. But price is only one part of the problem. Purpose is another issue entirely. After living with the Vision Pro since its debut, I can tell that Apple is at least thinking a bit more deeply about what it’s like to wear a computer on your face. Just look at the upgrades its made around ultra-wide Mac mirroring, or the way Spatial Personas make it feel as if you’re working alongside other people. With Android XR, Google seems to just be making a more open Vision Pro.Honestly, it’s unclear if normal users will ever want to use any sort of XR headset regularly, no matter how cheap they get. The experience making these headsets could help Google, Apple and Meta develop future AR glasses, or eyewear that offer some sort of XR experience (Samsung already has something in the works with Warby Parker and Gentle Monster). But while Apple and Meta have broken new ground in XR, Google and Samsung just seem to be following in their footsteps.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsungs-galaxy-xr-doesnt-give-me-much-hope-for-android-xr-110000129.html?src=rss",
          "feed_position": 28
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-noise-canceling-headphones-130029881.html",
          "published_at": "Thu, 23 Oct 2025 09:00:35 +0000",
          "title": "The best noise-canceling headphones for 2025",
          "standfirst": "Whether you're working in a noisy office, commuting on a packed train or just trying to focus at home, a good pair of noise-canceling headphones can make all the difference. The best noise-canceling headphones block out distractions and let you enjoy your music, podcasts or calls in peace — all while delivering great sound quality and all-day comfort. From models with plush cushions to wireless cans with loads of extra features, there’s something here for every style and budget. Table of contents Best noise-canceling headphones for 2025 How to choose the best noise-canceling headphones for you How we test noise-canceling headphones Other noise-canceling headphones we tested Noise-canceling headphones FAQs Best noise-canceling headphones of 2025 How to choose the best noise-canceling headphones for you Design When you’re shopping for the best wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of this guide, I focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear, active noise-canceling headphones are much more effective at blocking outside sounds since your ears are completely covered. For gamers, there are also gaming headsets that feature noise cancellation — some even have detachable microphones, so they can double as over-ear headphones. However, for the purpose of this article, we’re only going to be focusing on noise-canceling headphones rather than headsets. Look for models with a comfortable headband and memory foam ear cups to ensure you can wear them for long periods without discomfort. Many headphones also come with a range of color options, so if aesthetics matter to you, you’ll find plenty of choices beyond just black or white. Whether you’re looking for something neutral or a bold pop of color, brands now offer a variety of styles to match your personal taste. Finally, if you’re planning to wear your headphones for long periods of time, it’s important to pick a model with a comfortable fit. Memory foam ear cups, an adjustable headband, and lightweight materials can make all the difference during extended listening sessions. After all, great sound is only part of the equation; comfort matters just as much. Type of noise cancellation Next, you’ll want to look at the type of ANC a set of headphones offers. You’ll come across terms like “hybrid active noise cancellation” or “hybrid adaptive active noise cancellation,” and there are key differences between the two. A hybrid ANC setup uses microphones on the inside and on the outside of the device to detect outside noise and cancel it out. By analyzing input from both mics, a hybrid system can combat more sounds than “regular” ANC, but it does so at a constant level that doesn’t change. Adaptive ANC takes the hybrid configuration a step further by continuously adjusting the noise cancellation for changes in your environment and any leakage around the padding of the ear cups. Adaptive noise-canceling also does a better job with wind noise, which can really kill your vibe while using headphones outdoors. Some high-end headphones also support Dolby Atmos, which enhances spatial audio and makes everything from music to movies sound more immersive. For the purposes of this best headphones list, I’m only considering products with hybrid ANC or adaptive ANC setups because those are the most effective at blocking noise and improving your overall listening experience. Customization You’ll also want to check to see if the ANC system on a prospective set of headphones offers adjustable levels of noise cancellation or presets. These can help you dial in the amount of ANC you need for various environments, but it can also help you save battery life. Master & Dynamic, for example, has ANC presets that provide both maximum noise blocking and more efficient cancellation that is more energy efficient. Other companies may include a slider in their companion apps that let you adjust the ANC level to your liking. Some high-end models even allow you to fine-tune the ANC for specific types of environments. How we test noise-canceling headphones The primary way we test headphones is to wear them as much as possible. I prefer to do this over a one-to-two-week period, but sometimes deadlines don’t allow it. During this time, I listen to a mix of music and podcasts, while also using the headphones to take both voice and video calls. Since battery life for headphones can be 30 hours or more, I drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, I’ll typically power the headphones off several times and leave them that way during a review. This simulates real-world use and keeps me from having to constantly monitor the process for over 24 straight hours. To test ANC performance specifically, I use headphones in a variety of environments, from noisy coffee shops to quiet home offices. When my schedule allows, I use them during air travel since plane noise is a massive distraction to both work and relaxation. Even if I can’t hop on a flight, I’ll simulate a constant roar with white noise machines, bathroom fans, vacuums and more. I also make note of how well each device blocks human voices, which are a key stumbling block for a lot of ANC headphones. ANC-related features are something else to consider. Here, I do a thorough review of companion apps, testing each feature as I work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones I’m testing are an updated version of a previous model, I’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that I review. Other noise-canceling headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancellation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor, which is actually handy. All told, that’s not a lot for a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 is more expensive and not nearly as comfortable as the Px7 S3. Noble Audio FoKus Apollo While this is my top pick for overall sound quality in our main guide to the best wireless headphones, the ANC performance is less impressive than the Px7 S3. Bowers & Wilkins gets the nod here for its improved noise cancellation over the Px7 S2 and Px7 S2e, and its overall excellent audio quality. Noise-canceling headphones FAQs Does noise cancellation block all noise? Noise cancellation doesn’t block out all noise, though it does drastically reduce the volume of most external sounds. Is there a difference between wired vs wireless noise-canceling headphones? In terms of sound quality, if you have two headphones — one wired and one wireless — with similar specs, the difference is going to be very minimal. However, wireless headphones offer more convenience, allowing you to move around more freely with your headphones on, which is why they often feature noise cancellation to minimize external sounds. Does noise cancellation impact sound quality? ANC does bear some weight on sound quality, but the impact of this often doesn’t outweigh the benefits. Noise cancellation reduces ambient noise, allowing a greater focus on audio detail. For audiophiles, however, there may be a small difference in sound fidelity when ANC is turned on.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-noise-canceling-headphones-130029881.html?src=rss",
          "content": "Whether you're working in a noisy office, commuting on a packed train or just trying to focus at home, a good pair of noise-canceling headphones can make all the difference. The best noise-canceling headphones block out distractions and let you enjoy your music, podcasts or calls in peace — all while delivering great sound quality and all-day comfort. From models with plush cushions to wireless cans with loads of extra features, there’s something here for every style and budget. Table of contents Best noise-canceling headphones for 2025 How to choose the best noise-canceling headphones for you How we test noise-canceling headphones Other noise-canceling headphones we tested Noise-canceling headphones FAQs Best noise-canceling headphones of 2025 How to choose the best noise-canceling headphones for you Design When you’re shopping for the best wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of this guide, I focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear, active noise-canceling headphones are much more effective at blocking outside sounds since your ears are completely covered. For gamers, there are also gaming headsets that feature noise cancellation — some even have detachable microphones, so they can double as over-ear headphones. However, for the purpose of this article, we’re only going to be focusing on noise-canceling headphones rather than headsets. Look for models with a comfortable headband and memory foam ear cups to ensure you can wear them for long periods without discomfort. Many headphones also come with a range of color options, so if aesthetics matter to you, you’ll find plenty of choices beyond just black or white. Whether you’re looking for something neutral or a bold pop of color, brands now offer a variety of styles to match your personal taste. Finally, if you’re planning to wear your headphones for long periods of time, it’s important to pick a model with a comfortable fit. Memory foam ear cups, an adjustable headband, and lightweight materials can make all the difference during extended listening sessions. After all, great sound is only part of the equation; comfort matters just as much. Type of noise cancellation Next, you’ll want to look at the type of ANC a set of headphones offers. You’ll come across terms like “hybrid active noise cancellation” or “hybrid adaptive active noise cancellation,” and there are key differences between the two. A hybrid ANC setup uses microphones on the inside and on the outside of the device to detect outside noise and cancel it out. By analyzing input from both mics, a hybrid system can combat more sounds than “regular” ANC, but it does so at a constant level that doesn’t change. Adaptive ANC takes the hybrid configuration a step further by continuously adjusting the noise cancellation for changes in your environment and any leakage around the padding of the ear cups. Adaptive noise-canceling also does a better job with wind noise, which can really kill your vibe while using headphones outdoors. Some high-end headphones also support Dolby Atmos, which enhances spatial audio and makes everything from music to movies sound more immersive. For the purposes of this best headphones list, I’m only considering products with hybrid ANC or adaptive ANC setups because those are the most effective at blocking noise and improving your overall listening experience. Customization You’ll also want to check to see if the ANC system on a prospective set of headphones offers adjustable levels of noise cancellation or presets. These can help you dial in the amount of ANC you need for various environments, but it can also help you save battery life. Master & Dynamic, for example, has ANC presets that provide both maximum noise blocking and more efficient cancellation that is more energy efficient. Other companies may include a slider in their companion apps that let you adjust the ANC level to your liking. Some high-end models even allow you to fine-tune the ANC for specific types of environments. How we test noise-canceling headphones The primary way we test headphones is to wear them as much as possible. I prefer to do this over a one-to-two-week period, but sometimes deadlines don’t allow it. During this time, I listen to a mix of music and podcasts, while also using the headphones to take both voice and video calls. Since battery life for headphones can be 30 hours or more, I drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, I’ll typically power the headphones off several times and leave them that way during a review. This simulates real-world use and keeps me from having to constantly monitor the process for over 24 straight hours. To test ANC performance specifically, I use headphones in a variety of environments, from noisy coffee shops to quiet home offices. When my schedule allows, I use them during air travel since plane noise is a massive distraction to both work and relaxation. Even if I can’t hop on a flight, I’ll simulate a constant roar with white noise machines, bathroom fans, vacuums and more. I also make note of how well each device blocks human voices, which are a key stumbling block for a lot of ANC headphones. ANC-related features are something else to consider. Here, I do a thorough review of companion apps, testing each feature as I work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones I’m testing are an updated version of a previous model, I’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that I review. Other noise-canceling headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancellation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor, which is actually handy. All told, that’s not a lot for a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 is more expensive and not nearly as comfortable as the Px7 S3. Noble Audio FoKus Apollo While this is my top pick for overall sound quality in our main guide to the best wireless headphones, the ANC performance is less impressive than the Px7 S3. Bowers & Wilkins gets the nod here for its improved noise cancellation over the Px7 S2 and Px7 S2e, and its overall excellent audio quality. Noise-canceling headphones FAQs Does noise cancellation block all noise? Noise cancellation doesn’t block out all noise, though it does drastically reduce the volume of most external sounds. Is there a difference between wired vs wireless noise-canceling headphones? In terms of sound quality, if you have two headphones — one wired and one wireless — with similar specs, the difference is going to be very minimal. However, wireless headphones offer more convenience, allowing you to move around more freely with your headphones on, which is why they often feature noise cancellation to minimize external sounds. Does noise cancellation impact sound quality? ANC does bear some weight on sound quality, but the impact of this often doesn’t outweigh the benefits. Noise cancellation reduces ambient noise, allowing a greater focus on audio detail. For audiophiles, however, there may be a small difference in sound fidelity when ANC is turned on.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-noise-canceling-headphones-130029881.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/fujifilms-x-t30-iii-adds-a-film-simulation-dial-and-6k-video-072148245.html",
          "published_at": "Thu, 23 Oct 2025 07:21:48 +0000",
          "title": "Fujifilm's X-T30 III adds a film simulation dial and 6K video",
          "standfirst": "When Fujifilm launched the X-T50 last year, no one was sure what would happen with its aging X-T30 lineup. The company just answered that question with the launch of the X-T30 III, boosting the speed and improving autofocus of the last model, while adding a film simulation dial seen on other recent models. It's very light for travel or street photography, but has some powerful features like 6.2K video and subject-detect autofocus, all at a reasonable price. The original X-T30 first arrived in 2019 and was replaced in 2022 by the X-T30 II that was more of a mild update than an all-new camera. However, the X-T30 III has a number of key updates that bring it in line with other recent models like the X-M5 and X-T50. It does have the same 26.1MP X-Trans sensor as before (with a 1.5x crop compared to a full-frame camera), but now uses Fujifilm's latest image processor that doubles image processing speed and significantly improves video capabilities. Ryan Tuttle for Fujifilm The X-T30 III is meant to be taken on adventures, so it's still very light at just 378 grams or 13.33 ounces, a touch less than the previous model. Control-wise, the biggest addition is a film simulation dial just like the one on the X-M5 and X-T50, replacing the mode dial from the X-T30 II. It's designed to make it easy to switch between film simulations like Reala Ace and Nostalgic Neg, while offering three customizable positions to let users save \"recipes\" of their own making. Otherwise, the X-T30 III has a generous complement of dials and buttons something that allows for precise control but may intimidate newbies. The rear display tilts up but doesn't flip out, and the 2.36-million-dot electronic viewfinder is on the low end for resolution. The main feature missing on the X-T30 III is in-body stabilization, so you'll need either a stabilized (OIS) lens or electronic stabilization for video. Fujjifilm Burst shooting speeds are the same as before at 8 fps with the mechanical shutter and 20 fps in electronic mode. However, more of your shots are likely to be sharp thanks to the updated, faster autofocus. Along with the extra speed, Fujifilm introduced new AI subject detection modes including Auto-Tracking, Animals, Birds and Vehicles. Video also gets a big upgrade. The X-T30 III can now shot 6.2K 30 fps video using the entire sensor (up from 4K 30p before), or 4K at 60 fps with a mild 1.18x crop. All of those resolutions are available with 10-bit modes to boost dynamic range. However, the X-T30 III lacks in-body stabilization, has a weird 2.5mm microphone input and a display that only tilts and doesn't flip out. That makes it fine as a hybrid camera, but if you mostly shoot video, a model like the X-S20 may be a better choice. Fujifilm Other key features include a microHDMI port for RAW video output, a single SD memory card (that's of the low-speed UHS-I variety unfortunately), and improved battery life with up to 425 shots to a charge. Fujifilm also introduced a new lens, the Fujinon XC13-33mmF3.5-6.3 OIS that offers an interesting ultrawide full-frame equivalent zoom range of around 20-50mm. The X-T30 III is now on pre-order for $999 in multiple colors (black, charcoal silver and silver) with shipping set to start in November 2025. The Fujinon XC13-33mmF3.5-6.3 OIS will also ship around the same time for $399. This article originally appeared on Engadget at https://www.engadget.com/cameras/fujifilms-x-t30-iii-adds-a-film-simulation-dial-and-6k-video-072148245.html?src=rss",
          "content": "When Fujifilm launched the X-T50 last year, no one was sure what would happen with its aging X-T30 lineup. The company just answered that question with the launch of the X-T30 III, boosting the speed and improving autofocus of the last model, while adding a film simulation dial seen on other recent models. It's very light for travel or street photography, but has some powerful features like 6.2K video and subject-detect autofocus, all at a reasonable price. The original X-T30 first arrived in 2019 and was replaced in 2022 by the X-T30 II that was more of a mild update than an all-new camera. However, the X-T30 III has a number of key updates that bring it in line with other recent models like the X-M5 and X-T50. It does have the same 26.1MP X-Trans sensor as before (with a 1.5x crop compared to a full-frame camera), but now uses Fujifilm's latest image processor that doubles image processing speed and significantly improves video capabilities. Ryan Tuttle for Fujifilm The X-T30 III is meant to be taken on adventures, so it's still very light at just 378 grams or 13.33 ounces, a touch less than the previous model. Control-wise, the biggest addition is a film simulation dial just like the one on the X-M5 and X-T50, replacing the mode dial from the X-T30 II. It's designed to make it easy to switch between film simulations like Reala Ace and Nostalgic Neg, while offering three customizable positions to let users save \"recipes\" of their own making. Otherwise, the X-T30 III has a generous complement of dials and buttons something that allows for precise control but may intimidate newbies. The rear display tilts up but doesn't flip out, and the 2.36-million-dot electronic viewfinder is on the low end for resolution. The main feature missing on the X-T30 III is in-body stabilization, so you'll need either a stabilized (OIS) lens or electronic stabilization for video. Fujjifilm Burst shooting speeds are the same as before at 8 fps with the mechanical shutter and 20 fps in electronic mode. However, more of your shots are likely to be sharp thanks to the updated, faster autofocus. Along with the extra speed, Fujifilm introduced new AI subject detection modes including Auto-Tracking, Animals, Birds and Vehicles. Video also gets a big upgrade. The X-T30 III can now shot 6.2K 30 fps video using the entire sensor (up from 4K 30p before), or 4K at 60 fps with a mild 1.18x crop. All of those resolutions are available with 10-bit modes to boost dynamic range. However, the X-T30 III lacks in-body stabilization, has a weird 2.5mm microphone input and a display that only tilts and doesn't flip out. That makes it fine as a hybrid camera, but if you mostly shoot video, a model like the X-S20 may be a better choice. Fujifilm Other key features include a microHDMI port for RAW video output, a single SD memory card (that's of the low-speed UHS-I variety unfortunately), and improved battery life with up to 425 shots to a charge. Fujifilm also introduced a new lens, the Fujinon XC13-33mmF3.5-6.3 OIS that offers an interesting ultrawide full-frame equivalent zoom range of around 20-50mm. The X-T30 III is now on pre-order for $999 in multiple colors (black, charcoal silver and silver) with shipping set to start in November 2025. The Fujinon XC13-33mmF3.5-6.3 OIS will also ship around the same time for $399. This article originally appeared on Engadget at https://www.engadget.com/cameras/fujifilms-x-t30-iii-adds-a-film-simulation-dial-and-6k-video-072148245.html?src=rss",
          "feed_position": 30,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c61cba10-afdd-11f0-9fff-ba497027a57e"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html",
          "published_at": "Thu, 23 Oct 2025 07:00:37 +0000",
          "title": "The best wireless earbuds for 2025",
          "standfirst": "Wireless earbuds have become the go-to choice for listening on the move. Whether you’re at the gym, commuting or relaxing at home, the best wireless earbuds give you comfort, freedom and solid sound quality without tangled cables. They’re lightweight, slip easily into your pocket and connect quickly to your phone, tablet or laptop.The tricky part is choosing the right pair. Some models focus on powerful noise cancellation while others put battery life or affordability first. Then you’ve got features like water resistance for workouts or touch controls for quick track changes. With so many choices, finding the best wireless earbuds depends on what matters most to you, and that’s exactly what this guide will help you figure out. Table of contents Best wireless earbuds of 2025 What to look for in the best wireless earbuds How we test wireless earbuds Other wireless earbuds we tested Wireless earbuds FAQs Best wireless earbuds of 2025 What to look for in the best wireless earbuds When it comes to shopping for earphones, the first thing to consider is design or wear style. Do you prefer a semi-open fit like AirPods or do you want something that completely closes off your ears? If you’re shopping for earbuds with active noise cancellation, you'll want the latter, but a case can be made for the former if you want to wear them all day or frequent places where you need to be tuned in to the ambient sounds. The overall shape of earbuds can determine whether you get a comfortable fit, so can the size and weight, so you’ll want to consider all that before deciding. And remember: audio companies aren’t perfect, so despite lots of research, the earbud shape they decided on may not fit you well. Don’t be afraid to return ill-fitting earbuds for something that’s more comfortable. As wireless earbuds have become the norm, they’re now more reliable for basic things like consistent Bluetooth connectivity. Companies are still in a race to pack as much as they can into increasingly smaller designs. This typically means a longer list of features on the more premium sets of earbuds with basic functionality on the cheapest models. Carefully consider what you can’t live without when selecting your next earbuds, and make sure key items like automatic pausing and multipoint connectivity are on the spec sheet. You’ll also want to investigate the volume and touch controls as you’ll often have to sacrifice access to something else to make that adjustment via on-board taps or swipes. Some earbuds even offer app settings to tweak the audio profiles or firmware updates to improve performance over time. For those in the Apple ecosystem, features like auto-pairing with devices, especially with AirPods Pro 3, can be an added advantage, while Android users may want to look for models that offer similar cross-device functionality. When it comes to battery life, the average set of earbuds lasts about five hours on a single charge. You can find sets that last longer, but this is likely enough to get you through a work day if you’re docking the buds during lunch or the occasional meeting. You’ll want to check on how many extra charges are available via the case and if it supports wireless charging. Companies will also make lofty claims about call quality on wireless earbuds. Despite lots of promises, the reality is most earbuds still leave you sounding like you’re on speakerphone. There are some sets that deliver, but don’t get your hopes up unless reviews confirm the claims. Sound can be subjective, so we recommend trying before you buy if at all possible. This is especially true if you're an audiophile. We understand this isn’t easy when most of us do a lot of shopping online, but trying on a set of earbuds and listening to them for a few minutes can save you from an expensive case of buyer's remorse. If a store doesn’t allow a quick demo, most retailers have return policies that will let you take earbuds back you don’t like. Of course, you have to be willing to temporarily part with funds in order to do this. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all earbuds support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you, especially if you plan to use them for playback of high-quality audio. How we test wireless earbuds The primary way we test earbuds is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for earbuds is typically less than a full day, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). To judge audio quality, we listen to a range of genres, noting any differences in the sound profile across the styles. We also test at both low and high volumes to check for consistency in the tuning. To assess call quality, we’ll record audio samples with the earbuds’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the earbuds we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older buds. Ditto for the closest competition for each new set of earbuds that we review. Other wireless Bluetooth earbuds we tested Sony WF-C710N The WF-C710N is a set of compact and comfy earbuds that offer several of Sony’s best features. While the ANC performance is above average for this price ($120), sound quality isn’t as good as the company’s slightly more expensive options. Battery life fell below stated figures and call performance isn’t good enough to use these buds for work. Beats Powerbeats Pro 2 The newest version of the Powerbeats Pro have an improved, comfortable design, balanced bass and new H2 chips and a heart rate sensor inside. But heart rate support is currently limited on iOS. Samsung Galaxy Buds 3 The Galaxy Buds 3 combine ANC with an open-type design, which renders the noise-blocking abilities of the earbuds mostly useless. Still, there’s great low-end tone with ample bass when a track demands it. There are also lots of handy features, most of which require a Samsung phone. But at this price, there are better options from Google, Beats and Sony Sennheiser Momentum Sport I really like the overall shape of the Momentum Sport earbuds. They’re more comfortable than the Momentum True Wireless 4 and fit in my ears better. What’s more, the body temperature and heart rate sensors work well, sending those stats to a variety of apps. However, that sport-tracking feature works best with Polar’s app and devices, so there’s that consideration. Also, the audio quality and ANC performance isn’t as good as the MTW4, and these earbuds are pricey. Beats Solo Buds There’s a lot to like about the Solo Buds for $80. For me, the primary perk is they’re very comfortable to wear for long periods of time thanks to some thoughtful design considerations. You only get the basics here in terms of features and, as expected, the overall sound quality isn’t as good as the pricier models in the Beats lineup. You will get 18 hours of battery life though, since the company nixed the battery in the case and beefed up the listening time in the buds themselves. Bose Ultra Open Earbuds Bose created something very unique for this set of earbuds that allows you to stay in-tune with the world while listening to audio content. The clip-on design is very comfortable, but sound quality suffers due to the open-type fit, especially when it comes to bass and spatial audio. Audio-Technica ATH-TWX7 These stick buds have a compact design that’s comfortable to wear and the warm sound profile is great at times. However, overall audio performance is inconsistent and there’s no automatic pausing. Master & Dynamic MW09 Retooled audio, better ambient sound mode and reliable multipoint Bluetooth are the best things the MW09 has to offer. They’re expensive though, and you can find better ANC performance elsewhere. Wireless earbud FAQs What is considered good battery life for true wireless earbuds? Most wireless earbuds will last five hours on a single charge, at the least. You can find some pairs that have even better battery life, lasting between six and eight hours before they need more juice. All of the best wireless earbuds come with a charging case, which will provide additional hours of battery life — but you'll have to return each bud to the case in order to charge them up. Is sound quality better on headphones or earbuds? Comparing sound quality on earbuds and headphones is a bit like comparing apples and oranges. There are a lot of variables to consider and the differences in components make a direct comparison difficult. Personally, I prefer the audio quality from over-ear headphones, but I can tell you the sound from earbuds like Sennheiser’s Momentum True Wireless 3 is also outstanding. Which wireless earbuds have the longest battery life? With new models coming out all the time, tracking the hours of battery life for each this can be difficult to keep tabs on. The longest-lasting earbuds we’ve reviewed are Audio-Technica’s ATH-CKS5TW. The company states they last 15 hours, but the app was still showing 40 percent at that mark during our tests. The only downside is these earbuds debuted in 2019 and both technology and features have improved since. In terms of current models, Master & Dynamic’s MW08 offers 12 hours of use on a charge with ANC off (10 with ANC on) and JBL has multiple options with 10-hour batteries. What wireless earbuds are waterproof? There are plenty of options these days when it comes to increased water resistance. To determine the level of protection, you’ll want to look for an IP (ingress protection) rating. The first number indicates intrusion protection from things like dust. The second number is the level of moisture protection and you’ll want to make sure that figure is 7 or higher. At this water-resistance rating, earbuds can withstand full immersion for up to 30 minutes in depths up to one meter (3.28 feet). If either of the IP numbers is an X, that means it doesn’t have any special protection. For example, a pair of wireless earbuds that are IPX7 wouldn’t be built to avoid dust intrusion, but they would be ok if you dropped them in shallow water. Which earbuds stay in ears the best? A secure fit can vary wildly from person to person. All of our ears are different, so audio companies are designing their products to fit the most people they can with a single shape. This is why AirPods will easily fall out for some but stay put for others. Design touches like wing tips or fins typically come on fitness models and those elements can help keep things in place. You’ll likely just have to try earbuds on, and if they don’t fit well return them. What wireless earbuds work with PS5? PlayStation 5 doesn’t support Bluetooth audio without an adapter or dongle. Even Sony’s own gaming headsets come with a transmitter that connects to the console. There are universal options that allow you to use any headphones, headset or earbuds with a PS5. Once you have one, plug it into a USB port on the console and pair your earbuds with it. Recent updates September 2025: Updated to add AirPods Pro 3 to our top picks. May 2025: Updated to ensure top picks and buying advice remain accurate. March 2025: Updated the top pick for the best sounding wireless earbuds - runner up. January 2025: Updated the top pick for best sounding wireless earbuds. July 2024: Updated our list to include the Samsung Galaxy Buds 3 Pro.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html?src=rss",
          "content": "Wireless earbuds have become the go-to choice for listening on the move. Whether you’re at the gym, commuting or relaxing at home, the best wireless earbuds give you comfort, freedom and solid sound quality without tangled cables. They’re lightweight, slip easily into your pocket and connect quickly to your phone, tablet or laptop.The tricky part is choosing the right pair. Some models focus on powerful noise cancellation while others put battery life or affordability first. Then you’ve got features like water resistance for workouts or touch controls for quick track changes. With so many choices, finding the best wireless earbuds depends on what matters most to you, and that’s exactly what this guide will help you figure out. Table of contents Best wireless earbuds of 2025 What to look for in the best wireless earbuds How we test wireless earbuds Other wireless earbuds we tested Wireless earbuds FAQs Best wireless earbuds of 2025 What to look for in the best wireless earbuds When it comes to shopping for earphones, the first thing to consider is design or wear style. Do you prefer a semi-open fit like AirPods or do you want something that completely closes off your ears? If you’re shopping for earbuds with active noise cancellation, you'll want the latter, but a case can be made for the former if you want to wear them all day or frequent places where you need to be tuned in to the ambient sounds. The overall shape of earbuds can determine whether you get a comfortable fit, so can the size and weight, so you’ll want to consider all that before deciding. And remember: audio companies aren’t perfect, so despite lots of research, the earbud shape they decided on may not fit you well. Don’t be afraid to return ill-fitting earbuds for something that’s more comfortable. As wireless earbuds have become the norm, they’re now more reliable for basic things like consistent Bluetooth connectivity. Companies are still in a race to pack as much as they can into increasingly smaller designs. This typically means a longer list of features on the more premium sets of earbuds with basic functionality on the cheapest models. Carefully consider what you can’t live without when selecting your next earbuds, and make sure key items like automatic pausing and multipoint connectivity are on the spec sheet. You’ll also want to investigate the volume and touch controls as you’ll often have to sacrifice access to something else to make that adjustment via on-board taps or swipes. Some earbuds even offer app settings to tweak the audio profiles or firmware updates to improve performance over time. For those in the Apple ecosystem, features like auto-pairing with devices, especially with AirPods Pro 3, can be an added advantage, while Android users may want to look for models that offer similar cross-device functionality. When it comes to battery life, the average set of earbuds lasts about five hours on a single charge. You can find sets that last longer, but this is likely enough to get you through a work day if you’re docking the buds during lunch or the occasional meeting. You’ll want to check on how many extra charges are available via the case and if it supports wireless charging. Companies will also make lofty claims about call quality on wireless earbuds. Despite lots of promises, the reality is most earbuds still leave you sounding like you’re on speakerphone. There are some sets that deliver, but don’t get your hopes up unless reviews confirm the claims. Sound can be subjective, so we recommend trying before you buy if at all possible. This is especially true if you're an audiophile. We understand this isn’t easy when most of us do a lot of shopping online, but trying on a set of earbuds and listening to them for a few minutes can save you from an expensive case of buyer's remorse. If a store doesn’t allow a quick demo, most retailers have return policies that will let you take earbuds back you don’t like. Of course, you have to be willing to temporarily part with funds in order to do this. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all earbuds support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you, especially if you plan to use them for playback of high-quality audio. How we test wireless earbuds The primary way we test earbuds is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for earbuds is typically less than a full day, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). To judge audio quality, we listen to a range of genres, noting any differences in the sound profile across the styles. We also test at both low and high volumes to check for consistency in the tuning. To assess call quality, we’ll record audio samples with the earbuds’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the earbuds we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older buds. Ditto for the closest competition for each new set of earbuds that we review. Other wireless Bluetooth earbuds we tested Sony WF-C710N The WF-C710N is a set of compact and comfy earbuds that offer several of Sony’s best features. While the ANC performance is above average for this price ($120), sound quality isn’t as good as the company’s slightly more expensive options. Battery life fell below stated figures and call performance isn’t good enough to use these buds for work. Beats Powerbeats Pro 2 The newest version of the Powerbeats Pro have an improved, comfortable design, balanced bass and new H2 chips and a heart rate sensor inside. But heart rate support is currently limited on iOS. Samsung Galaxy Buds 3 The Galaxy Buds 3 combine ANC with an open-type design, which renders the noise-blocking abilities of the earbuds mostly useless. Still, there’s great low-end tone with ample bass when a track demands it. There are also lots of handy features, most of which require a Samsung phone. But at this price, there are better options from Google, Beats and Sony Sennheiser Momentum Sport I really like the overall shape of the Momentum Sport earbuds. They’re more comfortable than the Momentum True Wireless 4 and fit in my ears better. What’s more, the body temperature and heart rate sensors work well, sending those stats to a variety of apps. However, that sport-tracking feature works best with Polar’s app and devices, so there’s that consideration. Also, the audio quality and ANC performance isn’t as good as the MTW4, and these earbuds are pricey. Beats Solo Buds There’s a lot to like about the Solo Buds for $80. For me, the primary perk is they’re very comfortable to wear for long periods of time thanks to some thoughtful design considerations. You only get the basics here in terms of features and, as expected, the overall sound quality isn’t as good as the pricier models in the Beats lineup. You will get 18 hours of battery life though, since the company nixed the battery in the case and beefed up the listening time in the buds themselves. Bose Ultra Open Earbuds Bose created something very unique for this set of earbuds that allows you to stay in-tune with the world while listening to audio content. The clip-on design is very comfortable, but sound quality suffers due to the open-type fit, especially when it comes to bass and spatial audio. Audio-Technica ATH-TWX7 These stick buds have a compact design that’s comfortable to wear and the warm sound profile is great at times. However, overall audio performance is inconsistent and there’s no automatic pausing. Master & Dynamic MW09 Retooled audio, better ambient sound mode and reliable multipoint Bluetooth are the best things the MW09 has to offer. They’re expensive though, and you can find better ANC performance elsewhere. Wireless earbud FAQs What is considered good battery life for true wireless earbuds? Most wireless earbuds will last five hours on a single charge, at the least. You can find some pairs that have even better battery life, lasting between six and eight hours before they need more juice. All of the best wireless earbuds come with a charging case, which will provide additional hours of battery life — but you'll have to return each bud to the case in order to charge them up. Is sound quality better on headphones or earbuds? Comparing sound quality on earbuds and headphones is a bit like comparing apples and oranges. There are a lot of variables to consider and the differences in components make a direct comparison difficult. Personally, I prefer the audio quality from over-ear headphones, but I can tell you the sound from earbuds like Sennheiser’s Momentum True Wireless 3 is also outstanding. Which wireless earbuds have the longest battery life? With new models coming out all the time, tracking the hours of battery life for each this can be difficult to keep tabs on. The longest-lasting earbuds we’ve reviewed are Audio-Technica’s ATH-CKS5TW. The company states they last 15 hours, but the app was still showing 40 percent at that mark during our tests. The only downside is these earbuds debuted in 2019 and both technology and features have improved since. In terms of current models, Master & Dynamic’s MW08 offers 12 hours of use on a charge with ANC off (10 with ANC on) and JBL has multiple options with 10-hour batteries. What wireless earbuds are waterproof? There are plenty of options these days when it comes to increased water resistance. To determine the level of protection, you’ll want to look for an IP (ingress protection) rating. The first number indicates intrusion protection from things like dust. The second number is the level of moisture protection and you’ll want to make sure that figure is 7 or higher. At this water-resistance rating, earbuds can withstand full immersion for up to 30 minutes in depths up to one meter (3.28 feet). If either of the IP numbers is an X, that means it doesn’t have any special protection. For example, a pair of wireless earbuds that are IPX7 wouldn’t be built to avoid dust intrusion, but they would be ok if you dropped them in shallow water. Which earbuds stay in ears the best? A secure fit can vary wildly from person to person. All of our ears are different, so audio companies are designing their products to fit the most people they can with a single shape. This is why AirPods will easily fall out for some but stay put for others. Design touches like wing tips or fins typically come on fitness models and those elements can help keep things in place. You’ll likely just have to try earbuds on, and if they don’t fit well return them. What wireless earbuds work with PS5? PlayStation 5 doesn’t support Bluetooth audio without an adapter or dongle. Even Sony’s own gaming headsets come with a transmitter that connects to the console. There are universal options that allow you to use any headphones, headset or earbuds with a PS5. Once you have one, plug it into a USB port on the console and pair your earbuds with it. Recent updates September 2025: Updated to add AirPods Pro 3 to our top picks. May 2025: Updated to ensure top picks and buying advice remain accurate. March 2025: Updated the top pick for the best sounding wireless earbuds - runner up. January 2025: Updated the top pick for best sounding wireless earbuds. July 2024: Updated our list to include the Samsung Galaxy Buds 3 Pro.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/amazons-smart-glasses-with-ai-will-help-its-drivers-deliver-packages-faster-041009681.html",
          "published_at": "Thu, 23 Oct 2025 04:10:09 +0000",
          "title": "Amazon's smart glasses with AI will help its drivers deliver packages faster",
          "standfirst": "Amazon has revealed that it's currently working on smart glasses designed for delivery drivers, confirming previous reports about the project. The company said that glasses use AI-powered sensing capabilities and computer vision to detect what their cameras are seeing. Drivers then get guidance through the glasses' heads-up display (HUD) embedded right into the lens. Based on Amazon's announcement, it's been working on the glasses for a while, and hundreds of delivery drivers had already tested early versions to provide the company with feedback. The glasses automatically activate after the driver parks their vehicle. They then show users the right packages to deliver, according to their location. Users will see the list of packages they have to take out on the HUD, and the glasses can even tell them if they pull out the right package from their pile. When they get out of their vehicle, the glasses will display turn-by-turn navigation to the delivery address and will also show them hazards along the way, as well as help them navigate complex locations like apartment buildings. Simply put, the device allows them to find delivery addresses and drop off packages without having to use their phones. Drivers will even be able to capture proof of delivery with the wearable. Amazon's glasses will be paired with a vest that's fitted with a controller and a dedicated emergency button drivers can press to call emergency services along their routes. The device comes with a swappable battery to ensure all-day use and can be fitted with prescription and transitional lenses if the drivers need them. Amazon expects future versions of the glasses to be able to notify drivers if they're dropping a package at the wrong address and to be able to detect and notify them about more hazardous elements, like if there's a pet in the yard. In the annual event wherein the company announced the device, Amazon transportation vice president Beryl Tomay said it \"reduces the need to manage a phone and a package\" and helps drivers \"stay at attention, which enhances their safety.\" She also said that among the testers, Amazon had seen time savings of 30 minutes for a given shit. The company didn't say anything about developing smart glasses for consumers, but The Information's previous report said that it's also working on a model for the general public slated to be released in late 2026 or early 2027. This article originally appeared on Engadget at https://www.engadget.com/wearables/amazons-smart-glasses-with-ai-will-help-its-drivers-deliver-packages-faster-041009681.html?src=rss",
          "content": "Amazon has revealed that it's currently working on smart glasses designed for delivery drivers, confirming previous reports about the project. The company said that glasses use AI-powered sensing capabilities and computer vision to detect what their cameras are seeing. Drivers then get guidance through the glasses' heads-up display (HUD) embedded right into the lens. Based on Amazon's announcement, it's been working on the glasses for a while, and hundreds of delivery drivers had already tested early versions to provide the company with feedback. The glasses automatically activate after the driver parks their vehicle. They then show users the right packages to deliver, according to their location. Users will see the list of packages they have to take out on the HUD, and the glasses can even tell them if they pull out the right package from their pile. When they get out of their vehicle, the glasses will display turn-by-turn navigation to the delivery address and will also show them hazards along the way, as well as help them navigate complex locations like apartment buildings. Simply put, the device allows them to find delivery addresses and drop off packages without having to use their phones. Drivers will even be able to capture proof of delivery with the wearable. Amazon's glasses will be paired with a vest that's fitted with a controller and a dedicated emergency button drivers can press to call emergency services along their routes. The device comes with a swappable battery to ensure all-day use and can be fitted with prescription and transitional lenses if the drivers need them. Amazon expects future versions of the glasses to be able to notify drivers if they're dropping a package at the wrong address and to be able to detect and notify them about more hazardous elements, like if there's a pet in the yard. In the annual event wherein the company announced the device, Amazon transportation vice president Beryl Tomay said it \"reduces the need to manage a phone and a package\" and helps drivers \"stay at attention, which enhances their safety.\" She also said that among the testers, Amazon had seen time savings of 30 minutes for a given shit. The company didn't say anything about developing smart glasses for consumers, but The Information's previous report said that it's also working on a model for the general public slated to be released in late 2026 or early 2027. This article originally appeared on Engadget at https://www.engadget.com/wearables/amazons-smart-glasses-with-ai-will-help-its-drivers-deliver-packages-faster-041009681.html?src=rss",
          "feed_position": 32
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/what-enterprises-can-take-away-from-microsoft-ceo-satya-nadellas-shareholder",
          "published_at": "Thu, 23 Oct 2025 01:34:00 GMT",
          "title": "What enterprises can take away from Microsoft CEO Satya Nadella's shareholder letter",
          "standfirst": "One of the leading architects of the current generative AI boom — Microsoft CEO Satya Nadella, famed for having the software giant take an early investment in OpenAI (and later saying he was \"good for my $80 billion\") — published his latest annual letter yesterday on LinkedIn (a Microsoft subsidiary), and it&#x27;s chock full of interesting ideas about the near-term future that enterprise technical decision makers would do well to pay attention to, as it could aid in their own planning and tech stack development.In a companion post on X, Nadella wrote, “AI is radically changing every layer of the tech stack, and we’re changing with it.\" The full letter reinforces that message: Microsoft sees itself not just participating in the AI revolution, but shaping its infrastructure, security, tooling and governance for decades to come.While the message is addressed to Microsoft shareholders, the implications reach much further. The letter is a strategic signal to enterprise engineering leaders: CIOs, CTOs, AI leads, platform architects and security directors. Nadella outlines the direction of Microsoft’s innovation, but also what it expects from its customers and partners. The AI era is here, but it will be built by those who combine technical vision with operational discipline.Below are the five most important takeaways for enterprise technical decision makers.1. Security and reliability are now the foundation of the AI stackNadella makes security the first priority in the letter and ties it directly to Microsoft’s relevance going forward. Through its Secure Future Initiative (SFI), Microsoft has assigned the equivalent of 34,000 engineers to secure its identity systems, networks and software supply chain. Its Quality Excellence Initiative (QEI) aims to increase platform resiliency and strengthen global service uptime.Microsoft’s positioning makes it clear that enterprises will no longer get away with “ship fast, harden later” AI deployments. Nadella calls security “non-negotiable,” signaling that AI infrastructure must now meet the standards of mission-critical software. That means identity-first architecture, zero-trust execution environments and change management discipline are now table stakes for enterprise AI.2. AI infrastructure strategy is hybrid, open and sovereignty-readyNadella commits Microsoft to building “planet-scale systems” and backs that up with numbers: more than 400 Azure datacenters across 70 regions, two gigawatts of new compute capacity added this year, and new liquid-cooled GPU clusters rolling out across Azure. Microsoft also introduced Fairwater, a massive new AI datacenter in Wisconsin positioned to deliver unprecedented scale. Just as important, Microsoft is now officially multi-model. Azure AI Foundry offers access to more than 11,000 models including OpenAI, Meta, Mistral, Cohere and xAI. Microsoft is no longer pushing a single-model future, but a hybrid AI strategy.Enterprises should interpret this as validation of “portfolio architectures,” where closed, open and domain-specific models coexist. Nadella also emphasizes growing investment in sovereign cloud offerings for regulated industries, previewing a world where AI systems will have to meet regional data residency and compliance requirements from day one.3. AI agents—not just chatbots—are now Microsoft’s futureThe AI shift inside Microsoft is no longer about copilots that answer questions. It is now about AI agents that perform work. Nadella points to the rollout of Agent Mode in Microsoft 365 Copilot, which turns natural language requests into multistep business workflows. GitHub Copilot evolves from code autocomplete into a “peer programmer” capable of executing tasks asynchronously. In security operations, Microsoft has deployed AI agents that autonomously respond to incidents. In healthcare, Copilot for Dragon Medical documents clinical encounters automatically.This represents a major architectural pivot. Enterprises will need to move beyond prompt-response interfaces and begin engineering agent ecosystems that safely take actions inside business systems. That requires workflow orchestration, API integration strategies and strong guardrails. Nadella’s letter frames this as the next software platform shift.4. Unified data platforms are required to unlock AI valueNadella devotes significant attention to Microsoft Fabric and OneLake, calling Fabric the company’s fastest-growing data and analytics product ever. Fabric promises to centralize enterprise data from multiple cloud and analytics environments. OneLake provides a universal storage layer that binds analytics and AI workloads together.Microsoft’s message is blunt: siloed data means stalled AI. Enterprise teams that want AI at scale must unify operational and analytical data into a single architecture, enforce consistent data contracts and standardize metadata governance. AI success is now a data engineering problem more than a model problem.5. Trust, compliance and responsible AI are now mandatory for deployment“People want technology they can trust,” Nadella writes. Microsoft now publishes Responsible AI Transparency Reports and aligns parts of its development process with UN human rights guidance. Microsoft is also committing to digital resilience in Europe and proactive safeguards against misuse of AI-generated content.This shifts responsible AI out of the realm of corporate messaging and into engineering practice. Enterprises will need model documentation, reproducibility practices, audit trails, risk monitoring and human-in-the-loop checkpoints. Nadella signals that compliance will become integrated with product delivery—not an afterthought layered on top.The real meaning of Microsoft’s AI strategyTaken together, these five pillars send a clear message to enterprise leaders: AI maturity is no longer about building prototypes or proving use cases. System-level readiness now defines success. Nadella frames Microsoft’s mission as helping customers “think in decades and execute in quarters,” and that is more than corporate poetry. It is a call to build AI platforms engineered for longevity.The companies that win in enterprise AI will be the ones that invest early in secure cloud foundations, unify their data architectures, enable agent-based workflows and embrace responsible AI as a prerequisite for scale—not a press release. Nadella is betting that the next industrial transformation will be powered by AI infrastructure, not AI demos. With this letter, he has made Microsoft’s ambition clear: to become the platform on which that transformation is built.",
          "content": "One of the leading architects of the current generative AI boom — Microsoft CEO Satya Nadella, famed for having the software giant take an early investment in OpenAI (and later saying he was \"good for my $80 billion\") — published his latest annual letter yesterday on LinkedIn (a Microsoft subsidiary), and it&#x27;s chock full of interesting ideas about the near-term future that enterprise technical decision makers would do well to pay attention to, as it could aid in their own planning and tech stack development.In a companion post on X, Nadella wrote, “AI is radically changing every layer of the tech stack, and we’re changing with it.\" The full letter reinforces that message: Microsoft sees itself not just participating in the AI revolution, but shaping its infrastructure, security, tooling and governance for decades to come.While the message is addressed to Microsoft shareholders, the implications reach much further. The letter is a strategic signal to enterprise engineering leaders: CIOs, CTOs, AI leads, platform architects and security directors. Nadella outlines the direction of Microsoft’s innovation, but also what it expects from its customers and partners. The AI era is here, but it will be built by those who combine technical vision with operational discipline.Below are the five most important takeaways for enterprise technical decision makers.1. Security and reliability are now the foundation of the AI stackNadella makes security the first priority in the letter and ties it directly to Microsoft’s relevance going forward. Through its Secure Future Initiative (SFI), Microsoft has assigned the equivalent of 34,000 engineers to secure its identity systems, networks and software supply chain. Its Quality Excellence Initiative (QEI) aims to increase platform resiliency and strengthen global service uptime.Microsoft’s positioning makes it clear that enterprises will no longer get away with “ship fast, harden later” AI deployments. Nadella calls security “non-negotiable,” signaling that AI infrastructure must now meet the standards of mission-critical software. That means identity-first architecture, zero-trust execution environments and change management discipline are now table stakes for enterprise AI.2. AI infrastructure strategy is hybrid, open and sovereignty-readyNadella commits Microsoft to building “planet-scale systems” and backs that up with numbers: more than 400 Azure datacenters across 70 regions, two gigawatts of new compute capacity added this year, and new liquid-cooled GPU clusters rolling out across Azure. Microsoft also introduced Fairwater, a massive new AI datacenter in Wisconsin positioned to deliver unprecedented scale. Just as important, Microsoft is now officially multi-model. Azure AI Foundry offers access to more than 11,000 models including OpenAI, Meta, Mistral, Cohere and xAI. Microsoft is no longer pushing a single-model future, but a hybrid AI strategy.Enterprises should interpret this as validation of “portfolio architectures,” where closed, open and domain-specific models coexist. Nadella also emphasizes growing investment in sovereign cloud offerings for regulated industries, previewing a world where AI systems will have to meet regional data residency and compliance requirements from day one.3. AI agents—not just chatbots—are now Microsoft’s futureThe AI shift inside Microsoft is no longer about copilots that answer questions. It is now about AI agents that perform work. Nadella points to the rollout of Agent Mode in Microsoft 365 Copilot, which turns natural language requests into multistep business workflows. GitHub Copilot evolves from code autocomplete into a “peer programmer” capable of executing tasks asynchronously. In security operations, Microsoft has deployed AI agents that autonomously respond to incidents. In healthcare, Copilot for Dragon Medical documents clinical encounters automatically.This represents a major architectural pivot. Enterprises will need to move beyond prompt-response interfaces and begin engineering agent ecosystems that safely take actions inside business systems. That requires workflow orchestration, API integration strategies and strong guardrails. Nadella’s letter frames this as the next software platform shift.4. Unified data platforms are required to unlock AI valueNadella devotes significant attention to Microsoft Fabric and OneLake, calling Fabric the company’s fastest-growing data and analytics product ever. Fabric promises to centralize enterprise data from multiple cloud and analytics environments. OneLake provides a universal storage layer that binds analytics and AI workloads together.Microsoft’s message is blunt: siloed data means stalled AI. Enterprise teams that want AI at scale must unify operational and analytical data into a single architecture, enforce consistent data contracts and standardize metadata governance. AI success is now a data engineering problem more than a model problem.5. Trust, compliance and responsible AI are now mandatory for deployment“People want technology they can trust,” Nadella writes. Microsoft now publishes Responsible AI Transparency Reports and aligns parts of its development process with UN human rights guidance. Microsoft is also committing to digital resilience in Europe and proactive safeguards against misuse of AI-generated content.This shifts responsible AI out of the realm of corporate messaging and into engineering practice. Enterprises will need model documentation, reproducibility practices, audit trails, risk monitoring and human-in-the-loop checkpoints. Nadella signals that compliance will become integrated with product delivery—not an afterthought layered on top.The real meaning of Microsoft’s AI strategyTaken together, these five pillars send a clear message to enterprise leaders: AI maturity is no longer about building prototypes or proving use cases. System-level readiness now defines success. Nadella frames Microsoft’s mission as helping customers “think in decades and execute in quarters,” and that is more than corporate poetry. It is a call to build AI platforms engineered for longevity.The companies that win in enterprise AI will be the ones that invest early in secure cloud foundations, unify their data architectures, enable agent-based workflows and embrace responsible AI as a prerequisite for scale—not a press release. Nadella is betting that the next industrial transformation will be powered by AI infrastructure, not AI demos. With this letter, he has made Microsoft’s ambition clear: to become the platform on which that transformation is built.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/QSvQwRJMpyn4Xku8ZnAyk/dd36ccdb1258c23fd9dbabf947ba7cd4/cfr0z3n_httpss.mj.runM4mKVYlCu30_Cut_and_paste_collage_style_ph_780082c3-eb52-4012-ad6c-016de100662a__1_.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/the-first-e-bike-from-rivian-spinoff-also-has-a-virtual-drivetrain-173000250.html",
          "published_at": "Wed, 22 Oct 2025 21:29:41 +0000",
          "title": "The first e-bike from Rivian spinoff Also has a virtual drivetrain",
          "standfirst": "Ever since Rivian spun off its \"micromobility business\" into a standalone startup called Also earlier this year, there's been much speculation about what kind of vehicles the company is working on. Now, Also is showing off its first products: a lineup of e-bikes and two pedal-assisted electric quads. The TM-B e-bike is Also's attempt at a do-it-all e-bike that can adapt to different use cases whether that's daily commuting, trail riding or kid and cargo-hauling. It sports a modular frame that can also accommodate a bench seat or rear cargo rack that supports up to 35KG of weight. The different seats can be easily swapped out without extra tools. Instead, a button on the bike’s touchscreen display controls a latching mechanism that releases the seat. It only comes in one frame size, but Also says it should be able to adapt to \"multiple body sizes,” thanks to different seat sizes and styles. The bench seat for the TM-B.Karissa Bell for EngadgetThe removable USB-C battery comes in two sizes: standard, which can power up to 60 miles of riding, and large, which maxes out at 100 miles of range. When you’re not riding, the batteries can also be used as a large external battery pack.In terms of power, the TM-B’s throttle tops out at 20MPH though the bike can reach speeds up to 28MPH with added pedaling. Also is taking an interesting approach to its drive system, with a setup it's labeled \"DreamRide.\" Instead of a mechanical connection between the bike's rear wheel and the pedals, the TM-B uses \"software-defined pedaling,\" In practice, this means that you pedaling is actually feeding the generator that powers the bike’s battery rather than directly pushing you forward. However, an Also rep told me that there is also a “limp mode” for when the bike runs out of juice so riders won’t get stranded. In those situations, pedaling will give the bike enough juice to hopefully get you to a spot where you can recharge.Also has envisioned the TM-B in a lot of scenarios, many of which involve hauling a lot of cargo.Karissa Bell for EngadgetSoftware-controlled pedaling probably won’t appeal to purists, but Also says it enables a much more customizable riding experience. When in auto mode, the bike will adapt to the speed you’re pedaling, though you can push on the throttle to get a boost. There’s also a manual mode that lets you select a “gear” (these are also software-controlled). It also uses regenerative braking, so tapping on the brakes helps recharge the battery. Though in my short test ride I found that I didn’t need to use the brakes much, because when I stopped pedaling the bike slowed down pretty quickly, kind of like taking your foot off the accelerator in an EV.The Also app and Portal display.AlsoGiven the bike's roots at Rivian, it's not surprising that there are also a bunch of other tech-enabled features, including a 5-inch touchscreen display, called \"Portal,\" that supports navigation, music playback and calling features via an accompanying app. There’s also a built-in security system that automatically locks the frame and rear wheel when you walk away. On the handlebars, there are customizable controls that can be used to adjust the volume and music playback, answer calls or navigate through display. Customizable controls on the left side fo the handlebar and a throttle on the right.Karissa Bell for EngadgetAlso is selling the TM-B in three configurations. The first to ship next spring will be the $4,500 TM-B Limited Launch Edition, which has a range up to 100 miles, support for standard and sport ride modes and features transparent purple accents. The $4,500 TM-B Performance has the same features as the limited edition model, but has a slightly different color scheme, and will be available within the \"first half\" of 2026. Finally, there's a base-level TM-B model with a range of up to 60 miles that only comes with standard ride modes. Also hasn't announced an exact price, but says it will cost less than $4,000 when it ships \"later in 2026.\" Pre-orders for the Launch Edition are open now and the other two bikes are available to reserve with a $50 deposit. The bikes will also be on display in Rivian showrooms later this year,Also's quad for commercial uses cases (left) and a smaller quad for families (right).AlsoThe company also previewed two electric, pedal-assisted quads it's calling TM-Q. The smaller quad is apparently meant for \"families and individuals seeking a safe, compact alternative to cars\" that can still haul “significant loads.” The larger TM-Q, on the other hand, is meant for commercial deliveries. Also has partnered with Amazon to develop fleets of such vehicles that can be used by delivery drivers. Both quads are intended to be used in bike lanes, according to Also. Also will partner with Amazon for a Prime-branded TM-Q.Karissa Bell for EngadgetThe company didn't share details about when these vehicles might be available or how much they'll cost. Update, October 22, 2025, 2:29PM PT: Added more details and photos from Also’s launch event.This article originally appeared on Engadget at https://www.engadget.com/transportation/the-first-e-bike-from-rivian-spinoff-also-has-a-virtual-drivetrain-173000250.html?src=rss",
          "content": "Ever since Rivian spun off its \"micromobility business\" into a standalone startup called Also earlier this year, there's been much speculation about what kind of vehicles the company is working on. Now, Also is showing off its first products: a lineup of e-bikes and two pedal-assisted electric quads. The TM-B e-bike is Also's attempt at a do-it-all e-bike that can adapt to different use cases whether that's daily commuting, trail riding or kid and cargo-hauling. It sports a modular frame that can also accommodate a bench seat or rear cargo rack that supports up to 35KG of weight. The different seats can be easily swapped out without extra tools. Instead, a button on the bike’s touchscreen display controls a latching mechanism that releases the seat. It only comes in one frame size, but Also says it should be able to adapt to \"multiple body sizes,” thanks to different seat sizes and styles. The bench seat for the TM-B.Karissa Bell for EngadgetThe removable USB-C battery comes in two sizes: standard, which can power up to 60 miles of riding, and large, which maxes out at 100 miles of range. When you’re not riding, the batteries can also be used as a large external battery pack.In terms of power, the TM-B’s throttle tops out at 20MPH though the bike can reach speeds up to 28MPH with added pedaling. Also is taking an interesting approach to its drive system, with a setup it's labeled \"DreamRide.\" Instead of a mechanical connection between the bike's rear wheel and the pedals, the TM-B uses \"software-defined pedaling,\" In practice, this means that you pedaling is actually feeding the generator that powers the bike’s battery rather than directly pushing you forward. However, an Also rep told me that there is also a “limp mode” for when the bike runs out of juice so riders won’t get stranded. In those situations, pedaling will give the bike enough juice to hopefully get you to a spot where you can recharge.Also has envisioned the TM-B in a lot of scenarios, many of which involve hauling a lot of cargo.Karissa Bell for EngadgetSoftware-controlled pedaling probably won’t appeal to purists, but Also says it enables a much more customizable riding experience. When in auto mode, the bike will adapt to the speed you’re pedaling, though you can push on the throttle to get a boost. There’s also a manual mode that lets you select a “gear” (these are also software-controlled). It also uses regenerative braking, so tapping on the brakes helps recharge the battery. Though in my short test ride I found that I didn’t need to use the brakes much, because when I stopped pedaling the bike slowed down pretty quickly, kind of like taking your foot off the accelerator in an EV.The Also app and Portal display.AlsoGiven the bike's roots at Rivian, it's not surprising that there are also a bunch of other tech-enabled features, including a 5-inch touchscreen display, called \"Portal,\" that supports navigation, music playback and calling features via an accompanying app. There’s also a built-in security system that automatically locks the frame and rear wheel when you walk away. On the handlebars, there are customizable controls that can be used to adjust the volume and music playback, answer calls or navigate through display. Customizable controls on the left side fo the handlebar and a throttle on the right.Karissa Bell for EngadgetAlso is selling the TM-B in three configurations. The first to ship next spring will be the $4,500 TM-B Limited Launch Edition, which has a range up to 100 miles, support for standard and sport ride modes and features transparent purple accents. The $4,500 TM-B Performance has the same features as the limited edition model, but has a slightly different color scheme, and will be available within the \"first half\" of 2026. Finally, there's a base-level TM-B model with a range of up to 60 miles that only comes with standard ride modes. Also hasn't announced an exact price, but says it will cost less than $4,000 when it ships \"later in 2026.\" Pre-orders for the Launch Edition are open now and the other two bikes are available to reserve with a $50 deposit. The bikes will also be on display in Rivian showrooms later this year,Also's quad for commercial uses cases (left) and a smaller quad for families (right).AlsoThe company also previewed two electric, pedal-assisted quads it's calling TM-Q. The smaller quad is apparently meant for \"families and individuals seeking a safe, compact alternative to cars\" that can still haul “significant loads.” The larger TM-Q, on the other hand, is meant for commercial deliveries. Also has partnered with Amazon to develop fleets of such vehicles that can be used by delivery drivers. Both quads are intended to be used in bike lanes, according to Also. Also will partner with Amazon for a Prime-branded TM-Q.Karissa Bell for EngadgetThe company didn't share details about when these vehicles might be available or how much they'll cost. Update, October 22, 2025, 2:29PM PT: Added more details and photos from Also’s launch event.This article originally appeared on Engadget at https://www.engadget.com/transportation/the-first-e-bike-from-rivian-spinoff-also-has-a-virtual-drivetrain-173000250.html?src=rss",
          "feed_position": 33,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/tmb_seat_swap.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/google-gemini-will-arrive-in-gm-cars-starting-next-year-181249237.html",
          "published_at": "Wed, 22 Oct 2025 18:12:50 +0000",
          "title": "Google Gemini will arrive in GM cars starting next year",
          "standfirst": "Google Gemini is coming to GM vehicles in 2026. The company will be integrating a conversational AI assistant powered by Google's platform into many of its cars, trucks and SUVs. GM says this assistant will be able to access vehicle data to suss out maintenance concerns, alerting the driver when necessary. The company also promises it'll be able to help plan routes and explain various features of the car. It should also be able to do stuff like turn on the heat or air conditioning, even before entering the vehicle. This will replace the \"Google built-in\" operating system that already exists in many GM vehicles. This OS already offers access to stuff like Google Maps, Google Assistant and related apps. The upcoming Gemini-based chat assistant will do the same type of things, but it should perform better. “One of the challenges with current voice assistants is that, if you’ve used the, you’ve probably also been frustrated by them because they’re trained on certain code words or they don’t understand accents very well or if you don’t say it quite right, you don’t get the right response,” GM VP Dave Richardson told TechCrunch. “What’s great about large language models is they don’t seem to be affected by that.\" One brand-new feature that Gemini will bring to the table is web integration. This will let drivers ask the chatbot questions pertaining to geographic location and the like. GM gives an example of someone asking about the history of a bridge they are passing over. The Gemini assistant will be available via the Play Store after launch as an over-the-air upgrade to Onstar-equipped vehicles. It won't be limited to newer releases, as GM says it'll work with vehicles from the model year 2015 and above. The company also says it's working on its own AI chatbot that has been \"custom-built for your vehicle.\" There's no timetable on that one. GM ran into hot water recently when it was found that it had been selling some customer information sourced from its OnStar Smart Driver program to insurance companies without user consent. This led to the FTC banning the company from selling any driver data for five years. Richardson says the Gemini integration will be privacy-focused and the software will let drivers control what information it can access and use. GM The company made these announcements at the GM Forward media event, where it also discussed other forthcoming initiatives. It has scheduled a rollout of its self-driving platform for 2028. It's also developing its own computing platform, also launching in 2028. This does mean that GM will be sunsetting integration with Apple CarPlay and Android Auto. This software will be phased out over the next few years. This article originally appeared on Engadget at https://www.engadget.com/transportation/google-gemini-will-arrive-in-gm-cars-starting-next-year-181249237.html?src=rss",
          "content": "Google Gemini is coming to GM vehicles in 2026. The company will be integrating a conversational AI assistant powered by Google's platform into many of its cars, trucks and SUVs. GM says this assistant will be able to access vehicle data to suss out maintenance concerns, alerting the driver when necessary. The company also promises it'll be able to help plan routes and explain various features of the car. It should also be able to do stuff like turn on the heat or air conditioning, even before entering the vehicle. This will replace the \"Google built-in\" operating system that already exists in many GM vehicles. This OS already offers access to stuff like Google Maps, Google Assistant and related apps. The upcoming Gemini-based chat assistant will do the same type of things, but it should perform better. “One of the challenges with current voice assistants is that, if you’ve used the, you’ve probably also been frustrated by them because they’re trained on certain code words or they don’t understand accents very well or if you don’t say it quite right, you don’t get the right response,” GM VP Dave Richardson told TechCrunch. “What’s great about large language models is they don’t seem to be affected by that.\" One brand-new feature that Gemini will bring to the table is web integration. This will let drivers ask the chatbot questions pertaining to geographic location and the like. GM gives an example of someone asking about the history of a bridge they are passing over. The Gemini assistant will be available via the Play Store after launch as an over-the-air upgrade to Onstar-equipped vehicles. It won't be limited to newer releases, as GM says it'll work with vehicles from the model year 2015 and above. The company also says it's working on its own AI chatbot that has been \"custom-built for your vehicle.\" There's no timetable on that one. GM ran into hot water recently when it was found that it had been selling some customer information sourced from its OnStar Smart Driver program to insurance companies without user consent. This led to the FTC banning the company from selling any driver data for five years. Richardson says the Gemini integration will be privacy-focused and the software will let drivers control what information it can access and use. GM The company made these announcements at the GM Forward media event, where it also discussed other forthcoming initiatives. It has scheduled a rollout of its self-driving platform for 2028. It's also developing its own computing platform, also launching in 2028. This does mean that GM will be sunsetting integration with Apple CarPlay and Android Auto. This software will be phased out over the next few years. This article originally appeared on Engadget at https://www.engadget.com/transportation/google-gemini-will-arrive-in-gm-cars-starting-next-year-181249237.html?src=rss",
          "feed_position": 38,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/adf23380-af6e-11f0-975e-b59d7cbc084f"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-vpn-deals-120056041.html",
          "published_at": "Wed, 22 Oct 2025 17:34:34 +0000",
          "title": "The best VPN deals: Get up to 88 percent off ProtonVPN, ExpressVPN, Surfshark and more",
          "standfirst": "A virtual private network (VPN) is useful in lots of ways every day, whether you're streaming foreign TV shows or keeping yourself anonymous online so advertisers can't track you. But while we strongly recommend using a VPN, it pays to do some research before investing in one — pricing can be opaque for these services, and you can't always trust how the providers portray their best deals. Even so, there are genuinely great deals to be had. VPN providers love to give out deep discounts to anybody willing to sign up for a year or more at once. This means you've got to pay out more upfront, but if you divide the cost by the months of service, you're actually paying less per month over time. With deals like this, VPN providers boost their subscriber numbers, and you get heavy price cuts on some of our favorite services. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-vpn-deals-120056041.html?src=rss",
          "content": "A virtual private network (VPN) is useful in lots of ways every day, whether you're streaming foreign TV shows or keeping yourself anonymous online so advertisers can't track you. But while we strongly recommend using a VPN, it pays to do some research before investing in one — pricing can be opaque for these services, and you can't always trust how the providers portray their best deals. Even so, there are genuinely great deals to be had. VPN providers love to give out deep discounts to anybody willing to sign up for a year or more at once. This means you've got to pay out more upfront, but if you divide the cost by the months of service, you're actually paying less per month over time. With deals like this, VPN providers boost their subscriber numbers, and you get heavy price cuts on some of our favorite services. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-vpn-deals-120056041.html?src=rss",
          "feed_position": 39
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/samsung-galaxy-xr-everything-you-need-to-know-111532664.html",
          "published_at": "Wed, 22 Oct 2025 15:58:59 +0000",
          "title": "Samsung Galaxy XR: Everything you need to know",
          "standfirst": "With Galaxy XR, you can split screen between a game like Stardew Valley and a real-time video chat.Samsung After dropping hints for over two years, Samsung, in partnership with Google, finally revealed its first-ever Android extended reality headset Tuesday night. The new device, dubbed Galaxy XR, will run you $1,800 and you can actually buy it today. Due to its collaboration with Google, it's not a surprise that the headset comes fully equipped with Gemini AI built in. \"Android XR is the first Android platform built entirely for the Gemini era, and we are incredibly excited to take a significant leap forward today with the launch of Galaxy XR,\" Sameer Samat, President of Android Ecosystem at Google, said. What are the features of the Galaxy XR headset, and how does it differ from its main competitor, the $3,499 Apple Vision Pro? Glad you asked! What is the Galaxy XR? The Samsung Galaxy XR is the first-ever Android XR headset, created by Google and Samsung. If Apple's Vision Pro is the \"virtual reality iPhone,\" the Samsung is basically its \"virtual reality Galaxy S phone\" alternative. The headset looks like a pair of snowboard goggles, but it comes with a whopping total of 12 cameras and six microphones. And because it's 2025, AI is a big part of the Galaxy XR's upsell: It has Google's Gemini AI assistant built in, so while you're wearing the headset, it can see and hear everything around you. Google's \"XR\" designation stands for \"extended reality,\" which is effectively an \"all of the above\" term encompassing augmented reality (AR), virtual reality (VR) and mixed reality. That means the Galaxy XR can put a virtual overlay on the real world (thanks to all those cameras), or it can completely shut out your space to immerse you in a totally virtual environment. In other words, you can customize your own workspace or turn your room into your own personal theater, or you can transport yourself to an international locale with a first-person \"you are there\" viewpoint. What can you do with the Galaxy XR? For watching videos on apps like YouTube, the headset offers a library of 180- and 360-degree VR content. You can also watch movies using Google TV on a large, resizable screen. Plus, if you have a question about whatever you're watching, you can ask Gemini since it sees everything you see. And when you're looking at your photos and videos, you can convert them to 3D so it feels like you're back in the memory. While using Google Maps, you can use Immersive View to go anywhere in the world (virtually, of course). Visiting somewhere historical? You can ask Gemini to tell you more information about the landmark. Spot a weird-looking plant or bug around your house? You can use Circle to Search to find out what it is while wearing the headset. The Immersive View feature of Google Maps lets Galaxy XR users zoom across cityscapes.Samsung As for getting work done efficiently, you can arrange your most-needed apps all around your screen — for instance, your web browser, favorite music app, important documents and video conferencing app. And if things start to feel cluttered, you can ask Gemini to organize your windows. Even better, you can link your PC to your headset, as well as your keyboard and mouse. The headset uses two passthrough cameras for real-time viewing, six world-facing tracking cameras and four eye-tracking cameras, as well as depth and flicker sensors. It also supports iris recognition so you can unlock the device and enter passwords within some apps. What apps work on the Galaxy XR? \"Almost all\" Google Play Store apps will be available on the Galaxy XR headset. That means hundreds of thousands of apps should be available on the headset on day one, including basic streaming apps (for watching things like Netflix, HBO Max or Peacock on that giant virtual display) as well as \"new versions\" of some of Google's key first-party software, from Photos to Chrome and YouTube. And, of course, the aforementioned Google Maps is on board, too. Using the Galaxy XR as a PC monitor, you can stream in a game -- such as this \"Assassin's Creed\" tile -- from an external source. Samsung As you'd expect, Google is also focusing on gaming. In addition to the full panoply of Android games, the Galaxy XR's PC Link also lets you use it as a monitor for PC-based games, too. How does it feel to wear the Galaxy XR? Engadget Senior Reporter Sam Rutherford wearing the Samsung Galaxy XR headset. Sam Rutherford for Engadget Engadget's Sam Rutherford got some hands-on time with the Galaxy XR recently, and had some notable first impressions on its comfort and usability: [I]t seems Samsung learned a lot from its rivals by including a much larger and thicker head cushion that helps distribute the weight of the headset more evenly. Granted, during a longer session, I still noticed a bit of pressure and felt relief after taking off the Galaxy XR, but it's nothing like the Vision Pro, which in my experience gets uncomfortable almost immediately. Finally, around back, there's a simple strap with a knob that you can twist to tighten or loosen the headband as necessary. So even without extra support running across the top of your head, getting in and out of the Galaxy XR is much easier and comfier than the Vision Pro. How is the Galaxy XR different from the Apple Vision Pro? While the headset may look pretty similar to the Apple Vision Pro, there are some bigger (and even better) differences. For starters, the Galaxy's micro-OLED display has 29 million pixels, compared to Apple's 23 million pixels, and a resolution of 3,552 x 3,840, which offers a tad more detail than Apple's model. Additionally, it has 96% of the DCI‑P3 color gamut, while the Vision Pro has 92%. However, Apple's headset beats out the Samsung on refresh rate, going a full 120Hz versus the Galaxy XR's 90Hz. Since you'll be wearing it on your head for an extended period, you'll be relieved to know the Galaxy XR is a bit lighter than Apple's XR headset by 205g (0.5lbs). On the battery life front, Samsung is pledging up to two hours of \"general use\" and 2.5 hours of video playback, whereas the new M5 Vision Pro runs 30 minutes longer in both modes, per Apple. Besides the obvious operating system differences, of course, the aforementioned price delta is perhaps the biggest advantage Samsung has over the Apple model: At $1,800, you can get almost two full Galaxy XR units for every $3,499 Apple Vision Pro. How do I order the Samsung Galaxy XR? Sam Rutherford for Engadget You can order the Galaxy XR now via Samsung. While that $1,800 price tag is formidable, Samsung is offering financing options. And the headset's price is actually less than that of Samsung's flagship Galaxy Z Fold 7 foldable phone. Key accessories like the Travel Case and Galaxy XR Controller usually cost $250 each, though both can be bundled in for $175 apiece. There are additional incentives, too. For anyone buying the Galaxy XR before the end of the year, Samsung is throwing in the \"Explorer Pack\" at no extra charge. That includes a year's worth of Google AI Pro, YouTube Premium (including YouTube Music) and Google Play Pass; access to the new season of NBA League Pass; and access to the NFL Pro Era game, the Asteroid and Calm apps and Adobe's Project Pulsar, a 3D compositing app. Update, 11:58AM ET: Upon original publication, one instance of the price listed in this story was inaccurate because of a typo. It now correctly reflects the $1,800 price. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-galaxy-xr-everything-you-need-to-know-111532664.html?src=rss",
          "content": "With Galaxy XR, you can split screen between a game like Stardew Valley and a real-time video chat.Samsung After dropping hints for over two years, Samsung, in partnership with Google, finally revealed its first-ever Android extended reality headset Tuesday night. The new device, dubbed Galaxy XR, will run you $1,800 and you can actually buy it today. Due to its collaboration with Google, it's not a surprise that the headset comes fully equipped with Gemini AI built in. \"Android XR is the first Android platform built entirely for the Gemini era, and we are incredibly excited to take a significant leap forward today with the launch of Galaxy XR,\" Sameer Samat, President of Android Ecosystem at Google, said. What are the features of the Galaxy XR headset, and how does it differ from its main competitor, the $3,499 Apple Vision Pro? Glad you asked! What is the Galaxy XR? The Samsung Galaxy XR is the first-ever Android XR headset, created by Google and Samsung. If Apple's Vision Pro is the \"virtual reality iPhone,\" the Samsung is basically its \"virtual reality Galaxy S phone\" alternative. The headset looks like a pair of snowboard goggles, but it comes with a whopping total of 12 cameras and six microphones. And because it's 2025, AI is a big part of the Galaxy XR's upsell: It has Google's Gemini AI assistant built in, so while you're wearing the headset, it can see and hear everything around you. Google's \"XR\" designation stands for \"extended reality,\" which is effectively an \"all of the above\" term encompassing augmented reality (AR), virtual reality (VR) and mixed reality. That means the Galaxy XR can put a virtual overlay on the real world (thanks to all those cameras), or it can completely shut out your space to immerse you in a totally virtual environment. In other words, you can customize your own workspace or turn your room into your own personal theater, or you can transport yourself to an international locale with a first-person \"you are there\" viewpoint. What can you do with the Galaxy XR? For watching videos on apps like YouTube, the headset offers a library of 180- and 360-degree VR content. You can also watch movies using Google TV on a large, resizable screen. Plus, if you have a question about whatever you're watching, you can ask Gemini since it sees everything you see. And when you're looking at your photos and videos, you can convert them to 3D so it feels like you're back in the memory. While using Google Maps, you can use Immersive View to go anywhere in the world (virtually, of course). Visiting somewhere historical? You can ask Gemini to tell you more information about the landmark. Spot a weird-looking plant or bug around your house? You can use Circle to Search to find out what it is while wearing the headset. The Immersive View feature of Google Maps lets Galaxy XR users zoom across cityscapes.Samsung As for getting work done efficiently, you can arrange your most-needed apps all around your screen — for instance, your web browser, favorite music app, important documents and video conferencing app. And if things start to feel cluttered, you can ask Gemini to organize your windows. Even better, you can link your PC to your headset, as well as your keyboard and mouse. The headset uses two passthrough cameras for real-time viewing, six world-facing tracking cameras and four eye-tracking cameras, as well as depth and flicker sensors. It also supports iris recognition so you can unlock the device and enter passwords within some apps. What apps work on the Galaxy XR? \"Almost all\" Google Play Store apps will be available on the Galaxy XR headset. That means hundreds of thousands of apps should be available on the headset on day one, including basic streaming apps (for watching things like Netflix, HBO Max or Peacock on that giant virtual display) as well as \"new versions\" of some of Google's key first-party software, from Photos to Chrome and YouTube. And, of course, the aforementioned Google Maps is on board, too. Using the Galaxy XR as a PC monitor, you can stream in a game -- such as this \"Assassin's Creed\" tile -- from an external source. Samsung As you'd expect, Google is also focusing on gaming. In addition to the full panoply of Android games, the Galaxy XR's PC Link also lets you use it as a monitor for PC-based games, too. How does it feel to wear the Galaxy XR? Engadget Senior Reporter Sam Rutherford wearing the Samsung Galaxy XR headset. Sam Rutherford for Engadget Engadget's Sam Rutherford got some hands-on time with the Galaxy XR recently, and had some notable first impressions on its comfort and usability: [I]t seems Samsung learned a lot from its rivals by including a much larger and thicker head cushion that helps distribute the weight of the headset more evenly. Granted, during a longer session, I still noticed a bit of pressure and felt relief after taking off the Galaxy XR, but it's nothing like the Vision Pro, which in my experience gets uncomfortable almost immediately. Finally, around back, there's a simple strap with a knob that you can twist to tighten or loosen the headband as necessary. So even without extra support running across the top of your head, getting in and out of the Galaxy XR is much easier and comfier than the Vision Pro. How is the Galaxy XR different from the Apple Vision Pro? While the headset may look pretty similar to the Apple Vision Pro, there are some bigger (and even better) differences. For starters, the Galaxy's micro-OLED display has 29 million pixels, compared to Apple's 23 million pixels, and a resolution of 3,552 x 3,840, which offers a tad more detail than Apple's model. Additionally, it has 96% of the DCI‑P3 color gamut, while the Vision Pro has 92%. However, Apple's headset beats out the Samsung on refresh rate, going a full 120Hz versus the Galaxy XR's 90Hz. Since you'll be wearing it on your head for an extended period, you'll be relieved to know the Galaxy XR is a bit lighter than Apple's XR headset by 205g (0.5lbs). On the battery life front, Samsung is pledging up to two hours of \"general use\" and 2.5 hours of video playback, whereas the new M5 Vision Pro runs 30 minutes longer in both modes, per Apple. Besides the obvious operating system differences, of course, the aforementioned price delta is perhaps the biggest advantage Samsung has over the Apple model: At $1,800, you can get almost two full Galaxy XR units for every $3,499 Apple Vision Pro. How do I order the Samsung Galaxy XR? Sam Rutherford for Engadget You can order the Galaxy XR now via Samsung. While that $1,800 price tag is formidable, Samsung is offering financing options. And the headset's price is actually less than that of Samsung's flagship Galaxy Z Fold 7 foldable phone. Key accessories like the Travel Case and Galaxy XR Controller usually cost $250 each, though both can be bundled in for $175 apiece. There are additional incentives, too. For anyone buying the Galaxy XR before the end of the year, Samsung is throwing in the \"Explorer Pack\" at no extra charge. That includes a year's worth of Google AI Pro, YouTube Premium (including YouTube Music) and Google Play Pass; access to the new season of NBA League Pass; and access to the NFL Pro Era game, the Asteroid and Calm apps and Adobe's Project Pulsar, a 3D compositing app. Update, 11:58AM ET: Upon original publication, one instance of the price listed in this story was inaccurate because of a typo. It now correctly reflects the $1,800 price. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-galaxy-xr-everything-you-need-to-know-111532664.html?src=rss",
          "feed_position": 46,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/7dee0e70-aef1-11f0-adfa-613ea884712c"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/kai-fu-lees-brutal-assessment-america-is-already-losing-the-ai-hardware-war",
          "published_at": "Wed, 22 Oct 2025 12:30:00 GMT",
          "title": "Kai-Fu Lee's brutal assessment: America is already losing the AI hardware war to China",
          "standfirst": "China is on track to dominate consumer artificial intelligence applications and robotics manufacturing within years, but the United States will maintain its substantial lead in enterprise AI adoption and cutting-edge research, according to Kai-Fu Lee, one of the world&#x27;s most prominent AI scientists and investors.In a rare, unvarnished assessment delivered via video link from Beijing to the TED AI conference in San Francisco Tuesday, Lee — a former executive at Apple, Microsoft, and Google who now runs both a major venture capital firm and his own AI company — laid out a technology landscape splitting along geographic and economic lines, with profound implications for both commercial competition and national security.\"China&#x27;s robotics has the advantage of having integrated AI into much lower costs, better supply chain and fast turnaround, so companies like Unitree are actually the farthest ahead in the world in terms of building affordable, embodied humanoid AI,\" Lee said, referring to a Chinese robotics manufacturer that has undercut Western competitors on price while advancing capabilities.The comments, made to a room filled with Silicon Valley executives, investors, and researchers, represented one of the most detailed public assessments from Lee about the comparative strengths and weaknesses of the world&#x27;s two AI superpowers — and suggested that the race for artificial intelligence leadership is becoming less a single contest than a series of parallel competitions with different winners.Why venture capital is flowing in opposite directions in the U.S. and ChinaAt the heart of Lee&#x27;s analysis lies a fundamental difference in how capital flows in the two countries&#x27; innovation ecosystems. American venture capitalists, Lee said, are pouring money into generative AI companies building large language models and enterprise software, while Chinese investors are betting heavily on robotics and hardware.\"The VCs in the US don&#x27;t fund robotics the way the VCs do in China,\" Lee said. \"Just like the VCs in China don&#x27;t fund generative AI the way the VCs do in the US.\"This investment divergence reflects different economic incentives and market structures. In the United States, where companies have grown accustomed to paying for software subscriptions and where labor costs are high, enterprise AI tools that boost white-collar productivity command premium prices. In China, where software subscription models have historically struggled to gain traction but manufacturing dominates the economy, robotics offers a clearer path to commercialization.The result, Lee suggested, is that each country is pulling ahead in different domains — and may continue to do so.\"China&#x27;s got some challenges to overcome in getting a company funded as well as OpenAI or Anthropic,\" Lee acknowledged, referring to the leading American AI labs. \"But I think U.S., on the flip side, will have trouble developing the investment interest and value creation in the robotics\" sector.Why American companies dominate enterprise AI while Chinese firms struggle with subscriptionsLee was explicit about one area where the United States maintains what appears to be a durable advantage: getting businesses to actually adopt and pay for AI software.\"The enterprise adoption will clearly be led by the United States,\" Lee said. \"The Chinese companies have not yet developed a habit of paying for software on a subscription.\"This seemingly mundane difference in business culture — whether companies will pay monthly fees for software — has become a critical factor in the AI race. The explosion of spending on tools like GitHub Copilot, ChatGPT Enterprise, and other AI-powered productivity software has fueled American companies&#x27; ability to invest billions in further research and development.Lee noted that China has historically overcome similar challenges in consumer technology by developing alternative business models. \"In the early days of internet software, China was also well behind because people weren&#x27;t willing to pay for software,\" he said. \"But then advertising models, e-commerce models really propelled China forward.\"Still, he suggested, someone will need to \"find a new business model that isn&#x27;t just pay per software per use or per month basis. That&#x27;s going to not happen in China anytime soon.\"The implication: American companies building enterprise AI tools have a window — perhaps a substantial one — where they can generate revenue and reinvest in R&D without facing serious Chinese competition in their core market.How ByteDance, Alibaba and Tencent will outpace Meta and Google in consumer AIWhere Lee sees China pulling ahead decisively is in consumer-facing AI applications — the kind embedded in social media, e-commerce, and entertainment platforms that billions of people use daily.\"In terms of consumer usage, that&#x27;s likely to happen,\" Lee said, referring to China matching or surpassing the United States in AI deployment. \"The Chinese giants, like ByteDance and Alibaba and Tencent, will definitely move a lot faster than their equivalent in the United States, companies like Meta, YouTube and so on.\"Lee pointed to a cultural advantage: Chinese technology companies have spent the past decade obsessively optimizing for user engagement and product-market fit in brutally competitive markets. \"The Chinese giants really work tenaciously, and they have mastered the art of figuring out product market fit,\" he said. \"Now they have to add technology to it. So that is inevitably going to happen.\"This assessment aligns with recent industry observations. ByteDance&#x27;s TikTok became the world&#x27;s most downloaded app through sophisticated AI-driven content recommendation, and Chinese companies have pioneered AI-powered features in areas like live-streaming commerce and short-form video that Western companies later copied.Lee also noted that China has already deployed AI more widely in certain domains. \"There are a lot of areas where China has also done a great job, such as using computer vision, speech recognition, and translation more widely,\" he said.The surprising open-source shift that has Chinese models beating Meta&#x27;s LlamaPerhaps Lee&#x27;s most striking data point concerned open-source AI development — an area where China appears to have seized leadership from American companies in a remarkably short time.\"The 10 highest rated open source [models] are from China,\" Lee said. \"These companies have now eclipsed Meta&#x27;s Llama, which used to be number one.\"This represents a significant shift. Meta&#x27;s Llama models were widely viewed as the gold standard for open-source large language models as recently as early 2024. But Chinese companies — including Lee&#x27;s own firm, 01.AI, along with Alibaba, Baidu, and others — have released a flood of open-source models that, according to various benchmarks, now outperform their American counterparts.The open-source question has become a flashpoint in AI development. Lee made an extensive case for why open-source models will prove essential to the technology&#x27;s future, even as closed models from companies like OpenAI command higher prices and, often, superior performance.\"I think open source has a number of major advantages,\" Lee argued. With open-source models, \"you can examine it, tune it, improve it. It&#x27;s yours, and it&#x27;s free, and it&#x27;s important for building if you want to build an application or tune the model to do something specific.\"He drew an analogy to operating systems: \"People who work in operating systems loved Linux, and that&#x27;s why its adoption went through the roof. And I think in the future, open source will also allow people to tune a sovereign model for a country, make it work better for a particular language.\"Still, Lee predicted both approaches will coexist. \"I don&#x27;t think open source models will win,\" he said. \"I think just like we have Apple, which is closed, but provides a somewhat better experience than Android... I think we&#x27;re going to see more apps using open-source models, more engineers wanting to build open-source models, but I think more money will remain in the closed model.\"Why China&#x27;s manufacturing advantage makes the robotics race &#x27;not over, but&#x27; nearly decidedOn robotics, Lee&#x27;s message was blunt: the combination of China&#x27;s manufacturing prowess, lower costs, and aggressive investment has created an advantage that will be difficult for American companies to overcome.When asked directly whether the robotics race was already over with China victorious, Lee hedged only slightly. \"It&#x27;s not over, but I think the U.S. is still capable of coming up with the best robotic research ideas,\" he said. \"But the VCs in the U.S. don&#x27;t fund robotics the way the VCs do in China.\"The challenge is structural. Building robots requires not just software and AI, but hardware manufacturing at scale — precisely the kind of integrated supply chain and low-cost production that China has spent decades perfecting. While American labs at universities and companies like Boston Dynamics continue to produce impressive research prototypes, turning those prototypes into affordable commercial products requires the manufacturing ecosystem that China possesses.Companies like Unitree have demonstrated this advantage concretely. The company&#x27;s humanoid robots and quadrupedal robots cost a fraction of their American-made equivalents while offering comparable or superior capabilities — a price-to-performance ratio that could prove decisive in commercial markets.What worries Lee most: not AGI, but the race itselfDespite his generally measured tone about China&#x27;s AI development, Lee expressed concern about one area where he believes the global AI community faces real danger — not the far-future risk of superintelligent AI, but the near-term consequences of moving too fast.When asked about AGI risks, Lee reframed the question. \"I&#x27;m less afraid of AI becoming self-aware and causing danger for humans in the short term,\" he said, \"but more worried about it being used by bad people to do terrible things, or by the AI race pushing people to work so hard, so fast and furious and move fast and break things that they build products that have problems and holes to be exploited.\"He continued: \"I&#x27;m very worried about that. In fact, I think some terrible event will happen that will be a wake up call from this sort of problem.\"Lee&#x27;s perspective carries unusual weight because of his unique vantage point spanning both Chinese and American AI development. Over a career spanning more than three decades, he has held senior positions at Apple, Microsoft, and Google, while also founding Sinovation Ventures, which has invested in more than 400 companies across both countries. His AI company, 01.AI, founded in 2023, has released several open-source models that rank among the most capable in the world.For American companies and policymakers, Lee&#x27;s analysis presents a complex strategic picture. The United States appears to have clear advantages in enterprise AI software, fundamental research, and computing infrastructure. But China is moving faster in consumer applications, manufacturing robotics at lower costs, and potentially pulling ahead in open-source model development.The bifurcation suggests that rather than a single \"winner\" in AI, the world may be heading toward a technology landscape where different countries excel in different domains — with all the economic and geopolitical complications that implies.As the TED AI conference continued Wednesday, Lee&#x27;s assessment hung over subsequent discussions. His message seemed clear: the AI race is not one contest, but many — and the United States and China are each winning different races.Standing in the conference hall afterward, one venture capitalist, who asked not to be named, summed up the mood in the room: \"We&#x27;re not competing with China anymore. We&#x27;re competing on parallel tracks.\" Whether those tracks eventually converge — or diverge into entirely separate technology ecosystems — may be the defining question of the next decade.",
          "content": "China is on track to dominate consumer artificial intelligence applications and robotics manufacturing within years, but the United States will maintain its substantial lead in enterprise AI adoption and cutting-edge research, according to Kai-Fu Lee, one of the world&#x27;s most prominent AI scientists and investors.In a rare, unvarnished assessment delivered via video link from Beijing to the TED AI conference in San Francisco Tuesday, Lee — a former executive at Apple, Microsoft, and Google who now runs both a major venture capital firm and his own AI company — laid out a technology landscape splitting along geographic and economic lines, with profound implications for both commercial competition and national security.\"China&#x27;s robotics has the advantage of having integrated AI into much lower costs, better supply chain and fast turnaround, so companies like Unitree are actually the farthest ahead in the world in terms of building affordable, embodied humanoid AI,\" Lee said, referring to a Chinese robotics manufacturer that has undercut Western competitors on price while advancing capabilities.The comments, made to a room filled with Silicon Valley executives, investors, and researchers, represented one of the most detailed public assessments from Lee about the comparative strengths and weaknesses of the world&#x27;s two AI superpowers — and suggested that the race for artificial intelligence leadership is becoming less a single contest than a series of parallel competitions with different winners.Why venture capital is flowing in opposite directions in the U.S. and ChinaAt the heart of Lee&#x27;s analysis lies a fundamental difference in how capital flows in the two countries&#x27; innovation ecosystems. American venture capitalists, Lee said, are pouring money into generative AI companies building large language models and enterprise software, while Chinese investors are betting heavily on robotics and hardware.\"The VCs in the US don&#x27;t fund robotics the way the VCs do in China,\" Lee said. \"Just like the VCs in China don&#x27;t fund generative AI the way the VCs do in the US.\"This investment divergence reflects different economic incentives and market structures. In the United States, where companies have grown accustomed to paying for software subscriptions and where labor costs are high, enterprise AI tools that boost white-collar productivity command premium prices. In China, where software subscription models have historically struggled to gain traction but manufacturing dominates the economy, robotics offers a clearer path to commercialization.The result, Lee suggested, is that each country is pulling ahead in different domains — and may continue to do so.\"China&#x27;s got some challenges to overcome in getting a company funded as well as OpenAI or Anthropic,\" Lee acknowledged, referring to the leading American AI labs. \"But I think U.S., on the flip side, will have trouble developing the investment interest and value creation in the robotics\" sector.Why American companies dominate enterprise AI while Chinese firms struggle with subscriptionsLee was explicit about one area where the United States maintains what appears to be a durable advantage: getting businesses to actually adopt and pay for AI software.\"The enterprise adoption will clearly be led by the United States,\" Lee said. \"The Chinese companies have not yet developed a habit of paying for software on a subscription.\"This seemingly mundane difference in business culture — whether companies will pay monthly fees for software — has become a critical factor in the AI race. The explosion of spending on tools like GitHub Copilot, ChatGPT Enterprise, and other AI-powered productivity software has fueled American companies&#x27; ability to invest billions in further research and development.Lee noted that China has historically overcome similar challenges in consumer technology by developing alternative business models. \"In the early days of internet software, China was also well behind because people weren&#x27;t willing to pay for software,\" he said. \"But then advertising models, e-commerce models really propelled China forward.\"Still, he suggested, someone will need to \"find a new business model that isn&#x27;t just pay per software per use or per month basis. That&#x27;s going to not happen in China anytime soon.\"The implication: American companies building enterprise AI tools have a window — perhaps a substantial one — where they can generate revenue and reinvest in R&D without facing serious Chinese competition in their core market.How ByteDance, Alibaba and Tencent will outpace Meta and Google in consumer AIWhere Lee sees China pulling ahead decisively is in consumer-facing AI applications — the kind embedded in social media, e-commerce, and entertainment platforms that billions of people use daily.\"In terms of consumer usage, that&#x27;s likely to happen,\" Lee said, referring to China matching or surpassing the United States in AI deployment. \"The Chinese giants, like ByteDance and Alibaba and Tencent, will definitely move a lot faster than their equivalent in the United States, companies like Meta, YouTube and so on.\"Lee pointed to a cultural advantage: Chinese technology companies have spent the past decade obsessively optimizing for user engagement and product-market fit in brutally competitive markets. \"The Chinese giants really work tenaciously, and they have mastered the art of figuring out product market fit,\" he said. \"Now they have to add technology to it. So that is inevitably going to happen.\"This assessment aligns with recent industry observations. ByteDance&#x27;s TikTok became the world&#x27;s most downloaded app through sophisticated AI-driven content recommendation, and Chinese companies have pioneered AI-powered features in areas like live-streaming commerce and short-form video that Western companies later copied.Lee also noted that China has already deployed AI more widely in certain domains. \"There are a lot of areas where China has also done a great job, such as using computer vision, speech recognition, and translation more widely,\" he said.The surprising open-source shift that has Chinese models beating Meta&#x27;s LlamaPerhaps Lee&#x27;s most striking data point concerned open-source AI development — an area where China appears to have seized leadership from American companies in a remarkably short time.\"The 10 highest rated open source [models] are from China,\" Lee said. \"These companies have now eclipsed Meta&#x27;s Llama, which used to be number one.\"This represents a significant shift. Meta&#x27;s Llama models were widely viewed as the gold standard for open-source large language models as recently as early 2024. But Chinese companies — including Lee&#x27;s own firm, 01.AI, along with Alibaba, Baidu, and others — have released a flood of open-source models that, according to various benchmarks, now outperform their American counterparts.The open-source question has become a flashpoint in AI development. Lee made an extensive case for why open-source models will prove essential to the technology&#x27;s future, even as closed models from companies like OpenAI command higher prices and, often, superior performance.\"I think open source has a number of major advantages,\" Lee argued. With open-source models, \"you can examine it, tune it, improve it. It&#x27;s yours, and it&#x27;s free, and it&#x27;s important for building if you want to build an application or tune the model to do something specific.\"He drew an analogy to operating systems: \"People who work in operating systems loved Linux, and that&#x27;s why its adoption went through the roof. And I think in the future, open source will also allow people to tune a sovereign model for a country, make it work better for a particular language.\"Still, Lee predicted both approaches will coexist. \"I don&#x27;t think open source models will win,\" he said. \"I think just like we have Apple, which is closed, but provides a somewhat better experience than Android... I think we&#x27;re going to see more apps using open-source models, more engineers wanting to build open-source models, but I think more money will remain in the closed model.\"Why China&#x27;s manufacturing advantage makes the robotics race &#x27;not over, but&#x27; nearly decidedOn robotics, Lee&#x27;s message was blunt: the combination of China&#x27;s manufacturing prowess, lower costs, and aggressive investment has created an advantage that will be difficult for American companies to overcome.When asked directly whether the robotics race was already over with China victorious, Lee hedged only slightly. \"It&#x27;s not over, but I think the U.S. is still capable of coming up with the best robotic research ideas,\" he said. \"But the VCs in the U.S. don&#x27;t fund robotics the way the VCs do in China.\"The challenge is structural. Building robots requires not just software and AI, but hardware manufacturing at scale — precisely the kind of integrated supply chain and low-cost production that China has spent decades perfecting. While American labs at universities and companies like Boston Dynamics continue to produce impressive research prototypes, turning those prototypes into affordable commercial products requires the manufacturing ecosystem that China possesses.Companies like Unitree have demonstrated this advantage concretely. The company&#x27;s humanoid robots and quadrupedal robots cost a fraction of their American-made equivalents while offering comparable or superior capabilities — a price-to-performance ratio that could prove decisive in commercial markets.What worries Lee most: not AGI, but the race itselfDespite his generally measured tone about China&#x27;s AI development, Lee expressed concern about one area where he believes the global AI community faces real danger — not the far-future risk of superintelligent AI, but the near-term consequences of moving too fast.When asked about AGI risks, Lee reframed the question. \"I&#x27;m less afraid of AI becoming self-aware and causing danger for humans in the short term,\" he said, \"but more worried about it being used by bad people to do terrible things, or by the AI race pushing people to work so hard, so fast and furious and move fast and break things that they build products that have problems and holes to be exploited.\"He continued: \"I&#x27;m very worried about that. In fact, I think some terrible event will happen that will be a wake up call from this sort of problem.\"Lee&#x27;s perspective carries unusual weight because of his unique vantage point spanning both Chinese and American AI development. Over a career spanning more than three decades, he has held senior positions at Apple, Microsoft, and Google, while also founding Sinovation Ventures, which has invested in more than 400 companies across both countries. His AI company, 01.AI, founded in 2023, has released several open-source models that rank among the most capable in the world.For American companies and policymakers, Lee&#x27;s analysis presents a complex strategic picture. The United States appears to have clear advantages in enterprise AI software, fundamental research, and computing infrastructure. But China is moving faster in consumer applications, manufacturing robotics at lower costs, and potentially pulling ahead in open-source model development.The bifurcation suggests that rather than a single \"winner\" in AI, the world may be heading toward a technology landscape where different countries excel in different domains — with all the economic and geopolitical complications that implies.As the TED AI conference continued Wednesday, Lee&#x27;s assessment hung over subsequent discussions. His message seemed clear: the AI race is not one contest, but many — and the United States and China are each winning different races.Standing in the conference hall afterward, one venture capitalist, who asked not to be named, summed up the mood in the room: \"We&#x27;re not competing with China anymore. We&#x27;re competing on parallel tracks.\" Whether those tracks eventually converge — or diverge into entirely separate technology ecosystems — may be the defining question of the next decade.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/ayDtsYfCFDVHHKnTvWKwk/04173bcfce3f9d53ecd9fe3ecfd14d5c/nuneybits_Vector_art_of_Chinese_flag-coded_AI_chip_6c9fcafc-8614-4d3b-858f-d64bede8c2df.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/simplifying-the-ai-stack-the-key-to-scalable-portable-intelligence-from",
          "published_at": "Wed, 22 Oct 2025 04:00:00 GMT",
          "title": "Simplifying the AI stack: The key to scalable, portable intelligence from cloud to edge",
          "standfirst": "Presented by ArmA simpler software stack is the key to portable, scalable AI across cloud and edge. AI is now powering real-world applications, yet fragmented software stacks are holding it back. Developers routinely rebuild the same models for different hardware targets, losing time to glue code instead of shipping features. The good news is that a shift is underway. Unified toolchains and optimized libraries are making it possible to deploy models across platforms without compromising performance.Yet one critical hurdle remains: software complexity. Disparate tools, hardware-specific optimizations, and layered tech stacks continue to bottleneck progress. To unlock the next wave of AI innovation, the industry must pivot decisively away from siloed development and toward streamlined, end-to-end platforms.This transformation is already taking shape. Major cloud providers, edge platform vendors, and open-source communities are converging on unified toolchains that simplify development and accelerate deployment, from cloud to edge. In this article, we’ll explore why simplification is the key to scalable AI, what’s driving this momentum, and how next-gen platforms are turning that vision into real-world results.The bottleneck: fragmentation, complexity, and inefficiencyThe issue isn’t just hardware variety; it’s duplicated effort across frameworks and targets that slows time-to-value.Diverse hardware targets: GPUs, NPUs, CPU-only devices, mobile SoCs, and custom accelerators.Tooling and framework fragmentation: TensorFlow, PyTorch, ONNX, MediaPipe, and others.Edge constraints: Devices require real-time, energy-efficient performance with minimal overhead.According to Gartner Research, these mismatches create a key hurdle: over 60% of AI initiatives stall before production, driven by integration complexity and performance variability. What software simplification looks likeSimplification is coalescing around five moves that cut re-engineering cost and risk:Cross-platform abstraction layers that minimize re-engineering when porting models.Performance-tuned libraries integrated into major ML frameworks.Unified architectural designs that scale from datacenter to mobile.Open standards and runtimes (e.g., ONNX, MLIR) reducing lock-in and improving compatibility.Developer-first ecosystems emphasizing speed, reproducibility, and scalability.These shifts are making AI more accessible, especially for startups and academic teams that previously lacked the resources for bespoke optimization. Projects like Hugging Face’s Optimum and MLPerf benchmarks are also helping standardize and validate cross-hardware performance.Ecosystem momentum and real-world signals Simplification is no longer aspirational; it’s happening now. Across the industry, software considerations are influencing decisions at the IP and silicon design level, resulting in solutions that are production-ready from day one. Major ecosystem players are driving this shift by aligning hardware and software development efforts, delivering tighter integration across the stack.A key catalyst is the rapid rise of edge inference, where AI models are deployed directly on devices rather than in the cloud. This has intensified demand for streamlined software stacks that support end-to-end optimization, from silicon to system to application. Companies like Arm are responding by enabling tighter coupling between their compute platforms and software toolchains, helping developers accelerate time-to-deployment without sacrificing performance or portability. The emergence of multi-modal and general-purpose foundation models (e.g., LLaMA, Gemini, Claude) has also added urgency. These models require flexible runtimes that can scale across cloud and edge environments. AI agents, which interact, adapt, and perform tasks autonomously, further drive the need for high-efficiency, cross-platform software.MLPerf Inference v3.1 included over 13,500 performance results from 26 submitters, validating multi-platform benchmarking of AI workloads. Results spanned both data center and edge devices, demonstrating the diversity of optimized deployments now being tested and shared.Taken together, these signals make clear that the market’s demand and incentives are aligning around a common set of priorities, including maximizing performance-per-watt, ensuring portability, minimizing latency, and delivering security and consistency at scale.What must happen for successful simplificationTo realize the promise of simplified AI platforms, several things must occur:Strong hardware/software co-design: hardware features that are exposed in software frameworks (e.g., matrix multipliers, accelerator instructions), and conversely, software that is designed to take advantage of underlying hardware.Consistent, robust toolchains and libraries: developers need reliable, well-documented libraries that work across devices. Performance portability is only useful if the tools are stable and well supported.Open ecosystem: hardware vendors, software framework maintainers, and model developers need to cooperate. Standards and shared projects help avoid re-inventing the wheel for every new device or use case.Abstractions that don’t obscure performance: while high-level abstraction helps developers, they must still allow tuning or visibility where needed. The right balance between abstraction and control is key.Security, privacy, and trust built in: especially as more compute shifts to devices (edge/mobile), issues like data protection, safe execution, model integrity, and privacy matter.Arm as one example of ecosystem-led simplification Simplifying AI at scale now hinges on system-wide design, where silicon, software, and developer tools evolve in lockstep. This approach enables AI workloads to run efficiently across diverse environments, from cloud inference clusters to battery-constrained edge devices. It also reduces the overhead of bespoke optimization, making it easier to bring new products to market faster. Arm (Nasdaq:Arm) is advancing this model with a platform-centric focus that pushes hardware-software optimizations up through the software stack. At COMPUTEX 2025, Arm demonstrated how its latest Arm9 CPUs, combined with AI-specific ISA extensions and the Kleidi libraries, enable tighter integration with widely used frameworks like PyTorch, ExecuTorch, ONNX Runtime, and MediaPipe. This alignment reduces the need for custom kernels or hand-tuned operators, allowing developers to unlock hardware performance without abandoning familiar toolchains. The real-world implications are significant. In the data center, Arm-based platforms are delivering improved performance-per-watt, critical for scaling AI workloads sustainably. On consumer devices, these optimizations enable ultra-responsive user experiences and background intelligence that’s always on, yet power efficient.More broadly, the industry is coalescing around simplification as a design imperative, embedding AI support directly into hardware roadmaps, optimizing for software portability, and standardizing support for mainstream AI runtimes. Arm’s approach illustrates how deep integration across the compute stack can make scalable AI a practical reality.Market validation and momentumIn 2025, nearly half of the compute shipped to major hyperscalers will run on Arm-based architectures, a milestone that underscores a significant shift in cloud infrastructure. As AI workloads become more resource-intensive, cloud providers are prioritizing architectures that deliver superior performance-per-watt and support seamless software portability. This evolution marks a strategic pivot toward energy-efficient, scalable infrastructure optimized for the performance and demands of modern AI.At the edge, Arm-compatible inference engines are enabling real-time experiences, such as live translation and always-on voice assistants, on battery-powered devices. These advancements bring powerful AI capabilities directly to users, without sacrificing energy efficiency.Developer momentum is accelerating as well. In a recent collaboration, GitHub and Arm introduced native Arm Linux and Windows runners for GitHub Actions, streamlining CI workflows for Arm-based platforms. These tools lower the barrier to entry for developers and enable more efficient, cross-platform development at scale. What comes nextSimplification doesn’t mean removing complexity entirely; it means managing it in ways that empower innovation. As the AI stack stabilizes, winners will be those who deliver seamless performance across a fragmented landscape.From a future-facing perspective, expect:Benchmarks as guardrails: MLPerf + OSS suites guide where to optimize next.More upstream, fewer forks: Hardware features land in mainstream tools, not custom branches.Convergence of research + production: Faster handoff from papers to product via shared runtimes.ConclusionAI’s next phase isn’t about exotic hardware; it’s also about software that travels well. When the same model lands efficiently on cloud, client, and edge, teams ship faster and spend less time rebuilding the stack.Ecosystem-wide simplification, not brand-led slogans, will separate the winners. The practical playbook is clear: unify platforms, upstream optimizations, and measure with open benchmarks. Explore how Arm AI software platforms are enabling this future — efficiently, securely, and at scale.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by ArmA simpler software stack is the key to portable, scalable AI across cloud and edge. AI is now powering real-world applications, yet fragmented software stacks are holding it back. Developers routinely rebuild the same models for different hardware targets, losing time to glue code instead of shipping features. The good news is that a shift is underway. Unified toolchains and optimized libraries are making it possible to deploy models across platforms without compromising performance.Yet one critical hurdle remains: software complexity. Disparate tools, hardware-specific optimizations, and layered tech stacks continue to bottleneck progress. To unlock the next wave of AI innovation, the industry must pivot decisively away from siloed development and toward streamlined, end-to-end platforms.This transformation is already taking shape. Major cloud providers, edge platform vendors, and open-source communities are converging on unified toolchains that simplify development and accelerate deployment, from cloud to edge. In this article, we’ll explore why simplification is the key to scalable AI, what’s driving this momentum, and how next-gen platforms are turning that vision into real-world results.The bottleneck: fragmentation, complexity, and inefficiencyThe issue isn’t just hardware variety; it’s duplicated effort across frameworks and targets that slows time-to-value.Diverse hardware targets: GPUs, NPUs, CPU-only devices, mobile SoCs, and custom accelerators.Tooling and framework fragmentation: TensorFlow, PyTorch, ONNX, MediaPipe, and others.Edge constraints: Devices require real-time, energy-efficient performance with minimal overhead.According to Gartner Research, these mismatches create a key hurdle: over 60% of AI initiatives stall before production, driven by integration complexity and performance variability. What software simplification looks likeSimplification is coalescing around five moves that cut re-engineering cost and risk:Cross-platform abstraction layers that minimize re-engineering when porting models.Performance-tuned libraries integrated into major ML frameworks.Unified architectural designs that scale from datacenter to mobile.Open standards and runtimes (e.g., ONNX, MLIR) reducing lock-in and improving compatibility.Developer-first ecosystems emphasizing speed, reproducibility, and scalability.These shifts are making AI more accessible, especially for startups and academic teams that previously lacked the resources for bespoke optimization. Projects like Hugging Face’s Optimum and MLPerf benchmarks are also helping standardize and validate cross-hardware performance.Ecosystem momentum and real-world signals Simplification is no longer aspirational; it’s happening now. Across the industry, software considerations are influencing decisions at the IP and silicon design level, resulting in solutions that are production-ready from day one. Major ecosystem players are driving this shift by aligning hardware and software development efforts, delivering tighter integration across the stack.A key catalyst is the rapid rise of edge inference, where AI models are deployed directly on devices rather than in the cloud. This has intensified demand for streamlined software stacks that support end-to-end optimization, from silicon to system to application. Companies like Arm are responding by enabling tighter coupling between their compute platforms and software toolchains, helping developers accelerate time-to-deployment without sacrificing performance or portability. The emergence of multi-modal and general-purpose foundation models (e.g., LLaMA, Gemini, Claude) has also added urgency. These models require flexible runtimes that can scale across cloud and edge environments. AI agents, which interact, adapt, and perform tasks autonomously, further drive the need for high-efficiency, cross-platform software.MLPerf Inference v3.1 included over 13,500 performance results from 26 submitters, validating multi-platform benchmarking of AI workloads. Results spanned both data center and edge devices, demonstrating the diversity of optimized deployments now being tested and shared.Taken together, these signals make clear that the market’s demand and incentives are aligning around a common set of priorities, including maximizing performance-per-watt, ensuring portability, minimizing latency, and delivering security and consistency at scale.What must happen for successful simplificationTo realize the promise of simplified AI platforms, several things must occur:Strong hardware/software co-design: hardware features that are exposed in software frameworks (e.g., matrix multipliers, accelerator instructions), and conversely, software that is designed to take advantage of underlying hardware.Consistent, robust toolchains and libraries: developers need reliable, well-documented libraries that work across devices. Performance portability is only useful if the tools are stable and well supported.Open ecosystem: hardware vendors, software framework maintainers, and model developers need to cooperate. Standards and shared projects help avoid re-inventing the wheel for every new device or use case.Abstractions that don’t obscure performance: while high-level abstraction helps developers, they must still allow tuning or visibility where needed. The right balance between abstraction and control is key.Security, privacy, and trust built in: especially as more compute shifts to devices (edge/mobile), issues like data protection, safe execution, model integrity, and privacy matter.Arm as one example of ecosystem-led simplification Simplifying AI at scale now hinges on system-wide design, where silicon, software, and developer tools evolve in lockstep. This approach enables AI workloads to run efficiently across diverse environments, from cloud inference clusters to battery-constrained edge devices. It also reduces the overhead of bespoke optimization, making it easier to bring new products to market faster. Arm (Nasdaq:Arm) is advancing this model with a platform-centric focus that pushes hardware-software optimizations up through the software stack. At COMPUTEX 2025, Arm demonstrated how its latest Arm9 CPUs, combined with AI-specific ISA extensions and the Kleidi libraries, enable tighter integration with widely used frameworks like PyTorch, ExecuTorch, ONNX Runtime, and MediaPipe. This alignment reduces the need for custom kernels or hand-tuned operators, allowing developers to unlock hardware performance without abandoning familiar toolchains. The real-world implications are significant. In the data center, Arm-based platforms are delivering improved performance-per-watt, critical for scaling AI workloads sustainably. On consumer devices, these optimizations enable ultra-responsive user experiences and background intelligence that’s always on, yet power efficient.More broadly, the industry is coalescing around simplification as a design imperative, embedding AI support directly into hardware roadmaps, optimizing for software portability, and standardizing support for mainstream AI runtimes. Arm’s approach illustrates how deep integration across the compute stack can make scalable AI a practical reality.Market validation and momentumIn 2025, nearly half of the compute shipped to major hyperscalers will run on Arm-based architectures, a milestone that underscores a significant shift in cloud infrastructure. As AI workloads become more resource-intensive, cloud providers are prioritizing architectures that deliver superior performance-per-watt and support seamless software portability. This evolution marks a strategic pivot toward energy-efficient, scalable infrastructure optimized for the performance and demands of modern AI.At the edge, Arm-compatible inference engines are enabling real-time experiences, such as live translation and always-on voice assistants, on battery-powered devices. These advancements bring powerful AI capabilities directly to users, without sacrificing energy efficiency.Developer momentum is accelerating as well. In a recent collaboration, GitHub and Arm introduced native Arm Linux and Windows runners for GitHub Actions, streamlining CI workflows for Arm-based platforms. These tools lower the barrier to entry for developers and enable more efficient, cross-platform development at scale. What comes nextSimplification doesn’t mean removing complexity entirely; it means managing it in ways that empower innovation. As the AI stack stabilizes, winners will be those who deliver seamless performance across a fragmented landscape.From a future-facing perspective, expect:Benchmarks as guardrails: MLPerf + OSS suites guide where to optimize next.More upstream, fewer forks: Hardware features land in mainstream tools, not custom branches.Convergence of research + production: Faster handoff from papers to product via shared runtimes.ConclusionAI’s next phase isn’t about exotic hardware; it’s also about software that travels well. When the same model lands efficiently on cloud, client, and edge, teams ship faster and spend less time rebuilding the stack.Ecosystem-wide simplification, not brand-led slogans, will separate the winners. The practical playbook is clear: unify platforms, upstream optimizations, and measure with open benchmarks. Explore how Arm AI software platforms are enabling this future — efficiently, securely, and at scale.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5NhML02FGAEkp2yOpsPkrx/b62d547d376660e631c01d70283f7946/AdobeStock_1243259614.jpeg?w=300&q=30"
        }
      ],
      "featured_image": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/ee8e2060-b041-11f0-bfd8-56b8b6c7bea8",
      "popularity_score": 2019.8295533333333,
      "ai_summary": [
        "Leica's M EV1 camera replaces the rangefinder with an electronic viewfinder.",
        "The camera has a 60MP sensor and maintains the classic M design.",
        "The change may appeal to buyers seeking a modern Leica experience.",
        "The EVF offers a more accurate view compared to the rangefinder.",
        "The camera is handmade in Germany and features a new leatherette design."
      ]
    },
    {
      "id": "cluster_3",
      "coverage": 2,
      "updated_at": "Thu, 23 Oct 2025 14:55:01 -0400",
      "title": "Anthropic says Claude's memory feature, initially available for Team and Enterprise users, is rolling out to Pro and Max subscribers (Sabrina Ortiz/ZDNET)",
      "neutral_headline": "Anthropic’s Claude chatbot is getting a ‘memory’ upgrade",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251023/p40#a251023p40",
          "published_at": "Thu, 23 Oct 2025 14:55:01 -0400",
          "title": "Anthropic says Claude's memory feature, initially available for Team and Enterprise users, is rolling out to Pro and Max subscribers (Sabrina Ortiz/ZDNET)",
          "standfirst": "Sabrina Ortiz / ZDNET: Anthropic says Claude's memory feature, initially available for Team and Enterprise users, is rolling out to Pro and Max subscribers &mdash; ZDNET's key takeaways &mdash; Anthropic Pro and Max subscribers have access to Memory. &mdash; The feature creates a more intuitive experience with AI that knows you.",
          "content": "Sabrina Ortiz / ZDNET: Anthropic says Claude's memory feature, initially available for Team and Enterprise users, is rolling out to Pro and Max subscribers &mdash; ZDNET's key takeaways &mdash; Anthropic Pro and Max subscribers have access to Memory. &mdash; The feature creates a more intuitive experience with AI that knows you.",
          "feed_position": 1,
          "image_url": "http://www.techmeme.com/251023/i40.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/804124/anthropic-claude-ai-memory-upgrade-all-subscribers",
          "published_at": "2025-10-23T13:00:00-04:00",
          "title": "Anthropic’s Claude chatbot is getting a ‘memory’ upgrade",
          "standfirst": "Anthropic is rolling out an update for Claude that will let the AI chatbot “remember” past conversations without prompting. The upgrade for all paid subscribers should make Claude more useful and convenient. Max subscribers will be able to turn on Claude’s “memory” in their settings from today, Anthropic said. The feature, which has been available [&#8230;]",
          "content": "Anthropic is rolling out an update for Claude that will let the AI chatbot “remember” past conversations without prompting. The upgrade for all paid subscribers should make Claude more useful and convenient. Max subscribers will be able to turn on Claude’s “memory” in their settings from today, Anthropic said. The feature, which has been available to Team and Enterprise users since September, lets Claude remember details from previous chats. Pro subscribers will see the memory feature “roll out over the coming days,” Anthropic said. The company did not say whether it plans to make the feature available to free users in the future. Anthropic says the goal is “complete transparency.” Users will be able to clearly see what Claude remembers rather than “vague summaries,” it said. Specific memories can also be toggled on and off or edited with natural conversation. For example, you could tell Claude to focus on specific memories or “forget an old job entirely.” Users can also create “distinct memory spaces” that will keep various memories apart. If it works, this could be useful at stopping memories from different conversations or projects bleeding through into other chats, handy for separating different work projects or using the bot for personal and professional reasons. The hotly anticipated memory function brings Claude closer in line with rival chatbots like ChatGPT and Gemini. All are competing ferociously for users and memory functions are a way of encouraging users to stick around rather than starting all over again with another bot. Claude has lagged its rivals in memory — OpenAI and Google both rolled out memory features for their chatbots last year — and it only gained the ability to remember past conversations this August. Even then, you had to explicitly ask Claude to remember. Anthropic hopes to reduce the friction of starting over by letting users import memories from ChatGPT or Gemini. These will need to be copy-and-pasted in. Memories can also be exported “anytime” from Claude, it said. “No lock-in.” Chatbot memory has, however, proven divisive. While hailed as a useful feature, some experts warn recall can help sustain or amplify delusional thinking and other mental health concerns colloquially called “AI psychosis,” particularly given the sycophantic tendencies of some models.",
          "feed_position": 5
        }
      ],
      "featured_image": "http://www.techmeme.com/251023/i40.jpg",
      "popularity_score": 2019.6501088888888,
      "ai_summary": [
        "Anthropic is rolling out a memory feature for its Claude chatbot.",
        "The feature allows Claude to remember past conversations without prompting.",
        "The upgrade is available to all paid subscribers of Claude.",
        "Max subscribers can enable the memory feature in their settings.",
        "The update aims to make Claude more useful and convenient."
      ]
    },
    {
      "id": "cluster_44",
      "coverage": 2,
      "updated_at": "Thu, 23 Oct 2025 12:20:00 -0400",
      "title": "Microsoft unveils Mico, a character that responds with real-time expressions when talked to, now on by default in Copilot's voice mode in the US, UK, and Canada (Tom Warren/The Verge)",
      "neutral_headline": "Microsoft updates Copilot with new features",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251023/p34#a251023p34",
          "published_at": "Thu, 23 Oct 2025 12:20:00 -0400",
          "title": "Microsoft unveils Mico, a character that responds with real-time expressions when talked to, now on by default in Copilot's voice mode in the US, UK, and Canada (Tom Warren/The Verge)",
          "standfirst": "Tom Warren / The Verge: Microsoft unveils Mico, a character that responds with real-time expressions when talked to, now on by default in Copilot's voice mode in the US, UK, and Canada &mdash; Copilot now has its own virtual character for its voice mode. &hellip; It's been nearly 30 years since Microsoft's Office assistant &hellip;",
          "content": "Tom Warren / The Verge: Microsoft unveils Mico, a character that responds with real-time expressions when talked to, now on by default in Copilot's voice mode in the US, UK, and Canada &mdash; Copilot now has its own virtual character for its voice mode. &hellip; It's been nearly 30 years since Microsoft's Office assistant &hellip;",
          "feed_position": 7,
          "image_url": "http://www.techmeme.com/251023/i34.jpg"
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251023/p33#a251023p33",
          "published_at": "Thu, 23 Oct 2025 12:15:02 -0400",
          "title": "Microsoft updates Copilot to add Copilot Groups, enabling up to 32 people to collaborate in a session, and a \"real talk\" mode to add more personality to Copilot (Tom Warren/The Verge)",
          "standfirst": "Tom Warren / The Verge: Microsoft updates Copilot to add Copilot Groups, enabling up to 32 people to collaborate in a session, and a &ldquo;real talk&rdquo; mode to add more personality to Copilot &mdash; Microsoft is also adding better memory, improvements to health queries, and a new Mico voice character.",
          "content": "Tom Warren / The Verge: Microsoft updates Copilot to add Copilot Groups, enabling up to 32 people to collaborate in a session, and a &ldquo;real talk&rdquo; mode to add more personality to Copilot &mdash; Microsoft is also adding better memory, improvements to health queries, and a new Mico voice character.",
          "feed_position": 8,
          "image_url": "http://www.techmeme.com/251023/i33.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/804122/microsoft-copilot-real-talk-mode-group-chats-features",
          "published_at": "2025-10-23T12:00:00-04:00",
          "title": "Copilot is getting more personality with a ‘real talk’ mode and group chats",
          "standfirst": "Microsoft is rolling out some significant changes to its Copilot AI assistant today. There’s a new groups feature that connects multiple people into a Copilot chat, memory to let Copilot learn things about you, a new “real talk” mode that will bring back some of Copilot’s early personality, and more. Copilot Groups is designed for [&#8230;]",
          "content": "Microsoft is rolling out some significant changes to its Copilot AI assistant today. There’s a new groups feature that connects multiple people into a Copilot chat, memory to let Copilot learn things about you, a new “real talk” mode that will bring back some of Copilot’s early personality, and more. Copilot Groups is designed for groups of friends, classmates, and even teammates to use Copilot in a single session. Microsoft is targeting this at people who need to make a plan or solve problems together, and the company is supporting up to 32 people in Copilot Groups, in an effort to make AI more social. “My guess is you’re going to see groups of two or three dominate this,” says Jacob Andreou, CVP of product and growth at Microsoft AI, in an interview with The Verge. “I think it’s actually going to be a lot of small groups, it’s not going to be like your long-running group chat suddenly has an AI in it.” While Copilot Groups sounds like it’s more ideally suited to work environments, it’s only launching inside the US consumer version of Copilot today and not the business-focused Microsoft 365 Copilot. That might change in the future, though. “I do think it’s going to be amazing in work contexts,” says Andreou. “Bringing experiences like this into Microsoft 365 are going to be really important.&#8221; Microsoft is also adding an optional “real talk” mode to Copilot that will adapt to the way you’re asking questions and have more challenging responses. When Microsoft first launched Copilot as its Bing AI chatbot, it could often be prompted to refer to itself as Sydney and sometimes respond rudely to users. While the real talk mode doesn’t bring back the full sassiness of Sydney, it sounds like Copilot is about to get a lot more personality in its responses. “In real talk this mode will match your tone, add its own perspective, and maybe be a little more witty than people expect,” says Andreou. “It&#8217;s also going to challenge you, so it won&#8217;t just agree with everything you say.” Real talk won’t be the default mode, it will just be another mode you select in the dropdown menu, and it’s also only limited to text and not Copilot’s voice mode. Real talk will be able to take advantage of improvements to Copilot’s memory features, though. “Copilot is getting way better memory. It will be able to remember facts about you, the people you care about, your life, and the things you&#8217;re working on,” explains Andreou. You’ll also be able to control what Copilot knows about you. “You&#8217;ll be able to see a list of everything Copilot knows about you, and you&#8217;ll be able to go in and delete things,” says Andreou. “We also really want to invest is doing a lot of this conversationally.” You’ll be able to use the Copilot voice mode to ask the AI assistant to forget everything it knows about your partner, for example. Copilot is also getting changes to how it answers health-related questions by improving how it sources and grounds responses with trusted sources like Harvard Health. “Copilot also helps you find the right doctors quickly and confidently, matching based on location, language, and other preferences,” says Microsoft. Microsoft is also updating its Copilot voice mode to introduce Mico, a new Clippy-like character. It will react with real-time expressions and bounce around a Copilot window. It also has a Learn Live mode that acts like a tutor. You can read all about Mico right here.",
          "feed_position": 8
        }
      ],
      "featured_image": "http://www.techmeme.com/251023/i34.jpg",
      "popularity_score": 2017.0664977777778,
      "ai_summary": [
        "Microsoft is adding a \"real talk\" mode to Copilot for more personality.",
        "Copilot will have a new \"Mico\" voice character with real-time expressions.",
        "Copilot Groups will allow up to 32 people to collaborate in a session.",
        "The updates include improvements to memory and health queries.",
        "The changes aim to enhance Copilot's user experience."
      ]
    },
    {
      "id": "cluster_6",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 18:48:52 +0000",
      "title": "Microsoft makes Copilot “human-centered” with a ‘90s-style animated assistant",
      "neutral_headline": "Microsoft's Copilot gets a '90s-style animated assistant",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/microsoft-makes-copilot-human-centered-with-a-90s-style-animated-assistant/",
          "published_at": "Thu, 23 Oct 2025 18:48:52 +0000",
          "title": "Microsoft makes Copilot “human-centered” with a ‘90s-style animated assistant",
          "standfirst": "\"Mico\" literally tries to put a face on Microsoft's chatbot-turned-assistant.",
          "content": "Microsoft said earlier this month that it wanted to add better voice controls to Copilot, Windows 11’s built-in chatbot-slash-virtual assistant. As described, this new version of Copilot sounds an awful lot like another stab at Cortana, the voice assistant that Microsoft tried (and failed) to get people to use in Windows 10 in the mid-to-late 2010s. Turns out that the company isn’t done trying to reformulate and revive ideas it has already tried before. As part of a push toward what it calls “human-centered AI,” Microsoft is now putting a face on Copilot. Literally, a face: “Mico” is an “expressive, customizable, and warm” blob with a face that dynamically “listens, reacts, and even changes colors to reflect your interactions” as you interact with Copilot. (Another important adjective for Mico: “optional.”) Mico (rhymes with “pico”) recalls old digital assistants like Clippy, Microsoft Bob, and Rover, ideas that Microsoft tried in the ’90s and early 2000s before mostly abandoning them.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Mico-1-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Mico-1-1152x648.jpeg",
      "popularity_score": 364.5476088888889,
      "ai_summary": [
        "Microsoft's Copilot is getting a new animated assistant named \"Mico.\"",
        "\"Mico\" aims to give a face to Microsoft's chatbot-turned-assistant.",
        "The assistant is designed to be \"human-centered\" in its interactions.",
        "The design evokes a style reminiscent of the 1990s.",
        "The update is part of Microsoft's ongoing development of Copilot."
      ]
    },
    {
      "id": "cluster_31",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 17:04:16 +0000",
      "title": "The first people to set foot in Australia were fossil hunters",
      "neutral_headline": "Fossil hunters were the first in Australia",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/the-first-people-to-set-foot-in-australia-were-fossil-hunters/",
          "published_at": "Thu, 23 Oct 2025 17:04:16 +0000",
          "title": "The first people to set foot in Australia were fossil hunters",
          "standfirst": "Europeans weren't the first people to collect fossils in Australia.",
          "content": "Australia’s First Peoples may or may not have hunted the continent’s megafauna to extinction, but they definitely collected fossils. A team of archaeologists examined the fossilized leg bone of an extinct kangaroo and realized that instead of evidence of butchery, cut marks on the bone reveal an ancient attempt at fossil collecting. That leaves Australia with little evidence of First Peoples hunting or butchering the continent’s extinct megafauna—and reopens the question of whether humans were responsible for the die-off of that continent’s giant Ice Age marsupials. Fossil hunting in the Ice Age In the unsolved case of whether humans hunted Australia’s Ice Age megafauna to extinction, the key piece of evidence so far is a tibia (one of the bones of the lower leg) from an extinct short-faced kangaroo. Instead of hopping like their modern relatives, these extinct kangaroos walked on their hind legs, probably placing all their weight on the tips of single hoofed toes. This particular kangaroo wasn’t quite fully grown when it died, which happened sometime between 44,500 and 55,200 years ago, based on uranium-series dating of the thin layer of rock covering most of the fossils in Mammoth Cave (in what’s now Western Australia).Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/rsosSimosthenurus_occidentalis-1152x648-1761239043.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/rsosSimosthenurus_occidentalis-1152x648-1761239043.jpg",
      "popularity_score": 340.80427555555553,
      "ai_summary": [
        "Europeans were not the first to collect fossils in Australia.",
        "The article discusses the history of fossil hunting in Australia.",
        "The focus is on who first discovered and collected fossils.",
        "The information provides a different perspective on history.",
        "The article highlights the early exploration of fossils."
      ]
    },
    {
      "id": "cluster_38",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 16:40:22 +0000",
      "title": "CS2 item market loses nearly $2B in value overnight due to “trade up” update",
      "neutral_headline": "CS2 item market loses value after \"trade up\" update",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/10/valve-upends-the-cs2-item-marketplace-with-new-trade-up-update/",
          "published_at": "Thu, 23 Oct 2025 16:40:22 +0000",
          "title": "CS2 item market loses nearly $2B in value overnight due to “trade up” update",
          "standfirst": "Once rare $14K knife now sells for $7K, some common guns jump from $10 to over $100.",
          "content": "From the outside, Counter-Strike 2 looks a lot like a game that’s primarily about shooting people. For millions of players, though, the game is more about collecting and/or buying rare in-game loot and flipping it for what can be very significant sums on the Steam Marketplace. Wednesday night, Valve sent that multi-billion-dollar market into turmoil as part of a so-called “small update.” Now, players can use the game’s “Trade Up contracts” to exchange five common, “Covert” items (also known as “reds”) for the kinds of knives and gloves that have until now been much harder to obtain. That “small update” has unsurprisingly had an immediate and sharp impact on the Marketplace price for those items. One rare knife that sold for over $14,000 less than 24 hours ago has seen its minimum price plummet over 50 percent as of this writing, according to the trackers at Pricempire. Meanwhile, the median sale price for a common P90 Asimov gun on the Steam Marketplace shot up from $10 on Wednesday to well over $100 as of this writing.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/cs2knife-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/cs2knife-1152x648.png",
      "popularity_score": 330.4059422222222,
      "ai_summary": [
        "The CS2 item market experienced a nearly $2B loss in value.",
        "A \"trade up\" update caused significant price drops for items.",
        "A rare knife's value decreased from $14K to $7K.",
        "Some common guns increased in price from $10 to over $100.",
        "The update significantly impacted the in-game economy."
      ]
    },
    {
      "id": "cluster_68",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 15:04:47 +0000",
      "title": "Reports suggest Apple is already pulling back on the iPhone Air",
      "neutral_headline": "Apple may be scaling back iPhone Air plans",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/early-indicators-analyst-reports-suggest-apples-iphone-air-isnt-taking-off/",
          "published_at": "Thu, 23 Oct 2025 15:04:47 +0000",
          "title": "Reports suggest Apple is already pulling back on the iPhone Air",
          "standfirst": "New phone design compromises on camera and battery to achieve a lighter weight.",
          "content": "Apple’s iPhone Air was the company’s most interesting new iPhone this year, at least insofar as it was the one most different from previous iPhones. We came away impressed by its size and weight in our review. But early reports suggest that its novelty might not be translating into sales success. A note from analyst Ming-Chi Kuo, whose supply chain sources are often accurate about Apple’s future plans, said yesterday that demand for the iPhone Air “has fallen short of expectations” and that “both shipments and production capacity” were being scaled back to account for the lower-than-expected demand. Kuo’s note is backed up by reports from other analysts at Mizuho Securities (via MacRumors) and Nikkei Asia. Both of these reports say that demand for the iPhone 17 and 17 Pro models remains strong, indicating that this is just a problem for the iPhone Air and not a wider slowdown caused by tariffs or other external factors.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_3384-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_3384-1152x648.jpeg",
      "popularity_score": 325.81288666666666,
      "ai_summary": [
        "Reports suggest Apple is already reducing plans for the iPhone Air.",
        "The new phone design compromises on camera and battery.",
        "These compromises are to achieve a lighter weight.",
        "The article discusses the potential changes to the iPhone Air.",
        "The focus is on the design and features of the phone."
      ]
    },
    {
      "id": "cluster_43",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 16:25:00 +0000",
      "title": "Great hybrid V6, lousy HMI: Three days with a Ferrari 296 GTB",
      "neutral_headline": "Ferrari 296 GTB review: Great hybrid V6, lousy HMI",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/great-hybrid-v6-lousy-hmi-three-days-with-a-ferrari-296-gtb/",
          "published_at": "Thu, 23 Oct 2025 16:25:00 +0000",
          "title": "Great hybrid V6, lousy HMI: Three days with a Ferrari 296 GTB",
          "standfirst": "Three days with a car revealed its character in more ways than one.",
          "content": "Ferrari provided flights from Washington, DC, to Austin, Texas, and accommodation so Ars could attend the Lone Star Le Mans. Ars does not accept paid editorial content. The first time I drove this generation of mid-engined Ferrari, it was on a curated route on the company’s home turf. As the Po Valley gives way to the Apennines, you find plenty of narrow winding roads, steep gradients, and hairpin turns. It was an engaging few hours of driving, but it was too brief to properly assess some of the 296’s technology. I found the ride firm but comfortable on rough Italian tarmac and the hybrid system easy to operate, flicking into calm-and-quiet electric-only mode through the villages I encountered. That was back in 2022 during the unveiling of Ferrari’s 499P race car. Last month, I met the 499P again as it visited the Circuit of the Americas in Austin, along with the rest of the World Endurance Championship. And that afforded another chance to get to know the 296, with three days rather than three hours to form an impression. Head west from Austin and you’ll find twisty roads that wrap around the hills. It would have been easy to spend an entire day out there, but that seemed repetitive—I’d experienced the 296’s back road behavior already. Plus, there were things to do at the racetrack, although I’ll admit I took the long way there and back each day.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2025-Ferrari-296-GTB-1-of-12-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2025-Ferrari-296-GTB-1-of-12-1152x648.jpg",
      "popularity_score": 320.1498311111111,
      "ai_summary": [
        "The review focuses on the Ferrari 296 GTB's hybrid V6 engine.",
        "The car's character was revealed over three days of testing.",
        "The review critiques the car's Human-Machine Interface (HMI).",
        "The article provides an assessment of the car's performance.",
        "The review highlights both strengths and weaknesses."
      ]
    },
    {
      "id": "cluster_61",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 15:33:04 +0000",
      "title": "Trump eyes government control of quantum computing firms with Intel-like deals",
      "neutral_headline": "Trump considers government control of quantum firms",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/trumps-industry-meddling-may-give-us-a-stake-in-quantum-computing-firms/",
          "published_at": "Thu, 23 Oct 2025 15:33:04 +0000",
          "title": "Trump eyes government control of quantum computing firms with Intel-like deals",
          "standfirst": "Some quantum computing firms seem optimistic about Trump's proposed deals.",
          "content": "Donald Trump is eyeing taking equity stakes in quantum computing firms in exchange for federal funding, The Wall Street Journal reported. At least five companies are weighing whether allowing the government to become a shareholder would be worth it to snag funding that the Trump administration has “earmarked for promising technology companies,” sources familiar with the potential deals told the WSJ. IonQ, Rigetti Computing, and D-Wave Quantum are currently in talks with the government over potential funding agreements, with minimum awards of $10 million each, some sources said. Quantum Computing Inc. and Atom Computing are reportedly “considering similar arrangements,” as are other companies in the sector, which is viewed as critical for scientific advancements and next-generation technologies.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2229574852-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2229574852-1152x648.jpg",
      "popularity_score": 309.28427555555555,
      "ai_summary": [
        "Trump is considering government control of quantum computing firms.",
        "The proposed deals are similar to those with Intel.",
        "Some quantum computing firms are optimistic about the deals.",
        "The article discusses potential government involvement.",
        "The focus is on the future of quantum computing."
      ]
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 13:58:46 +0000",
      "title": "An outcast faces a deadly alien world in Predator: Badlands trailer",
      "neutral_headline": "Predator: Badlands trailer shows deadly alien world",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/10/an-outcast-faces-a-deadly-alien-world-in-predator-badlands-trailer/",
          "published_at": "Thu, 23 Oct 2025 13:58:46 +0000",
          "title": "An outcast faces a deadly alien world in Predator: Badlands trailer",
          "standfirst": "\"The ways of your kind are ones of violence. Either you are hunted or you become the hunter.\"",
          "content": "We’ve got a new international trailer for Predator: Badlands, the latest installment in a popular franchise that’s been around since 1987. It’s directed by Dan Trachtenberg, who is very familiar with the franchise, having also directed 2022’s highly acclaimed standalone Predator movie, Prey. In April, Twentieth Century Studios released the first teaser, which involved multiple predators fighting or threatening one another, Elle Fanning looking very strange and cool as an android, and glimpses of new monsters and the alien world the movie focuses on. And the film was featured prominently at San Diego Comic-Con this summer. But it hasn’t quite wormed its way into the cultural zeitgeist for fall releases. Perhaps this latest trailer will boost its profile. This is a standalone film in the franchise, with a particular focus on the culture of the Predator species; in fact, the same conlanger who created the Na’Vi language for James Cameron’s Avatar franchise also created a written and verbal language for the Predators. (We hear a bit of the dialogue in the new trailer.) And this time around, the primary Predator is actually the film’s protagonist rather than an adversary. Per the official premise: “Set in the future on a deadly remote planet, Predator: Badlands follows a young Predator outcast (Dimitrius Schuster-Koloamatangi) who finds an unlikely ally in Thia (Elle Fanning) as he embarks on a treacherous journey in search of the ultimate adversary.”Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bloodlands1-1152x648-1761226866.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bloodlands1-1152x648-1761226866.jpg",
      "popularity_score": 302.7126088888889,
      "ai_summary": [
        "The trailer for Predator: Badlands has been released.",
        "The trailer shows an outcast facing a deadly alien world.",
        "The trailer includes the line, \"Either you are hunted or you become the hunter.\"",
        "The article discusses the trailer's content and themes.",
        "The focus is on the upcoming film's plot."
      ]
    },
    {
      "id": "cluster_84",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 13:42:41 +0000",
      "title": "Porsche does U-turn on electric vehicles, will focus on gas engines",
      "neutral_headline": "Porsche Shifts Focus to Gas Engines Amidst Market Challenges",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/porsche-does-u-turn-on-electric-vehicles-will-focus-on-gas-engines/",
          "published_at": "Thu, 23 Oct 2025 13:42:41 +0000",
          "title": "Porsche does U-turn on electric vehicles, will focus on gas engines",
          "standfirst": "China weakness, US tariffs, and disappointing uptake of battery vehicles lurk in background.",
          "content": "Porsche’s new boss was a skeptic of battery motors for luxury vehicles long before he was picked to lead the revival of the petrol engine at the German sports car group. “The technology isn’t ready,” Michael Leiters told the Financial Times late last year while still in his old job as chief executive of British supercar manufacturer McLaren. Electric vehicles lacked the emotional thrill of noisy engines and were quicker to lose their value, he said. Leiters will take over at Porsche in January at a critical juncture for the Stuttgart-based company, as it tempers its electric ambitions and ploughs new investment into petrol engine models in an attempt to turn its fortunes around.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2019/10/02-Porsche-Taycan-4S--1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2019/10/02-Porsche-Taycan-4S--1152x648.jpg",
      "popularity_score": 283.4445533333333,
      "ai_summary": [
        "Porsche will focus on gas engines due to weak China sales and US tariffs.",
        "Disappointing uptake of battery vehicles also contributed to the shift in strategy.",
        "The company is reevaluating its electric vehicle production plans.",
        "Market conditions are influencing Porsche's decisions regarding vehicle types.",
        "Porsche is responding to changing market dynamics and consumer preferences."
      ]
    },
    {
      "id": "cluster_95",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 11:30:55 +0000",
      "title": "Texas lawmakers double down on Discovery, call for DOJ investigation into Smithsonian",
      "neutral_headline": "Texas Lawmakers Seek Investigation into Smithsonian Discovery",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/texas-lawmakers-double-down-on-discovery-call-for-doj-investigation-into-smithsonian/",
          "published_at": "Thu, 23 Oct 2025 11:30:55 +0000",
          "title": "Texas lawmakers double down on Discovery, call for DOJ investigation into Smithsonian",
          "standfirst": "\"This is the dumbest plan I've ever heard in nearly five years in the United States Senate.\"",
          "content": "Have you heard the news that Texas’ senators want to chop up NASA’s retired space shuttle Discovery in order to move it from the Smithsonian to Houston? The lawmakers in question have and are now crying foul to the Department of Justice. Sens. John Cornyn (R-Texas) and Ted Cruz (R-Texas), together with Rep. Randy Weber (R-Texas), on Wednesday sent a letter to the DOJ urging the Smithsonian be investigated for allegedly violating the Anti-Lobbying Act. They claim that the institution—Discovery‘s home for the past 13 years—improperly used appropriated funds to influence Congress regarding the relocation of the winged orbiter. “Public reporting suggests the Smithsonian Institution has taken affirmative steps to oppose the passage and implementation of the shuttle’s relocation, as part of President Trump’s One Big Beautiful Bill Act,” wrote Cornyn and Cruz to Attorney General Pamela Bondi and Assistant Attorney General Brett Shumate. “These steps include lobbying the staff of the Senate Appropriations and Rules Committees to express disapproval, coordinating with members of the press to generate public opposition to the law’s passage and disseminating misinformation about the cost and logistics of the move.”Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/news-102225a-lg-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/news-102225a-lg-1152x648.jpg",
      "popularity_score": 265.2484422222222,
      "ai_summary": [
        "Texas lawmakers are calling for a Department of Justice investigation.",
        "The lawmakers are focused on the Smithsonian's Discovery program.",
        "One senator called the plan \"the dumbest\" they had heard.",
        "The investigation request reflects concerns about the program.",
        "The lawmakers' actions highlight political scrutiny of the Smithsonian."
      ]
    },
    {
      "id": "cluster_97",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 11:15:12 +0000",
      "title": "California startup to demonstrate space weapon on its own dime",
      "neutral_headline": "California Startup Plans Space Weapon Demonstration",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/california-startup-to-demonstrate-space-weapon-on-its-own-dime/",
          "published_at": "Thu, 23 Oct 2025 11:15:12 +0000",
          "title": "California startup to demonstrate space weapon on its own dime",
          "standfirst": "\"All of the pieces that are required to make it viable exist.\"",
          "content": "Defense contractors are in full sales mode to win a piece of a potentially trillion-dollar pie for development of the Trump administration’s proposed Golden Dome missile shield. CEOs are touting their companies’ ability to rapidly spool up satellite, sensor, and rocket production. Publicly, they all agree with the assertion of Pentagon officials that US industry already possesses the technologies required to make a homeland missile defense system work. The challenge, they say, is tying all of it together under the umbrella of a sophisticated command and control network. Sensors must be able to detect and track missile threats, and that information must rapidly get to weapons that can shoot them down. Gen. Chance Saltzman, the Space Force’s top commander, likes to call Golden Dome a “systems of systems.”Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/apex_sbi-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/apex_sbi-1152x648.jpg",
      "popularity_score": 262.9864977777778,
      "ai_summary": [
        "A California startup intends to demonstrate a space weapon.",
        "The demonstration will be funded by the startup itself.",
        "The company believes all necessary components are available.",
        "The project aims to showcase the weapon's viability.",
        "The demonstration represents a step in space weapon development."
      ]
    },
    {
      "id": "cluster_100",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 11:00:08 +0000",
      "title": "We let OpenAI’s “Agent Mode” surf the web for us—here’s what happened",
      "neutral_headline": "OpenAI's Agent Mode Automates Web-Based Tasks",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/features/2025/10/we-let-openais-agent-mode-surf-the-web-for-us-heres-what-happened/",
          "published_at": "Thu, 23 Oct 2025 11:00:08 +0000",
          "title": "We let OpenAI’s “Agent Mode” surf the web for us—here’s what happened",
          "standfirst": "From scanning emails to building fansites, Atlas can ably automate some web-based tasks.",
          "content": "On Tuesday, OpenAI announced Atlas, a new web browser with ChatGPT integration, to let you “chat with a page,” as the company puts it. But Atlas also goes beyond the usual LLM back-and-forth with Agent Mode, a “preview mode” feature the company says can “get work done for you” by clicking, scrolling, and reading through various tabs. “Agentic” AI is far from new, of course; OpenAI itself rolled out a preview of the web browsing Operator agent in January and introduced the more generalized “ChatGPT agent” in July. Still, prominently featuring this capability in a major product release like this—even in “preview mode”—signals a clear push to get this kind of system in front of end users. I wanted to put Atlas’ Agent Mode through its paces to see if it could really save me time in doing the kinds of tedious online tasks I plod through every day. In each case, I’ll outline a web-based problem, lay out the Agent Mode prompt I devised to try to solve it, and describe the results. My final evaluation will rank each task on a 10-point scale, with 10 being “did exactly what I wanted with no problems” and one being “complete failure.”Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2022302070-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2022302070-1152x648.jpg",
      "popularity_score": 159.73538666666667,
      "ai_summary": [
        "OpenAI's \"Agent Mode\" can scan emails and build fan sites.",
        "The tool automates some web-based tasks for users.",
        "Atlas is the name of the tool that can automate tasks.",
        "The tool's capabilities include various web-based actions.",
        "The Agent Mode demonstrates automation potential."
      ]
    },
    {
      "id": "cluster_115",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 20:29:11 +0000",
      "title": "General Motors will integrate AI into its cars, plus new hands-free assist",
      "neutral_headline": "General Motors Integrates AI and New Hands-Free Assist",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/ai-and-hands-free-driving-are-coming-to-gms-vehicles/",
          "published_at": "Wed, 22 Oct 2025 20:29:11 +0000",
          "title": "General Motors will integrate AI into its cars, plus new hands-free assist",
          "standfirst": "Do we want LLMs in our cars? GM thinks we do.",
          "content": "GM provided flights from Detroit to New York City and accommodation so Ars could attend its tech event. Ars does not accept paid editorial content. General Motors held a preview event today to show the world what it’s working on. We’ve already seen some projects, like the further development of lithium manganese-rich battery technology or backup power for EVs that can power a home or support the power grid. The most significant new announcement is that Cadillac will offer an Escalade IQ with a so-called “Level 3” conditional automated driving system in 2028. GM is referring to it as a “hands off, eyes off” system and says it will integrate advanced digital mapping, use of lidar and other systems, and advanced machine learning to handle the driving duties in a controlled environment up to 80 mph (129 km/h). This means you can theoretically watch a movie from the driver’s seat while your car takes you down the highway to the airport. Over time, the system’s operation areas will expand to cover even more roads, making driving unnecessary in many situations—unless, of course, you like to drive.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1776398279-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1776398279-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "General Motors will integrate artificial intelligence into its cars.",
        "The company is also introducing a new hands-free assist feature.",
        "The integration reflects GM's focus on AI in vehicles.",
        "The new features aim to enhance the driving experience.",
        "GM is betting on consumer acceptance of AI in cars."
      ]
    },
    {
      "id": "cluster_123",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 18:26:38 +0000",
      "title": "SpaceX disables 2,500 Starlink terminals allegedly used by Asian scam centers",
      "neutral_headline": "SpaceX Disables Starlink Terminals Used by Scammers",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/starlink-blocks-2500-dishes-allegedly-used-by-myanmars-notorious-scam-centers/",
          "published_at": "Wed, 22 Oct 2025 18:26:38 +0000",
          "title": "SpaceX disables 2,500 Starlink terminals allegedly used by Asian scam centers",
          "standfirst": "Starlink not allowed in Myanmar, but scammers reportedly use it \"on a huge scale.\"",
          "content": "SpaceX said it disabled over 2,500 Starlink terminals suspected of being used by scammers in Myanmar. Lauren Dreyer, vice president of Starlink business operations, described the action in an X post last night after reports that Myanmar’s military shut down a major scam operation. “SpaceX complies with local laws in all 150+ markets where Starlink is licensed to operate,” Dreyer wrote. “SpaceX continually works to identify violations of our Acceptable Use Policy and applicable law… On the rare occasion we identify a violation, we take appropriate action, including working with law enforcement agencies around the world. In Myanmar, for example, SpaceX proactively identified and disabled over 2,500 Starlink Kits in the vicinity of suspected ‘scam centers.'” Starlink is not licensed to operate in Myanmar. While Dreyer didn’t say how the terminals were disabled, it’s known that Starlink can disable individual terminals based on their ID numbers or use geofencing to block areas from receiving signals.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlink-myanmar-1152x648-1761154369.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlink-myanmar-1152x648-1761154369.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "SpaceX disabled 2,500 Starlink terminals due to scam use.",
        "The terminals were allegedly used by Asian scam centers.",
        "Starlink is not allowed in Myanmar, but was used there.",
        "Scammers reportedly used Starlink on a large scale.",
        "SpaceX is taking action against misuse of its service."
      ]
    },
    {
      "id": "cluster_112",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 20:45:23 +0000",
      "title": "This may be the most bonkers tech job listing I’ve ever seen",
      "neutral_headline": "Tech Job Listing Describes Extremely High Expectations",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/10/the-tech-ceo-who-would-eat-dog-poop-if-it-means-winning/",
          "published_at": "Wed, 22 Oct 2025 20:45:23 +0000",
          "title": "This may be the most bonkers tech job listing I’ve ever seen",
          "standfirst": "Don't even apply if you're not a Tier 1 \"A-player.\"",
          "content": "Here’s a job pitch you don’t see often. What if, instead of “work-life balance,” you had no balance at all—your life was your work… and work happened seven days a week? Did I say days? I actually meant days and nights, because the job I’m talking about wants you to know that you will also work weekends and evenings, and that “it’s ok to send messages at 3am.”Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1149297973-1152x648-1761164087.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1149297973-1152x648-1761164087.jpg",
      "popularity_score": 139,
      "ai_summary": [
        "The job listing is considered unusual and demanding.",
        "The listing specifies a preference for \"A-player\" candidates.",
        "The listing sets a high bar for potential applicants.",
        "The job description emphasizes top-tier performance.",
        "The listing's tone is notably selective and exclusive."
      ]
    },
    {
      "id": "cluster_116",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 20:23:35 +0000",
      "title": "Health plan enrollment period is set to be horrifying for everyone this year",
      "neutral_headline": "Health Plan Enrollment Period Faces Potential Challenges",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/health-care-costs-are-soaring-for-americans-and-2026-is-looking-grim/",
          "published_at": "Wed, 22 Oct 2025 20:23:35 +0000",
          "title": "Health plan enrollment period is set to be horrifying for everyone this year",
          "standfirst": "Some marketplace premiums could more than double. Employer-based plans are soaring.",
          "content": "Shock and dismay have already begun as Americans face next year’s health insurance costs—and it looks like everyone will be in for some grim numbers. So far, much of the attention has been on the stratospheric prices that Americans might see on plans they buy from Affordable Care Act marketplaces. Critical tax credits for those plans are set to expire at the end of the year, and, on top of that, insurers have proposed a median 18 percent price increase for 2026. With the higher prices and a loss of credits, some Americans could see their monthly premiums more than double. In an analysis last month, nonpartisan health policy group KFF estimated that, on average, ACA marketplace premiums would rise 114 percent, going from $888 in 2025 to $1,904 in 2026.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2018/09/GettyImages-148302547-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2018/09/GettyImages-148302547-1152x648.jpg",
      "popularity_score": 139,
      "ai_summary": [
        "The health plan enrollment period is expected to be difficult.",
        "Some marketplace premiums could more than double.",
        "Employer-based health plans are also experiencing rising costs.",
        "The challenges affect both individual and employer plans.",
        "Consumers face potential increases in health insurance costs."
      ]
    },
    {
      "id": "cluster_110",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 21:42:47 +0000",
      "title": "Tesla profits fall 37% in Q3 despite healthy sales",
      "neutral_headline": "Tesla Reports a 37% Profit Decline in Third Quarter",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/tesla-profits-fall-37-in-q3-despite-healthy-sales/",
          "published_at": "Wed, 22 Oct 2025 21:42:47 +0000",
          "title": "Tesla profits fall 37% in Q3 despite healthy sales",
          "standfirst": "A loss of regulatory credits and increased expenses didn't help.",
          "content": "Tesla reported its financial results for the third quarter of 2025 this afternoon. Earlier this month, we learned that the electric vehicle manufacturer had a pretty good Q3 in terms of sales, which grew by 7.3 percent year over year and cleared out tens of thousands of cars from inventory in the process. However, that hasn’t translated into greater profitability. Even though revenues grew by 12 percent to $28 billion compared to the same period last year, Tesla’s operating expenses grew by 50 percent. As a result, its operating margin halved to just 5.8 percent. And so its profit for the quarter fell by 37 percent to $1.4 billion. Some growth in revenue came from its battery and solar division; this increased by 44 percent to $3.4 billion compared to Q3 2024. Services—including the Supercharger network, which is now open to an increasing number of other makes of EV—also grew, increasing by 25 percent to $3.4 billion. EV deliveries increased by 7 percent to 497,099, most of which were the Model 3 sedan and Model Y crossover. Automotive revenues grew slightly less, increasing 6 percent year over year to $21.2 billion.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/tesladown-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/tesladown-1024x648.jpg",
      "popularity_score": 136,
      "ai_summary": [
        "Tesla's profits fell by 37% during the third quarter.",
        "The decline occurred despite healthy sales figures.",
        "A loss of regulatory credits contributed to the decrease.",
        "Increased expenses also impacted Tesla's profitability.",
        "The company faced challenges affecting its financial performance."
      ]
    },
    {
      "id": "cluster_109",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 22:35:41 +0000",
      "title": "Cache poisoning vulnerabilities found in 2 DNS resolving apps",
      "neutral_headline": "Cache Poisoning Vulnerabilities Found in DNS Apps",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/bind-warns-of-bugs-that-could-bring-dns-cache-attack-back-from-the-dead/",
          "published_at": "Wed, 22 Oct 2025 22:35:41 +0000",
          "title": "Cache poisoning vulnerabilities found in 2 DNS resolving apps",
          "standfirst": "At least one CVE could weaken defenses put in place following 2008 disclosure.",
          "content": "The makers of BIND, the Internet’s most widely used software for resolving domain names, are warning of two vulnerabilities that allow attackers to poison entire caches of results and send users to malicious destinations that are indistinguishable from the real ones. The vulnerabilities, tracked as CVE-2025-40778 and CVE-2025-40780, stem from a logic error and a weakness in generating pseudo-random numbers, respectively. They each carry a severity rating of 8.6. Separately, makers of the Domain Name System resolver software Unbound warned of similar vulnerabilities that were reported by the same researchers. The unbound vulnerability severity score is 5.6 Revisiting Kaminsky’s cache poisoning attack The vulnerabilities can be exploited to cause DNS resolvers located inside thousands of organizations to replace valid results for domain lookups with corrupted ones. The corrupted results would replace the IP addresses controlled by the domain name operator (for instance, 3.15.119.63 for arstechnica.com) with malicious ones controlled by the attacker. Patches for all three vulnerabilities became available on Wednesday.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/browser-security-threat-1152x627.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/browser-security-threat-1152x627.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Cache poisoning vulnerabilities were found in DNS resolving apps.",
        "At least one CVE could weaken defenses from 2008 disclosure.",
        "The vulnerabilities could compromise DNS security.",
        "The discovery highlights potential security weaknesses.",
        "The vulnerabilities require attention for security updates."
      ]
    },
    {
      "id": "cluster_125",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 18:12:50 +0000",
      "title": "Samsung Galaxy XR is the first Android XR headset, now on sale for $1,800",
      "neutral_headline": "Samsung Galaxy XR Headset Now Available for Purchase",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/10/samsung-galaxy-xr-is-the-first-android-xr-headset-now-on-sale-for-1800/",
          "published_at": "Wed, 22 Oct 2025 18:12:50 +0000",
          "title": "Samsung Galaxy XR is the first Android XR headset, now on sale for $1,800",
          "standfirst": "It may not be as spendy as the Vision Pro, but $1,800 is still a lot.",
          "content": "The era of Android virtual reality is here… again. Google’s first two attempts at making Android fit for your face didn’t work out, but the AI era and a partnership with Samsung have enabled a third attempt, and maybe the third time’s the charm. Samsung has unveiled the Galaxy XR headset, the first and currently only device running Google’s new Android XR platform. It’s available for pre-order today, but it will not come cheap. The headset, which doesn’t come with controllers, retails for $1,800. Galaxy XR is a fully enclosed headset with passthrough video. It looks similar to the Apple Vision Pro, right down to the battery pack at the end of a cable. It packs solid hardware, including 16GB of RAM, 256GB of storage, and a Snapdragon XR2+ Gen 2 processor. That’s a slightly newer version of the chip powering Meta’s Quest 3 headset, featuring six CPU cores and an Adreno GPU that supports up to dual 4.3K displays. The new headset has a pair of 3,552 x 3,840 Micro-OLED displays with a 109-degree field of view. That’s marginally more pixels than the Vision Pro and almost three times as many as the Quest 3. The displays can refresh at up to 90Hz, but the default is 72Hz to save power.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Samsung-Mobile-Galaxy-XR-Multimodal-AI-Android-XR-Opening-New-Worlds_main1.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Samsung-Mobile-Galaxy-XR-Multimodal-AI-Android-XR-Opening-New-Worlds_main1.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "The Samsung Galaxy XR headset is now on sale.",
        "The headset is the first Android XR headset available.",
        "The device is priced at $1,800.",
        "The price point is considered high by some.",
        "The headset represents Samsung's entry into XR."
      ]
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 17:57:10 +0000",
      "title": "AWS outage reminds us why $2,449 Internet-dependent beds are a bad idea",
      "neutral_headline": "AWS Outage Highlights Risks of Internet-Dependent Devices",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/smart-beds-leave-sleepers-hot-and-bothered-during-aws-outage/",
          "published_at": "Wed, 22 Oct 2025 17:57:10 +0000",
          "title": "AWS outage reminds us why $2,449 Internet-dependent beds are a bad idea",
          "standfirst": "“Would be great if my bed wasn’t stuck in an inclined position ...\"",
          "content": "This week’s Amazon Web Services outage had some people waking up on the wrong side of the bed. A Domain Name System (DNS) resolution problem affected AWS cloud hosting, resulting in an outage that impacted more than 1,000 web-based products and services and millions of people. Perhaps one of the most avoidable breakdowns came via people’s beds. The reliance on the Internet for smart bed products from Eight Sleep resulted in people being awoken by beds locked into inclined positions and sweltering temperatures.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Eight-Sleep-Pod-5-Product-Full-System-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Eight-Sleep-Pod-5-Product-Full-System-1152x648.jpeg",
      "popularity_score": 133,
      "ai_summary": [
        "An AWS outage exposed the risks of internet-dependent devices.",
        "The outage affected devices like internet-connected beds.",
        "One user's bed was stuck in an inclined position.",
        "The incident highlighted the reliance on internet services.",
        "The outage raised concerns about device functionality."
      ]
    },
    {
      "id": "cluster_117",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 19:46:01 +0000",
      "title": "When sycophancy and bias meet medicine",
      "neutral_headline": "Bias and Sycophancy Threaten Medical Research",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/when-sycophancy-and-bias-meet-medicine/",
          "published_at": "Wed, 22 Oct 2025 19:46:01 +0000",
          "title": "When sycophancy and bias meet medicine",
          "standfirst": "Biased, eager-to-please models threaten health research replicability and trust.",
          "content": "Once upon a time, two villagers visited the fabled Mullah Nasreddin. They hoped that the Sufi philosopher, famed for his acerbic wisdom, could mediate a dispute that had driven a wedge between them. Nasreddin listened patiently to the first villager’s version of the story and, upon its conclusion, exclaimed, “You are absolutely right!” The second villager then presented his case. After hearing him out, Nasreddin again responded, “You are absolutely right!” An observant bystander, confused by Nasreddin’s proclamations, interjected, “But Mullah, they can’t both be right.” Nasreddin paused, regarding the bystander for a moment before replying, “You are absolutely right, too!” In late May, the White House’s first “Make America Healthy Again” (MAHA) report was criticized for citing multiple research studies that did not exist. Fabricated citations like these are common in the outputs of generative artificial intelligence based on large language models, or LLMs. LLMs have presented plausible-sounding sources, catchy titles, or even false data to craft their conclusions. Here, the White House pushed back on the journalists who first broke the story before admitting to “minor citation errors.” It is ironic that fake citations were used to support a principal recommendation of the MAHA report: addressing the health research sector’s “replication crisis,” wherein scientists’ findings often cannot be reproduced by other independent teams.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2214872699-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2214872699-1152x648.jpg",
      "popularity_score": 130,
      "ai_summary": [
        "Biased models threaten health research replicability.",
        "Eager-to-please models also pose a risk.",
        "These issues can undermine trust in research.",
        "The problems affect the reliability of studies.",
        "The issues highlight the need for critical evaluation."
      ]
    }
  ]
}