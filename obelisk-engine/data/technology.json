{
  "updated_at": "2026-01-05T23:20:20.195Z",
  "clusters": [
    {
      "id": "cluster_4",
      "coverage": 2,
      "updated_at": "Mon, 05 Jan 2026 23:01:25 +0000",
      "title": "AMD at CES 2026: Live updates from CEO Lisa Su's keynote presentation",
      "neutral_headline": "AMD at CES 2026: Live updates from CEO Lisa Su's keynote presentation",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/amd-at-ces-2026-live-updates-from-ceo-lisa-sus-keynote-presentation-190012370.html",
          "published_at": "Mon, 05 Jan 2026 23:01:25 +0000",
          "title": "AMD at CES 2026: Live updates from CEO Lisa Su's keynote presentation",
          "standfirst": "NVIDIA and Intel had their moment in the spotlight, and now it's AMD's turn. The chipmaker is kicking off CES 2026 on Monday night, where it'll cover its latest AI developments and perhaps show off its newest Ryzen chips. It's the kickoff keynote of CES 2026, and CEO Dr. Lisa Su is expected to outline how AMD's hardware will power the AI revolution — and what the company can offer partners and consumers that those aforementioned rivals can't. We'll tell you how to tune in to the livestream and what else you can expect to see. How to watch AMD's keynote live Dr. Su will deliver a keynote speech from the Palazzo Ballroom at the Venetian on Monday, January 5 at 9:30PM ET (6:30PM PT). You can watch the event live on the CES YouTube channel (we've embedded the livestream below). Engadget will also be liveblogging the AMD keynote in real-time. What to expect from AMD at CES 2026 While AMD says it's keeping its product details under wraps, we can expect \"updates on AI solutions, from cloud to enterprise, edge and devices.\" It's also likely that AMD will unveil its new versions of the Ryzen chips during its keynote on Monday, as Su will talk about the \"advancements driven by Ryzen CPUs.\" That could include the Ryzen 7 9850X3D, which is expected to have better single-threaded performance than its predecessors. Additionally, we can expect to see the Ryzen 9000G series, which is potentially built with AMD's Zen 5 architecture. Regarding AI, AMD could further discuss its new FSR Redstone technology, which it previously previewed on December 10. AMD's upscaling tech aims to close the gap on NVIDIA's DLSS 4, which was announced during CES 2025. Su's presentation caps off CES's press day, so she'll be taking the stage in the hours after rivals NVIDIA and Intel present their chipmaking and AI plans to the world. As a reminder of how cross-linked these companies have become: OpenAI has pledged billions of dollars of hardware orders to AMD, while rival NVIDIA has invested billions in OpenAI — and taken a stake worth billions in Intel, too. This article originally appeared on Engadget at https://www.engadget.com/computing/amd-at-ces-2026-live-updates-from-ceo-lisa-sus-keynote-presentation-190012370.html?src=rss",
          "content": "NVIDIA and Intel had their moment in the spotlight, and now it's AMD's turn. The chipmaker is kicking off CES 2026 on Monday night, where it'll cover its latest AI developments and perhaps show off its newest Ryzen chips. It's the kickoff keynote of CES 2026, and CEO Dr. Lisa Su is expected to outline how AMD's hardware will power the AI revolution — and what the company can offer partners and consumers that those aforementioned rivals can't. We'll tell you how to tune in to the livestream and what else you can expect to see. How to watch AMD's keynote live Dr. Su will deliver a keynote speech from the Palazzo Ballroom at the Venetian on Monday, January 5 at 9:30PM ET (6:30PM PT). You can watch the event live on the CES YouTube channel (we've embedded the livestream below). Engadget will also be liveblogging the AMD keynote in real-time. What to expect from AMD at CES 2026 While AMD says it's keeping its product details under wraps, we can expect \"updates on AI solutions, from cloud to enterprise, edge and devices.\" It's also likely that AMD will unveil its new versions of the Ryzen chips during its keynote on Monday, as Su will talk about the \"advancements driven by Ryzen CPUs.\" That could include the Ryzen 7 9850X3D, which is expected to have better single-threaded performance than its predecessors. Additionally, we can expect to see the Ryzen 9000G series, which is potentially built with AMD's Zen 5 architecture. Regarding AI, AMD could further discuss its new FSR Redstone technology, which it previously previewed on December 10. AMD's upscaling tech aims to close the gap on NVIDIA's DLSS 4, which was announced during CES 2025. Su's presentation caps off CES's press day, so she'll be taking the stage in the hours after rivals NVIDIA and Intel present their chipmaking and AI plans to the world. As a reminder of how cross-linked these companies have become: OpenAI has pledged billions of dollars of hardware orders to AMD, while rival NVIDIA has invested billions in OpenAI — and taken a stake worth billions in Intel, too. This article originally appeared on Engadget at https://www.engadget.com/computing/amd-at-ces-2026-live-updates-from-ceo-lisa-sus-keynote-presentation-190012370.html?src=rss",
          "feed_position": 0
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/acers-predator-helios-neo-16s-ai-laptop-can-be-outfitted-with-intels-new-core-ultra-9-386h-cpu-230048825.html",
          "published_at": "Mon, 05 Jan 2026 23:00:48 +0000",
          "title": "Acer's Predator Helios Neo 16S AI laptop can be outfitted with Intel's new Core Ultra 9 386H CPU",
          "standfirst": "Acer just announced the Predator Helios 16S AI gaming laptop at CES 2026. This computer is filled with both bells and whistles, making it a decent choice for modern gamers. To that end, the laptop can be equipped with up to an Intel Core Ultra 9 386H processor. This is Intel's upcoming flagship mobile processor that has previously been known as Panther Lake. The Helios 16S AI can also be outfitted with up to the NVIDIA GeForce RTX 5070 GPU. Acer It comes with a 16-inch WQXGA OLED display that offers true HDR imaging support. The laptop can be loaded with up to 64GB of RAM and up to 2TB of storage. The connectivity here is on point, with support for Thunderbolt 4, Wi-Fi 6E and Bluetooth. Everything is housed in an 18.9mm slim metal chassis. It looks pretty solid. We don't have any pricing, and the company might still be calculating that, given that ongoing RAM shortage. Acer says they'll disclose that closer to launch.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/acers-predator-helios-neo-16s-ai-laptop-can-be-outfitted-with-intels-new-core-ultra-9-386h-cpu-230048825.html?src=rss",
          "content": "Acer just announced the Predator Helios 16S AI gaming laptop at CES 2026. This computer is filled with both bells and whistles, making it a decent choice for modern gamers. To that end, the laptop can be equipped with up to an Intel Core Ultra 9 386H processor. This is Intel's upcoming flagship mobile processor that has previously been known as Panther Lake. The Helios 16S AI can also be outfitted with up to the NVIDIA GeForce RTX 5070 GPU. Acer It comes with a 16-inch WQXGA OLED display that offers true HDR imaging support. The laptop can be loaded with up to 64GB of RAM and up to 2TB of storage. The connectivity here is on point, with support for Thunderbolt 4, Wi-Fi 6E and Bluetooth. Everything is housed in an 18.9mm slim metal chassis. It looks pretty solid. We don't have any pricing, and the company might still be calculating that, given that ongoing RAM shortage. Acer says they'll disclose that closer to launch.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/acers-predator-helios-neo-16s-ai-laptop-can-be-outfitted-with-intels-new-core-ultra-9-386h-cpu-230048825.html?src=rss",
          "feed_position": 2,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/865fe6d0-e666-11f0-bf3e-78b0cfcd9889"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/samsungs-galaxy-book-6-series-ces-2026-intel-panther-lake-230010324.html",
          "published_at": "Mon, 05 Jan 2026 23:00:10 +0000",
          "title": "Samsung’s Galaxy Book 6 series launches at CES with Intel’s newest chips and a refined design",
          "standfirst": "In addition to huge TVs, compact projectors, Trifolds and more, Samsung announced a new family of laptops at CES called the Galaxy Book 6 series. The company says it’s focused on what matters and on what you, hopefully, want in your next laptop. That means Intel’s latest chips, a cleaner design and battery life that lasts longer than a day. They’re really thin, too. Timed alongside Intel’s CES announcements, the whole Galaxy Book 6 series features new Panther Lake chips, optimized by Samsung for three new laptops: The Galaxy Book 6 Ultra, Galaxy Book 6 Pro and Galaxy Book 6. The 16-inch Galaxy Book 6 Ultra can be equipped with up to Core Ultra X9 processors and promises significant performance improvements, with a new 5th-generation MPU, Intel Arc graphics and NVIDIA’s RTX 50 series GPUs (with RTX 5070 and 5060 options). That package leads Samsung to promise up to 1.6x greater CPU power and 1.7x improved graphics performance compared to the last Galaxy Book series. (It’s worth noting that Samsung skipped an Ultra configuration of the Galaxy Book 5 series.) All the laptops feature improved heat-management architecture, with a wider vapor chamber and re-engineered fans. At the same time, the Ultra features a new dual-path fan to cool the GPU even more efficiently and swiftly. Mat Smith for Engadget The Galaxy Book 6 Pro will come in 14- and 16-inch versions, with up to Core Ultra X7 processors and Intel Arc graphics. Both the Book 6 Ultra and Pro have improved AMOLED 2X (2,880 x 1,800) displays with touch, reaching up to 1000 nits of peak brightness — twice the brightness of the Book 5 Pro. Both models support adaptive refresh rates too, going up to 120Hz. The Book 6 Ultra has a more typical laptop shape, while the Book 6 Pro has a teardrop profile, made famous by the MacBook Air. Even if there’s some Apple inspiration, the Samsung laptops look great. Samsung has removed many unnecessary design elements. Although the Book 6 Ultra clings onto a USB-A port, it now (finally) has a full-size SD card reader, the lack of which was a major oversight on previous laptops. Mat Smith for Engadget Samsung has also tweaked the keyboard layout, though it’s too early to say whether it offers a significant improvement to the typing experience. It has added haptic trackpads to the Galaxy Book series for the first time too, although I found the one on my demo unit a little too hair-trigger sensitive to my touch. Thankfully, that’s something that can be addressed in the settings. As you might notice from the photos, there are upward-firing speakers on either side of the keyboard. The Book 6 Ultra has six built-in speakers (four woofers, two tweeters) and has apparently balanced them symmetrically to reduce noise distortion. Both laptops are slimmer than their predecessors, too. The Galaxy Book 6 Ultra is 15.4mm thick, while the Book 6 Pro is a svelte 11.9mm. Inside, Samsung has also enhanced heat management, including a wider vapour chamber and re-engineered fans, to ensure optimal performance during intensive tasks – apparently another priority for the Book 6 Series. Likewise, battery enclosures and placements have been re-engineered, and Samsung claims the new Book 6 Ultra and Pro can each deliver up to 30 hours of video playback. The Book 6 Ultra has the extra benefit of faster charging, reaching 63% in 30 minutes. It wouldn't be a laptop launch in 2026 without AI features. Alongside the Book 6 series, Samsung highlighted a tool that uses AI to help create cut-outs of images for copy-and-pasting across devices, as well as a Note Assist feature to help collate and summarize your notes. As is often the case at CES, Samsung hasn’t yet shared pricing or release dates for the Galaxy Book 6 series, so expect to hear more in the coming months.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/samsungs-galaxy-book-6-series-ces-2026-intel-panther-lake-230010324.html?src=rss",
          "content": "In addition to huge TVs, compact projectors, Trifolds and more, Samsung announced a new family of laptops at CES called the Galaxy Book 6 series. The company says it’s focused on what matters and on what you, hopefully, want in your next laptop. That means Intel’s latest chips, a cleaner design and battery life that lasts longer than a day. They’re really thin, too. Timed alongside Intel’s CES announcements, the whole Galaxy Book 6 series features new Panther Lake chips, optimized by Samsung for three new laptops: The Galaxy Book 6 Ultra, Galaxy Book 6 Pro and Galaxy Book 6. The 16-inch Galaxy Book 6 Ultra can be equipped with up to Core Ultra X9 processors and promises significant performance improvements, with a new 5th-generation MPU, Intel Arc graphics and NVIDIA’s RTX 50 series GPUs (with RTX 5070 and 5060 options). That package leads Samsung to promise up to 1.6x greater CPU power and 1.7x improved graphics performance compared to the last Galaxy Book series. (It’s worth noting that Samsung skipped an Ultra configuration of the Galaxy Book 5 series.) All the laptops feature improved heat-management architecture, with a wider vapor chamber and re-engineered fans. At the same time, the Ultra features a new dual-path fan to cool the GPU even more efficiently and swiftly. Mat Smith for Engadget The Galaxy Book 6 Pro will come in 14- and 16-inch versions, with up to Core Ultra X7 processors and Intel Arc graphics. Both the Book 6 Ultra and Pro have improved AMOLED 2X (2,880 x 1,800) displays with touch, reaching up to 1000 nits of peak brightness — twice the brightness of the Book 5 Pro. Both models support adaptive refresh rates too, going up to 120Hz. The Book 6 Ultra has a more typical laptop shape, while the Book 6 Pro has a teardrop profile, made famous by the MacBook Air. Even if there’s some Apple inspiration, the Samsung laptops look great. Samsung has removed many unnecessary design elements. Although the Book 6 Ultra clings onto a USB-A port, it now (finally) has a full-size SD card reader, the lack of which was a major oversight on previous laptops. Mat Smith for Engadget Samsung has also tweaked the keyboard layout, though it’s too early to say whether it offers a significant improvement to the typing experience. It has added haptic trackpads to the Galaxy Book series for the first time too, although I found the one on my demo unit a little too hair-trigger sensitive to my touch. Thankfully, that’s something that can be addressed in the settings. As you might notice from the photos, there are upward-firing speakers on either side of the keyboard. The Book 6 Ultra has six built-in speakers (four woofers, two tweeters) and has apparently balanced them symmetrically to reduce noise distortion. Both laptops are slimmer than their predecessors, too. The Galaxy Book 6 Ultra is 15.4mm thick, while the Book 6 Pro is a svelte 11.9mm. Inside, Samsung has also enhanced heat management, including a wider vapour chamber and re-engineered fans, to ensure optimal performance during intensive tasks – apparently another priority for the Book 6 Series. Likewise, battery enclosures and placements have been re-engineered, and Samsung claims the new Book 6 Ultra and Pro can each deliver up to 30 hours of video playback. The Book 6 Ultra has the extra benefit of faster charging, reaching 63% in 30 minutes. It wouldn't be a laptop launch in 2026 without AI features. Alongside the Book 6 series, Samsung highlighted a tool that uses AI to help create cut-outs of images for copy-and-pasting across devices, as well as a Note Assist feature to help collate and summarize your notes. As is often the case at CES, Samsung hasn’t yet shared pricing or release dates for the Galaxy Book 6 series, so expect to hear more in the coming months.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/samsungs-galaxy-book-6-series-ces-2026-intel-panther-lake-230010324.html?src=rss",
          "feed_position": 3,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/fa07a3c0-ea85-11f0-a52f-e92491d60a06"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/msi-unveils-new-gaming-and-prestige-business-laptops-at-ces-2026-230000027.html",
          "published_at": "Mon, 05 Jan 2026 23:00:00 +0000",
          "title": "MSI unveils new gaming and Prestige business laptops at CES 2026",
          "standfirst": "MSI has presented its refreshed Prestige lineup of business laptops, as well as its next-generation Raider, Stealth and Crosshair gaming models at this year’s CES. The Raider 16 Max HX is a 300w laptop, which the company says its its most powerful gaming model yet. It can supply 175w to its GeForce RTX 5090 or RTX 5080 GPU, while feeding 125w to its Intel Core Ultra 200HX processor at the same time under full-load conditions. To be able to handle that kind of power, MSI equipped it with a new cooling system consisting of three fans, six heat pipes, five exhaust vents and phase-change thermal compound. The Raider 16 Max also has a quick-access bottom panel that gives users an easy way to upgrade their storage and memory. Meanwhile, the new Stealth 16 AI+ laptop’s selling point seems to be its portability. It’s just 16.6mm thin, weighs under two kilograms, comes equipped with RTX 50 series GPU and has dual memory and SSD slots. MSI has also introduced the new Crosshair 16 Max HX and Crosshair 16 HX laptops powered by Intel Core Ultra 200HX processors and NVIDIA GeForce RTX 50 series GPUs at the event. Buyers can pay extra for an optional QHD+ 165Hz OLED display if they want sharper visuals, as well. In addition to its new gaming laptops, MSI has introduced its all-new Prestige 14 and Prestige 16 business laptops at CES. They’re slimmer with a more rounded silhouette compared to their predecessors, and they’re encased in full aluminum. The laptops are powered by the latest Intel Core Ultra Series 3 processors and are equipped with an 81Wh battery that can offer over 30 hours of video playback in 1080p. MSI has debuted the new Modern 14S and 16S series powered by the latest Intel Core Ultra Series 3 processors for everyday users, as well. Plus, the company has unveiled a Glacier Blue edition of its handheld gaming console, the Claw 8AI+, that’s powered by the Intel Core Ultra 200V processor with Arc Xe2 graphics. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/msi-unveils-new-gaming-and-prestige-business-laptops-at-ces-2026-230000027.html?src=rss",
          "content": "MSI has presented its refreshed Prestige lineup of business laptops, as well as its next-generation Raider, Stealth and Crosshair gaming models at this year’s CES. The Raider 16 Max HX is a 300w laptop, which the company says its its most powerful gaming model yet. It can supply 175w to its GeForce RTX 5090 or RTX 5080 GPU, while feeding 125w to its Intel Core Ultra 200HX processor at the same time under full-load conditions. To be able to handle that kind of power, MSI equipped it with a new cooling system consisting of three fans, six heat pipes, five exhaust vents and phase-change thermal compound. The Raider 16 Max also has a quick-access bottom panel that gives users an easy way to upgrade their storage and memory. Meanwhile, the new Stealth 16 AI+ laptop’s selling point seems to be its portability. It’s just 16.6mm thin, weighs under two kilograms, comes equipped with RTX 50 series GPU and has dual memory and SSD slots. MSI has also introduced the new Crosshair 16 Max HX and Crosshair 16 HX laptops powered by Intel Core Ultra 200HX processors and NVIDIA GeForce RTX 50 series GPUs at the event. Buyers can pay extra for an optional QHD+ 165Hz OLED display if they want sharper visuals, as well. In addition to its new gaming laptops, MSI has introduced its all-new Prestige 14 and Prestige 16 business laptops at CES. They’re slimmer with a more rounded silhouette compared to their predecessors, and they’re encased in full aluminum. The laptops are powered by the latest Intel Core Ultra Series 3 processors and are equipped with an 81Wh battery that can offer over 30 hours of video playback in 1080p. MSI has debuted the new Modern 14S and 16S series powered by the latest Intel Core Ultra Series 3 processors for everyday users, as well. Plus, the company has unveiled a Glacier Blue edition of its handheld gaming console, the Claw 8AI+, that’s powered by the Intel Core Ultra 200V processor with Arc Xe2 graphics. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/msi-unveils-new-gaming-and-prestige-business-laptops-at-ces-2026-230000027.html?src=rss",
          "feed_position": 4
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/acer-goes-big-on-the-haptic-trackpad-for-ces-with-the-swift-16-ai-laptop-230000750.html",
          "published_at": "Mon, 05 Jan 2026 23:00:00 +0000",
          "title": "Acer goes big on the haptic trackpad for CES with the Swift 16 AI laptop",
          "standfirst": "Acer has a handful of laptop updates at this year's CES show. The headlining item is the addition of the Acer Swift 16 AI to the company's flagship line. This laptop has what the company says is currently the world's largest haptic touchpad at 5.5mm by 109.7mm, and it can support up to MPP 2.5 stylus inputs. The screen is a 16-inch 3K OLED WQXGA+ touch display with HDR, a 120 Hz refresh rate and 100% DCI-P3 color gamut. On the inside, the Swift 16 AI can be kitted with up to an Intel Core Ultra X9 388H processor with built-in Intel Arc B390 graphics. The whole package is in a 14.9mm thin chassis and the machine weighs 1.55kg (about 3.4 lbs). Closeup of the trackpad on the Acer Swift 16 AI laptopAcer (modified)Another notable element in the company's CES announcements is Acer Swift Edge 14 AI, one of two new lightweight laptops revealed at the event. The Swift Edge 14 AI measures just 13.95mm thick and weighs 0.99kg (about 2.2 lbs). It is powered by up to an Intel Core Ultra 9 processor 386H. The max spec 14-inch screen has a 3KWQXGA+ OLED touch display with 120 Hz refresh rate.Both machines can have up to 32GB of RAM and are part of the Copilot+ PC program. Storage in the Swift 16 AI maxes out at 2TB while the Swift Edge 14 AI be up to 1TB.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/acer-goes-big-on-the-haptic-trackpad-for-ces-with-the-swift-16-ai-laptop-230000750.html?src=rss",
          "content": "Acer has a handful of laptop updates at this year's CES show. The headlining item is the addition of the Acer Swift 16 AI to the company's flagship line. This laptop has what the company says is currently the world's largest haptic touchpad at 5.5mm by 109.7mm, and it can support up to MPP 2.5 stylus inputs. The screen is a 16-inch 3K OLED WQXGA+ touch display with HDR, a 120 Hz refresh rate and 100% DCI-P3 color gamut. On the inside, the Swift 16 AI can be kitted with up to an Intel Core Ultra X9 388H processor with built-in Intel Arc B390 graphics. The whole package is in a 14.9mm thin chassis and the machine weighs 1.55kg (about 3.4 lbs). Closeup of the trackpad on the Acer Swift 16 AI laptopAcer (modified)Another notable element in the company's CES announcements is Acer Swift Edge 14 AI, one of two new lightweight laptops revealed at the event. The Swift Edge 14 AI measures just 13.95mm thick and weighs 0.99kg (about 2.2 lbs). It is powered by up to an Intel Core Ultra 9 processor 386H. The max spec 14-inch screen has a 3KWQXGA+ OLED touch display with 120 Hz refresh rate.Both machines can have up to 32GB of RAM and are part of the Copilot+ PC program. Storage in the Swift 16 AI maxes out at 2TB while the Swift Edge 14 AI be up to 1TB.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/acer-goes-big-on-the-haptic-trackpad-for-ces-with-the-swift-16-ai-laptop-230000750.html?src=rss",
          "feed_position": 5,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/touchpad.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/ces-2026-hp-says-the-hyperx-omen-max-16-is-the-most-powerful-16-inch-gaming-laptop-in-the-world-230000272.html",
          "published_at": "Mon, 05 Jan 2026 23:00:00 +0000",
          "title": "CES 2026: HP says the HyperX Omen Max 16 is the most powerful 16-inch gaming laptop in the world",
          "standfirst": "This year HP is making an important change by taking its name off its gaming hardware entirely and letting its HyperX branding take center stage. At CES 2026, the company is celebrating this transition in a big way with Omen Max 16, which is being heralded as the world’s most powerful gaming laptop with fully internal cooling.Now the last part of that claim is a bit of a cop out, but considering that most gamers probably don’t want to lug around a notebook with hoses coming out the back, it’s an understandable qualifier. Plus, with a total platform power of 300 watts that includes support for the latest chips from Intel and AMD and up to an NVIDIA RTX 5090 GPU, this thing certainly won’t be lacking in speed. Under the hood, the Max 16 features a third cooling fan to prevent throttling under sustained workloads along with HP’s Fan Cleaner tech that reverses the direction of the laptop’s fans to prevent dust from building up inside. As for its design, the Max 16 doesn’t stray too far from HyperX’s signature matte black color scheme, though I do appreciate that the company kept a handful of accents like the RGB lightbar mounted on the laptop’s front lip. The notebook also features a per-key RGB backlit keyboard with a 1,000Hz polling rate, which should all but eliminate any issues with ghosting or rollover during hectic facerolling sessions. However, one quirk about the system I noticed when checking it out first hand is that even with above average brightness of 500 nits for its 2.5K OLED display, the screen also comes with an unusually glossy coating. The benefit of this is that colors appear super saturated. The downside is that especially in well-lit rooms with a lot of sunlight, there’s more glare and reflections than you might expect. Another nice improvement about the Max 16 that might go unnoticed if you only look at its spec sheet is that despite having a TPP of 300 watts, its power brick is relatively compact. It wasn’t all that long ago that a laptop with this kind of performance might have required dual power cables in order to supply the notebook with the amount of juice it needs. That said, weighing between 6.1 and 6.5 pounds depending on the exact configuration, the Max 16 still isn’t the kind of laptop you’re going to want to carry around on a frequent basis. Regardless, if you’re in the market for what is essentially an old-school desktop replacement laptop without moving up to even larger 18-inch machines, HyperX’s latest flagship gaming laptop should be a strong contender that won’t be lacking in speed.One change for 2026 is that HP is taking its name off of its gaming systems and letting the HyperX brand take center stage. Sam Rutherford for EngadgetUnfortunately, HP doesn’t have concrete info about how much the HyperX Omen Max 16 will cost or when it will go on sale. However, we should know more when it becomes available sometime later this spring. And finally, if you’re looking for something slightly smaller or a more affordable system (we don't have official pricing, but the Max 16 won't come cheap), HP is also updating the Omen 15 and Omen 16 with fresh components and new HyperX branding for 2026 as well. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/ces-2026-hp-says-the-hyperx-omen-max-16-is-the-most-powerful-16-inch-gaming-laptop-in-the-world-230000272.html?src=rss",
          "content": "This year HP is making an important change by taking its name off its gaming hardware entirely and letting its HyperX branding take center stage. At CES 2026, the company is celebrating this transition in a big way with Omen Max 16, which is being heralded as the world’s most powerful gaming laptop with fully internal cooling.Now the last part of that claim is a bit of a cop out, but considering that most gamers probably don’t want to lug around a notebook with hoses coming out the back, it’s an understandable qualifier. Plus, with a total platform power of 300 watts that includes support for the latest chips from Intel and AMD and up to an NVIDIA RTX 5090 GPU, this thing certainly won’t be lacking in speed. Under the hood, the Max 16 features a third cooling fan to prevent throttling under sustained workloads along with HP’s Fan Cleaner tech that reverses the direction of the laptop’s fans to prevent dust from building up inside. As for its design, the Max 16 doesn’t stray too far from HyperX’s signature matte black color scheme, though I do appreciate that the company kept a handful of accents like the RGB lightbar mounted on the laptop’s front lip. The notebook also features a per-key RGB backlit keyboard with a 1,000Hz polling rate, which should all but eliminate any issues with ghosting or rollover during hectic facerolling sessions. However, one quirk about the system I noticed when checking it out first hand is that even with above average brightness of 500 nits for its 2.5K OLED display, the screen also comes with an unusually glossy coating. The benefit of this is that colors appear super saturated. The downside is that especially in well-lit rooms with a lot of sunlight, there’s more glare and reflections than you might expect. Another nice improvement about the Max 16 that might go unnoticed if you only look at its spec sheet is that despite having a TPP of 300 watts, its power brick is relatively compact. It wasn’t all that long ago that a laptop with this kind of performance might have required dual power cables in order to supply the notebook with the amount of juice it needs. That said, weighing between 6.1 and 6.5 pounds depending on the exact configuration, the Max 16 still isn’t the kind of laptop you’re going to want to carry around on a frequent basis. Regardless, if you’re in the market for what is essentially an old-school desktop replacement laptop without moving up to even larger 18-inch machines, HyperX’s latest flagship gaming laptop should be a strong contender that won’t be lacking in speed.One change for 2026 is that HP is taking its name off of its gaming systems and letting the HyperX brand take center stage. Sam Rutherford for EngadgetUnfortunately, HP doesn’t have concrete info about how much the HyperX Omen Max 16 will cost or when it will go on sale. However, we should know more when it becomes available sometime later this spring. And finally, if you’re looking for something slightly smaller or a more affordable system (we don't have official pricing, but the Max 16 won't come cheap), HP is also updating the Omen 15 and Omen 16 with fresh components and new HyperX branding for 2026 as well. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/ces-2026-hp-says-the-hyperx-omen-max-16-is-the-most-powerful-16-inch-gaming-laptop-in-the-world-230000272.html?src=rss",
          "feed_position": 6,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Max-16-lid.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-z-trifold-hands-on-flexing-is-believing-at-ces-2026-224343480.html",
          "published_at": "Mon, 05 Jan 2026 22:43:43 +0000",
          "title": "Samsung Galaxy Z TriFold hands-on: Flexing is believing at CES 2026",
          "standfirst": "When I first heard whispers about the Samsung Galaxy Z TriFold, I immediately felt conflicted. On one hand it felt like the natural evolution of bi-fold phones like the Z Fold 7. But on the other, all this fancy tech comes with an even higher price — around $2,500 based on current conversion rates from Korean won — not to mention the added bulk you get from a third folding panel. So even as someone who has used a foldable as my daily driver for almost a decade straight, it felt like Samsung’s latest high-end phone was going backwards in terms of both portability and affordability. But then at CES 2026, I got a chance to go hands-on with the Galaxy Z TriFold and all of my concerns pretty much instantly disappeared because with this thing, flexing is believing.My initial consternation comes in large part from using the Z Fold 7, which hit a major milestone this year thanks to a revamped design that doesn’t come with any added size or weight even when compared to comparable candybar-style phones like the Galaxy S25 Ultra. That’s a major breakthrough considering how hefty and chunky the original Galaxy Fold was back in 2019. And when you compare the Z Fold 7’s dimensions (7.58 ounces and 8.9mm thick when folded) to the new TriFold (10.9 ounces and 12.9mm when folded), there’s no doubt that Samsung’s new flagship foldable comes with a lot of extra bulk. To put things into context, we have to go back several generations to the Z Fold 5 just to find a comparable phone with similar thickness (13.4mm). And even then, that handset is still significantly lighter than the TriFold at 8.92 ounces. There's simply no denying that the Z TriFold (left) is a much bulkier device than the Z Fold 7 (right). Sam Rutherford for EngadgetBut then I opened it up and my concerns were quickly pushed aside because suddenly you’re greeted with 10 inches of vivid AMOLED goodness. As a phone that can pull double duty as a tablet, the jump up from the Z Fold 7’s 8-inch main display cannot be understated. Not only does it make multitasking so much easier, when combined with Samsung’s DeX desktop mode, you basically get a miniature laptop experience from a device that fits in a pocket. Especially if you don’t mind carrying around a travel-friendly mouse and keyboard. Plus, you can connect the TriFold to an external display (either wired or wirelessly) to access even more screen space. Way more than with the Z Fold 7, I can honestly see myself leaving my PC at home and using the TriFold as my primary work device. Another important but easily overlooked upgrade on the Galaxy Z Trifold is the 4:3 aspect ratio for its 10-inch main display. Compared to the Z Fold 7 and its almost perfectly square screen, you just get so much extra room on the sides for widescreen movies and shows. I tested this out by watching the trailer for Christopher Nolan’s The Odyssey, and even though that movie uses a super wide aspect ratio due to being filmed entirely on IMAX cameras, the viewing experience was just so much better. Peak watchability is something the regular Z Fold line has sort of left by the wayside as the company moved to larger exterior displays, which resulted in the series’ primary screen becoming more square. The one downside though is that the TriFold may make you more of a resolution snob, as it’s a lot easier to tell the difference between 1080p and 2K or 4K on a larger 10-inch panel. The final pillar of the TriFold’s kit is all the engineering that Samsung put into making it easy to open and close. Simply moving from one hinge to two while adding a third folding panel undersells the complexity of its design. Samsung actually uses two different types of magnets that push or pull depending on where they are, which makes accessing the TriFold’s primary display practically just as easy as on the Z Fold 7. That’s no small feat. Opening and shutting this thing is just so satisfying on a tactile level, and that’s before you consider that there’s basically no downgrade in terms of image quality. While there’s only one way to unfurl the TriFold, which might seem confusing at first, Samsung addressed that too by throwing up a warning and making the whole phone vibrate if you try to do it wrong. And then there are components like the glass-reinforced carbon panels Samsung uses to add strength and durability to its chassis while keeping it as thin as possible. The one potential concern in the future is that unlike Samsung’s older foldables, there’s not as much room for improvement to shrink its dimensions much further, as the TriFold’s slimness is currently limited by the size of its USB-C jack. So if the next model wants to make big gains there, it may need to go completely portless.Here's what The Odyssey trailer looks like on the Z TriFold (right) compared to the Z Fold 7 (left). It's such a better experience. Sam Rutherford for EngadgetOn a certain level, I kind of hate how much I like the Galaxy Z TriFold. I really don’t want to go back to bigger, heavier phones that are even more bulky and expensive than the Z Fold 7. But the appeal is impossible to deny and for people who love a good multitasker, I can easily see how these tradeoffs are worth the upside of Samsung’s latest apex foldable. The Samsung Galaxy Z TriFold is currently on sale in South Korea, though we’re still waiting for official pricing and availability for the US and North American market.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-z-trifold-hands-on-flexing-is-believing-at-ces-2026-224343480.html?src=rss",
          "content": "When I first heard whispers about the Samsung Galaxy Z TriFold, I immediately felt conflicted. On one hand it felt like the natural evolution of bi-fold phones like the Z Fold 7. But on the other, all this fancy tech comes with an even higher price — around $2,500 based on current conversion rates from Korean won — not to mention the added bulk you get from a third folding panel. So even as someone who has used a foldable as my daily driver for almost a decade straight, it felt like Samsung’s latest high-end phone was going backwards in terms of both portability and affordability. But then at CES 2026, I got a chance to go hands-on with the Galaxy Z TriFold and all of my concerns pretty much instantly disappeared because with this thing, flexing is believing.My initial consternation comes in large part from using the Z Fold 7, which hit a major milestone this year thanks to a revamped design that doesn’t come with any added size or weight even when compared to comparable candybar-style phones like the Galaxy S25 Ultra. That’s a major breakthrough considering how hefty and chunky the original Galaxy Fold was back in 2019. And when you compare the Z Fold 7’s dimensions (7.58 ounces and 8.9mm thick when folded) to the new TriFold (10.9 ounces and 12.9mm when folded), there’s no doubt that Samsung’s new flagship foldable comes with a lot of extra bulk. To put things into context, we have to go back several generations to the Z Fold 5 just to find a comparable phone with similar thickness (13.4mm). And even then, that handset is still significantly lighter than the TriFold at 8.92 ounces. There's simply no denying that the Z TriFold (left) is a much bulkier device than the Z Fold 7 (right). Sam Rutherford for EngadgetBut then I opened it up and my concerns were quickly pushed aside because suddenly you’re greeted with 10 inches of vivid AMOLED goodness. As a phone that can pull double duty as a tablet, the jump up from the Z Fold 7’s 8-inch main display cannot be understated. Not only does it make multitasking so much easier, when combined with Samsung’s DeX desktop mode, you basically get a miniature laptop experience from a device that fits in a pocket. Especially if you don’t mind carrying around a travel-friendly mouse and keyboard. Plus, you can connect the TriFold to an external display (either wired or wirelessly) to access even more screen space. Way more than with the Z Fold 7, I can honestly see myself leaving my PC at home and using the TriFold as my primary work device. Another important but easily overlooked upgrade on the Galaxy Z Trifold is the 4:3 aspect ratio for its 10-inch main display. Compared to the Z Fold 7 and its almost perfectly square screen, you just get so much extra room on the sides for widescreen movies and shows. I tested this out by watching the trailer for Christopher Nolan’s The Odyssey, and even though that movie uses a super wide aspect ratio due to being filmed entirely on IMAX cameras, the viewing experience was just so much better. Peak watchability is something the regular Z Fold line has sort of left by the wayside as the company moved to larger exterior displays, which resulted in the series’ primary screen becoming more square. The one downside though is that the TriFold may make you more of a resolution snob, as it’s a lot easier to tell the difference between 1080p and 2K or 4K on a larger 10-inch panel. The final pillar of the TriFold’s kit is all the engineering that Samsung put into making it easy to open and close. Simply moving from one hinge to two while adding a third folding panel undersells the complexity of its design. Samsung actually uses two different types of magnets that push or pull depending on where they are, which makes accessing the TriFold’s primary display practically just as easy as on the Z Fold 7. That’s no small feat. Opening and shutting this thing is just so satisfying on a tactile level, and that’s before you consider that there’s basically no downgrade in terms of image quality. While there’s only one way to unfurl the TriFold, which might seem confusing at first, Samsung addressed that too by throwing up a warning and making the whole phone vibrate if you try to do it wrong. And then there are components like the glass-reinforced carbon panels Samsung uses to add strength and durability to its chassis while keeping it as thin as possible. The one potential concern in the future is that unlike Samsung’s older foldables, there’s not as much room for improvement to shrink its dimensions much further, as the TriFold’s slimness is currently limited by the size of its USB-C jack. So if the next model wants to make big gains there, it may need to go completely portless.Here's what The Odyssey trailer looks like on the Z TriFold (right) compared to the Z Fold 7 (left). It's such a better experience. Sam Rutherford for EngadgetOn a certain level, I kind of hate how much I like the Galaxy Z TriFold. I really don’t want to go back to bigger, heavier phones that are even more bulky and expensive than the Z Fold 7. But the appeal is impossible to deny and for people who love a good multitasker, I can easily see how these tradeoffs are worth the upside of Samsung’s latest apex foldable. The Samsung Galaxy Z TriFold is currently on sale in South Korea, though we’re still waiting for official pricing and availability for the US and North American market.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-z-trifold-hands-on-flexing-is-believing-at-ces-2026-224343480.html?src=rss",
          "feed_position": 8,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/TriFold-thickness.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/google-tvs-new-gemini-features-range-from-useful-to-unnecessary-222900001.html",
          "published_at": "Mon, 05 Jan 2026 22:29:00 +0000",
          "title": "Google TV's new Gemini features range from useful to unnecessary",
          "standfirst": "I met up with a few people from Google at the Encore Villas during CES (which is just 2,500 feet from my hotel but took 28 minutes to walk to, thanks to Vegas’s pedestrian-averse design [also I got lost]). Once there, I saw what “more Gemini” will mean for people with a Google TV. The AI integration ranged from useful to probably unnecessary. The most useful bit, for me at least, came at the end. It’s admittedly a boring, but now you an adjust your TV’s settings just by talking. In the demo, Salahuddin Choudhary, Google’s Gemini for Android product lead said, “Can you boost the dialogue?” and Gemini changed the mode accordingly, without leaving the golf game he was watching. I asked if it could turn off motion smoothing, the first thing I adjust on a new TV (and sometimes other people’s). Yes, it can. The “deep dive” Gemini feature could prove fairly useful, too. With it, asking for general information turns into a mini lesson on the subject, complete with generated images and narration. When Choudhary asked Gemini to “explain the Northern Lights to [his] eighth grader,” the screen filled with the standard Gemini answer: a brief definition and images and video tiles for further exploration. But a small Dive deeper button on the screen led to a narrated and illustrated tour of the science behind the phenomenon. My kid is at the age where he asks me questions I can’t answer about the fundamental makeup of the universe — maybe this could help.The Google TV demo at CES showed an answer on the science behind how the northern lights are created Amy Skorheim for EngadgetGoogle Photos is getting a much deeper integration with Google TVs, too. Choudhary asked for pics from a trip to the beach and snapshots of happy people amongst the sea and sand popped up on the screen. One particular shot would make a nice screen saver, I was told, and he asked Gemini to give the photo an oil painting makeover using the Remix feature. However, if you want your photo recast in a way not offered with Remix, you can use Nano Banana. Choudhary turned one of the personal photos into a cartoon just by asking. Using Veo turned the same image into an short (if slightly glitchy) animation of a person playing fetch with the dog in the photo. Google TV used Neo to recast a picture as a cartoon.Amy Skorheim for EngadgetYour ability to generate video will depend on your Gemini subscription tier, but I was told a purchase of a Google TV device would include most of the other AI capabilities that I saw demonstrated. I’d classify the photo manipulation and video generation as decidedly less useful that the other features, but my kid would probably get a kick out of messing with them for a while. For people who use Gemini a lot, being able to do so on the biggest screen in the house may appeal. Ditto for those who like seeing your Google Photos in a giant format. Some folks will appreciate the AI image manipulation and generation, I’m sure, but I’m mostly excited about the admittedly boring part of not having to leave a show to boost the brightness of a scene. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/google-tvs-new-gemini-features-range-from-useful-to-unnecessary-222900001.html?src=rss",
          "content": "I met up with a few people from Google at the Encore Villas during CES (which is just 2,500 feet from my hotel but took 28 minutes to walk to, thanks to Vegas’s pedestrian-averse design [also I got lost]). Once there, I saw what “more Gemini” will mean for people with a Google TV. The AI integration ranged from useful to probably unnecessary. The most useful bit, for me at least, came at the end. It’s admittedly a boring, but now you an adjust your TV’s settings just by talking. In the demo, Salahuddin Choudhary, Google’s Gemini for Android product lead said, “Can you boost the dialogue?” and Gemini changed the mode accordingly, without leaving the golf game he was watching. I asked if it could turn off motion smoothing, the first thing I adjust on a new TV (and sometimes other people’s). Yes, it can. The “deep dive” Gemini feature could prove fairly useful, too. With it, asking for general information turns into a mini lesson on the subject, complete with generated images and narration. When Choudhary asked Gemini to “explain the Northern Lights to [his] eighth grader,” the screen filled with the standard Gemini answer: a brief definition and images and video tiles for further exploration. But a small Dive deeper button on the screen led to a narrated and illustrated tour of the science behind the phenomenon. My kid is at the age where he asks me questions I can’t answer about the fundamental makeup of the universe — maybe this could help.The Google TV demo at CES showed an answer on the science behind how the northern lights are created Amy Skorheim for EngadgetGoogle Photos is getting a much deeper integration with Google TVs, too. Choudhary asked for pics from a trip to the beach and snapshots of happy people amongst the sea and sand popped up on the screen. One particular shot would make a nice screen saver, I was told, and he asked Gemini to give the photo an oil painting makeover using the Remix feature. However, if you want your photo recast in a way not offered with Remix, you can use Nano Banana. Choudhary turned one of the personal photos into a cartoon just by asking. Using Veo turned the same image into an short (if slightly glitchy) animation of a person playing fetch with the dog in the photo. Google TV used Neo to recast a picture as a cartoon.Amy Skorheim for EngadgetYour ability to generate video will depend on your Gemini subscription tier, but I was told a purchase of a Google TV device would include most of the other AI capabilities that I saw demonstrated. I’d classify the photo manipulation and video generation as decidedly less useful that the other features, but my kid would probably get a kick out of messing with them for a while. For people who use Gemini a lot, being able to do so on the biggest screen in the house may appeal. Ditto for those who like seeing your Google Photos in a giant format. Some folks will appreciate the AI image manipulation and generation, I’m sure, but I’m mostly excited about the admittedly boring part of not having to leave a show to boost the brightness of a scene. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/google-tvs-new-gemini-features-range-from-useful-to-unnecessary-222900001.html?src=rss",
          "feed_position": 9,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/google_tv_northern_lights_lesson.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/tiis-falcon-h1r-7b-can-out-reason-models-up-to-7x-its-size-and-its-mostly",
          "published_at": "Mon, 05 Jan 2026 20:27:00 GMT",
          "title": "TII’s Falcon H1R 7B can out-reason models up to 7x its size — and it’s (mostly) open",
          "standfirst": "For the last two years, the prevailing logic in generative AI has been one of brute force: if you want better reasoning, you need a bigger model. While \"small\" models (under 10 billion parameters) have become capable conversationalists, they have historically crumbled when asked to perform multi-step logical deduction or complex mathematical proofs.Today, the Technology Innovation Institute (TII) in Abu Dhabi is challenging that scaling law with the release of Falcon H1R 7B. By abandoning the pure Transformer orthodoxy in favor of a hybrid architecture, TII claims to have built a 7-billion parameter model that not only rivals but outperforms competitors nearly 7X its size — including the 32B and 47B variants of Alibaba&#x27;s Qwen and Nvidia&#x27;s Nemotron.The release marks a significant shift in the open-weight ecosystem, moving the battleground from raw parameter count to architectural efficiency and inference-time scaling.The full model code is available now at Hugging Face and can be tested by individuals in a live demo inference on Falcon Chat (a chatbot experience). TII further released a seemingly quite comprehensive technical report on the approach and training methodology for Falcon H1 7B, as well. Moving Beyond the Foundational LLM Tech, the TransformerThe defining feature of Falcon H1R 7B is its \"hybrid\" backbone. Most modern LLMs rely exclusively on the Transformer architecture, which scales predictably but suffers from high memory costs when processing long sequences. Falcon H1R 7B integrates Mamba, a state-space model (SSM) architecture, alongside standard Transformer attention layers.Originally developed by researchers Albert Gu and Tri Dao at Carnegie Mellon University and Princeton University, Mamba was first introduced in the paper \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\" published on December 1, 2023.The architecture processes data sequences differently than Transformers: while Transformers compare every piece of data to every other piece (quadratic scaling), Mamba processes tokens sequentially, allowing it to handle vast amounts of information with linear scaling and significantly reduced compute costs.This combination addresses one of the most persistent bottlenecks in deploying reasoning models: the cost of \"thinking.\" Reasoning models require generating long \"chains of thought\"—step-by-step internal monologues—before arriving at an answer. For standard Transformers, these long contexts explode computational costs.According to TII’s technical report, the hybrid approach allows Falcon H1R 7B to maintain high throughput even as response lengths grow. At a batch size of 64, the model processes approximately 1,500 tokens per second per GPU—nearly double the speed of the competing Qwen3 8B model.Benchmark Performance: Punching UpIn the benchmarks released by TII, the disparity between Falcon H1R 7B’s size and its performance is stark. On the AIME 2025 leaderboard—a rigorous test of mathematical reasoning—Falcon H1R 7B scored 83.1%, a result that disrupts the traditional hierarchy of model sizing.While the 7B model naturally trails massive proprietary frontiers like GPT-5.2 (99.0%) and Gemini 3 Flash (97.0%) on the separate Artificial Analysis index (run by the independent organization of the same name, which has not yet benchmarked Falcon H1R 7B yet), it has effectively collapsed the gap between \"efficient\" open weights and mid-tier proprietary systems.Beating Larger \"Thinkers\": Falcon H1R 7B (83.1%) outperforms the 15-billion parameter Apriel-v1.6-Thinker (82.7%) and the 32-billion parameter OLMo 3 Think (73.7%), validating TII&#x27;s claim that hybrid architectures can out-reason larger Transformers.Chasing Proprietary Leaders: It sits within striking distance of Claude 4.5 Sonnet (88.0%) and Amazon Nova 2.0 Lite (88.7%), suggesting that for specific math-heavy workflows, this 7B model is a viable, low-latency alternative to expensive commercial APIs.Outperforming Legacy Giants: On this specific reasoning metric, it decisively beats broadly capable but older architectures like Mistral Large 3 (38.0%) and Llama 4 Maverick (19.3%), highlighting how specialized reasoning training (\"Deep Think\") has become more critical than raw scale for logic tasks.Other key domain wins include:Coding: The model achieved 68.6% on the LCB v6 benchmark, a score TII claims is the highest among all tested models, including those four times its size.General Reasoning: While it dominates in math and code, its general reasoning score (49.48%) remains competitive, sitting just below the 14B and 15B parameter models but comfortably ahead of comparable 8B models.Training TechniquesFalcon H1R 7B’s performance is not just architectural; it stems from a rigorous, two-stage training pipeline designed to maximize reasoning density without inflating parameter count, according to TII&#x27;s technical report on the model.Stage 1: Cold-Start Supervised Fine-Tuning (SFT). The model underwent \"cold-start\" SFT on a curated dataset dominated by mathematics (56.8% of tokens) and code (29.8%), with response lengths stretching up to 48,000 tokens.Difficulty-Aware Weighting: TII rejected the standard practice of treating all data equally. Instead, they applied a weighting scheme where \"hard\" problems were up-weighted by 1.25x to 1.75x, while easy problems were down-weighted or removed entirely to prevent overfitting to trivial tasks.Single-Teacher Consistency: Ablation studies revealed that mixing reasoning traces from multiple \"teacher\" models actually degraded performance due to conflicting reasoning styles. Consequently, TII opted for a single-teacher approach to maintain coherent internal logic.Balanced Token Normalization: To handle the massive variance in sequence lengths (short instructions vs. massive reasoning chains), the team introduced a Balanced Data-Parallel Token Normalization strategy. This technique equalizes the gradient contribution of each token across GPUs, preventing ranks with shorter sequences from destabilizing the loss—a change that yielded a consistent 4-10% accuracy boost during training.Stage 2: Reinforcement Learning via Group Relative Policy Optimization (GRPO). Following SFT, the model was refined using GRPO a reinforcement learning algorithm that rewards correct outcomes without needing a separate value model.The \"No-KL\" Shift: In a deviation from standard RLHF, TII removed the KL-divergence penalty (beta=0) entirely. This allowed the model to drift significantly from its base SFT policy, encouraging aggressive exploration of novel reasoning paths.Math-Only Curriculum: Surprisingly, TII found that training exclusively on math problems during the RL stage yielded better generalization across all domains—including code and science—than mixed strategies. Ablations showed that \"code-only\" training improved coding scores but harmed general reasoning, whereas math-focused RL lifted performance globally.TII optimized the model specifically for Test-Time Scaling (TTS), a technique where a model generates multiple reasoning paths in parallel to find the best solution.The model utilizes Deep Think with Confidence (DeepConf), which leverages the model&#x27;s internal confidence scores to dynamically prune low-quality reasoning traces.Adaptive Pruning: During generation, the system initiates a \"warm-up\" phase with 16 traces to establish a confidence baseline. It then aggressively filters subsequent traces, terminating any chain that falls below the 10th percentile of the baseline confidence.Efficiency Gains: This method creates a new Pareto frontier for deployment. In benchmark tests, Falcon H1R 7B achieved 96.7% accuracy on AIME 25 while reducing token usage by 38% compared to the DeepSeek-R1-0528-Qwen3-8B baseline.Licensing: Open For Commercial Usage, But With Strings AttachedTII has released Falcon H1R 7B under the custom Falcon LLM License 1.0 based on Apache 2.0 — but with notable modifications — chiefly among them: not to litigate against TII, and also to always credit it.For developers and startups, the license is largely permissive:Royalty-Free: Users can run, modify, and distribute the model commercially without paying TII.Attribution: Any derivative work (including fine-tunes) must prominently state: \"[Name of work] is built using Falcon LLM technology from the Technology Innovation Institute\".However, unlike a pure Open Source Initiative (OSI) license, the Falcon license includes a strict Acceptable Use Policy (AUP). The license terminates automatically if the model is used to create work that conflicts with the AUP or if the user initiates patent litigation against TII. Specifically, the AUP prohibits using Falcon H1R 7B or its derivatives for:Violating Laws: Any use that violates applicable national, federal, state, local, or international laws or regulations.Harm to Minors or Living Beings: Exploiting, harming, or attempting to exploit or harm minors or any living beings.Disinformation: Generating or disseminating verifiably false information with the purpose of harming others.Harassment: Defaming, disparaging, or otherwise harassing others.The Hybrid Wave: Nvidia, IBM, AI21, and MistralTII is not alone in betting on this hybrid future; the industry is increasingly moving toward architectures that blend the strengths of SSMs and Transformers.Nvidia recently debuted the Nemotron 3 family on December 15, 2025, which utilizes a hybrid mixture-of-experts (MoE) and Mamba-Transformer design to drive efficient agentic AI.IBM launched its Granite 4.0 family on October 2, 2025, using a hybrid Mamba-Transformer architecture to cut memory requirements by over 70% while maintaining high performance on enterprise benchmarks.AI21 has pursued this path with its Jamba (Joint Attention and Mamba) models, releasing the Jamba 1.5 family on August 22, 2024, to boost agentic AI capabilities through a hybrid SSM-Transformer approach.Mistral entered the space early with Codestral Mamba on July 16, 2024, a model specifically optimized for faster, longer code generation.Falcon H1R 7B represents the latest evolution in this trend, specifically targeting dense reasoning tasks in a compact form factor.",
          "content": "For the last two years, the prevailing logic in generative AI has been one of brute force: if you want better reasoning, you need a bigger model. While \"small\" models (under 10 billion parameters) have become capable conversationalists, they have historically crumbled when asked to perform multi-step logical deduction or complex mathematical proofs.Today, the Technology Innovation Institute (TII) in Abu Dhabi is challenging that scaling law with the release of Falcon H1R 7B. By abandoning the pure Transformer orthodoxy in favor of a hybrid architecture, TII claims to have built a 7-billion parameter model that not only rivals but outperforms competitors nearly 7X its size — including the 32B and 47B variants of Alibaba&#x27;s Qwen and Nvidia&#x27;s Nemotron.The release marks a significant shift in the open-weight ecosystem, moving the battleground from raw parameter count to architectural efficiency and inference-time scaling.The full model code is available now at Hugging Face and can be tested by individuals in a live demo inference on Falcon Chat (a chatbot experience). TII further released a seemingly quite comprehensive technical report on the approach and training methodology for Falcon H1 7B, as well. Moving Beyond the Foundational LLM Tech, the TransformerThe defining feature of Falcon H1R 7B is its \"hybrid\" backbone. Most modern LLMs rely exclusively on the Transformer architecture, which scales predictably but suffers from high memory costs when processing long sequences. Falcon H1R 7B integrates Mamba, a state-space model (SSM) architecture, alongside standard Transformer attention layers.Originally developed by researchers Albert Gu and Tri Dao at Carnegie Mellon University and Princeton University, Mamba was first introduced in the paper \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\" published on December 1, 2023.The architecture processes data sequences differently than Transformers: while Transformers compare every piece of data to every other piece (quadratic scaling), Mamba processes tokens sequentially, allowing it to handle vast amounts of information with linear scaling and significantly reduced compute costs.This combination addresses one of the most persistent bottlenecks in deploying reasoning models: the cost of \"thinking.\" Reasoning models require generating long \"chains of thought\"—step-by-step internal monologues—before arriving at an answer. For standard Transformers, these long contexts explode computational costs.According to TII’s technical report, the hybrid approach allows Falcon H1R 7B to maintain high throughput even as response lengths grow. At a batch size of 64, the model processes approximately 1,500 tokens per second per GPU—nearly double the speed of the competing Qwen3 8B model.Benchmark Performance: Punching UpIn the benchmarks released by TII, the disparity between Falcon H1R 7B’s size and its performance is stark. On the AIME 2025 leaderboard—a rigorous test of mathematical reasoning—Falcon H1R 7B scored 83.1%, a result that disrupts the traditional hierarchy of model sizing.While the 7B model naturally trails massive proprietary frontiers like GPT-5.2 (99.0%) and Gemini 3 Flash (97.0%) on the separate Artificial Analysis index (run by the independent organization of the same name, which has not yet benchmarked Falcon H1R 7B yet), it has effectively collapsed the gap between \"efficient\" open weights and mid-tier proprietary systems.Beating Larger \"Thinkers\": Falcon H1R 7B (83.1%) outperforms the 15-billion parameter Apriel-v1.6-Thinker (82.7%) and the 32-billion parameter OLMo 3 Think (73.7%), validating TII&#x27;s claim that hybrid architectures can out-reason larger Transformers.Chasing Proprietary Leaders: It sits within striking distance of Claude 4.5 Sonnet (88.0%) and Amazon Nova 2.0 Lite (88.7%), suggesting that for specific math-heavy workflows, this 7B model is a viable, low-latency alternative to expensive commercial APIs.Outperforming Legacy Giants: On this specific reasoning metric, it decisively beats broadly capable but older architectures like Mistral Large 3 (38.0%) and Llama 4 Maverick (19.3%), highlighting how specialized reasoning training (\"Deep Think\") has become more critical than raw scale for logic tasks.Other key domain wins include:Coding: The model achieved 68.6% on the LCB v6 benchmark, a score TII claims is the highest among all tested models, including those four times its size.General Reasoning: While it dominates in math and code, its general reasoning score (49.48%) remains competitive, sitting just below the 14B and 15B parameter models but comfortably ahead of comparable 8B models.Training TechniquesFalcon H1R 7B’s performance is not just architectural; it stems from a rigorous, two-stage training pipeline designed to maximize reasoning density without inflating parameter count, according to TII&#x27;s technical report on the model.Stage 1: Cold-Start Supervised Fine-Tuning (SFT). The model underwent \"cold-start\" SFT on a curated dataset dominated by mathematics (56.8% of tokens) and code (29.8%), with response lengths stretching up to 48,000 tokens.Difficulty-Aware Weighting: TII rejected the standard practice of treating all data equally. Instead, they applied a weighting scheme where \"hard\" problems were up-weighted by 1.25x to 1.75x, while easy problems were down-weighted or removed entirely to prevent overfitting to trivial tasks.Single-Teacher Consistency: Ablation studies revealed that mixing reasoning traces from multiple \"teacher\" models actually degraded performance due to conflicting reasoning styles. Consequently, TII opted for a single-teacher approach to maintain coherent internal logic.Balanced Token Normalization: To handle the massive variance in sequence lengths (short instructions vs. massive reasoning chains), the team introduced a Balanced Data-Parallel Token Normalization strategy. This technique equalizes the gradient contribution of each token across GPUs, preventing ranks with shorter sequences from destabilizing the loss—a change that yielded a consistent 4-10% accuracy boost during training.Stage 2: Reinforcement Learning via Group Relative Policy Optimization (GRPO). Following SFT, the model was refined using GRPO a reinforcement learning algorithm that rewards correct outcomes without needing a separate value model.The \"No-KL\" Shift: In a deviation from standard RLHF, TII removed the KL-divergence penalty (beta=0) entirely. This allowed the model to drift significantly from its base SFT policy, encouraging aggressive exploration of novel reasoning paths.Math-Only Curriculum: Surprisingly, TII found that training exclusively on math problems during the RL stage yielded better generalization across all domains—including code and science—than mixed strategies. Ablations showed that \"code-only\" training improved coding scores but harmed general reasoning, whereas math-focused RL lifted performance globally.TII optimized the model specifically for Test-Time Scaling (TTS), a technique where a model generates multiple reasoning paths in parallel to find the best solution.The model utilizes Deep Think with Confidence (DeepConf), which leverages the model&#x27;s internal confidence scores to dynamically prune low-quality reasoning traces.Adaptive Pruning: During generation, the system initiates a \"warm-up\" phase with 16 traces to establish a confidence baseline. It then aggressively filters subsequent traces, terminating any chain that falls below the 10th percentile of the baseline confidence.Efficiency Gains: This method creates a new Pareto frontier for deployment. In benchmark tests, Falcon H1R 7B achieved 96.7% accuracy on AIME 25 while reducing token usage by 38% compared to the DeepSeek-R1-0528-Qwen3-8B baseline.Licensing: Open For Commercial Usage, But With Strings AttachedTII has released Falcon H1R 7B under the custom Falcon LLM License 1.0 based on Apache 2.0 — but with notable modifications — chiefly among them: not to litigate against TII, and also to always credit it.For developers and startups, the license is largely permissive:Royalty-Free: Users can run, modify, and distribute the model commercially without paying TII.Attribution: Any derivative work (including fine-tunes) must prominently state: \"[Name of work] is built using Falcon LLM technology from the Technology Innovation Institute\".However, unlike a pure Open Source Initiative (OSI) license, the Falcon license includes a strict Acceptable Use Policy (AUP). The license terminates automatically if the model is used to create work that conflicts with the AUP or if the user initiates patent litigation against TII. Specifically, the AUP prohibits using Falcon H1R 7B or its derivatives for:Violating Laws: Any use that violates applicable national, federal, state, local, or international laws or regulations.Harm to Minors or Living Beings: Exploiting, harming, or attempting to exploit or harm minors or any living beings.Disinformation: Generating or disseminating verifiably false information with the purpose of harming others.Harassment: Defaming, disparaging, or otherwise harassing others.The Hybrid Wave: Nvidia, IBM, AI21, and MistralTII is not alone in betting on this hybrid future; the industry is increasingly moving toward architectures that blend the strengths of SSMs and Transformers.Nvidia recently debuted the Nemotron 3 family on December 15, 2025, which utilizes a hybrid mixture-of-experts (MoE) and Mamba-Transformer design to drive efficient agentic AI.IBM launched its Granite 4.0 family on October 2, 2025, using a hybrid Mamba-Transformer architecture to cut memory requirements by over 70% while maintaining high performance on enterprise benchmarks.AI21 has pursued this path with its Jamba (Joint Attention and Mamba) models, releasing the Jamba 1.5 family on August 22, 2024, to boost agentic AI capabilities through a hybrid SSM-Transformer approach.Mistral entered the space early with Codestral Mamba on July 16, 2024, a model specifically optimized for faster, longer code generation.Falcon H1R 7B represents the latest evolution in this trend, specifically targeting dense reasoning tasks in a compact form factor.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6S3Um2MKMQJZavLvb5iEzH/7f8270446a2734c8c6a2d1150b2fc332/9-x0igmpkjXB7E9vru3gT.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/nvidias-cosmos-reason-2-aims-to-bring-reasoning-vlms-into-the-physical-world",
          "published_at": "Mon, 05 Jan 2026 20:00:00 GMT",
          "title": "Nvidia’s Cosmos Reason 2 aims to bring reasoning VLMs into the physical world",
          "standfirst": "Nvidia CEO Jensen Huang said last year that we are now entering the age of physical AI. While the company continues to offer LLMs for software use cases, Nvidia is increasingly positioning itself as a provider of AI models for fully AI-powered systems — including agentic AI in the physical world.At CES 2026, Nvidia announced a slate of new models designed to push AI agents beyond chat interfaces and into physical environments.Nvidia launched Cosmos Reason 2, the latest version of its vision-language model designed for embodied reasoning. Cosmos Reason 1, released last year, introduced a two-dimensional ontology for embodied reasoning and currently leads Hugging Face’s physical reasoning for video leaderboard.Cosmos Reason 2 builds on the same ontology while giving enterprises more flexibility to customize applications and enabling physical agents to plan their next actions, similar to how software-based agents reason through digital workflows.Nvidia also released a new version of Cosmos Transfer, a model that lets developers generate training simulations for robots.Other vision-language models, such as Google’s PaliGemma and Pixtral Large from Mistral, can process visual inputs, but not all commercially available VLMs support reasoning.“Robotics is at an inflection point. We are moving from specialist robots limited to single tasks to generalist specialist systems,” said Kari Briski, Nvidia vice president for generative AI software, in a briefing with reporters. She was referring to robots that combine broad foundational knowledge with deep task-specific skills. “These new robots combine broad fundamental knowledge with deep proficiency and complex tasks.”She added that Cosmos Reason 2 “enhances the reasoning capabilities that robots need to navigate the unpredictable physical world.”Moving to physical agentsBriski noted that Nvidia’s roadmap follows “the same pattern of assets across all of our open models.”“In building specialized AI agents, a digital workforce, or the physical embodiment of AI in robots and autonomous vehicles, more than just the model is needed,” Briski said. “First, the AI needs the compute resources to train, simulate the world around it. Data is the fuel for AI to learn and improve and we contribute to the world&#x27;s largest collection of open and diverse datasets, going beyond just opening the weights of the models. The open libraries and training scripts give developers the tools to purpose-build AI for their applications, and we publish blueprints and examples to help deploy AI as systems of models.”The company now has open models specifically for physical AI in Cosmos, robotics, with the open-reasoning vision-language-action (VLA) model Gr00t and its Nemotron models for agentic AI. Nvidia is making the case that open models across different branches of AI form a shared enterprise ecosystem that feeds data, training, and reasoning to agents in both the digital and physical worlds. Additions to the Nemotron familyBriski said Nvidia plans to continue expanding its open models, including its Nemotron family, beyond reasoning to include a new RAG and embeddings model to make information more readily available to agents. The company released Nemotron 3, the latest version of its agentic reasoning models, in December. Nvidia announced three new additions to the Nemotron family: Nemotron Speech, Nemotron RAG and Nemotron Safety. In a blog post, Nvidia said Nemotron Speech delivers “real-time low-latency speech recognition for live captions and speech AI applications” and is 10 times faster than other speech models. Nemotron RAG is technically comprised of two models: an embedding model and a rerank model, both of which can understand images to provide more multimodal insights that data agents will tap. “Nemotron RAG is on top of what we call the MMTab, or the Massive Multilingual Text Embedding Benchmark, with strong multilingual performance while using less computing power memory, so they are a good fit for systems that must handle a lot of requests very quickly and with low delay,” Briski said. Nemotron Safety detects sensitive data so AI agents do not accidentally unleash personally identifiable data.",
          "content": "Nvidia CEO Jensen Huang said last year that we are now entering the age of physical AI. While the company continues to offer LLMs for software use cases, Nvidia is increasingly positioning itself as a provider of AI models for fully AI-powered systems — including agentic AI in the physical world.At CES 2026, Nvidia announced a slate of new models designed to push AI agents beyond chat interfaces and into physical environments.Nvidia launched Cosmos Reason 2, the latest version of its vision-language model designed for embodied reasoning. Cosmos Reason 1, released last year, introduced a two-dimensional ontology for embodied reasoning and currently leads Hugging Face’s physical reasoning for video leaderboard.Cosmos Reason 2 builds on the same ontology while giving enterprises more flexibility to customize applications and enabling physical agents to plan their next actions, similar to how software-based agents reason through digital workflows.Nvidia also released a new version of Cosmos Transfer, a model that lets developers generate training simulations for robots.Other vision-language models, such as Google’s PaliGemma and Pixtral Large from Mistral, can process visual inputs, but not all commercially available VLMs support reasoning.“Robotics is at an inflection point. We are moving from specialist robots limited to single tasks to generalist specialist systems,” said Kari Briski, Nvidia vice president for generative AI software, in a briefing with reporters. She was referring to robots that combine broad foundational knowledge with deep task-specific skills. “These new robots combine broad fundamental knowledge with deep proficiency and complex tasks.”She added that Cosmos Reason 2 “enhances the reasoning capabilities that robots need to navigate the unpredictable physical world.”Moving to physical agentsBriski noted that Nvidia’s roadmap follows “the same pattern of assets across all of our open models.”“In building specialized AI agents, a digital workforce, or the physical embodiment of AI in robots and autonomous vehicles, more than just the model is needed,” Briski said. “First, the AI needs the compute resources to train, simulate the world around it. Data is the fuel for AI to learn and improve and we contribute to the world&#x27;s largest collection of open and diverse datasets, going beyond just opening the weights of the models. The open libraries and training scripts give developers the tools to purpose-build AI for their applications, and we publish blueprints and examples to help deploy AI as systems of models.”The company now has open models specifically for physical AI in Cosmos, robotics, with the open-reasoning vision-language-action (VLA) model Gr00t and its Nemotron models for agentic AI. Nvidia is making the case that open models across different branches of AI form a shared enterprise ecosystem that feeds data, training, and reasoning to agents in both the digital and physical worlds. Additions to the Nemotron familyBriski said Nvidia plans to continue expanding its open models, including its Nemotron family, beyond reasoning to include a new RAG and embeddings model to make information more readily available to agents. The company released Nemotron 3, the latest version of its agentic reasoning models, in December. Nvidia announced three new additions to the Nemotron family: Nemotron Speech, Nemotron RAG and Nemotron Safety. In a blog post, Nvidia said Nemotron Speech delivers “real-time low-latency speech recognition for live captions and speech AI applications” and is 10 times faster than other speech models. Nemotron RAG is technically comprised of two models: an embedding model and a rerank model, both of which can understand images to provide more multimodal insights that data agents will tap. “Nemotron RAG is on top of what we call the MMTab, or the Massive Multilingual Text Embedding Benchmark, with strong multilingual performance while using less computing power memory, so they are a good fit for systems that must handle a lot of requests very quickly and with low delay,” Briski said. Nemotron Safety detects sensitive data so AI agents do not accidentally unleash personally identifiable data.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2dOxvcQe247RRe0QqURNoc/4226294f75548d9fb351c7df254ff529/crimedy7_illustration_of_robots_learning_in_a_school_--ar_169_ff89c646-4604-4650-88d5-14713adf2cdc_3.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-press-conference-live-190051823.html",
          "published_at": "Mon, 05 Jan 2026 19:59:08 +0000",
          "title": "How to watch the Hyundai CES 2026 press conference live",
          "standfirst": "Hyundai CES has long felt like a full-on auto show, but the car-centric energy seems somewhat muted at CES 2026. Sure, the Afeela electric vehicle from the Sony-Honda joint venture is returning to the show floor, but with the Trump administration yanking most EV incentives from the market, the industry isn't offering a full-court press of new vehicles in Las Vegas this year. That includes Hyundai. While the company's Mobis subsidiary will present \"more than 30 mobility convergence technologies\" during CES week — including its Holographic Windshield Display — we're hearing the Korean auto giant will instead use its press conference to focus on its AI Robotics Strategy. That will apparently include showcasing its new Atlas robot, as well as the wheeled MobED robot line. We'll get into the details below, along with how to watch it today. How to watch Hyundai's presentation at CES 2026 Hyundai's presentation takes place today, January 5 at 4PM ET, and you can livestream it on either its HyundaiUSA YouTube channel or its global YouTube channel. (We've embedded the link below.) We'll also post relevant news from the Hyundai presser in our main CES 2026 liveblog. What to expect from Hyundai at CES 2026 Hyundai is putting a huge focus on its AI Robotics Strategy during its presentation today — the theme is \"Partnering Human Progress.\" That'll include its strategies for commercializing AI-enhanced robotics, keeping with the very AI-centric focus of this year's CES. We'll also get a first-ever look at the company's new Atlas robot. In the teaser image shown in the press release, Atlas looks rather dog-like, which makes sense when you remember that Boston Dynamics was purchased by the Korean multinational back in 2020. \"This next-generation Atlas represents a tangible step toward the commercialization of AI Robotics, highlighting the Group’s commitment to building safe and adaptable robotic co-workers,\" the company said in the same press release. But Atlas isn't the only robot the company has up its sleeve. There's also the MobED Droid, a wheeled 'bot that scored a CES 2026 Innovation Award as the show opened this week. While on stage, Hyundai says it will \"reveal its strategic AI Robotics learning, training and expansion plans,\" via its Group Value Network and Software-Defined Factory approach. That includes a manufacturing strategy and an advanced smart factory. We originally thought Hyundai would showcase its Holographic Windshield Display during its press conference, but a Hyundai representative notified us it won't be featured today. It will have a separate CES presence, though not a separate press conference. Update, January 5 2026, 2:58PM ET: This story has been updated to include information on the MobED robot line, and to note that the Holographic Windshield Display likely won't be featured at the press conference.This article originally appeared on Engadget at https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-press-conference-live-190051823.html?src=rss",
          "content": "Hyundai CES has long felt like a full-on auto show, but the car-centric energy seems somewhat muted at CES 2026. Sure, the Afeela electric vehicle from the Sony-Honda joint venture is returning to the show floor, but with the Trump administration yanking most EV incentives from the market, the industry isn't offering a full-court press of new vehicles in Las Vegas this year. That includes Hyundai. While the company's Mobis subsidiary will present \"more than 30 mobility convergence technologies\" during CES week — including its Holographic Windshield Display — we're hearing the Korean auto giant will instead use its press conference to focus on its AI Robotics Strategy. That will apparently include showcasing its new Atlas robot, as well as the wheeled MobED robot line. We'll get into the details below, along with how to watch it today. How to watch Hyundai's presentation at CES 2026 Hyundai's presentation takes place today, January 5 at 4PM ET, and you can livestream it on either its HyundaiUSA YouTube channel or its global YouTube channel. (We've embedded the link below.) We'll also post relevant news from the Hyundai presser in our main CES 2026 liveblog. What to expect from Hyundai at CES 2026 Hyundai is putting a huge focus on its AI Robotics Strategy during its presentation today — the theme is \"Partnering Human Progress.\" That'll include its strategies for commercializing AI-enhanced robotics, keeping with the very AI-centric focus of this year's CES. We'll also get a first-ever look at the company's new Atlas robot. In the teaser image shown in the press release, Atlas looks rather dog-like, which makes sense when you remember that Boston Dynamics was purchased by the Korean multinational back in 2020. \"This next-generation Atlas represents a tangible step toward the commercialization of AI Robotics, highlighting the Group’s commitment to building safe and adaptable robotic co-workers,\" the company said in the same press release. But Atlas isn't the only robot the company has up its sleeve. There's also the MobED Droid, a wheeled 'bot that scored a CES 2026 Innovation Award as the show opened this week. While on stage, Hyundai says it will \"reveal its strategic AI Robotics learning, training and expansion plans,\" via its Group Value Network and Software-Defined Factory approach. That includes a manufacturing strategy and an advanced smart factory. We originally thought Hyundai would showcase its Holographic Windshield Display during its press conference, but a Hyundai representative notified us it won't be featured today. It will have a separate CES presence, though not a separate press conference. Update, January 5 2026, 2:58PM ET: This story has been updated to include information on the MobED robot line, and to note that the Holographic Windshield Display likely won't be featured at the press conference.This article originally appeared on Engadget at https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-press-conference-live-190051823.html?src=rss",
          "feed_position": 12,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/938979f0-e9dd-11f0-b73f-c1acf71c1faf"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/everything-announced-at-ces-2026-130124802.html",
          "published_at": "Mon, 05 Jan 2026 19:40:29 +0000",
          "title": "Everything announced at CES 2026",
          "standfirst": "It's the first week of a new year and there's no time for the tech world to slowly ease back into things following the holidays. That's because CES 2026 is in full swing, with all manner of companies descending on Las Vegas to reveal their latest innovations and what they're planning to bring your way in the near future. Many of the Engadget crew are on the ground to check out as much of the new tech as possible. Of course, we're keeping tabs on all of the major CES press conferences too. Samsung has already held its First Look presentation, which focuses on home products, while LG has shown off a wide array of TVs and Lego unveiled its new Smart Brick technology. Presentations from NVIDIA, Sony, Lego, Hyundai and others are yet to come.You can catch up on all of the big CES 2026 announcements (and some of the more offbeat gizmos that are being shown off at the event) right here. We'll be keeping this story updated throughout the week. Micro RGB TVs Samsung's 130-inch Micro RGB TV. Devindra Hardawar for EngadgetMicro RGB is a term you can expect to hear about quite a bit in the coming months and years, especially when you're shopping for your next TV. Micro RGB is a new tech that's similar to Mini LED, though it uses red, green and blue LEDs instead of white backlights. Contrast ratios aren't quite as high as those on Micro LED and OLED displays, since the pixels can't be turned on and off individually. However, Micro RGB units are said to be brighter and more color accurate than TVs that use other display tech, in part because the LEDs in these screens offer smaller, more customizable dimming zones. We're seeing more of these TVs pop up at CES 2026, including a mammoth 130-inch concept model that Samsung brought to Las Vegas. The company unveiled its first Micro RGB TV in August, — that’s a 115-inch, $29,999 model. This year, you can expect it to start offering Micro RGB TVs in 55-, 65- and 75-inch sizes. There are also 85-, 100- and 115-inch models on the way.LG revealed its first Micro RGB set at CES as well. The largest variant is 100 inches, but there are 86- and 75-inch models too. Elsewhere, LG showed off its latest Wallpaper TV, which is a 100-inch OLED display. We also got a look at LG's new Gallery TV — The Gallery is the company's take on Samsung's Frame TV format.Other new TVs and OS updatesEmber Artline TV.AmazonWe’ve got another competitor to The Frame, as Amazon has entered that scene with the Ember Artline TV. The 4K OLED model has Amazon Photos integration and you can choose from 2,000 pieces of free art to show on the screen. The Ember Artline can switch on or off automatically when someone enters or leaves the room. It runs on the Fire TV platform and (of course) there’s Alexa+ integration, along with support for Dolby Vision, HDR10+ and Wi-Fi 6. The Ember Artline is expected to start shipping this spring. It starts at $899 for the 55-inch model.The rounder redesigned Fire TV UI.AmazonSpeaking of Fire TV, Amazon has revamped the platform’s user interface with rounded corners for show, movie and app tiles; a little more space for said tiles; and typography and color gradient changes. The company has reworked the platform’s codebase as well, and it says the Fire TV OS will deliver speed boosts of up to 20 to 30 percent. Amazon will start rolling out the updated UI next month.On the Google side of TV land, you can expect more Gemini-powered features. The company is bringing the ability to search Google Photos for certain moments and people to Google TV, along with the options to remix photos into different styles and create slideshows on the fly. The Veo and Nano Banana AI video and photo generation models are coming to Google TV as well. You can also expect the ability to adjust TV settings using your voice. These Gemini features are coming to Google TV-powered TCL models first, then other devices in the following months.SamsungSamsung's Music Studio 5 speakers at CES 2026.Billy Steele for EngadgetSamsung being Samsung, the company had a lot more up its sleeve at CES than just TVs. In the leadup to the event, it announced its two new soundbars (we're had some hands-on time with one of those), the stylish Music Studio speakers (we've got some IRL impressions of those), a bunch of monitors, the refreshed FreeStyle+ projector (we've checked that out too). It also announced plans to bring Google Photos to TVs.At the First Look showcase on Sunday, Samsung talked up \"AI experiences everywhere. For everyone\" (sigh). Here, we saw more TVs, such as the thin S95H OLED, which has a zero-gap mount that allows you to position the unit flush against a wall. First Look has long been focused on home products. Naturally, Samsung execs discussed some features for the company's fridges, such as ​​recipe selection updates, AI cooling tech and Google Gemini-powered AI Vision that's said to be able to recognize more items and help you figure out what you need to buy without having to manually take inventory. FoodNote, meanwhile, is a weekly summary that breaks down what has gone in and out of your fridge.Moreover, Samsung highlighted the Samsung Bespoke AI Laundry Combo and its new AI wash cycle. With the new Air Dresser — which has an Auto Wrinkle Care feature — Samsung aims to do away with irons (thank you, Samsung). As for the Bespoke AI smart vacuum and mop, that can apparently keep an eye on your pets when you're not home.LGLG's CLOiD robot.LGLikewise, LG brought other non-TV tech to CES. The company is shining the spotlight on its CLOiD robot. Like the far creepier-looking 1X Neo, the CLOiD is designed to help with household tasks such as starting laundry cycles, folding clothes, unloading the dishwasher and serving food. This appears to be more of a concept than something you'll be able to buy anytime soon, but we should get a closer look at the CLOiD in person this week.The company also debuted the LG Sound Suite, a modular home audio system it developed in conjunction with Dolby to take on the likes of Sonos. Just ahead of CES, LG pulled back the curtain on a new batch of xboom speakers as well as some monitors and ultralight Gram laptops that are made with a material it's calling Aerominum. LegoLego introduced the Smart Brick at CES 2026.LegoIn its first CES appearance, Lego announced the Smart Brick, a standard-sized brick with a 4.1mm ASIC chip inside that’s designed to respond in different ways depending on what set you’re building and how you’re building it. Using what Lego calls the “Play Engine” and integrated copper coils, each brick can sense things like motion, orientation and magnetic fields, plus its own distance, direction and orientation in relation to other Smart Bricks. Each brick also has a teeny tiny speaker built in that will play audio “tied to live play actions” rather than only pre-recorded clips.Accompanying Smart Bricks are Smart Tags and Smart Minifigures, which have their own capabilities — one of which is letting Smart Bricks know what context they are being used in. All of these pieces tie together via a local wireless layer dubbed BrickNet that, in part, lets Smart Bricks know where they are placed in relation to other smart components.The first “Smart Play” partner is, unsurprisingly, Star Wars, which will launch three “all-in-one” sets using Smart Bricks, Smart Tags and Smart Minifigures. The 473-piece Darth Vader TIE Fighter set will cost $70; the 584-piece Luke’s Red Five X-Wing set comes in at $100 and the 962-piece Throne Room Duel & A-wing set will set you back $160.L'OrealA pair of transparent eye masks with wires and bulbs inside them.L'Oréal L'Oreal often brings some interesting beauty tech to CES and the company did so again this year with a trio of gadgets. The LED Eye Mask uses red light and near-infrared light to address the likes of puffiness, discoloration and fine lines.The LED Face Mask seems to be a more pliable version of masks that we've seen from the likes of Dr. Dennis Gross, Omnilux, Therabody and Shark in recent years. However, it's only in prototype form for now and it isn't expected to hit the market until next year. The Light Straight + Multi-styler uses infrared light to help dry and style hair in similar fashion to L'Oreal's AirLight Pro. It's said to have sensors that employ \"built-in proprietary algorithms and machine learning\" so they can adapt to your gestures and \"maximize individual experience.\" L'Oreal claims that while traditional straighteners can operate at 400°F or higher (temperatures that can damage hair), its latest innovation \"effectively straightens hair while never exceeding 320°F.\" You can expect the Light Straight to arrive in 2027 as well.Laptops and desktopsLG Gram ProEngadgetIt's CES, so of course we're going to see a bunch of laptops and desktops. The majority of those will surely emerge after NVIDIA's press conference on Monday evening, though we've already had a peek at LG's Aerominum laptops.MobileBack at CES 2024, we got to try out a physical keyboard phone accessory from Clicks. Fast forward two years, and the brand is making its own Blackberry-esque phones, as well as a new physical phone keyboard accessory. The Android 16-based Clicks Communicator has a tactile keyboard with a fingerprint sensor in the spacebar, a 4-inch OLED display, a 3.5mm headphone jack (hooray!) and expandable microSD storage up to 2TB. You can reserve one now for $399 — the price will increase to $499 on February 27.As for the new accessory, Clicks is calling that the Power Keyboard. It connects to an iOS or Android phone via MagSafe or Qi2, and it can operate as a power bank in a pinch thanks to the 2,150 mAh battery. The Power Keyboard has Bluetooth functionality as well, so you can use it with devices like tablets, smart TVs and virtual reality headsets. Pre-orders are open now and the Power Keyboard is expected to ship in the spring. Early adopters can lock in a pre-order for $79 before the retail price jumps to $110.The Punkt MC03 phone.PunktThose who prefer their mobile phones to have fewer bells and whistles might be interested in the latest model from Punkt. The MC03 is a nifty-looking touchscreen model that runs on the privacy- and security-centric AphyOS, which is based on the Android Open Source Project. It has a UI that borrows a page out of the Light Phone's playbook, though you can still install any Android app. The MC03 will hit European markets this month for €699 / CHF699 / £610. There's a mandatory subscription, however. You get a year of access included with a phone purchase, then it's a €10 / CHF10 / £9 monthly fee (paying for a long-term plan up front can reduce the cost by up to 60 percent).AI Amazon introduced Alexa.com to Alexa+ Early Access customers.AmazonNo prizes for guessing that there's going to be a ton of AI-related news at CES this year. Amazon, for one, announced that it's rolling out a web-based version of Alexa+. That means you won't necessarily need to have an Amazon device to try out the generative AI-powered assistant. However, Alexa+ Early Access customers are getting first dibs on the web version.Two Sweekar devices are pictured on a table, one wearing a pink and blue snowboarder outfit and the other (behind it) wearing a cowboy hat and outfitKarissa Bell for EngadgetThere are a boatload of AI-powered devices on the CES show floor too. One that we saw early on is a Tamagotchi-style virtual pet from a startup called Takway. The Sweekar will remember your interactions with it (you'll need to feed and play with the pet to keep it healthy and happy). Once it's all grown up, the Sweekar will head off on virtual adventures and tell you about its exploits when it \"returns.\" Takway will soon start a Kickstarter campaign for the Sweekar, which will likely cost between $100 and $150.The Fraimic art display at CESAmy Skorheim for EngadgetWe also saw the Fraimic, an E Ink display that can tap into OpenAI to generate images. There's no subscription for the Fraimic (which costs $399 for the standard size, which has a 13-inch display) and you get 100 AI-generated images per year included with your purchase. Pre-orders are open now and the Fraimic is expected to start shipping in this spring.MindClip held in a hand.Daniel Cooper for EngadgetSome companies still trying to make wearable AI devices happen. SwitchBot has a wearable mic called the AI MindClip, which can seemingly record and transcribe everything you say (no, thank you!). Plaid, meanwhile, brought its NotePin follow up to the dance. This time around, the NotePin S has a button that you can push to record conversations. You can also press the button to flag key moments for an AI-generated summary to focus on. The NotePin S is available now for $179, should you be enticed to buy such a thing.This article originally appeared on Engadget at https://www.engadget.com/general/everything-announced-at-ces-2026-130124802.html?src=rss",
          "content": "It's the first week of a new year and there's no time for the tech world to slowly ease back into things following the holidays. That's because CES 2026 is in full swing, with all manner of companies descending on Las Vegas to reveal their latest innovations and what they're planning to bring your way in the near future. Many of the Engadget crew are on the ground to check out as much of the new tech as possible. Of course, we're keeping tabs on all of the major CES press conferences too. Samsung has already held its First Look presentation, which focuses on home products, while LG has shown off a wide array of TVs and Lego unveiled its new Smart Brick technology. Presentations from NVIDIA, Sony, Lego, Hyundai and others are yet to come.You can catch up on all of the big CES 2026 announcements (and some of the more offbeat gizmos that are being shown off at the event) right here. We'll be keeping this story updated throughout the week. Micro RGB TVs Samsung's 130-inch Micro RGB TV. Devindra Hardawar for EngadgetMicro RGB is a term you can expect to hear about quite a bit in the coming months and years, especially when you're shopping for your next TV. Micro RGB is a new tech that's similar to Mini LED, though it uses red, green and blue LEDs instead of white backlights. Contrast ratios aren't quite as high as those on Micro LED and OLED displays, since the pixels can't be turned on and off individually. However, Micro RGB units are said to be brighter and more color accurate than TVs that use other display tech, in part because the LEDs in these screens offer smaller, more customizable dimming zones. We're seeing more of these TVs pop up at CES 2026, including a mammoth 130-inch concept model that Samsung brought to Las Vegas. The company unveiled its first Micro RGB TV in August, — that’s a 115-inch, $29,999 model. This year, you can expect it to start offering Micro RGB TVs in 55-, 65- and 75-inch sizes. There are also 85-, 100- and 115-inch models on the way.LG revealed its first Micro RGB set at CES as well. The largest variant is 100 inches, but there are 86- and 75-inch models too. Elsewhere, LG showed off its latest Wallpaper TV, which is a 100-inch OLED display. We also got a look at LG's new Gallery TV — The Gallery is the company's take on Samsung's Frame TV format.Other new TVs and OS updatesEmber Artline TV.AmazonWe’ve got another competitor to The Frame, as Amazon has entered that scene with the Ember Artline TV. The 4K OLED model has Amazon Photos integration and you can choose from 2,000 pieces of free art to show on the screen. The Ember Artline can switch on or off automatically when someone enters or leaves the room. It runs on the Fire TV platform and (of course) there’s Alexa+ integration, along with support for Dolby Vision, HDR10+ and Wi-Fi 6. The Ember Artline is expected to start shipping this spring. It starts at $899 for the 55-inch model.The rounder redesigned Fire TV UI.AmazonSpeaking of Fire TV, Amazon has revamped the platform’s user interface with rounded corners for show, movie and app tiles; a little more space for said tiles; and typography and color gradient changes. The company has reworked the platform’s codebase as well, and it says the Fire TV OS will deliver speed boosts of up to 20 to 30 percent. Amazon will start rolling out the updated UI next month.On the Google side of TV land, you can expect more Gemini-powered features. The company is bringing the ability to search Google Photos for certain moments and people to Google TV, along with the options to remix photos into different styles and create slideshows on the fly. The Veo and Nano Banana AI video and photo generation models are coming to Google TV as well. You can also expect the ability to adjust TV settings using your voice. These Gemini features are coming to Google TV-powered TCL models first, then other devices in the following months.SamsungSamsung's Music Studio 5 speakers at CES 2026.Billy Steele for EngadgetSamsung being Samsung, the company had a lot more up its sleeve at CES than just TVs. In the leadup to the event, it announced its two new soundbars (we're had some hands-on time with one of those), the stylish Music Studio speakers (we've got some IRL impressions of those), a bunch of monitors, the refreshed FreeStyle+ projector (we've checked that out too). It also announced plans to bring Google Photos to TVs.At the First Look showcase on Sunday, Samsung talked up \"AI experiences everywhere. For everyone\" (sigh). Here, we saw more TVs, such as the thin S95H OLED, which has a zero-gap mount that allows you to position the unit flush against a wall. First Look has long been focused on home products. Naturally, Samsung execs discussed some features for the company's fridges, such as ​​recipe selection updates, AI cooling tech and Google Gemini-powered AI Vision that's said to be able to recognize more items and help you figure out what you need to buy without having to manually take inventory. FoodNote, meanwhile, is a weekly summary that breaks down what has gone in and out of your fridge.Moreover, Samsung highlighted the Samsung Bespoke AI Laundry Combo and its new AI wash cycle. With the new Air Dresser — which has an Auto Wrinkle Care feature — Samsung aims to do away with irons (thank you, Samsung). As for the Bespoke AI smart vacuum and mop, that can apparently keep an eye on your pets when you're not home.LGLG's CLOiD robot.LGLikewise, LG brought other non-TV tech to CES. The company is shining the spotlight on its CLOiD robot. Like the far creepier-looking 1X Neo, the CLOiD is designed to help with household tasks such as starting laundry cycles, folding clothes, unloading the dishwasher and serving food. This appears to be more of a concept than something you'll be able to buy anytime soon, but we should get a closer look at the CLOiD in person this week.The company also debuted the LG Sound Suite, a modular home audio system it developed in conjunction with Dolby to take on the likes of Sonos. Just ahead of CES, LG pulled back the curtain on a new batch of xboom speakers as well as some monitors and ultralight Gram laptops that are made with a material it's calling Aerominum. LegoLego introduced the Smart Brick at CES 2026.LegoIn its first CES appearance, Lego announced the Smart Brick, a standard-sized brick with a 4.1mm ASIC chip inside that’s designed to respond in different ways depending on what set you’re building and how you’re building it. Using what Lego calls the “Play Engine” and integrated copper coils, each brick can sense things like motion, orientation and magnetic fields, plus its own distance, direction and orientation in relation to other Smart Bricks. Each brick also has a teeny tiny speaker built in that will play audio “tied to live play actions” rather than only pre-recorded clips.Accompanying Smart Bricks are Smart Tags and Smart Minifigures, which have their own capabilities — one of which is letting Smart Bricks know what context they are being used in. All of these pieces tie together via a local wireless layer dubbed BrickNet that, in part, lets Smart Bricks know where they are placed in relation to other smart components.The first “Smart Play” partner is, unsurprisingly, Star Wars, which will launch three “all-in-one” sets using Smart Bricks, Smart Tags and Smart Minifigures. The 473-piece Darth Vader TIE Fighter set will cost $70; the 584-piece Luke’s Red Five X-Wing set comes in at $100 and the 962-piece Throne Room Duel & A-wing set will set you back $160.L'OrealA pair of transparent eye masks with wires and bulbs inside them.L'Oréal L'Oreal often brings some interesting beauty tech to CES and the company did so again this year with a trio of gadgets. The LED Eye Mask uses red light and near-infrared light to address the likes of puffiness, discoloration and fine lines.The LED Face Mask seems to be a more pliable version of masks that we've seen from the likes of Dr. Dennis Gross, Omnilux, Therabody and Shark in recent years. However, it's only in prototype form for now and it isn't expected to hit the market until next year. The Light Straight + Multi-styler uses infrared light to help dry and style hair in similar fashion to L'Oreal's AirLight Pro. It's said to have sensors that employ \"built-in proprietary algorithms and machine learning\" so they can adapt to your gestures and \"maximize individual experience.\" L'Oreal claims that while traditional straighteners can operate at 400°F or higher (temperatures that can damage hair), its latest innovation \"effectively straightens hair while never exceeding 320°F.\" You can expect the Light Straight to arrive in 2027 as well.Laptops and desktopsLG Gram ProEngadgetIt's CES, so of course we're going to see a bunch of laptops and desktops. The majority of those will surely emerge after NVIDIA's press conference on Monday evening, though we've already had a peek at LG's Aerominum laptops.MobileBack at CES 2024, we got to try out a physical keyboard phone accessory from Clicks. Fast forward two years, and the brand is making its own Blackberry-esque phones, as well as a new physical phone keyboard accessory. The Android 16-based Clicks Communicator has a tactile keyboard with a fingerprint sensor in the spacebar, a 4-inch OLED display, a 3.5mm headphone jack (hooray!) and expandable microSD storage up to 2TB. You can reserve one now for $399 — the price will increase to $499 on February 27.As for the new accessory, Clicks is calling that the Power Keyboard. It connects to an iOS or Android phone via MagSafe or Qi2, and it can operate as a power bank in a pinch thanks to the 2,150 mAh battery. The Power Keyboard has Bluetooth functionality as well, so you can use it with devices like tablets, smart TVs and virtual reality headsets. Pre-orders are open now and the Power Keyboard is expected to ship in the spring. Early adopters can lock in a pre-order for $79 before the retail price jumps to $110.The Punkt MC03 phone.PunktThose who prefer their mobile phones to have fewer bells and whistles might be interested in the latest model from Punkt. The MC03 is a nifty-looking touchscreen model that runs on the privacy- and security-centric AphyOS, which is based on the Android Open Source Project. It has a UI that borrows a page out of the Light Phone's playbook, though you can still install any Android app. The MC03 will hit European markets this month for €699 / CHF699 / £610. There's a mandatory subscription, however. You get a year of access included with a phone purchase, then it's a €10 / CHF10 / £9 monthly fee (paying for a long-term plan up front can reduce the cost by up to 60 percent).AI Amazon introduced Alexa.com to Alexa+ Early Access customers.AmazonNo prizes for guessing that there's going to be a ton of AI-related news at CES this year. Amazon, for one, announced that it's rolling out a web-based version of Alexa+. That means you won't necessarily need to have an Amazon device to try out the generative AI-powered assistant. However, Alexa+ Early Access customers are getting first dibs on the web version.Two Sweekar devices are pictured on a table, one wearing a pink and blue snowboarder outfit and the other (behind it) wearing a cowboy hat and outfitKarissa Bell for EngadgetThere are a boatload of AI-powered devices on the CES show floor too. One that we saw early on is a Tamagotchi-style virtual pet from a startup called Takway. The Sweekar will remember your interactions with it (you'll need to feed and play with the pet to keep it healthy and happy). Once it's all grown up, the Sweekar will head off on virtual adventures and tell you about its exploits when it \"returns.\" Takway will soon start a Kickstarter campaign for the Sweekar, which will likely cost between $100 and $150.The Fraimic art display at CESAmy Skorheim for EngadgetWe also saw the Fraimic, an E Ink display that can tap into OpenAI to generate images. There's no subscription for the Fraimic (which costs $399 for the standard size, which has a 13-inch display) and you get 100 AI-generated images per year included with your purchase. Pre-orders are open now and the Fraimic is expected to start shipping in this spring.MindClip held in a hand.Daniel Cooper for EngadgetSome companies still trying to make wearable AI devices happen. SwitchBot has a wearable mic called the AI MindClip, which can seemingly record and transcribe everything you say (no, thank you!). Plaid, meanwhile, brought its NotePin follow up to the dance. This time around, the NotePin S has a button that you can push to record conversations. You can also press the button to flag key moments for an AI-generated summary to focus on. The NotePin S is available now for $179, should you be enticed to buy such a thing.This article originally appeared on Engadget at https://www.engadget.com/general/everything-announced-at-ces-2026-130124802.html?src=rss",
          "feed_position": 15,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Samsung_Micro_RGB-1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/lg-sound-suite-hands-on-at-ces-2026-home-theater-powered-by-dolby-atmos-flexconnect-192709499.html",
          "published_at": "Mon, 05 Jan 2026 19:27:09 +0000",
          "title": "LG Sound Suite hands-on at CES 2026: Home theater powered by Dolby Atmos FlexConnect",
          "standfirst": "Dolby introduced its FlexConnect technology a few years ago, vowing that it would allow customers to position soundbars and speakers anywhere in a room. The company said the platform would then reconfigure the sound automatically, taking into account any locations that may be further away from the center sweet spot. At CES 2026, LG is the first to put Dolby Atmos FlexConnect in a soundbar, offering the so-called Sound Suite that also includes satellite speaker options and a subwoofer. You don’t need every member of the lineup to use Dolby’s tech, so you can pick and choose which items work best for your living room. The centerpiece of the Sound Suite is the H7 soundbar. This 9.1.6-channel speaker is configured for spatial audio (Dolby Atmos) and supports lossless audio up to 24 bit/96kHz. The standout on the spec sheet for me is the six up-firing channels, which should enhance the sensation of overhead sounds. Most of the soundbars I review have only two of those. What’s more, the H7 is equipped with a feature called Sound Follow that tracks the location of your phone to reconfigure the audio when your position changes. Maybe you move to a comfy chair instead of the sofa right in front of the TV. The idea is that you don’t have to suffer through subpar audio during a movie or show just because you aren’t in the best spot. LG Sound Suite H7 soundbarBilly Steele for EngadgetThen there are the M5 and M7 speakers. When used with the H7 soundbar, these are the satellite speakers, but LG cautioned me against calling them “rear” units. While it’s true a pair of them will be positioned behind most people’s sofas, the company explained that there’s more audio content coming out of them than traditional rear channels provide. As such, two of the M5s or M7s that are used to complement the speakers inside one of LG’s impressively thin TVs are doing more work than just beaming sounds that are designed to come from behind. The M5 is a 1.1.1-channel speaker while the M7 is 2.1.1. Like the H7, both support Dolby Atmos and lossless music. What’s more, the entire Sound Suite arsenal has Wi-Fi and Bluetooth connectivity, including AirPlay 2, Google Cast and both Spotify and Tidal connect. The whole shebang also employs LG’s own AI Sound Pro and Room Calibration Pro, and all of the settings are customized in the ThinQ app for Android and iOS. Each speaker can be used independently should the need arise, and as I already mentioned, you can pick and choose which components will work best for you — up to four total speakers. So you can opt for the H7, sub and two speakers or four of either the M5 or M7. You can also get a smaller setup with two speakers or just the soundbar and subwoofer. Dolby Atmos FlexConnect is still in play no matter what combination you decide on. I should note the optional W7 subwoofer is quite large, but you can use it standing upright or laying flat, according to LG.LG Sound Suite M5 speakerBilly Steele for EngadgetOf course, none of this means anything if Sound Suite doesn’t actually sound good. I’m happy to report LG’s collection of speakers are sonically impressive. I was able to get a good sense of how they’ll perform in a quite demo room at CES. Watching a variety of movie clips in Dolby Atmos, I flipped back and forth between a setup with four M7 speakers and a more robust configuration of the soundbar, subwoofer and M7 speakers. While I preferred the overall tone and tuning of the four M7s, I can concede the bigger collection offered more immersive sound and better directional audio. That said, they both provided excellent clarity and pristine detail. With Sound Follow, you can quickly have Sound Suite reconfigure the audio based on the location of your phone with just a tap. Let’s say you move from the couch to a comfy chair and want to adjust the sound to that spot. You can do that in the app. And while I could tell a slight difference in a side-of-the-room location and the center sweet spot in front of the TV, the correction did offer an improvement over the unadjusted audio.I was also able to test standalone mode, where you can quickly use any Sound Suite speaker individually for music. Sound quality was consistent here too, and the system allowed me to add a second M7 speaker for a stereo pair with a few taps in LG’s app. Overall, the Sound Suite lineup offers lots of flexibility in terms of features and configurations. In fact, LG says that between the H7, W7, M5 and M7, there are 50 possible combinations. Unfortunately, LG hasn’t announced pricing or availability yet. Given the capabilities of the Sound Suite system, I don’t expect the more robust collections to come cheap. However, I do think the company will offer a few different bundles that will hopefully provide a discount over buying each component individually. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-sound-suite-hands-on-at-ces-2026-home-theater-powered-by-dolby-atmos-flexconnect-192709499.html?src=rss",
          "content": "Dolby introduced its FlexConnect technology a few years ago, vowing that it would allow customers to position soundbars and speakers anywhere in a room. The company said the platform would then reconfigure the sound automatically, taking into account any locations that may be further away from the center sweet spot. At CES 2026, LG is the first to put Dolby Atmos FlexConnect in a soundbar, offering the so-called Sound Suite that also includes satellite speaker options and a subwoofer. You don’t need every member of the lineup to use Dolby’s tech, so you can pick and choose which items work best for your living room. The centerpiece of the Sound Suite is the H7 soundbar. This 9.1.6-channel speaker is configured for spatial audio (Dolby Atmos) and supports lossless audio up to 24 bit/96kHz. The standout on the spec sheet for me is the six up-firing channels, which should enhance the sensation of overhead sounds. Most of the soundbars I review have only two of those. What’s more, the H7 is equipped with a feature called Sound Follow that tracks the location of your phone to reconfigure the audio when your position changes. Maybe you move to a comfy chair instead of the sofa right in front of the TV. The idea is that you don’t have to suffer through subpar audio during a movie or show just because you aren’t in the best spot. LG Sound Suite H7 soundbarBilly Steele for EngadgetThen there are the M5 and M7 speakers. When used with the H7 soundbar, these are the satellite speakers, but LG cautioned me against calling them “rear” units. While it’s true a pair of them will be positioned behind most people’s sofas, the company explained that there’s more audio content coming out of them than traditional rear channels provide. As such, two of the M5s or M7s that are used to complement the speakers inside one of LG’s impressively thin TVs are doing more work than just beaming sounds that are designed to come from behind. The M5 is a 1.1.1-channel speaker while the M7 is 2.1.1. Like the H7, both support Dolby Atmos and lossless music. What’s more, the entire Sound Suite arsenal has Wi-Fi and Bluetooth connectivity, including AirPlay 2, Google Cast and both Spotify and Tidal connect. The whole shebang also employs LG’s own AI Sound Pro and Room Calibration Pro, and all of the settings are customized in the ThinQ app for Android and iOS. Each speaker can be used independently should the need arise, and as I already mentioned, you can pick and choose which components will work best for you — up to four total speakers. So you can opt for the H7, sub and two speakers or four of either the M5 or M7. You can also get a smaller setup with two speakers or just the soundbar and subwoofer. Dolby Atmos FlexConnect is still in play no matter what combination you decide on. I should note the optional W7 subwoofer is quite large, but you can use it standing upright or laying flat, according to LG.LG Sound Suite M5 speakerBilly Steele for EngadgetOf course, none of this means anything if Sound Suite doesn’t actually sound good. I’m happy to report LG’s collection of speakers are sonically impressive. I was able to get a good sense of how they’ll perform in a quite demo room at CES. Watching a variety of movie clips in Dolby Atmos, I flipped back and forth between a setup with four M7 speakers and a more robust configuration of the soundbar, subwoofer and M7 speakers. While I preferred the overall tone and tuning of the four M7s, I can concede the bigger collection offered more immersive sound and better directional audio. That said, they both provided excellent clarity and pristine detail. With Sound Follow, you can quickly have Sound Suite reconfigure the audio based on the location of your phone with just a tap. Let’s say you move from the couch to a comfy chair and want to adjust the sound to that spot. You can do that in the app. And while I could tell a slight difference in a side-of-the-room location and the center sweet spot in front of the TV, the correction did offer an improvement over the unadjusted audio.I was also able to test standalone mode, where you can quickly use any Sound Suite speaker individually for music. Sound quality was consistent here too, and the system allowed me to add a second M7 speaker for a stereo pair with a few taps in LG’s app. Overall, the Sound Suite lineup offers lots of flexibility in terms of features and configurations. In fact, LG says that between the H7, W7, M5 and M7, there are 50 possible combinations. Unfortunately, LG hasn’t announced pricing or availability yet. Given the capabilities of the Sound Suite system, I don’t expect the more robust collections to come cheap. However, I do think the company will offer a few different bundles that will hopefully provide a discount over buying each component individually. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-sound-suite-hands-on-at-ces-2026-home-theater-powered-by-dolby-atmos-flexconnect-192709499.html?src=rss",
          "feed_position": 16,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/lg-2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/the-biggest-tv-announcements-at-ces-2026-190929976.html",
          "published_at": "Mon, 05 Jan 2026 19:09:29 +0000",
          "title": "The biggest TV announcements at CES 2026",
          "standfirst": "CES is once again where TV manufacturers lay out their plans for the year ahead, and CES 2026 is shaping up to be a showcase of both familiar rivalries and genuinely new display tech. While OLED and Mini LED remain central to most lineups, Micro RGB has emerged as one of the most talked-about developments at the show so far, especially at the higher end of the market. Below are the TV announcements that stood out most from the pre-show events and early press conferences, with more expected as CES continues. Samsung Micro RGB TVs Samsung's flagship Micro RGB TV Engadget Samsung’s Micro RGB push at CES 2026 isn’t just about big screens — it’s also about how the technology tries to redefine color accuracy and brightness in LCD-based TVs. Unlike traditional Mini LED backlights that rely on white LEDs and filters, Samsung’s Micro RGB TVs use microscopic red, green and blue LEDs in the backlight plane, which help deliver a wider color gamut and more precise local luminance control than conventional backlit LCDs. The standout of the lineup so far is the jaw-dropping 130-inch Micro RGB concept, shown suspended on a massive gallery-style stand at Samsung’s First Look event. It’s powered by Samsung’s Micro RGB AI Engine Pro, a processing suite that includes Micro RGB Color Booster Pro and Micro RGB HDR Pro to refine contrast and push color depth and detail frame by frame, with HDR10+ Advanced support built in. Compared with previous Micro RGB models, Samsung says this expanded family will start at more practical sizes — 55- and 65-inch — and go up to sizes as large as 75, 85 and 100 inches, all with next-gen AI-driven picture and sound features baked in. Samsung’s Micro RGB sets also carry the company’s Glare Free anti-reflection finish and tie into its broader Vision AI platform, which supports things like conversational search and contextual content discovery. While the 130-inch concept may remain more of a statement piece than a consumer product, the move underscores how Samsung continues to push next-gen TV tech forward. Samsung OLED TVs Samsung’s new 2026 OLED slate — including the S95H, S90H and S85H models — continues the brand’s use of quantum dot-enhanced OLED panels, bringing brighter highlights and richer colors than older WOLED approaches. These TVs also benefit from Samsung’s continued refinement of processing and anti-glare screen treatments, which make them more adaptable in bright living rooms than traditional OLEDs. The flagship S95H retains its position as the most premium, using a quantum dot layer to help improve brightness and color purity. Below that, the S90H brings glare-reducing optical layers and robust picture processing to a slightly more affordable price point, while the S85H is designed to offer core OLED benefits, like deep blacks and wide viewing angles, in a more accessible package that now includes a new 48-inch size for smaller spaces or gaming setups. Across the OLED family, Samsung’s Vision AI-powered tools such as AI Motion Enhancer Pro and AI Sound Controller (which dynamically adjusts audio based on content) are also part of the story, making these sets not just about panel tech but about richer, more adaptable viewing experiences. LG OLED evo W6 Wallpaper TV LG's 2026 Wallpaper wireless OLED TV Devindra Hardawar for Engadget LG’s OLED evo W6 Wallpaper TV makes a striking return at CES 2026, and this year’s version manages to blend design flair with high-end performance. The panel itself is an astonishing 9mm thick, designed to sit almost flush against a wall, and pairs with a Zero Connect Box that hosts all inputs and delivers wireless video feeds up to 10 meters away. Under the ultra-thin exterior, the W6 uses LG’s Hyper Radiant Color technology coupled with Brightness Booster Ultra to push improved brightness and color saturation compared with previous Wallpaper models. It also received Intertek’s “Reflection Free with Premium” certification, indicating some of the lowest reflectance levels yet on an OLED TV. Gaming shooters and fast action fans might appreciate support for up to 165Hz refresh rates and both G-SYNC and FreeSync Premium compatibility, making this one of the most technically ambitious Wallpaper designs LG has shown. LG Micro RGB evo TVs LG is also entering the premium RGB-backlit arena at CES with its Micro RGB evo lineup, bringing a similar focus on wider color gamut and intense brightness. Early coverage indicates the Micro RGB evo models will arrive in 75-, 86- and 100-inch sizes, and are built around LG’s α11 AI Processor Gen3, which handles advanced upscaling, local dimming and dynamic HDR optimization. LG’s Micro RGB evo TVs have been certified for full coverage of BT.2020, DCI-P3 and Adobe RGB color spaces, suggesting an exceptionally wide palette and precise color fidelity. Under the hood, the Micro Dimming Ultra system is said to deliver 1,000+ local dimming zones, which narrows the gap between LCD-based displays and self-emissive technologies like OLED in terms of contrast management. This early positioning of RGB LED tech by LG also highlights a growing industry shift, with multiple brands teasing similar systems designed to improve brightness and color performance on large screen sizes — especially where OLED’s peak luminance traditionally struggles. LG OLED TVs (C6 and C6H) OLED remains a core focus for LG, and CES 2026 brought updates to its popular C-series. The LG C6 OLED continues the company’s tradition of balancing performance and price, while the C6H OLED steps things up with a new Primary RGB Tandem panel designed to deliver higher brightness and improved color volume. These models are clearly aimed at buyers who want OLED’s deep blacks and wide viewing angles without jumping to LG’s most expensive designs, making them likely to be among the most popular TVs LG releases this year. TCL X11L SQD-Mini LED TV TCL used CES 2026 to make a strong case for Mini LED’s continued relevance with the X11L SQD-Mini LED TV, its new flagship model aimed squarely at large-screen home theater setups. Rather than chasing Micro RGB, TCL is refining its own approach with SQD, or Super Quantum Dot, technology, which combines an enhanced quantum dot layer with a dense Mini LED backlight to improve color purity and brightness. The headline number here is brightness. TCL claims the X11L can hit up to 10,000 nits peak brightness, putting it among the brightest TVs shown at CES this year. That’s paired with an extremely dense local dimming system, with up to 20,000 dimming zones, which is designed to improve contrast and keep blooming in check despite the extreme luminance. TCL also says the panel covers 100 percent of the BT.2020 color space, a bold claim that, if it holds up in real-world testing, would put it in rare company. The X11L is a 4K TV available in 75-inch, 85-inch and 98-inch sizes, with the largest models clearly intended to rival premium OLED and Micro RGB sets in dedicated home theaters. It supports a 144Hz refresh rate, making it appealing for gaming as well as fast-moving sports, and includes support for advanced HDR formats, including Dolby Vision, with further enhancements expected via software updates. With CES press day underway and the show floor opening on January 6, more TV announcements are expected from major manufacturers. As additional models are revealed or details are confirmed, we’ll continue updating this roundup with the latest information. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/the-biggest-tv-announcements-at-ces-2026-190929976.html?src=rss",
          "content": "CES is once again where TV manufacturers lay out their plans for the year ahead, and CES 2026 is shaping up to be a showcase of both familiar rivalries and genuinely new display tech. While OLED and Mini LED remain central to most lineups, Micro RGB has emerged as one of the most talked-about developments at the show so far, especially at the higher end of the market. Below are the TV announcements that stood out most from the pre-show events and early press conferences, with more expected as CES continues. Samsung Micro RGB TVs Samsung's flagship Micro RGB TV Engadget Samsung’s Micro RGB push at CES 2026 isn’t just about big screens — it’s also about how the technology tries to redefine color accuracy and brightness in LCD-based TVs. Unlike traditional Mini LED backlights that rely on white LEDs and filters, Samsung’s Micro RGB TVs use microscopic red, green and blue LEDs in the backlight plane, which help deliver a wider color gamut and more precise local luminance control than conventional backlit LCDs. The standout of the lineup so far is the jaw-dropping 130-inch Micro RGB concept, shown suspended on a massive gallery-style stand at Samsung’s First Look event. It’s powered by Samsung’s Micro RGB AI Engine Pro, a processing suite that includes Micro RGB Color Booster Pro and Micro RGB HDR Pro to refine contrast and push color depth and detail frame by frame, with HDR10+ Advanced support built in. Compared with previous Micro RGB models, Samsung says this expanded family will start at more practical sizes — 55- and 65-inch — and go up to sizes as large as 75, 85 and 100 inches, all with next-gen AI-driven picture and sound features baked in. Samsung’s Micro RGB sets also carry the company’s Glare Free anti-reflection finish and tie into its broader Vision AI platform, which supports things like conversational search and contextual content discovery. While the 130-inch concept may remain more of a statement piece than a consumer product, the move underscores how Samsung continues to push next-gen TV tech forward. Samsung OLED TVs Samsung’s new 2026 OLED slate — including the S95H, S90H and S85H models — continues the brand’s use of quantum dot-enhanced OLED panels, bringing brighter highlights and richer colors than older WOLED approaches. These TVs also benefit from Samsung’s continued refinement of processing and anti-glare screen treatments, which make them more adaptable in bright living rooms than traditional OLEDs. The flagship S95H retains its position as the most premium, using a quantum dot layer to help improve brightness and color purity. Below that, the S90H brings glare-reducing optical layers and robust picture processing to a slightly more affordable price point, while the S85H is designed to offer core OLED benefits, like deep blacks and wide viewing angles, in a more accessible package that now includes a new 48-inch size for smaller spaces or gaming setups. Across the OLED family, Samsung’s Vision AI-powered tools such as AI Motion Enhancer Pro and AI Sound Controller (which dynamically adjusts audio based on content) are also part of the story, making these sets not just about panel tech but about richer, more adaptable viewing experiences. LG OLED evo W6 Wallpaper TV LG's 2026 Wallpaper wireless OLED TV Devindra Hardawar for Engadget LG’s OLED evo W6 Wallpaper TV makes a striking return at CES 2026, and this year’s version manages to blend design flair with high-end performance. The panel itself is an astonishing 9mm thick, designed to sit almost flush against a wall, and pairs with a Zero Connect Box that hosts all inputs and delivers wireless video feeds up to 10 meters away. Under the ultra-thin exterior, the W6 uses LG’s Hyper Radiant Color technology coupled with Brightness Booster Ultra to push improved brightness and color saturation compared with previous Wallpaper models. It also received Intertek’s “Reflection Free with Premium” certification, indicating some of the lowest reflectance levels yet on an OLED TV. Gaming shooters and fast action fans might appreciate support for up to 165Hz refresh rates and both G-SYNC and FreeSync Premium compatibility, making this one of the most technically ambitious Wallpaper designs LG has shown. LG Micro RGB evo TVs LG is also entering the premium RGB-backlit arena at CES with its Micro RGB evo lineup, bringing a similar focus on wider color gamut and intense brightness. Early coverage indicates the Micro RGB evo models will arrive in 75-, 86- and 100-inch sizes, and are built around LG’s α11 AI Processor Gen3, which handles advanced upscaling, local dimming and dynamic HDR optimization. LG’s Micro RGB evo TVs have been certified for full coverage of BT.2020, DCI-P3 and Adobe RGB color spaces, suggesting an exceptionally wide palette and precise color fidelity. Under the hood, the Micro Dimming Ultra system is said to deliver 1,000+ local dimming zones, which narrows the gap between LCD-based displays and self-emissive technologies like OLED in terms of contrast management. This early positioning of RGB LED tech by LG also highlights a growing industry shift, with multiple brands teasing similar systems designed to improve brightness and color performance on large screen sizes — especially where OLED’s peak luminance traditionally struggles. LG OLED TVs (C6 and C6H) OLED remains a core focus for LG, and CES 2026 brought updates to its popular C-series. The LG C6 OLED continues the company’s tradition of balancing performance and price, while the C6H OLED steps things up with a new Primary RGB Tandem panel designed to deliver higher brightness and improved color volume. These models are clearly aimed at buyers who want OLED’s deep blacks and wide viewing angles without jumping to LG’s most expensive designs, making them likely to be among the most popular TVs LG releases this year. TCL X11L SQD-Mini LED TV TCL used CES 2026 to make a strong case for Mini LED’s continued relevance with the X11L SQD-Mini LED TV, its new flagship model aimed squarely at large-screen home theater setups. Rather than chasing Micro RGB, TCL is refining its own approach with SQD, or Super Quantum Dot, technology, which combines an enhanced quantum dot layer with a dense Mini LED backlight to improve color purity and brightness. The headline number here is brightness. TCL claims the X11L can hit up to 10,000 nits peak brightness, putting it among the brightest TVs shown at CES this year. That’s paired with an extremely dense local dimming system, with up to 20,000 dimming zones, which is designed to improve contrast and keep blooming in check despite the extreme luminance. TCL also says the panel covers 100 percent of the BT.2020 color space, a bold claim that, if it holds up in real-world testing, would put it in rare company. The X11L is a 4K TV available in 75-inch, 85-inch and 98-inch sizes, with the largest models clearly intended to rival premium OLED and Micro RGB sets in dedicated home theaters. It supports a 144Hz refresh rate, making it appealing for gaming as well as fast-moving sports, and includes support for advanced HDR formats, including Dolby Vision, with further enhancements expected via software updates. With CES press day underway and the show floor opening on January 6, more TV announcements are expected from major manufacturers. As additional models are revealed or details are confirmed, we’ll continue updating this roundup with the latest information. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/the-biggest-tv-announcements-at-ces-2026-190929976.html?src=rss",
          "feed_position": 17,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/a087c5f0-e9f4-11f0-87f1-6f39e4849c7d.jpeg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/lego-unveils-a-technology-packed-smart-brick-at-ces-2026-190000511.html",
          "published_at": "Mon, 05 Jan 2026 19:00:00 +0000",
          "title": "Lego unveils a technology-packed Smart Brick at CES 2026",
          "standfirst": "Lego bricks come in a ridiculously vast array of sizes and shapes, but the company is unveiling an entirely new take on its classic shape at CES 2026. Meet the Lego Smart Brick, a standard-sized 2 x 4 brick that’s packed with modern technology to enable sets that can respond to how they’re played with or the sets you build. It’s part of a new initiative called Smart Play, which encompasses the Smart Brick as well as Smart Minifigures and Smart Tags. While we obviously don’t know yet how Lego fans will take to this new system, it’s still fair to say it’s the biggest move Lego has every made to infuse its products with connected technology. The Smart Brick has a 4.1mm ASIC chip inside of it that Lego says is smaller than a standard Lego stud. It runs something called the Play Engine that can sense things like motion, orientation and magnetic fields. Thanks to this and some integrated copper coils, the Smart Brick can sense distance, direction and orientation of other Smart Bricks near it when you’re building. The brick also has a tiny built-in speaker, an accelerometer and an LED array. Lego says the speaker can produce audio that is “tied to live play actions” rather than just playing pre-recorded clips. The Smart Tag and Smart Minifigures are a lot simpler. The Tag is a 2 x 2 studless tile with a digital ID embedded in it that the Smart Brick can read via “near-field magnetic communication.” This obviously sounds a lot like NFC, but we can’t be sure that these new Lego pieces will be able to communicate with any other NFC devices. Similarly, the Smart Minifigure also has a digital ID readable by NFC. The purpose of the Smart Tag as well as the similar tech in a Smart Minifigure is to let the Smart Brick know what kind of context it is being used in. As Lego puts it, “The role of the Smart Tag is to tell the Smart Brick how it should play back with you.” The Tag tells the Brick what kind of object, animal, vehicle and so forth it should become. A Smart Tag in a Lego Star Wars X-Wing set, for example, will contain the unique ID and instructions for how the Smart Brick should behave. If this isn’t enough, Lego has also built a local wireless layer that connects this all together called BrickNet. It’s based on Bluetooth and uses Lego’s proprietary “Neighbor Position Measurement\" system, which is what lets the Smart Bricks know how close they are to each other and how they’re oriented. Lego says that this lets the bricks “talk” to each other directly without the need for apps, internet connections or external controls. It sounds like the idea is all three of these new Smart pieces can communicate and interact without any need for setup, which should make it refreshingly like a traditional Lego set. That said, these bricks naturally will need some power. Lego says that their batteries should still perform even after “years” of inactivity, and the coils and power system is designed so that multiple bricks can be charged wirelessly on a shared charging pad. Lego Star Wars set with Smart Bricks Lego Speaking of sets, Lego is unsurprisingly launching the Smart Play system with its biggest licensed partner: Star Wars. There will be three “all-in-one” Star Wars sets available, all of which are on the smaller side and definitely geared towards kids, rather than the 1,000 piece and up sets that the company has released to get adults (like me) interested. The prices are inflated compared to non-smart sets, but not outrageously so. Darth Vader’s TIE Fighter is a 473-piece set with a smart Darth Vader Minifigure, one Smart Brick and one Smart Tag, priced at $70. Luke’s Red Five X-Wing is a 584-piece set with two Smart Minifigures, one Smart Brick and five Smart Tags, priced at $100. The Throne Room Duel & A-wing is a 962-piece set with three Smart Minifigures, two Smart Bricks and five Smart Tags, priced at a slightly shocking $160. It’s an entirely new direction for Lego, and you won’t have to wait long to check it out. The company is putting those three sets up for pre-order on January 9, and they’ll launch on March 1. There’s obviously a lot of technology here that’s entirely new to Lego, and as such it’s hard to imagine just how this will all look when it comes together — but we’re hoping that Lego will have some sets on hand here at CES so we can get a closer look at how the Smart Play system works. In the meantime, you can find a few videos on how Smart Play works here. This article originally appeared on Engadget at https://www.engadget.com/entertainment/lego-unveils-a-technology-packed-smart-brick-at-ces-2026-190000511.html?src=rss",
          "content": "Lego bricks come in a ridiculously vast array of sizes and shapes, but the company is unveiling an entirely new take on its classic shape at CES 2026. Meet the Lego Smart Brick, a standard-sized 2 x 4 brick that’s packed with modern technology to enable sets that can respond to how they’re played with or the sets you build. It’s part of a new initiative called Smart Play, which encompasses the Smart Brick as well as Smart Minifigures and Smart Tags. While we obviously don’t know yet how Lego fans will take to this new system, it’s still fair to say it’s the biggest move Lego has every made to infuse its products with connected technology. The Smart Brick has a 4.1mm ASIC chip inside of it that Lego says is smaller than a standard Lego stud. It runs something called the Play Engine that can sense things like motion, orientation and magnetic fields. Thanks to this and some integrated copper coils, the Smart Brick can sense distance, direction and orientation of other Smart Bricks near it when you’re building. The brick also has a tiny built-in speaker, an accelerometer and an LED array. Lego says the speaker can produce audio that is “tied to live play actions” rather than just playing pre-recorded clips. The Smart Tag and Smart Minifigures are a lot simpler. The Tag is a 2 x 2 studless tile with a digital ID embedded in it that the Smart Brick can read via “near-field magnetic communication.” This obviously sounds a lot like NFC, but we can’t be sure that these new Lego pieces will be able to communicate with any other NFC devices. Similarly, the Smart Minifigure also has a digital ID readable by NFC. The purpose of the Smart Tag as well as the similar tech in a Smart Minifigure is to let the Smart Brick know what kind of context it is being used in. As Lego puts it, “The role of the Smart Tag is to tell the Smart Brick how it should play back with you.” The Tag tells the Brick what kind of object, animal, vehicle and so forth it should become. A Smart Tag in a Lego Star Wars X-Wing set, for example, will contain the unique ID and instructions for how the Smart Brick should behave. If this isn’t enough, Lego has also built a local wireless layer that connects this all together called BrickNet. It’s based on Bluetooth and uses Lego’s proprietary “Neighbor Position Measurement\" system, which is what lets the Smart Bricks know how close they are to each other and how they’re oriented. Lego says that this lets the bricks “talk” to each other directly without the need for apps, internet connections or external controls. It sounds like the idea is all three of these new Smart pieces can communicate and interact without any need for setup, which should make it refreshingly like a traditional Lego set. That said, these bricks naturally will need some power. Lego says that their batteries should still perform even after “years” of inactivity, and the coils and power system is designed so that multiple bricks can be charged wirelessly on a shared charging pad. Lego Star Wars set with Smart Bricks Lego Speaking of sets, Lego is unsurprisingly launching the Smart Play system with its biggest licensed partner: Star Wars. There will be three “all-in-one” Star Wars sets available, all of which are on the smaller side and definitely geared towards kids, rather than the 1,000 piece and up sets that the company has released to get adults (like me) interested. The prices are inflated compared to non-smart sets, but not outrageously so. Darth Vader’s TIE Fighter is a 473-piece set with a smart Darth Vader Minifigure, one Smart Brick and one Smart Tag, priced at $70. Luke’s Red Five X-Wing is a 584-piece set with two Smart Minifigures, one Smart Brick and five Smart Tags, priced at $100. The Throne Room Duel & A-wing is a 962-piece set with three Smart Minifigures, two Smart Bricks and five Smart Tags, priced at a slightly shocking $160. It’s an entirely new direction for Lego, and you won’t have to wait long to check it out. The company is putting those three sets up for pre-order on January 9, and they’ll launch on March 1. There’s obviously a lot of technology here that’s entirely new to Lego, and as such it’s hard to imagine just how this will all look when it comes together — but we’re hoping that Lego will have some sets on hand here at CES so we can get a closer look at how the Smart Play system works. In the meantime, you can find a few videos on how Smart Play works here. This article originally appeared on Engadget at https://www.engadget.com/entertainment/lego-unveils-a-technology-packed-smart-brick-at-ces-2026-190000511.html?src=rss",
          "feed_position": 18,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/75427_Lifestyle_cons_4.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/what-are-micro-rgb-tvs-and-why-are-they-everywhere-at-ces-2026-182441543.html",
          "published_at": "Mon, 05 Jan 2026 18:24:42 +0000",
          "title": "What are Micro RGB TVs and why are they everywhere at CES 2026?",
          "standfirst": "Micro RGB TVs first arrived last year with little fanfare and a confusing name, so you may have mistaken it for other panel tech or not even noticed. That is not likely to be the case this year, though — it’s the hot new “luxury” display technology and is all over the place at CES 2026. So why do we even need these new TVs and how are they different from OLED, Micro LED and Mini LED models? Here’s how it works and how it compares. A brief history of flat panel display tech To better understand Micro RGB, it helps to see how flat panel display technology has evolved over the last 20 years. The first LCD TVs used liquid crystals that become transparent to light when voltage is applied, letting a rear backlight shine through as a pixel. Those pixels combine to create moving or still images, with color created via an RGB filter layer placed in front. The main problem is that LCD crystals let some light partially leak through, so blacks are dark grey instead of pure black. And for a backlight, early LCD TVs used a white screen lit by dim and power-hungry fluorescent lights, which caused uneven light distribution. And finally, the RGB filter color layer reduced a panel’s brightness. The next step up, then, was to use LED backlights instead, placed at first at the edges of the white screen and then later directly behind it (the first TV with this tech was Sony’s 2004 Qualia). That added the benefits of higher brightness, lower power consumption, improved color balance and even light distribution. It also allowed individual dimming zones that improve contrast by allowing near-pure blacks in shadow areas of an image. Samsung's Neo QLED 8K TV from CES 2025Samsung Quantum dot (QD) technology came on the scene around 2013 with Sony’s Triluminos televisions. This type of LCD panel employs a semiconductor nanocrystal layer (rather than an RGB filter layer) that can produce pure monochromatic red, green, and blue light when struck with a blue backlight. Unlike previous LCDs, they offer higher brightness and color accuracy thanks to the purity (narrowness) of the base RGB colors. The best-known TVs using this tech are Samsung’s QLED models. The latest evolution of QD LED technology is Mini LED. That combines the accuracy of quantum dot tech with hundreds or even thousands of LED dimming zones. Those models offer high brightness and color accuracy along with good contrast, but still don’t deliver perfect blacks and can display “blooming” in scenes with bright points of light due to leakage into neighboring pixels. Both of those problems were solved with OLED technology, which first came on the market in 2007 with Sony’s XEL-1 model. The panels are made using sheets coated with organic LEDs, each paired with a transistor that can switch the LED on or off. On regular OLED TVs, OLED pixels are white and a filter layer generates colors, much as with LED TVs. However, with QD-OLEDs, OLED pixels are blue and color is created via a quantum dot layer, like LED QD displays. The latest version of QD-OLED featured on several new monitors at CES 2026 (Samsung’s 5th-gen QD-OLED) uses an RGB stripe pattern to reduce color “fringing” on text. This is the first, and still the only widely commercialized TV tech that can switch its light source off on a pixel-by-pixel basis, allowing perfect black levels and near-infinite contrast. However, due to their organic nature, OLED TVs suffer from a lack of brightness and the potential for “burn-in” that can kill pixels. There is another type of self-illuminating tech called Micro LED. Rather than organic, it uses microscopic inorganic LEDs to form the individual pixel elements. Those can also be turned on or off individually, so they offer the same pure blacks and sky-high contrast as OLED. At the same time they’re potentially brighter than OLED and don’t suffer from burn-in. The tech is still prohibitively expensive to manufacture, though, so none have arrived to market other than Samsung’s The Wall, which costs a cool $40,000. Micro RGB Devindra Hardawar for Engadget Before talking about Micro RGB, let’s look at color space and gamut both for HDR, which uses the BT.2020 standard, and SDR, commonly associated with the REC.709 standard. REC.709 is ideal for regular HD content like TV broadcasts and YouTube videos. It can display a limited set of colors and brightness is generally capped at 100 nits. BT.2020, however, is designed for high-end HDR streaming and 4K or 8K content creation (via Dolby Vision, HDR 10 or HDR10+). It has a much wider color gamut, meaning it can display a wider variety of colors and a bigger chunk of the visible color spectrum. It’s also designed for significantly higher brightness levels of 1,000 nits or more. To achieve the color accuracy required for BT.2020, TVs must have extremely accurate red, green and blue pixels. Up until last year, the most color-accurate TVs used quantum dot technology and achieved a maximum of around 85 percent BT.2020 coverage (some projectors can cover 100 percent or more of the BT.2020 spectrum as they use RGB lasers to create colors). That brings us to Micro RGB (also known as RGB Mini LED), the most advanced LED panel yet. Unlike the uniform white or blue backlights found on Mini LED models, it features individually-controlled, precise red, green and blue LED backlights that shine through a liquid crystal layer. It also offers more local dimming zones. The net result is higher color accuracy and better contrast than regular Mini LED displays, but with potentially greater brightness than OLED. Since each pixel still can’t be turned on and off like OLED or Micro LED, though, contrast falls short of those technologies. Wikipedia So far, there is one and only one Micro RGB TV on the market, Samsung’s 115-inch 4K MR95F model. The color accuracy is impressive with 100 percent coverage of the challenging BT.2020 HDR standard, an industry-first and huge leap over quantum dot tech. That means it can produce billions of colors natively and display a higher percentage of them in the visible spectrum than any TV to date. Samsung left out a few key specs like the local dimming zone count, only saying that it has four times more than its similarly-priced 115-inch Q90F QLED model (so likely around 3,600). The company also failed to disclose the total brightness in nits, but the figure should be impressive given the potential of Micro RGB. We were gobsmacked with the MR95F Micro RGB model in person. Engadget editor Sam Rutherford said it produced “stunningly rich and vivid colors that put Samsung’s other top-tier TVs to shame,” including the aforementioned Q90F. It also came with an equally stunning $29,999 price tag. A couple of other manufacturers including HiSense have also released RGB Mini LED models similar to Samsung’s Micro RGB, but they differ slightly in that the RGB modules are larger than the ones found on Samsung’s latest TVs. Which companies will have Micro RGB tech at CES 2026? Samsung Luckily, the number of Micro RGB TVs is about to dramatically increase. Earlier this month, Samsung announced a full lineup using the technology with 55-, 65-, 75-, 85-, 100- and 115-inch screen sizes, saying they’d set “a new standard for premium home viewing.” Those sets will also offer 100 percent BT.2020 HDR coverage under a new certification standard called Micro RGB Precision Color 100. While certainly likely to carry more reasonable prices than the first model, they’ll probably still be Samsung’s most expensive TVs when released later this year. And on Sunday, Samsung also revealed a 130-inch Micro RGB prototype meant to showcase the technology. Once again, it blew us away partially just because of the huge size, but also due to the incredible \"color accuracy and richness,\" as Engadget editor Devindra Hardawar put it. \"I couldn’t help but notice how everyone just looked a bit stunned, like the monkeys from 2001 seeing the monolith for the first time,\" he added. At the same time, LG announced its first Micro RGB “evo” TV lineup in 75-, 86- and 100-inch models. The company is also promising 100 percent BT.2020 color gamut coverage and said the sets will have over a thousand local dimming zones for color control. Not only that, it said that its new TVs will deliver 100 percent coverage in SDR modes as well, both for Adobe RGB and the challenge P3 standard. It was interesting to compare LG's Wallpaper and other OLED sets with the new Micro RGB tech, with our editor Devindra again being amazed. \"LG already announced its Micro RGB set a few weeks ago, but that didn't prepare me for standing in front of the 100-inch demo TV it brought to CES,\" he said. \"Throughout a variety of clips, colors looked wonderfully rich, and the overall texture of the images looked surprisingly life-like.\" For its part, Hisense also unveiled a lineup of \"evo\" TVs that it calls RGB Mini-LED instead of Micro RGB. It's offering them at two price points, called the UR9 and UR8, with sizes ranging from 55 up to 100 inches. The company is promising an even wider color gamut than Samsung and LG with up to 110 percent BT.2020 coverage and \"color control achieving 134 bits,\" the company said. On top of that, HiSense had a surprise up its sleeve with the launch of an enormous 163-inch Micro LED TV to compete with Samsung's The Wall. The company actually calls it RGBY Micro LED, because it introduces a fourth yellow color into the RGB mix. The reason, according to the company, is that yellow expands the color spectrum \"where human vision perceives the most nuance.\" Update January 5, 2026 at 5:18 PM: The article now includes information about HiSense's latest RGB Mini LED and Micro LED TVs. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/what-are-micro-rgb-tvs-and-why-are-they-everywhere-at-ces-2026-182441543.html?src=rss",
          "content": "Micro RGB TVs first arrived last year with little fanfare and a confusing name, so you may have mistaken it for other panel tech or not even noticed. That is not likely to be the case this year, though — it’s the hot new “luxury” display technology and is all over the place at CES 2026. So why do we even need these new TVs and how are they different from OLED, Micro LED and Mini LED models? Here’s how it works and how it compares. A brief history of flat panel display tech To better understand Micro RGB, it helps to see how flat panel display technology has evolved over the last 20 years. The first LCD TVs used liquid crystals that become transparent to light when voltage is applied, letting a rear backlight shine through as a pixel. Those pixels combine to create moving or still images, with color created via an RGB filter layer placed in front. The main problem is that LCD crystals let some light partially leak through, so blacks are dark grey instead of pure black. And for a backlight, early LCD TVs used a white screen lit by dim and power-hungry fluorescent lights, which caused uneven light distribution. And finally, the RGB filter color layer reduced a panel’s brightness. The next step up, then, was to use LED backlights instead, placed at first at the edges of the white screen and then later directly behind it (the first TV with this tech was Sony’s 2004 Qualia). That added the benefits of higher brightness, lower power consumption, improved color balance and even light distribution. It also allowed individual dimming zones that improve contrast by allowing near-pure blacks in shadow areas of an image. Samsung's Neo QLED 8K TV from CES 2025Samsung Quantum dot (QD) technology came on the scene around 2013 with Sony’s Triluminos televisions. This type of LCD panel employs a semiconductor nanocrystal layer (rather than an RGB filter layer) that can produce pure monochromatic red, green, and blue light when struck with a blue backlight. Unlike previous LCDs, they offer higher brightness and color accuracy thanks to the purity (narrowness) of the base RGB colors. The best-known TVs using this tech are Samsung’s QLED models. The latest evolution of QD LED technology is Mini LED. That combines the accuracy of quantum dot tech with hundreds or even thousands of LED dimming zones. Those models offer high brightness and color accuracy along with good contrast, but still don’t deliver perfect blacks and can display “blooming” in scenes with bright points of light due to leakage into neighboring pixels. Both of those problems were solved with OLED technology, which first came on the market in 2007 with Sony’s XEL-1 model. The panels are made using sheets coated with organic LEDs, each paired with a transistor that can switch the LED on or off. On regular OLED TVs, OLED pixels are white and a filter layer generates colors, much as with LED TVs. However, with QD-OLEDs, OLED pixels are blue and color is created via a quantum dot layer, like LED QD displays. The latest version of QD-OLED featured on several new monitors at CES 2026 (Samsung’s 5th-gen QD-OLED) uses an RGB stripe pattern to reduce color “fringing” on text. This is the first, and still the only widely commercialized TV tech that can switch its light source off on a pixel-by-pixel basis, allowing perfect black levels and near-infinite contrast. However, due to their organic nature, OLED TVs suffer from a lack of brightness and the potential for “burn-in” that can kill pixels. There is another type of self-illuminating tech called Micro LED. Rather than organic, it uses microscopic inorganic LEDs to form the individual pixel elements. Those can also be turned on or off individually, so they offer the same pure blacks and sky-high contrast as OLED. At the same time they’re potentially brighter than OLED and don’t suffer from burn-in. The tech is still prohibitively expensive to manufacture, though, so none have arrived to market other than Samsung’s The Wall, which costs a cool $40,000. Micro RGB Devindra Hardawar for Engadget Before talking about Micro RGB, let’s look at color space and gamut both for HDR, which uses the BT.2020 standard, and SDR, commonly associated with the REC.709 standard. REC.709 is ideal for regular HD content like TV broadcasts and YouTube videos. It can display a limited set of colors and brightness is generally capped at 100 nits. BT.2020, however, is designed for high-end HDR streaming and 4K or 8K content creation (via Dolby Vision, HDR 10 or HDR10+). It has a much wider color gamut, meaning it can display a wider variety of colors and a bigger chunk of the visible color spectrum. It’s also designed for significantly higher brightness levels of 1,000 nits or more. To achieve the color accuracy required for BT.2020, TVs must have extremely accurate red, green and blue pixels. Up until last year, the most color-accurate TVs used quantum dot technology and achieved a maximum of around 85 percent BT.2020 coverage (some projectors can cover 100 percent or more of the BT.2020 spectrum as they use RGB lasers to create colors). That brings us to Micro RGB (also known as RGB Mini LED), the most advanced LED panel yet. Unlike the uniform white or blue backlights found on Mini LED models, it features individually-controlled, precise red, green and blue LED backlights that shine through a liquid crystal layer. It also offers more local dimming zones. The net result is higher color accuracy and better contrast than regular Mini LED displays, but with potentially greater brightness than OLED. Since each pixel still can’t be turned on and off like OLED or Micro LED, though, contrast falls short of those technologies. Wikipedia So far, there is one and only one Micro RGB TV on the market, Samsung’s 115-inch 4K MR95F model. The color accuracy is impressive with 100 percent coverage of the challenging BT.2020 HDR standard, an industry-first and huge leap over quantum dot tech. That means it can produce billions of colors natively and display a higher percentage of them in the visible spectrum than any TV to date. Samsung left out a few key specs like the local dimming zone count, only saying that it has four times more than its similarly-priced 115-inch Q90F QLED model (so likely around 3,600). The company also failed to disclose the total brightness in nits, but the figure should be impressive given the potential of Micro RGB. We were gobsmacked with the MR95F Micro RGB model in person. Engadget editor Sam Rutherford said it produced “stunningly rich and vivid colors that put Samsung’s other top-tier TVs to shame,” including the aforementioned Q90F. It also came with an equally stunning $29,999 price tag. A couple of other manufacturers including HiSense have also released RGB Mini LED models similar to Samsung’s Micro RGB, but they differ slightly in that the RGB modules are larger than the ones found on Samsung’s latest TVs. Which companies will have Micro RGB tech at CES 2026? Samsung Luckily, the number of Micro RGB TVs is about to dramatically increase. Earlier this month, Samsung announced a full lineup using the technology with 55-, 65-, 75-, 85-, 100- and 115-inch screen sizes, saying they’d set “a new standard for premium home viewing.” Those sets will also offer 100 percent BT.2020 HDR coverage under a new certification standard called Micro RGB Precision Color 100. While certainly likely to carry more reasonable prices than the first model, they’ll probably still be Samsung’s most expensive TVs when released later this year. And on Sunday, Samsung also revealed a 130-inch Micro RGB prototype meant to showcase the technology. Once again, it blew us away partially just because of the huge size, but also due to the incredible \"color accuracy and richness,\" as Engadget editor Devindra Hardawar put it. \"I couldn’t help but notice how everyone just looked a bit stunned, like the monkeys from 2001 seeing the monolith for the first time,\" he added. At the same time, LG announced its first Micro RGB “evo” TV lineup in 75-, 86- and 100-inch models. The company is also promising 100 percent BT.2020 color gamut coverage and said the sets will have over a thousand local dimming zones for color control. Not only that, it said that its new TVs will deliver 100 percent coverage in SDR modes as well, both for Adobe RGB and the challenge P3 standard. It was interesting to compare LG's Wallpaper and other OLED sets with the new Micro RGB tech, with our editor Devindra again being amazed. \"LG already announced its Micro RGB set a few weeks ago, but that didn't prepare me for standing in front of the 100-inch demo TV it brought to CES,\" he said. \"Throughout a variety of clips, colors looked wonderfully rich, and the overall texture of the images looked surprisingly life-like.\" For its part, Hisense also unveiled a lineup of \"evo\" TVs that it calls RGB Mini-LED instead of Micro RGB. It's offering them at two price points, called the UR9 and UR8, with sizes ranging from 55 up to 100 inches. The company is promising an even wider color gamut than Samsung and LG with up to 110 percent BT.2020 coverage and \"color control achieving 134 bits,\" the company said. On top of that, HiSense had a surprise up its sleeve with the launch of an enormous 163-inch Micro LED TV to compete with Samsung's The Wall. The company actually calls it RGBY Micro LED, because it introduces a fourth yellow color into the RGB mix. The reason, according to the company, is that yellow expands the color spectrum \"where human vision perceives the most nuance.\" Update January 5, 2026 at 5:18 PM: The article now includes information about HiSense's latest RGB Mini LED and Micro LED TVs. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/what-are-micro-rgb-tvs-and-why-are-they-everywhere-at-ces-2026-182441543.html?src=rss",
          "feed_position": 19,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/de40ab00-ea62-11f0-9dff-31cb26633672"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-press-conference-live-190040504.html",
          "published_at": "Mon, 05 Jan 2026 17:55:28 +0000",
          "title": "How to watch the Hisense CES 2026 press conference live",
          "standfirst": "Xinhua News Agency via Getty Images Hisense is typically best known for its affordable electronics and home appliances, from TVs to refrigerators. But at CES 2025, the China-based company showed off its premium side with a massive 136-inch micro LED TV — now available for a jaw-dropping $100,000. So what's in store for this year's show? New leadership, for starters. The company has two new hires, including Chief Marketing Officer Sarah Larsen and Chief Commercial Officer James Fishler. In a press release, Hisense said Fishler's experience in home entertainment, appliances and HVAC is important as the company \"builds toward a milestone 2026 and its presence at CES.\" We'll give you a rundown of what to expect during Hisense's presentation and how you can watch it live. How to watch Hisense's presentation Hisense is livestreaming the event on its YouTube channel today (Monday, January 5) at 1PM ET. We've embedded it below. You can also follow the Engadget CES 2026 liveblog for real-time updates from the show. What to expect With its new hires in place, Hisense is clearly aiming to further polish its brand. Between Fishler and Larsen, the new front office is bringing to bear their experience from such high-powered competitors as LG, Samsung and Beats. And in a recent interview with Tom's Guide, Larsen emphasized a continued focus on the company's fast turnaround time from concept to market as a key differentiator for Hisense. As for actual announcements, Hisense has already revealed the following products on its website: Hisense S6 FollowMe display: This is a TV on wheels (really!) that apparently can follow you from room to room. Hisense XR10 and PX4-PRO laser projectors: The company's latest laser projectors can deliver up to 6,000 lumens of brightness and screen sizes as big as 300 inches. ConnectLife AI-enhanced appliances: In an early press release, the company touted (what else) the enhanced AI smarts of its ConnectLife platform, stretching across everything from HVAC systems to kitchen gear to washer/dryers (\"... with the enhanced AI Laundry Agent, fabric types and soil levels are automatically identified...\"). Meanwhile, Larsen's aforementioned interview specifically calls out the emerging RGB TV space as a focus. We expect this year's show will be all about explaining the shades of difference between mini and micro LED display technologies, as both Samsung and LG have already thrown down pre-announcement gauntlets on the latter. Will any of them cost less than six figures? Let's hope Hisense has some good news to share on that front. Update, January 4 2026, 2:17PM ET: This story has been updated to include information on the Hisense ConnectLife AI platform. Update, January 5 2026, 10:45AM ET: This story has been updated to include info on Hisense's S6 FollowMe display and laser projectors. Update, January 5 2026, 11:31AM ET: This story has been updated to include the embedded YouTube livestream.This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-press-conference-live-190040504.html?src=rss",
          "content": "Xinhua News Agency via Getty Images Hisense is typically best known for its affordable electronics and home appliances, from TVs to refrigerators. But at CES 2025, the China-based company showed off its premium side with a massive 136-inch micro LED TV — now available for a jaw-dropping $100,000. So what's in store for this year's show? New leadership, for starters. The company has two new hires, including Chief Marketing Officer Sarah Larsen and Chief Commercial Officer James Fishler. In a press release, Hisense said Fishler's experience in home entertainment, appliances and HVAC is important as the company \"builds toward a milestone 2026 and its presence at CES.\" We'll give you a rundown of what to expect during Hisense's presentation and how you can watch it live. How to watch Hisense's presentation Hisense is livestreaming the event on its YouTube channel today (Monday, January 5) at 1PM ET. We've embedded it below. You can also follow the Engadget CES 2026 liveblog for real-time updates from the show. What to expect With its new hires in place, Hisense is clearly aiming to further polish its brand. Between Fishler and Larsen, the new front office is bringing to bear their experience from such high-powered competitors as LG, Samsung and Beats. And in a recent interview with Tom's Guide, Larsen emphasized a continued focus on the company's fast turnaround time from concept to market as a key differentiator for Hisense. As for actual announcements, Hisense has already revealed the following products on its website: Hisense S6 FollowMe display: This is a TV on wheels (really!) that apparently can follow you from room to room. Hisense XR10 and PX4-PRO laser projectors: The company's latest laser projectors can deliver up to 6,000 lumens of brightness and screen sizes as big as 300 inches. ConnectLife AI-enhanced appliances: In an early press release, the company touted (what else) the enhanced AI smarts of its ConnectLife platform, stretching across everything from HVAC systems to kitchen gear to washer/dryers (\"... with the enhanced AI Laundry Agent, fabric types and soil levels are automatically identified...\"). Meanwhile, Larsen's aforementioned interview specifically calls out the emerging RGB TV space as a focus. We expect this year's show will be all about explaining the shades of difference between mini and micro LED display technologies, as both Samsung and LG have already thrown down pre-announcement gauntlets on the latter. Will any of them cost less than six figures? Let's hope Hisense has some good news to share on that front. Update, January 4 2026, 2:17PM ET: This story has been updated to include information on the Hisense ConnectLife AI platform. Update, January 5 2026, 10:45AM ET: This story has been updated to include info on Hisense's S6 FollowMe display and laser projectors. Update, January 5 2026, 11:31AM ET: This story has been updated to include the embedded YouTube livestream.This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-press-conference-live-190040504.html?src=rss",
          "feed_position": 23,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/834aecc0-dcf1-11f0-b7de-13a29302f310"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/voccis-ai-note-taking-ring-aims-to-do-much-more-170536442.html",
          "published_at": "Mon, 05 Jan 2026 17:05:36 +0000",
          "title": "Vocci's AI note-taking ring aims to do much more",
          "standfirst": "One trend emerging from CES 2026 is wearable microphones you can use to dictate your thoughts. Vocci is one such gadget, a titanium ring with a single button capable of recording audio for up to eight hours on a charge. Unlike some of its competitors, Vocci isn’t just for catching your own thoughts as they spring forth from your scalp. Instead, you’ll be able to record whole conversations and meetings from the comfort of your proximal phalanx. Users can start and end recordings by double clicking the ring’s single button, while single clicks are used to mark important moments within the recording. Tagged moments will instruct the AI app to add more context, highlights or reminders, where appropriate. Once the file has been processed, you’ll receive a transcript, complete with a summary and commentary.I’m told the ring has a range of five meters, but I was unable to hear an example recording or see a working demo of the technology. I did ask why a ring would be more effective at capturing a room’s worth of chat over, say, using a recording app on one’s phone laid on a table. But the response was to point out a user may forget to start the recording, and you can’t disagree with that.Vocci will ship with a charging case, and will be able to recharge to full in half an hour, but it’s not clear yet how much (if at all) power will be stored in the case’s batteries. We also don’t know how much the ring will cost, but it’s likely to be available for pre-order at some point in February. As for the ring’s pedigree, it comes from Gyges Labs, the company which leant its name, manufacturing and engineering expertise to last year’s Halliday Smart Glasses.This article originally appeared on Engadget at https://www.engadget.com/wearables/voccis-ai-note-taking-ring-aims-to-do-much-more-170536442.html?src=rss",
          "content": "One trend emerging from CES 2026 is wearable microphones you can use to dictate your thoughts. Vocci is one such gadget, a titanium ring with a single button capable of recording audio for up to eight hours on a charge. Unlike some of its competitors, Vocci isn’t just for catching your own thoughts as they spring forth from your scalp. Instead, you’ll be able to record whole conversations and meetings from the comfort of your proximal phalanx. Users can start and end recordings by double clicking the ring’s single button, while single clicks are used to mark important moments within the recording. Tagged moments will instruct the AI app to add more context, highlights or reminders, where appropriate. Once the file has been processed, you’ll receive a transcript, complete with a summary and commentary.I’m told the ring has a range of five meters, but I was unable to hear an example recording or see a working demo of the technology. I did ask why a ring would be more effective at capturing a room’s worth of chat over, say, using a recording app on one’s phone laid on a table. But the response was to point out a user may forget to start the recording, and you can’t disagree with that.Vocci will ship with a charging case, and will be able to recharge to full in half an hour, but it’s not clear yet how much (if at all) power will be stored in the case’s batteries. We also don’t know how much the ring will cost, but it’s likely to be available for pre-order at some point in February. As for the ring’s pedigree, it comes from Gyges Labs, the company which leant its name, manufacturing and engineering expertise to last year’s Halliday Smart Glasses.This article originally appeared on Engadget at https://www.engadget.com/wearables/voccis-ai-note-taking-ring-aims-to-do-much-more-170536442.html?src=rss",
          "feed_position": 25
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/xgimis-titan-noir-max-4k-projector-has-a-dynamic-iris-for-increased-contrast-170044625.html",
          "published_at": "Mon, 05 Jan 2026 17:00:44 +0000",
          "title": "XGIMI's Titan Noir Max 4K projector has a dynamic IRIS for increased contrast",
          "standfirst": "XGIMI, which burst on the scene in 2025 with several impressive projectors, has unveiled its latest high-end model called the Titan Noir Max. The new model revealed at CES 2026 has many of the bells and whistles found on professional-level projectors including a dynamic IRIS system for improved contrast, along with a new thermal system designed to boost brightness. The Titan Noir Max has a design to XGIMI's Titan model announced last year, but it's taller and a bit squarer with an elegant grille-like pattern on the front. As with other XGIMI models, it features a laser light engine and 4K video quality, though the company didn't say if it had the same big Texas Instruments 0.78-inch DMD (digital micromirror device) chip as the original Titan model. The key new feature is a dynamic IRIS system that boosts native contrast to 10,000:1 for deeper blacks and brighter highlights. At the same time, it boasts new \"precision tuned optics\" (ie a better lens) also designed to improve contrast and color nuance. Another key feature is a re-engineered DMD architecture that can handle \"substantially higher light power densities,\" XGIMI says. This should allow for increased brightness, though the company didn't provide a figure in ANSI Lumens. It would be impressive if it topped the 5,000 Lumen Titan, though. Many other specs are lacking, like color accuracy in the Rec.2020 space. However, the company is promising a lot, saying that the Titan Noir Max will offer \"the stability, accuracy, and reliability required for color-critical work, studio environments, and high-end installations.\" At the same time, it's also targeted at home enthusiasts, promising to \"turn a blank wall into a cinematic event.\" XGIMI's Titan was only recently released for $3,999 but there's no word yet on the price or release date of the Titan Noir Max. Unlike the Horizon 20 series (which has a smaller 0.47-inch DMD chip) the Titan has received very few reviews so far, but one French projector site gave it a solid score. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/xgimis-titan-noir-max-4k-projector-has-a-dynamic-iris-for-increased-contrast-170044625.html?src=rss",
          "content": "XGIMI, which burst on the scene in 2025 with several impressive projectors, has unveiled its latest high-end model called the Titan Noir Max. The new model revealed at CES 2026 has many of the bells and whistles found on professional-level projectors including a dynamic IRIS system for improved contrast, along with a new thermal system designed to boost brightness. The Titan Noir Max has a design to XGIMI's Titan model announced last year, but it's taller and a bit squarer with an elegant grille-like pattern on the front. As with other XGIMI models, it features a laser light engine and 4K video quality, though the company didn't say if it had the same big Texas Instruments 0.78-inch DMD (digital micromirror device) chip as the original Titan model. The key new feature is a dynamic IRIS system that boosts native contrast to 10,000:1 for deeper blacks and brighter highlights. At the same time, it boasts new \"precision tuned optics\" (ie a better lens) also designed to improve contrast and color nuance. Another key feature is a re-engineered DMD architecture that can handle \"substantially higher light power densities,\" XGIMI says. This should allow for increased brightness, though the company didn't provide a figure in ANSI Lumens. It would be impressive if it topped the 5,000 Lumen Titan, though. Many other specs are lacking, like color accuracy in the Rec.2020 space. However, the company is promising a lot, saying that the Titan Noir Max will offer \"the stability, accuracy, and reliability required for color-critical work, studio environments, and high-end installations.\" At the same time, it's also targeted at home enthusiasts, promising to \"turn a blank wall into a cinematic event.\" XGIMI's Titan was only recently released for $3,999 but there's no word yet on the price or release date of the Titan Noir Max. Unlike the Horizon 20 series (which has a smaller 0.47-inch DMD chip) the Titan has received very few reviews so far, but one French projector site gave it a solid score. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/xgimis-titan-noir-max-4k-projector-has-a-dynamic-iris-for-increased-contrast-170044625.html?src=rss",
          "feed_position": 27
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/xgimi-best-known-for-projectors-launches-its-own-smart-glasses-170000968.html",
          "published_at": "Mon, 05 Jan 2026 17:00:00 +0000",
          "title": "XGIMI, best known for projectors, launches its own smart glasses",
          "standfirst": "Projector maker XGIMI has turned up at CES to launch its own range of AR glasses, but don’t get the champagne out too soon. MemoMind is a new brand under which its AI-infused eyewear will be sold, with two distinct units arriving at some point in the near future. The company says it has leveraged its know-how in optics and engineering to produce glasses which are unobtrusively light, all the better for blending into your daily life. Fashionistas will even be overjoyed to learn the glasses’ ship in eight different frame styles, five different temple designs and can be worn with prescription lenses. Memo One is the company’s flagship option, with dual-eye displays and integrated speakers so you can see and hear your AI assistant. The Memo Air, meanwhile, is a more stripped down model weighing just 28.9 grams which just has a single eye display. Unfortunately, the company is using microLED displays rather than waveguides, making them a far harder sell for a lot of would-be users. After all, putting something that small so close to your eye but behind your prescription means it’s a painful experience for short sighted folks to focus on text. As I explained in my Halliday review, this technology is no friend to the glasses wearers who would otherwise be the ideal early adopters.MemoMind LineupXGIMIThe glasses are just a vehicle for the company’s AI assistant, promising translation, summarization, note-taking, reminders and contextual guidance. Unlike some of its would-be rivals, XGIMI says its platform will switch between OpenAI, Azure and (Alibaba’s) Qwen depending on what it thinks will offer you the best result for each task. Naturally, we’ll need to get them in to test before passing final judgment on their qualities but, you can color us naturally hostile to those damn microLEDs until we’re convinced otherwise.XGIMI says the flagship Memo One will be available to pre-order “soon,” priced at $599, with additional models available further down the line. This article originally appeared on Engadget at https://www.engadget.com/wearables/xgimi-best-known-for-projectors-launches-its-own-smart-glasses-170000968.html?src=rss",
          "content": "Projector maker XGIMI has turned up at CES to launch its own range of AR glasses, but don’t get the champagne out too soon. MemoMind is a new brand under which its AI-infused eyewear will be sold, with two distinct units arriving at some point in the near future. The company says it has leveraged its know-how in optics and engineering to produce glasses which are unobtrusively light, all the better for blending into your daily life. Fashionistas will even be overjoyed to learn the glasses’ ship in eight different frame styles, five different temple designs and can be worn with prescription lenses. Memo One is the company’s flagship option, with dual-eye displays and integrated speakers so you can see and hear your AI assistant. The Memo Air, meanwhile, is a more stripped down model weighing just 28.9 grams which just has a single eye display. Unfortunately, the company is using microLED displays rather than waveguides, making them a far harder sell for a lot of would-be users. After all, putting something that small so close to your eye but behind your prescription means it’s a painful experience for short sighted folks to focus on text. As I explained in my Halliday review, this technology is no friend to the glasses wearers who would otherwise be the ideal early adopters.MemoMind LineupXGIMIThe glasses are just a vehicle for the company’s AI assistant, promising translation, summarization, note-taking, reminders and contextual guidance. Unlike some of its would-be rivals, XGIMI says its platform will switch between OpenAI, Azure and (Alibaba’s) Qwen depending on what it thinks will offer you the best result for each task. Naturally, we’ll need to get them in to test before passing final judgment on their qualities but, you can color us naturally hostile to those damn microLEDs until we’re convinced otherwise.XGIMI says the flagship Memo One will be available to pre-order “soon,” priced at $599, with additional models available further down the line. This article originally appeared on Engadget at https://www.engadget.com/wearables/xgimi-best-known-for-projectors-launches-its-own-smart-glasses-170000968.html?src=rss",
          "feed_position": 30,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/20251218-110941_%281%29.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/the-hp-omnibook-ultra-14-at-ces-2026-super-sleek-and-surprisingly-durable-170000330.html",
          "published_at": "Mon, 05 Jan 2026 17:00:00 +0000",
          "title": "The HP Omnibook Ultra 14 at CES 2026: Super sleek and surprisingly durable",
          "standfirst": "At CES 2026, HP is showing off its latest flagship consumer laptop: The Omnibook Ultra 14. It features an all-new super thin design that’s much tougher than it looks. According to HP, the Omnibook Ultra 14 is the “world’s most durably slim 14-inch consumer notebook,” which is a somewhat convoluted way of saying the system remains quite portable — just 0.42 inches thick — while still passing 20 different military standard tests (MIL-STD-810) for things like shock resistance, drops and extreme temperatures. The whole system is crafted from aluminum, though instead of taking a unibody approach like you see on Apple’s MacBooks, HP opted for forge stamped manufacturing which is said to give the laptop added strength and bend resistance. The result is a notebook that’s both 52 percent lighter than the previous model at 2.8 pounds and five percent thinner than a 2025 M4 MacBook Air 13. And after seeing it in person, I have to say it looks pretty slick, too. As you’d expect from a premium ultraportable, the Omnibook comes with a vivid 3K OLED display, up to 64GB of memory, 2TB of storage and your choice of either an Intel Core Ultra 3 CPU or a Snapdragon Elite X2 chip. That said, thanks to an exclusive partnership with Qualcomm, anyone planning on running a lot of AI-based apps on the Ultra 14 may want to go with the Snapdragon variant as it’ll come with a slightly more powerful NPU that maxes out at 85 TOPS (that’s trillions of operations per second) rather than the 80 TOPS you’d get from other OEMs. Furthermore, to help support strong sustained performance, the Ultra 14 is also the first Omnibook to feature a built-in vapor chamber. Granted, as a pretty straightforward ultraportable, this thing doesn’t have a ton of special features. But even so, I appreciate that HP didn’t cut corners regarding its keyboard, which has a nice feel that’s not too stiff or bouncy and sits above a rather large touchpad. The company even found room for quad speakers and three USB-C ports that offer Thunderbolt 4, power delivery (USB PD 3.1) and DisplayPort 2.1. My one small nitpick is that I would have liked to see an SD or microSD card reader as well, but considering HP’s emphasis on portability and toughness, I’m not surprised that it didn't make it. The other thing I’m not so sure about is the Omnibook name in general. It’s been a little while since HP axed the Spectre branding for its top tier consumer laptops and I kind of wish HP would bring it back as it sounds better and feels more befitting of a flagship system like this. Regardless, if you’re in the market for a premium 14-inch Windows laptop, the Omnibook Ultra 14 looks like it will be a very strong contender when it goes on sale later this month starting at $1,550.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/the-hp-omnibook-ultra-14-at-ces-2026-super-sleek-and-surprisingly-durable-170000330.html?src=rss",
          "content": "At CES 2026, HP is showing off its latest flagship consumer laptop: The Omnibook Ultra 14. It features an all-new super thin design that’s much tougher than it looks. According to HP, the Omnibook Ultra 14 is the “world’s most durably slim 14-inch consumer notebook,” which is a somewhat convoluted way of saying the system remains quite portable — just 0.42 inches thick — while still passing 20 different military standard tests (MIL-STD-810) for things like shock resistance, drops and extreme temperatures. The whole system is crafted from aluminum, though instead of taking a unibody approach like you see on Apple’s MacBooks, HP opted for forge stamped manufacturing which is said to give the laptop added strength and bend resistance. The result is a notebook that’s both 52 percent lighter than the previous model at 2.8 pounds and five percent thinner than a 2025 M4 MacBook Air 13. And after seeing it in person, I have to say it looks pretty slick, too. As you’d expect from a premium ultraportable, the Omnibook comes with a vivid 3K OLED display, up to 64GB of memory, 2TB of storage and your choice of either an Intel Core Ultra 3 CPU or a Snapdragon Elite X2 chip. That said, thanks to an exclusive partnership with Qualcomm, anyone planning on running a lot of AI-based apps on the Ultra 14 may want to go with the Snapdragon variant as it’ll come with a slightly more powerful NPU that maxes out at 85 TOPS (that’s trillions of operations per second) rather than the 80 TOPS you’d get from other OEMs. Furthermore, to help support strong sustained performance, the Ultra 14 is also the first Omnibook to feature a built-in vapor chamber. Granted, as a pretty straightforward ultraportable, this thing doesn’t have a ton of special features. But even so, I appreciate that HP didn’t cut corners regarding its keyboard, which has a nice feel that’s not too stiff or bouncy and sits above a rather large touchpad. The company even found room for quad speakers and three USB-C ports that offer Thunderbolt 4, power delivery (USB PD 3.1) and DisplayPort 2.1. My one small nitpick is that I would have liked to see an SD or microSD card reader as well, but considering HP’s emphasis on portability and toughness, I’m not surprised that it didn't make it. The other thing I’m not so sure about is the Omnibook name in general. It’s been a little while since HP axed the Spectre branding for its top tier consumer laptops and I kind of wish HP would bring it back as it sounds better and feels more befitting of a flagship system like this. Regardless, if you’re in the market for a premium 14-inch Windows laptop, the Omnibook Ultra 14 looks like it will be a very strong contender when it goes on sale later this month starting at $1,550.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/the-hp-omnibook-ultra-14-at-ces-2026-super-sleek-and-surprisingly-durable-170000330.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/lg-tvs-at-ces-2026-a-stunning-wallpaper-set-glorious-micro-rgb-colors-and-a-better-gallery-tv-033739600.html",
          "published_at": "Mon, 05 Jan 2026 16:46:20 +0000",
          "title": "LG TVs at CES 2026: A stunning Wallpaper set, glorious Micro RGB colors and a better Gallery TV",
          "standfirst": "We typically see LG TV announcements a bit before CES, but this year the company had a surprise in store. CES 2026 marks the return of LG's ultra-thin \"Wallpaper\" TV. The latest version sports a gorgeous OLED screen and wireless connectivity, and it's about as thin as a pencil. We were able to check out the new Wallpaper TV during a CES preview event, along with LG’s Gallery and Micro RGB sets. The company also announced refreshed OLED and LED sets for this year, but it's clear that 2026 will be filled with intriguing TVs for a variety of consumers.LG's 2026 Wallpaper OLED TVDevindra Hardawar for EngadgetThe Wallpaper TV (LG W6)If money were no object, I'd want a 100-inch LG Wallpaper TV in my family room immediately. It looks shockingly thin in person — almost as if it's some sort of sci-fi prop — and it delivers the rich colors and dark levels we expect from OLED. Cable management is also a cinch, since it requires just a single power cable. The A/V inputs are handled by LG's One Connect box, which you can position wirelessly up to 10 meters away from the TV. LG's 2026 Wallpaper OLED TV from the rearDevindra Hardawar for EngadgetThe LG W6 combines the best of LG's OLED technology, including \"Hyper Radiant Color\" for improved black levels and color, \"Brightness Booster Ultra\" to crank up luminance 3.9 times more than conventional OLEDs and a reflection free screen material. LG's Alpha 9 Gen 3 processor beefs up its performance, and its NPU also helps to improve upscaling and overall image performance. (And yes, you can also access generative AI features via Microsoft Copilot and Google Gemini, if you're into that sort of thing.)All of that adds up to one of the most remarkable TVs I've seen in years. I haven't been too enamored with other TV gimmicks lately, like everything trying to mimic Samsung's The Frame, or the usless 8K sets. But a super-thin wireless TV with the best OLED panel available? That's the stuff dreams are made of. LG's 2026 Gallery TVDevindra Hardawar for EngadgetThe Gallery TV competes with Samsung’s FrameWhile LG has made Gallery TVs before, in 2026 it's making a more concerted effort to take on Samsung's popular Frame TV. LG says the new sets were designed with the help of museum curators, which helps the \"Gallery Mode\" adjust brightness and contrast to specific works of art. They also ship with magnetic frame-like bezels, and they have anti-reflective screens to help make the art shine. In person, the new Gallery TV looks fine, though it's easy to tell that the colors and contrast levels don't match LG's premium OLED TVs. To avoid burn-in issues, these sets feature Mini LED panels. As I noted above, I'm not the core consumer for one of these TVs, but it's nice to see more competition against Samsung's Frame TVs. (Despite pioneering the idea of TVs displaying art, the Frame sets are still fairly mediocre when it comes to actually watching TV shows and movies.) LG's Micro RGB TVDevindra Hardawar for EngadgetMicro RGB looks like a genuine Mini LED upgradeAs if we needed more TV acronyms to worry about, say hello to Micro RGB, a new technology built atop Mini LED to cover vastly more color range. Just don't confuse it with Micro LED, which is the wildly expensive evolutionary step forward for OLED. LG already announced its Micro RGB set a few weeks ago, but that didn't prepare me for standing in front of the 100-inch demo TV it brought to CES. Throughout a variety of clips, colors looked wonderfully rich, and the overall texture of the images looked surprisingly life-like. I'd have to compare it to LG's Wall TV side-by-side to truly see how Micro RGB competes with OLED, but technically OLED should still offer better contrast and black levels, since each of its pixels are self-emissive. But sure, if I couldn't get a 100-inch Wall TV in my family room, I certainly wouldn't turn down an enormous Micro RGB. What about LG's other OLED TVs?All of the next-generation OLED technology in the wallpaper TV will also make its way into LG's G6 OLED models, while the new C6 and other lines will see improvements of their own. All I can say is that the new G6 OLED looked impressive, with a noticeably brighter picture and HDR elements compared to G-series OLEDs from several years ago. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-tvs-at-ces-2026-a-stunning-wallpaper-set-glorious-micro-rgb-colors-and-a-better-gallery-tv-033739600.html?src=rss",
          "content": "We typically see LG TV announcements a bit before CES, but this year the company had a surprise in store. CES 2026 marks the return of LG's ultra-thin \"Wallpaper\" TV. The latest version sports a gorgeous OLED screen and wireless connectivity, and it's about as thin as a pencil. We were able to check out the new Wallpaper TV during a CES preview event, along with LG’s Gallery and Micro RGB sets. The company also announced refreshed OLED and LED sets for this year, but it's clear that 2026 will be filled with intriguing TVs for a variety of consumers.LG's 2026 Wallpaper OLED TVDevindra Hardawar for EngadgetThe Wallpaper TV (LG W6)If money were no object, I'd want a 100-inch LG Wallpaper TV in my family room immediately. It looks shockingly thin in person — almost as if it's some sort of sci-fi prop — and it delivers the rich colors and dark levels we expect from OLED. Cable management is also a cinch, since it requires just a single power cable. The A/V inputs are handled by LG's One Connect box, which you can position wirelessly up to 10 meters away from the TV. LG's 2026 Wallpaper OLED TV from the rearDevindra Hardawar for EngadgetThe LG W6 combines the best of LG's OLED technology, including \"Hyper Radiant Color\" for improved black levels and color, \"Brightness Booster Ultra\" to crank up luminance 3.9 times more than conventional OLEDs and a reflection free screen material. LG's Alpha 9 Gen 3 processor beefs up its performance, and its NPU also helps to improve upscaling and overall image performance. (And yes, you can also access generative AI features via Microsoft Copilot and Google Gemini, if you're into that sort of thing.)All of that adds up to one of the most remarkable TVs I've seen in years. I haven't been too enamored with other TV gimmicks lately, like everything trying to mimic Samsung's The Frame, or the usless 8K sets. But a super-thin wireless TV with the best OLED panel available? That's the stuff dreams are made of. LG's 2026 Gallery TVDevindra Hardawar for EngadgetThe Gallery TV competes with Samsung’s FrameWhile LG has made Gallery TVs before, in 2026 it's making a more concerted effort to take on Samsung's popular Frame TV. LG says the new sets were designed with the help of museum curators, which helps the \"Gallery Mode\" adjust brightness and contrast to specific works of art. They also ship with magnetic frame-like bezels, and they have anti-reflective screens to help make the art shine. In person, the new Gallery TV looks fine, though it's easy to tell that the colors and contrast levels don't match LG's premium OLED TVs. To avoid burn-in issues, these sets feature Mini LED panels. As I noted above, I'm not the core consumer for one of these TVs, but it's nice to see more competition against Samsung's Frame TVs. (Despite pioneering the idea of TVs displaying art, the Frame sets are still fairly mediocre when it comes to actually watching TV shows and movies.) LG's Micro RGB TVDevindra Hardawar for EngadgetMicro RGB looks like a genuine Mini LED upgradeAs if we needed more TV acronyms to worry about, say hello to Micro RGB, a new technology built atop Mini LED to cover vastly more color range. Just don't confuse it with Micro LED, which is the wildly expensive evolutionary step forward for OLED. LG already announced its Micro RGB set a few weeks ago, but that didn't prepare me for standing in front of the 100-inch demo TV it brought to CES. Throughout a variety of clips, colors looked wonderfully rich, and the overall texture of the images looked surprisingly life-like. I'd have to compare it to LG's Wall TV side-by-side to truly see how Micro RGB competes with OLED, but technically OLED should still offer better contrast and black levels, since each of its pixels are self-emissive. But sure, if I couldn't get a 100-inch Wall TV in my family room, I certainly wouldn't turn down an enormous Micro RGB. What about LG's other OLED TVs?All of the next-generation OLED technology in the wallpaper TV will also make its way into LG's G6 OLED models, while the new C6 and other lines will see improvements of their own. All I can say is that the new G6 OLED looked impressive, with a noticeably brighter picture and HDR elements compared to G-series OLEDs from several years ago. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-tvs-at-ces-2026-a-stunning-wallpaper-set-glorious-micro-rgb-colors-and-a-better-gallery-tv-033739600.html?src=rss",
          "feed_position": 32,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/LG_CES_2026-5.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/soundcores-nebula-p1i-portable-projector-launches-in-early-2026-for-369-160020321.html",
          "published_at": "Mon, 05 Jan 2026 16:00:20 +0000",
          "title": "Soundcore's Nebula P1i portable projector launches in early 2026 for $369",
          "standfirst": "If you had your eye on Nebula P1 projector but $799 is too rich for your blood, Soundcore has a new option at CES 2026. The Anker affiliate just unveiled the 1080p Nebula P1i portable projector that's less than half the price and even more portable, albeit with less brightness. Instead of detachable speakers like the Nebula P1, the P1i's speakers are embedded in the projector and can be flipped open and tilted through 180 degrees. It also lacks the P1's tilting projector body and instead offers a stand that can incline the projector from zero to 12 degrees. Though it offers the same 1080p maximum resolution as the Nebula P1, it's a bit less bright at 400 instead of 650 ANSI Lumens. Like the more expensive model, though, it supports autofocus, auto keystone correction and screen fit, which will make setup easy for spontaneous outdoor use. And like other projectors in the Nebula lineup, it supports Google TV so you can stream Netflix, Prime Video, Disney and other apps. Best of all, the Nebula P1i is priced at a very reasonable $369 and is set to arrive in \"early 2026,\" according to Soundcore. Soundcore Soundcore also revealed availability for its Nebula X1 Pro party projector that marries its impressive Nebula X1 projector with a 160W sound system, all in one assembly. As a reminder, the projector delivers 3,500 ANSI lumens and an impressive 110 percent coverage of the Rec.2020 HDR color space. The sound system, meanwhile, features a floating subwoofer, 80W soundbar speakers and two wireless satellite speakers for 7.1.4 surround sound. It even supports Dolby Atmos, which the projector on its own doesn't do, while offering IP43 protection from light rain and dust if you want to use it outdoors. The Nebula X1 Pro is tentatively set to launch on January 20, 2026 for $4,999, though you currently preorder one on Soundcore.com for $4,499. If you need a screen, the company is offering a 200-inch inflatable model for $2,000. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/soundcores-nebula-p1i-portable-projector-launches-in-early-2026-for-369-160020321.html?src=rss",
          "content": "If you had your eye on Nebula P1 projector but $799 is too rich for your blood, Soundcore has a new option at CES 2026. The Anker affiliate just unveiled the 1080p Nebula P1i portable projector that's less than half the price and even more portable, albeit with less brightness. Instead of detachable speakers like the Nebula P1, the P1i's speakers are embedded in the projector and can be flipped open and tilted through 180 degrees. It also lacks the P1's tilting projector body and instead offers a stand that can incline the projector from zero to 12 degrees. Though it offers the same 1080p maximum resolution as the Nebula P1, it's a bit less bright at 400 instead of 650 ANSI Lumens. Like the more expensive model, though, it supports autofocus, auto keystone correction and screen fit, which will make setup easy for spontaneous outdoor use. And like other projectors in the Nebula lineup, it supports Google TV so you can stream Netflix, Prime Video, Disney and other apps. Best of all, the Nebula P1i is priced at a very reasonable $369 and is set to arrive in \"early 2026,\" according to Soundcore. Soundcore Soundcore also revealed availability for its Nebula X1 Pro party projector that marries its impressive Nebula X1 projector with a 160W sound system, all in one assembly. As a reminder, the projector delivers 3,500 ANSI lumens and an impressive 110 percent coverage of the Rec.2020 HDR color space. The sound system, meanwhile, features a floating subwoofer, 80W soundbar speakers and two wireless satellite speakers for 7.1.4 surround sound. It even supports Dolby Atmos, which the projector on its own doesn't do, while offering IP43 protection from light rain and dust if you want to use it outdoors. The Nebula X1 Pro is tentatively set to launch on January 20, 2026 for $4,999, though you currently preorder one on Soundcore.com for $4,499. If you need a screen, the company is offering a 200-inch inflatable model for $2,000. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/soundcores-nebula-p1i-portable-projector-launches-in-early-2026-for-369-160020321.html?src=rss",
          "feed_position": 36,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/78936520-ea0f-11f0-b93d-34c3841957f7"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/ankers-ces-smart-home-lineup-includes-a-1600-eufy-robovac-160000133.html",
          "published_at": "Mon, 05 Jan 2026 16:00:00 +0000",
          "title": "Anker's CES smart home lineup includes a $1,600 Eufy robovac",
          "standfirst": "It seems like only a few years ago that Anker made nothing more than batteries and chargers. But 15 years into its history, the company's CES portfolio continues to illustrate how much it's expanded. Among other announcements, the company has a new robot vacuum, video doorbell, outdoor light and smart lock. They're all rolling out under Anker's Eufy smart home brand.The company hopes its Eufy Clean Robot Vacuum Omni S2 will be your next robovac. The $1,600 device vacuums with 100 AW suction, and it mops, too. Anker claims the vac works on shag carpets up to about 2 inches (5 cm) in pile height. It has an 11.4-inch rolling mop that applies up to 15 N of downward pressure.As is increasingly common in robovacs, Omni S2 uses AI to identify floor types and adjust several factors on the fly. These include cleaning mode, suction, scrubbing force and wheel height. The machine can also generate lightly oxidizing disinfectants (a hypochlorous acid and ozone water solution) inside its tank.Presales for the Eufy Clean Robot Vacuum Omni S2 begin on January 6. Shipping and in-store availability for the $1,600 robovac kicks off on January 20.Eufy Video Doorbell S4AnkerAnker also has a new doorbell, the Eufy Video Doorbell S4. It includes an AI-powered people detection feature with auto-framing. The doorbell has 3,024 x 3,024 resolution at 24 FPS and offers a panoramic (180 x 180-degree) view.You can use the doorbell in either wired or wireless mode, and it supports solar charging. The Video Doorbell S4 is scheduled to launch \"later in Q1\" for $280.Eufy Solar Wall Light Cam S4AnkerAlong similar lines, there's the Solar Wall Light Cam S4. The outdoor light has a built-in 4K camera with an f/1.6 aperture. The light has a color temperature ranging from warm white (2700K) to cool white (6500K).As its name suggests, it supports solar charging. It’s bundled with a detachable 2W solar panel. It also has a 10,000mAh battery that's rated for up to two months. Anker says the Solar Wall Light Cam S4 will arrive in Q1 for $200.Eufy Smart Lock E40AnkerFinally, Anker has a new lock / camera combo: the Eufy Smart Lock E40. It has \"advanced 3D face recognition\" that can identify you and your family from up to 10 feet away, unlocking accordingly. Its camera has 2K resolution and a 135-degree field of view, which should capture visitors from head to toe. The lock has a removable 15,000mAh battery (rated for six months) and a smaller 800mAh backup battery to keep things running while the main one is charging.The Smart Lock E40 supports Matter, Apple Home, Amazon Alexa, Google Home Assistant and Samsung SmartThings. It's expected to launch in Q1 at Home Depot (online and in stores) for $300.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/ankers-ces-smart-home-lineup-includes-a-1600-eufy-robovac-160000133.html?src=rss",
          "content": "It seems like only a few years ago that Anker made nothing more than batteries and chargers. But 15 years into its history, the company's CES portfolio continues to illustrate how much it's expanded. Among other announcements, the company has a new robot vacuum, video doorbell, outdoor light and smart lock. They're all rolling out under Anker's Eufy smart home brand.The company hopes its Eufy Clean Robot Vacuum Omni S2 will be your next robovac. The $1,600 device vacuums with 100 AW suction, and it mops, too. Anker claims the vac works on shag carpets up to about 2 inches (5 cm) in pile height. It has an 11.4-inch rolling mop that applies up to 15 N of downward pressure.As is increasingly common in robovacs, Omni S2 uses AI to identify floor types and adjust several factors on the fly. These include cleaning mode, suction, scrubbing force and wheel height. The machine can also generate lightly oxidizing disinfectants (a hypochlorous acid and ozone water solution) inside its tank.Presales for the Eufy Clean Robot Vacuum Omni S2 begin on January 6. Shipping and in-store availability for the $1,600 robovac kicks off on January 20.Eufy Video Doorbell S4AnkerAnker also has a new doorbell, the Eufy Video Doorbell S4. It includes an AI-powered people detection feature with auto-framing. The doorbell has 3,024 x 3,024 resolution at 24 FPS and offers a panoramic (180 x 180-degree) view.You can use the doorbell in either wired or wireless mode, and it supports solar charging. The Video Doorbell S4 is scheduled to launch \"later in Q1\" for $280.Eufy Solar Wall Light Cam S4AnkerAlong similar lines, there's the Solar Wall Light Cam S4. The outdoor light has a built-in 4K camera with an f/1.6 aperture. The light has a color temperature ranging from warm white (2700K) to cool white (6500K).As its name suggests, it supports solar charging. It’s bundled with a detachable 2W solar panel. It also has a 10,000mAh battery that's rated for up to two months. Anker says the Solar Wall Light Cam S4 will arrive in Q1 for $200.Eufy Smart Lock E40AnkerFinally, Anker has a new lock / camera combo: the Eufy Smart Lock E40. It has \"advanced 3D face recognition\" that can identify you and your family from up to 10 feet away, unlocking accordingly. Its camera has 2K resolution and a 135-degree field of view, which should capture visitors from head to toe. The lock has a removable 15,000mAh battery (rated for six months) and a smaller 800mAh backup battery to keep things running while the main one is charging.The Smart Lock E40 supports Matter, Apple Home, Amazon Alexa, Google Home Assistant and Samsung SmartThings. It's expected to launch in Q1 at Home Depot (online and in stores) for $300.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/ankers-ces-smart-home-lineup-includes-a-1600-eufy-robovac-160000133.html?src=rss",
          "feed_position": 39,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/anker_2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/how-to-watch-todays-bosch-ces-2026-press-conference-live-130020554.html",
          "published_at": "Mon, 05 Jan 2026 15:31:25 +0000",
          "title": "How to watch today's Bosch CES 2026 press conference live",
          "standfirst": "You might think of Bosch as the modern European equivalent to what the GE brand once was in America. It's a home appliance name (thanks to its partnership with Siemens), but the German multinational brand's core business is really about providing the underlying technology and engineering that powers cars, homes and factories around the world. That focus is reflected at CES 2026, where much of what Bosch is unveiling is intended to be licensed to other companies rather than sold as Bosch-branded products on store shelves. Case in point is Bosch's automotive plans at CES. The company is showcasing what it calls \"AI in the car,\" or more specifically, in the cockpit of the car. \"Bosch's AI-powered cockpit makes driving more comfortable, intuitive, and safer for all occupants,\" Bosch board member Markus Heyn said in a press release. We'll get into all the details below, as well as how to tune in to the press conference on Monday. How to watch Bosch's CES 2026 presentation You can livestream the event on Monday, January 5 at 12PM ET via the Bosch press page or YouTube. (We've embedded the stream link below.) We'll also be highlighting any relevant info from Bosch's presentation in the main Engadget CES 2026 liveblog. What to expect Bosch will be setting up shop in the Central Hall of the Las Vegas Convention Center (booth 16203), where the company will be focusing on its three big themes — mobility, smart home integrations and manufacturing — all of which will include hardware, software and AI solutions. Like many other CES 2026 exhibitors, look for Bosch to emphasize its partnerships with the big dogs of the AI space at the show. For instance, that AI-powered car cockpit mentioned above will feature integrations with both Microsoft and NVIDIA. Bosch is touting the ability to use voice commands to join a Teams call, while the car's system will automatically activate adaptive cruise control. And it's noting that NVIDIA's software suites will help manage \"real-time sensor processing and vision-language models.\" Here's a glimpse of what the booth will look like: This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-watch-todays-bosch-ces-2026-press-conference-live-130020554.html?src=rss",
          "content": "You might think of Bosch as the modern European equivalent to what the GE brand once was in America. It's a home appliance name (thanks to its partnership with Siemens), but the German multinational brand's core business is really about providing the underlying technology and engineering that powers cars, homes and factories around the world. That focus is reflected at CES 2026, where much of what Bosch is unveiling is intended to be licensed to other companies rather than sold as Bosch-branded products on store shelves. Case in point is Bosch's automotive plans at CES. The company is showcasing what it calls \"AI in the car,\" or more specifically, in the cockpit of the car. \"Bosch's AI-powered cockpit makes driving more comfortable, intuitive, and safer for all occupants,\" Bosch board member Markus Heyn said in a press release. We'll get into all the details below, as well as how to tune in to the press conference on Monday. How to watch Bosch's CES 2026 presentation You can livestream the event on Monday, January 5 at 12PM ET via the Bosch press page or YouTube. (We've embedded the stream link below.) We'll also be highlighting any relevant info from Bosch's presentation in the main Engadget CES 2026 liveblog. What to expect Bosch will be setting up shop in the Central Hall of the Las Vegas Convention Center (booth 16203), where the company will be focusing on its three big themes — mobility, smart home integrations and manufacturing — all of which will include hardware, software and AI solutions. Like many other CES 2026 exhibitors, look for Bosch to emphasize its partnerships with the big dogs of the AI space at the show. For instance, that AI-powered car cockpit mentioned above will feature integrations with both Microsoft and NVIDIA. Bosch is touting the ability to use voice commands to join a Teams call, while the car's system will automatically activate adaptive cruise control. And it's noting that NVIDIA's software suites will help manage \"real-time sensor processing and vision-language models.\" Here's a glimpse of what the booth will look like: This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-watch-todays-bosch-ces-2026-press-conference-live-130020554.html?src=rss",
          "feed_position": 43
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/samsung-unveiled-ai-powered-products-at-ces-2026-everything-announced-from-the-years-first-press-conference-230059247.html",
          "published_at": "Mon, 05 Jan 2026 15:27:02 +0000",
          "title": "Samsung unveiled AI-powered products at CES 2026: Everything announced from the year's first press conference",
          "standfirst": "CES 2026 kicked off with a big press conference from one of the biggest companies at the show: Samsung. The tech giant held its \"first look\" presentation to show off new home products and make a plethora of AI-infused announcements. New TVs, speakers, projectors and more were among the headliners, along with updated gaming monitors and soundbars. Many of the products announced on stage were not actually new, but instead had been dripped out by Samsung recently. Like its minimalist Music Studio speakers or new Micro RGB TVs. We did get a closer look a previously undisclosed set, a flagship 130-inch Micro RGB TV framed by a giant metal easel with embedded speakers. It's one of the most striking sets we've ever seen, but it's much more in the realm of concept than reality. (That's not to say they won't sell it, just that we've heard no plans and if they do it will be hideously expensive.) Samsung's flagship Micro RGB TV.Devindra Hardawar for Engadget As for the rest of Samsung's Micro RGB TV line, that may actually be slightly more affordable. The company released its first set last year for an eye-watering $30,000, but that was a 115-inch proof of concept. This year it'll be offering TVs in more reasonable sizes, including the ever-popular 55-, 65- and 75-inch sets. We don't know pricing on those but those smaller models will definitely be cheaper than $30,000. For those that want something bigger, there'll also be 85-, 100- and 115-inch models. As before, the Micro RGB range will offer a purported 100% coverage of the Rec.2020 color space, which is something that even the highest-end OLEDs can't match. While they may have been announced prior to CES, we did get a few minutes in person with Samsung's Music Studio speakers in the demo area after the big show. The Music Studio 5 and 7 are wireles speakers supporting both Bluetooth and Wi-Fi. The Studio 5 has a four-inch woofer and dual tweeters, while the Studio 7 has a 3.1.1 setup with top-, front-, left- and right-firing speakers to give an \"immersive 3D audio experience.\" For all of that, it's clear the main draw of these new speakers is the design, which is definitely striking. Another thing from those heady pre-CES days was the Freestyle+, the latest attempt at a micro projector from Samsung. Like previous Freestyle models, it's small and unobtrusive, but this one is a little brighter and has \"smarter AI capabilities.\" “The Freestyle+ reflects Samsung’s vision to create displays that adapt naturally to how people live and move between spaces,” said Hun Lee, Executive Vice President of the Visual Display Business at Samsung Electronics. “By combining true portability with intelligent AI that optimizes both the viewing environment and the content itself, The Freestyle+ makes it easier to enjoy a consistent, high-quality experience wherever you are.” Samsung's Music Studio 5 speakers at CES 2026.Billy Steele for Engadget There were even products that Samsung didn't mention on stage that we then found in the demo area. Like the Samsung HW-QS90H soundbar, a new skew on its popular HW-QS90 line that targets those of us that would rather not have a subwoofer sitting in our living rooms. It's an all-in-one 7.1.2 soundbar with 13 drivers, including four (we're assuming) woofers for its \"Quad Bass Woofer system.\" Or the And that was really that for the big announcements. The rest of the stage show was focused on how Samsung thinks (or really, at this point, insists) AI is going to make all of its products more useful. Demos included using AI noise cancelling to turn off the commentators in a soccer match, using AI to watch recipes on your fridge door, using AI to wash your clothes better (?) and... to cut a long story short, Samsung would very much appreciate it if you could please use AI. We're expecting to see and hear more from Samsung during CES, but for now you can find all of our news stories and more detailed hands-on impressions below, or if you want to relieve the event in extruciating detail there's the livestream replay too. (Don't worry, though the video is three hours long the event itself was a tight hour.) Samsung hands-on impressions at CES 2026: Samsung brought an absolute beast of a 130-inch Micro RGB TV to CES 2026 Samsung Music Studio 5 and 7 hands-on: Unique speaker designs debut at CES 2026 Samsung HW-QS90H soundbar hands-on: Impressive bass performance without a subwoofer Samsung’s Freestyle+ projector hands-on: Much brighter and impressively adaptable Samsung's biggest announcements at CES 2026 so far: Samsung will show off its expanded Micro RGB TV series at CES Samsung's latest Odyssey gaming monitor has a 32-inch 6K screen with glasses-free 3D Samsung's two new speakers will deliver crisp audio while blending into your decor Samsung's latest Freestyle portable projector is brighter and smarter This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/samsung-unveiled-ai-powered-products-at-ces-2026-everything-announced-from-the-years-first-press-conference-230059247.html?src=rss",
          "content": "CES 2026 kicked off with a big press conference from one of the biggest companies at the show: Samsung. The tech giant held its \"first look\" presentation to show off new home products and make a plethora of AI-infused announcements. New TVs, speakers, projectors and more were among the headliners, along with updated gaming monitors and soundbars. Many of the products announced on stage were not actually new, but instead had been dripped out by Samsung recently. Like its minimalist Music Studio speakers or new Micro RGB TVs. We did get a closer look a previously undisclosed set, a flagship 130-inch Micro RGB TV framed by a giant metal easel with embedded speakers. It's one of the most striking sets we've ever seen, but it's much more in the realm of concept than reality. (That's not to say they won't sell it, just that we've heard no plans and if they do it will be hideously expensive.) Samsung's flagship Micro RGB TV.Devindra Hardawar for Engadget As for the rest of Samsung's Micro RGB TV line, that may actually be slightly more affordable. The company released its first set last year for an eye-watering $30,000, but that was a 115-inch proof of concept. This year it'll be offering TVs in more reasonable sizes, including the ever-popular 55-, 65- and 75-inch sets. We don't know pricing on those but those smaller models will definitely be cheaper than $30,000. For those that want something bigger, there'll also be 85-, 100- and 115-inch models. As before, the Micro RGB range will offer a purported 100% coverage of the Rec.2020 color space, which is something that even the highest-end OLEDs can't match. While they may have been announced prior to CES, we did get a few minutes in person with Samsung's Music Studio speakers in the demo area after the big show. The Music Studio 5 and 7 are wireles speakers supporting both Bluetooth and Wi-Fi. The Studio 5 has a four-inch woofer and dual tweeters, while the Studio 7 has a 3.1.1 setup with top-, front-, left- and right-firing speakers to give an \"immersive 3D audio experience.\" For all of that, it's clear the main draw of these new speakers is the design, which is definitely striking. Another thing from those heady pre-CES days was the Freestyle+, the latest attempt at a micro projector from Samsung. Like previous Freestyle models, it's small and unobtrusive, but this one is a little brighter and has \"smarter AI capabilities.\" “The Freestyle+ reflects Samsung’s vision to create displays that adapt naturally to how people live and move between spaces,” said Hun Lee, Executive Vice President of the Visual Display Business at Samsung Electronics. “By combining true portability with intelligent AI that optimizes both the viewing environment and the content itself, The Freestyle+ makes it easier to enjoy a consistent, high-quality experience wherever you are.” Samsung's Music Studio 5 speakers at CES 2026.Billy Steele for Engadget There were even products that Samsung didn't mention on stage that we then found in the demo area. Like the Samsung HW-QS90H soundbar, a new skew on its popular HW-QS90 line that targets those of us that would rather not have a subwoofer sitting in our living rooms. It's an all-in-one 7.1.2 soundbar with 13 drivers, including four (we're assuming) woofers for its \"Quad Bass Woofer system.\" Or the And that was really that for the big announcements. The rest of the stage show was focused on how Samsung thinks (or really, at this point, insists) AI is going to make all of its products more useful. Demos included using AI noise cancelling to turn off the commentators in a soccer match, using AI to watch recipes on your fridge door, using AI to wash your clothes better (?) and... to cut a long story short, Samsung would very much appreciate it if you could please use AI. We're expecting to see and hear more from Samsung during CES, but for now you can find all of our news stories and more detailed hands-on impressions below, or if you want to relieve the event in extruciating detail there's the livestream replay too. (Don't worry, though the video is three hours long the event itself was a tight hour.) Samsung hands-on impressions at CES 2026: Samsung brought an absolute beast of a 130-inch Micro RGB TV to CES 2026 Samsung Music Studio 5 and 7 hands-on: Unique speaker designs debut at CES 2026 Samsung HW-QS90H soundbar hands-on: Impressive bass performance without a subwoofer Samsung’s Freestyle+ projector hands-on: Much brighter and impressively adaptable Samsung's biggest announcements at CES 2026 so far: Samsung will show off its expanded Micro RGB TV series at CES Samsung's latest Odyssey gaming monitor has a 32-inch 6K screen with glasses-free 3D Samsung's two new speakers will deliver crisp audio while blending into your decor Samsung's latest Freestyle portable projector is brighter and smarter This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/samsung-unveiled-ai-powered-products-at-ces-2026-everything-announced-from-the-years-first-press-conference-230059247.html?src=rss",
          "feed_position": 44,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/a087c5f0-e9f4-11f0-87f1-6f39e4849c7d"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/amazon-is-rolling-out-alexa-for-the-web-so-you-can-use-its-assistant-without-a-dedicated-device-150053826.html",
          "published_at": "Mon, 05 Jan 2026 15:00:53 +0000",
          "title": "Amazon is rolling out Alexa+ for the web so you can use its assistant without a dedicated device",
          "standfirst": "You no longer need an Amazon device to summon Alexa since the AI assistant will be available on the Alexa.com website. Amazon will roll out the web client to its Alexa+ Early Access customers first, still featuring the company's new and improved AI assistant that was announced in February. The web model won't be much different from the existing Alexa+ that's already available on Echo devices, Fire TV and Fire tablets. However, instead of buying into the Amazon ecosystem, Early Access customers can use any web browser to get Alexa+'s help with everything from basic questions to complex tasks, like controlling your smart home devices, customizing a recipe to account for dietary restrictions or making restaurant reservations if you don't feel like cooking. The Alexa+ web version will also feature a navigation sidebar that will be home to your most-used Alexa features. Amazon recently revamped its Alexa mobile app, while also integrating Alexa+ with Ring doorbells and BMW cars. However, introducing its AI assistant to web browsers could indicate that Amazon wants to encroach on a competitive market, which is currently dominated by OpenAI's ChatGPT and Google Gemini. To see how Amazon's Alexa+ on web compares to the rest, you need to set up the Alexa+ Early Access first. After that, you can log into your Amazon account on Alexa.com to get started.This article originally appeared on Engadget at https://www.engadget.com/ai/amazon-is-rolling-out-alexa-for-the-web-so-you-can-use-its-assistant-without-a-dedicated-device-150053826.html?src=rss",
          "content": "You no longer need an Amazon device to summon Alexa since the AI assistant will be available on the Alexa.com website. Amazon will roll out the web client to its Alexa+ Early Access customers first, still featuring the company's new and improved AI assistant that was announced in February. The web model won't be much different from the existing Alexa+ that's already available on Echo devices, Fire TV and Fire tablets. However, instead of buying into the Amazon ecosystem, Early Access customers can use any web browser to get Alexa+'s help with everything from basic questions to complex tasks, like controlling your smart home devices, customizing a recipe to account for dietary restrictions or making restaurant reservations if you don't feel like cooking. The Alexa+ web version will also feature a navigation sidebar that will be home to your most-used Alexa features. Amazon recently revamped its Alexa mobile app, while also integrating Alexa+ with Ring doorbells and BMW cars. However, introducing its AI assistant to web browsers could indicate that Amazon wants to encroach on a competitive market, which is currently dominated by OpenAI's ChatGPT and Google Gemini. To see how Amazon's Alexa+ on web compares to the rest, you need to set up the Alexa+ Early Access first. After that, you can log into your Amazon account on Alexa.com to get started.This article originally appeared on Engadget at https://www.engadget.com/ai/amazon-is-rolling-out-alexa-for-the-web-so-you-can-use-its-assistant-without-a-dedicated-device-150053826.html?src=rss",
          "feed_position": 45
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/ember-artline-is-amazons-answer-to-samsungs-the-frame-150015104.html",
          "published_at": "Mon, 05 Jan 2026 15:00:15 +0000",
          "title": "Ember Artline is Amazon's answer to Samsung's The Frame",
          "standfirst": "Amazon just revealed the Ember Artline TV at CES 2026. This is a lifestyle TV that displays art, putting it in direct competition with Samsung's The Frame. The 4K QLED screen is extremely thin, at 1.5-inches, so it'll likely fit just about anywhere. It also features a glare-reducing matte screen that has been \"designed to make your art and photos look great.\" The Artline integrates with Amazon Photos and offers access to 2,000 pieces of free art to display. For those worried about electricity usage, the TV includes proprietary technology that senses when someone has entered or left the room and turns on or off accordingly. The display comes with Amazon's new smart assistant Alexa+, allowing it to double as a smart TV. This is helped along by the inclusion of far-field microphones. Alexa+ is a beefier version of the company's long-standing digital assistant. You can talk to it like a person, if that's your bag. There's even a new use case in which Alexa+ analyzes the aesthetics of a room and recommends art to throw on the screen. Amazon This is also a standard TV. It features support for Dolby Vision, HDR10+ and Wi-Fi 6 and will operate on the Fire TV platform. Customers can choose from 10 magnetic frames in a wide variety of colorways, further diversifying the aesthetics. We don't have a release date yet, other than \"later this spring.\" Amazon has released pricing, however, as this TV starts at $899 for the 55-inch version.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/ember-artline-is-amazons-answer-to-samsungs-the-frame-150015104.html?src=rss",
          "content": "Amazon just revealed the Ember Artline TV at CES 2026. This is a lifestyle TV that displays art, putting it in direct competition with Samsung's The Frame. The 4K QLED screen is extremely thin, at 1.5-inches, so it'll likely fit just about anywhere. It also features a glare-reducing matte screen that has been \"designed to make your art and photos look great.\" The Artline integrates with Amazon Photos and offers access to 2,000 pieces of free art to display. For those worried about electricity usage, the TV includes proprietary technology that senses when someone has entered or left the room and turns on or off accordingly. The display comes with Amazon's new smart assistant Alexa+, allowing it to double as a smart TV. This is helped along by the inclusion of far-field microphones. Alexa+ is a beefier version of the company's long-standing digital assistant. You can talk to it like a person, if that's your bag. There's even a new use case in which Alexa+ analyzes the aesthetics of a room and recommends art to throw on the screen. Amazon This is also a standard TV. It features support for Dolby Vision, HDR10+ and Wi-Fi 6 and will operate on the Fire TV platform. Customers can choose from 10 magnetic frames in a wide variety of colorways, further diversifying the aesthetics. We don't have a release date yet, other than \"later this spring.\" Amazon has released pricing, however, as this TV starts at $899 for the 55-inch version.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/ember-artline-is-amazons-answer-to-samsungs-the-frame-150015104.html?src=rss",
          "feed_position": 47,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/877150a0-e683-11f0-82fe-0fd2cae385ac"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/amazon-is-redesigning-its-fire-tv-ui-for-streaming-sticks-and-tvs-150000622.html",
          "published_at": "Mon, 05 Jan 2026 15:00:00 +0000",
          "title": "Amazon is redesigning its Fire TV UI for streaming sticks and TVs",
          "standfirst": "Amazon is kicking off the new year by announcing a redesign of its Fire TV UI at CES 2026. The new UI is designed to make finding things to watch on the platform faster, while making it easier to access more of Fire TV's features straight from the home screen.On first blush, the biggest difference in the new Fire TV UI is that everything is rounder. Shows, movies and apps have rounded corners, and Amazon's changed the spacing in the interface to give everything more room to breathe. Tweaks to typography and color gradients also give the UI a more modern feel, and Amazon says it's rebuilt the code of the Fire TV software to make everything faster, too, in some cases demonstrating \"up to 20-30 percent gains in speed.\"The fundamentals haven't changed all that much, however. There's a menu bar of different tabs at the top of the interface that separates the Home page from things like Movies, TV Shows and Sports. Each page shows content in carousels, and Amazon still lets you pin streaming apps like Netflix or Apple TV underneath recommended content, with the biggest difference being you can now pin more apps at once (20 rather than six). Amazon is also changing up how the Fire TV Remote works. Pressing the Menu button now lets you quickly access Fire TV's Art & Photos, Games and Ambient Experience features, and a long press of the Home button pulls up a shortcut panel with access to things like settings and connected Ring cameras. Alexa+, Amazon's rebuilt AI assistant, is also available directly inside of the Fire TV interface for adding things to your watchlist, recommending content and controlling your smart home.The new Fire TV mobile app can act as a remote and a way to search Amazon's library of content.AmazonAmazon offers the Fire TV mobile app as a way to control its streaming devices and TVs with a smartphone, but alongside this redesign, the company is also expanding what the app can do. The new Fire TV app lets you browse content, edit your watchlist and start playing things on your TV, in much the same way Roku and Google's streaming apps do.Both the new Fire TV mobile app and redesigned Fire TV UI will be available for free for all users, Amazon says. The new Fire TV UI will launch in February on the Fire TV Stick 4K Plus, the second-generation Fire TV Stick 4K Max and Fire TV Omni Mini-LED series. Later in the spring, Amazon says it will bring the redesign to more countries and devices, including the latest Fire TV 4K streaming devices, TVs like the Fire TV 2-series, 4-series and Fire TV Omni QLED series and TVs from third-party partners like Hisense, Insignia, Panasonic and TCL.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/amazon-is-redesigning-its-fire-tv-ui-for-streaming-sticks-and-tvs-150000622.html?src=rss",
          "content": "Amazon is kicking off the new year by announcing a redesign of its Fire TV UI at CES 2026. The new UI is designed to make finding things to watch on the platform faster, while making it easier to access more of Fire TV's features straight from the home screen.On first blush, the biggest difference in the new Fire TV UI is that everything is rounder. Shows, movies and apps have rounded corners, and Amazon's changed the spacing in the interface to give everything more room to breathe. Tweaks to typography and color gradients also give the UI a more modern feel, and Amazon says it's rebuilt the code of the Fire TV software to make everything faster, too, in some cases demonstrating \"up to 20-30 percent gains in speed.\"The fundamentals haven't changed all that much, however. There's a menu bar of different tabs at the top of the interface that separates the Home page from things like Movies, TV Shows and Sports. Each page shows content in carousels, and Amazon still lets you pin streaming apps like Netflix or Apple TV underneath recommended content, with the biggest difference being you can now pin more apps at once (20 rather than six). Amazon is also changing up how the Fire TV Remote works. Pressing the Menu button now lets you quickly access Fire TV's Art & Photos, Games and Ambient Experience features, and a long press of the Home button pulls up a shortcut panel with access to things like settings and connected Ring cameras. Alexa+, Amazon's rebuilt AI assistant, is also available directly inside of the Fire TV interface for adding things to your watchlist, recommending content and controlling your smart home.The new Fire TV mobile app can act as a remote and a way to search Amazon's library of content.AmazonAmazon offers the Fire TV mobile app as a way to control its streaming devices and TVs with a smartphone, but alongside this redesign, the company is also expanding what the app can do. The new Fire TV app lets you browse content, edit your watchlist and start playing things on your TV, in much the same way Roku and Google's streaming apps do.Both the new Fire TV mobile app and redesigned Fire TV UI will be available for free for all users, Amazon says. The new Fire TV UI will launch in February on the Fire TV Stick 4K Plus, the second-generation Fire TV Stick 4K Max and Fire TV Omni Mini-LED series. Later in the spring, Amazon says it will bring the redesign to more countries and devices, including the latest Fire TV 4K streaming devices, TVs like the Fire TV 2-series, 4-series and Fire TV Omni QLED series and TVs from third-party partners like Hisense, Insignia, Panasonic and TCL.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/amazon-is-redesigning-its-fire-tv-ui-for-streaming-sticks-and-tvs-150000622.html?src=rss",
          "feed_position": 48,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Fire-TV-mobile-app.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/brex-bets-on-less-orchestration-as-it-builds-an-agent-mesh-for-autonomous",
          "published_at": "Mon, 05 Jan 2026 08:00:00 GMT",
          "title": "Brex bets on ‘less orchestration’ as it builds an Agent Mesh for autonomous finance",
          "standfirst": "Fintech Brex is betting that the future of enterprise AI isn’t better orchestration — it’s less of it.As generative AI agents move from copilots to autonomous systems, Brex CTO James Reggio says traditional agent orchestration frameworks are becoming a constraint rather than an enabler. Instead of relying on a central coordinator or rigid workflows, Brex has built what it calls an “Agent Mesh”: a network of narrow, role-specific agents that communicate in plain language and operate independently — but with full visibility.“Our goal is to use AI to make Brex effectively disappear,” Reggio told VentureBeat. “We’re aiming for total automation.”Brex learned that for its purposes, agents need to work in narrow, specific roles to be more modular, flexible, and auditable. Reggio said the architectural goal is to enable every manager in an enterprise “to have a single point of contact within Brex that’s handling the totality of their responsibilities, be it spend management, requesting travel, or approving spend limit requests.”The journey from Brex AssistantThe financial services industry has long embraced AI and machine learning to handle the massive amounts of data it processes. But when it comes to bringing AI models and agents, the industry took a more cautious road at the beginning. Now, more financial services companies, including Brex, have launched AI-powered platforms and several agentic workflows. Brex’s first foray into generative AI was with its Brex Assistant, released in 2023, which helped customers automate certain finance and expense tasks. It provides suggestions to complete expenses, automatically fills in information, and follows up on expenses that violate policies. Reggio acknowledges that Brex Assistant works, but it’s not enough. “I think to some degree, it remains a bit of a technology where we don&#x27;t entirely know the limits of it,\" he said. \"There&#x27;s quite a large number of patterns that need to exist around it that are kind of being developed by the industry as the technology matures and as more companies build with it.\" Brex Assistant uses multiple models, including Anthropic’s Claude and custom Brex-models, as well as OpenAI’s API. The assistant automates some tasks but is still limited in how low-touch it can be. Reggio said Brex Assistant still plays a big role in the company’s autonomy journey, mainly because its Agent Mesh product flows into the application. Agent Mesh to replace orchestrationThe consensus in the industry is that multi-agent ecosystems, in which agents communicate to accomplish tasks, require an orchestration framework to guide them. Reggio, on the other hand, has a different take. \"Deterministic orchestration infrastructure … was a solution for the problems that we saw two years ago, which was that agents, just like the models, hallucinate a lot,” Reggio said. “They&#x27;re not very good with multiple tools, so you need to give them these degrees of freedom, but in a more structured, rigid system. But as the models get better, I think it&#x27;s starting to hold back the range of possibilities that are expanding.”More traditional agent orchestration architectures either focus on a single agent that does everything or, more commonly, coordinator/orchestrator plus tool agents that explicitly define workflows. Reggio said both frameworks are too rigid and solve issues more commonly seen in traditional software than in AI. The difference, Reggio argues, is structural:Traditional orchestration: predefined workflows, central coordinator, deterministic pathsAgent Mesh: event-driven, role-specialized agents, message-based coordinationAgent Mesh relies on stitching together networks of many small agents, each specializing in a single task. The agents, once again using the hybrid mix of models as with the Brex Assistant, communicate with other agents “in plain English” over a shared message stream. A routing model quickly determines which tools to invoke, he said. A single reimbursement request triggers several tasks: a compliance check to align with expense policies, budget validation, receipt matching, and then payment initiation. While an agent can certainly be coded to do all of that, this method is “brittle and error-prone,” and it responds to new information shared through a message stream anyway. Reggio said the idea is to disambiguate all of those separate tasks and assign them to smaller agents instead. He likened the architecture to a Wi-Fi mesh, where no single node controls the system — reliability emerges from many small, overlapping contributors. “We basically found a really good fit with the idea of embodying specific roles as agents on top of the best platform to manage specific responsibilities, much like how you might delegate accounts payable to one team versus expense management to another team,” Reggio said. Brex defines three core ideas in the Agent Mesh architecture:Config, where definitions of the agent, model, tools and subscription liveMessageStream, a log of every message, tool call and state transition Clock, which ensures deterministic ordering Brex also built evaluations into the system, in which the LLM acts as a judge, and an audit agent reviews each agent’s decisions to ensure they adhere to accuracy and behavioral policies. Success so farBrex says it has seen substantial efficiency gains among its customers in its AI ecosystem. Brex did not provide third-party benchmarks or customer-specific data to validate those gains.But Reggio said enterprise customers using Brex Assistant and the company’s machine learning systems “are able to achieve 99% automation, especially for customers that really leaned into AI.”This is a marked improvement from the 60 to 70% Brex customers who were able to automate their expense processes before the launch of Brex Assistant. The company is still early in its autonomy journey, Reggio said. But if the Agent Mesh approach works, the most successful outcome may be invisible: employees no longer thinking about expenses at all.",
          "content": "Fintech Brex is betting that the future of enterprise AI isn’t better orchestration — it’s less of it.As generative AI agents move from copilots to autonomous systems, Brex CTO James Reggio says traditional agent orchestration frameworks are becoming a constraint rather than an enabler. Instead of relying on a central coordinator or rigid workflows, Brex has built what it calls an “Agent Mesh”: a network of narrow, role-specific agents that communicate in plain language and operate independently — but with full visibility.“Our goal is to use AI to make Brex effectively disappear,” Reggio told VentureBeat. “We’re aiming for total automation.”Brex learned that for its purposes, agents need to work in narrow, specific roles to be more modular, flexible, and auditable. Reggio said the architectural goal is to enable every manager in an enterprise “to have a single point of contact within Brex that’s handling the totality of their responsibilities, be it spend management, requesting travel, or approving spend limit requests.”The journey from Brex AssistantThe financial services industry has long embraced AI and machine learning to handle the massive amounts of data it processes. But when it comes to bringing AI models and agents, the industry took a more cautious road at the beginning. Now, more financial services companies, including Brex, have launched AI-powered platforms and several agentic workflows. Brex’s first foray into generative AI was with its Brex Assistant, released in 2023, which helped customers automate certain finance and expense tasks. It provides suggestions to complete expenses, automatically fills in information, and follows up on expenses that violate policies. Reggio acknowledges that Brex Assistant works, but it’s not enough. “I think to some degree, it remains a bit of a technology where we don&#x27;t entirely know the limits of it,\" he said. \"There&#x27;s quite a large number of patterns that need to exist around it that are kind of being developed by the industry as the technology matures and as more companies build with it.\" Brex Assistant uses multiple models, including Anthropic’s Claude and custom Brex-models, as well as OpenAI’s API. The assistant automates some tasks but is still limited in how low-touch it can be. Reggio said Brex Assistant still plays a big role in the company’s autonomy journey, mainly because its Agent Mesh product flows into the application. Agent Mesh to replace orchestrationThe consensus in the industry is that multi-agent ecosystems, in which agents communicate to accomplish tasks, require an orchestration framework to guide them. Reggio, on the other hand, has a different take. \"Deterministic orchestration infrastructure … was a solution for the problems that we saw two years ago, which was that agents, just like the models, hallucinate a lot,” Reggio said. “They&#x27;re not very good with multiple tools, so you need to give them these degrees of freedom, but in a more structured, rigid system. But as the models get better, I think it&#x27;s starting to hold back the range of possibilities that are expanding.”More traditional agent orchestration architectures either focus on a single agent that does everything or, more commonly, coordinator/orchestrator plus tool agents that explicitly define workflows. Reggio said both frameworks are too rigid and solve issues more commonly seen in traditional software than in AI. The difference, Reggio argues, is structural:Traditional orchestration: predefined workflows, central coordinator, deterministic pathsAgent Mesh: event-driven, role-specialized agents, message-based coordinationAgent Mesh relies on stitching together networks of many small agents, each specializing in a single task. The agents, once again using the hybrid mix of models as with the Brex Assistant, communicate with other agents “in plain English” over a shared message stream. A routing model quickly determines which tools to invoke, he said. A single reimbursement request triggers several tasks: a compliance check to align with expense policies, budget validation, receipt matching, and then payment initiation. While an agent can certainly be coded to do all of that, this method is “brittle and error-prone,” and it responds to new information shared through a message stream anyway. Reggio said the idea is to disambiguate all of those separate tasks and assign them to smaller agents instead. He likened the architecture to a Wi-Fi mesh, where no single node controls the system — reliability emerges from many small, overlapping contributors. “We basically found a really good fit with the idea of embodying specific roles as agents on top of the best platform to manage specific responsibilities, much like how you might delegate accounts payable to one team versus expense management to another team,” Reggio said. Brex defines three core ideas in the Agent Mesh architecture:Config, where definitions of the agent, model, tools and subscription liveMessageStream, a log of every message, tool call and state transition Clock, which ensures deterministic ordering Brex also built evaluations into the system, in which the LLM acts as a judge, and an audit agent reviews each agent’s decisions to ensure they adhere to accuracy and behavioral policies. Success so farBrex says it has seen substantial efficiency gains among its customers in its AI ecosystem. Brex did not provide third-party benchmarks or customer-specific data to validate those gains.But Reggio said enterprise customers using Brex Assistant and the company’s machine learning systems “are able to achieve 99% automation, especially for customers that really leaned into AI.”This is a marked improvement from the 60 to 70% Brex customers who were able to automate their expense processes before the launch of Brex Assistant. The company is still early in its autonomy journey, Reggio said. But if the Agent Mesh approach works, the most successful outcome may be invisible: employees no longer thinking about expenses at all.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2bn5jMREgSASEDf2vDQ6HQ/e5229bf4536b36825a2dbb7cb92fcf6e/crimedy7_illustration_of_a_robot_poring_through_expense_repor_a03892f6-f441-4dab-a57b-8e664b411198_1.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
          "published_at": "Mon, 05 Jan 2026 07:45:00 GMT",
          "title": "The creator of Claude Code just revealed his workflow, and developers are losing their minds",
          "standfirst": "When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.For the past week, the engineering community has been dissecting a thread on X from Boris Cherny, the creator and head of Claude Code at Anthropic. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.\"If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,\" wrote Jeff Tang, a prominent voice in the developer community. Kyle McNease, another industry observer, went further, declaring that with Cherny&#x27;s \"game-changing updates,\" Anthropic is \"on fire,\" potentially facing \"their ChatGPT moment.\"The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience \"feels more like Starcraft\" than traditional coding — a shift from typing syntax to commanding autonomous units.Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. How running five AI agents at once turns coding into a real-time strategy gameThe most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional \"inner loop\" of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.\"I run 5 Claudes in parallel in my terminal,\" Cherny wrote. \"I number my tabs 1-5, and use system notifications to know when a Claude needs input.\"By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs \"5-10 Claudes on claude.ai\" in his browser, using a \"teleport\" command to hand off sessions between the web and his local machine.This validates the \"do more with less\" strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.The counterintuitive case for choosing the slowest, smartest modelIn a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: Opus 4.5.\"I use Opus 4.5 with thinking for everything,\" Cherny explained. \"It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger & slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.\"For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the \"compute tax\" for a smarter model upfront eliminates the \"correction tax\" later.One shared file turns every AI mistake into a permanent lessonCherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not \"remember\" a company&#x27;s specific coding style or architectural decisions from one session to the next.To address this, Cherny&#x27;s team maintains a single file named CLAUDE.md in their git repository. \"Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,\" he wrote.This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. \"Every mistake becomes a rule,\" noted Aakash Gupta, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.Slash commands and subagents automate the most tedious parts of developmentThe \"vanilla\" workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&#x27;s repository — to handle complex operations with a single keystroke.He highlighted a command called /commit-push-pr, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.Why verification loops are the real unlock for AI-generated codeIf there is a single reason Claude Code has reportedly hit $1 billion in annual recurring revenue so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.\"Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,\" Cherny wrote. \"It opens a browser, tests the UI, and iterates until the code works and the UX feels good.\"He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by \"2-3x.\" The agent doesn&#x27;t just write code; it proves the code works.What Cherny&#x27;s workflow signals about the future of software engineeringThe reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, \"AI coding\" meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.\"Read this if you&#x27;re already an engineer... and want more power,\" Jeff Tang summarized on X.The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game — and everyone else will still be typing.",
          "content": "When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.For the past week, the engineering community has been dissecting a thread on X from Boris Cherny, the creator and head of Claude Code at Anthropic. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.\"If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,\" wrote Jeff Tang, a prominent voice in the developer community. Kyle McNease, another industry observer, went further, declaring that with Cherny&#x27;s \"game-changing updates,\" Anthropic is \"on fire,\" potentially facing \"their ChatGPT moment.\"The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience \"feels more like Starcraft\" than traditional coding — a shift from typing syntax to commanding autonomous units.Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. How running five AI agents at once turns coding into a real-time strategy gameThe most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional \"inner loop\" of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.\"I run 5 Claudes in parallel in my terminal,\" Cherny wrote. \"I number my tabs 1-5, and use system notifications to know when a Claude needs input.\"By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs \"5-10 Claudes on claude.ai\" in his browser, using a \"teleport\" command to hand off sessions between the web and his local machine.This validates the \"do more with less\" strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.The counterintuitive case for choosing the slowest, smartest modelIn a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: Opus 4.5.\"I use Opus 4.5 with thinking for everything,\" Cherny explained. \"It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger & slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.\"For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the \"compute tax\" for a smarter model upfront eliminates the \"correction tax\" later.One shared file turns every AI mistake into a permanent lessonCherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not \"remember\" a company&#x27;s specific coding style or architectural decisions from one session to the next.To address this, Cherny&#x27;s team maintains a single file named CLAUDE.md in their git repository. \"Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,\" he wrote.This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. \"Every mistake becomes a rule,\" noted Aakash Gupta, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.Slash commands and subagents automate the most tedious parts of developmentThe \"vanilla\" workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&#x27;s repository — to handle complex operations with a single keystroke.He highlighted a command called /commit-push-pr, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.Why verification loops are the real unlock for AI-generated codeIf there is a single reason Claude Code has reportedly hit $1 billion in annual recurring revenue so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.\"Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,\" Cherny wrote. \"It opens a browser, tests the UI, and iterates until the code works and the UX feels good.\"He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by \"2-3x.\" The agent doesn&#x27;t just write code; it proves the code works.What Cherny&#x27;s workflow signals about the future of software engineeringThe reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, \"AI coding\" meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.\"Read this if you&#x27;re already an engineer... and want more power,\" Jeff Tang summarized on X.The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game — and everyone else will still be typing.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6VsJWNsStTR57q9vFd5L08/a0d88b4dcbd1e9ba77fd72a9c55988d9/nuneybits_Vector_art_of_programmer_conducting_robot_orchestra_i_908157a9-d44f-4bce-b390-5913b88dad27.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/intelition-changes-everything-ai-is-no-longer-a-tool-you-invoke",
          "published_at": "Sun, 04 Jan 2026 19:00:00 GMT",
          "title": "'Intelition' changes everything: AI is no longer a tool you invoke",
          "standfirst": "AI is evolving faster than our vocabulary for describing it. We may need a few new words. We have “cognition” for how a single mind thinks, but we don&#x27;t have a word for what happens when human and machine intelligence work together to perceive, decide, create and act. Let’s call that process intelition. Intelition isn’t a feature; it’s the organizing principle for the next wave of software where humans and AI operate inside the same shared model of the enterprise. Today’s systems treat AI models as things you invoke from the outside. You act as a “user,” prompting for responses or wiring a “human in the loop” step into agentic workflows. But that&#x27;s evolving into continuous co-production: People and agents are shaping decisions, logic and actions together, in real time. Read on for a breakdown of the three forces driving this new paradigm. A unified ontology is just the beginningIn a recent shareholder letter, Palantir CEO Alex Karp wrote that “all the value in the market is going to go to chips and what we call ontology,” and argued that this shift is “only the beginning of something much larger and more significant.” By ontology, Karp means a shared model of objects (customers, policies, assets, events) and their relationships. This also includes what Palantir calls an ontology’s “kinetic layer” that defines the actions and security permissions connecting objects.In the SaaS era, every enterprise application creates its own object and process models. Combined with a host of legacy systems and often chaotic models, enterprises face the challenge of stitching all this together. It’s a big and difficult job, with redundancies, incomplete structures and missing data. The reality: No matter how many data warehouse or data lake projects commissioned, few enterprises come close to creating a consolidated enterprise ontology. A unified ontology is essential for today’s agentic AI tools. As organizations link and federate ontologies, a new software paradigm emerges: Agentic AI can reason and act across suppliers, regulators, customers and operations, not just within a single app. As Karp describes it, the aim is “to tether the power of artificial intelligence to objects and relationships in the real world.” World models and continuous learningToday’s models can hold extensive context, but holding information isn’t the same as learning from it. Continual learning requires the accumulation of understanding, rather than resets with each retraining. To his aim, Google recently announced “Nested Learning” as a potential solution, grounded direclty into existing LLM architecture and training data. The authors don’t claim to have solved the challenges of building world models. But, Nested Learning could supply the raw ingredients for them: Durable memory with continual learning layered into the system. The endpoint would make retraining obsolete. In June 2022, Meta&#x27;s chief AI scientist Yann LeCun created a blueprint for “autonomous machine intelligence” that featured a hierarchical approach to using joint embeddings to make predictions using world models. He called the technique H-JEPA, and later put bluntly: “LLMs are good at manipulating language, but not at thinking.”Over the past three years, LeCun and his colleagues at Meta have moved H-JEPA theory into practice with open source models V-JEPA and I-JEPA, which learn image and video representations of the world. The personal intelition interface The third force in this agentic, ontology-driven world is the personal interface. This puts people at the center rather than as “users” on the periphery. This is not another app; it is the primary way a person participates in the next era of work and life. Rather than treating AI as something we visit through a chat window or API cal, the personal intelition interface will be always-on, aware of our context, preferences and goals and capable of acting on our behalf across the entire federated economy. Let’s analyze how this is already coming together.In May, Jony Ive sold his AI device company io to OpenAI to accelerate a new AI device category. He noted at the time: “If you make something new, if you innovate, there will be consequences unforeseen, and some will be wonderful, and some will be harmful. While some of the less positive consequences were unintentional, I still feel responsibility. And the manifestation of that is a determination to try and be useful.” That is, getting the personal intelligence device right means more than an attractive venture opportunity. Apple is looking beyond LLMs for on-device solutions that require less processing power and result in less latency when creating AI apps to understand “user intent.” Last year, they created UI-JEPA, an innovation that moves to “on-device analysis” of what the user wants. This strikes directly at the business model of today’s digital economy, where centralized profiling of “users” transforms intent and behavior data into vast revenue streams.Tim Berners-Lee, the inventor of the World Wide Web, recently noted: “The user has been reduced to a consumable product for the advertiser ... there&#x27;s still time to build machines that work for humans, and not the other way around.\" Moving user intent to the device will drive interest in a secure personal data management standard, Solid, that Berners-Lee and his colleagues have been developing since 2022. The standard is ideally suited to pair with new personal AI devices. For instance, Inrupt, Inc., a company founded by Berners-Lee, recently combined Solid with Anthropic’s MCP standard for Agentic Wallets. Personal control is more than a feature of this paradigm; it is the architectural safeguard as systems gain the ability to learn and act continuously.Ultimately, these three forces are moving and converging faster than most realize. Enterprise ontologies provide the nouns and verbs, world-model research supplies durable memory and learning and the personal interface becomes the permissioned point of control. The next software era isn&#x27;t coming. It&#x27;s already here.Brian Mulconrey is SVP at Sureify Labs.",
          "content": "AI is evolving faster than our vocabulary for describing it. We may need a few new words. We have “cognition” for how a single mind thinks, but we don&#x27;t have a word for what happens when human and machine intelligence work together to perceive, decide, create and act. Let’s call that process intelition. Intelition isn’t a feature; it’s the organizing principle for the next wave of software where humans and AI operate inside the same shared model of the enterprise. Today’s systems treat AI models as things you invoke from the outside. You act as a “user,” prompting for responses or wiring a “human in the loop” step into agentic workflows. But that&#x27;s evolving into continuous co-production: People and agents are shaping decisions, logic and actions together, in real time. Read on for a breakdown of the three forces driving this new paradigm. A unified ontology is just the beginningIn a recent shareholder letter, Palantir CEO Alex Karp wrote that “all the value in the market is going to go to chips and what we call ontology,” and argued that this shift is “only the beginning of something much larger and more significant.” By ontology, Karp means a shared model of objects (customers, policies, assets, events) and their relationships. This also includes what Palantir calls an ontology’s “kinetic layer” that defines the actions and security permissions connecting objects.In the SaaS era, every enterprise application creates its own object and process models. Combined with a host of legacy systems and often chaotic models, enterprises face the challenge of stitching all this together. It’s a big and difficult job, with redundancies, incomplete structures and missing data. The reality: No matter how many data warehouse or data lake projects commissioned, few enterprises come close to creating a consolidated enterprise ontology. A unified ontology is essential for today’s agentic AI tools. As organizations link and federate ontologies, a new software paradigm emerges: Agentic AI can reason and act across suppliers, regulators, customers and operations, not just within a single app. As Karp describes it, the aim is “to tether the power of artificial intelligence to objects and relationships in the real world.” World models and continuous learningToday’s models can hold extensive context, but holding information isn’t the same as learning from it. Continual learning requires the accumulation of understanding, rather than resets with each retraining. To his aim, Google recently announced “Nested Learning” as a potential solution, grounded direclty into existing LLM architecture and training data. The authors don’t claim to have solved the challenges of building world models. But, Nested Learning could supply the raw ingredients for them: Durable memory with continual learning layered into the system. The endpoint would make retraining obsolete. In June 2022, Meta&#x27;s chief AI scientist Yann LeCun created a blueprint for “autonomous machine intelligence” that featured a hierarchical approach to using joint embeddings to make predictions using world models. He called the technique H-JEPA, and later put bluntly: “LLMs are good at manipulating language, but not at thinking.”Over the past three years, LeCun and his colleagues at Meta have moved H-JEPA theory into practice with open source models V-JEPA and I-JEPA, which learn image and video representations of the world. The personal intelition interface The third force in this agentic, ontology-driven world is the personal interface. This puts people at the center rather than as “users” on the periphery. This is not another app; it is the primary way a person participates in the next era of work and life. Rather than treating AI as something we visit through a chat window or API cal, the personal intelition interface will be always-on, aware of our context, preferences and goals and capable of acting on our behalf across the entire federated economy. Let’s analyze how this is already coming together.In May, Jony Ive sold his AI device company io to OpenAI to accelerate a new AI device category. He noted at the time: “If you make something new, if you innovate, there will be consequences unforeseen, and some will be wonderful, and some will be harmful. While some of the less positive consequences were unintentional, I still feel responsibility. And the manifestation of that is a determination to try and be useful.” That is, getting the personal intelligence device right means more than an attractive venture opportunity. Apple is looking beyond LLMs for on-device solutions that require less processing power and result in less latency when creating AI apps to understand “user intent.” Last year, they created UI-JEPA, an innovation that moves to “on-device analysis” of what the user wants. This strikes directly at the business model of today’s digital economy, where centralized profiling of “users” transforms intent and behavior data into vast revenue streams.Tim Berners-Lee, the inventor of the World Wide Web, recently noted: “The user has been reduced to a consumable product for the advertiser ... there&#x27;s still time to build machines that work for humans, and not the other way around.\" Moving user intent to the device will drive interest in a secure personal data management standard, Solid, that Berners-Lee and his colleagues have been developing since 2022. The standard is ideally suited to pair with new personal AI devices. For instance, Inrupt, Inc., a company founded by Berners-Lee, recently combined Solid with Anthropic’s MCP standard for Agentic Wallets. Personal control is more than a feature of this paradigm; it is the architectural safeguard as systems gain the ability to learn and act continuously.Ultimately, these three forces are moving and converging faster than most realize. Enterprise ontologies provide the nouns and verbs, world-model research supplies durable memory and learning and the personal interface becomes the permissioned point of control. The next software era isn&#x27;t coming. It&#x27;s already here.Brian Mulconrey is SVP at Sureify Labs.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7nS0fhhd8rb4GWzz2aXNYd/2f0ea05e1f3753e57a1ef4b14cc773d0/Thinking_together.png?w=300&q=30"
        }
      ],
      "featured_image": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/865fe6d0-e666-11f0-bf3e-78b0cfcd9889",
      "popularity_score": 2019.6846683333333
    },
    {
      "id": "cluster_6",
      "coverage": 2,
      "updated_at": "Mon, 05 Jan 2026 23:01:00 GMT",
      "title": "MSI's new thin and light laptops are one of the most pleasant surprises at CES",
      "neutral_headline": "MSI's new thin and light laptops are one of the most pleasant surprises at CES",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/msi-prestige-modern-laptops-ces/",
          "published_at": "Mon, 05 Jan 2026 23:01:00 GMT",
          "title": "MSI's new thin and light laptops are one of the most pleasant surprises at CES",
          "standfirst": "MSI's Prestige and Modern series laptops have standard OLED displays and Intel \"Panther Lake\" chips.",
          "content": "MSI's Prestige and Modern series laptops have standard OLED displays and Intel \"Panther Lake\" chips.",
          "feed_position": 1
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/851382/these-are-the-sleekest-msi-laptops-ive-ever-seen",
          "published_at": "2026-01-05T18:00:00-05:00",
          "title": "These are the sleekest MSI laptops I’ve ever seen",
          "standfirst": "MSI is announcing a revamped Prestige business laptop line for CES 2026 with thinner designs, OLED displays, 2-in-1 options, bigger trackpads, and Intel's new Panther Lake chips. The Prestige 14 AI Plus and Prestige 16 AI Plus are the flagship clamshells of the line, and there are also 2-in-1 versions on offer called the Prestige [&#8230;]",
          "content": "OLEDs make everything better. MSI is announcing a revamped Prestige business laptop line for CES 2026 with thinner designs, OLED displays, 2-in-1 options, bigger trackpads, and Intel's new Panther Lake chips. The Prestige 14 AI Plus and Prestige 16 AI Plus are the flagship clamshells of the line, and there are also 2-in-1 versions on offer called the Prestige Flip. Each of them, Flip or non-Flip, comes standard with a 1920 x 1200 OLED display, while the 16-inch models can also be configured with a higher-res 2880 x 1800 / 120Hz OLED. The Flip versions also include an MSI Nano Pen stylus that's stored in a charging slot on the laptop's underside. The tiny stylus has a ti … Read the full story at The Verge.",
          "feed_position": 5
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/851516/msi-stealth-16-laptop-gaming-looks-stealthy",
          "published_at": "2026-01-05T18:00:00-05:00",
          "title": "The new Stealth 16 laptop from MSI finally looks stealthy (well, a little)",
          "standfirst": "MSI is announcing a new Stealth 16 AI Plus gaming laptop for CES 2026. Borrowing a little from its business-class brethren, the new Stealth has a thinner and lighter design, features a larger trackpad, and comes standard with a 240Hz OLED display (though some global regions may start with IPS). It'll run $2,099 with an [&#8230;]",
          "content": "The MSI dragon logo has been slayed. And by that I mean it’s now small and tucked into the corner. MSI is announcing a new Stealth 16 AI Plus gaming laptop for CES 2026. Borrowing a little from its business-class brethren, the new Stealth has a thinner and lighter design, features a larger trackpad, and comes standard with a 240Hz OLED display (though some global regions may start with IPS). It'll run $2,099 with an Intel Panther Lake processor and Nvidia RTX 5060 GPU (configurations go up to an RTX 5090), and it's due out in March. The GPUs in the Stealth are throttled to 100W, as this laptop prioritizes a thin chassis to appeal to creators and everyday users instead of aiming purely for gaming performance. So it makes sense that the St … Read the full story at The Verge.",
          "feed_position": 6
        }
      ],
      "popularity_score": 2019.677723888889
    },
    {
      "id": "cluster_28",
      "coverage": 2,
      "updated_at": "Mon, 05 Jan 2026 21:55:55 +0000",
      "title": "Boston Dynamics&#8217; next-gen humanoid robot will have Google DeepMind DNA",
      "neutral_headline": "Boston Dynamics&#8217; next-gen humanoid robot will have Google DeepMind DNA",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/05/boston-dynamicss-next-gen-humanoid-robot-will-have-google-deepmind-dna/",
          "published_at": "Mon, 05 Jan 2026 21:55:55 +0000",
          "title": "Boston Dynamics&#8217; next-gen humanoid robot will have Google DeepMind DNA",
          "standfirst": "Google's AI research lab is working with Boston Dynamics to make Atlas act more like a human.",
          "content": "Google's AI research lab is working with Boston Dynamics to make Atlas act more like a human.",
          "feed_position": 4
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/google-boston-dynamics-gemini-powered-robot-atlas/",
          "published_at": "Mon, 05 Jan 2026 21:00:00 +0000",
          "title": "Google Gemini Is Taking Control of Humanoid Robots on Auto Factory Floors",
          "standfirst": "Google DeepMind and Boston Dynamics are teaming up to integrate Gemini into a humanoid robot called Atlas.",
          "content": "Google DeepMind and Boston Dynamics are teaming up to integrate Gemini into a humanoid robot called Atlas.",
          "feed_position": 1,
          "image_url": "https://media.wired.com/photos/695c067688c4535fb1546355/master/pass/Googles-AI-Taking-Control-of-Humanoids-On-Auto-Factory-Floor-Business-YT-Pre-Launch-Thumbnail.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/695c067688c4535fb1546355/master/pass/Googles-AI-Taking-Control-of-Humanoids-On-Auto-Factory-Floor-Business-YT-Pre-Launch-Thumbnail.jpg",
      "popularity_score": 2018.5930016666666
    },
    {
      "id": "cluster_43",
      "coverage": 2,
      "updated_at": "Mon, 05 Jan 2026 15:25:04 -0500",
      "title": "Lego unveils the Smart Play platform, with a brick powered by a custom chip that connects to compatible minifigures and tags for interactive lights and sounds (Jeremy White/Wired)",
      "neutral_headline": "Lego’s Smart Brick Gives the Iconic Analog Toy a New Digital Brain",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260105/p25#a260105p25",
          "published_at": "Mon, 05 Jan 2026 15:25:04 -0500",
          "title": "Lego unveils the Smart Play platform, with a brick powered by a custom chip that connects to compatible minifigures and tags for interactive lights and sounds (Jeremy White/Wired)",
          "standfirst": "Jeremy White / Wired: Lego unveils the Smart Play platform, with a brick powered by a custom chip that connects to compatible minifigures and tags for interactive lights and sounds &mdash; The new sensor-packed Smart Play Brick will land this spring as part of a special Star Wars collection.",
          "content": "Jeremy White / Wired: Lego unveils the Smart Play platform, with a brick powered by a custom chip that connects to compatible minifigures and tags for interactive lights and sounds &mdash; The new sensor-packed Smart Play Brick will land this spring as part of a special Star Wars collection.",
          "feed_position": 3,
          "image_url": "http://www.techmeme.com/260105/i25.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/lego-smart-brick-new-digital-brain/",
          "published_at": "Mon, 05 Jan 2026 19:00:00 +0000",
          "title": "Lego’s Smart Brick Gives the Iconic Analog Toy a New Digital Brain",
          "standfirst": "The new sensor-packed Smart Play Brick will land this spring as part of a special Star Wars collection. The update adds interactive lights and sound to the Lego experience—including the minifigs.",
          "content": "The new sensor-packed Smart Play Brick will land this spring as part of a special Star Wars collection. The update adds interactive lights and sound to the Lego experience—including the minifigs.",
          "feed_position": 3,
          "image_url": "https://media.wired.com/photos/695bc74f1e9a19f18d143eeb/master/pass/SMARTBrick_Hero_16x9.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260105/i25.jpg",
      "popularity_score": 2017.078835
    },
    {
      "id": "cluster_23",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 22:14:50 +0000",
      "title": "NASA’s science budget won’t be a train wreck after all",
      "neutral_headline": "NASA’s science budget won’t be a train wreck after all",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/nasas-science-budget-wont-be-a-train-wreck-after-all/",
          "published_at": "Mon, 05 Jan 2026 22:14:50 +0000",
          "title": "NASA’s science budget won’t be a train wreck after all",
          "standfirst": "\"There's very little to not like in this.\"",
          "content": "In June, the White House released a budget proposal for fiscal year 2026 that slashed funding for NASA's science programs by nearly 50 percent. Then, in July, the Trump administration began telling the leaders of dozens of space science missions to prepare \"closeout\" plans for their spacecraft. Things looked pretty grim for a while, but then Congress stepped in. Congress, of course, sets the federal government's budget. In many ways, Congress abdicated authority to the Trump administration last year. But not so, it turns out, with federal spending. Throughout the summer and fall, as the White House and Congress wrangled over various issues, lawmakers made it clear they intended to fund most of NASA's science portfolio. Preliminary efforts to shut down active missions were put on hold.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/05/50530415266_a67d907fac_b-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/05/50530415266_a67d907fac_b-1024x648.jpg",
      "popularity_score": 366.9082794444445
    },
    {
      "id": "cluster_30",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 21:42:14 +0000",
      "title": "The nation’s strictest privacy law just took effect, to data brokers’ chagrin",
      "neutral_headline": "The nation’s strictest privacy law just took effect, to data brokers’ chagrin",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/data-broker-hoarding-is-rampant-new-law-lets-consumers-fight-back/",
          "published_at": "Mon, 05 Jan 2026 21:42:14 +0000",
          "title": "The nation’s strictest privacy law just took effect, to data brokers’ chagrin",
          "standfirst": "Californians can now submit demands requiring 500 brokers to delete their data.",
          "content": "Californians are getting a new, supercharged way to stop data brokers from hoarding and selling their personal information, as a recently enacted law that’s among the strictest in the nation took effect at the beginning of the year. According to the California Privacy Protection Agency, more than 500 companies actively scour all sorts of sources for scraps of information about individuals, then package and store it to sell to marketers, private investigators, and others. The nonprofit Consumer Watchdog said in 2024 that brokers trawl automakers, tech companies, junk-food restaurants, device makers, and others for financial info, purchases, family situations, eating, exercising, travel, entertainment habits, and just about any other imaginable information belonging to millions of people.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/04/data-leak-1000x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/04/data-leak-1000x648.jpeg",
      "popularity_score": 346.3649461111111
    },
    {
      "id": "cluster_26",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 21:57:07 +0000",
      "title": "Under anti-vaccine RFK Jr., CDC slashes childhood vaccine schedule",
      "neutral_headline": "Under anti-vaccine RFK Jr., CDC slashes childhood vaccine schedule",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/under-anti-vaccine-rfk-jr-cdc-slashes-childhood-vaccine-schedule/",
          "published_at": "Mon, 05 Jan 2026 21:57:07 +0000",
          "title": "Under anti-vaccine RFK Jr., CDC slashes childhood vaccine schedule",
          "standfirst": "The changes are modeled after a small country with universal health care.",
          "content": "Under anti-vaccine Health Secretary Robert F. Kennedy Jr., federal health officials on Monday announced a sweeping and unprecedented overhaul of federal vaccine recommendations, abruptly paring down recommended immunizations for children from 17 to 11. Officials claimed the rationale for the change was to align US vaccine recommendations more closely with those of other high-income countries, namely Denmark, a small, far less diverse country of around 6 million people (smaller than the population of New York City) that has universal health care. The officials also claim the change is necessary to address the decline in public trust in vaccinations, which has been driven by anti-vaccine activists, including Kennedy. \"This decision protects children, respects families, and rebuilds trust in public health,\" Kennedy said in a statement.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2252087162-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2252087162-1152x648.jpg",
      "popularity_score": 341.61300166666666
    },
    {
      "id": "cluster_38",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 20:38:48 +0000",
      "title": "Anna’s Archive loses .org domain, says suspension likely unrelated to Spotify piracy",
      "neutral_headline": "Anna’s Archive loses .org domain, says suspension likely unrelated to Spotify piracy",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/annas-archive-loses-org-domain-says-suspension-likely-unrelated-to-spotify-piracy/",
          "published_at": "Mon, 05 Jan 2026 20:38:48 +0000",
          "title": "Anna’s Archive loses .org domain, says suspension likely unrelated to Spotify piracy",
          "standfirst": "\"We don't believe this has to do with our Spotify backup,\" Anna's Archive says.",
          "content": "The primary domain of Shadow library Anna's Archive was taken offline, with annas-archive.org being put under the serverHold status. While Anna's Archive recently made waves with a massive \"backup\" of Spotify, the shadow library's operator said the music pirating doesn't appear to be connected to the .org domain suspension. Anna's Archive remains available at several other domains. Anna's Archive launched in 2022 in response to the US Department of Justice seizure of domains used by e-book pirate site Z-Library. Acting as a shadow library and a search engine for other shadow libraries, Anna's Archive aims to archive books and other written materials and make them widely available via torrents. Its data sets have also been heavily used by AI companies to train large language models. In addition to mirroring shadow libraries such as Sci-Hub, Library Genesis, and Z-Library, Anna's Archive made a major move into music pirating two weeks ago with an announcement that it scraped Spotify and made a 300TB copy of the most streamed songs. Despite that development, the person behind Anna's Archive said the domain suspension doesn't seem to be related to the Spotify scraping.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/spotify-logos-1152x648-1767642275.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/spotify-logos-1152x648-1767642275.jpg",
      "popularity_score": 335.30772388888886
    },
    {
      "id": "cluster_42",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 20:28:06 +0000",
      "title": "Stewart Cheifet, PBS host who chronicled the PC revolution, dies at 87",
      "neutral_headline": "Stewart Cheifet, PBS host who chronicled the PC revolution, dies at 87",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/stewart-cheifet-pbs-host-who-chronicled-the-pc-revolution-dies-at-87/",
          "published_at": "Mon, 05 Jan 2026 20:28:06 +0000",
          "title": "Stewart Cheifet, PBS host who chronicled the PC revolution, dies at 87",
          "standfirst": "Cheifet produced more than 400 episodes of TV tracing the rise of personal computing.",
          "content": "Stewart Cheifet, the television producer and host who documented the personal computer revolution for nearly two decades on PBS, died on December 28, 2025, at age 87 in Philadelphia. Cheifet created and hosted Computer Chronicles, which ran on the public television network from 1983 to 2002 and helped demystify a new tech medium for millions of American viewers. Computer Chronicles covered everything from the earliest IBM PCs and Apple Macintosh models to the rise of the World Wide Web and the dot-com boom. Cheifet conducted interviews with computing industry figures, including Bill Gates, Steve Jobs, and Jeff Bezos, while demonstrating hardware and software for a general audience. From 1983 to 1990, he co-hosted the show with Gary Kildall, the Digital Research founder who created the popular CP/M operating system that predated MS-DOS on early personal computer systems.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/cheifet_obit-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/cheifet_obit-1152x648.jpg",
      "popularity_score": 316.1293905555556
    },
    {
      "id": "cluster_46",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 20:01:12 +0000",
      "title": "Amazon Alexa+ released to the general public via an early access website",
      "neutral_headline": "Amazon Alexa+ released to the general public via an early access website",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/amazon-alexa-released-to-the-general-public-via-an-early-access-website/",
          "published_at": "Mon, 05 Jan 2026 20:01:12 +0000",
          "title": "Amazon Alexa+ released to the general public via an early access website",
          "standfirst": "Amazon brings back browser-based Alexa but will eventually add a paywall.",
          "content": "Anyone can now try Alexa+, Amazon’s generative AI assistant, through a free early access program at Alexa.com. The website frees the AI, which Amazon released via early access in February, from hardware and makes it as easily accessible as more established chatbots, like OpenAI's ChatGPT and Google's Gemini. Until today, you needed a supporting device to access Alexa+. Amazon hasn’t said when the early access period will end, but when it does, Alexa+ will be included with Amazon Prime memberships, which start at $15 per month, or cost $20 per month on its own. The above pricing suggests that Amazon wants Alexa+ to drive people toward Prime subscriptions. By being interwoven with Amazon’s shopping ecosystem, including Amazon's e-commerce platform, grocery delivery business, and Whole Foods, Alexa+ can make more money for Amazon.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-1024x648.jpg",
      "popularity_score": 299.68105694444444
    },
    {
      "id": "cluster_49",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 19:32:28 +0000",
      "title": "SanDisk says goodbye to WD Blue and Black SSDs, hello to new “Optimus” drives",
      "neutral_headline": "SanDisk says goodbye to WD Blue and Black SSDs, hello to new “Optimus” drives",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/sandisk-says-goodbye-to-wd-blue-and-black-ssds-hello-to-new-optimus-drives/",
          "published_at": "Mon, 05 Jan 2026 19:32:28 +0000",
          "title": "SanDisk says goodbye to WD Blue and Black SSDs, hello to new “Optimus” drives",
          "standfirst": "Optimus SSDs will continue with the same model numbers that the WD SSDs used.",
          "content": "In late 2023, storage company Western Digital announced plans to split itself into two companies. One, which would still be called Western Digital, would focus on spinning hard drives, which are no longer used much in consumer systems but remain important to NAS devices and data centers. The other, called SanDisk, would handle solid-state storage, including the drives that Western Digital sold to consumers under its Blue, Black, Green, and Red brands. That split effectively undid what Western Digital did a decade ago when it bought SanDisk for $19 billion. And we're just now starting to see the way the split will affect the company's existing consumer drives. Today, SanDisk announced that mainstream WD Blue and WD Black SSDs would be discontinued and replaced by SanDisk Optimus-branded disks with the same model numbers.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/sandisk-optimus-product-family-pr-1152x648-1767638879.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/sandisk-optimus-product-family-pr-1152x648-1767638879.jpeg",
      "popularity_score": 289.20216805555555
    },
    {
      "id": "cluster_63",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 17:51:36 +0000",
      "title": "Google TV’s big Gemini update adds image and video generation, voice control for settings",
      "neutral_headline": "Google TV’s big Gemini update adds image and video...",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/01/gemini-expands-on-google-tv-bringing-nano-banana-and-veo-models-to-your-tv/",
          "published_at": "Mon, 05 Jan 2026 17:51:36 +0000",
          "title": "Google TV’s big Gemini update adds image and video generation, voice control for settings",
          "standfirst": "Google TV will let you generate and watch AI content on the big screen.",
          "content": "Soon, even loafing around on the couch won't help you steer clear of AI. TV makers are busily integrating AI models into the experience, and Google is no different. At CES, the company announced a big expansion of Gemini features on the Google TV platform, starting with TCL smart TVs. Google began integrating Gemini with the TV Streamer box this past fall, but the new expansion brings some of the company's most popular AI features to TVs: Nano Banana (image) and Veo (video), which offered a huge leap in visual fidelity at launch and have only improved with subsequent updates. Both models will be part of the TV experience, allowing users to modify or create new content. Google Photos AI remixing in Google TV. Credit: Google The Google TV platform connects to Google Photos, allowing Gemini to access those images with your approval. Gemini can generate a slideshow of your choosing on the spot, but it can also feed those images into Veo or Nano Banana. Using Gemini voice controls, you can remix a photo or turn a still image into a video. You can also enter a solo prompt to generate a totally new image or video with Google's AI on your TV.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/We_previewed_new_Gemini_for_Google_TV-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/We_previewed_new_Gemini_for_Google_TV-1152x648.png",
      "popularity_score": 279.52105694444447
    },
    {
      "id": "cluster_51",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 19:15:09 +0000",
      "title": "BioWare’s Anthem will soon be completely unplayable",
      "neutral_headline": "BioWare’s Anthem will soon be completely unplayable",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/biowares-anthem-will-soon-be-completely-unplayable/",
          "published_at": "Mon, 05 Jan 2026 19:15:09 +0000",
          "title": "BioWare’s Anthem will soon be completely unplayable",
          "standfirst": "Replay the troubled jetpack shooter before the servers shut down for good on Jan. 12.",
          "content": "We'll admit that we weren't paying enough attention to the state of Anthem—BioWare's troubled 2019 jetpack-powered open-world shooter—to notice EA's July announcement that it was planning to shut down the game's servers. But with that planned server shutdown now just a week away, we thought it was worth alerting you readers to your final opportunity to play one of BioWare's most ambitious failures. Anthem was unveiled at E3 2017 in a demo that was later revealed to have been largely faked to paper over major issues with the game's early development. Anthem’s early 2019 release was met with a lot of middling-to-poor reviews (including one from Ars itself), followed about a year later by a promise from BioWare General Manager Casey Hudson that a \"longer-term redesign\" and \"substantial reinvention\" of the overall game experience were coming. Hudson left BioWare in December 2020, though, and a few months later, that planned Anthem overhaul was officially canceled. While active development on Anthem has been dormant for years, the game's servers have remained up and running. And though the game didn't exactly explode in popularity during that period of benign neglect, estimates from MMO Populations suggest a few hundred to a few thousand players have been jetpacking around the game's world daily. The game also still sees a smattering of daily subreddit posts, including some hoping against hope for a fan-led private server revival, a la the Pretendo Network. And there are still a small handful of Twitch streamers sharing the game while they still can, including one racing to obtain all of the in-game achievements after picking up a $4 copy at Goodwill.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/anthem-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/anthem-1152x648.jpg",
      "popularity_score": 278.91355694444445
    },
    {
      "id": "cluster_65",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 17:42:45 +0000",
      "title": "X blames users for Grok-generated CSAM; no fixes announced",
      "neutral_headline": "X blames users for Grok-generated CSAM; no fixes announced",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/x-blames-users-for-grok-generated-csam-no-fixes-announced/",
          "published_at": "Mon, 05 Jan 2026 17:42:45 +0000",
          "title": "X blames users for Grok-generated CSAM; no fixes announced",
          "standfirst": "Critics call for App Store ban after Grok sexualized images of minors.",
          "content": "It seems that instead of updating Grok to prevent outputs of sexualized images of minors, X is planning to purge users generating content that the platform deems illegal, including Grok-generated child sexual abuse material (CSAM). On Saturday, X Safety finally posted an official response after nearly a week of backlash over Grok outputs that sexualized real people without consent. Offering no apology for Grok's functionality, X Safety blamed users for prompting Grok to produce CSAM while reminding them that such prompts can trigger account suspensions and possible legal consequences. \"We take action against illegal content on X, including Child Sexual Abuse Material (CSAM), by removing it, permanently suspending accounts, and working with local governments and law enforcement as necessary,\" X Safety said. \"Anyone using or prompting Grok to make illegal content will suffer the same consequences as if they upload illegal content.\"Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2233914159-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2233914159-1024x648.jpg",
      "popularity_score": 257.37355694444443
    },
    {
      "id": "cluster_75",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 16:48:07 +0000",
      "title": "Providers dropping common anesthesia drug that’s also a climate super pollutant",
      "neutral_headline": "Providers dropping common anesthesia drug that’s also a climate super pollutant",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/providers-dropping-common-anesthesia-drug-thats-also-a-climate-super-pollutant/",
          "published_at": "Mon, 05 Jan 2026 16:48:07 +0000",
          "title": "Providers dropping common anesthesia drug that’s also a climate super pollutant",
          "standfirst": "The European Union now prohibits desflurane's use during most procedures.",
          "content": "Desflurane is a common anesthetic used in hospital operating rooms worldwide. It’s also a climate super pollutant. Now, several decades after the drug was first introduced, a growing number of US hospitals have stopped using the anesthetic because of its outsized environmental impact. On January 1, the European Union went a step further, prohibiting its use in all but medically necessary cases. Desflurane is more than 7,000 times more effective at warming the planet over a 20-year period than carbon dioxide on a pound-for-pound basis. However, curbing its use alone won’t solve climate change. The anesthetic contributes only a small fraction of total global warming, which is driven by far larger volumes of carbon dioxide and methane emissions. Still, emissions from the drug add up. Approximately 1,000 tons of the gas are vented from hospitals and other health care facilities worldwide each year. The emissions have a near-term climate impact equivalent to the annual greenhouse gas emissions from approximately 1.6 million automobiles.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-596435371-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-596435371-1152x648.jpg",
      "popularity_score": 154.4630013888889
    },
    {
      "id": "cluster_80",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 15:26:35 +0000",
      "title": "Ars readers gave over $42,000 in our 2025 Charity Drive",
      "neutral_headline": "Ars readers gave over $42,000 in our 2025 Charity Drive",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/ars-readers-gave-over-42000-in-our-2025-charity-drive/",
          "published_at": "Mon, 05 Jan 2026 15:26:35 +0000",
          "title": "Ars readers gave over $42,000 in our 2025 Charity Drive",
          "standfirst": "Ars’ total charity haul since 2007 now tops $585,000.",
          "content": "Last month, we asked readers to donate to a couple of good causes in our 2025 Charity Drive sweepstakes. And boy, did you deliver. With the drive now complete and the donations all tallied, we can report that Ars Technica readers gave an incredible $42,936.83 to Child's Play and the Electronic Frontier Foundation in this year's drive. That doesn't set a new record, but it beats last year's total and raises our lifetime Ars Charity Drive donation haul since 2007 to over $585,000. Well done, Arsians! Thanks to everyone who gave whatever they could. We're still early in the process of selecting and notifying winners of our swag giveaway, so don't fret if you haven't heard if you're a winner yet. In the meantime, enjoy these quick stats from the 2025 drive. 2024 fundraising total: $42,936.83 Total given to Child's Play: $19,424.27 Total given to the EFF: $23,512.56 Number of individual donations: 474 Child's Play donations: 272 EFF donations: 202 Average donation: $90.58 Child's Play average donation: $71.41 EFF average donation: $116.40 Median donation: $50.00 Median Child's Play donation: $26.25 Median EFF donation: $66.95 Top single donation: $3,000 (to EFF) Donations of $1,000 or more: 8 Donations of $100 or more: 133 Donation of $10 or less: 72 (every little bit helps!) Total charity donations from Ars Technica drives since 2007 (approximate): $585,872.01 2025: $42,936.83 2024: $39,047.66 2023: $39,830.36 2022: $31,656.07 2021: $40,261.71 2020: $58,758.11 2019: $33,181.11 2018: $20,210.66 2017: $36,012.37 2016: $38,738.11 2015: $38,861.06 2014: $25,094.31 2013: $23,570.13 2012: $28,713.52 2011: ~$26,000 2010: ~$24,000 2009: ~$17,000 2008: ~$12,000 2007: ~$10,000 Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2017/01/charity.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2017/01/charity.jpg",
      "popularity_score": 145.10411249999999
    },
    {
      "id": "cluster_70",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 17:10:55 +0000",
      "title": "Earliest African cremation was 9,500 years ago",
      "neutral_headline": "Earliest African cremation was 9,500 years ago",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/earliest-african-cremation-was-9500-years-ago/",
          "published_at": "Mon, 05 Jan 2026 17:10:55 +0000",
          "title": "Earliest African cremation was 9,500 years ago",
          "standfirst": "New findings prompt a rethinking of group labor and ritual in ancient hunter-gatherer communities.",
          "content": "Archaeologists have discovered Africa's oldest known cremation pyre at the base of Mount Hora in Malawi. According to a paper published in the journal Science Advances, radiocarbon testing dates the site to about 9,500 years ago, prompting a rethinking of group labor and ritual in such ancient hunter-gatherer communities. Many cultures have practiced some form of cremation. There is a Viking cremation site known as Kalvestene on the small island of Hjarnø in Denmark, for instance. And back in 2023, we reported on an unusual Roman burial site where cremated remains had not been transported to a separate final resting place but remained in place, covered in brick tiles and a layer of lime and surrounded by several dozen bent and twisted nails—possibly an attempt to prevent the deceased from rising from the grave to haunt the living.) But the practice was extremely rare among hunter-gatherer societies, since building a pyre is labor-intensive and requires a great deal of communal resources. There is very little evidence of cremation predating the mid-Holocene (between 5,000 and 7,000 years ago). According to the authors of this latest paper, the earliest known concentration of burnt human remains was found at Lake Mungo in Australia and dates back 40,000 years, but there is no evidence of a pyre, making it challenging to determine specific details.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/hora5-TOP-CROP-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/hora5-TOP-CROP-1152x648.jpg",
      "popularity_score": 143.8430013888889
    },
    {
      "id": "cluster_92",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 14:00:47 +0000",
      "title": "Hands off! An on-the-road demo of Mercedes’ advanced new driver assist",
      "neutral_headline": "Hands off. An on-the-road demo of Mercedes’ advanced new driver assist",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/mercedes-teaches-its-driver-assist-how-to-handle-surface-streets/",
          "published_at": "Mon, 05 Jan 2026 14:00:47 +0000",
          "title": "Hands off! An on-the-road demo of Mercedes’ advanced new driver assist",
          "standfirst": "It's like Tesla Autopilot, but made by a company with a culture of safety.",
          "content": "Mercedes-Benz provided flights from Washington to San Francisco and accommodation so Ars could drive the CLA, as well as receive a demonstration of Drive Assist Pro. Ars does not accept paid editorial content. There's some debate as to when adaptive cruise control first showed up, but if you ask Mercedes-Benz, it will say in 1999 with that year's S-Class. Instead of just keeping a set speed, radar-enabled adaptive cruise control allowed the car to react to deceleration by the car ahead, and thus, the first partially automated car was created. From there, automakers added a function to keep cars in their lanes, and now we have location-aware, GPS-geofenced vehicles that, as long as the driver is paying attention, will do most of the driving—on the highway at least. But the goal for developers of both autonomous and partially automated vehicles is to remove as much of the burden of driving from the human as possible, not just on controlled access highways but at lower speeds, on surface streets. Which is what Mercedes' latest Drive Assist Pro has been designed to do. And after a recent demo—albeit from the passenger seat—on the streets of downtown San Francisco, it appears to be a very credible effort. CLA gets it first The big, powerful, comfortable S-Class is normally the standard-bearer for the latest and greatest tech Mercedes has cooked up, but not always. In December, we drove the production version of its new entry-level EV, the CLA. At under $50,000, the sleek Mercedes sedan (or four-door coupé) is already available with the current version of the automaker's Drive Assist suite, with better control of braking and deceleration. A particular improvement, which I'm not sure made the final version of our first drive report, is the way you can use the brake while adaptive cruise control is active without canceling the system.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Mercedes-Benz-drive-pilot-pro-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Mercedes-Benz-drive-pilot-pro-1-1152x648.jpg",
      "popularity_score": 143.6741125
    },
    {
      "id": "cluster_97",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 12:00:58 +0000",
      "title": "Our annual power ranking of US rocket companies has changes near the top and bottom",
      "neutral_headline": "Our annual power ranking of US rocket companies has changes near the top and bottom",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/theres-a-big-shake-up-near-the-top-of-our-annual-us-launch-company-rankings/",
          "published_at": "Mon, 05 Jan 2026 12:00:58 +0000",
          "title": "Our annual power ranking of US rocket companies has changes near the top and bottom",
          "standfirst": "There are some fresh faces entering the rankings this year.",
          "content": "Which US rocket companies achieved the most during 2025? Once again, Ars Technica is here to provide some answers in the form of our annual power ranking of US launch companies. We began doing this in 2022 and have since put out a top-10 list every year (see 2023 and 2024). Our intent, as always, is to spark debate, discussion, and appreciation for the challenge of operating a successful rocket company. It's a demanding business, both technically and financially. We respect the grit and hustle because we know just how hard this stuff is. Please also note that this is a subjective list, although hard metrics such as total launches, tonnage to orbit, success rate, and more were all important factors in the decision. And finally, our focus remains on what each company accomplished in 2025, not on what they might do in the future.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/NG-2-Ascent-11-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/NG-2-Ascent-11-1152x648.jpg",
      "popularity_score": 141.67716805555557
    }
  ]
}