{
  "updated_at": "2026-01-08T19:20:34.970Z",
  "clusters": [
    {
      "id": "cluster_3",
      "coverage": 2,
      "updated_at": "Thu, 08 Jan 2026 19:08:42 GMT",
      "title": "The coolest audio gear of CES 2026: soundbars, headphones, speakers and more",
      "neutral_headline": "The coolest audio gear of CES 2026: soundbars, headphones, speakers and more",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/headphones-speakers-soundbars-ces-2026/",
          "published_at": "Thu, 08 Jan 2026 19:08:42 GMT",
          "title": "The coolest audio gear of CES 2026: soundbars, headphones, speakers and more",
          "standfirst": "I spent a week at CES 2026 finding the best audio products. Here's what I found.",
          "content": "I spent a week at CES 2026 finding the best audio products. Here's what I found.",
          "feed_position": 0
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/smart-home-tech-ces-2026/",
          "published_at": "Thu, 08 Jan 2026 13:11:00 GMT",
          "title": "The best and most useful smart home tech I've seen at CES 2026",
          "standfirst": "I spent the week on the CES show floor, searching for compelling smart home devices. Here's what I found.",
          "content": "I spent the week on the CES show floor, searching for compelling smart home devices. Here's what I found.",
          "feed_position": 14
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/bose-coupon-code/",
          "published_at": "Thu, 08 Jan 2026 07:30:00 +0000",
          "title": "Bose Promo Code: 40% Off Bose for January 2026",
          "standfirst": "Enjoy at least 40% off headphones, speakers, soundbars, and other audio products from Bose.",
          "content": "Enjoy at least 40% off headphones, speakers, soundbars, and other audio products from Bose.",
          "feed_position": 11,
          "image_url": "https://media.wired.com/photos/67b63b9283a9f95e0ab9b215/master/pass/WIRED-Coupons-R2_3.png"
        }
      ],
      "featured_image": "https://media.wired.com/photos/67b63b9283a9f95e0ab9b215/master/pass/WIRED-Coupons-R2_3.png",
      "popularity_score": 2019.8019527777778
    },
    {
      "id": "cluster_33",
      "coverage": 2,
      "updated_at": "Thu, 08 Jan 2026 17:24:33 +0000",
      "title": "The GE Profile Smart Fridge stops you from buying too much kale",
      "neutral_headline": "The GE Profile Smart Fridge stops you from buying too much kale",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/kitchen-tech/the-ge-profile-smart-fridge-stops-you-from-buying-too-much-kale-172433059.html",
          "published_at": "Thu, 08 Jan 2026 17:24:33 +0000",
          "title": "The GE Profile Smart Fridge stops you from buying too much kale",
          "standfirst": "If you’ve ever bought a bag of spinach only to come home and realize you already had a bag of spinach, you may appreciate this fridge. I had a chance to check out the GE Profile Smart Fridge with Kitchen Assistant at CES and was surprised to find I kinda wanted one. To be perfectly honest, most attempts I’ve seen at the show to “stick some AI in it” are at best amusing but usually completely unnecessary. Here, though, the AI has a purpose. After seeing how the autofill water dispenser worked, I asked the GE Appliance reps how easy it was to change the fridge’s water filter. Jason May, a GE Appliances product management executive, walked up to the fridge’s (appropriately sized) touchscreen and said “Hey HQ, where’s my water filter?” (HQ is short for SmartHQ, GE Profile’s assistant). Then, relying on information it had gathered from this model’s user manual, the AI assistant explained exactly where to find it (in the left hand door below the ice maker). It took another rep about two seconds to pop out the filter and, justlikethat, the task was on its way to done. As for the spinach conundrum, that’s handled by a crisper drawer camera, called Fridge Focus. Each time you open the drawers, a built-in camera (that you can physically shutter or turn off in the app) takes a video snapshot of what’s left when you’re done. So if you’re at the store and wondering how much kale you already have, you can take a peek and see. Checking out what's in the crisper drawer using the Fridge Focus feature. Sam Rutherford for Engadget Wendy Treinen, GE Appliances’ senior director of product communications, told me the camera can see what’s in the crisper drawer, but can’t see who accessed it. So if you’re hoping your fridge will rat out whoever at the last of the grapes, you’re out of luck. It can however, help that grape-eater easily add more fruit to the family shopping list. That’s the most unique feature the fridge offers: a patented, built-in barcode scanner. It lives in the water dispenser and when you walk up, a little green light activates and scans the barcode of whatever you hold up to it. So if you’re drinking the last of the almond milk, you scan the container and it’ll automatically add it to your list. That list can be accessed through the SmartHQ app which you can either check off at the grocery store or, if you really want to get deluxe about it, use the Instacart integration and have it delivered to your door. I scanned a few products — a box of vitamin C mix and a package of cinnamon raisin bagels — both of which quickly popped up on the screen and joined the running list. Adding grocery items to Instacart with one button. Sam Rutherford for Engadget The scanner can recognize four million products, including household items like paper towels and trash bags, but you can add things a other ways too. The easiest is probably just asking your fridge to do so, saying “Hey HQ, add paper towels to my shopping list.” The app allows manual additions and you can add items using the recipe function as well. For the launch of the fridge, GE Profile has partnered with Taste of Home and will send 50 recipes each month to the fridge for users to try. Once you see the ingredients list, you can add anything you’re missing to your shopping. Those 50 recipes will cycle out at the end of the month to make way for a new 50, so if you cook something and like it, you’ll need to to add it to your personal recipe vault. The AI assistant can also create recipes for you. The GE rep snapped a picture of an array of produce and asked SmartHQ what he could make with it. A list of recipe suggestions popped up and they all looked quite tasty (to be fair, I hadn’t eaten yet and it was already 2PM). The recipe created from a picture of produce. Sam Rutherford for Engadget I mentioned the water dispenser’s hands-free auto-fill feature earlier. That’s been available on GE Profile fridges for a while and lets you select your glass capacity and walk away while it fills. You can also ask for, say, a half cup of water for a recipe. A new “precise fill” feature will dispense larger amounts in sequence. Say you need ten cups of water for soup. Since you can’t fit a huge vat in the water dispenser tray, you can instead use a smaller jug and the auto-filler will fill it the correct amount of times. Another of my favorite bits is the screen. Fridges with giant, interactive screens make my eyes roll. Yes, it’s novel and eye-catching and perhaps amusing, but what possible problem is it trying to solve? The screen here is eight inches, which is enough to display scanned items, show recipes, and display the weather atop a pretty image when you’re not actively using the interface. Finally! A reasonably sized fridge screen. Sam Rutherford for Engadget The GE Appliances reps were eager to point out that this is just the beginning of what they want to do with the fridge. My college Sam Rutherford asked whether the fridge would be able to alert you before your lettuce went bad, and we were told something that addresses that problem is on the horizon. It would likely work by recognizing when you purchased a perishable, and how long that perishable typically lasts. The company is also working with a chef on a feature that can reimagine your leftovers to create something new. During the demo, May told me that the whole idea around the fridge’s design was to do something other than just “put a big screen on it with a bunch of apps that don’t have ay relevance to anything.” Instead the engineers started with problems people actually have — knowing what to buy at the store, knowing what’s already in the fridge, answering the eternal, unrelenting “What’s for dinner?” question — and designed the fridge around that. I’d have to live with it a while to know whether those problems were solved, but so far, I can say this is the most intrigued I’ve felt about a smart fridge yet. The GE Profile Smart Fridge with Kitchen Assistant will be available in March from geappliances.com for $4,899. A good amount of organization. Sam Rutherford for Engadget This article originally appeared on Engadget at https://www.engadget.com/home/kitchen-tech/the-ge-profile-smart-fridge-stops-you-from-buying-too-much-kale-172433059.html?src=rss",
          "content": "If you’ve ever bought a bag of spinach only to come home and realize you already had a bag of spinach, you may appreciate this fridge. I had a chance to check out the GE Profile Smart Fridge with Kitchen Assistant at CES and was surprised to find I kinda wanted one. To be perfectly honest, most attempts I’ve seen at the show to “stick some AI in it” are at best amusing but usually completely unnecessary. Here, though, the AI has a purpose. After seeing how the autofill water dispenser worked, I asked the GE Appliance reps how easy it was to change the fridge’s water filter. Jason May, a GE Appliances product management executive, walked up to the fridge’s (appropriately sized) touchscreen and said “Hey HQ, where’s my water filter?” (HQ is short for SmartHQ, GE Profile’s assistant). Then, relying on information it had gathered from this model’s user manual, the AI assistant explained exactly where to find it (in the left hand door below the ice maker). It took another rep about two seconds to pop out the filter and, justlikethat, the task was on its way to done. As for the spinach conundrum, that’s handled by a crisper drawer camera, called Fridge Focus. Each time you open the drawers, a built-in camera (that you can physically shutter or turn off in the app) takes a video snapshot of what’s left when you’re done. So if you’re at the store and wondering how much kale you already have, you can take a peek and see. Checking out what's in the crisper drawer using the Fridge Focus feature. Sam Rutherford for Engadget Wendy Treinen, GE Appliances’ senior director of product communications, told me the camera can see what’s in the crisper drawer, but can’t see who accessed it. So if you’re hoping your fridge will rat out whoever at the last of the grapes, you’re out of luck. It can however, help that grape-eater easily add more fruit to the family shopping list. That’s the most unique feature the fridge offers: a patented, built-in barcode scanner. It lives in the water dispenser and when you walk up, a little green light activates and scans the barcode of whatever you hold up to it. So if you’re drinking the last of the almond milk, you scan the container and it’ll automatically add it to your list. That list can be accessed through the SmartHQ app which you can either check off at the grocery store or, if you really want to get deluxe about it, use the Instacart integration and have it delivered to your door. I scanned a few products — a box of vitamin C mix and a package of cinnamon raisin bagels — both of which quickly popped up on the screen and joined the running list. Adding grocery items to Instacart with one button. Sam Rutherford for Engadget The scanner can recognize four million products, including household items like paper towels and trash bags, but you can add things a other ways too. The easiest is probably just asking your fridge to do so, saying “Hey HQ, add paper towels to my shopping list.” The app allows manual additions and you can add items using the recipe function as well. For the launch of the fridge, GE Profile has partnered with Taste of Home and will send 50 recipes each month to the fridge for users to try. Once you see the ingredients list, you can add anything you’re missing to your shopping. Those 50 recipes will cycle out at the end of the month to make way for a new 50, so if you cook something and like it, you’ll need to to add it to your personal recipe vault. The AI assistant can also create recipes for you. The GE rep snapped a picture of an array of produce and asked SmartHQ what he could make with it. A list of recipe suggestions popped up and they all looked quite tasty (to be fair, I hadn’t eaten yet and it was already 2PM). The recipe created from a picture of produce. Sam Rutherford for Engadget I mentioned the water dispenser’s hands-free auto-fill feature earlier. That’s been available on GE Profile fridges for a while and lets you select your glass capacity and walk away while it fills. You can also ask for, say, a half cup of water for a recipe. A new “precise fill” feature will dispense larger amounts in sequence. Say you need ten cups of water for soup. Since you can’t fit a huge vat in the water dispenser tray, you can instead use a smaller jug and the auto-filler will fill it the correct amount of times. Another of my favorite bits is the screen. Fridges with giant, interactive screens make my eyes roll. Yes, it’s novel and eye-catching and perhaps amusing, but what possible problem is it trying to solve? The screen here is eight inches, which is enough to display scanned items, show recipes, and display the weather atop a pretty image when you’re not actively using the interface. Finally! A reasonably sized fridge screen. Sam Rutherford for Engadget The GE Appliances reps were eager to point out that this is just the beginning of what they want to do with the fridge. My college Sam Rutherford asked whether the fridge would be able to alert you before your lettuce went bad, and we were told something that addresses that problem is on the horizon. It would likely work by recognizing when you purchased a perishable, and how long that perishable typically lasts. The company is also working with a chef on a feature that can reimagine your leftovers to create something new. During the demo, May told me that the whole idea around the fridge’s design was to do something other than just “put a big screen on it with a bunch of apps that don’t have ay relevance to anything.” Instead the engineers started with problems people actually have — knowing what to buy at the store, knowing what’s already in the fridge, answering the eternal, unrelenting “What’s for dinner?” question — and designed the fridge around that. I’d have to live with it a while to know whether those problems were solved, but so far, I can say this is the most intrigued I’ve felt about a smart fridge yet. The GE Profile Smart Fridge with Kitchen Assistant will be available in March from geappliances.com for $4,899. A good amount of organization. Sam Rutherford for Engadget This article originally appeared on Engadget at https://www.engadget.com/home/kitchen-tech/the-ge-profile-smart-fridge-stops-you-from-buying-too-much-kale-172433059.html?src=rss",
          "feed_position": 3,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/GE_Profile_Smart_Fridge_fridge_focus.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/it-took-guts-for-dell-to-admit-its-mistake-heres-how-xps-will-make-its-big-comeback-in-2026-233248065.html",
          "published_at": "Thu, 08 Jan 2026 17:17:24 +0000",
          "title": "It took guts for Dell to admit its mistake, here's how XPS will make its big comeback in 2026",
          "standfirst": "When Dell made the decision to kill off its XPS laptop name last year, it felt like a big mistake. We said so, in fact, multiple times. But at CES 2026, the company is righting its past wrongs by resurrecting the iconic laptop brand — and this time, this decision feels like the right move both for Dell as a whole and its flagship consumer devices.Even more than the words the letters XPS are meant to represent (Extreme Performance Systems), over the last decade, Dell’s signature laptop brand stood for excellent design, quality engineering and top notch performance. And it was precisely those laptops that landed the company at the top of nearly every best Windows laptop guide every year for the last decade. So to replace XPS with a generic tag like premium felt like a big step backwards. Now if you were living under a rock (at least when it comes to Windows laptops), you can sort of squint your eyes and see the reasoning behind Dell’s misguided rebranding. Premium means good, typically something much better than average. By putting that word in front of its top-tier systems, there’s no way anyone could be confused about what kind of device they were buying, right? Take for example the Dell Premium 14, which was the new moniker for what was previously called the XPS 14. A laptop like that has to be decent. I mean, it’s right there in the product name. The issue is that XPS already meant good. Actually, way better than that, if we were just going by the sheer number of accolades previous-gen models got, like Dell’s 2020-era machines which we called practically perfect (which it was). Going away from that wasn’t just reductive, it was throwing the best part of Dell’s consumer business in the trash for no real reason. The first two new XPS machines will be the XPS 14 and XPS 16. Sam Rutherford for EngadgetAdditionally, Dell’s new naming strategy was intended to simplify its product portfolio, and it failed to deliver on that original goal. COO Jeff Clarke was refreshingly honest about this when announcing the return of XPS at a CES media preview in early December. Not only did Dell lose its signature XPS brand last year, it actually made things more confusing for consumers when it simultaneously created a full range of Dell Pro and Pro Max systems. Unlike Apple’s MacBook Pros and iPhone Pro Maxes, those devices were actually meant for enterprise customers instead of regular Joes. Another photo of the new XPS 14 and 16, which have a bunch of welcome changes and then some. Sam Rutherford for EngadgetAmidst its rebrand, the company also eliminated a lot of its budget and entry-level models. That left a lot of people turning to more expensive mid-range “Plus” systems or waiting for a proper redesign of its top tier Premium laptops, which weren’t expected to arrive until 2026 anyway. So where is Dell going from here? Well as Clarke put it quite succinctly, “We’re getting back to our roots.” Starting in 2026, the company is planning to create its broadest PC portfolio ever including, a full line of XPS laptops. This includes an all-new version of the XPS 13, which is going to be the thinnest and lightest model to date, along with complete overhauls for the XPS 14 and XPS 16. But Dell isn’t stopping there because on a slide it showed at its press event, there were two additional placeholders for future XPS systems coming at some later date. Dell wouldn't let me take photos of the XPS 13 prototype model, but here's a teaser it provided for CES. DellEven when it comes to specific features and components on individual models, Dell is finally acknowledging some of the criticism it has received over the past few years by returning to segmented touchpads instead of seamless all-glass slates and ditching capacitive function keys for good ‘ol buttons. Dell isn’t just bringing the XPS line back, it’s kind of on a revenge tour (even if the original wound was self-inflicted). On top of that, the consumer device team will be reporting directly to Clarke while the company retools itself internally. Dell is also updating its naming scheme to finally deliver on the promise of making things clear and simple. XPS will once again be the company’s flagship consumer brand with the XPS logo (not Dell’s) front and center on the lid of every laptop, while everything else will fall under the general Dell umbrella. Alienware will continue to do its own thing for gaming and the Dell Pro family will remain aimed strictly at enterprise businesses, professional services (like first responders) and education. No more confusion. And underlying all of that is a very straightforward motto from Clarke that “great products win.” After ditching the XPS brand, Dell is now bring it back for 2026 in its rightful spot at the top of the company's consumer portfolio. DellIn the end, even though Dell’s big plan from last year ended up being a mess, I appreciate when a company is self aware enough to know it messed up and has come up with a plan to fix things. Regardless of whether it's a corporation or a single person, admitting mistakes is always hard. Oftentimes, what you learn in the process is the real prize and from what I’ve seen Dell and its iconic XPS line is poised for a major comeback. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/it-took-guts-for-dell-to-admit-its-mistake-heres-how-xps-will-make-its-big-comeback-in-2026-233248065.html?src=rss",
          "content": "When Dell made the decision to kill off its XPS laptop name last year, it felt like a big mistake. We said so, in fact, multiple times. But at CES 2026, the company is righting its past wrongs by resurrecting the iconic laptop brand — and this time, this decision feels like the right move both for Dell as a whole and its flagship consumer devices.Even more than the words the letters XPS are meant to represent (Extreme Performance Systems), over the last decade, Dell’s signature laptop brand stood for excellent design, quality engineering and top notch performance. And it was precisely those laptops that landed the company at the top of nearly every best Windows laptop guide every year for the last decade. So to replace XPS with a generic tag like premium felt like a big step backwards. Now if you were living under a rock (at least when it comes to Windows laptops), you can sort of squint your eyes and see the reasoning behind Dell’s misguided rebranding. Premium means good, typically something much better than average. By putting that word in front of its top-tier systems, there’s no way anyone could be confused about what kind of device they were buying, right? Take for example the Dell Premium 14, which was the new moniker for what was previously called the XPS 14. A laptop like that has to be decent. I mean, it’s right there in the product name. The issue is that XPS already meant good. Actually, way better than that, if we were just going by the sheer number of accolades previous-gen models got, like Dell’s 2020-era machines which we called practically perfect (which it was). Going away from that wasn’t just reductive, it was throwing the best part of Dell’s consumer business in the trash for no real reason. The first two new XPS machines will be the XPS 14 and XPS 16. Sam Rutherford for EngadgetAdditionally, Dell’s new naming strategy was intended to simplify its product portfolio, and it failed to deliver on that original goal. COO Jeff Clarke was refreshingly honest about this when announcing the return of XPS at a CES media preview in early December. Not only did Dell lose its signature XPS brand last year, it actually made things more confusing for consumers when it simultaneously created a full range of Dell Pro and Pro Max systems. Unlike Apple’s MacBook Pros and iPhone Pro Maxes, those devices were actually meant for enterprise customers instead of regular Joes. Another photo of the new XPS 14 and 16, which have a bunch of welcome changes and then some. Sam Rutherford for EngadgetAmidst its rebrand, the company also eliminated a lot of its budget and entry-level models. That left a lot of people turning to more expensive mid-range “Plus” systems or waiting for a proper redesign of its top tier Premium laptops, which weren’t expected to arrive until 2026 anyway. So where is Dell going from here? Well as Clarke put it quite succinctly, “We’re getting back to our roots.” Starting in 2026, the company is planning to create its broadest PC portfolio ever including, a full line of XPS laptops. This includes an all-new version of the XPS 13, which is going to be the thinnest and lightest model to date, along with complete overhauls for the XPS 14 and XPS 16. But Dell isn’t stopping there because on a slide it showed at its press event, there were two additional placeholders for future XPS systems coming at some later date. Dell wouldn't let me take photos of the XPS 13 prototype model, but here's a teaser it provided for CES. DellEven when it comes to specific features and components on individual models, Dell is finally acknowledging some of the criticism it has received over the past few years by returning to segmented touchpads instead of seamless all-glass slates and ditching capacitive function keys for good ‘ol buttons. Dell isn’t just bringing the XPS line back, it’s kind of on a revenge tour (even if the original wound was self-inflicted). On top of that, the consumer device team will be reporting directly to Clarke while the company retools itself internally. Dell is also updating its naming scheme to finally deliver on the promise of making things clear and simple. XPS will once again be the company’s flagship consumer brand with the XPS logo (not Dell’s) front and center on the lid of every laptop, while everything else will fall under the general Dell umbrella. Alienware will continue to do its own thing for gaming and the Dell Pro family will remain aimed strictly at enterprise businesses, professional services (like first responders) and education. No more confusion. And underlying all of that is a very straightforward motto from Clarke that “great products win.” After ditching the XPS brand, Dell is now bring it back for 2026 in its rightful spot at the top of the company's consumer portfolio. DellIn the end, even though Dell’s big plan from last year ended up being a mess, I appreciate when a company is self aware enough to know it messed up and has come up with a plan to fix things. Regardless of whether it's a corporation or a single person, admitting mistakes is always hard. Oftentimes, what you learn in the process is the real prize and from what I’ve seen Dell and its iconic XPS line is poised for a major comeback. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/it-took-guts-for-dell-to-admit-its-mistake-heres-how-xps-will-make-its-big-comeback-in-2026-233248065.html?src=rss",
          "feed_position": 5,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/XPS-14-and-16.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/star-trek-starfleet-academy-deftly-balances-teen-drama-with-intergalactic-intrigue-170253808.html",
          "published_at": "Thu, 08 Jan 2026 17:02:53 +0000",
          "title": "Star Trek: Starfleet Academy deftly balances teen drama with intergalactic intrigue",
          "standfirst": "Star Trek is in a weird place right now. Less than three years ago we were living in a golden age with five shows on the air, all with different styles and intended audiences. But the universe rapidly contracted, with Picard ending while four other shows were cut short. Strange New Worlds still has another two seasons left, sure, but even that final season got truncated. As it stands, there’s only one project with a firm future right now, and that’s a brand-new show, Starfleet Academy, premiering January 15 on Paramount+.How this show is received could very well determine the future of Star Trek. That’s a lot to put on it, but there’s something very appropriate given the subject matter. Starfleet Academy takes place in the 32nd century, 900 years after the adventures of James T. Kirk and company, and it takes place at the titular academy, meaning its principal cast is a collection of teens representing the next generation of Starfleet officers. That focus on a younger cadre has led to fans online derisively calling the series “CW Trek” without seeing a single episode. As Starfleet Academy is technically a Discovery spinoff, it picks up some of that series’ traits. The sleek, shiny sets are back, as well as a few plot threads originally set up in Discovery. The most notable is the collapse of the United Federation of Planets and the rebuilding of both the Federation and Starfleet. In fact, the series picks up on that as early as its second episode, with the Academy hosting a delegation from a once stalwart Federation planet that’s now gone isolationist. Scenes from Star Trek: Starfleet AcademyJohn Medland/Paramount+While many complaints about the series have focused on how what fans wanted was an academy show set during the 24th century (the time of The Next Generation, Deep Space Nine, et al.), this particular episode plot works precisely because of the distant future in which it is set. In a fully-functioning galactic democracy like the United Federation of Planets, there’s no logical reason for the average 18-year-old college freshman to be involved in interplanetary diplomacy. But in the 32nd century, the Federation is a lot scrappier and the individuals involved might be asked to wear many hats. It’s a lot like an early-stage tech startup.The setting also lets the show be a little more creative with its cast: where TNG featured the first Klingon in Starfleet (Worf), 900 years of progress have created a Starfleet where no one bats an eye when a Klingon cadet like Jay-Den Kraag (played by Karim Diané) shows up to study science. There’s also a holographic cadet, Sam, who is the first of her kind to attend the academy (and she’s super excited to do so). A few new species are present as well: Darem Reymi (George Hawkins) is a Khionian and Genesis Lythe (Bella Shepard) is a Dar-Sha, both aliens making their debut in the Star Trek universe.The cast of Star Trek: Starfleet AcademyJohn Medland/Paramount+However, the show does still lean on some Trek stalwarts, and it’s these characters that have gotten the most chatter from fans. Mary Weisman as Sylvia Tilly was originally slated for the cast, and there was even a backdoor pilot-esque episode of Discovery to tie her in to the new show, but she’s no longer a regular and is nowhere to be seen in the first two episodes. Instead, we have Jett Reno (played by the wonderful Tig Notaro) as supporting cast, and Admiral Vance (Oded Fehr) appearing in a few episodes. And old school fans have been abuzz by the inclusion of The Doctor, who first appeared on Voyager (and later Prodigy). As a hologram, he’s practically immortal so his presence doesn’t need any convoluted explanation, and after 800 years he’s still the same gregarious blowhard (and it’s delightful).They’re joined by new characters like Lara Thok, a part Klingon, part Jem’Hadar security officer and a Lanthanite chancellor, Nahla Ake, played by Academy Award Winner Holly Hunter. And Hunter isn’t even the only Oscar winner on the cast, with a major villain, Nus Braka, being portrayed by Paul Giamatti.It’s a stellar cast, and the show’s sets certainly rise up to meet the challenge. Like in the shows of old, a good portion of Starfleet Academy is clearly shot on location, though not in the familiar water reclamation plant that was used back during the TNG and DS9 era. This time it’s all being shot in Ontario, with the outdoor scenes in particular being filmed in Waterloo. Regardless of where it’s shot, it looks enough like sunny California to work. Scenes from Star Trek: Starfleet AcademyJohn Medland/Paramount+The indoor scenes, shot at Toronto’s Pinewood Studios, have a pleasant convention center quality to them, with lots of wide hallways and large windows in contrast to Discovery’s cramped ship corridors. The hallways are full of students and teachers going to and fro, including some from species that would normally be off-limits to a show with a limited budget. But here robots and strange aliens roam freely in the background. The CGI can’t have been cheap.And that’s ultimately my biggest question about Starfleet Academy. Exactly how much is this costing Paramount? So much of it is being shot on real sets instead of green screens, established actors like Hunter and Giamatti couldn’t have been cheap, and plentiful CG points to a robust special effects budget. Though Paramount doesn’t release official numbers, estimates have put an average episode of Strange New Worlds at $10 million, so it figures that Starfleet Academy is probably more than that, with some online estimates as high as $20 million per episode. With 10 episodes scheduled, that’s on par with a major motion picture budget but without the promise of blockbuster box office returns. No wonder Paramount has been doing so much cost-cutting, which includes axing every other Star Trek show.That said, Starfleet Academy is carrying a lot on its shoulders. Just as the success or failure of its class of Starfleet cadets will determine the future of Starfleet and the Federation, the success of the show may even affect whether this era of Star Trek continues. As a Star Trek fan, this can be nerve-wracking; no one wants the franchise to go dormant again. But Starfleet Academy has so far shown itself to be up to the challenge.This article originally appeared on Engadget at https://www.engadget.com/entertainment/star-trek-starfleet-academy-deftly-balances-teen-drama-with-intergalactic-intrigue-170253808.html?src=rss",
          "content": "Star Trek is in a weird place right now. Less than three years ago we were living in a golden age with five shows on the air, all with different styles and intended audiences. But the universe rapidly contracted, with Picard ending while four other shows were cut short. Strange New Worlds still has another two seasons left, sure, but even that final season got truncated. As it stands, there’s only one project with a firm future right now, and that’s a brand-new show, Starfleet Academy, premiering January 15 on Paramount+.How this show is received could very well determine the future of Star Trek. That’s a lot to put on it, but there’s something very appropriate given the subject matter. Starfleet Academy takes place in the 32nd century, 900 years after the adventures of James T. Kirk and company, and it takes place at the titular academy, meaning its principal cast is a collection of teens representing the next generation of Starfleet officers. That focus on a younger cadre has led to fans online derisively calling the series “CW Trek” without seeing a single episode. As Starfleet Academy is technically a Discovery spinoff, it picks up some of that series’ traits. The sleek, shiny sets are back, as well as a few plot threads originally set up in Discovery. The most notable is the collapse of the United Federation of Planets and the rebuilding of both the Federation and Starfleet. In fact, the series picks up on that as early as its second episode, with the Academy hosting a delegation from a once stalwart Federation planet that’s now gone isolationist. Scenes from Star Trek: Starfleet AcademyJohn Medland/Paramount+While many complaints about the series have focused on how what fans wanted was an academy show set during the 24th century (the time of The Next Generation, Deep Space Nine, et al.), this particular episode plot works precisely because of the distant future in which it is set. In a fully-functioning galactic democracy like the United Federation of Planets, there’s no logical reason for the average 18-year-old college freshman to be involved in interplanetary diplomacy. But in the 32nd century, the Federation is a lot scrappier and the individuals involved might be asked to wear many hats. It’s a lot like an early-stage tech startup.The setting also lets the show be a little more creative with its cast: where TNG featured the first Klingon in Starfleet (Worf), 900 years of progress have created a Starfleet where no one bats an eye when a Klingon cadet like Jay-Den Kraag (played by Karim Diané) shows up to study science. There’s also a holographic cadet, Sam, who is the first of her kind to attend the academy (and she’s super excited to do so). A few new species are present as well: Darem Reymi (George Hawkins) is a Khionian and Genesis Lythe (Bella Shepard) is a Dar-Sha, both aliens making their debut in the Star Trek universe.The cast of Star Trek: Starfleet AcademyJohn Medland/Paramount+However, the show does still lean on some Trek stalwarts, and it’s these characters that have gotten the most chatter from fans. Mary Weisman as Sylvia Tilly was originally slated for the cast, and there was even a backdoor pilot-esque episode of Discovery to tie her in to the new show, but she’s no longer a regular and is nowhere to be seen in the first two episodes. Instead, we have Jett Reno (played by the wonderful Tig Notaro) as supporting cast, and Admiral Vance (Oded Fehr) appearing in a few episodes. And old school fans have been abuzz by the inclusion of The Doctor, who first appeared on Voyager (and later Prodigy). As a hologram, he’s practically immortal so his presence doesn’t need any convoluted explanation, and after 800 years he’s still the same gregarious blowhard (and it’s delightful).They’re joined by new characters like Lara Thok, a part Klingon, part Jem’Hadar security officer and a Lanthanite chancellor, Nahla Ake, played by Academy Award Winner Holly Hunter. And Hunter isn’t even the only Oscar winner on the cast, with a major villain, Nus Braka, being portrayed by Paul Giamatti.It’s a stellar cast, and the show’s sets certainly rise up to meet the challenge. Like in the shows of old, a good portion of Starfleet Academy is clearly shot on location, though not in the familiar water reclamation plant that was used back during the TNG and DS9 era. This time it’s all being shot in Ontario, with the outdoor scenes in particular being filmed in Waterloo. Regardless of where it’s shot, it looks enough like sunny California to work. Scenes from Star Trek: Starfleet AcademyJohn Medland/Paramount+The indoor scenes, shot at Toronto’s Pinewood Studios, have a pleasant convention center quality to them, with lots of wide hallways and large windows in contrast to Discovery’s cramped ship corridors. The hallways are full of students and teachers going to and fro, including some from species that would normally be off-limits to a show with a limited budget. But here robots and strange aliens roam freely in the background. The CGI can’t have been cheap.And that’s ultimately my biggest question about Starfleet Academy. Exactly how much is this costing Paramount? So much of it is being shot on real sets instead of green screens, established actors like Hunter and Giamatti couldn’t have been cheap, and plentiful CG points to a robust special effects budget. Though Paramount doesn’t release official numbers, estimates have put an average episode of Strange New Worlds at $10 million, so it figures that Starfleet Academy is probably more than that, with some online estimates as high as $20 million per episode. With 10 episodes scheduled, that’s on par with a major motion picture budget but without the promise of blockbuster box office returns. No wonder Paramount has been doing so much cost-cutting, which includes axing every other Star Trek show.That said, Starfleet Academy is carrying a lot on its shoulders. Just as the success or failure of its class of Starfleet cadets will determine the future of Starfleet and the Federation, the success of the show may even affect whether this era of Star Trek continues. As a Star Trek fan, this can be nerve-wracking; no one wants the franchise to go dormant again. But Starfleet Academy has so far shown itself to be up to the challenge.This article originally appeared on Engadget at https://www.engadget.com/entertainment/star-trek-starfleet-academy-deftly-balances-teen-drama-with-intergalactic-intrigue-170253808.html?src=rss",
          "feed_position": 6,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/SFA_102_BP_1004_0320_RT_7636.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/all-the-tech-and-gadgets-announced-at-ces-2026-130124023.html",
          "published_at": "Thu, 08 Jan 2026 16:20:18 +0000",
          "title": "All the tech and gadgets announced at CES 2026",
          "standfirst": "It's the first week of a new year and there's no time for the tech world to slowly ease back into things following the holidays. That's because CES 2026 is in full swing, with all manner of companies descending on Las Vegas to reveal their latest innovations and what they're planning to bring your way in the near future. Many of the Engadget crew are on the ground to check out as much of the new tech as possible. Of course, we're keeping tabs on all of the major CES press conferences too. Samsung held its First Look presentation, which focuses on home products, while LG has shown off a wide array of TVs and Lego unveiled its new Smart Brick technology. We’ve heard from the major chipmakers, gone hands-on with Samsung’s trifold phone, checked out some funky laptops and seen some cute robots. There’s some hot gaming gear at the show too, not to mention some weird tech.You don’t necessarily have to wait to get your hands on all of these gadgets either. Some are available to buy right now.You can catch up on all of the big CES 2026 announcements (and some of the more offbeat gizmos we’ve seen) right here. We'll be keeping this story updated throughout the week. We also have CES live updates, with all the latest news from the event.LegoLego introduced the Smart Brick at CES 2026.LegoIn its first CES appearance, Lego announced the Smart Brick, a standard-sized brick with a 4.1mm ASIC chip inside that’s designed to respond in different ways depending on what set you’re building and how you’re building it. Using what Lego calls the “Play Engine” and integrated copper coils, each brick can sense things like motion, orientation and magnetic fields, plus its own distance, direction and orientation in relation to other Smart Bricks. Each brick also has a teeny tiny speaker built in that will play audio “tied to live play actions” rather than only pre-recorded clips.Accompanying Smart Bricks are Smart Tags and Smart Minifigures, which have their own capabilities — one of which is letting Smart Bricks know what context they are being used in. All of these pieces tie together via a local wireless layer dubbed BrickNet that, in part, lets Smart Bricks know where they are placed in relation to other smart components. The first “Smart Play” partner is, unsurprisingly, Star Wars, which will launch three “all-in-one” sets using Smart Bricks, Smart Tags and Smart Minifigures. The 473-piece Darth Vader TIE Fighter set will cost $70; the 584-piece Luke’s Red Five X-Wing set comes in at $100 and the 962-piece Throne Room Duel & A-wing set will set you back $160. The speakers in these sets can emit lightsaber swooshes, fighter sounds and The Imperial March.Engadget deputy editor Nathan Ingraham got to check out Lego’s Smart Play system in person and I’ve never been more envious of him. One of the Star Wars sets allows you to have an interactive lightsaber duel between Luke Skywalker and Darth Vader. Not only does the Vader minifigure have his signature heavy breathing sound, the speaker emits the Sith Lord’s “nooooo” yell if he loses the duel.All of this seems extremely cool. I'm looking forward to seeing what else Lego and fans can do with the Smart Play tech.LGLG's CLOiD robot.LGAlong with some TVs (which we’ll get to momentarily), LG brought plenty of other products to CES. For one thing, the company shone the spotlight on its CLOiD robot. Like the far creepier-looking 1X Neo, the CLOiD is designed to help with household tasks such as starting laundry cycles, folding clothes, unloading the dishwasher and serving food. This appears to be more of a concept than something you'll be able to buy anytime soon. During an in-person CES demo, Engadget senior reporter Karissa Bell saw CLOiD competently pull off some household tasks, albeit very slowly.The company also debuted the LG Sound Suite, a modular home audio system it developed in conjunction with Dolby to take on the likes of Sonos. Just ahead of CES, LG pulled back the curtain on a new batch of xboom speakers as well as some monitors and ultralight Gram laptops that are made with a material it's calling Aerominum. The chipmakersNVIDIA CEO Jensen Huang presents at CES 2026, wearing a black snakeskin-like jacket.NVIDIAIt's CES, so of course we're going to see a bunch of laptops and desktops, along with announcements about the tech that powers the new models. That means NVIDIA, Intel, AMD and Qualcomm are all in town to talk up their latest chips and other innovations.Given its lofty position in the industry (and the economy) NVIDIA’s CES press conference is always one to keep an eye on. This year’s edition was laregly a recap of the company’s recent moves, but it did have some news to share.NVIDIA announced Alpamayo, which is a group of open-source reasoning models designed to help autonomous vehicles handle difficult driving scenarios. The company also revealed that a super computer built on the Vera Rubin GPU architecture NVIDIA unveiled in 2024 is in production. As Intel wraps up, Johnson is eager to assure the viewers that Intel has ways to make AI profitable. He may have a better case than OpenAI does right now.Sam Chapman for EngadgetThings haven’t exactly been going great for Intel for a while, but the company is surely hoping that its Core Ultra Series 3 chips can help it right the ship. These are the first chips to be built using Intel’s 18A (18 angstroms, which is just under 2nm) process. The company says they offer improved performance — 60 percent more than the previous-gen Lunar Lake processors — and battery life improvements for laptops. The Ultra Series 3 includes a new Arc B390 integrated GPU, with 50 percent more graphics cores, double the cache and 120 GPU TOPS of performance. Put all that together and these chips should deliver up to 77 percent faster gaming performance than Lunar Lake models, Intel said. To that end, the company teased a Ultra Series 3-powered gaming handheld for later this year.Engadget senior editor Devindra Hardawar played some Battlefield 6 on a Core Ultra Series 3-powered Lenovo IdeaPad Pro 5 (an ultraportable) and came away impressed. The game ran at up to 190 fps in 1080p with the graphics settings on high, even without a dedicated GPU. That’s a promising sign for the embedded Arc graphics on Intel’s chips, as well as the company’s upscaling and frame generation tech.A screenshot from AMD's CES 2026 press conference showing a hellish vision of the future of gaming.AMDOf course, AMD wasn’t going to be left out of the CES party. The company announced several CPUs for laptops and desktops, while chillingly declaring that “AI is everywhere” and “changing the face of gaming.” Ick. There was a lot of AI chat during the two-hour(!) keynote, along with a “a jet-powered flying robot.” Illustration showing the Qualcomm Snapdragon X2 Plus on a stylized red circuit board showing the abbreviation \"X2.\"QualcommAnd then there’s Qualcomm. The company revealed the Snapdragon X2 Plus chip at the show. It’s more of a mid-range chip that isn’t quite as powerful as the higher end Snapdragon X2 Elite — it doesn’t have as many CPU cores, for one thing. Still, Qualcomm claims the X2 Plus offers as much as 35 percent faster single-core performance over the previous gen. The company also says the Adreno GPU offers a performance boost of up to 29 percent compared with the last generation.Laptops Samsung Galaxy Book 6 series hands-onMat Smith for EngadgetWhat would CES be without some new hardware that makes use of those new chips? As ever, laptop and desktop makers were at the show to offer up their latest models for your consideration. (Be sure to check out our dedicated roundup of all the laptops that grabbed our attention at this year’s show.)Samsung’s Galaxy Book 6 Ultra, Galaxy Book 6 Pro and Galaxy Book 6 boast Intel’s Core Ultra Series 3 chips and revamped designs that are said to improve heat management. You can read our story on the Galaxy Book 6 series for the specs of these laptops, though we don’t have pricing or a release window as yet.Dell realized it messed up by killing off the XPS name as part of a broader rebranding effort and we’re glad to see that the company is making a U-turn on that front. A full lineup of XPS laptops is coming this year, including an all-new XPS 13 (a long-time Engadget fave on the Windows ultraportable front). Dell also has 14- and 16-inch XPS models in the hopper, along with others it’s keeping under wraps for now.On top of having two displays, the Zephyrus Duo's screens also feature excellent brightness at up to 1,100 nits.We love an odd laptop and ASUS didn’t disappoint by bringing the ROG Zephyrus Duo to CES. This is a dual-screen gaming laptop with two 16-inch OLED panels, one of Intel’s new CPUs and up to an NVIDIA RTX 5090 GPU. The keyboard is detachable and can work wirelessly. A kickstand can help you set up the Zephyrus Duo in all kinds of orientations. You can even position the dual screens in an upside-down “V” tent mode. We don’t know the price of the Zephyrus Duo as yet, but it surely won’t be inexpensive.Marketing photo of a Kojima-inspired ROG Flow Z13 tabletASUSThat’s not all ASUS brought to the dance. The company made a special edition of the ROG Flow Z13 some that’s styled after the works of the famed game designer Hideo Kojima. The ROG Flow Z13-KJP has visual flair that’s draws from the likes of Death Stranding and Metal Gear. Kojima’s Ludens mascot is here too. There’s no pricing or release date for this variant or its matching accessories just yet.Micro RGB TVs Samsung's 130-inch Micro RGB TV. Devindra Hardawar for EngadgetMicro RGB is a term you can expect to hear about quite a bit in the coming months and years, especially when you're shopping for your next TV. Micro RGB is a new tech that's similar to Mini LED, though it uses red, green and blue LEDs instead of white backlights. Contrast ratios aren't quite as high as those on Micro LED and OLED displays, since the pixels can't be turned on and off individually. However, Micro RGB units are said to be brighter and more color accurate than TVs that use other display tech, in part because the LEDs in these screens offer smaller, more customizable dimming zones. Read reporter Steve Dent’s explainer for a deeper dive into how Micro RGB differs from other types of display tech.We're seeing more of these TVs pop up at CES 2026, including a mammoth 130-inch concept model that Samsung brought to Las Vegas. The company unveiled its first Micro RGB TV in August, — that’s a 115-inch, $29,999 model. This year, you can expect it to start offering Micro RGB TVs in 55-, 65- and 75-inch sizes. There are also 85-, 100- and 115-inch models on the way.LG revealed its first Micro RGB set at CES as well. The largest variant is 100 inches, but there are 86- and 75-inch models too. Elsewhere, LG showed off its latest Wallpaper TV, which is a 100-inch OLED display. We also got a look at LG's new Gallery TV — The Gallery is the company's take on Samsung's Frame TV format.Other new TVs and OS updatesEmber Artline TV.AmazonWe’ve got another competitor to The Frame, as Amazon has entered that scene with the Ember Artline TV. The 4K OLED model has Amazon Photos integration and you can choose from 2,000 pieces of free art to show on the screen. The Ember Artline can switch on or off automatically when someone enters or leaves the room. It runs on the Fire TV platform and (of course) there’s Alexa+ integration, along with support for Dolby Vision, HDR10+ and Wi-Fi 6. The Ember Artline is expected to start shipping this spring. It starts at $899 for the 55-inch model.The rounder redesigned Fire TV UI.AmazonSpeaking of Fire TV, Amazon has revamped the platform’s user interface with rounded corners for show, movie and app tiles; a little more space for said tiles; and typography and color gradient changes. The company has reworked the platform’s codebase as well, and it says the Fire TV OS will deliver speed boosts of up to 20 to 30 percent. Amazon will start rolling out the updated UI next month.On the Google side of TV land, you can expect more Gemini-powered features. The company is bringing the ability to search Google Photos for certain moments and people to Google TV, along with the options to remix photos into different styles and create slideshows on the fly. The Veo and Nano Banana AI video and photo generation models are coming to Google TV as well. You can also expect the ability to adjust TV settings using your voice. These Gemini features are coming to Google TV-powered TCL models first, then other devices in the following months. In the meantime, you can check out senior reporter Amy Skorheim’s hands-on impressions of the Gemini updates.Also in TV-related news, Peacock and Dolby have expanded their partnership. Currently, Peacock’s Sunday Night Football streams have Dolby Atmos support. You’ll soon be able to watch more live sports on Peacock with Dolby Vision and Atmos, as support for NBA and MLB events are on the way. Dolby Vision is coming to Sunday Night Football on Peacock too. Belkin, meanwhile, has a new wireless HDMI dongle that doesn't require a Wi-Fi connection. That should make it easy to beam videos from a device with a USB-C port to a TV, monitor or projector — handy if you’re planning an outdoor movie night in a space with spotty internet access.Monitors and projectorsLet's keep the focus on display tech for a bit with a look at some of the monitors and projectors we've seen at CES this year. Dell revealed a 52-inch ultrawide curved 6K monitor (the first of those on the planet, according to the company). The UltraSharp 52 Thunderbolt Hub Monitor has a nifty feature in that it's possible to hook up four PCs simultaneously and give each a dedicated section of the display — that could make co-op games pretty fun if you're dedicated enough to try that set up. It's possible to control all four connected PCs with a single mouse and keyboard too. This monitor is available now for $2,900 with a stand and $2,800 without.Dell also showed off a new 32-inch 4K QD-OLED monitor with Dolby Vision and True Black 500 HDR support. The Dell UltraSharp 32 4K QD-OLED Monitor can be all yours for $2,600 as of February 24.Samsung and LG revealed some new gaming monitors ahead of CES. Samsung’s 32-inch Odyssey 3D is a model that offers glasses-free 3D on a 6K display, while LG has a new bunch of 5K monitors. During CES , though, the latter also pulled back the curtain on the 27-inch UltraGear GX7, a $1,000 QHD OLED display with a 540Hz refresh rate.Samsung brought the latest version of its FreeStyle+ projector to the show. Engadget’s UK bureau chief Mat Smith checked out the new model in person and reckoned that Samsung has given the projector a serious upgrade over previous iteration. The FreeStyle+ is now much brighter, while the updated keystone correction feature seems very useful.Elsewhere, Anker’s Soundcore announced the Nebula P1i, a 1080p portable projector with speakers that you can fold out and tilt. At $369, that seems like a pretty decent option if you’re looking for an entry-level projector you can take anywhere. The P1i should arrive in time for camping trips too, since Soundcore says it’ll be available in the early part of this year. The brand also said its higher-end Nebula X1 Pro, a version of its 4K Nebula X1 that includes a 160W surround sound system, will be available this month for $4,999.XGIMI was also at CES to show off its latest high-end projector, the Titan Noir Max. There’s no word on pricing yet, but this appears to be an upgraded version of the $3,999 Titan model.SamsungSamsung's Music Studio 5 speakers at CES 2026.Billy Steele for EngadgetSamsung being Samsung, the company had a lot more up its sleeve at CES than just TVs. In the leadup to the event, it announced its two new soundbars (we're had some hands-on time with one of those) and the stylish Music Studio speakers (we've got some IRL impressions of those). It also announced plans to bring Google Photos to TVs.At the First Look showcase on Sunday, Samsung talked up \"AI experiences everywhere. For everyone\" (sigh). Here, we saw more TVs, such as the thin S95H OLED, which has a zero-gap mount that allows you to position the unit flush against a wall. First Look has long been focused on home products. Naturally, Samsung execs discussed some features for the company's fridges, such as ​​recipe selection updates, AI cooling tech and Google Gemini-powered AI Vision that's said to be able to recognize more items and help you figure out what you need to buy without having to manually take inventory. FoodNote, meanwhile, is a weekly summary that breaks down what has gone in and out of your fridge.Moreover, Samsung highlighted the Samsung Bespoke AI Laundry Combo and its new AI wash cycle. With the new Air Dresser — which has an Auto Wrinkle Care feature — Samsung aims to do away with irons (thank you, Samsung). As for the Bespoke AI smart vacuum and mop, that can apparently keep an eye on your pets when you're not home.L'OrealA pair of transparent eye masks with wires and bulbs inside them.L'Oréal L'Oreal often brings some interesting beauty tech to CES and the company did so again this year with a trio of gadgets. The LED Eye Mask uses red light and near-infrared light to address the likes of puffiness, discoloration and fine lines.The LED Face Mask seems to be a more pliable version of masks that we've seen from the likes of Dr. Dennis Gross, Omnilux, Therabody and Shark in recent years. However, it's only in prototype form for now and it isn't expected to hit the market until next year. The Light Straight + Multi-styler uses infrared light to help dry and style hair in similar fashion to L'Oreal's AirLight Pro. It's said to have sensors that employ \"built-in proprietary algorithms and machine learning\" so they can adapt to your gestures and \"maximize individual experience.\" L'Oreal claims that while traditional straighteners can operate at 400°F or higher (temperatures that can damage hair), its latest innovation \"effectively straightens hair while never exceeding 320°F.\" You can expect the Light Straight to arrive in 2027 as well.MobileSamsung Galaxy Z TriFold EngadgetAt CES 2026, we had our first chance to go hands on with the Samsung Galaxy Z TriFold, which the company officially announced last month. Senior writer Sam Rutherford had qualms about the price (not confirmed yet for North America, but it costs around $2,500 in Korea) and bulkiness. However, after Sam opened it up, “my concerns were quickly pushed aside because suddenly you’re greeted with 10 inches of vivid AMOLED goodness.” That extra real estate could come in very useful for many folks. Combined with a keyboard and perhaps a mouse, it could well be the laptop/tablet replacement many have been waiting for. Be sure to read Sam’s hands-on for his full initial impressions.Almost exactly three decades after releasing its first proper clamshell flip phone, Motorola revealed its very first side-folding phone. The Razr Fold has a 6.6-inch external screen and a 8.1-inch main display, with stylus support on both. The camera array includes a 50MP main sensor from Sony, a 50MP ultra-wide/macro lens and a 50MP telephoto. There’s a 32MP external selfie camera and a 20MP internal sensor too. We’ll get the full specs, pricing and availability info in the coming months.Back at CES 2024, we got to try out a physical keyboard phone accessory from Clicks. Fast forward two years, and the brand is making its own Blackberry-esque phones, as well as a new physical phone keyboard accessory. The Android 16-based Clicks Communicator has a tactile keyboard with a fingerprint sensor in the spacebar, a 4-inch OLED display, a 3.5mm headphone jack (hooray!) and expandable microSD storage up to 2TB. You can reserve one now for $399 — the price will increase to $499 on February 27.As for the new accessory, Clicks is calling that the Power Keyboard. It connects to an iOS or Android phone via MagSafe or Qi2, and it can operate as a power bank in a pinch thanks to the 2,150 mAh battery. The Power Keyboard has Bluetooth functionality as well, so you can use it with devices like tablets, smart TVs and virtual reality headsets. Pre-orders are open now and the Power Keyboard is expected to ship in the spring. Early adopters can lock in a pre-order for $79 before the retail price jumps to $110.The Punkt MC03 phone.PunktThose who prefer their mobile phones to have fewer bells and whistles might be interested in the latest model from Punkt. The MC03 is a nifty-looking touchscreen model that runs on the privacy- and security-centric AphyOS, which is based on the Android Open Source Project. It has a UI that borrows a page out of the Light Phone's playbook, though you can still install any Android app. The MC03 will hit European markets this month for €699 / CHF699 / £610. There's a mandatory subscription, however. You get a year of access included with a phone purchase, then it's a €10 / CHF10 / £9 monthly fee (paying for a long-term plan up front can reduce the cost by up to 60 percent).Charging techAnker and Belkin feel like CES mainstays at this point. They each had some interesting charging gear to show off this year. Belkin offered up a refreshed Nintendo Switch 2 case that recharges the console via its 10,000mAh power bank (which delivers up to 30W of fast charging). The case has an LCD screen on the outside to show you at a glance how much juice it has left and there’s a built-in kickstand for you to prop the console up on. Belkin’s new Switch 2 charging case costs $100 and it’s available now. The company’s new $100 UltraCharge Pro Power Bank can recharge two devices simultaneously. You can get your hands on that next month. There’s also a very slim BoostCharge power bank that can fit into your pocket. That will run you $60 and it will ship later this year. Anker Nano Charger (45W, Smart Display, 180° Foldable)AnkerAnker unveiled its neat Nano Charger, which can seemingly identify the iPhone model you hook up to it and provide the appropriate level of charging power. This plug will arrive later this month for $40. The company announced a string of other products that can charge multiple devices at the same time. The $150 foldable Prime Wireless Charging Station can juice up your iPhone, Apple Watch and AirPods simultaneously, with up to 25W of Qi2 wireless power. That’ll arrive by the end of March. There’s also a 10-in-1 Nano Power Strip ($70, late January release) with 70W of output, surge protection and multiple USB-C ports, USB-A ports and AC outlets. Anker also showed off a 13-in-1 Nano Docking Station that you can snag right now for $150. Among other things, this supports up to three 4K displays, as much as 100W of upstream charging and 10 Gbps of data transfer between devices that are hooked up to it. Handy!AI Amazon introduced Alexa.com to Alexa+ Early Access customers.AmazonNo prizes for guessing that there's going to be a ton of AI-related news at CES this year. Amazon, for one, announced that it's rolling out a web-based version of Alexa+. That means you won't necessarily need to have an Amazon device to try out the generative AI-powered assistant. However, Alexa+ Early Access customers are getting first dibs on the web version.Two Sweekar devices are pictured on a table, one wearing a pink and blue snowboarder outfit and the other (behind it) wearing a cowboy hat and outfitKarissa Bell for EngadgetThere are a boatload of AI-powered devices on the CES show floor too. One that we saw early on is a Tamagotchi-style virtual pet from a startup called Takway. The Sweekar will remember your interactions with it (you'll need to feed and play with the pet to keep it healthy and happy). Once it's all grown up, the Sweekar will head off on virtual adventures and tell you about its exploits when it \"returns.\" Takway will soon start a Kickstarter campaign for the Sweekar, which will likely cost between $100 and $150.Ludens AI's Cocomo robot,Cheyenne MacDonald for EngadgetLudens AI, meanwhile, showed off a pair of AI companion robots that are admittedly pretty cute. Cocomo can react to your voice and touch interactions, follow you around your home and learn about you over time. It stays close to human body temps, so it feels cozy if you hug it. Inu, on the other hand, stays on your desktop. It, too, responds to your voice and touch. The Fraimic art display at CESAmy Skorheim for EngadgetWe also saw the Fraimic, an E Ink display that can tap into OpenAI to generate images. There's no subscription for the Fraimic (which costs $399 for the standard size, which has a 13-inch display) and you get 100 AI-generated images per year included with your purchase. Pre-orders are open now and the Fraimic is expected to start shipping in this spring.MindClip held in a hand.Daniel Cooper for EngadgetSome companies are still trying to make wearable AI devices happen. SwitchBot has a wearable mic called the AI MindClip, which can seemingly record and transcribe everything you say (no, thank you!). Anker’s Soundcore division got in on the mix too with its Work voice recorder.Plaid, meanwhile, brought its NotePin follow up to the dance. This time around, the NotePin S has a button that you can push to record conversations. You can also press the button to flag key moments for an AI-generated summary to focus on. The NotePin S is available now for $179, should you be enticed to buy such a thing. On a similar note, Bee provided an update on what it’s bee-n up to since Amazon bought the company last year. It has developed four features that it’s rolling out to its existing AI voice recording wearable devices, including one that draft an email when you say you need to send one, and another that highlights trends in what you say over a period of weeks or months. There’s also a voice notes feature, because that’s something you can’t do with your phone already.RobotsThe product version of Boston Dynamics' Atlas.Boston DynamicsBoston Dynamics’ Atlas robot is ready to roll. We’ve seen a few iterations of this machine over the last few years and now the company’s latest model is set to go into production. In addition, Boston Dynamics has teamed up with Google DeepMind to fuse Gemini Robotics AI foundation models into Atlas robots. Per a press release, the partnership \"will focus on enabling humanoids to complete a wide variety of industrial tasks and is expected to become a driving force of manufacturing transformation, beginning in the automotive industry.\" As it happens, Hyundai (Boston Dynamics’ majority shareholder) and DeepMind will be among the first to receive Atlas robots.Switchbot's Onero H1.Karissa Bell for EngadgetLG’s CLOiD is still a concept helper robot for now, but the Onero H1 is one you may be able to buy as soon as this year. During an in-person demo, we saw Switchbot’s robot (slowly) pick up clothes, chuck them in a washing machine and close the door. The company has also released a video that shows the Onero H1 carrying out other household tasks, from serving food and drinks to washing windows. We’re told Switchbot plans to sell the robot for \"less than $10,000.\"TransportationSony Honda Mobility Afeela Press Conference at CES 2026 AfeelaSony and Honda brought the latest revision of their first Afeela EV to CES 2026. We already knew that you’d be able to play your PS5 remotely while the vehicle is parked, though we learned some new details from the companies’ presentation. The Afeela 1 will debut with an advanced hands-off, eyes-on driver assistance system. The aim is to eventually offer Level 4 autonomy via over-the-air updates. Sony Honda Mobility plans to start shipments at the tail end of 2026, first in California, then in Arizona. However, after getting a close-up look at the latest iteration of the EV, Engadget contributor Tim Stevens reckons the Afeela 1 feels “more and more out of touch” with each passing year, even though it “was an audacious product when it was announced at CES 2020.”We also got our first look at a model that’s a further down the pike. The Afeela Prototype 2026 is a taller version of the first EV. Just don’t expect to be able to try it yourself until at least 2028.MuxiSegwaySegway is expanding its e-bike lineup with two new models that have a heap of smart features, from Apple Find My integration and GPS tracking to remote locking and health app functions. The Muxi (above) looks quite pretty and has a cup holder(!), while the $2,000 Myon has a chunkier frame and features such as electronic gear shifting. Both are cargo-centric step-through models. You can buy the Myon now, and the $1,700 Muxi will be available in March, just in time for spring.Along with those e-bikes, Segway had a new electric dirt bike to tell us about. The Xaber 300 was created with off-roading in mind. There are three power modes, offering the equivalent of 150cc, 200cc and 300cc engines. Segway hasn’t revealed pricing for the Xaber 300, which should be available this spring or summer.Gaming Slide from NVIDIA's CES 2026 presentation about DLSS 4.5NVIDIANVIDIA announced the latest version of its DLSS (Deep Learning Super Sampling) upscaling tech. DLSS 4.5 is said to offer sharper visuals thanks to the 2nd Generation Super Resolution Transformer, which is available now for all RTX GPUs. NVIDIA says this offers better temporal stability, reduced ghosting and improved anti-aliasing.On GeForce RTX 50 Series GPUs, DLSS 4.5 will be able to generate up to five extra frames for each traditionally rendered one and deliver up to 4K 240Hz path traced performance, NVIDIA says. The Dynamic 6x Frame Generation feature will be available for those graphics cards sometime this spring.NVIDIA also detailed a new version of its G-Sync variable refresh rate tech. It says that G-Sync Pulsar can minimize motion blur by effectively quadrupling your refresh rate. So 250 Hz gameplay will seemingly offer up a perceived effective motion clarity of over 1,000 Hz with G-Sync Pulsar enabled. You’ll need a G-Sync Pulsar-compatible display to use this feature. Most displays have a backlight that’s always on, so images fade from one frame to the next. On G-Sync Pulsar displays, there are several horizontal backlight sections. The backlights pulse from top to bottom. This is said to help the pixels in each frame stabilize before they’re backlit, resulting in lower motion blur. It’s interesting stuff. Acer, AOC, ASUS and MSI are each releasing a G-Sync Pulsar-compatible 27-inch monitor this week.8BitDo FlipPad8BitDoThe FlipPad is one of my favorite things I’ve seen coming out of CES this year. It’s an 8BitDo mobile game controller that’s designed for vertical use. There are a bunch of neat physical controllers for phones that are built for landscape mode. But many mobile games are played with the phone oriented to the vertical position. And that’s not to mention emulators that allow you to play the likes of Game Boy titles while your phone stands tall. So it’s neat to see 8BitDo offering a physical controller that’ll do the trick. The company also unveiled a new Xbox controller with swappable joysticks and button modules.A keyboard thing.CorsairWhy have a numpad on the side of your keyboard when you can have a highly customizable controller instead? Corsair slapped a Stream Deck into a keyboard and it looks absolutely rad. I’ve yet to take the plunge on a Stream Deck-style controller and since I’d rather not have an extra device on my desk, I’m very tempted to pick up the $350 Galleon 100 SD, which is available now.It has 12 programmable keys that you can use for gaming (give me that Helldivers 2 profile so I don’t have to keep punching in stratagem codes) or livestreaming, but there are plenty of other applications too. They can help with video editing, controlling smart home devices or simply adjusting media playback. There’s a five-inch screen and two dials for fine control too. Oh, and it’s a full-sized mechanical keyboard to boot.GameSir had a couple of interesting controllers to tell us about. The Swift Drive (which seems to be a working name) has a steering wheel with force feedback in the middle of a regular gamepad. It’s a cool idea and it seems to work pretty well. The Swift Drive should hit the market later this year. In addition, GameSir teamed up with Hyperkin to make a modular controller that works with phones, tablets and Nintendo Switch consoles. You’ll be able to slot those devices into the X5 Alteron’s grip (as you might with a Backbone or Razer Kishi controller) though there’s a Bluetooth option for PC gaming too. The magnetic modules include ones styled after the GameCube and Nintendo 64, and there’ll be one with a trackpad that’s made with first-person shooters in mind. There’s no pricing or release date for the X5 Alteron yet, but I’m eager to try it.Elsewhere on the gaming front, Lenovo revealed a SteamOS-powered version of the Legion Go 2. That variant of the handheld is heading your way in June for $1,199. Razer had some concept gear to show off, including an AI-driven headset with built-in cameras that can recognize objects and text, and a gaming chair with haptic feedback and spatial audio built in. There’s also an AI desktop companion device with several avatars to choose from, including an anime girl and legendary League of Legends player Faker.AudioA speaker and a turntable.Victrola Victrola announced a pretty Bluetooth speaker that sits neatly underneath its turntables. You can use a cable to connect the two as well. Of course, you can play audio from other devices, including phones and tablets. I’ve had my eye on a Victrola turntable for a while thanks to its Sonos integration, and the Soundstage speaker is tempting too. The Soundstage will be available this summer for $350. The three sizes from the Cambridge Audio L/R speaker series. Green speakers in three sizes.Cambridge AudioSpeaking of pretty speakers, I really like the aesthetic of these three wireless bookshelf options from Cambridge Audio. The classy-lookin’ L/R Series speakers start at $549 for a 100W model with a 21mm hard-dome tweeter with a 3-inch long-throw woofer hut no support for Wi-Fi streaming (there is Bluetooth aptX HD, though). At the top end is the $2,299 L/R X, a 800W speaker that has a a 2.5-way acoustic design with a 28mm Torus tweeter and dual five-inch woofers. There’s even a touch of LED underlighting on this model and the $1,599 L/R M, which has 300W of power, smaller four-inch dual woofers and the same 28mm tweeter. All three speakers will be available later this year.There’s lots more audio gear at CES beyond the Victorla and Cambridge Audio speakers, of course. JBL was at the event to show off a whole bunch of earbuds and gaming headsets. Shure now has a USB-C version of its MV88 condenser microphone, making it compatible with Android devices and recent iPhones. That’ll run you $159. The latest version of JLab’s teeny JBuds Mini earbuds now have customizable active noise cancellation (ANC) and yet they still cost $40. PartyStudio is a speaker with 128 different instrument sounds that works with any MIDI keyboard.Nathan Ingraham for EngadgetPartyStudio seems like a fun product — it’s a MIDI speaker with 128 built-in instrument tones and 50-plus drum machine patterns. There’s a companion 36-key MIDI keyboard called PartyKeys as well (the speaker will work with any MIDI keyboard, though). PopuMusic is the company behind both.Anker, meanwhile, has new AeroFit 2 Pro earbuds that are pretty interesting. They’re the company’s first open-ear earbuds with ANC. You can snap them up in February for $180. There’s also a new portable Bluetooth speaker from Anker called the Soundcore Boom Go 3i. It’s a 15W unit with (according to Anker) up to 22 hours of battery life, and it should cost between $65 and $80 when it drops in March. Engadget deputy editor Billy Steele has been checking out some of the audio gear at CES, including Shokz’ $250 OpenFit Pro earbuds, which have Dolby Atmos support. Billy has also had some hands-on (or heads-on) time with Klipsch’s first new headphones in years. There are initially three models in the company’s Atlas series, including the Atlas HP-1, a wireless set with ANC that has a lovely wood finish on the exterior of the earcups. Klipsch is only allowing demos with lossless audio over USB-C for now, but the audio quality is “excellent,” Billy wrote in his hands-on story. Smart homeDreame Cyber X robot vacuumEngadgetAs ever, there was a ton of smart home gear at CES this year. One thing that caught our eye is a robot vacuum concept from Dreame. It's one of several companies working on models that can climb stairs, but the Cyber X is a slightly terrifying one since it has large legs that look a bit like chainsaws. The teeth in these legs help provide traction so that the Cyber X can climb stairs that are almost 10 inches high. While Dreame’s vacuum positions its legs horizontally to climb stairs with tank-style traction, Roborock’s Saros rover pushes itself upwards on extendable legs to reach higher floors. The legs have wheels on the bottom and knee-like joints — these can help the robot vacuum to raise itself over obstacles on floors too.Narwhal built a vacuum for your mattress. The U50 is a handheld model that has a UV sterilization light. It has a high-speed tapping feature that can help dislodge gunk and mites. The company also showed off a new robot vacuum and mop with a \"PetCare Mode\" you can use to track down your bestest furry friend and keep an eye on them when you're not home. You can even talk to your pet via a speaker system. Both products should be available in the spring.Anker's Eufy brand has a new robot vacuum too, along with a video doorbell, outdoor light and smart lock. This one’s pretty interesting: Lockin’s latest vein-recognition smart lock can wirelessly recharge via an optical infrared beam emitted by a separate device that’s plugged into an outlet.On a similar note, Ring has updated its door, window and break glass sensors, and it has introduced an OBD-II car alarm, motion detectors and panic buttons. Most of those will be available in March, though can pre-order the car alarm now.Elsewhere in home security, Ugreen announced a modular system that does not require a subscription. At a time when so many companies are desperate to sell you a subscription for dependable monthly revenue, that’s quite refreshing. Devices that are part of Ugreen’s platform — including a video doorbell and 4K cameras — should be available later this year.IKEA made its CES debut to show off some of its smart home tech, namely a string of budget-friendly, Matter-compatible devices. Along with some home sensors, the company plans to offer a $6 smart bulb, an $8 smart plug and a $6 smart remote in the coming weeks. Senior reporter Amy Skorheim checked out the products and particularly liked the BILREA remote, which you can use to control IKEA's lamps and other devices.Philips Hue SpatialAware featureSpeaking of smart bulbs, Philips announced some Hue updates at CES. You'll need a Hue Bridge Pro to use the SpatialAware feature, which uses augmented reality to make sure all of the lights in a room are working together harmoniously to create, for instance, a more natural-looking sunset scene. Philips will be rolling out SpatialAware to Hue users this spring. Also on the way is Apple Home support for the Hue Secure Camera, Hue Secure video doorbell and Hue contact sensors.Elsewhere in lighting, Govee has a new floor lamp, as well as a ceiling light that's said to simulate a skylight.In terms of kitchen tech, GE Appliances has a new smart refrigerator that's designed to make restocking easier. It has a built-in barcode scanner you can use to quickly add items to a shopping list. It's possible to sync the items to Instacart for grocery delivery. There's also an interior camera that can help you keep tabs on the goods in your fridge's crisper drawer. As you might expect for a smart fridge, it has a touchscreen on the door that you can use to call up recipes. The GE Profile Smart Refrigerator will be available in April for $4,899.NoshDaniel Cooper for EngadgetNosh, meanwhile, is an AI cooking robot that you'll be able to buy in the next few months. Load it with ingredients, pick one of the 500 dishes in Nosh's repertoire and the robot will put everything together. While it has water and oil reservoirs, as well as a built-in spice rack, you'll still need to prep the fresh ingredients before adding them to the machine. Nosh will cost $2,000 but if you're ready to pre-order now, you can snag one for an early bird price of $1,200.Moving outside, Whisper Aero claims that the T1 leaf blower (from its Tone Outdoors division) is 80 percent quieter and 60 percent more powerful than “leading gas handheld blowers.” That seems pretty great on paper, so here’s hoping that your noisy neighbors will be convinced to shell out $599 for a T1 when it arrives in September. Meanwhile, Segway’s Navimow unit has a bunch of new robot mowers. Health and accessibilityImage of the Throne Toilet Computer perched on the side of a toilet.Daniel Cooper for EngadgetIt perhaps shouldn’t come as a surprise that a toilet computer made an appearance in our roundup of weird CES tech. But if I’ve learned anything from watching Scrubs, it’s that our waste offers up a lot of revealing information about our health, so Throne is a pretty compelling device. It has a camera and microphone to track your bowel motions and urination levels. The idea is to figure out your regular toilet usage and then flag any deviations from that. The creators hope that Throne will help you gain a better understanding of your gut health, which could be beneficial for those on GLP-1 drugs, for instance. Throne will start shipping in February for $340 and a $6 per month subscription.Image of Vivoo's FlowPadVivooVivoo also showed off a toilet device that can monitor your urination levels. Not only that, the company unveiled a smart menstrual pad. The idea is for for wearers to scan the pad with their phone camera after use.Elsewhere, the latest version of Withing’s Body Scan scale can track 60 biomarkers, up from the 40 that the first model from 2023 can keep tabs on. The Body Scan 2 should be available in the spring for $600.A man sits in a manual wheelchair with an add-on attached that gives it a large central front wheel and raises the casters off the groundCheyenne MacDonald for EngadgetAccessibility tech is a welcome sight at CES, and WheelMove looks like it could be useful for many wheelchair users. It’s a device with a large front wheel that can quickly be attached to any manual wheelchair. It can then raise the wheelchair’s smaller front wheels off the ground, primarily to help users navigate rough terrain. The $6,000 WheelMove will debut in France later their year before a broader rollout.ReviMo has built a robotic lift that it says can help people move themselves from (for instance) a bed to a wheelchair without the assistance of a caregiver. The company expects Niko to cost around $15,000, but it’s attempting to get the device covered by insurance.Dephy's Sidekick, which the company describes as \"bionic footwear.\"Karissa Bell for EngadgetDephy’s Sidekick is designed as a walking aid. It’s an ankle-worn exoskeleton that’s attached to a sneaker. The Sidekick has sensors that can detect the user’s gait and adapt to it in order to deliver an effective boost in each step. At $4,500, the Sidekick isn’t cheap, but it could be a boon for those who are perhaps not as physically active as they’d like to be. Dephy is also adapting the tech for athletic use — the company is working with Nike on a robotic sneaker project.This article originally appeared on Engadget at https://www.engadget.com/general/all-the-tech-and-gadgets-announced-at-ces-2026-130124023.html?src=rss",
          "content": "It's the first week of a new year and there's no time for the tech world to slowly ease back into things following the holidays. That's because CES 2026 is in full swing, with all manner of companies descending on Las Vegas to reveal their latest innovations and what they're planning to bring your way in the near future. Many of the Engadget crew are on the ground to check out as much of the new tech as possible. Of course, we're keeping tabs on all of the major CES press conferences too. Samsung held its First Look presentation, which focuses on home products, while LG has shown off a wide array of TVs and Lego unveiled its new Smart Brick technology. We’ve heard from the major chipmakers, gone hands-on with Samsung’s trifold phone, checked out some funky laptops and seen some cute robots. There’s some hot gaming gear at the show too, not to mention some weird tech.You don’t necessarily have to wait to get your hands on all of these gadgets either. Some are available to buy right now.You can catch up on all of the big CES 2026 announcements (and some of the more offbeat gizmos we’ve seen) right here. We'll be keeping this story updated throughout the week. We also have CES live updates, with all the latest news from the event.LegoLego introduced the Smart Brick at CES 2026.LegoIn its first CES appearance, Lego announced the Smart Brick, a standard-sized brick with a 4.1mm ASIC chip inside that’s designed to respond in different ways depending on what set you’re building and how you’re building it. Using what Lego calls the “Play Engine” and integrated copper coils, each brick can sense things like motion, orientation and magnetic fields, plus its own distance, direction and orientation in relation to other Smart Bricks. Each brick also has a teeny tiny speaker built in that will play audio “tied to live play actions” rather than only pre-recorded clips.Accompanying Smart Bricks are Smart Tags and Smart Minifigures, which have their own capabilities — one of which is letting Smart Bricks know what context they are being used in. All of these pieces tie together via a local wireless layer dubbed BrickNet that, in part, lets Smart Bricks know where they are placed in relation to other smart components. The first “Smart Play” partner is, unsurprisingly, Star Wars, which will launch three “all-in-one” sets using Smart Bricks, Smart Tags and Smart Minifigures. The 473-piece Darth Vader TIE Fighter set will cost $70; the 584-piece Luke’s Red Five X-Wing set comes in at $100 and the 962-piece Throne Room Duel & A-wing set will set you back $160. The speakers in these sets can emit lightsaber swooshes, fighter sounds and The Imperial March.Engadget deputy editor Nathan Ingraham got to check out Lego’s Smart Play system in person and I’ve never been more envious of him. One of the Star Wars sets allows you to have an interactive lightsaber duel between Luke Skywalker and Darth Vader. Not only does the Vader minifigure have his signature heavy breathing sound, the speaker emits the Sith Lord’s “nooooo” yell if he loses the duel.All of this seems extremely cool. I'm looking forward to seeing what else Lego and fans can do with the Smart Play tech.LGLG's CLOiD robot.LGAlong with some TVs (which we’ll get to momentarily), LG brought plenty of other products to CES. For one thing, the company shone the spotlight on its CLOiD robot. Like the far creepier-looking 1X Neo, the CLOiD is designed to help with household tasks such as starting laundry cycles, folding clothes, unloading the dishwasher and serving food. This appears to be more of a concept than something you'll be able to buy anytime soon. During an in-person CES demo, Engadget senior reporter Karissa Bell saw CLOiD competently pull off some household tasks, albeit very slowly.The company also debuted the LG Sound Suite, a modular home audio system it developed in conjunction with Dolby to take on the likes of Sonos. Just ahead of CES, LG pulled back the curtain on a new batch of xboom speakers as well as some monitors and ultralight Gram laptops that are made with a material it's calling Aerominum. The chipmakersNVIDIA CEO Jensen Huang presents at CES 2026, wearing a black snakeskin-like jacket.NVIDIAIt's CES, so of course we're going to see a bunch of laptops and desktops, along with announcements about the tech that powers the new models. That means NVIDIA, Intel, AMD and Qualcomm are all in town to talk up their latest chips and other innovations.Given its lofty position in the industry (and the economy) NVIDIA’s CES press conference is always one to keep an eye on. This year’s edition was laregly a recap of the company’s recent moves, but it did have some news to share.NVIDIA announced Alpamayo, which is a group of open-source reasoning models designed to help autonomous vehicles handle difficult driving scenarios. The company also revealed that a super computer built on the Vera Rubin GPU architecture NVIDIA unveiled in 2024 is in production. As Intel wraps up, Johnson is eager to assure the viewers that Intel has ways to make AI profitable. He may have a better case than OpenAI does right now.Sam Chapman for EngadgetThings haven’t exactly been going great for Intel for a while, but the company is surely hoping that its Core Ultra Series 3 chips can help it right the ship. These are the first chips to be built using Intel’s 18A (18 angstroms, which is just under 2nm) process. The company says they offer improved performance — 60 percent more than the previous-gen Lunar Lake processors — and battery life improvements for laptops. The Ultra Series 3 includes a new Arc B390 integrated GPU, with 50 percent more graphics cores, double the cache and 120 GPU TOPS of performance. Put all that together and these chips should deliver up to 77 percent faster gaming performance than Lunar Lake models, Intel said. To that end, the company teased a Ultra Series 3-powered gaming handheld for later this year.Engadget senior editor Devindra Hardawar played some Battlefield 6 on a Core Ultra Series 3-powered Lenovo IdeaPad Pro 5 (an ultraportable) and came away impressed. The game ran at up to 190 fps in 1080p with the graphics settings on high, even without a dedicated GPU. That’s a promising sign for the embedded Arc graphics on Intel’s chips, as well as the company’s upscaling and frame generation tech.A screenshot from AMD's CES 2026 press conference showing a hellish vision of the future of gaming.AMDOf course, AMD wasn’t going to be left out of the CES party. The company announced several CPUs for laptops and desktops, while chillingly declaring that “AI is everywhere” and “changing the face of gaming.” Ick. There was a lot of AI chat during the two-hour(!) keynote, along with a “a jet-powered flying robot.” Illustration showing the Qualcomm Snapdragon X2 Plus on a stylized red circuit board showing the abbreviation \"X2.\"QualcommAnd then there’s Qualcomm. The company revealed the Snapdragon X2 Plus chip at the show. It’s more of a mid-range chip that isn’t quite as powerful as the higher end Snapdragon X2 Elite — it doesn’t have as many CPU cores, for one thing. Still, Qualcomm claims the X2 Plus offers as much as 35 percent faster single-core performance over the previous gen. The company also says the Adreno GPU offers a performance boost of up to 29 percent compared with the last generation.Laptops Samsung Galaxy Book 6 series hands-onMat Smith for EngadgetWhat would CES be without some new hardware that makes use of those new chips? As ever, laptop and desktop makers were at the show to offer up their latest models for your consideration. (Be sure to check out our dedicated roundup of all the laptops that grabbed our attention at this year’s show.)Samsung’s Galaxy Book 6 Ultra, Galaxy Book 6 Pro and Galaxy Book 6 boast Intel’s Core Ultra Series 3 chips and revamped designs that are said to improve heat management. You can read our story on the Galaxy Book 6 series for the specs of these laptops, though we don’t have pricing or a release window as yet.Dell realized it messed up by killing off the XPS name as part of a broader rebranding effort and we’re glad to see that the company is making a U-turn on that front. A full lineup of XPS laptops is coming this year, including an all-new XPS 13 (a long-time Engadget fave on the Windows ultraportable front). Dell also has 14- and 16-inch XPS models in the hopper, along with others it’s keeping under wraps for now.On top of having two displays, the Zephyrus Duo's screens also feature excellent brightness at up to 1,100 nits.We love an odd laptop and ASUS didn’t disappoint by bringing the ROG Zephyrus Duo to CES. This is a dual-screen gaming laptop with two 16-inch OLED panels, one of Intel’s new CPUs and up to an NVIDIA RTX 5090 GPU. The keyboard is detachable and can work wirelessly. A kickstand can help you set up the Zephyrus Duo in all kinds of orientations. You can even position the dual screens in an upside-down “V” tent mode. We don’t know the price of the Zephyrus Duo as yet, but it surely won’t be inexpensive.Marketing photo of a Kojima-inspired ROG Flow Z13 tabletASUSThat’s not all ASUS brought to the dance. The company made a special edition of the ROG Flow Z13 some that’s styled after the works of the famed game designer Hideo Kojima. The ROG Flow Z13-KJP has visual flair that’s draws from the likes of Death Stranding and Metal Gear. Kojima’s Ludens mascot is here too. There’s no pricing or release date for this variant or its matching accessories just yet.Micro RGB TVs Samsung's 130-inch Micro RGB TV. Devindra Hardawar for EngadgetMicro RGB is a term you can expect to hear about quite a bit in the coming months and years, especially when you're shopping for your next TV. Micro RGB is a new tech that's similar to Mini LED, though it uses red, green and blue LEDs instead of white backlights. Contrast ratios aren't quite as high as those on Micro LED and OLED displays, since the pixels can't be turned on and off individually. However, Micro RGB units are said to be brighter and more color accurate than TVs that use other display tech, in part because the LEDs in these screens offer smaller, more customizable dimming zones. Read reporter Steve Dent’s explainer for a deeper dive into how Micro RGB differs from other types of display tech.We're seeing more of these TVs pop up at CES 2026, including a mammoth 130-inch concept model that Samsung brought to Las Vegas. The company unveiled its first Micro RGB TV in August, — that’s a 115-inch, $29,999 model. This year, you can expect it to start offering Micro RGB TVs in 55-, 65- and 75-inch sizes. There are also 85-, 100- and 115-inch models on the way.LG revealed its first Micro RGB set at CES as well. The largest variant is 100 inches, but there are 86- and 75-inch models too. Elsewhere, LG showed off its latest Wallpaper TV, which is a 100-inch OLED display. We also got a look at LG's new Gallery TV — The Gallery is the company's take on Samsung's Frame TV format.Other new TVs and OS updatesEmber Artline TV.AmazonWe’ve got another competitor to The Frame, as Amazon has entered that scene with the Ember Artline TV. The 4K OLED model has Amazon Photos integration and you can choose from 2,000 pieces of free art to show on the screen. The Ember Artline can switch on or off automatically when someone enters or leaves the room. It runs on the Fire TV platform and (of course) there’s Alexa+ integration, along with support for Dolby Vision, HDR10+ and Wi-Fi 6. The Ember Artline is expected to start shipping this spring. It starts at $899 for the 55-inch model.The rounder redesigned Fire TV UI.AmazonSpeaking of Fire TV, Amazon has revamped the platform’s user interface with rounded corners for show, movie and app tiles; a little more space for said tiles; and typography and color gradient changes. The company has reworked the platform’s codebase as well, and it says the Fire TV OS will deliver speed boosts of up to 20 to 30 percent. Amazon will start rolling out the updated UI next month.On the Google side of TV land, you can expect more Gemini-powered features. The company is bringing the ability to search Google Photos for certain moments and people to Google TV, along with the options to remix photos into different styles and create slideshows on the fly. The Veo and Nano Banana AI video and photo generation models are coming to Google TV as well. You can also expect the ability to adjust TV settings using your voice. These Gemini features are coming to Google TV-powered TCL models first, then other devices in the following months. In the meantime, you can check out senior reporter Amy Skorheim’s hands-on impressions of the Gemini updates.Also in TV-related news, Peacock and Dolby have expanded their partnership. Currently, Peacock’s Sunday Night Football streams have Dolby Atmos support. You’ll soon be able to watch more live sports on Peacock with Dolby Vision and Atmos, as support for NBA and MLB events are on the way. Dolby Vision is coming to Sunday Night Football on Peacock too. Belkin, meanwhile, has a new wireless HDMI dongle that doesn't require a Wi-Fi connection. That should make it easy to beam videos from a device with a USB-C port to a TV, monitor or projector — handy if you’re planning an outdoor movie night in a space with spotty internet access.Monitors and projectorsLet's keep the focus on display tech for a bit with a look at some of the monitors and projectors we've seen at CES this year. Dell revealed a 52-inch ultrawide curved 6K monitor (the first of those on the planet, according to the company). The UltraSharp 52 Thunderbolt Hub Monitor has a nifty feature in that it's possible to hook up four PCs simultaneously and give each a dedicated section of the display — that could make co-op games pretty fun if you're dedicated enough to try that set up. It's possible to control all four connected PCs with a single mouse and keyboard too. This monitor is available now for $2,900 with a stand and $2,800 without.Dell also showed off a new 32-inch 4K QD-OLED monitor with Dolby Vision and True Black 500 HDR support. The Dell UltraSharp 32 4K QD-OLED Monitor can be all yours for $2,600 as of February 24.Samsung and LG revealed some new gaming monitors ahead of CES. Samsung’s 32-inch Odyssey 3D is a model that offers glasses-free 3D on a 6K display, while LG has a new bunch of 5K monitors. During CES , though, the latter also pulled back the curtain on the 27-inch UltraGear GX7, a $1,000 QHD OLED display with a 540Hz refresh rate.Samsung brought the latest version of its FreeStyle+ projector to the show. Engadget’s UK bureau chief Mat Smith checked out the new model in person and reckoned that Samsung has given the projector a serious upgrade over previous iteration. The FreeStyle+ is now much brighter, while the updated keystone correction feature seems very useful.Elsewhere, Anker’s Soundcore announced the Nebula P1i, a 1080p portable projector with speakers that you can fold out and tilt. At $369, that seems like a pretty decent option if you’re looking for an entry-level projector you can take anywhere. The P1i should arrive in time for camping trips too, since Soundcore says it’ll be available in the early part of this year. The brand also said its higher-end Nebula X1 Pro, a version of its 4K Nebula X1 that includes a 160W surround sound system, will be available this month for $4,999.XGIMI was also at CES to show off its latest high-end projector, the Titan Noir Max. There’s no word on pricing yet, but this appears to be an upgraded version of the $3,999 Titan model.SamsungSamsung's Music Studio 5 speakers at CES 2026.Billy Steele for EngadgetSamsung being Samsung, the company had a lot more up its sleeve at CES than just TVs. In the leadup to the event, it announced its two new soundbars (we're had some hands-on time with one of those) and the stylish Music Studio speakers (we've got some IRL impressions of those). It also announced plans to bring Google Photos to TVs.At the First Look showcase on Sunday, Samsung talked up \"AI experiences everywhere. For everyone\" (sigh). Here, we saw more TVs, such as the thin S95H OLED, which has a zero-gap mount that allows you to position the unit flush against a wall. First Look has long been focused on home products. Naturally, Samsung execs discussed some features for the company's fridges, such as ​​recipe selection updates, AI cooling tech and Google Gemini-powered AI Vision that's said to be able to recognize more items and help you figure out what you need to buy without having to manually take inventory. FoodNote, meanwhile, is a weekly summary that breaks down what has gone in and out of your fridge.Moreover, Samsung highlighted the Samsung Bespoke AI Laundry Combo and its new AI wash cycle. With the new Air Dresser — which has an Auto Wrinkle Care feature — Samsung aims to do away with irons (thank you, Samsung). As for the Bespoke AI smart vacuum and mop, that can apparently keep an eye on your pets when you're not home.L'OrealA pair of transparent eye masks with wires and bulbs inside them.L'Oréal L'Oreal often brings some interesting beauty tech to CES and the company did so again this year with a trio of gadgets. The LED Eye Mask uses red light and near-infrared light to address the likes of puffiness, discoloration and fine lines.The LED Face Mask seems to be a more pliable version of masks that we've seen from the likes of Dr. Dennis Gross, Omnilux, Therabody and Shark in recent years. However, it's only in prototype form for now and it isn't expected to hit the market until next year. The Light Straight + Multi-styler uses infrared light to help dry and style hair in similar fashion to L'Oreal's AirLight Pro. It's said to have sensors that employ \"built-in proprietary algorithms and machine learning\" so they can adapt to your gestures and \"maximize individual experience.\" L'Oreal claims that while traditional straighteners can operate at 400°F or higher (temperatures that can damage hair), its latest innovation \"effectively straightens hair while never exceeding 320°F.\" You can expect the Light Straight to arrive in 2027 as well.MobileSamsung Galaxy Z TriFold EngadgetAt CES 2026, we had our first chance to go hands on with the Samsung Galaxy Z TriFold, which the company officially announced last month. Senior writer Sam Rutherford had qualms about the price (not confirmed yet for North America, but it costs around $2,500 in Korea) and bulkiness. However, after Sam opened it up, “my concerns were quickly pushed aside because suddenly you’re greeted with 10 inches of vivid AMOLED goodness.” That extra real estate could come in very useful for many folks. Combined with a keyboard and perhaps a mouse, it could well be the laptop/tablet replacement many have been waiting for. Be sure to read Sam’s hands-on for his full initial impressions.Almost exactly three decades after releasing its first proper clamshell flip phone, Motorola revealed its very first side-folding phone. The Razr Fold has a 6.6-inch external screen and a 8.1-inch main display, with stylus support on both. The camera array includes a 50MP main sensor from Sony, a 50MP ultra-wide/macro lens and a 50MP telephoto. There’s a 32MP external selfie camera and a 20MP internal sensor too. We’ll get the full specs, pricing and availability info in the coming months.Back at CES 2024, we got to try out a physical keyboard phone accessory from Clicks. Fast forward two years, and the brand is making its own Blackberry-esque phones, as well as a new physical phone keyboard accessory. The Android 16-based Clicks Communicator has a tactile keyboard with a fingerprint sensor in the spacebar, a 4-inch OLED display, a 3.5mm headphone jack (hooray!) and expandable microSD storage up to 2TB. You can reserve one now for $399 — the price will increase to $499 on February 27.As for the new accessory, Clicks is calling that the Power Keyboard. It connects to an iOS or Android phone via MagSafe or Qi2, and it can operate as a power bank in a pinch thanks to the 2,150 mAh battery. The Power Keyboard has Bluetooth functionality as well, so you can use it with devices like tablets, smart TVs and virtual reality headsets. Pre-orders are open now and the Power Keyboard is expected to ship in the spring. Early adopters can lock in a pre-order for $79 before the retail price jumps to $110.The Punkt MC03 phone.PunktThose who prefer their mobile phones to have fewer bells and whistles might be interested in the latest model from Punkt. The MC03 is a nifty-looking touchscreen model that runs on the privacy- and security-centric AphyOS, which is based on the Android Open Source Project. It has a UI that borrows a page out of the Light Phone's playbook, though you can still install any Android app. The MC03 will hit European markets this month for €699 / CHF699 / £610. There's a mandatory subscription, however. You get a year of access included with a phone purchase, then it's a €10 / CHF10 / £9 monthly fee (paying for a long-term plan up front can reduce the cost by up to 60 percent).Charging techAnker and Belkin feel like CES mainstays at this point. They each had some interesting charging gear to show off this year. Belkin offered up a refreshed Nintendo Switch 2 case that recharges the console via its 10,000mAh power bank (which delivers up to 30W of fast charging). The case has an LCD screen on the outside to show you at a glance how much juice it has left and there’s a built-in kickstand for you to prop the console up on. Belkin’s new Switch 2 charging case costs $100 and it’s available now. The company’s new $100 UltraCharge Pro Power Bank can recharge two devices simultaneously. You can get your hands on that next month. There’s also a very slim BoostCharge power bank that can fit into your pocket. That will run you $60 and it will ship later this year. Anker Nano Charger (45W, Smart Display, 180° Foldable)AnkerAnker unveiled its neat Nano Charger, which can seemingly identify the iPhone model you hook up to it and provide the appropriate level of charging power. This plug will arrive later this month for $40. The company announced a string of other products that can charge multiple devices at the same time. The $150 foldable Prime Wireless Charging Station can juice up your iPhone, Apple Watch and AirPods simultaneously, with up to 25W of Qi2 wireless power. That’ll arrive by the end of March. There’s also a 10-in-1 Nano Power Strip ($70, late January release) with 70W of output, surge protection and multiple USB-C ports, USB-A ports and AC outlets. Anker also showed off a 13-in-1 Nano Docking Station that you can snag right now for $150. Among other things, this supports up to three 4K displays, as much as 100W of upstream charging and 10 Gbps of data transfer between devices that are hooked up to it. Handy!AI Amazon introduced Alexa.com to Alexa+ Early Access customers.AmazonNo prizes for guessing that there's going to be a ton of AI-related news at CES this year. Amazon, for one, announced that it's rolling out a web-based version of Alexa+. That means you won't necessarily need to have an Amazon device to try out the generative AI-powered assistant. However, Alexa+ Early Access customers are getting first dibs on the web version.Two Sweekar devices are pictured on a table, one wearing a pink and blue snowboarder outfit and the other (behind it) wearing a cowboy hat and outfitKarissa Bell for EngadgetThere are a boatload of AI-powered devices on the CES show floor too. One that we saw early on is a Tamagotchi-style virtual pet from a startup called Takway. The Sweekar will remember your interactions with it (you'll need to feed and play with the pet to keep it healthy and happy). Once it's all grown up, the Sweekar will head off on virtual adventures and tell you about its exploits when it \"returns.\" Takway will soon start a Kickstarter campaign for the Sweekar, which will likely cost between $100 and $150.Ludens AI's Cocomo robot,Cheyenne MacDonald for EngadgetLudens AI, meanwhile, showed off a pair of AI companion robots that are admittedly pretty cute. Cocomo can react to your voice and touch interactions, follow you around your home and learn about you over time. It stays close to human body temps, so it feels cozy if you hug it. Inu, on the other hand, stays on your desktop. It, too, responds to your voice and touch. The Fraimic art display at CESAmy Skorheim for EngadgetWe also saw the Fraimic, an E Ink display that can tap into OpenAI to generate images. There's no subscription for the Fraimic (which costs $399 for the standard size, which has a 13-inch display) and you get 100 AI-generated images per year included with your purchase. Pre-orders are open now and the Fraimic is expected to start shipping in this spring.MindClip held in a hand.Daniel Cooper for EngadgetSome companies are still trying to make wearable AI devices happen. SwitchBot has a wearable mic called the AI MindClip, which can seemingly record and transcribe everything you say (no, thank you!). Anker’s Soundcore division got in on the mix too with its Work voice recorder.Plaid, meanwhile, brought its NotePin follow up to the dance. This time around, the NotePin S has a button that you can push to record conversations. You can also press the button to flag key moments for an AI-generated summary to focus on. The NotePin S is available now for $179, should you be enticed to buy such a thing. On a similar note, Bee provided an update on what it’s bee-n up to since Amazon bought the company last year. It has developed four features that it’s rolling out to its existing AI voice recording wearable devices, including one that draft an email when you say you need to send one, and another that highlights trends in what you say over a period of weeks or months. There’s also a voice notes feature, because that’s something you can’t do with your phone already.RobotsThe product version of Boston Dynamics' Atlas.Boston DynamicsBoston Dynamics’ Atlas robot is ready to roll. We’ve seen a few iterations of this machine over the last few years and now the company’s latest model is set to go into production. In addition, Boston Dynamics has teamed up with Google DeepMind to fuse Gemini Robotics AI foundation models into Atlas robots. Per a press release, the partnership \"will focus on enabling humanoids to complete a wide variety of industrial tasks and is expected to become a driving force of manufacturing transformation, beginning in the automotive industry.\" As it happens, Hyundai (Boston Dynamics’ majority shareholder) and DeepMind will be among the first to receive Atlas robots.Switchbot's Onero H1.Karissa Bell for EngadgetLG’s CLOiD is still a concept helper robot for now, but the Onero H1 is one you may be able to buy as soon as this year. During an in-person demo, we saw Switchbot’s robot (slowly) pick up clothes, chuck them in a washing machine and close the door. The company has also released a video that shows the Onero H1 carrying out other household tasks, from serving food and drinks to washing windows. We’re told Switchbot plans to sell the robot for \"less than $10,000.\"TransportationSony Honda Mobility Afeela Press Conference at CES 2026 AfeelaSony and Honda brought the latest revision of their first Afeela EV to CES 2026. We already knew that you’d be able to play your PS5 remotely while the vehicle is parked, though we learned some new details from the companies’ presentation. The Afeela 1 will debut with an advanced hands-off, eyes-on driver assistance system. The aim is to eventually offer Level 4 autonomy via over-the-air updates. Sony Honda Mobility plans to start shipments at the tail end of 2026, first in California, then in Arizona. However, after getting a close-up look at the latest iteration of the EV, Engadget contributor Tim Stevens reckons the Afeela 1 feels “more and more out of touch” with each passing year, even though it “was an audacious product when it was announced at CES 2020.”We also got our first look at a model that’s a further down the pike. The Afeela Prototype 2026 is a taller version of the first EV. Just don’t expect to be able to try it yourself until at least 2028.MuxiSegwaySegway is expanding its e-bike lineup with two new models that have a heap of smart features, from Apple Find My integration and GPS tracking to remote locking and health app functions. The Muxi (above) looks quite pretty and has a cup holder(!), while the $2,000 Myon has a chunkier frame and features such as electronic gear shifting. Both are cargo-centric step-through models. You can buy the Myon now, and the $1,700 Muxi will be available in March, just in time for spring.Along with those e-bikes, Segway had a new electric dirt bike to tell us about. The Xaber 300 was created with off-roading in mind. There are three power modes, offering the equivalent of 150cc, 200cc and 300cc engines. Segway hasn’t revealed pricing for the Xaber 300, which should be available this spring or summer.Gaming Slide from NVIDIA's CES 2026 presentation about DLSS 4.5NVIDIANVIDIA announced the latest version of its DLSS (Deep Learning Super Sampling) upscaling tech. DLSS 4.5 is said to offer sharper visuals thanks to the 2nd Generation Super Resolution Transformer, which is available now for all RTX GPUs. NVIDIA says this offers better temporal stability, reduced ghosting and improved anti-aliasing.On GeForce RTX 50 Series GPUs, DLSS 4.5 will be able to generate up to five extra frames for each traditionally rendered one and deliver up to 4K 240Hz path traced performance, NVIDIA says. The Dynamic 6x Frame Generation feature will be available for those graphics cards sometime this spring.NVIDIA also detailed a new version of its G-Sync variable refresh rate tech. It says that G-Sync Pulsar can minimize motion blur by effectively quadrupling your refresh rate. So 250 Hz gameplay will seemingly offer up a perceived effective motion clarity of over 1,000 Hz with G-Sync Pulsar enabled. You’ll need a G-Sync Pulsar-compatible display to use this feature. Most displays have a backlight that’s always on, so images fade from one frame to the next. On G-Sync Pulsar displays, there are several horizontal backlight sections. The backlights pulse from top to bottom. This is said to help the pixels in each frame stabilize before they’re backlit, resulting in lower motion blur. It’s interesting stuff. Acer, AOC, ASUS and MSI are each releasing a G-Sync Pulsar-compatible 27-inch monitor this week.8BitDo FlipPad8BitDoThe FlipPad is one of my favorite things I’ve seen coming out of CES this year. It’s an 8BitDo mobile game controller that’s designed for vertical use. There are a bunch of neat physical controllers for phones that are built for landscape mode. But many mobile games are played with the phone oriented to the vertical position. And that’s not to mention emulators that allow you to play the likes of Game Boy titles while your phone stands tall. So it’s neat to see 8BitDo offering a physical controller that’ll do the trick. The company also unveiled a new Xbox controller with swappable joysticks and button modules.A keyboard thing.CorsairWhy have a numpad on the side of your keyboard when you can have a highly customizable controller instead? Corsair slapped a Stream Deck into a keyboard and it looks absolutely rad. I’ve yet to take the plunge on a Stream Deck-style controller and since I’d rather not have an extra device on my desk, I’m very tempted to pick up the $350 Galleon 100 SD, which is available now.It has 12 programmable keys that you can use for gaming (give me that Helldivers 2 profile so I don’t have to keep punching in stratagem codes) or livestreaming, but there are plenty of other applications too. They can help with video editing, controlling smart home devices or simply adjusting media playback. There’s a five-inch screen and two dials for fine control too. Oh, and it’s a full-sized mechanical keyboard to boot.GameSir had a couple of interesting controllers to tell us about. The Swift Drive (which seems to be a working name) has a steering wheel with force feedback in the middle of a regular gamepad. It’s a cool idea and it seems to work pretty well. The Swift Drive should hit the market later this year. In addition, GameSir teamed up with Hyperkin to make a modular controller that works with phones, tablets and Nintendo Switch consoles. You’ll be able to slot those devices into the X5 Alteron’s grip (as you might with a Backbone or Razer Kishi controller) though there’s a Bluetooth option for PC gaming too. The magnetic modules include ones styled after the GameCube and Nintendo 64, and there’ll be one with a trackpad that’s made with first-person shooters in mind. There’s no pricing or release date for the X5 Alteron yet, but I’m eager to try it.Elsewhere on the gaming front, Lenovo revealed a SteamOS-powered version of the Legion Go 2. That variant of the handheld is heading your way in June for $1,199. Razer had some concept gear to show off, including an AI-driven headset with built-in cameras that can recognize objects and text, and a gaming chair with haptic feedback and spatial audio built in. There’s also an AI desktop companion device with several avatars to choose from, including an anime girl and legendary League of Legends player Faker.AudioA speaker and a turntable.Victrola Victrola announced a pretty Bluetooth speaker that sits neatly underneath its turntables. You can use a cable to connect the two as well. Of course, you can play audio from other devices, including phones and tablets. I’ve had my eye on a Victrola turntable for a while thanks to its Sonos integration, and the Soundstage speaker is tempting too. The Soundstage will be available this summer for $350. The three sizes from the Cambridge Audio L/R speaker series. Green speakers in three sizes.Cambridge AudioSpeaking of pretty speakers, I really like the aesthetic of these three wireless bookshelf options from Cambridge Audio. The classy-lookin’ L/R Series speakers start at $549 for a 100W model with a 21mm hard-dome tweeter with a 3-inch long-throw woofer hut no support for Wi-Fi streaming (there is Bluetooth aptX HD, though). At the top end is the $2,299 L/R X, a 800W speaker that has a a 2.5-way acoustic design with a 28mm Torus tweeter and dual five-inch woofers. There’s even a touch of LED underlighting on this model and the $1,599 L/R M, which has 300W of power, smaller four-inch dual woofers and the same 28mm tweeter. All three speakers will be available later this year.There’s lots more audio gear at CES beyond the Victorla and Cambridge Audio speakers, of course. JBL was at the event to show off a whole bunch of earbuds and gaming headsets. Shure now has a USB-C version of its MV88 condenser microphone, making it compatible with Android devices and recent iPhones. That’ll run you $159. The latest version of JLab’s teeny JBuds Mini earbuds now have customizable active noise cancellation (ANC) and yet they still cost $40. PartyStudio is a speaker with 128 different instrument sounds that works with any MIDI keyboard.Nathan Ingraham for EngadgetPartyStudio seems like a fun product — it’s a MIDI speaker with 128 built-in instrument tones and 50-plus drum machine patterns. There’s a companion 36-key MIDI keyboard called PartyKeys as well (the speaker will work with any MIDI keyboard, though). PopuMusic is the company behind both.Anker, meanwhile, has new AeroFit 2 Pro earbuds that are pretty interesting. They’re the company’s first open-ear earbuds with ANC. You can snap them up in February for $180. There’s also a new portable Bluetooth speaker from Anker called the Soundcore Boom Go 3i. It’s a 15W unit with (according to Anker) up to 22 hours of battery life, and it should cost between $65 and $80 when it drops in March. Engadget deputy editor Billy Steele has been checking out some of the audio gear at CES, including Shokz’ $250 OpenFit Pro earbuds, which have Dolby Atmos support. Billy has also had some hands-on (or heads-on) time with Klipsch’s first new headphones in years. There are initially three models in the company’s Atlas series, including the Atlas HP-1, a wireless set with ANC that has a lovely wood finish on the exterior of the earcups. Klipsch is only allowing demos with lossless audio over USB-C for now, but the audio quality is “excellent,” Billy wrote in his hands-on story. Smart homeDreame Cyber X robot vacuumEngadgetAs ever, there was a ton of smart home gear at CES this year. One thing that caught our eye is a robot vacuum concept from Dreame. It's one of several companies working on models that can climb stairs, but the Cyber X is a slightly terrifying one since it has large legs that look a bit like chainsaws. The teeth in these legs help provide traction so that the Cyber X can climb stairs that are almost 10 inches high. While Dreame’s vacuum positions its legs horizontally to climb stairs with tank-style traction, Roborock’s Saros rover pushes itself upwards on extendable legs to reach higher floors. The legs have wheels on the bottom and knee-like joints — these can help the robot vacuum to raise itself over obstacles on floors too.Narwhal built a vacuum for your mattress. The U50 is a handheld model that has a UV sterilization light. It has a high-speed tapping feature that can help dislodge gunk and mites. The company also showed off a new robot vacuum and mop with a \"PetCare Mode\" you can use to track down your bestest furry friend and keep an eye on them when you're not home. You can even talk to your pet via a speaker system. Both products should be available in the spring.Anker's Eufy brand has a new robot vacuum too, along with a video doorbell, outdoor light and smart lock. This one’s pretty interesting: Lockin’s latest vein-recognition smart lock can wirelessly recharge via an optical infrared beam emitted by a separate device that’s plugged into an outlet.On a similar note, Ring has updated its door, window and break glass sensors, and it has introduced an OBD-II car alarm, motion detectors and panic buttons. Most of those will be available in March, though can pre-order the car alarm now.Elsewhere in home security, Ugreen announced a modular system that does not require a subscription. At a time when so many companies are desperate to sell you a subscription for dependable monthly revenue, that’s quite refreshing. Devices that are part of Ugreen’s platform — including a video doorbell and 4K cameras — should be available later this year.IKEA made its CES debut to show off some of its smart home tech, namely a string of budget-friendly, Matter-compatible devices. Along with some home sensors, the company plans to offer a $6 smart bulb, an $8 smart plug and a $6 smart remote in the coming weeks. Senior reporter Amy Skorheim checked out the products and particularly liked the BILREA remote, which you can use to control IKEA's lamps and other devices.Philips Hue SpatialAware featureSpeaking of smart bulbs, Philips announced some Hue updates at CES. You'll need a Hue Bridge Pro to use the SpatialAware feature, which uses augmented reality to make sure all of the lights in a room are working together harmoniously to create, for instance, a more natural-looking sunset scene. Philips will be rolling out SpatialAware to Hue users this spring. Also on the way is Apple Home support for the Hue Secure Camera, Hue Secure video doorbell and Hue contact sensors.Elsewhere in lighting, Govee has a new floor lamp, as well as a ceiling light that's said to simulate a skylight.In terms of kitchen tech, GE Appliances has a new smart refrigerator that's designed to make restocking easier. It has a built-in barcode scanner you can use to quickly add items to a shopping list. It's possible to sync the items to Instacart for grocery delivery. There's also an interior camera that can help you keep tabs on the goods in your fridge's crisper drawer. As you might expect for a smart fridge, it has a touchscreen on the door that you can use to call up recipes. The GE Profile Smart Refrigerator will be available in April for $4,899.NoshDaniel Cooper for EngadgetNosh, meanwhile, is an AI cooking robot that you'll be able to buy in the next few months. Load it with ingredients, pick one of the 500 dishes in Nosh's repertoire and the robot will put everything together. While it has water and oil reservoirs, as well as a built-in spice rack, you'll still need to prep the fresh ingredients before adding them to the machine. Nosh will cost $2,000 but if you're ready to pre-order now, you can snag one for an early bird price of $1,200.Moving outside, Whisper Aero claims that the T1 leaf blower (from its Tone Outdoors division) is 80 percent quieter and 60 percent more powerful than “leading gas handheld blowers.” That seems pretty great on paper, so here’s hoping that your noisy neighbors will be convinced to shell out $599 for a T1 when it arrives in September. Meanwhile, Segway’s Navimow unit has a bunch of new robot mowers. Health and accessibilityImage of the Throne Toilet Computer perched on the side of a toilet.Daniel Cooper for EngadgetIt perhaps shouldn’t come as a surprise that a toilet computer made an appearance in our roundup of weird CES tech. But if I’ve learned anything from watching Scrubs, it’s that our waste offers up a lot of revealing information about our health, so Throne is a pretty compelling device. It has a camera and microphone to track your bowel motions and urination levels. The idea is to figure out your regular toilet usage and then flag any deviations from that. The creators hope that Throne will help you gain a better understanding of your gut health, which could be beneficial for those on GLP-1 drugs, for instance. Throne will start shipping in February for $340 and a $6 per month subscription.Image of Vivoo's FlowPadVivooVivoo also showed off a toilet device that can monitor your urination levels. Not only that, the company unveiled a smart menstrual pad. The idea is for for wearers to scan the pad with their phone camera after use.Elsewhere, the latest version of Withing’s Body Scan scale can track 60 biomarkers, up from the 40 that the first model from 2023 can keep tabs on. The Body Scan 2 should be available in the spring for $600.A man sits in a manual wheelchair with an add-on attached that gives it a large central front wheel and raises the casters off the groundCheyenne MacDonald for EngadgetAccessibility tech is a welcome sight at CES, and WheelMove looks like it could be useful for many wheelchair users. It’s a device with a large front wheel that can quickly be attached to any manual wheelchair. It can then raise the wheelchair’s smaller front wheels off the ground, primarily to help users navigate rough terrain. The $6,000 WheelMove will debut in France later their year before a broader rollout.ReviMo has built a robotic lift that it says can help people move themselves from (for instance) a bed to a wheelchair without the assistance of a caregiver. The company expects Niko to cost around $15,000, but it’s attempting to get the device covered by insurance.Dephy's Sidekick, which the company describes as \"bionic footwear.\"Karissa Bell for EngadgetDephy’s Sidekick is designed as a walking aid. It’s an ankle-worn exoskeleton that’s attached to a sneaker. The Sidekick has sensors that can detect the user’s gait and adapt to it in order to deliver an effective boost in each step. At $4,500, the Sidekick isn’t cheap, but it could be a boon for those who are perhaps not as physically active as they’d like to be. Dephy is also adapting the tech for athletic use — the company is working with Nike on a robotic sneaker project.This article originally appeared on Engadget at https://www.engadget.com/general/all-the-tech-and-gadgets-announced-at-ces-2026-130124023.html?src=rss",
          "feed_position": 8,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/SMARTBrick_16x9.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/claude-code-2-1-0-arrives-with-smoother-workflows-and-smarter-agents",
          "published_at": "Thu, 08 Jan 2026 16:14:00 GMT",
          "title": "Claude Code 2.1.0 arrives with smoother workflows and smarter agents",
          "standfirst": "Anthropic has released Claude Code v2.1.0, a notable update to its \"vibe coding\" development environment for autonomously building software, spinning up AI agents, and completing a wide range of computer tasks, according to Head of Claude Code Boris Cherny in a post on X last night.The release introduces improvements across agent lifecycle control, skill development, session portability, and multilingual output — all bundled in a dense package of 1,096 commits. It comes amid a growing wave of praise for Claude Code from software developers and startup founders on X, as they increasingly use the system — powered by Anthropic&#x27;s Claude model family, including the flagship Opus 4.5 — to push beyond simple completions and into long-running, modular workflows.Enterprise Relevance: Agent Lifecycle and Orchestration ImprovementsClaude Code was originally released as a \"command line\" tool back in February 2025, almost a year ago, alongside Anthropic&#x27;s then cutting-edge Claude Sonnet 3.7 large language model (LLM). It has been updated various times since then, as Anthropic has also advanced its underlying LLMs. The new version, Claude Code 2.1.0 introduces infrastructure-level features aimed at developers deploying structured workflows and reusable skills. These changes reduce the manual scaffolding required to manage agents across sessions, tools, and environments — letting teams spend less time on configuration and more time on building.Key additions include:Hooks for agents, skills, and slash commands, enabling scoped PreToolUse, PostToolUse, and Stop logic. This gives developers fine-grained control over state management, tool constraints, and audit logging — reducing unexpected behavior and making agent actions easier to debug and reproduce.Hot reload for skills, so new or updated skills in ~/.claude/skills or .claude/skills become available immediately without restarting sessions. Developers can iterate on skill logic in real time, eliminating the stop-start friction that slows down experimentation.Forked sub-agent context via context: fork in skill frontmatter, allowing skills and slash commands to run in isolated contexts. This prevents unintended side effects and makes it safer to test new logic without polluting the main agent&#x27;s state.Wildcard tool permissions (e.g., Bash(npm *), Bash(*-h*)) for easier rule configuration and access management. Teams can define broader permission patterns with fewer rules, reducing configuration overhead and the risk of mismatched permissions blocking legitimate workflows.Language-specific output via a language setting, enabling workflows that require output in Japanese, Spanish, or other languages. Global teams and multilingual projects no longer need post-processing workarounds to localize Claude&#x27;s responses.Session teleportation via /teleport and /remote-env slash commands, which allow claude.ai subscribers to resume and configure remote sessions at claude.ai/code. Developers can seamlessly move work between local terminals and the web interface — ideal for switching devices or sharing sessions with collaborators.Improved terminal UX, including Shift+Enter working out of the box in iTerm2, Kitty, Ghostty, and WezTerm without modifying terminal configs. This removes a common setup frustration and lets developers start working immediately in their preferred terminal.Unified Ctrl+B behavior for backgrounding both agents and shell commands simultaneously. Developers can push long-running tasks to the background with a single keystroke, freeing up the terminal for other work without losing progress.New Vim motions including ; and , to repeat f/F/t/T motions, yank operator (y, yy, Y), paste (p/P), text objects, indent/dedent (>>, <<), and line joining (J). Power users who rely on Vim-style editing can now work faster without switching mental models or reaching for the mouse.MCP list_changed notifications, allowing MCP servers to dynamically update their available tools, prompts, and resources without requiring reconnection. This keeps workflows running smoothly when tool configurations change, avoiding interruptions and manual restarts.Agents continue after permission denial, allowing subagents to try alternative approaches rather than stopping entirely. This makes autonomous workflows more resilient, reducing the need for human intervention when an agent hits a permissions wall.Developer Experience ImprovementsBeyond the headline features, this release includes numerous quality-of-life improvements designed to reduce daily friction and help developers stay in flow./plan command shortcut to enable plan mode directly from the prompt — fewer keystrokes to switch modes means less context-switching and faster iteration on complex tasks.Slash command autocomplete now works when / appears anywhere in input, not just at the beginning. Developers can compose commands more naturally without backtracking to the start of a line.Real-time thinking block display in Ctrl+O transcript mode, giving developers visibility into Claude&#x27;s reasoning as it happens. This makes it easier to catch misunderstandings early and steer the agent before it goes down the wrong path.respectGitignore support in settings.json for per-project control over @-mention file picker behavior. Teams can keep sensitive or irrelevant files out of suggestions, reducing noise and preventing accidental exposure of ignored content.IS_DEMO environment variable to hide email and organization from the UI, useful for streaming or recording sessions. Developers can share their work publicly without leaking personal or company information.Skills progress indicators showing tool uses as they happen during execution. Developers get real-time feedback on what Claude is doing, reducing uncertainty during long-running operations and making it easier to spot issues mid-flight.Skills visible in slash command menu by default from /skills/ directories (opt-out with user-invocable: false in frontmatter. Custom skills are now more discoverable, helping teams adopt shared workflows without hunting through documentation.Improved permission prompt UX with Tab hint moved to footer, cleaner Yes/No input labels with contextual placeholders. Clearer prompts mean fewer mistakes and faster decisions when approving tool access.Multiple startup performance optimizations and improved terminal rendering performance, especially for text with emoji, ANSI codes, and Unicode characters. Faster startup and smoother rendering reduce waiting time and visual distractions, keeping developers focused on the task at hand.The release also addresses numerous bug fixes, including a security fix where sensitive data (OAuth tokens, API keys, passwords) could be exposed in debug logs, fixes for session persistence after transient server errors, and resolution of API context overflow when background tasks produce large output. Together, these fixes improve reliability and reduce the risk of data leaks or lost work.Why This Matters: Claude Code Hits a Turning Point with Power UsersClaude Code 2.1.0 arrives in the midst of a significant shift in developer behavior. Originally built as an internal tool at Anthropic, Claude Code is now gaining real traction among external power users — especially those building autonomous workflows, experimenting with agent tooling, and integrating Claude into terminal-based pipelines.According to X discussions in late December 2025 and early January 2026, enthusiasm surged as developers began describing Claude Code as a game-changer for \"vibe coding,\" agent composition, and productivity at scale.@JsonBasedman captured the prevailing sentiment: \"I don&#x27;t even see the timeline anymore, it&#x27;s just &#x27;Holy shit Claude code is so good&#x27;...\" \"Claude Code addiction is real,\" opined Matt Shumer, co-founder and CEO of Hyperwrite/Otherside AI, in another X post. Non-developers have embraced the accessibility. @LegallyInnovate, a lawyer, noted: \"Trying Claude code for the first time today. I’m a lawyer not a developer. It’s AMAZING. I am blown away and probably not even scratching the surface. \"Some users are shifting away from popular alternatives — @troychaplin switched from Cursor, calling Claude Code \"so much better!\" for standalone use. Claude Code has even fueled discussion that Anthropic has actually achieved artificial generalized intelligence, AGI, the so-called \"holy grail\" of artificial systems development — something that outperforms humans at most \"economically valuable work,\" according to the definition offered by Anthropic rival OpenAI. @deepfates argued that Claude Code may not be AGI, but that \"if Claude Code is good enough to to do that, combine ideas on the computer, then I think it is &#x27;artificial general intellect&#x27; at least. And that is good enough to create a new frontier...\" A clear pattern emerges: users who engage with Claude Code as an orchestration layer — configuring tools, defining reusable components, and layering logic — report transformative results. Those treating it as a standard AI assistant often find its limitations more apparent.Claude Code 2.1.0 doesn&#x27;t try to paper over those divisions — it builds for the advanced tier. Features like agent lifecycle hooks, hot-reloading of skills, wildcard permissioning, and session teleportation reinforce Claude Code&#x27;s identity as a tool for builders who treat agents not as chatbots, but as programmable infrastructure.In total, these updates don&#x27;t reinvent Claude Code, but they do lower friction for repeat users and unlock more sophisticated workflows. For teams orchestrating multi-step agent logic, Claude Code 2.1.0 makes Claude feel less like a model — and more like a framework.Pricing and AvailabilityClaude Code is available to Claude Pro ($20/month), Claude Max ($100/month), Claude Team (Premium Seat, $150 per month) with and Claude Enterprise (variable pricing) subscribers. The /teleport and /remote-env commands require access to Claude Code&#x27;s web interface at claude.ai/code. Full installation instructions and documentation are available at code.claude.com/docs/en/setup.What&#x27;s Next?With reusable skills, lifecycle hooks, and improved agent control, Claude Code continues evolving from a chat-based coding assistant into a structured environment for programmable, persistent agents. As enterprise teams and solo builders increasingly test Claude in real workflows — from internal copilots to complex bash-driven orchestration — version 2.1.0 makes it easier to treat agents as first-class components of a production stack.Anthropic appears to be signaling that it views Claude Code not as an experiment, but as infrastructure. And with this release, it&#x27;s building like it means it.",
          "content": "Anthropic has released Claude Code v2.1.0, a notable update to its \"vibe coding\" development environment for autonomously building software, spinning up AI agents, and completing a wide range of computer tasks, according to Head of Claude Code Boris Cherny in a post on X last night.The release introduces improvements across agent lifecycle control, skill development, session portability, and multilingual output — all bundled in a dense package of 1,096 commits. It comes amid a growing wave of praise for Claude Code from software developers and startup founders on X, as they increasingly use the system — powered by Anthropic&#x27;s Claude model family, including the flagship Opus 4.5 — to push beyond simple completions and into long-running, modular workflows.Enterprise Relevance: Agent Lifecycle and Orchestration ImprovementsClaude Code was originally released as a \"command line\" tool back in February 2025, almost a year ago, alongside Anthropic&#x27;s then cutting-edge Claude Sonnet 3.7 large language model (LLM). It has been updated various times since then, as Anthropic has also advanced its underlying LLMs. The new version, Claude Code 2.1.0 introduces infrastructure-level features aimed at developers deploying structured workflows and reusable skills. These changes reduce the manual scaffolding required to manage agents across sessions, tools, and environments — letting teams spend less time on configuration and more time on building.Key additions include:Hooks for agents, skills, and slash commands, enabling scoped PreToolUse, PostToolUse, and Stop logic. This gives developers fine-grained control over state management, tool constraints, and audit logging — reducing unexpected behavior and making agent actions easier to debug and reproduce.Hot reload for skills, so new or updated skills in ~/.claude/skills or .claude/skills become available immediately without restarting sessions. Developers can iterate on skill logic in real time, eliminating the stop-start friction that slows down experimentation.Forked sub-agent context via context: fork in skill frontmatter, allowing skills and slash commands to run in isolated contexts. This prevents unintended side effects and makes it safer to test new logic without polluting the main agent&#x27;s state.Wildcard tool permissions (e.g., Bash(npm *), Bash(*-h*)) for easier rule configuration and access management. Teams can define broader permission patterns with fewer rules, reducing configuration overhead and the risk of mismatched permissions blocking legitimate workflows.Language-specific output via a language setting, enabling workflows that require output in Japanese, Spanish, or other languages. Global teams and multilingual projects no longer need post-processing workarounds to localize Claude&#x27;s responses.Session teleportation via /teleport and /remote-env slash commands, which allow claude.ai subscribers to resume and configure remote sessions at claude.ai/code. Developers can seamlessly move work between local terminals and the web interface — ideal for switching devices or sharing sessions with collaborators.Improved terminal UX, including Shift+Enter working out of the box in iTerm2, Kitty, Ghostty, and WezTerm without modifying terminal configs. This removes a common setup frustration and lets developers start working immediately in their preferred terminal.Unified Ctrl+B behavior for backgrounding both agents and shell commands simultaneously. Developers can push long-running tasks to the background with a single keystroke, freeing up the terminal for other work without losing progress.New Vim motions including ; and , to repeat f/F/t/T motions, yank operator (y, yy, Y), paste (p/P), text objects, indent/dedent (>>, <<), and line joining (J). Power users who rely on Vim-style editing can now work faster without switching mental models or reaching for the mouse.MCP list_changed notifications, allowing MCP servers to dynamically update their available tools, prompts, and resources without requiring reconnection. This keeps workflows running smoothly when tool configurations change, avoiding interruptions and manual restarts.Agents continue after permission denial, allowing subagents to try alternative approaches rather than stopping entirely. This makes autonomous workflows more resilient, reducing the need for human intervention when an agent hits a permissions wall.Developer Experience ImprovementsBeyond the headline features, this release includes numerous quality-of-life improvements designed to reduce daily friction and help developers stay in flow./plan command shortcut to enable plan mode directly from the prompt — fewer keystrokes to switch modes means less context-switching and faster iteration on complex tasks.Slash command autocomplete now works when / appears anywhere in input, not just at the beginning. Developers can compose commands more naturally without backtracking to the start of a line.Real-time thinking block display in Ctrl+O transcript mode, giving developers visibility into Claude&#x27;s reasoning as it happens. This makes it easier to catch misunderstandings early and steer the agent before it goes down the wrong path.respectGitignore support in settings.json for per-project control over @-mention file picker behavior. Teams can keep sensitive or irrelevant files out of suggestions, reducing noise and preventing accidental exposure of ignored content.IS_DEMO environment variable to hide email and organization from the UI, useful for streaming or recording sessions. Developers can share their work publicly without leaking personal or company information.Skills progress indicators showing tool uses as they happen during execution. Developers get real-time feedback on what Claude is doing, reducing uncertainty during long-running operations and making it easier to spot issues mid-flight.Skills visible in slash command menu by default from /skills/ directories (opt-out with user-invocable: false in frontmatter. Custom skills are now more discoverable, helping teams adopt shared workflows without hunting through documentation.Improved permission prompt UX with Tab hint moved to footer, cleaner Yes/No input labels with contextual placeholders. Clearer prompts mean fewer mistakes and faster decisions when approving tool access.Multiple startup performance optimizations and improved terminal rendering performance, especially for text with emoji, ANSI codes, and Unicode characters. Faster startup and smoother rendering reduce waiting time and visual distractions, keeping developers focused on the task at hand.The release also addresses numerous bug fixes, including a security fix where sensitive data (OAuth tokens, API keys, passwords) could be exposed in debug logs, fixes for session persistence after transient server errors, and resolution of API context overflow when background tasks produce large output. Together, these fixes improve reliability and reduce the risk of data leaks or lost work.Why This Matters: Claude Code Hits a Turning Point with Power UsersClaude Code 2.1.0 arrives in the midst of a significant shift in developer behavior. Originally built as an internal tool at Anthropic, Claude Code is now gaining real traction among external power users — especially those building autonomous workflows, experimenting with agent tooling, and integrating Claude into terminal-based pipelines.According to X discussions in late December 2025 and early January 2026, enthusiasm surged as developers began describing Claude Code as a game-changer for \"vibe coding,\" agent composition, and productivity at scale.@JsonBasedman captured the prevailing sentiment: \"I don&#x27;t even see the timeline anymore, it&#x27;s just &#x27;Holy shit Claude code is so good&#x27;...\" \"Claude Code addiction is real,\" opined Matt Shumer, co-founder and CEO of Hyperwrite/Otherside AI, in another X post. Non-developers have embraced the accessibility. @LegallyInnovate, a lawyer, noted: \"Trying Claude code for the first time today. I’m a lawyer not a developer. It’s AMAZING. I am blown away and probably not even scratching the surface. \"Some users are shifting away from popular alternatives — @troychaplin switched from Cursor, calling Claude Code \"so much better!\" for standalone use. Claude Code has even fueled discussion that Anthropic has actually achieved artificial generalized intelligence, AGI, the so-called \"holy grail\" of artificial systems development — something that outperforms humans at most \"economically valuable work,\" according to the definition offered by Anthropic rival OpenAI. @deepfates argued that Claude Code may not be AGI, but that \"if Claude Code is good enough to to do that, combine ideas on the computer, then I think it is &#x27;artificial general intellect&#x27; at least. And that is good enough to create a new frontier...\" A clear pattern emerges: users who engage with Claude Code as an orchestration layer — configuring tools, defining reusable components, and layering logic — report transformative results. Those treating it as a standard AI assistant often find its limitations more apparent.Claude Code 2.1.0 doesn&#x27;t try to paper over those divisions — it builds for the advanced tier. Features like agent lifecycle hooks, hot-reloading of skills, wildcard permissioning, and session teleportation reinforce Claude Code&#x27;s identity as a tool for builders who treat agents not as chatbots, but as programmable infrastructure.In total, these updates don&#x27;t reinvent Claude Code, but they do lower friction for repeat users and unlock more sophisticated workflows. For teams orchestrating multi-step agent logic, Claude Code 2.1.0 makes Claude feel less like a model — and more like a framework.Pricing and AvailabilityClaude Code is available to Claude Pro ($20/month), Claude Max ($100/month), Claude Team (Premium Seat, $150 per month) with and Claude Enterprise (variable pricing) subscribers. The /teleport and /remote-env commands require access to Claude Code&#x27;s web interface at claude.ai/code. Full installation instructions and documentation are available at code.claude.com/docs/en/setup.What&#x27;s Next?With reusable skills, lifecycle hooks, and improved agent control, Claude Code continues evolving from a chat-based coding assistant into a structured environment for programmable, persistent agents. As enterprise teams and solo builders increasingly test Claude in real workflows — from internal copilots to complex bash-driven orchestration — version 2.1.0 makes it easier to treat agents as first-class components of a production stack.Anthropic appears to be signaling that it views Claude Code not as an experiment, but as infrastructure. And with this release, it&#x27;s building like it means it.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/VJOOEdM2W3XTpiKR09T2d/7c640966cb70007a9ea5a465637f38a9/nano_banana_removed.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/the-gaming-monitors-that-caught-our-eye-at-ces-2026-130000433.html",
          "published_at": "Thu, 08 Jan 2026 15:47:37 +0000",
          "title": "The gaming monitors that caught our eye at CES 2026",
          "standfirst": "CES 2026 has been a big event for screens of all sizes: TVs, laptops and everything in between. New PC monitors are among the CES announcements, with several companies are using the trade show as an opportunity to update their gaming monitor lineups. Some companies are showing off expanded OLED panels with improved refresh rates, brightness and color production, while others are showing off weirder ideas like a glasses-free 3D monitor. The collection below are some of our favorite gaming monitors that have already been announced: LG UltraGear GX7LG's latest QHD OLED gaming monitor is its brightest to dateLGThe LG UltraGear GX7 is the fastest and brightest gaming monitor LG has offered so far and a gaming-focused showcase for LG Display's 4th-gen RGB Tandem 2.0 OLED technology. The new display tech splits up the yellow layer of the company's 3rd-gen OLED tech into distinct red and green layers that, when stacked with blue layers, create brighter, more energy-efficient screens.In the case of the UltraGear GX7, the new 27-inch monitor reaches a typical brightness of 335 nits, and is VES DisplayHDR True Black 500 certified, for deeper contrast between the dark and bright parts of the screen. LG touts the display's Dual Mode, which lets discerning gamers switch between two distinct settings: a 540Hz refresh rate mode at QHD resolution, when image quality is what you care about most, or a 720Hz refresh rate mode at HD resolution, when speed is your priority.Whichever mode you choose, LG promises the monitor will offer a smooth and stutter free experience. It has a 0.02ms response time and supports both NVIDIA G-Sync and AMD FreeSYNC Premium Pro, so you should be set, regardless of what your computer's specialty is. For $1,000, the LG UltraGear GX7 seems like a high watermark for OLED gaming monitors.Samsung Odyssey 3D and Odyssey OLED G8Samsung's new Odyssey 3D monitor is the \"world's first 6K display with glasses-free 3D,\" with a 6,144 x 3,456 resolution, and the ability to take games \"beyond 2D\" by tracking the position of your eyes, and enhancing terrain, distance and object separation. Even if you're not interested in playing formerly 2D games like Lies of P: Overture with an added sense of depth, a 32-inch LCD screen with a 165Hz refresh rate that's capable of being boosted to 330Hz through Samsung's Dual Mode is nothing to sneeze at, especially with a 1ms response time.On top of its big 3D monitor, Samsung is also pushing its own updated OLED tech at CES. The company's new 32-inch Odyssey OLED G8 uses a 4K QD-OLED panel with a 240Hz refresh rate and a glare-free treatment for added visibility. The monitor has a VESA DisplayHDR True Black 500 certification, but unlike LG's display, its brightness is capped at 300 nits.ASUS ROG Swift OLED PG27UCWM and ROG Strix Pulsar XG27AQNGVThe back and front of ASUS' new ROG Swift monitor with a Tandem OLED panel.ASUSWhile the ASUS ROG Swift OLED PG27UCWM uses a Tandem OLED panel – a panel with two light-emitting layers, like the Ultra XDR Retina display on Apple's recent iPad Pros – the big change ASUS is focused on at CES 2026 is its new RGB Stripe OLED layout, technology LG helped pioneer. These updated panels use \"a full RGB sub-pixel arrangement\" to produce sharper text and more accurate color reproduction when compared to the QD-OLED panels the company has used in the past.The 27-inch ROG Swift OLED PG27UCWM can be run at 4K with a 240Hz refresh rate or at FHD with a 480Hz refresh rate. The display also has a 0.03ms minimum response time for smooth and clear action, and 99 percent DCI-P3 color gamut coverage for more vibrant and accurate color reproduction. The OLED monitor also includes a \"Neo PRoximity Sensor\" which automatically turns the screen off when you're not looking at it, to prevent burn-in.NVIDIA's new G-Sync Pulsar tech, which uses variable backlighting to reduce blur, is specifically meant for competitive gamers, and ASUS' new ROG Strix Pulsar XG27AQNGV monitor is one of the first to support the new tech. The monitor features a 27-inch, 1440p panel with a 360Hz refresh rate and \"the fastest response time\" ASUS has ever achieved in a 1440p LCD display. The monitor also includes DisplayPort, HDMI 2.1 and multiple USB 3.2 Gen 1 Type-A ports for whatever devices you want to connect to it.MSI MPG 314CQR QD-OLED X36MSI's new curved MPG monitor with a QD-OLED panel.MSIThe star monitor of MSI's new products at CES 2026 is the wordily titled MSI MPG 341CQR QD-OLED X36, a curved, 34-inch ultrawide monitor, with new OLED panel. Like Asus, MSI is mixing different OLED display technologies for better results. This new monitor uses a 5th-gen Tandem QD-OLED panel with an \"RGB Stripe sub-pixel layout\" for sharper visuals. MSI also applies what it calls \"DarkArmor Film\" to \"enhance light absorption,\" eliminate the reddish tint some QD-OLED panels have under ambient light, and boost black levels by \"up to 40 percent.\"As an ultrawide, the MPG 341CQR QD-OLED X36 has a resolution of 3,440 x 1,440, an aspect ratio of 21:9 and a refresh rate of 360Hz. MSI says the monitor can reach a peak brightness of 1,300 nits, and the company provides multiple HDR modes to switch between depending on your needs. Similar to ASUS, the monitor also includes a sensor for detecting whether a human is in front of the screen – MSI calls it an AI Care Sensor – so that the monitor can power-off or enter standby mode when not in active use.ViewSonic VX2738 2K OLED Gaming MonitorViewSonic's new 24-inch OLED monitor.ViewSonicViewSonic's new gaming monitors are more approachable and (presumably) more affordable than the options from competitors, but not necessarily less performant. The company top-of-the-line model, the ViewSonic VX2738 2K OLED Gaming Monitor has a 27-inch 2K QHD QD-OLED panel with a 240Hz refresh rate and up to 0.03ms response time.The monitor supports AMD FreeSync Premium and NVIDIA G-Sync for smoother gameplay. The VX2738 also has the ability to scale down its image via a 24.5-inch \"esports mode\" for competitive settings. ViewSonic says the monitor will include HDMI 2.1 and DisplayPort 1.4 ports and be available for $500.HP HyperX Omen OLED 34HP's new curved OLED monitor with a headphone hook.HPHP's newest monitor under its unified HyperX Omen gaming brand is the HyperX Omen OLED 34, a curved 34-inch monitor with a QD-OLED panel. HP says the monitor uses V-stripe QD-OLED tech, which like in MSI and ASUS' monitors, means sharper text and better color accuracy. The HyperX Omen OLEd 34 has an aspect ratio of 21:9, a 360Hz refresh rate and a 0.03ms response time.The monitor has 100W USB-C power delivery for whichever laptop you decide to connect to it, and a built-in KVM switch, HP says. Plus, the company is offering a customizable, 3D-printable headphone hook, if you want to store your accessories nearby.Acer Predator XB273U F6 Gaming MonitorAn Acer Predator monitor on a white background.AcerAcer is showing off multiple new monitors at CES 2026, but the Predator XB273U F6 Gaming Monitor stands out for its ridiculously fast refresh rate. Acer says the 27-inch screen has a 500Hz refresh rate by default, that can be boosted to 1000Hz at a 1,280 x 720 resolution if you use the company's Dynamic Frequency and Resolution (DFR) mode. The Predator XB273U F6 otherwise features a 2,560 x 1,440 IPS panel with a brightness of 350 nits, that's calibrated to cover 95 percent of the DCI-P3 and 99 percent of the sRGB color gamut. The monitor also has 2-watt speakers built-in, and includes HDMI2.1, DisplayPort 1.4 and audio out ports for connecting to the rest of your PC gaming setup. Acer says the Predator XB273U F6 will be available for $800 when it launches in Q2 2026 in North America.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/the-gaming-monitors-that-caught-our-eye-at-ces-2026-130000433.html?src=rss",
          "content": "CES 2026 has been a big event for screens of all sizes: TVs, laptops and everything in between. New PC monitors are among the CES announcements, with several companies are using the trade show as an opportunity to update their gaming monitor lineups. Some companies are showing off expanded OLED panels with improved refresh rates, brightness and color production, while others are showing off weirder ideas like a glasses-free 3D monitor. The collection below are some of our favorite gaming monitors that have already been announced: LG UltraGear GX7LG's latest QHD OLED gaming monitor is its brightest to dateLGThe LG UltraGear GX7 is the fastest and brightest gaming monitor LG has offered so far and a gaming-focused showcase for LG Display's 4th-gen RGB Tandem 2.0 OLED technology. The new display tech splits up the yellow layer of the company's 3rd-gen OLED tech into distinct red and green layers that, when stacked with blue layers, create brighter, more energy-efficient screens.In the case of the UltraGear GX7, the new 27-inch monitor reaches a typical brightness of 335 nits, and is VES DisplayHDR True Black 500 certified, for deeper contrast between the dark and bright parts of the screen. LG touts the display's Dual Mode, which lets discerning gamers switch between two distinct settings: a 540Hz refresh rate mode at QHD resolution, when image quality is what you care about most, or a 720Hz refresh rate mode at HD resolution, when speed is your priority.Whichever mode you choose, LG promises the monitor will offer a smooth and stutter free experience. It has a 0.02ms response time and supports both NVIDIA G-Sync and AMD FreeSYNC Premium Pro, so you should be set, regardless of what your computer's specialty is. For $1,000, the LG UltraGear GX7 seems like a high watermark for OLED gaming monitors.Samsung Odyssey 3D and Odyssey OLED G8Samsung's new Odyssey 3D monitor is the \"world's first 6K display with glasses-free 3D,\" with a 6,144 x 3,456 resolution, and the ability to take games \"beyond 2D\" by tracking the position of your eyes, and enhancing terrain, distance and object separation. Even if you're not interested in playing formerly 2D games like Lies of P: Overture with an added sense of depth, a 32-inch LCD screen with a 165Hz refresh rate that's capable of being boosted to 330Hz through Samsung's Dual Mode is nothing to sneeze at, especially with a 1ms response time.On top of its big 3D monitor, Samsung is also pushing its own updated OLED tech at CES. The company's new 32-inch Odyssey OLED G8 uses a 4K QD-OLED panel with a 240Hz refresh rate and a glare-free treatment for added visibility. The monitor has a VESA DisplayHDR True Black 500 certification, but unlike LG's display, its brightness is capped at 300 nits.ASUS ROG Swift OLED PG27UCWM and ROG Strix Pulsar XG27AQNGVThe back and front of ASUS' new ROG Swift monitor with a Tandem OLED panel.ASUSWhile the ASUS ROG Swift OLED PG27UCWM uses a Tandem OLED panel – a panel with two light-emitting layers, like the Ultra XDR Retina display on Apple's recent iPad Pros – the big change ASUS is focused on at CES 2026 is its new RGB Stripe OLED layout, technology LG helped pioneer. These updated panels use \"a full RGB sub-pixel arrangement\" to produce sharper text and more accurate color reproduction when compared to the QD-OLED panels the company has used in the past.The 27-inch ROG Swift OLED PG27UCWM can be run at 4K with a 240Hz refresh rate or at FHD with a 480Hz refresh rate. The display also has a 0.03ms minimum response time for smooth and clear action, and 99 percent DCI-P3 color gamut coverage for more vibrant and accurate color reproduction. The OLED monitor also includes a \"Neo PRoximity Sensor\" which automatically turns the screen off when you're not looking at it, to prevent burn-in.NVIDIA's new G-Sync Pulsar tech, which uses variable backlighting to reduce blur, is specifically meant for competitive gamers, and ASUS' new ROG Strix Pulsar XG27AQNGV monitor is one of the first to support the new tech. The monitor features a 27-inch, 1440p panel with a 360Hz refresh rate and \"the fastest response time\" ASUS has ever achieved in a 1440p LCD display. The monitor also includes DisplayPort, HDMI 2.1 and multiple USB 3.2 Gen 1 Type-A ports for whatever devices you want to connect to it.MSI MPG 314CQR QD-OLED X36MSI's new curved MPG monitor with a QD-OLED panel.MSIThe star monitor of MSI's new products at CES 2026 is the wordily titled MSI MPG 341CQR QD-OLED X36, a curved, 34-inch ultrawide monitor, with new OLED panel. Like Asus, MSI is mixing different OLED display technologies for better results. This new monitor uses a 5th-gen Tandem QD-OLED panel with an \"RGB Stripe sub-pixel layout\" for sharper visuals. MSI also applies what it calls \"DarkArmor Film\" to \"enhance light absorption,\" eliminate the reddish tint some QD-OLED panels have under ambient light, and boost black levels by \"up to 40 percent.\"As an ultrawide, the MPG 341CQR QD-OLED X36 has a resolution of 3,440 x 1,440, an aspect ratio of 21:9 and a refresh rate of 360Hz. MSI says the monitor can reach a peak brightness of 1,300 nits, and the company provides multiple HDR modes to switch between depending on your needs. Similar to ASUS, the monitor also includes a sensor for detecting whether a human is in front of the screen – MSI calls it an AI Care Sensor – so that the monitor can power-off or enter standby mode when not in active use.ViewSonic VX2738 2K OLED Gaming MonitorViewSonic's new 24-inch OLED monitor.ViewSonicViewSonic's new gaming monitors are more approachable and (presumably) more affordable than the options from competitors, but not necessarily less performant. The company top-of-the-line model, the ViewSonic VX2738 2K OLED Gaming Monitor has a 27-inch 2K QHD QD-OLED panel with a 240Hz refresh rate and up to 0.03ms response time.The monitor supports AMD FreeSync Premium and NVIDIA G-Sync for smoother gameplay. The VX2738 also has the ability to scale down its image via a 24.5-inch \"esports mode\" for competitive settings. ViewSonic says the monitor will include HDMI 2.1 and DisplayPort 1.4 ports and be available for $500.HP HyperX Omen OLED 34HP's new curved OLED monitor with a headphone hook.HPHP's newest monitor under its unified HyperX Omen gaming brand is the HyperX Omen OLED 34, a curved 34-inch monitor with a QD-OLED panel. HP says the monitor uses V-stripe QD-OLED tech, which like in MSI and ASUS' monitors, means sharper text and better color accuracy. The HyperX Omen OLEd 34 has an aspect ratio of 21:9, a 360Hz refresh rate and a 0.03ms response time.The monitor has 100W USB-C power delivery for whichever laptop you decide to connect to it, and a built-in KVM switch, HP says. Plus, the company is offering a customizable, 3D-printable headphone hook, if you want to store your accessories nearby.Acer Predator XB273U F6 Gaming MonitorAn Acer Predator monitor on a white background.AcerAcer is showing off multiple new monitors at CES 2026, but the Predator XB273U F6 Gaming Monitor stands out for its ridiculously fast refresh rate. Acer says the 27-inch screen has a 500Hz refresh rate by default, that can be boosted to 1000Hz at a 1,280 x 720 resolution if you use the company's Dynamic Frequency and Resolution (DFR) mode. The Predator XB273U F6 otherwise features a 2,560 x 1,440 IPS panel with a brightness of 350 nits, that's calibrated to cover 95 percent of the DCI-P3 and 99 percent of the sRGB color gamut. The monitor also has 2-watt speakers built-in, and includes HDMI2.1, DisplayPort 1.4 and audio out ports for connecting to the rest of your PC gaming setup. Acer says the Predator XB273U F6 will be available for $800 when it launches in Q2 2026 in North America.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/the-gaming-monitors-that-caught-our-eye-at-ces-2026-130000433.html?src=rss",
          "feed_position": 10,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2026-01/cc274f90-eaf9-11f0-926d-18b410a2ddcf"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/ces-2026-day-2-all-of-the-coolest-tech-we-saw-on-the-show-floor-during-the-second-day-134608348.html",
          "published_at": "Thu, 08 Jan 2026 13:46:08 +0000",
          "title": "CES 2026 Day 2: All of the coolest tech we saw on the show floor during the second day",
          "standfirst": "CES 2026’s second day was all about hands on time with new tech. From Lego’s most ambitious play experiment yet to assistive mobility tech, smart home ideas that actually feel affordable and robots that might one day fold your laundry, here’s what stood out most on January 7.Lego Smart PlayLego Star Wars Smart Play: Luke's Red Five X-WingNathan Ingraham for EngadgetLEGO’s new Smart Play system feels far more compelling in person than it did on stage. The Smart Brick, combined with Smart Tags and Smart Minifigures, responds dynamically to movement, proximity and context, triggering sounds and interactions without screens or apps. Seeing kids physically act out Star Wars battles while the bricks reacted in real time made it clear this is designed first and foremost for active social play, not digital distraction.WheelMoveA man sits in a manual wheelchair with an add-on attached that gives it a large central front wheel and raises the casters off the groundCheyenne MacDonald for EngadgetWheelMove’s motorized wheelchair attachment is compact, surprisingly quick to install and genuinely empowering in action. The add-on lifts a chair’s front wheels and adds powered assistance, making grass, cobblestones and slopes far easier to navigate. After seeing it demonstrated on uneven surfaces, it’s easy to imagine this opening up spaces that would otherwise be exhausting or inaccessible for manual wheelchair users.ThroneImage of the Throne Toilet Computer perched on the side of a toilet.Daniel Cooper for EngadgetThrone’s toilet-mounted health tracker is exactly as strange as it sounds, but it’s also thoughtfully designed. Using computer vision to analyze bowel movements and urination, the device aims to establish a personal baseline and flag changes over time, with gut health and GLP-1 users firmly in mind. It’s too early to judge accuracy, but seeing it in person made it feel less gimmicky and more like a niche wellness tool worth testing.IKEA smart home gearThe popular VARMBLIXT donut lamp is now smart. Amy Skorheim for EngadgetIKEA’s first CES appearance leaned heavily into what it does best: simple, affordable design. The new Matter-compatible smart home range includes bulbs, plugs, remotes and sensors priced low enough to make smart homes feel accessible again. Standouts like the magnetically mounted BILREA remote and playful TEKLAN lamps showed that IKEA hasn’t sacrificed charm in its push toward interoperability.SwitchBotSwitchbot's Onero H1.Karissa Bell for EngadgetSwitchBot’s Onero H1 was one of the most intriguing robots on the show floor because it’s meant to ship this year. The wheeled humanoid robot uses articulated arms and onboard AI to perform household chores, like loading a washing machine, albeit at a deliberate pace. Watching it work made the case that speed matters less than reliability when a robot can handle tasks while you’re not home.Eyebot vision testingImage of the Eyebot KioskDaniel Cooper for EngadgetEyebot’s self-service vision testing kiosk turns a 20-minute optometrist visit into a process that takes just a few minutes. The test is guided by a large touchscreen and reviewed remotely by a licensed eye doctor, striking a balance between automation and oversight. After comparing results with a recent traditional exam, the accuracy felt reassuring, even if it doesn’t replace full eye health screenings.Dephy Sidekick sneakersDephy's Sidekick, which the company describes as \"footwear.\"Karissa Bell for EngadgetDephy’s Sidekick robotic sneakers deliver a subtle but noticeable boost with each step. The ankle-mounted exoskeleton adapts to your gait, and walking with it feels bouncy rather than overpowering, especially at lower assist levels. It’s not for everyone, but after hours on the CES floor, the idea of powered help for people with limited mobility started to make a lot of sense.Klipsch headphonesKlipsch Atlas HP-1Billy Steele for EngadgetKlipsch’s return to headphones starts strong with the Atlas HP-1. The wireless ANC model looks premium, borrows familiar design cues and delivers the brand’s warm, balanced sound in early demos. Pricing is still unknown, but based on build quality and audio alone, these feel positioned firmly at the high end.Clear DropThe Clear Drop soft plastics compactor next to a pile of the bricks it produces.Amy Skorheim for EngadgetClear Drop’s home plastic compactor tackles a real recycling problem most households face. The machine takes bags and wraps them into dense bricks that can be shipped to partner recycling facilities, and watching it swallow soft plastics was oddly satisfying. It’s expensive and not perfect, but it’s one of the more practical attempts at dealing with waste outside municipal systems.Nosh cooking robotNoshDaniel Cooper for EngadgetNosh is an AI cooking robot designed for low-effort, sauce-heavy meals like soups, curries and pasta. Multiple ingredient trays allow you to prep meals ahead of time, then slide them in when you’re ready to eat. It’s not replacing real cooking anytime soon, but as an alternative to microwaved meals, it’s more appealing than expected.Day two leaned heavily toward tech you could physically interact with, whether that meant flying Lego ships through the air, watching a robot load laundry or testing a vision exam in a kiosk. With more show-floor time still ahead, we’ll be back with additional hands-ons, impressions and daily recaps as CES 2026 continues.This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-day-2-all-of-the-coolest-tech-we-saw-on-the-show-floor-during-the-second-day-134608348.html?src=rss",
          "content": "CES 2026’s second day was all about hands on time with new tech. From Lego’s most ambitious play experiment yet to assistive mobility tech, smart home ideas that actually feel affordable and robots that might one day fold your laundry, here’s what stood out most on January 7.Lego Smart PlayLego Star Wars Smart Play: Luke's Red Five X-WingNathan Ingraham for EngadgetLEGO’s new Smart Play system feels far more compelling in person than it did on stage. The Smart Brick, combined with Smart Tags and Smart Minifigures, responds dynamically to movement, proximity and context, triggering sounds and interactions without screens or apps. Seeing kids physically act out Star Wars battles while the bricks reacted in real time made it clear this is designed first and foremost for active social play, not digital distraction.WheelMoveA man sits in a manual wheelchair with an add-on attached that gives it a large central front wheel and raises the casters off the groundCheyenne MacDonald for EngadgetWheelMove’s motorized wheelchair attachment is compact, surprisingly quick to install and genuinely empowering in action. The add-on lifts a chair’s front wheels and adds powered assistance, making grass, cobblestones and slopes far easier to navigate. After seeing it demonstrated on uneven surfaces, it’s easy to imagine this opening up spaces that would otherwise be exhausting or inaccessible for manual wheelchair users.ThroneImage of the Throne Toilet Computer perched on the side of a toilet.Daniel Cooper for EngadgetThrone’s toilet-mounted health tracker is exactly as strange as it sounds, but it’s also thoughtfully designed. Using computer vision to analyze bowel movements and urination, the device aims to establish a personal baseline and flag changes over time, with gut health and GLP-1 users firmly in mind. It’s too early to judge accuracy, but seeing it in person made it feel less gimmicky and more like a niche wellness tool worth testing.IKEA smart home gearThe popular VARMBLIXT donut lamp is now smart. Amy Skorheim for EngadgetIKEA’s first CES appearance leaned heavily into what it does best: simple, affordable design. The new Matter-compatible smart home range includes bulbs, plugs, remotes and sensors priced low enough to make smart homes feel accessible again. Standouts like the magnetically mounted BILREA remote and playful TEKLAN lamps showed that IKEA hasn’t sacrificed charm in its push toward interoperability.SwitchBotSwitchbot's Onero H1.Karissa Bell for EngadgetSwitchBot’s Onero H1 was one of the most intriguing robots on the show floor because it’s meant to ship this year. The wheeled humanoid robot uses articulated arms and onboard AI to perform household chores, like loading a washing machine, albeit at a deliberate pace. Watching it work made the case that speed matters less than reliability when a robot can handle tasks while you’re not home.Eyebot vision testingImage of the Eyebot KioskDaniel Cooper for EngadgetEyebot’s self-service vision testing kiosk turns a 20-minute optometrist visit into a process that takes just a few minutes. The test is guided by a large touchscreen and reviewed remotely by a licensed eye doctor, striking a balance between automation and oversight. After comparing results with a recent traditional exam, the accuracy felt reassuring, even if it doesn’t replace full eye health screenings.Dephy Sidekick sneakersDephy's Sidekick, which the company describes as \"footwear.\"Karissa Bell for EngadgetDephy’s Sidekick robotic sneakers deliver a subtle but noticeable boost with each step. The ankle-mounted exoskeleton adapts to your gait, and walking with it feels bouncy rather than overpowering, especially at lower assist levels. It’s not for everyone, but after hours on the CES floor, the idea of powered help for people with limited mobility started to make a lot of sense.Klipsch headphonesKlipsch Atlas HP-1Billy Steele for EngadgetKlipsch’s return to headphones starts strong with the Atlas HP-1. The wireless ANC model looks premium, borrows familiar design cues and delivers the brand’s warm, balanced sound in early demos. Pricing is still unknown, but based on build quality and audio alone, these feel positioned firmly at the high end.Clear DropThe Clear Drop soft plastics compactor next to a pile of the bricks it produces.Amy Skorheim for EngadgetClear Drop’s home plastic compactor tackles a real recycling problem most households face. The machine takes bags and wraps them into dense bricks that can be shipped to partner recycling facilities, and watching it swallow soft plastics was oddly satisfying. It’s expensive and not perfect, but it’s one of the more practical attempts at dealing with waste outside municipal systems.Nosh cooking robotNoshDaniel Cooper for EngadgetNosh is an AI cooking robot designed for low-effort, sauce-heavy meals like soups, curries and pasta. Multiple ingredient trays allow you to prep meals ahead of time, then slide them in when you’re ready to eat. It’s not replacing real cooking anytime soon, but as an alternative to microwaved meals, it’s more appealing than expected.Day two leaned heavily toward tech you could physically interact with, whether that meant flying Lego ships through the air, watching a robot load laundry or testing a vision exam in a kiosk. With more show-floor time still ahead, we’ll be back with additional hands-ons, impressions and daily recaps as CES 2026 continues.This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-day-2-all-of-the-coolest-tech-we-saw-on-the-show-floor-during-the-second-day-134608348.html?src=rss",
          "feed_position": 16,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/DSCF9113.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/the-weirdest-tech-weve-seen-at-ces-2026-so-far-134056504.html",
          "published_at": "Thu, 08 Jan 2026 13:40:56 +0000",
          "title": "The weirdest tech we've seen at CES 2026 so far",
          "standfirst": "CES is famous for ushering in big TVs, faster chips and serious upgrades to the tech we already use every day. It’s also where companies feel emboldened to ask some very strange questions, like whether your toilet should analyze your poop or your nails should change color on command. From experimental laptops to health tech that probably didn’t need a camera, these are the weirdest gadgets we spotted at CES 2026.Throne toilet computerThe Throne device perched on the side of a toilet.Daniel Cooper for EngadgetThrone is a toilet-mounted computer that uses cameras and microphones to analyze your bowel movements, which is a sentence we did not expect to type this week. Designed to establish a personal “baseline” for your bathroom habits, it aims to flag changes that could indicate digestive or metabolic issues, including for people on GLP-1 drugs. We can’t speak to its effectiveness yet… but if knowledge is power, this thing might know way too much.Vivoo Hygienic FlowPad smart menstrual padVivoo's FlowPadVivooVivoo looked at at-home health tracking and decided the bathroom was still underutilized. Alongside its clip-on smart toilet that analyzes your hydration by literally monitoring your pee, the company also unveiled a menstrual pad infused with microfluidics that can track fertility and hormone markers once you scan it with your phone. It’s a bold reminder that CES 2026 is fully committed to quantifying everything — even the stuff we’d rather not discuss over brunch.Lenovo Legion Pro RollableWhile it normally has a 16-inch display, the Lenovo Legion Pro Rollable concept's screen can expand up to 23.8 inches across.Sam Rutherford for EngadgetLenovo’s Legion Pro Rollable is what happens when a gaming laptop decides it wants to be a widescreen monitor mid-match. Its 16-inch display can physically expand sideways into ultra-wide formats, turning flight sims and racing games into full cockpit experiences at the press of a couple of keys. It’s impractical, faintly ridiculous and absolutely the kind of CES concept we hope survives long enough to escape the demo floor.Lenovo ThinkBook XD RollableWith its XD Rollable concept, Lenovo took the Thinkbook Plus Gen 6's basic design and made it even more futuristic by allowing its flexible display to wrap around onto its lid.Sam Rutherford for EngadgetIf the Legion Pro Rollable is excessive, the ThinkBook XD Rollable is philosophically confusing. Its flexible display doesn’t just grow taller, it wraps over the lid to create a “world-facing” screen for people sitting across from you, which feels either futuristic or deeply unnecessary depending on your mood and situation (maybe this is the perfect device for hotel check-ins and other points of sale?). Still, it’s a gorgeous piece of hardware theater and proof Lenovo is determined to roll screens onto every surface it can reach.OhDoki Handy 2 ProImage of The Handy 2 and Handy 2 ProDaniel Cooper for EngadgetOhDoki’s Handy 2 Pro arrived at CES with one clear message: more power, fewer limits and absolutely no chill. The upgraded sex toy model cranks battery life up to five hours and unlocks a Turbo mode so aggressive it was described as “overclocked,” which is not a term we expected to hear in this category. It can also charge your phone, because apparently even pleasure tech needs to justify itself with productivity.iPolishiPolishDaniel Cooper for EngadgetiPolish finally made Total Recall nail tech real, minus the dystopia and Schwarzenegger. These press-on acrylic nails use an electric charge to switch between hundreds of colors in seconds, letting you change your manicure as often as your outfit. It’s delightfully impractical, surprisingly affordable and the most convincing argument yet for treating your nails like a customizable display.Hisense S6 FollowMe displayHisense S6 FollowMe displayHisenseHisense’s FollowMe display is a screen that physically follows you around the room — which no one really asked for, but CES happily delivered anyway. Designed to reposition itself automatically so content stays in view, it feels like the logical endpoint of smart TVs becoming increasingly clingy. We haven’t seen it in action yet, but the idea of a display that refuses to be ignored is deeply on brand for 2026.This article originally appeared on Engadget at https://www.engadget.com/the-weirdest-tech-weve-seen-at-ces-2026-so-far-134056504.html?src=rss",
          "content": "CES is famous for ushering in big TVs, faster chips and serious upgrades to the tech we already use every day. It’s also where companies feel emboldened to ask some very strange questions, like whether your toilet should analyze your poop or your nails should change color on command. From experimental laptops to health tech that probably didn’t need a camera, these are the weirdest gadgets we spotted at CES 2026.Throne toilet computerThe Throne device perched on the side of a toilet.Daniel Cooper for EngadgetThrone is a toilet-mounted computer that uses cameras and microphones to analyze your bowel movements, which is a sentence we did not expect to type this week. Designed to establish a personal “baseline” for your bathroom habits, it aims to flag changes that could indicate digestive or metabolic issues, including for people on GLP-1 drugs. We can’t speak to its effectiveness yet… but if knowledge is power, this thing might know way too much.Vivoo Hygienic FlowPad smart menstrual padVivoo's FlowPadVivooVivoo looked at at-home health tracking and decided the bathroom was still underutilized. Alongside its clip-on smart toilet that analyzes your hydration by literally monitoring your pee, the company also unveiled a menstrual pad infused with microfluidics that can track fertility and hormone markers once you scan it with your phone. It’s a bold reminder that CES 2026 is fully committed to quantifying everything — even the stuff we’d rather not discuss over brunch.Lenovo Legion Pro RollableWhile it normally has a 16-inch display, the Lenovo Legion Pro Rollable concept's screen can expand up to 23.8 inches across.Sam Rutherford for EngadgetLenovo’s Legion Pro Rollable is what happens when a gaming laptop decides it wants to be a widescreen monitor mid-match. Its 16-inch display can physically expand sideways into ultra-wide formats, turning flight sims and racing games into full cockpit experiences at the press of a couple of keys. It’s impractical, faintly ridiculous and absolutely the kind of CES concept we hope survives long enough to escape the demo floor.Lenovo ThinkBook XD RollableWith its XD Rollable concept, Lenovo took the Thinkbook Plus Gen 6's basic design and made it even more futuristic by allowing its flexible display to wrap around onto its lid.Sam Rutherford for EngadgetIf the Legion Pro Rollable is excessive, the ThinkBook XD Rollable is philosophically confusing. Its flexible display doesn’t just grow taller, it wraps over the lid to create a “world-facing” screen for people sitting across from you, which feels either futuristic or deeply unnecessary depending on your mood and situation (maybe this is the perfect device for hotel check-ins and other points of sale?). Still, it’s a gorgeous piece of hardware theater and proof Lenovo is determined to roll screens onto every surface it can reach.OhDoki Handy 2 ProImage of The Handy 2 and Handy 2 ProDaniel Cooper for EngadgetOhDoki’s Handy 2 Pro arrived at CES with one clear message: more power, fewer limits and absolutely no chill. The upgraded sex toy model cranks battery life up to five hours and unlocks a Turbo mode so aggressive it was described as “overclocked,” which is not a term we expected to hear in this category. It can also charge your phone, because apparently even pleasure tech needs to justify itself with productivity.iPolishiPolishDaniel Cooper for EngadgetiPolish finally made Total Recall nail tech real, minus the dystopia and Schwarzenegger. These press-on acrylic nails use an electric charge to switch between hundreds of colors in seconds, letting you change your manicure as often as your outfit. It’s delightfully impractical, surprisingly affordable and the most convincing argument yet for treating your nails like a customizable display.Hisense S6 FollowMe displayHisense S6 FollowMe displayHisenseHisense’s FollowMe display is a screen that physically follows you around the room — which no one really asked for, but CES happily delivered anyway. Designed to reposition itself automatically so content stays in view, it feels like the logical endpoint of smart TVs becoming increasingly clingy. We haven’t seen it in action yet, but the idea of a display that refuses to be ignored is deeply on brand for 2026.This article originally appeared on Engadget at https://www.engadget.com/the-weirdest-tech-weve-seen-at-ces-2026-so-far-134056504.html?src=rss",
          "feed_position": 18,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/thronelede.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/best-e-ink-tablet-130037939.html",
          "published_at": "Thu, 08 Jan 2026 10:01:26 +0000",
          "title": "The best E Ink tablets for 2026",
          "standfirst": "I’m a longtime lover of pen and paper, so E Ink tablets have been intriguing to me ever since they started becoming more widely available. After having hundreds of half-filled notebooks over the years, I, at some point, turned to digital tools instead because it was just easier to store everything on my phone or laptop so I always had my most important information at my fingertips.E-Ink tablets seem to provide the best of both worlds: the tactile satisfaction of regular notebooks with many of the conveniences found in digital tools, plus easy-on-the-eyes E-Ink screens. These devices have come a long way in recent years — now you can find them in multiple sizes, some have color E Ink screens and others double as full-blow ereaders with access to ebook stores and your local library’s offerings. I’ve tested out close to a dozen E Ink tablets over the past year or two to see how well they work, how convenient they really are and which are the best tablets using E Ink screens available today. Table of contents Best E Ink tablets for 2026 Are E Ink tablets worth it? What to look for in an E Ink tablet Other E Ink tablets we've tested Best E Ink tablets for 2026 Are E Ink tablets worth it? An E Ink tablet will be a worthwhile purchase to a very select group of people. If you prefer the look and feel of an e paper display to LCD panels found on traditional tablets, it makes a lot of sense. They’re also good options for those who want a more paper-like writing experience (although you can get that kind of functionality on a regular tablet with the right screen protector) or a more distraction-free device overall. The final note is key here. Many E Ink tablets don’t run on the same operating systems as regular tablets, so you’re automatically going to be limited in what you can do. And even with those that do allow you to download traditional apps like Chrome, Instagram and Facebook, E Ink tablets are not designed to give you the best casual-browsing experience. This is mostly due to the nature of E Ink displays, which have noticeable refreshes, a lack of vibrant colors and lower picture quality than the panels you’ll find on even the cheapest iPad. Arguably the biggest reason why you wouldn’t want to go with an iPad (all models of which support stylus input, a plethora of reading apps, etc) is because it’s much easier to get distracted by email, social media and other Internet-related temptations. What to look for in an E Ink tablet Writing and latency Arguably the most important thing to consider when looking for an E Ink tablet is the writing experience. How good it is will depend a lot on the display’s refresh rate (does it refresh after every time you put pen to “paper,” or at a different regular interval) and the stylus’ latency. Most of the tablets I’ve tested have little to no latency, but some are certainly better than others. Finally, you should double check before buying that your preferred E Ink tablet comes with a stylus, or if you need to purchase one separately. Reading How much will you be reading books, documents and other things on this tablet? E Ink tablets come in many sizes, but most of them tend to be larger than your standard e-reader because it makes writing much easier. Having a larger display isn’t a bad thing, but it might make holding it for long periods slightly more uncomfortable. (Most e-readers are roughly the size of a paperback book, giving you a similar feeling to analog reading). The supported file types for e-books can also make a big difference. It’s hard to make a blanket statement here because this varies so much among E Ink tablets. The TL;DR is that you’ll have a much better reading experience if you go with one made by a company that already has a history in e-book sales (i.e. Amazon or Kobo). All of the titles you bought via the Kindle or Kobo store should automatically be available to you on your Kindle or Kobo E Ink tablet. Also with Kindle titles, specifically, since they are protected by DRM, it’s not necessarily the best idea to try to bring those titles over to a third-party device. Unless the tablet runs an operating system like Android that supports downloads for apps like Kindle and Kobo, you’ll be limited to supported file types, like ePUB, PDF, MOBI, JPEG, PNG and others. Search functionality Most E Ink tablets have some on-device search features, but they can vary widely between models. You’ll want to consider how important it is to you to be able to search through all your handwritten notes and markups. I noticed in my testing that Amazon’s and Kobo’s E Ink tablets made it easy to refer back to notes made in books and files because they automatically save to the specific pages on which you took notes, made highlights and more. Searching is less standardized on E Ink tablets that have different supported file types, but their features can be quite powerful in their own right. For example, a few devices I tested supported text search in handwritten notes along with handwriting recognition, the latter of which allows you to translate your scribbles into typed text. Sharing and connectivity While we established that E Ink tablets can be great distraction-free devices, most manufacturers understand that your notes and doodles aren’t created in a vacuum. You may want to access them elsewhere, and that requires some form of connectivity. All of the E Ink tablets I tried have Wi-Fi support, and some support cloud syncing, companion mobile apps and the ability to export notes via email so you can access them elsewhere. None of them, however, integrate directly with a digital note taking system like Evernote or OneNote, so these devices will always be somewhat supplementary if you use apps like that, too. I’d argue that, if you already lean heavily on apps like OneNote, a standard tablet with a stylus and screen protector might be the best way to go. Ultimately, you should think about what you will want to do with the documents you’ll interact with on your E Ink tablet after the tablet portion is done. Price E Ink tablets aren’t known for being cheap. They generally fall into the $300-$800 price range, which is what you can expect to pay for a solid regular tablet, too. A key factor in price is size: cheaper devices with E Ink displays are likely to have smaller screens, and stylus support isn’t as much of a given. Also, those types of devices are generally considered e-readers because of their size and may not be the best for note-taking, doodling and the like. E Ink tablets have gone up in price recently. Supernote and Onyx Boox increased prices, as did reMarkable. The former said it was due to \"increased costs,” and a reMarkable representative confirmed this to Engadget and provided the following statement: \"We regularly review our pricing based on market conditions and operational costs. We've communicated an upcoming adjustment for the US market effective in May to provide transparency to our customers. Multiple factors influence our pricing decisions, including supply chain dynamics and overall operational costs in specific markets.” As a result, the reMarkable Paper Pro jumped from $579 to $629 (that's for the bundle with the standard Marker and no Folio). This isn't great, considering the Paper Pro was already on the expensive side of the spectrum for E Ink tablets. It's also worth noting that Supernote and Onyx Boox have raised prices in the past few months as well. Other E Ink tablets we've tested Onyx Boox Tab X C The Boox Tab X C is a color-screened version of the Tab X, the company’s all-purpose e-paper Android tablet. The Tab X C has a lovely 13.3-inch Kaleido 3 E Ink color display, an octa-core processor, 6GB of RAM and it runs on Android 13, making it one of the most powerful tablets in Boox’s lineup. I’ve used the Tab X in the past and this color version runs similarly, if not better, and at 5.3mm thick, it’s impressively svelte even when you pair it with its folio keyboard case. As someone who loves legal-pad sized things to write on, I also like how the Tab X C is most akin to A4-size paper. But at $820 for the bundle with the standard case (or a whopping $970 for the tablet and its keyboard case), it’s really only best for those who are ready to go all-in on a premium E Ink tablet. Lenovo Smart Paper Lenovo made a solid E Ink tablet in the Smart Paper, but it's too pricey and too married to the company's companion cloud service to warrant a spot on our top picks list. The hardware is great, but the software isn't as flexible as those of competitors like the reMarkable 2. It has good Google Drive integration, but you must pair it with Lenovo's cloud service to really get the most use out of it — and in the UK, the service costs £9 per month for three months, which is quite expensive. Onyx Boox Tab Ultra The Boox Tab Ultra has a lot of the same features we like in the Note Air 2 Plus, but it’s designed to be a true, all-purpose tablet with an E Ink screen. Running Android 11 and compatible with a magnetic keyboard case, you can use it like a standard 2-in-1 laptop, albeit a low-powered one. You can browse the web, check email and even watch YouTube videos on this thing — but that doesn’t mean you should. A standard 2-in-1 laptop with a more responsive screen and better overall performance would be a better fit for most people who even have the slightest desire to have an all-in-one device. Like the rest of Onyx’s devices, the Tab Ultra is specifically for those who put reading and eye comfort above all else.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-e-ink-tablet-130037939.html?src=rss",
          "content": "I’m a longtime lover of pen and paper, so E Ink tablets have been intriguing to me ever since they started becoming more widely available. After having hundreds of half-filled notebooks over the years, I, at some point, turned to digital tools instead because it was just easier to store everything on my phone or laptop so I always had my most important information at my fingertips.E-Ink tablets seem to provide the best of both worlds: the tactile satisfaction of regular notebooks with many of the conveniences found in digital tools, plus easy-on-the-eyes E-Ink screens. These devices have come a long way in recent years — now you can find them in multiple sizes, some have color E Ink screens and others double as full-blow ereaders with access to ebook stores and your local library’s offerings. I’ve tested out close to a dozen E Ink tablets over the past year or two to see how well they work, how convenient they really are and which are the best tablets using E Ink screens available today. Table of contents Best E Ink tablets for 2026 Are E Ink tablets worth it? What to look for in an E Ink tablet Other E Ink tablets we've tested Best E Ink tablets for 2026 Are E Ink tablets worth it? An E Ink tablet will be a worthwhile purchase to a very select group of people. If you prefer the look and feel of an e paper display to LCD panels found on traditional tablets, it makes a lot of sense. They’re also good options for those who want a more paper-like writing experience (although you can get that kind of functionality on a regular tablet with the right screen protector) or a more distraction-free device overall. The final note is key here. Many E Ink tablets don’t run on the same operating systems as regular tablets, so you’re automatically going to be limited in what you can do. And even with those that do allow you to download traditional apps like Chrome, Instagram and Facebook, E Ink tablets are not designed to give you the best casual-browsing experience. This is mostly due to the nature of E Ink displays, which have noticeable refreshes, a lack of vibrant colors and lower picture quality than the panels you’ll find on even the cheapest iPad. Arguably the biggest reason why you wouldn’t want to go with an iPad (all models of which support stylus input, a plethora of reading apps, etc) is because it’s much easier to get distracted by email, social media and other Internet-related temptations. What to look for in an E Ink tablet Writing and latency Arguably the most important thing to consider when looking for an E Ink tablet is the writing experience. How good it is will depend a lot on the display’s refresh rate (does it refresh after every time you put pen to “paper,” or at a different regular interval) and the stylus’ latency. Most of the tablets I’ve tested have little to no latency, but some are certainly better than others. Finally, you should double check before buying that your preferred E Ink tablet comes with a stylus, or if you need to purchase one separately. Reading How much will you be reading books, documents and other things on this tablet? E Ink tablets come in many sizes, but most of them tend to be larger than your standard e-reader because it makes writing much easier. Having a larger display isn’t a bad thing, but it might make holding it for long periods slightly more uncomfortable. (Most e-readers are roughly the size of a paperback book, giving you a similar feeling to analog reading). The supported file types for e-books can also make a big difference. It’s hard to make a blanket statement here because this varies so much among E Ink tablets. The TL;DR is that you’ll have a much better reading experience if you go with one made by a company that already has a history in e-book sales (i.e. Amazon or Kobo). All of the titles you bought via the Kindle or Kobo store should automatically be available to you on your Kindle or Kobo E Ink tablet. Also with Kindle titles, specifically, since they are protected by DRM, it’s not necessarily the best idea to try to bring those titles over to a third-party device. Unless the tablet runs an operating system like Android that supports downloads for apps like Kindle and Kobo, you’ll be limited to supported file types, like ePUB, PDF, MOBI, JPEG, PNG and others. Search functionality Most E Ink tablets have some on-device search features, but they can vary widely between models. You’ll want to consider how important it is to you to be able to search through all your handwritten notes and markups. I noticed in my testing that Amazon’s and Kobo’s E Ink tablets made it easy to refer back to notes made in books and files because they automatically save to the specific pages on which you took notes, made highlights and more. Searching is less standardized on E Ink tablets that have different supported file types, but their features can be quite powerful in their own right. For example, a few devices I tested supported text search in handwritten notes along with handwriting recognition, the latter of which allows you to translate your scribbles into typed text. Sharing and connectivity While we established that E Ink tablets can be great distraction-free devices, most manufacturers understand that your notes and doodles aren’t created in a vacuum. You may want to access them elsewhere, and that requires some form of connectivity. All of the E Ink tablets I tried have Wi-Fi support, and some support cloud syncing, companion mobile apps and the ability to export notes via email so you can access them elsewhere. None of them, however, integrate directly with a digital note taking system like Evernote or OneNote, so these devices will always be somewhat supplementary if you use apps like that, too. I’d argue that, if you already lean heavily on apps like OneNote, a standard tablet with a stylus and screen protector might be the best way to go. Ultimately, you should think about what you will want to do with the documents you’ll interact with on your E Ink tablet after the tablet portion is done. Price E Ink tablets aren’t known for being cheap. They generally fall into the $300-$800 price range, which is what you can expect to pay for a solid regular tablet, too. A key factor in price is size: cheaper devices with E Ink displays are likely to have smaller screens, and stylus support isn’t as much of a given. Also, those types of devices are generally considered e-readers because of their size and may not be the best for note-taking, doodling and the like. E Ink tablets have gone up in price recently. Supernote and Onyx Boox increased prices, as did reMarkable. The former said it was due to \"increased costs,” and a reMarkable representative confirmed this to Engadget and provided the following statement: \"We regularly review our pricing based on market conditions and operational costs. We've communicated an upcoming adjustment for the US market effective in May to provide transparency to our customers. Multiple factors influence our pricing decisions, including supply chain dynamics and overall operational costs in specific markets.” As a result, the reMarkable Paper Pro jumped from $579 to $629 (that's for the bundle with the standard Marker and no Folio). This isn't great, considering the Paper Pro was already on the expensive side of the spectrum for E Ink tablets. It's also worth noting that Supernote and Onyx Boox have raised prices in the past few months as well. Other E Ink tablets we've tested Onyx Boox Tab X C The Boox Tab X C is a color-screened version of the Tab X, the company’s all-purpose e-paper Android tablet. The Tab X C has a lovely 13.3-inch Kaleido 3 E Ink color display, an octa-core processor, 6GB of RAM and it runs on Android 13, making it one of the most powerful tablets in Boox’s lineup. I’ve used the Tab X in the past and this color version runs similarly, if not better, and at 5.3mm thick, it’s impressively svelte even when you pair it with its folio keyboard case. As someone who loves legal-pad sized things to write on, I also like how the Tab X C is most akin to A4-size paper. But at $820 for the bundle with the standard case (or a whopping $970 for the tablet and its keyboard case), it’s really only best for those who are ready to go all-in on a premium E Ink tablet. Lenovo Smart Paper Lenovo made a solid E Ink tablet in the Smart Paper, but it's too pricey and too married to the company's companion cloud service to warrant a spot on our top picks list. The hardware is great, but the software isn't as flexible as those of competitors like the reMarkable 2. It has good Google Drive integration, but you must pair it with Lenovo's cloud service to really get the most use out of it — and in the UK, the service costs £9 per month for three months, which is quite expensive. Onyx Boox Tab Ultra The Boox Tab Ultra has a lot of the same features we like in the Note Air 2 Plus, but it’s designed to be a true, all-purpose tablet with an E Ink screen. Running Android 11 and compatible with a magnetic keyboard case, you can use it like a standard 2-in-1 laptop, albeit a low-powered one. You can browse the web, check email and even watch YouTube videos on this thing — but that doesn’t mean you should. A standard 2-in-1 laptop with a more responsive screen and better overall performance would be a better fit for most people who even have the slightest desire to have an all-in-one device. Like the rest of Onyx’s devices, the Tab Ultra is specifically for those who put reading and eye comfort above all else.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-e-ink-tablet-130037939.html?src=rss",
          "feed_position": 23
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/databricks-instructed-retriever-beats-traditional-rag-data-retrieval-by-70",
          "published_at": "Thu, 08 Jan 2026 05:00:00 GMT",
          "title": "Databricks' Instructed Retriever beats traditional RAG data retrieval by 70% — enterprise metadata was the missing link",
          "standfirst": "A core element of any data retrieval operation is the use of a component known as a retriever. Its job is to retrieve the relevant content for a given query. In the AI era, retrievers have been used as part of RAG pipelines. The approach is straightforward: retrieve relevant documents, feed them to an LLM, and let the model generate an answer based on that context.While retrieval might have seemed like a solved problem, it actually wasn&#x27;t solved for modern agentic AI workflows.In research published this week, Databricks introduced Instructed Retriever, a new architecture that the company claims delivers up to 70% improvement over traditional RAG on complex, instruction-heavy enterprise question-answering tasks. The difference comes down to how the system understands and uses metadata.\"A lot of the systems that were built for retrieval before the age of large language models were really built for humans to use, not for agents to use,\" Michael Bendersky, a research director at Databricks, told VentureBeat. \"What we found is that in a lot of cases, the errors that are coming from the agent are not because the agent is not able to reason about the data. It&#x27;s because the agent is not able to retrieve the right data in the first place.\"What&#x27;s missing from traditional RAG retrieversThe core problem stems from how traditional RAG handles what Bendersky calls \"system-level specifications.\" These include the full context of user instructions, metadata schemas, and examples that define what a successful retrieval should look like.In a typical RAG pipeline, a user query gets converted into an embedding, similar documents are retrieved from a vector database, and those results feed into a language model for generation. The system might incorporate basic filtering, but it fundamentally treats each query as an isolated text-matching exercise.This approach breaks down with real enterprise data. Enterprise documents often include rich metadata like timestamps, author information, product ratings, document types, and domain-specific attributes. When a user asks a question that requires reasoning over these metadata fields, traditional RAG struggles.Consider this example: \"Show me five-star product reviews from the past six months, but exclude anything from Brand X.\" Traditional RAG cannot reliably translate that natural language constraint into the appropriate database filters and structured queries.\"If you just use a traditional RAG system, there&#x27;s no way to make use of all these different signals about the data that are encapsulated in metadata,\" Bendersky said. \"They need to be passed on to the agent itself to do the right job in retrieval.\"The issue becomes more acute as enterprises move beyond simple document search to agentic workflows. A human using a search system can reformulate queries and apply filters manually when initial results miss the mark. An AI agent operating autonomously needs the retrieval system itself to understand and execute complex, multi-faceted instructions.How Instructed Retriever worksDatabricks&#x27; approach fundamentally redesigns the retrieval pipeline. The system propagates complete system specifications through every stage of both retrieval and generation. These specifications include user instructions, labeled examples and index schemas.The architecture adds three key capabilities:Query decomposition: The system breaks complex, multi-part requests into a search plan containing multiple keyword searches and filter instructions. A request for \"recent FooBrand products excluding lite models\" gets decomposed into structured queries with appropriate metadata filters. Traditional systems would attempt a single semantic search.Metadata reasoning: Natural language instructions get translated into database filters. \"From last year\" becomes a date filter, \"five-star reviews\" becomes a rating filter. The system understands both what metadata is available and how to match it to user intent.Contextual relevance: The reranking stage uses the full context of user instructions to boost documents that match intent, even when keywords are a weaker match. The system can prioritize recency or specific document types based on specifications rather than just text similarity.\"The magic is in how we construct the queries,\" Bendersky said. \"We kind of try to use the tool as an agent would, not as a human would. It has all the intricacies of the API and uses them to the best possible ability.\"Contextual memory vs. retrieval architectureOver the latter half of 2025, there was an industry shift away from RAG toward agentic AI memory, sometimes referred to as contextual memory. Approaches including Hindsight and A-MEM emerged offering the promise of a RAG-free future.Bendersky argues that contextual memory and sophisticated retrieval serve different purposes. Both are necessary for enterprise AI systems.\"There&#x27;s no way you can put everything in your enterprise into your contextual memory,\" Bendersky noted. \"You kind of need both. You need contextual memory to provide specifications, to provide schemas, but still you need access to the data, which may be distributed across multiple tables and documents.\"Contextual memory excels at maintaining task specifications, user preferences, and metadata schemas within a session. It keeps the \"rules of the game\" readily available. But the actual enterprise data corpus exists outside this context window. Most enterprises have data volumes that exceed even generous context windows by orders of magnitude.Instructed Retriever leverages contextual memory for system-level specifications while using retrieval to access the broader data estate. The specifications in context inform how the retriever constructs queries and interprets results. The retrieval system then pulls specific documents from potentially billions of candidates.This division of labor matters for practical deployment. Loading millions of documents into context is neither feasible nor efficient. The metadata alone can be substantial when dealing with heterogeneous systems across an enterprise. Instructed Retriever solves this by making metadata immediately usable without requiring it all to fit in context.Availability and practical considerationsInstructed Retriever is available now as part of Databricks Agent Bricks; it&#x27;s built into the Knowledge Assistant product. Enterprises using Knowledge Assistant to build question-answering systems over their documents automatically leverage the Instructed Retriever architecture without building custom RAG pipelines.The system is not available as open source, though Bendersky indicated Databricks is considering broader availability. For now, the company&#x27;s strategy is to release benchmarks like StaRK-Instruct to the research community while keeping the implementation proprietary to its enterprise products.The technology shows particular promise for enterprises with complex, highly structured data that includes rich metadata. Bendersky cited use cases across finance, e-commerce, and healthcare. Essentially any domain where documents have meaningful attributes beyond raw text can benefit.\"What we&#x27;ve seen in some cases kind of unlocks things that the customer cannot do without it,\" Bendersky said.He explained that without Instructed Retriever, users have to do more data management tasks to put content into the right structure and tables in order for an LLM to properly retrieve the correct information.“Here you can just create an index with the right metadata, point your retriever to that, and it will just work out of the box,” he said.What this means for enterprise AI strategyFor enterprises building RAG-based systems today, the research surfaces a critical question: Is your retrieval pipeline actually capable of the instruction-following and metadata reasoning your use case requires?The 70% improvement Databricks demonstrates isn&#x27;t achievable through incremental optimization. It represents an architectural difference in how system specifications flow through the retrieval and generation process. Organizations that have invested in carefully structuring their data with detailed metadata may find that traditional RAG is leaving much of that structure&#x27;s value on the table.For enterprises looking to implement AI systems that can reliably follow complex, multi-part instructions over heterogeneous data sources, the research indicates that retrieval architecture may be the critical differentiator. Those still relying on basic RAG for production use cases involving rich metadata should evaluate whether their current approach can fundamentally meet their requirements. The performance gap Databricks demonstrates suggests that a more sophisticated retrieval architecture is now table stakes for enterprises with complex data estates.",
          "content": "A core element of any data retrieval operation is the use of a component known as a retriever. Its job is to retrieve the relevant content for a given query. In the AI era, retrievers have been used as part of RAG pipelines. The approach is straightforward: retrieve relevant documents, feed them to an LLM, and let the model generate an answer based on that context.While retrieval might have seemed like a solved problem, it actually wasn&#x27;t solved for modern agentic AI workflows.In research published this week, Databricks introduced Instructed Retriever, a new architecture that the company claims delivers up to 70% improvement over traditional RAG on complex, instruction-heavy enterprise question-answering tasks. The difference comes down to how the system understands and uses metadata.\"A lot of the systems that were built for retrieval before the age of large language models were really built for humans to use, not for agents to use,\" Michael Bendersky, a research director at Databricks, told VentureBeat. \"What we found is that in a lot of cases, the errors that are coming from the agent are not because the agent is not able to reason about the data. It&#x27;s because the agent is not able to retrieve the right data in the first place.\"What&#x27;s missing from traditional RAG retrieversThe core problem stems from how traditional RAG handles what Bendersky calls \"system-level specifications.\" These include the full context of user instructions, metadata schemas, and examples that define what a successful retrieval should look like.In a typical RAG pipeline, a user query gets converted into an embedding, similar documents are retrieved from a vector database, and those results feed into a language model for generation. The system might incorporate basic filtering, but it fundamentally treats each query as an isolated text-matching exercise.This approach breaks down with real enterprise data. Enterprise documents often include rich metadata like timestamps, author information, product ratings, document types, and domain-specific attributes. When a user asks a question that requires reasoning over these metadata fields, traditional RAG struggles.Consider this example: \"Show me five-star product reviews from the past six months, but exclude anything from Brand X.\" Traditional RAG cannot reliably translate that natural language constraint into the appropriate database filters and structured queries.\"If you just use a traditional RAG system, there&#x27;s no way to make use of all these different signals about the data that are encapsulated in metadata,\" Bendersky said. \"They need to be passed on to the agent itself to do the right job in retrieval.\"The issue becomes more acute as enterprises move beyond simple document search to agentic workflows. A human using a search system can reformulate queries and apply filters manually when initial results miss the mark. An AI agent operating autonomously needs the retrieval system itself to understand and execute complex, multi-faceted instructions.How Instructed Retriever worksDatabricks&#x27; approach fundamentally redesigns the retrieval pipeline. The system propagates complete system specifications through every stage of both retrieval and generation. These specifications include user instructions, labeled examples and index schemas.The architecture adds three key capabilities:Query decomposition: The system breaks complex, multi-part requests into a search plan containing multiple keyword searches and filter instructions. A request for \"recent FooBrand products excluding lite models\" gets decomposed into structured queries with appropriate metadata filters. Traditional systems would attempt a single semantic search.Metadata reasoning: Natural language instructions get translated into database filters. \"From last year\" becomes a date filter, \"five-star reviews\" becomes a rating filter. The system understands both what metadata is available and how to match it to user intent.Contextual relevance: The reranking stage uses the full context of user instructions to boost documents that match intent, even when keywords are a weaker match. The system can prioritize recency or specific document types based on specifications rather than just text similarity.\"The magic is in how we construct the queries,\" Bendersky said. \"We kind of try to use the tool as an agent would, not as a human would. It has all the intricacies of the API and uses them to the best possible ability.\"Contextual memory vs. retrieval architectureOver the latter half of 2025, there was an industry shift away from RAG toward agentic AI memory, sometimes referred to as contextual memory. Approaches including Hindsight and A-MEM emerged offering the promise of a RAG-free future.Bendersky argues that contextual memory and sophisticated retrieval serve different purposes. Both are necessary for enterprise AI systems.\"There&#x27;s no way you can put everything in your enterprise into your contextual memory,\" Bendersky noted. \"You kind of need both. You need contextual memory to provide specifications, to provide schemas, but still you need access to the data, which may be distributed across multiple tables and documents.\"Contextual memory excels at maintaining task specifications, user preferences, and metadata schemas within a session. It keeps the \"rules of the game\" readily available. But the actual enterprise data corpus exists outside this context window. Most enterprises have data volumes that exceed even generous context windows by orders of magnitude.Instructed Retriever leverages contextual memory for system-level specifications while using retrieval to access the broader data estate. The specifications in context inform how the retriever constructs queries and interprets results. The retrieval system then pulls specific documents from potentially billions of candidates.This division of labor matters for practical deployment. Loading millions of documents into context is neither feasible nor efficient. The metadata alone can be substantial when dealing with heterogeneous systems across an enterprise. Instructed Retriever solves this by making metadata immediately usable without requiring it all to fit in context.Availability and practical considerationsInstructed Retriever is available now as part of Databricks Agent Bricks; it&#x27;s built into the Knowledge Assistant product. Enterprises using Knowledge Assistant to build question-answering systems over their documents automatically leverage the Instructed Retriever architecture without building custom RAG pipelines.The system is not available as open source, though Bendersky indicated Databricks is considering broader availability. For now, the company&#x27;s strategy is to release benchmarks like StaRK-Instruct to the research community while keeping the implementation proprietary to its enterprise products.The technology shows particular promise for enterprises with complex, highly structured data that includes rich metadata. Bendersky cited use cases across finance, e-commerce, and healthcare. Essentially any domain where documents have meaningful attributes beyond raw text can benefit.\"What we&#x27;ve seen in some cases kind of unlocks things that the customer cannot do without it,\" Bendersky said.He explained that without Instructed Retriever, users have to do more data management tasks to put content into the right structure and tables in order for an LLM to properly retrieve the correct information.“Here you can just create an index with the right metadata, point your retriever to that, and it will just work out of the box,” he said.What this means for enterprise AI strategyFor enterprises building RAG-based systems today, the research surfaces a critical question: Is your retrieval pipeline actually capable of the instruction-following and metadata reasoning your use case requires?The 70% improvement Databricks demonstrates isn&#x27;t achievable through incremental optimization. It represents an architectural difference in how system specifications flow through the retrieval and generation process. Organizations that have invested in carefully structuring their data with detailed metadata may find that traditional RAG is leaving much of that structure&#x27;s value on the table.For enterprises looking to implement AI systems that can reliably follow complex, multi-part instructions over heterogeneous data sources, the research indicates that retrieval architecture may be the critical differentiator. Those still relying on basic RAG for production use cases involving rich metadata should evaluate whether their current approach can fundamentally meet their requirements. The performance gap Databricks demonstrates suggests that a more sophisticated retrieval architecture is now table stakes for enterprises with complex data estates.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1eZZaqvHTrdfNRsC2e4MOz/116b0265c0b8e908b89221917b7b55b9/instructed-retrieval-smk.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/mirominds-mirothinker-1-5-delivers-trillion-parameter-performance-from-a-30b",
          "published_at": "Thu, 08 Jan 2026 02:40:00 GMT",
          "title": "MiroMind’s MiroThinker 1.5 delivers trillion-parameter performance from a 30B model — at 1/20th the cost",
          "standfirst": "Joining the ranks of a growing number of smaller, powerful reasoning models is MiroThinker 1.5 from MiroMind, with just 30 billion parameters, compared to the hundreds of billions or trillions used by leading foundation large language models (LLMs).But MiroThinker 1.5 stands out among these smaller reasoners for one major reason: it offers agentic research capabilities rivaling trillion-parameter competitors like Kimi K2 and DeepSeek, at a fraction of the inference cost.The release marks a milestone in the push toward efficient, deployable AI agents. Enterprises have long been forced to choose between expensive API calls to frontier models or compromised local performance. MiroThinker 1.5 offers a third path: open-weight models architected specifically for extended tool use and multi-step reasoning.One of the biggest trends emerging in the industry is a move away from highly specialized agents toward more generalized ones. Until recently, that capability was largely limited to proprietary models. MiroThinker 1.5 represents a serious open-weight contender in this space. Watch my YouTube video on it below. Reduced Hallucination Risk Through Verifiable ReasoningFor IT teams evaluating AI deployment, hallucinations remain the primary barrier to using open models in production. MiroThinker 1.5 addresses this through what MiroMind calls “scientist mode”—a fundamental architectural shift in how the model handles uncertainty.Rather than generating statistically plausible answers from memorized patterns (the root cause of most hallucinations), MiroThinker is trained to execute a verifiable research loop: propose hypotheses, query external sources for evidence, identify mismatches, revise conclusions, and verify again. During training, the model is explicitly penalized for high-confidence outputs that lack source support.The practical implication for enterprise deployment is auditability. When MiroThinker produces an answer, it can surface both the reasoning chain and the external sources it consulted. For regulated industries such as financial services, healthcare, and legal, this creates a documentation trail that memorization-based models cannot provide. Compliance teams can review not just what the model concluded, but how it arrived there.This approach also reduces the “confident hallucination” problem common in production AI systems. The model is trained to seek verification rather than extrapolate when uncertain—a behavior that translates directly into fewer costly errors.Benchmark Performance: Punching Above Its WeightUnder this framework, MiroThinker-v1.5-30B delivers performance comparable to models with up to 30× more parameters, including the trillion-parameter Kimi-K2-Thinking model. On BrowseComp-ZH, a key benchmark for web research capabilities, the 30B model actually outperformed its trillion-parameter competitor with a score of 69.8.The cost differential is equally notable. MiroMind reports inference costs as low as $0.07 per call for the 30B variant—roughly one-twentieth the cost of Kimi-K2-Thinking—along with faster inference speeds.A larger 235B variant (with 22B active parameters in a mixture-of-experts architecture) ranks in the global top tier across multiple search-agent benchmarks. On general agentic search evaluations, these models hold their own against systems from DeepSeek V3.2, Minimax, GLM, and Kimi-K2.In testing, the larger model approaches Gemini 3 Pro on several benchmarks and comes closer to GPT-5-class systems than its parameter count might suggest. While benchmark hill-climbing is increasingly common, what matters more is overall competitiveness—and MiroThinker holds up well.Extended Tool Use: Up to 400 Tool Calls per SessionThe defining capability of MiroThinker 1.5 is sustained tool use.The models support up to 256,000 tokens of context and claim support for up to 400 tool calls per session—a critical requirement for complex research workflows involving extensive information gathering, synthesis, and cross-checking.This places MiroThinker firmly in the emerging category of agentic models designed for autonomous task completion rather than single-turn Q&A. Practical applications include deep research workflows, content pipelines, report generation, and podcast-style outputs similar to NotebookLM.Training Innovation: Time-Sensitive SandboxAnother major innovation in MiroThinker 1.5 is its Time-Sensitive Training Sandbox.Traditional model training operates from what MiroMind describes as a “God’s-eye view,” where the model has access to finalized outcomes within static datasets—creating hindsight bias. MiroThinker’s training removes that advantage.During training, the model can only interact with information published before a given timestamp, preventing future leakage and forcing it to reason under realistic conditions of incomplete information.The pipeline combines supervised fine-tuning with reinforcement learning using verifiable rewards via Group Relative Policy Optimization (GRPO), an advanced reinforcement learning algorithm popularized by DeepSeek,, encouraging the model to select the right tool at the right time.This approach is especially relevant for enterprise use cases where models must reason about evolving situations rather than recall static facts.Practical Deployment ConsiderationsFor IT teams considering deployment, hardware requirements still matter. Even the 30B model requires a substantial amount of GPU memory, and smaller setups may struggle.One advantage is compatibility. MiroThinker runs on vLLM servers with OpenAI-compatible API endpoints, making it easier to integrate into existing toolchains and function-calling workflows as a drop-in replacement.Both model sizes are available under the permissive, enterprise-friendly MIT license on Hugging Face, and an online demo is available for evaluation. The permissive license removes major barriers to internal deployment and fine-tuning.The Bigger Picture: Interactive Scaling vs. Parameter ScalingMiroThinker 1.5 arrives as the industry confronts the limits of traditional scaling laws. Bigger models no longer guarantee better real-world performance. As Artificial Analysis has noted, many benchmarks are saturated, pushing the industry toward evaluations based on economic usefulness rather than abstract reasoning alone.MiroMind’s bet is on interactive scaling—improving capability through deeper tool interaction rather than ever-larger parameter counts. If correct, this could enable sophisticated agents on infrastructure that does not depend on expensive frontier APIs.The company, founded by Tianqiao Chen and AI scientist Jifeng Dai, describes its mission as building “Native Intelligence”—AI that reasons through interaction, not memorization.Whether this approach becomes dominant or remains a specialized niche is still an open question. But for enterprises wrestling with cost-capability tradeoffs, MiroThinker 1.5 offers a compelling data point: sometimes, teaching a model how to research matters more than teaching it to remember everything.",
          "content": "Joining the ranks of a growing number of smaller, powerful reasoning models is MiroThinker 1.5 from MiroMind, with just 30 billion parameters, compared to the hundreds of billions or trillions used by leading foundation large language models (LLMs).But MiroThinker 1.5 stands out among these smaller reasoners for one major reason: it offers agentic research capabilities rivaling trillion-parameter competitors like Kimi K2 and DeepSeek, at a fraction of the inference cost.The release marks a milestone in the push toward efficient, deployable AI agents. Enterprises have long been forced to choose between expensive API calls to frontier models or compromised local performance. MiroThinker 1.5 offers a third path: open-weight models architected specifically for extended tool use and multi-step reasoning.One of the biggest trends emerging in the industry is a move away from highly specialized agents toward more generalized ones. Until recently, that capability was largely limited to proprietary models. MiroThinker 1.5 represents a serious open-weight contender in this space. Watch my YouTube video on it below. Reduced Hallucination Risk Through Verifiable ReasoningFor IT teams evaluating AI deployment, hallucinations remain the primary barrier to using open models in production. MiroThinker 1.5 addresses this through what MiroMind calls “scientist mode”—a fundamental architectural shift in how the model handles uncertainty.Rather than generating statistically plausible answers from memorized patterns (the root cause of most hallucinations), MiroThinker is trained to execute a verifiable research loop: propose hypotheses, query external sources for evidence, identify mismatches, revise conclusions, and verify again. During training, the model is explicitly penalized for high-confidence outputs that lack source support.The practical implication for enterprise deployment is auditability. When MiroThinker produces an answer, it can surface both the reasoning chain and the external sources it consulted. For regulated industries such as financial services, healthcare, and legal, this creates a documentation trail that memorization-based models cannot provide. Compliance teams can review not just what the model concluded, but how it arrived there.This approach also reduces the “confident hallucination” problem common in production AI systems. The model is trained to seek verification rather than extrapolate when uncertain—a behavior that translates directly into fewer costly errors.Benchmark Performance: Punching Above Its WeightUnder this framework, MiroThinker-v1.5-30B delivers performance comparable to models with up to 30× more parameters, including the trillion-parameter Kimi-K2-Thinking model. On BrowseComp-ZH, a key benchmark for web research capabilities, the 30B model actually outperformed its trillion-parameter competitor with a score of 69.8.The cost differential is equally notable. MiroMind reports inference costs as low as $0.07 per call for the 30B variant—roughly one-twentieth the cost of Kimi-K2-Thinking—along with faster inference speeds.A larger 235B variant (with 22B active parameters in a mixture-of-experts architecture) ranks in the global top tier across multiple search-agent benchmarks. On general agentic search evaluations, these models hold their own against systems from DeepSeek V3.2, Minimax, GLM, and Kimi-K2.In testing, the larger model approaches Gemini 3 Pro on several benchmarks and comes closer to GPT-5-class systems than its parameter count might suggest. While benchmark hill-climbing is increasingly common, what matters more is overall competitiveness—and MiroThinker holds up well.Extended Tool Use: Up to 400 Tool Calls per SessionThe defining capability of MiroThinker 1.5 is sustained tool use.The models support up to 256,000 tokens of context and claim support for up to 400 tool calls per session—a critical requirement for complex research workflows involving extensive information gathering, synthesis, and cross-checking.This places MiroThinker firmly in the emerging category of agentic models designed for autonomous task completion rather than single-turn Q&A. Practical applications include deep research workflows, content pipelines, report generation, and podcast-style outputs similar to NotebookLM.Training Innovation: Time-Sensitive SandboxAnother major innovation in MiroThinker 1.5 is its Time-Sensitive Training Sandbox.Traditional model training operates from what MiroMind describes as a “God’s-eye view,” where the model has access to finalized outcomes within static datasets—creating hindsight bias. MiroThinker’s training removes that advantage.During training, the model can only interact with information published before a given timestamp, preventing future leakage and forcing it to reason under realistic conditions of incomplete information.The pipeline combines supervised fine-tuning with reinforcement learning using verifiable rewards via Group Relative Policy Optimization (GRPO), an advanced reinforcement learning algorithm popularized by DeepSeek,, encouraging the model to select the right tool at the right time.This approach is especially relevant for enterprise use cases where models must reason about evolving situations rather than recall static facts.Practical Deployment ConsiderationsFor IT teams considering deployment, hardware requirements still matter. Even the 30B model requires a substantial amount of GPU memory, and smaller setups may struggle.One advantage is compatibility. MiroThinker runs on vLLM servers with OpenAI-compatible API endpoints, making it easier to integrate into existing toolchains and function-calling workflows as a drop-in replacement.Both model sizes are available under the permissive, enterprise-friendly MIT license on Hugging Face, and an online demo is available for evaluation. The permissive license removes major barriers to internal deployment and fine-tuning.The Bigger Picture: Interactive Scaling vs. Parameter ScalingMiroThinker 1.5 arrives as the industry confronts the limits of traditional scaling laws. Bigger models no longer guarantee better real-world performance. As Artificial Analysis has noted, many benchmarks are saturated, pushing the industry toward evaluations based on economic usefulness rather than abstract reasoning alone.MiroMind’s bet is on interactive scaling—improving capability through deeper tool interaction rather than ever-larger parameter counts. If correct, this could enable sophisticated agents on infrastructure that does not depend on expensive frontier APIs.The company, founded by Tianqiao Chen and AI scientist Jifeng Dai, describes its mission as building “Native Intelligence”—AI that reasons through interaction, not memorization.Whether this approach becomes dominant or remains a specialized niche is still an open question. But for enterprises wrestling with cost-capability tradeoffs, MiroThinker 1.5 offers a compelling data point: sometimes, teaching a model how to research matters more than teaching it to remember everything.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4JZCpN5sylmpNpKz7jO5bV/ff3e503930eca5d2ffa19af2850655d7/2b3QFPO19j-jSAfp4COGk.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/why-ai-feels-generic-replit-ceo-on-slop-toys-and-the-missing-ingredient-of",
          "published_at": "Wed, 07 Jan 2026 23:00:00 GMT",
          "title": "Why AI feels generic: Replit CEO on slop, toys, and the missing ingredient of taste",
          "standfirst": "Right now in the AI world, there are a lot of percolating ideas and experimentation. But as far as Replit CEO Amjad Masad is concerned, they&#x27;re just \"toys\": unreliable, marginally effective, and generic. “There&#x27;s a lot of sameness out there,” Masad explains in a new VB Beyond the Pilot podcast. “Everything kind of looks the same, all the images, all the code, everything.”This \"slop,\" as it’s come to be known, is not only the result of lazy one-shot prompting, but a lack of individual flavor. “The way to overcome slop is for the platform to expend more effort and for the developers of the platform to imbue the agent with taste,” Masad says.How Replit overcomes being generic Replit tackles the slop problem through a mix of specialized prompting, classification features built into its design systems, and proprietary RAG techniques. The team also isn’t hesitant to use more tokens; this results in higher-quality inputs, Masad notes. Ongoing testing is also critical. After the first generation of an app, Masad’s team kicks the result off to a testing agent, which analyzes all its features, then reports back to a coding agent about what worked (and didn’t). “If you introduce testing in the loop, you can give the model feedback and have the model reflect on its work,” Masad says. Pitting models against one another is another of Replit&#x27;s strategies: Testing agents may be built on one LLM, coding agents on another. This capitalizes on their different knowledge distributions. “That way the product you&#x27;re giving to the customer is high effort and less sloppy,” Masad says. “You generate more variety.” Ultimately, he describes a “push and pull” between what the model can actually do and what teams need to build on top of it to add value. Also, “if you wanna move fast and you wanna ship things, you need to throw away a lot of code,” he says. Why vibe coding is the future There’s still a lot of frustration around AI because, Masad acknowledges, it isn’t living up to the intense hype. Chatbots are well-established but they offer a “marginal improvement” in workflows. Vibe coding is beginning to take off partly because it&#x27;s the best way for companies to adopt AI in an impactful way, he notes. It can “make everyone in the enterprise the software engineer,” he says, allowing employees to solve problems and improve efficiency through automation, thus requiring less reliance on traditional SaaS tools. “I would say that the population of professional developers who studied computer science and trained as developers will shrink over time,” Masad says. On the flip side, the population of vibe coders who can solve problems with software and agents will grow “tremendously” over time. In the end, enterprises must fundamentally change how they think about software; traditional roadmaps are no longer relevant, Masad says. Because AI capabilities are evolving so dramatically, builders can only “roughly” estimate what things might look like months or even weeks into the future. Reflecting this reality, Replit’s team remains agile and isn’t hesitant to “drop everything” when a new model comes out to perform evals. “It&#x27;ll ebb and flow,” Masad contends. “You need to be very zen about it and not have an ego about it.” Listen to the full podcast to hear about: The “squishy” divide in AI intelligence that impedes specialization;The cathedral versus bazaar debate in open source — and why a “cathedral made of bazaars” may be the best path to collective innovation;How Replit “forks” the development environment to create isolated sandboxes for experimentation; The importance of context compression; What really defines AI agents: They don’t just retrieve information; they work autonomously, repeatedly, without human intervention. Subscribe to Beyond the Pilot on Apple Podcasts, Spotify and YouTube.",
          "content": "Right now in the AI world, there are a lot of percolating ideas and experimentation. But as far as Replit CEO Amjad Masad is concerned, they&#x27;re just \"toys\": unreliable, marginally effective, and generic. “There&#x27;s a lot of sameness out there,” Masad explains in a new VB Beyond the Pilot podcast. “Everything kind of looks the same, all the images, all the code, everything.”This \"slop,\" as it’s come to be known, is not only the result of lazy one-shot prompting, but a lack of individual flavor. “The way to overcome slop is for the platform to expend more effort and for the developers of the platform to imbue the agent with taste,” Masad says.How Replit overcomes being generic Replit tackles the slop problem through a mix of specialized prompting, classification features built into its design systems, and proprietary RAG techniques. The team also isn’t hesitant to use more tokens; this results in higher-quality inputs, Masad notes. Ongoing testing is also critical. After the first generation of an app, Masad’s team kicks the result off to a testing agent, which analyzes all its features, then reports back to a coding agent about what worked (and didn’t). “If you introduce testing in the loop, you can give the model feedback and have the model reflect on its work,” Masad says. Pitting models against one another is another of Replit&#x27;s strategies: Testing agents may be built on one LLM, coding agents on another. This capitalizes on their different knowledge distributions. “That way the product you&#x27;re giving to the customer is high effort and less sloppy,” Masad says. “You generate more variety.” Ultimately, he describes a “push and pull” between what the model can actually do and what teams need to build on top of it to add value. Also, “if you wanna move fast and you wanna ship things, you need to throw away a lot of code,” he says. Why vibe coding is the future There’s still a lot of frustration around AI because, Masad acknowledges, it isn’t living up to the intense hype. Chatbots are well-established but they offer a “marginal improvement” in workflows. Vibe coding is beginning to take off partly because it&#x27;s the best way for companies to adopt AI in an impactful way, he notes. It can “make everyone in the enterprise the software engineer,” he says, allowing employees to solve problems and improve efficiency through automation, thus requiring less reliance on traditional SaaS tools. “I would say that the population of professional developers who studied computer science and trained as developers will shrink over time,” Masad says. On the flip side, the population of vibe coders who can solve problems with software and agents will grow “tremendously” over time. In the end, enterprises must fundamentally change how they think about software; traditional roadmaps are no longer relevant, Masad says. Because AI capabilities are evolving so dramatically, builders can only “roughly” estimate what things might look like months or even weeks into the future. Reflecting this reality, Replit’s team remains agile and isn’t hesitant to “drop everything” when a new model comes out to perform evals. “It&#x27;ll ebb and flow,” Masad contends. “You need to be very zen about it and not have an ego about it.” Listen to the full podcast to hear about: The “squishy” divide in AI intelligence that impedes specialization;The cathedral versus bazaar debate in open source — and why a “cathedral made of bazaars” may be the best path to collective innovation;How Replit “forks” the development environment to create isolated sandboxes for experimentation; The importance of context compression; What really defines AI agents: They don’t just retrieve information; they work autonomously, repeatedly, without human intervention. Subscribe to Beyond the Pilot on Apple Podcasts, Spotify and YouTube.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/x3JXsaOyoUreUP6akGFIe/1096ba4aa0ed316378a0bba77e430c04/Replit-Slop.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/samsung-display-ces-2026-playful-demos-and-mysterious-prototypes-220407696.html",
          "published_at": "Wed, 07 Jan 2026 22:04:07 +0000",
          "title": "Samsung Display at CES 2026: Playful demos and mysterious prototypes",
          "standfirst": "Samsung Display is the part of its giant parent company that makes OLEDs, LCDs and other screens for both Samsung devices and anyone else that can afford them. This year, it’s going all-in on OLEDs of the future. And that meant things like foldable displays with invisible creases, robots hurling basketballs at supertough OLED panels, and OLED screens packed into baffling form factors for no good reason. Creases Samsung Display The “seamless” foldable display that might be a part of a future foldable iPhone disappeared from the booth during our tour, reappearing when it was time to leave. (This is an image provided by Samsung Display.) The device was labelled as an R&D concept, but it somehow disguised the crease in the center of the main display, making the (unlabelled) Galaxy Z Fold on the left look like a messy first-iteration foldable. There's still a crease there Will it actually form part of Apple’s foray into foldables, or just part of the Z Fold 8? Why not both? Put an OLED on it Mat Smith for Engadget This isn’t a record player you’ll ever buy. You don’t need an OLED display on the side of your wireless headphones, but you could have them. I liked the cute OLED pendants; a customizable near-future button badge, but a lot of this is just devices for the sake of making them. The booth tour had a small segment dedicated to portable gaming OLED, adding more possibilities whether that’s an eye-sight for FPS games or extra HUD for the most important info. The world’s brightest OLED TV Mat Smith for Engadget Reaching 4,500-nit brightness, I had to squint when sat in front of this beastly OLED. For reference, consumer-level TVs typically peak at around 2,700 nits. Compared to other display technologies, OLED can achieve deeper contrast and more accurate color reproduction, but it often lacks the brightness of rival TV technologies. Not for this prototype. Let me get my sunglasses. Kobe! Mat Smith for Engadget I didn’t consider OLED displays to be more fragile than other display technology, but that didn’t stop Samsung Display from installing a robot arm that throws a basketball at a hoop with a backboard made of 18 foldable OLEDs. With a bang, making Samsung Display execs and engineers nearby increasingly anxious as the days of CES go on. Foldables have come a long way Mat Smith for Engadget After Samsung finally solved the problem of weight and thickness with the Galaxy Z Fold 7, it made life hard for itself again with the TriFold, with 50 percent more foldable screen. But it's worth seeing how Samsung’s foldables have evolved over the past few years. A solid reminder that the first Galaxy Fold (2019) was beefy. The next big thing in gaming displays Mat Smith for Engadget Samsung Display has begun mass production of its 360Hz QD-OLED panel, with new “V-Stripe” RGB pixel structures. Inside each pixel, subpixels are vertically aligned, which appears to improve the clarity of text edges and other small contrast objects. While it was framed at the booth as a boon for office workers, a corner was dedicated to gaming applications. Screens across your sedan Mat Smith for Engadget Digital cockpits are the lifeblood of a CES showfloor, and Samsung Display’s version is predictably loaded with yet more OLEDs. The centerpiece is a “Flexible L” display that flows into the dashboard. A dedicated 13.8-inch display on the passenger side also slides out of the dash.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/samsung-display-ces-2026-playful-demos-and-mysterious-prototypes-220407696.html?src=rss",
          "content": "Samsung Display is the part of its giant parent company that makes OLEDs, LCDs and other screens for both Samsung devices and anyone else that can afford them. This year, it’s going all-in on OLEDs of the future. And that meant things like foldable displays with invisible creases, robots hurling basketballs at supertough OLED panels, and OLED screens packed into baffling form factors for no good reason. Creases Samsung Display The “seamless” foldable display that might be a part of a future foldable iPhone disappeared from the booth during our tour, reappearing when it was time to leave. (This is an image provided by Samsung Display.) The device was labelled as an R&D concept, but it somehow disguised the crease in the center of the main display, making the (unlabelled) Galaxy Z Fold on the left look like a messy first-iteration foldable. There's still a crease there Will it actually form part of Apple’s foray into foldables, or just part of the Z Fold 8? Why not both? Put an OLED on it Mat Smith for Engadget This isn’t a record player you’ll ever buy. You don’t need an OLED display on the side of your wireless headphones, but you could have them. I liked the cute OLED pendants; a customizable near-future button badge, but a lot of this is just devices for the sake of making them. The booth tour had a small segment dedicated to portable gaming OLED, adding more possibilities whether that’s an eye-sight for FPS games or extra HUD for the most important info. The world’s brightest OLED TV Mat Smith for Engadget Reaching 4,500-nit brightness, I had to squint when sat in front of this beastly OLED. For reference, consumer-level TVs typically peak at around 2,700 nits. Compared to other display technologies, OLED can achieve deeper contrast and more accurate color reproduction, but it often lacks the brightness of rival TV technologies. Not for this prototype. Let me get my sunglasses. Kobe! Mat Smith for Engadget I didn’t consider OLED displays to be more fragile than other display technology, but that didn’t stop Samsung Display from installing a robot arm that throws a basketball at a hoop with a backboard made of 18 foldable OLEDs. With a bang, making Samsung Display execs and engineers nearby increasingly anxious as the days of CES go on. Foldables have come a long way Mat Smith for Engadget After Samsung finally solved the problem of weight and thickness with the Galaxy Z Fold 7, it made life hard for itself again with the TriFold, with 50 percent more foldable screen. But it's worth seeing how Samsung’s foldables have evolved over the past few years. A solid reminder that the first Galaxy Fold (2019) was beefy. The next big thing in gaming displays Mat Smith for Engadget Samsung Display has begun mass production of its 360Hz QD-OLED panel, with new “V-Stripe” RGB pixel structures. Inside each pixel, subpixels are vertically aligned, which appears to improve the clarity of text edges and other small contrast objects. While it was framed at the booth as a boon for office workers, a corner was dedicated to gaming applications. Screens across your sedan Mat Smith for Engadget Digital cockpits are the lifeblood of a CES showfloor, and Samsung Display’s version is predictably loaded with yet more OLEDs. The centerpiece is a “Flexible L” display that flows into the dashboard. A dedicated 13.8-inch display on the passenger side also slides out of the dash.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/samsung-display-ces-2026-playful-demos-and-mysterious-prototypes-220407696.html?src=rss",
          "feed_position": 29,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/02758cb0-ec12-11f0-b35d-5627e1ac245d"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/this-haptic-wristband-pairs-with-meta-smart-glasses-to-decode-facial-expressions-214305431.html",
          "published_at": "Wed, 07 Jan 2026 21:43:05 +0000",
          "title": "This haptic wristband pairs with Meta smart glasses to decode facial expressions",
          "standfirst": "It's only been a few months since Meta announced that it would open its smart glasses platform to third-party developers. But one startup at CES is already showing off how the glasses can help power an intriguing set of accessibility features.Hapware has created Aleye, a haptic wristband that, when paired with Ray-Ban Meta smart glasses, can help people understand the facial expressions and other nonverbal cues of the people they are talking to. The company says the device could help people who are blind, low vision or neurodivergent unlock a type of communication that otherwise wouldn't be available.Aleye is a somewhat chunky wristband that can vibrate in specific patterns on your wrist to correspond to the facial expressions and gestures of the person you're talking to. It uses the Meta Ray-Ban glasses's computer vision abilities to stream video of your conversation to the accompanying app, which uses an algorithm to detect facial expressions and gestures.The bumps on the underside of the Aleye vibrate to form unique patterns.Karissa Bell for EngadgetUsers can customize which expressions and gestures they want to detect in the app, which also provides a way for people to learn to distinguish between the different patterns. Hapware CEO Jack Walters said in their early testing people have been able to learn a handful of patterns within a few minutes. The company has also tried to make them intuitive. \"Jaw drop might feel like a jaw drop, a wave feels more like a side to side haptics,\" he explains.The app is also able to use Meta AI to give vocal cues about people's expressions, though Hapware's CTO Dr. Bryan Duarte told me it can get a bit distracting to talk to people while the assistant is babbling in your ear. Duarte, who has been blind since a motorcycle accident at the age of 18, told me he prefers Aleye to Meta AI's other accessibility features like Live AI. \"It will only tell me there's a person in front of me,\" he explains. \"It won't tell me if you're smiling. You have to prompt it every time, it won't just tell you stuff.\"Hapware has started taking pre-orders for the Aleye, which starts at $359 for the wristband or $637 for the wristband plus a year subscription to the app (a subscription is required and otherwise will cost $29 a month). A pair of Ray-Ban Meta glasses is also not included, though Meta has also been building a number of its own accessibility features for the device.This article originally appeared on Engadget at https://www.engadget.com/wearables/this-haptic-wristband-pairs-with-meta-smart-glasses-to-decode-facial-expressions-214305431.html?src=rss",
          "content": "It's only been a few months since Meta announced that it would open its smart glasses platform to third-party developers. But one startup at CES is already showing off how the glasses can help power an intriguing set of accessibility features.Hapware has created Aleye, a haptic wristband that, when paired with Ray-Ban Meta smart glasses, can help people understand the facial expressions and other nonverbal cues of the people they are talking to. The company says the device could help people who are blind, low vision or neurodivergent unlock a type of communication that otherwise wouldn't be available.Aleye is a somewhat chunky wristband that can vibrate in specific patterns on your wrist to correspond to the facial expressions and gestures of the person you're talking to. It uses the Meta Ray-Ban glasses's computer vision abilities to stream video of your conversation to the accompanying app, which uses an algorithm to detect facial expressions and gestures.The bumps on the underside of the Aleye vibrate to form unique patterns.Karissa Bell for EngadgetUsers can customize which expressions and gestures they want to detect in the app, which also provides a way for people to learn to distinguish between the different patterns. Hapware CEO Jack Walters said in their early testing people have been able to learn a handful of patterns within a few minutes. The company has also tried to make them intuitive. \"Jaw drop might feel like a jaw drop, a wave feels more like a side to side haptics,\" he explains.The app is also able to use Meta AI to give vocal cues about people's expressions, though Hapware's CTO Dr. Bryan Duarte told me it can get a bit distracting to talk to people while the assistant is babbling in your ear. Duarte, who has been blind since a motorcycle accident at the age of 18, told me he prefers Aleye to Meta AI's other accessibility features like Live AI. \"It will only tell me there's a person in front of me,\" he explains. \"It won't tell me if you're smiling. You have to prompt it every time, it won't just tell you stuff.\"Hapware has started taking pre-orders for the Aleye, which starts at $359 for the wristband or $637 for the wristband plus a year subscription to the app (a subscription is required and otherwise will cost $29 a month). A pair of Ray-Ban Meta glasses is also not included, though Meta has also been building a number of its own accessibility features for the device.This article originally appeared on Engadget at https://www.engadget.com/wearables/this-haptic-wristband-pairs-with-meta-smart-glasses-to-decode-facial-expressions-214305431.html?src=rss",
          "feed_position": 30,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/alleye_haptics.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html",
          "published_at": "Wed, 07 Jan 2026 20:26:30 +0000",
          "title": "The best VPN deals: Up to 88 percent off ProtonVPN, Surfshark, ExpressVPN, NordVPN and more",
          "standfirst": "It's a new year, and a great time to fulfill your resolution to practice better cybersecurity. The early days of January are a great time to grab a last-minute subscription for yourself or a loved one. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. Although we strongly recommend using a VPN, jumping on the first deal that comes along might get you stuck with a substandard app. Beyond that, even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Plenty of the best VPNs — including our top pick, Proton VPN — are still running end-of-year deals that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're comfortable with a service before you take the plunge, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $78.18 for a two-year subscription with four months free (78 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 78 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $100.58 for a two-year subscription with four months free (74 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $81.36 for a two-year subscription (70 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 70 percent off the two-year plan. NordVPN Plus — $105.36 for a two-year subscription (70 percent off): NordVPN has also taken 70 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $67.23 for a two-year subscription with three months free (87 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with four months free (84 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 28 months of CyberGhost for 84 percent off the usual price, but it'll renew at $56.94 per year. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "content": "It's a new year, and a great time to fulfill your resolution to practice better cybersecurity. The early days of January are a great time to grab a last-minute subscription for yourself or a loved one. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. Although we strongly recommend using a VPN, jumping on the first deal that comes along might get you stuck with a substandard app. Beyond that, even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Plenty of the best VPNs — including our top pick, Proton VPN — are still running end-of-year deals that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're comfortable with a service before you take the plunge, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $78.18 for a two-year subscription with four months free (78 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 78 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $100.58 for a two-year subscription with four months free (74 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $81.36 for a two-year subscription (70 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 70 percent off the two-year plan. NordVPN Plus — $105.36 for a two-year subscription (70 percent off): NordVPN has also taken 70 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $67.23 for a two-year subscription with three months free (87 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with four months free (84 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 28 months of CyberGhost for 84 percent off the usual price, but it'll renew at $56.94 per year. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "feed_position": 32
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/how-to-use-a-vpn-on-iphone-201743118.html",
          "published_at": "Wed, 07 Jan 2026 20:17:43 +0000",
          "title": "How to use a VPN on iPhone",
          "standfirst": "Installing a virtual private network (VPN) on an iPhone or iPad is easy. The days are gone when Apple users had to be content with the leavings from the Windows ecosystem — in 2026, all the best VPN services have secure, user-friendly iOS apps on par with every other platform. If you've decided to add a VPN to your iPhone to stay anonymous online and change your virtual location, you've got plenty of great choices.Since you're here, chances are you're familiar with the benefits of using a VPN, including security on public Wi-Fi and the ability to explore streaming libraries in other countries. But you may still be daunted by the process of actually choosing, installing and configuring a VPN on your iPhone.In this article, I'll walk you through the steps, including how to configure a VPN manually without going through a service. Check out my how to use a VPN piece for more general information.How to choose an iPhone VPNOne of the trickiest parts of installing an iPhone VPN is picking the right service. That brings us to our first pro tip: Don’t just go to the App Store and search on “VPN.” That will simply front-load whichever vendor(s) are paying for top placement (note the little “Ad” icon) as well as a laundry list of free services that come with big caveats. There are dozens of mobile VPNs out there, and many of them don't put the user first (for example, I reported last year on popular VPNs that failed to disclose shared security flaws). Choosing hastily can leave you stuck with an iOS VPN that's either mediocre or actively harmful.Before downloading an iPhone VPN, do some research into the provider's background. A dependable VPN should have a well-written customer support page, a clear timeline of its history and a way to tell at a glance who actually owns and operates it. Check the reviews on the app store — it should have at least several hundred, almost all 4s and 5s.iPhone users have a particular advantage here: several VPNs let you download their iOS app and start using it without paying. You can use this free trial period to put the VPN through its paces. Start by testing its speed using Ookla speedtest or a similar app. You should also use an IP address checker to make sure it isn't leaking; to confirm this, just check your phone's IP address before and after connecting to the VPN and make sure it's different the second time.To keep things simple, my top recommendation for all platforms is Proton VPN. Out of all VPNs, it strikes the best balance of solid security, fast performance, useful features and a commitment to user privacy. Other iPhone VPNs I love include ExpressVPN, Surfshark and NordVPN.How to install a VPN on your iPhoneInstalling an iPhone VPN is like installing any other app. Just go to the App Store, find the VPN you've chosen and download it onto your phone. When it finishes downloading, open the app to grant permissions and finish setup. However, since there are a couple of potential sticking points, I'll run through the steps in more detail.Proton VPN on the iOS app store.Sam Chapman for EngadgetOpen the App Store.Tap the search bar and type in the name of your chosen VPN. Hit Search and look through the list of results. Be careful to pick the right one — there are some \"mockbuster\" VPNs that try to snare people looking for well-known names. As a rule, the one with the most reviews is the service worth using.On the page for the VPN app, tap Get. Enter your Apple ID and password to begin the installation.Once installation is complete, either tap Open in the App Store or find the new VPN icon on your home screen.Create a VPN account with a username and password. Most services let you do this within the app, but you may have to shift temporarily to a browser, so make sure you've got internet access.Choose a subscription. If there's a free trial, grab it and use it to test the VPN. If not, or if it's already expired, choose a plan that fits your budget and needs. Longer-term plans tend to save you money on average, but cost more at the start.On the VPN app, log in with your new credentials. You're now ready to get started.If you aren't interested in paying for software right now, you can still get an iOS VPN. Check out my list of the best free VPNs, which all have iPhone apps. We also constantly update a curated list of the best VPN deals for bargain hunters.How to configure and use a VPN on your iPhoneAn iOS VPN is generally usable with the default settings. Even so, it's a good idea to look through the options — you may not end up using all of them, but many of them are vital security checks or important quality-of-life boosters.Proton VPN's NetShield content blocker on iOS.Sam Chapman for EngadgetHere are some quick steps to make sure you're getting the best performance. These settings are in different places on each VPN, but most can be found by clicking a button with a gear icon, or any page labeled \"settings\" or \"preferences.\"Turn on the kill switch. This will protect you from broadcasting any data the VPN hasn't encrypted. In the event the VPN suddenly disconnects, the kill switch also cuts off your internet connection.Set the VPN to always reconnect automatically if it disconnects. The method for doing this varies between services, so check the VPN's help page. Some (like Proton VPN) have an always-on VPN setting in the app itself, while others (like ExpressVPN) handle it through iOS settings.Configure split tunneling. Not many iPhone VPNs have this option, but if yours does, you can use it to let certain apps or websites skip the VPN tunnel. Make sure to only bypass the VPN on sites and apps that share no sensitive information, or that refuse to work with a VPN active (some banks are like this).If your VPN has a feature for blocking ads and malware domains, I recommend using it — the worst it can do is not work. Some also include parental controls, in case you're setting up the VPN on your child's phone.Create shortcuts. Sometimes called Profiles, this relatively common feature lets you connect to the VPN and open a certain website with one tap.Decide when and how you want the VPN to send you notifications.Check available protocols. It's almost always best to let the VPN pick for you, but if you want to choose for yourself, IKEv2 is generally the fastest.Look over the server list to see what choices are available.When choosing a VPN server, think about what you need the VPN for. If you're just using it for privacy, pick the fastest server (or let the VPN app choose it for you). On the other hand, if you want to watch a movie or TV show that's only on streaming in another country, choose the fastest server in that country. If you're on a good VPN, it still shouldn't slow you down too much.If you have the address of a VPN server and the necessary credentials, iOS lets you set up your own VPN and connect directly. This is less convenient than using a provider app, since you need to know the details about every server you connect to, but it's nice if you're worried about trusting your privacy to a third party. It can also be convenient for quickly accessing a work or school VPN from your phone. Here's how to do it.Manually setting up a VPN connection on iOS.Sam Chapman for EngadgetOpen the Settings app. Scroll down and tap General.Scroll down again and tap VPN & Device Management. Tap the word VPN on the new page, then tap Add VPN Configuration. You should reach the screen shown above.Make sure Type is set to IKEv2, then enter the Description, Server and Remote ID for the server you're connecting to (plus the Local ID if there is one).Your source for the server information should also have told you if it authenticates access with a username/password or certificate. Pick the correct option, then enter the credentials required.Tap the Done button or the blue checkmark at the top-right of the screen.You'll arrive back on the previous menu with your new VPN option available. Toggle it on to connect. To turn it off, return to the same menu and deactivate the switch.Do you need an iPhone VPN?Whenever you get online, your internet service provider (ISP) assigns an IP address to your device — a unique fingerprint that follows you throughout the session. Your ISP may sell this knowledge to marketers to target ads at you, or in worse cases, collaborate with governments willing to violate their citizens' rights to privacy.When you use a VPN, though, your real IP address is hidden behind that of the VPN server, so nothing you do on the internet connects back to you. That's why I always advise using a VPN on any device, including iPhones, that connects to the internet. It's even more important on the unprotected public networks you sometimes find in cafes and hotels. On the fun side, you can also use a VPN to change your virtual location to show you different content libraries on Netflix and other streaming platforms.One more thing: I often hear iPhone users ask whether they need a VPN, since iCloud Private Relay comes standard on iOS devices. Just to clear this up, iCloud Private Relay is not a VPN. As you can see from this support page, your ISP can still see your real IP address when it’s active.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-use-a-vpn-on-iphone-201743118.html?src=rss",
          "content": "Installing a virtual private network (VPN) on an iPhone or iPad is easy. The days are gone when Apple users had to be content with the leavings from the Windows ecosystem — in 2026, all the best VPN services have secure, user-friendly iOS apps on par with every other platform. If you've decided to add a VPN to your iPhone to stay anonymous online and change your virtual location, you've got plenty of great choices.Since you're here, chances are you're familiar with the benefits of using a VPN, including security on public Wi-Fi and the ability to explore streaming libraries in other countries. But you may still be daunted by the process of actually choosing, installing and configuring a VPN on your iPhone.In this article, I'll walk you through the steps, including how to configure a VPN manually without going through a service. Check out my how to use a VPN piece for more general information.How to choose an iPhone VPNOne of the trickiest parts of installing an iPhone VPN is picking the right service. That brings us to our first pro tip: Don’t just go to the App Store and search on “VPN.” That will simply front-load whichever vendor(s) are paying for top placement (note the little “Ad” icon) as well as a laundry list of free services that come with big caveats. There are dozens of mobile VPNs out there, and many of them don't put the user first (for example, I reported last year on popular VPNs that failed to disclose shared security flaws). Choosing hastily can leave you stuck with an iOS VPN that's either mediocre or actively harmful.Before downloading an iPhone VPN, do some research into the provider's background. A dependable VPN should have a well-written customer support page, a clear timeline of its history and a way to tell at a glance who actually owns and operates it. Check the reviews on the app store — it should have at least several hundred, almost all 4s and 5s.iPhone users have a particular advantage here: several VPNs let you download their iOS app and start using it without paying. You can use this free trial period to put the VPN through its paces. Start by testing its speed using Ookla speedtest or a similar app. You should also use an IP address checker to make sure it isn't leaking; to confirm this, just check your phone's IP address before and after connecting to the VPN and make sure it's different the second time.To keep things simple, my top recommendation for all platforms is Proton VPN. Out of all VPNs, it strikes the best balance of solid security, fast performance, useful features and a commitment to user privacy. Other iPhone VPNs I love include ExpressVPN, Surfshark and NordVPN.How to install a VPN on your iPhoneInstalling an iPhone VPN is like installing any other app. Just go to the App Store, find the VPN you've chosen and download it onto your phone. When it finishes downloading, open the app to grant permissions and finish setup. However, since there are a couple of potential sticking points, I'll run through the steps in more detail.Proton VPN on the iOS app store.Sam Chapman for EngadgetOpen the App Store.Tap the search bar and type in the name of your chosen VPN. Hit Search and look through the list of results. Be careful to pick the right one — there are some \"mockbuster\" VPNs that try to snare people looking for well-known names. As a rule, the one with the most reviews is the service worth using.On the page for the VPN app, tap Get. Enter your Apple ID and password to begin the installation.Once installation is complete, either tap Open in the App Store or find the new VPN icon on your home screen.Create a VPN account with a username and password. Most services let you do this within the app, but you may have to shift temporarily to a browser, so make sure you've got internet access.Choose a subscription. If there's a free trial, grab it and use it to test the VPN. If not, or if it's already expired, choose a plan that fits your budget and needs. Longer-term plans tend to save you money on average, but cost more at the start.On the VPN app, log in with your new credentials. You're now ready to get started.If you aren't interested in paying for software right now, you can still get an iOS VPN. Check out my list of the best free VPNs, which all have iPhone apps. We also constantly update a curated list of the best VPN deals for bargain hunters.How to configure and use a VPN on your iPhoneAn iOS VPN is generally usable with the default settings. Even so, it's a good idea to look through the options — you may not end up using all of them, but many of them are vital security checks or important quality-of-life boosters.Proton VPN's NetShield content blocker on iOS.Sam Chapman for EngadgetHere are some quick steps to make sure you're getting the best performance. These settings are in different places on each VPN, but most can be found by clicking a button with a gear icon, or any page labeled \"settings\" or \"preferences.\"Turn on the kill switch. This will protect you from broadcasting any data the VPN hasn't encrypted. In the event the VPN suddenly disconnects, the kill switch also cuts off your internet connection.Set the VPN to always reconnect automatically if it disconnects. The method for doing this varies between services, so check the VPN's help page. Some (like Proton VPN) have an always-on VPN setting in the app itself, while others (like ExpressVPN) handle it through iOS settings.Configure split tunneling. Not many iPhone VPNs have this option, but if yours does, you can use it to let certain apps or websites skip the VPN tunnel. Make sure to only bypass the VPN on sites and apps that share no sensitive information, or that refuse to work with a VPN active (some banks are like this).If your VPN has a feature for blocking ads and malware domains, I recommend using it — the worst it can do is not work. Some also include parental controls, in case you're setting up the VPN on your child's phone.Create shortcuts. Sometimes called Profiles, this relatively common feature lets you connect to the VPN and open a certain website with one tap.Decide when and how you want the VPN to send you notifications.Check available protocols. It's almost always best to let the VPN pick for you, but if you want to choose for yourself, IKEv2 is generally the fastest.Look over the server list to see what choices are available.When choosing a VPN server, think about what you need the VPN for. If you're just using it for privacy, pick the fastest server (or let the VPN app choose it for you). On the other hand, if you want to watch a movie or TV show that's only on streaming in another country, choose the fastest server in that country. If you're on a good VPN, it still shouldn't slow you down too much.If you have the address of a VPN server and the necessary credentials, iOS lets you set up your own VPN and connect directly. This is less convenient than using a provider app, since you need to know the details about every server you connect to, but it's nice if you're worried about trusting your privacy to a third party. It can also be convenient for quickly accessing a work or school VPN from your phone. Here's how to do it.Manually setting up a VPN connection on iOS.Sam Chapman for EngadgetOpen the Settings app. Scroll down and tap General.Scroll down again and tap VPN & Device Management. Tap the word VPN on the new page, then tap Add VPN Configuration. You should reach the screen shown above.Make sure Type is set to IKEv2, then enter the Description, Server and Remote ID for the server you're connecting to (plus the Local ID if there is one).Your source for the server information should also have told you if it authenticates access with a username/password or certificate. Pick the correct option, then enter the credentials required.Tap the Done button or the blue checkmark at the top-right of the screen.You'll arrive back on the previous menu with your new VPN option available. Toggle it on to connect. To turn it off, return to the same menu and deactivate the switch.Do you need an iPhone VPN?Whenever you get online, your internet service provider (ISP) assigns an IP address to your device — a unique fingerprint that follows you throughout the session. Your ISP may sell this knowledge to marketers to target ads at you, or in worse cases, collaborate with governments willing to violate their citizens' rights to privacy.When you use a VPN, though, your real IP address is hidden behind that of the VPN server, so nothing you do on the internet connects back to you. That's why I always advise using a VPN on any device, including iPhones, that connects to the internet. It's even more important on the unprotected public networks you sometimes find in cafes and hotels. On the fun side, you can also use a VPN to change your virtual location to show you different content libraries on Netflix and other streaming platforms.One more thing: I often hear iPhone users ask whether they need a VPN, since iCloud Private Relay comes standard on iOS devices. Just to clear this up, iCloud Private Relay is not a VPN. As you can see from this support page, your ISP can still see your real IP address when it’s active.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-use-a-vpn-on-iphone-201743118.html?src=rss",
          "feed_position": 34,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/IMG_4077.PNG"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
          "published_at": "Wed, 07 Jan 2026 20:00:00 GMT",
          "title": "Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment",
          "standfirst": "Nous Research, the open-source artificial intelligence startup backed by crypto venture firm Paradigm, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&#x27;s latest B200 graphics processors.The model, called NousCoder-14B, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: Claude Code, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&#x27;s Day, with developers posting breathless testimonials about its capabilities. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.type: embedded-entry-inline id: 74cSyrq6OUrp9SEQ5zOUSlNousCoder-14B achieves a 67.87 percent accuracy rate on LiveCodeBench v6, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&#x27;s Qwen3-14B, according to Nous Research&#x27;s technical report published alongside the release.\"I gave Claude Code a description of the problem, it generated what we built last year in an hour,\" wrote Jaana Dogan, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.The juxtaposition is instructive: while Anthropic&#x27;s Claude Code has captured imaginations with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.How Nous Research built an AI coding model that anyone can replicateWhat distinguishes the NousCoder-14B release from many competitor announcements is its radical openness. Nous Research published not just the model weights but the complete reinforcement learning environment, benchmark suite, and training harness — built on the company&#x27;s Atropos framework — enabling any researcher with sufficient compute to reproduce or extend the work.\"Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,\" noted one observer on X, summarizing the significance for the academic and open-source communities.The model was trained by Joe Li, a researcher in residence at Nous Research and a former competitive programmer himself. Li&#x27;s technical report reveals an unexpectedly personal dimension: he compared the model&#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.\"Watching that final training run unfold was quite a surreal experience,\" Li wrote in the technical report.But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.Inside the reinforcement learning system that trains on 24,000 competitive programming problemsNousCoder-14B&#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.The approach relies on what researchers call \"verifiable rewards\" — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.Nous Research used Modal, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.The training employed a technique called DAPO (Dynamic Sampling Policy Optimization), which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves \"dynamic sampling\" — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.The researchers also adopted \"iterative context extension,\" first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.The looming data shortage that could slow AI coding model progressBuried in Li&#x27;s technical report is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses \"a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.\"In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.\"The total number of competitive programming problems on the Internet is roughly the same order of magnitude,\" Li wrote, referring to the 24,000 problems used for training. \"This suggests that within the competitive programming domain, we have approached the limits of high-quality data.\"This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is \"increasingly finite,\" as Li put it.\"It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,\" he concluded.The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&#x27;t — making synthetic data generation considerably more difficult.Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. \"Once synthetic problem generation is solved, self-play becomes a very interesting direction,\" he wrote.A $65 million bet that open-source AI can compete with Big TechNous Research has carved out a distinctive position in the AI landscape: a company committed to open-source releases that compete with — and sometimes exceed — proprietary alternatives.The company raised $50 million in April 2025 in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its Psyche platform.Previous releases include Hermes 4, a family of models that we reported \"outperform ChatGPT without content restrictions,\" and DeepHermes-3, which the company described as the first \"toggle-on reasoning model\" — allowing users to activate extended thinking capabilities on demand.The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. \"Ofc i&#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,\" wrote one critic on X, referring to Nous Research&#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.Others raised technical questions. \"Based on the benchmark, Nemotron is better,\" noted one commenter, referring to Nvidia&#x27;s family of language models. Another asked whether NousCoder-14B is \"agentic focused or just &#x27;one shot&#x27; coding\" — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.What researchers say must happen next for AI coding tools to keep improvingThe release includes several directions for future work that hint at where AI coding research may be heading.Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.Perhaps most ambitiously, Li proposed \"problem generation and self-play\" — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.\"Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,\" Li wrote.The model is available now on Hugging Face under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete Atropos training stack alongside it.What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.The question is no longer whether machines can learn to code. It&#x27;s whether they&#x27;ll soon be better teachers than we ever were.",
          "content": "Nous Research, the open-source artificial intelligence startup backed by crypto venture firm Paradigm, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&#x27;s latest B200 graphics processors.The model, called NousCoder-14B, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: Claude Code, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&#x27;s Day, with developers posting breathless testimonials about its capabilities. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.type: embedded-entry-inline id: 74cSyrq6OUrp9SEQ5zOUSlNousCoder-14B achieves a 67.87 percent accuracy rate on LiveCodeBench v6, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&#x27;s Qwen3-14B, according to Nous Research&#x27;s technical report published alongside the release.\"I gave Claude Code a description of the problem, it generated what we built last year in an hour,\" wrote Jaana Dogan, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.The juxtaposition is instructive: while Anthropic&#x27;s Claude Code has captured imaginations with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.How Nous Research built an AI coding model that anyone can replicateWhat distinguishes the NousCoder-14B release from many competitor announcements is its radical openness. Nous Research published not just the model weights but the complete reinforcement learning environment, benchmark suite, and training harness — built on the company&#x27;s Atropos framework — enabling any researcher with sufficient compute to reproduce or extend the work.\"Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,\" noted one observer on X, summarizing the significance for the academic and open-source communities.The model was trained by Joe Li, a researcher in residence at Nous Research and a former competitive programmer himself. Li&#x27;s technical report reveals an unexpectedly personal dimension: he compared the model&#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.\"Watching that final training run unfold was quite a surreal experience,\" Li wrote in the technical report.But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.Inside the reinforcement learning system that trains on 24,000 competitive programming problemsNousCoder-14B&#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.The approach relies on what researchers call \"verifiable rewards\" — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.Nous Research used Modal, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.The training employed a technique called DAPO (Dynamic Sampling Policy Optimization), which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves \"dynamic sampling\" — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.The researchers also adopted \"iterative context extension,\" first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.The looming data shortage that could slow AI coding model progressBuried in Li&#x27;s technical report is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses \"a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.\"In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.\"The total number of competitive programming problems on the Internet is roughly the same order of magnitude,\" Li wrote, referring to the 24,000 problems used for training. \"This suggests that within the competitive programming domain, we have approached the limits of high-quality data.\"This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is \"increasingly finite,\" as Li put it.\"It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,\" he concluded.The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&#x27;t — making synthetic data generation considerably more difficult.Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. \"Once synthetic problem generation is solved, self-play becomes a very interesting direction,\" he wrote.A $65 million bet that open-source AI can compete with Big TechNous Research has carved out a distinctive position in the AI landscape: a company committed to open-source releases that compete with — and sometimes exceed — proprietary alternatives.The company raised $50 million in April 2025 in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its Psyche platform.Previous releases include Hermes 4, a family of models that we reported \"outperform ChatGPT without content restrictions,\" and DeepHermes-3, which the company described as the first \"toggle-on reasoning model\" — allowing users to activate extended thinking capabilities on demand.The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. \"Ofc i&#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,\" wrote one critic on X, referring to Nous Research&#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.Others raised technical questions. \"Based on the benchmark, Nemotron is better,\" noted one commenter, referring to Nvidia&#x27;s family of language models. Another asked whether NousCoder-14B is \"agentic focused or just &#x27;one shot&#x27; coding\" — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.What researchers say must happen next for AI coding tools to keep improvingThe release includes several directions for future work that hint at where AI coding research may be heading.Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.Perhaps most ambitiously, Li proposed \"problem generation and self-play\" — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.\"Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,\" Li wrote.The model is available now on Hugging Face under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete Atropos training stack alongside it.What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.The question is no longer whether machines can learn to code. It&#x27;s whether they&#x27;ll soon be better teachers than we ever were.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/66Tw6dMGGoSZZOK6XB6gm6/0fafc7520898e26c88edf1de9e74e863/nuneybits_Vector_art_of_radiant_skull_emitting_code_beams_deep__17d19acc-0af7-41ad-ac28-16f09ef5234b.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/hps-new-eliteboard-made-me-believe-in-keyboard-computers-again-033000022.html",
          "published_at": "Wed, 07 Jan 2026 19:44:36 +0000",
          "title": "HP's new EliteBoard made me believe in keyboard computers again",
          "standfirst": "A keyboard computer has always been on my wishlist — that is, a computer where the entire machine was stuffed into a keyboard. Perhaps I caught a glimpse of the Commodore 64 at an impressionable age, but regardless, the idea has always been intriguing to me. At CES 2026, HP is bringing that concept back with the new EliteBoard G1a, which is dubbed a “Next Gen AI PC.”It's an IT administrator's dream: It looks a typical desktop keyboard, but it has the full power of a Copilot+ AI PC inside. You can equip it with Ryzen 5 or 7 CPUs and their embedded Radeon 800 GPUs, up to 64GB of RAM and as much as 2TB of NVMe SSD storage. All you need to do is add a monitor and a mouse, and you've got a full-fledged desktop setup.HP EliteBoard keyboard PC.Devindra Hardawar for EngadgetThe more I think about it, the more sad I am that the arc of the computing industry trended towards standardized desktops and laptops. There was a brief spark of interest with the UMPC (ultra mobile PC) trend in the 2000's, which Engadget covered extensively as a young blog, as well as ASUS's Eee keyboard. But they couldn't survive the rise of the smartphone and tablet. It turns out putting an entire computer behind a screen was more compelling than stuffing them into a keyboard. I was able to test out an early EliteBoard prototype, and while the experience wasn't perfect, it's still an intriguing computing option. I had trouble setting it up initially because it only had two USB-C ports on its rear, which meant I had to find a way to power it through one port and pass a video signal through the other. Thankfully, my Anker USB-C charging hub was able to juice it up, and I also had a USB-C hub with an HDMI port, which allowed me to connect to my monitor.Sadly, the overall setup was a jumble of wires, and not the clean layout I expected from a keyboard PC. Once I was able to start up Windows though, I was less annoyed and more amazed that the keyboard contained an entire computer. I suppose I shouldn't be too surprised, as Intel's Compute Stick placed a functional PC in a much smaller case, but unlike the failed product, the EliteBoard actually felt usable. I was able to load up several browser windows with tabs, edit a few photos and even play a few light games, like Vampire Survivors. And yes, typing on it felt pretty great too.HP EliteBoard keyboard PC.Devindra Hardawar for EngadgetSince I was testing out prototype hardware, I agreed not to benchmark the EliteBoard. But from the performance I saw, it felt about the same an entry-level laptop. Basically, it's perfectly suited to its main task: Being a boring office computer. Back in my IT days, I certainly would have preferred deploying a few light keyboards instead of the tank-like Dell desktops we typically ordered.While the EliteBoard is targeted at commercial users, HP is considering it an experiment to see how people respond to a keyboard PC. There's a chance we could see one that's eventually meant for mainstream consumers. I'm not sure if that's exactly, necessary, though. The whole concept of a desktop PC mainly appeals to tinkerers and IT folks. And for anyone who wants to get their hands on an EliteBoard soon, there's really nothing stopping you.This article originally appeared on Engadget at https://www.engadget.com/computing/hps-new-eliteboard-made-me-believe-in-keyboard-computers-again-033000022.html?src=rss",
          "content": "A keyboard computer has always been on my wishlist — that is, a computer where the entire machine was stuffed into a keyboard. Perhaps I caught a glimpse of the Commodore 64 at an impressionable age, but regardless, the idea has always been intriguing to me. At CES 2026, HP is bringing that concept back with the new EliteBoard G1a, which is dubbed a “Next Gen AI PC.”It's an IT administrator's dream: It looks a typical desktop keyboard, but it has the full power of a Copilot+ AI PC inside. You can equip it with Ryzen 5 or 7 CPUs and their embedded Radeon 800 GPUs, up to 64GB of RAM and as much as 2TB of NVMe SSD storage. All you need to do is add a monitor and a mouse, and you've got a full-fledged desktop setup.HP EliteBoard keyboard PC.Devindra Hardawar for EngadgetThe more I think about it, the more sad I am that the arc of the computing industry trended towards standardized desktops and laptops. There was a brief spark of interest with the UMPC (ultra mobile PC) trend in the 2000's, which Engadget covered extensively as a young blog, as well as ASUS's Eee keyboard. But they couldn't survive the rise of the smartphone and tablet. It turns out putting an entire computer behind a screen was more compelling than stuffing them into a keyboard. I was able to test out an early EliteBoard prototype, and while the experience wasn't perfect, it's still an intriguing computing option. I had trouble setting it up initially because it only had two USB-C ports on its rear, which meant I had to find a way to power it through one port and pass a video signal through the other. Thankfully, my Anker USB-C charging hub was able to juice it up, and I also had a USB-C hub with an HDMI port, which allowed me to connect to my monitor.Sadly, the overall setup was a jumble of wires, and not the clean layout I expected from a keyboard PC. Once I was able to start up Windows though, I was less annoyed and more amazed that the keyboard contained an entire computer. I suppose I shouldn't be too surprised, as Intel's Compute Stick placed a functional PC in a much smaller case, but unlike the failed product, the EliteBoard actually felt usable. I was able to load up several browser windows with tabs, edit a few photos and even play a few light games, like Vampire Survivors. And yes, typing on it felt pretty great too.HP EliteBoard keyboard PC.Devindra Hardawar for EngadgetSince I was testing out prototype hardware, I agreed not to benchmark the EliteBoard. But from the performance I saw, it felt about the same an entry-level laptop. Basically, it's perfectly suited to its main task: Being a boring office computer. Back in my IT days, I certainly would have preferred deploying a few light keyboards instead of the tank-like Dell desktops we typically ordered.While the EliteBoard is targeted at commercial users, HP is considering it an experiment to see how people respond to a keyboard PC. There's a chance we could see one that's eventually meant for mainstream consumers. I'm not sure if that's exactly, necessary, though. The whole concept of a desktop PC mainly appeals to tinkerers and IT folks. And for anyone who wants to get their hands on an EliteBoard soon, there's really nothing stopping you.This article originally appeared on Engadget at https://www.engadget.com/computing/hps-new-eliteboard-made-me-believe-in-keyboard-computers-again-033000022.html?src=rss",
          "feed_position": 37,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/HP_EliteBoard-1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/asus-and-xreal-teamed-up-at-ces-to-make-gaming-smartglasses-with-two-important-upgrades-190500897.html",
          "published_at": "Wed, 07 Jan 2026 19:05:00 +0000",
          "title": "ASUS and XREAL teamed up at CES to make gaming smartglasses with two important upgrades",
          "standfirst": "The latest generation of smartglasses can create huge virtual screens without the need to lug around giant monitors are a real boon to frequent travelers. However, their specs aren’t often tailored to the needs of gamers, so at CES 2026, ASUS and XREAL partnered to make a pair with two very important features you don’t normally get from rivals. The new ROG XREAL R1 AR glasses are based on the existing XREAL One Pro, so naturally they share a lot of the same components and specs including dual micro-OLED displays with a per-eye resolution of 1,920 x 1,080, three degrees of freedom (natively), 700-nit peak brightness, 57-degree FOV and built-in speakers tuned by Bose. However, the big difference on the R1s is that instead of maxing out with a 120Hz refresh rate, ASUS and XREAL’s collab goes all the way up to 240Hz. That’s a pretty nice bump, especially for people with older hardware or anyone who might not have access to a high refresh rate display or just doesn’t want to lower their standards while traveling. The ROG XREAL R1 AR smartglasses deliver 1,920 x 1,080 resolution to each eye with a 240Hz refresh rate and 57-degree FOV. Sam Rutherford for EngadgetThe other big addition is the R1’s included ROG Control Dock, which from what I’ve seen is slightly better suited for home use. It’s designed to be a simple hub with two HDMI 2.0 jacks, one DisplayPort 1.4 connector and a couple of USB-C slots (one is for power), so you can quickly switch between multiple systems like your desktop and console with a single touch. That said, depending on the situation you might not even need the dock at all because the R1s can also be connected to compatible PCs or gaming handhelds like the ROG Ally X and ROG Xbox Ally X (see the synergy there?) directly via USB-C. When I got to try them out at CES, the R1s delivered a very easy to use and relatively streamlined kit. At 91 grams, they are barely heavier than the original XREAL One Pro (87g) so they don’t feel too weighty or cumbersome. I also really like the inclusion of electrochromic lenses, which allow you to change the tint of the glasses with the touch of a button. This lets you adjust how much or little light you want to come in through the front to best suit your environment. And thanks to support for three DOF, you have the ability to pin your virtual screen in one location or let it follow you around. Of course, ASUS and XREAL couldn't resist putting RGB lighting on the ROG XREAL R1 AR smartglasses. Sam Rutherford for EngadgetNow it is important to remember that in order to get 240Hz on the smartglasses, you need hardware capable of pushing the kind of performance. So depending on the title, when the R1s are connected to something like a gaming handheld, you might not be able to get there. Luckily, I had the chance to use the specs when connected to a PC as well, which let me really appreciate the smoothness you get from faster refresh rates. General image quality was also quite good thanks to the glasses’ 1080p resolution, so I had no trouble reading text or discerning small UI elements. The ROG Control dock makes it easy to connect multiple devices to the ROG XREAL R1 AR smartglasses, but it may be a bit too bulky to pull out in tight situations like on a plane. Sam Rutherford for EngadgetMy one small gripe is that I kind of wish its 57-degree FOV was a tiny bit bigger, but that’s more of a limitation of current optical technology as there aren't a ton of similarly sized specs that can go much higher (at least not yet). That said, even with its current FOV, you can still create up to a 171-inch virtual screen at four meters away, which is massively bigger than any portable screen you might entertain carrying around.Unfortunately, ASUS and XREAL haven’t announced official pricing or a release date for the R1s yet, but hopefully they won’t cost too much more than the XREAL One Pro, which are currently going for $649.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/asus-and-xreal-teamed-up-at-ces-to-make-gaming-smartglasses-with-two-important-upgrades-190500897.html?src=rss",
          "content": "The latest generation of smartglasses can create huge virtual screens without the need to lug around giant monitors are a real boon to frequent travelers. However, their specs aren’t often tailored to the needs of gamers, so at CES 2026, ASUS and XREAL partnered to make a pair with two very important features you don’t normally get from rivals. The new ROG XREAL R1 AR glasses are based on the existing XREAL One Pro, so naturally they share a lot of the same components and specs including dual micro-OLED displays with a per-eye resolution of 1,920 x 1,080, three degrees of freedom (natively), 700-nit peak brightness, 57-degree FOV and built-in speakers tuned by Bose. However, the big difference on the R1s is that instead of maxing out with a 120Hz refresh rate, ASUS and XREAL’s collab goes all the way up to 240Hz. That’s a pretty nice bump, especially for people with older hardware or anyone who might not have access to a high refresh rate display or just doesn’t want to lower their standards while traveling. The ROG XREAL R1 AR smartglasses deliver 1,920 x 1,080 resolution to each eye with a 240Hz refresh rate and 57-degree FOV. Sam Rutherford for EngadgetThe other big addition is the R1’s included ROG Control Dock, which from what I’ve seen is slightly better suited for home use. It’s designed to be a simple hub with two HDMI 2.0 jacks, one DisplayPort 1.4 connector and a couple of USB-C slots (one is for power), so you can quickly switch between multiple systems like your desktop and console with a single touch. That said, depending on the situation you might not even need the dock at all because the R1s can also be connected to compatible PCs or gaming handhelds like the ROG Ally X and ROG Xbox Ally X (see the synergy there?) directly via USB-C. When I got to try them out at CES, the R1s delivered a very easy to use and relatively streamlined kit. At 91 grams, they are barely heavier than the original XREAL One Pro (87g) so they don’t feel too weighty or cumbersome. I also really like the inclusion of electrochromic lenses, which allow you to change the tint of the glasses with the touch of a button. This lets you adjust how much or little light you want to come in through the front to best suit your environment. And thanks to support for three DOF, you have the ability to pin your virtual screen in one location or let it follow you around. Of course, ASUS and XREAL couldn't resist putting RGB lighting on the ROG XREAL R1 AR smartglasses. Sam Rutherford for EngadgetNow it is important to remember that in order to get 240Hz on the smartglasses, you need hardware capable of pushing the kind of performance. So depending on the title, when the R1s are connected to something like a gaming handheld, you might not be able to get there. Luckily, I had the chance to use the specs when connected to a PC as well, which let me really appreciate the smoothness you get from faster refresh rates. General image quality was also quite good thanks to the glasses’ 1080p resolution, so I had no trouble reading text or discerning small UI elements. The ROG Control dock makes it easy to connect multiple devices to the ROG XREAL R1 AR smartglasses, but it may be a bit too bulky to pull out in tight situations like on a plane. Sam Rutherford for EngadgetMy one small gripe is that I kind of wish its 57-degree FOV was a tiny bit bigger, but that’s more of a limitation of current optical technology as there aren't a ton of similarly sized specs that can go much higher (at least not yet). That said, even with its current FOV, you can still create up to a 171-inch virtual screen at four meters away, which is massively bigger than any portable screen you might entertain carrying around.Unfortunately, ASUS and XREAL haven’t announced official pricing or a release date for the R1s yet, but hopefully they won’t cost too much more than the XREAL One Pro, which are currently going for $649.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/asus-and-xreal-teamed-up-at-ces-to-make-gaming-smartglasses-with-two-important-upgrades-190500897.html?src=rss",
          "feed_position": 39,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/ROG-Xreal-R1-lenses.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/brunswicks-latest-boats-at-ces-2026-feature-edge-ai-self-docking-capabilities-and-solar-power-185500213.html",
          "published_at": "Wed, 07 Jan 2026 18:55:00 +0000",
          "title": "Brunswick's latest boats at CES 2026 feature edge AI, self-docking capabilities and solar power",
          "standfirst": "If you've never docked a boat before, consider yourself lucky. There are plenty of popular TikTok channels devoted to shaming those who bring their craft back home clumsily or berth them with something less than finesse. Tricky crosswinds, unpredictable surf and even the jeers of passersby can make it a stressful experience at the best of times.Brunswick, which owns more than 50 water-borne brands like Sea Ray, Bayliner and Mercury Marine, has a solution. It's demonstrating some self-docking tech called AutoCaptain at CES 2026 that makes this process a cinch, plus a fleet of other innovations that, in some cases, leave some of the smart cars on the show floor looking a bit remedial.One of those technologies is edge AI. While in-car AI is an increasingly common feature, those agents are exclusively running remotely, relying on cellular connections to offload all the processing power required to drive a large language model.Sadly, that won't always work on a boat.One of Brunswick's tech-equipped boatsBrunswick\"One of the things about AI for boats is you don't have connectivity, so there is some edge compute required,\" David M. Foulkes told me. He's chairman and CEO of Brunswick.Many of the company's boats do have active cellular connectivity, but head far enough offshore, and you're on your own unless you're packing Starlink or the like.To solve that, Brunswick is running advanced SoCs from NVIDIA and other providers that enable running a limited agent offline — on the edge, as it were. When offline, Misty, as the on-boat AI assistant is called, won't be able to make dinner reservations or craft a 3,000-word treatise on the history of America's relationship with Greenland. It can, however, help with navigation or boat settings.\"It'll help answer the kind of questions that you might need to take out a manual to understand and maybe act as an assistant to make your boating a bit smoother,\" Foulkes said.When the company's smart boats are connected, they offer some degree of remote control. No, you can't drive it around the docks and freak out your pier-mates, but you can check on the boat remotely to make sure nobody's trying to stow away. You can even precondition it to get the cuddy cabin nice and cool before you come aboard.Navan C30Power for that, and a variety of other onboard systems, can come from an integrated power system called Fathom, which has a lot in common with modern smart home tech. Solar panels on the roof (nicely disguised beneath a black mesh) collect power to recharge an onboard battery, with various sizes upwards of 30 kWh depending on the boat's size. That battery can also be recharged by the onboard motors, like the three 425-horsepower V10s the Sea Ray SLX 360 drydocked at the Brunswick booth at CES 2026.The juice in that battery can then be used to power a variety of onboard systems, even charging a pair of electric hydrofoils, which another of the company's boats, called the Navan C30, had strapped on the roof.You'll also find cameras on the roof of these boats. That's how the AutoCaptain feature works, numerous fisheye lenses scanning the water in every direction. Approach a pier and the AI assistant asks if you'd like some help docking. Just tap the button on the touchscreen, then kick back and let Misty do the driving.Between automated docking, the in-cabin AI assistant and the smart power distribution system, Brunswick's boats offered some impressive tech. But then they'd have to, given the cost. The Sea Ray SLX 360 Outboard has a starting price of $586,000. The smaller Navan C30 is a rather more attainable, but still extreme, at $227,500. That’s still probably cheaper than hiring a real captain, though.This article originally appeared on Engadget at https://www.engadget.com/transportation/brunswicks-latest-boats-at-ces-2026-feature-edge-ai-self-docking-capabilities-and-solar-power-185500213.html?src=rss",
          "content": "If you've never docked a boat before, consider yourself lucky. There are plenty of popular TikTok channels devoted to shaming those who bring their craft back home clumsily or berth them with something less than finesse. Tricky crosswinds, unpredictable surf and even the jeers of passersby can make it a stressful experience at the best of times.Brunswick, which owns more than 50 water-borne brands like Sea Ray, Bayliner and Mercury Marine, has a solution. It's demonstrating some self-docking tech called AutoCaptain at CES 2026 that makes this process a cinch, plus a fleet of other innovations that, in some cases, leave some of the smart cars on the show floor looking a bit remedial.One of those technologies is edge AI. While in-car AI is an increasingly common feature, those agents are exclusively running remotely, relying on cellular connections to offload all the processing power required to drive a large language model.Sadly, that won't always work on a boat.One of Brunswick's tech-equipped boatsBrunswick\"One of the things about AI for boats is you don't have connectivity, so there is some edge compute required,\" David M. Foulkes told me. He's chairman and CEO of Brunswick.Many of the company's boats do have active cellular connectivity, but head far enough offshore, and you're on your own unless you're packing Starlink or the like.To solve that, Brunswick is running advanced SoCs from NVIDIA and other providers that enable running a limited agent offline — on the edge, as it were. When offline, Misty, as the on-boat AI assistant is called, won't be able to make dinner reservations or craft a 3,000-word treatise on the history of America's relationship with Greenland. It can, however, help with navigation or boat settings.\"It'll help answer the kind of questions that you might need to take out a manual to understand and maybe act as an assistant to make your boating a bit smoother,\" Foulkes said.When the company's smart boats are connected, they offer some degree of remote control. No, you can't drive it around the docks and freak out your pier-mates, but you can check on the boat remotely to make sure nobody's trying to stow away. You can even precondition it to get the cuddy cabin nice and cool before you come aboard.Navan C30Power for that, and a variety of other onboard systems, can come from an integrated power system called Fathom, which has a lot in common with modern smart home tech. Solar panels on the roof (nicely disguised beneath a black mesh) collect power to recharge an onboard battery, with various sizes upwards of 30 kWh depending on the boat's size. That battery can also be recharged by the onboard motors, like the three 425-horsepower V10s the Sea Ray SLX 360 drydocked at the Brunswick booth at CES 2026.The juice in that battery can then be used to power a variety of onboard systems, even charging a pair of electric hydrofoils, which another of the company's boats, called the Navan C30, had strapped on the roof.You'll also find cameras on the roof of these boats. That's how the AutoCaptain feature works, numerous fisheye lenses scanning the water in every direction. Approach a pier and the AI assistant asks if you'd like some help docking. Just tap the button on the touchscreen, then kick back and let Misty do the driving.Between automated docking, the in-cabin AI assistant and the smart power distribution system, Brunswick's boats offered some impressive tech. But then they'd have to, given the cost. The Sea Ray SLX 360 Outboard has a starting price of $586,000. The smaller Navan C30 is a rather more attainable, but still extreme, at $227,500. That’s still probably cheaper than hiring a real captain, though.This article originally appeared on Engadget at https://www.engadget.com/transportation/brunswicks-latest-boats-at-ces-2026-feature-edge-ai-self-docking-capabilities-and-solar-power-185500213.html?src=rss",
          "feed_position": 40,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/2026-SLX-360-Outboard-SXO360-aerial-overhead-underwater-accent-lighting-twilight-08558.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/segway-launches-two-more-e-bikes-at-ces-130000152.html",
          "published_at": "Wed, 07 Jan 2026 17:49:42 +0000",
          "title": "Segway launches two more e-bikes at CES",
          "standfirst": "I’m no psychologist, but I get a sense Segway turned up to CES 2026 with something to prove after last year. Certainly, it’s gone out of its way to prove its micromobility bona fides with the press, who perhaps were a bit too sniffy that scooter people were launching an e-bike. This year, Segway’s not just launching two more mainstream e-bikes, but an electric dirt bike, all of which are crammed with the sort of tech that might just make everyone halt their sniffiness.First up, there’s the Myon, a chunky step-through with a decent-sized pannier rack for folks who want to go far and carry a bit of luggage as they go. That’s hardly an eye-catching proposition given so many e-bikes fit within the same template, but Segway is hoping its tech will make a difference here. Myon is equipped with electronic gear shifting (tied to a Shimano CUES chain drivetrain), electronic motor optimization and the company’s proprietary Intelligent Ride System. The latter, along with Segway(TM) TurboTuned(TM) will automatically optimize motor and battery performance while under way. The company adds that the bike’s built-in gyros, cadence and torque sensors will meter out performance according to road conditions. So if you’re going up hill, the power will gently increase before you have to think about it. Additionally, if you stop at the lights, the system won’t just turn on the power to whatever you’ve set it at as soon as it senses the tiniest ounce of pressure on the pedal, removing the jerky start action you see in other bikes.Segway’s broader pitch is that its bikes will also feature a whole host of smart features, including integration with Apple’s Find My network, GPS tracking, remote locking, integration with your health and fitness app of choice, and smartphone pairing. MuxiSegwayMuxi (pronounced moo-shee) is a more interesting piece of hardware, since it’s been built like a longtail cargo bike, but with the long tail chopped off. Even so, the focus is on cargo, with the bike getting an optional passenger seat with foot pegs, and an optional middle basket. Plus, the bike comes with a beverage cup holder (although given it has a direct drive motor, I’m not sure I’d want to cruise around at low speed while trying to sip my morning latte). To ensure you don’t struggle with your load, the bike comes with Hill Start Assist, Hill Descent Control, regenerative braking and traction control. Plus the aforementioned suite of added value features, like Find My integration, remote locking, GPS and the app integrations. Rounding out the announcements is the Xaber (say-br) 300, an electric dirt bike geared toward off-roading. It has three power modes, letting you learn on the equivalent of a 150cc engine, then dialing that up to 200cc, before topping out at 300cc. If you still want a greater sense of control, you can activate an electronic clutch, and if you want to cede more of it to the bike, you can set the maximum wheelie angle. If you want to enjoy all of that dirt bikin’ action, it’ll set you back $5,300 when it arrives.As for Myon, it’s available to buy today from Segway’s official site and via its dealer network, priced at $2,000. Muxi will be available through those same channels in March, setting you back $1,700. This article originally appeared on Engadget at https://www.engadget.com/transportation/segway-launches-two-more-e-bikes-at-ces-130000152.html?src=rss",
          "content": "I’m no psychologist, but I get a sense Segway turned up to CES 2026 with something to prove after last year. Certainly, it’s gone out of its way to prove its micromobility bona fides with the press, who perhaps were a bit too sniffy that scooter people were launching an e-bike. This year, Segway’s not just launching two more mainstream e-bikes, but an electric dirt bike, all of which are crammed with the sort of tech that might just make everyone halt their sniffiness.First up, there’s the Myon, a chunky step-through with a decent-sized pannier rack for folks who want to go far and carry a bit of luggage as they go. That’s hardly an eye-catching proposition given so many e-bikes fit within the same template, but Segway is hoping its tech will make a difference here. Myon is equipped with electronic gear shifting (tied to a Shimano CUES chain drivetrain), electronic motor optimization and the company’s proprietary Intelligent Ride System. The latter, along with Segway(TM) TurboTuned(TM) will automatically optimize motor and battery performance while under way. The company adds that the bike’s built-in gyros, cadence and torque sensors will meter out performance according to road conditions. So if you’re going up hill, the power will gently increase before you have to think about it. Additionally, if you stop at the lights, the system won’t just turn on the power to whatever you’ve set it at as soon as it senses the tiniest ounce of pressure on the pedal, removing the jerky start action you see in other bikes.Segway’s broader pitch is that its bikes will also feature a whole host of smart features, including integration with Apple’s Find My network, GPS tracking, remote locking, integration with your health and fitness app of choice, and smartphone pairing. MuxiSegwayMuxi (pronounced moo-shee) is a more interesting piece of hardware, since it’s been built like a longtail cargo bike, but with the long tail chopped off. Even so, the focus is on cargo, with the bike getting an optional passenger seat with foot pegs, and an optional middle basket. Plus, the bike comes with a beverage cup holder (although given it has a direct drive motor, I’m not sure I’d want to cruise around at low speed while trying to sip my morning latte). To ensure you don’t struggle with your load, the bike comes with Hill Start Assist, Hill Descent Control, regenerative braking and traction control. Plus the aforementioned suite of added value features, like Find My integration, remote locking, GPS and the app integrations. Rounding out the announcements is the Xaber (say-br) 300, an electric dirt bike geared toward off-roading. It has three power modes, letting you learn on the equivalent of a 150cc engine, then dialing that up to 200cc, before topping out at 300cc. If you still want a greater sense of control, you can activate an electronic clutch, and if you want to cede more of it to the bike, you can set the maximum wheelie angle. If you want to enjoy all of that dirt bikin’ action, it’ll set you back $5,300 when it arrives.As for Myon, it’s available to buy today from Segway’s official site and via its dealer network, priced at $2,000. Muxi will be available through those same channels in March, setting you back $1,700. This article originally appeared on Engadget at https://www.engadget.com/transportation/segway-launches-two-more-e-bikes-at-ces-130000152.html?src=rss",
          "feed_position": 44,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Segway-Muxi-ebike-lifestyle-2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/these-robotic-sneakers-gave-me-a-surprising-boost-at-ces-174500005.html",
          "published_at": "Wed, 07 Jan 2026 17:45:00 +0000",
          "title": "These robotic sneakers gave me a surprising boost at CES",
          "standfirst": "I'll admit that I've always kind of taken walking for granted. Other than a knee injury more than a decade ago, my ability to walk long distances has largely been limited only by my own choices. That's not the case for everyone, though. And robotics company Dephy has created a pair of robotic sneakers, called the Sidekick, that are meant to help people who want to walk more than their bodies might otherwise be capable of.The system consists of two parts: an ankle-worn exoskeleton and a special pair of sneakers that attach to it. The exoskeleton hooks onto the back of the shoe and is secured with a strap around your calf. The battery powered device is equipped with sensors that can detect and adapt to the wearer's gait in order to deliver an extra \"boost\" with each step. The whole setup is pricey, at $4,500, but Dephy is betting that people who have \"personal range anxiety\" might be willing to pay for the extra confidence the Sidekick can provide. \"This is a device that's kind of like [having] an extra calf muscle,\" Dephy CEO Luke Mooney told me. The Sidekick.Karissa Bell for EngadgetI was able to take the Sidekick for a spin around the CES showfloor and it was a truly surprising sensation. The best way I can describe walking with the Sidekick powered on is that with every step forward there's a noticeable upward push from under your heel. It wasn't enough to throw me off balance, but it did feel a bit strange.The Sidekick has adjustable power levels based on how much help you might need. At the highest level, it definitely felt unnecessarily pushy. The lower levels were still noticeable but felt less disruptive. I just felt… bouncy. Later, when Mooney turned off the power entirely, I noticed that my feet felt weirdly heavy in a way they hadn't just a few minutes before. Mooney was quick to tell me that I'm not Dephy's target demographic. \"A lot of times people who are fit, or like athletes, actually struggle to adopt to the technology because their body's so in tune with how they move,\" he said. \"Whereas folks who are not as physically active and fit, their body's ready to accept help.\"The company's technology will be used in products more focused on athletic performance, however. Dephy has partnered with Nike on its upcoming robotic sneaker currently known as Project Amplify. Mooney declined to share details on the collaboration, but the shoemaker has claimed that some early testers have been able to improve their mile times by two minutes. I tried the Sidekick early in the day. Several hours later, though, when I was walking between the Las Vegas Conventions Center halls for the third or fourth time, I started thinking about those robotic sneakers again. I was getting close to 10,000 steps and hadn't sat down for hours. My feet were sore. I remembered that strange, bouncy boost and thought it sounded kind of nice.This article originally appeared on Engadget at https://www.engadget.com/wearables/these-robotic-sneakers-gave-me-a-surprising-boost-at-ces-174500005.html?src=rss",
          "content": "I'll admit that I've always kind of taken walking for granted. Other than a knee injury more than a decade ago, my ability to walk long distances has largely been limited only by my own choices. That's not the case for everyone, though. And robotics company Dephy has created a pair of robotic sneakers, called the Sidekick, that are meant to help people who want to walk more than their bodies might otherwise be capable of.The system consists of two parts: an ankle-worn exoskeleton and a special pair of sneakers that attach to it. The exoskeleton hooks onto the back of the shoe and is secured with a strap around your calf. The battery powered device is equipped with sensors that can detect and adapt to the wearer's gait in order to deliver an extra \"boost\" with each step. The whole setup is pricey, at $4,500, but Dephy is betting that people who have \"personal range anxiety\" might be willing to pay for the extra confidence the Sidekick can provide. \"This is a device that's kind of like [having] an extra calf muscle,\" Dephy CEO Luke Mooney told me. The Sidekick.Karissa Bell for EngadgetI was able to take the Sidekick for a spin around the CES showfloor and it was a truly surprising sensation. The best way I can describe walking with the Sidekick powered on is that with every step forward there's a noticeable upward push from under your heel. It wasn't enough to throw me off balance, but it did feel a bit strange.The Sidekick has adjustable power levels based on how much help you might need. At the highest level, it definitely felt unnecessarily pushy. The lower levels were still noticeable but felt less disruptive. I just felt… bouncy. Later, when Mooney turned off the power entirely, I noticed that my feet felt weirdly heavy in a way they hadn't just a few minutes before. Mooney was quick to tell me that I'm not Dephy's target demographic. \"A lot of times people who are fit, or like athletes, actually struggle to adopt to the technology because their body's so in tune with how they move,\" he said. \"Whereas folks who are not as physically active and fit, their body's ready to accept help.\"The company's technology will be used in products more focused on athletic performance, however. Dephy has partnered with Nike on its upcoming robotic sneaker currently known as Project Amplify. Mooney declined to share details on the collaboration, but the shoemaker has claimed that some early testers have been able to improve their mile times by two minutes. I tried the Sidekick early in the day. Several hours later, though, when I was walking between the Las Vegas Conventions Center halls for the third or fourth time, I started thinking about those robotic sneakers again. I was getting close to 10,000 steps and hadn't sat down for hours. My feet were sore. I remembered that strange, bouncy boost and thought it sounded kind of nice.This article originally appeared on Engadget at https://www.engadget.com/wearables/these-robotic-sneakers-gave-me-a-surprising-boost-at-ces-174500005.html?src=rss",
          "feed_position": 45,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/dephy_black_solo.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/ikeas-first-ces-appearance-included-a-6-matter-smart-bulb-172623474.html",
          "published_at": "Wed, 07 Jan 2026 17:26:23 +0000",
          "title": "IKEA's first CES appearance included a $6 Matter smart bulb",
          "standfirst": "I know IKEA is all about small, efficient spaces, but their meeting room inside the Venetian during the company’s first-ever CES was the same size as my (not large) living room. Plenty of people were as excited as I was to see what the Swedish designers brought with them to the show and the room was thick with humans. A bowl full of BELÖNING bars helped ease my mounting claustrophobia and I was able to check out the new smart home lineup. Like most things IKEA, the 21 Matter-compatible smart home devices are simple, sleek and silly affordable. They include a $6 smart bulb, an $8 smart plug, a $6 smart remote and a slew of home sensors. A slightly pricier ($15) globe bulb is a direct answer to my longstanding wish for more attractive (but affordable) smart bulbs. One of my favorite of the new devices was the BILREA remote control. It’s a smooth, riverstone-like object that either comes with two simple buttons or a button and a scroll wheel. It pairs up with and controls IKEA’s smart devices and lamps but what I really love is the magnetic mount integrated into its body. You can either attach the remote to any ferrous surface or use the small metal chip and included adhesive to give the remote a home on a wall or elsewhere. Why have so few other companies come up with a way to neatly and simply organize these tiny yet crucial controllers? The whole suite is Matter-compatible and, as such, it needs a hub to function. IKEA has its own, DIRIGERA, but, true to the Matter principles of interoperability, you can also use a Matter hub you already own. The new line of smart home devices should start showing up in IKEA stores and on its website sometime in January. Lamps and speakers from the TEKLAN smart home collection.Amy Skorheim for EngadgetApart from the egalitarian and utilitarian items, the Swedish brand also brought a new collection of products, TEKLAN, designed in collaboration with designer and photographer Tekla Evelina Severin. These include circular Bluetooth speakers in color-saturated patterns and solids ranging from eight to 18 inches. There are also two new speaker lamps, called KULGLASS, that have glass lampshades inspired by soft serve ice cream. Those devices went on sale on January 1 this year.Finally, I made my way (three feet) over to the curious, donut-shaped lamps. This is the smart version of the store’s popular VARMBLIXT lamp that debuted three years ago. It’s controllable through the app or the remote I mentioned above and gently cycles through a rainbow of color patterns, shifting slowly from shade to shade. I got lost for a while watching it morph from white to pink to red and back again. For a moment I forgot I was wedged into a room too full of people. I figured those around me probably wanted a look at the lamp for themselves, so I took a longing glance back at the BELÖNING bowl and squeezed out of the room. The popular VARMBLIXT donut lamp is now smart. Amy Skorheim for EngadgetThis article originally appeared on Engadget at https://www.engadget.com/home/smart-home/ikeas-first-ces-appearance-included-a-6-matter-smart-bulb-172623474.html?src=rss",
          "content": "I know IKEA is all about small, efficient spaces, but their meeting room inside the Venetian during the company’s first-ever CES was the same size as my (not large) living room. Plenty of people were as excited as I was to see what the Swedish designers brought with them to the show and the room was thick with humans. A bowl full of BELÖNING bars helped ease my mounting claustrophobia and I was able to check out the new smart home lineup. Like most things IKEA, the 21 Matter-compatible smart home devices are simple, sleek and silly affordable. They include a $6 smart bulb, an $8 smart plug, a $6 smart remote and a slew of home sensors. A slightly pricier ($15) globe bulb is a direct answer to my longstanding wish for more attractive (but affordable) smart bulbs. One of my favorite of the new devices was the BILREA remote control. It’s a smooth, riverstone-like object that either comes with two simple buttons or a button and a scroll wheel. It pairs up with and controls IKEA’s smart devices and lamps but what I really love is the magnetic mount integrated into its body. You can either attach the remote to any ferrous surface or use the small metal chip and included adhesive to give the remote a home on a wall or elsewhere. Why have so few other companies come up with a way to neatly and simply organize these tiny yet crucial controllers? The whole suite is Matter-compatible and, as such, it needs a hub to function. IKEA has its own, DIRIGERA, but, true to the Matter principles of interoperability, you can also use a Matter hub you already own. The new line of smart home devices should start showing up in IKEA stores and on its website sometime in January. Lamps and speakers from the TEKLAN smart home collection.Amy Skorheim for EngadgetApart from the egalitarian and utilitarian items, the Swedish brand also brought a new collection of products, TEKLAN, designed in collaboration with designer and photographer Tekla Evelina Severin. These include circular Bluetooth speakers in color-saturated patterns and solids ranging from eight to 18 inches. There are also two new speaker lamps, called KULGLASS, that have glass lampshades inspired by soft serve ice cream. Those devices went on sale on January 1 this year.Finally, I made my way (three feet) over to the curious, donut-shaped lamps. This is the smart version of the store’s popular VARMBLIXT lamp that debuted three years ago. It’s controllable through the app or the remote I mentioned above and gently cycles through a rainbow of color patterns, shifting slowly from shade to shade. I got lost for a while watching it morph from white to pink to red and back again. For a moment I forgot I was wedged into a room too full of people. I figured those around me probably wanted a look at the lamp for themselves, so I took a longing glance back at the BELÖNING bowl and squeezed out of the room. The popular VARMBLIXT donut lamp is now smart. Amy Skorheim for EngadgetThis article originally appeared on Engadget at https://www.engadget.com/home/smart-home/ikeas-first-ces-appearance-included-a-6-matter-smart-bulb-172623474.html?src=rss",
          "feed_position": 47,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/ikea_lamps_and_speakers.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/how-ralph-wiggum-went-from-the-simpsons-to-the-biggest-name-in-ai-right-now",
          "published_at": "Tue, 06 Jan 2026 20:11:00 GMT",
          "title": "How Ralph Wiggum went from 'The Simpsons' to the biggest name in AI right now",
          "standfirst": "In the fast-moving world of AI development, it is rare for a tool to be described as both \"a meme\" and AGI, artificial generalized intelligence, the \"holy grail\" of a model or system that can reliably outperform humans on economically valuable work. Yet, that is exactly where the Ralph Wiggum plugin for Claude Code now sits. Named after the infamously high-pitched, hapless yet persistent character on The Simpsons, this newish tool (released in summer 2025) — and the philosophy behind it — has set the developer community on X (formerly Twitter) into a tizzy of excitement over the last few weeks.For power users of Anthropic’s hit agentic, quasi-autonomous coding platform Claude Code, Wiggum represents a shift from \"chatting\" with AI to managing autonomous \"night shifts.\" It is a crude but effective step toward agentic coding, transforming the AI from a pair programmer into a relentless worker that doesn’t stop until the job is done.Origin Story: A Tale of Two RalphsTo understand the \"Ralph\" tool is to understand a new approach toward improving autonomous AI coding performance — one that relies on brute force, failure, and repetition as much as it does on raw intelligence and reasoning. Because Ralph Wiggum is not merely a Simpsons character anymore; it is a methodology born on a goat farm and refined in a San Francisco research lab, a divergence best documented in the conversations between its creator and the broader developer community.The story begins in roughly May 2025 with Geoffrey Huntley, a longtime open source software developer who pivoted to raising goats in rural Australia. Huntley was frustrated by a fundamental limitation in the agentic coding workflow: the \"human-in-the-loop\" bottleneck. He realized that while models were capable, they were hamstrung by the user’s need to manually review and re-prompt every error. Huntley’s solution was elegantly brutish. He wrote a 5-line Bash script that he jokingly named after Ralph Wiggum, the dim-witted but relentlessly optimistic and undeterred character from The Simpsons.As Huntley explained in his initial release blog post \"Ralph Wiggum as a &#x27;software engineer,&#x27;\" the idea relied on Context Engineering.By piping the model’s entire output—failures, stack traces, and hallucinations—back into its own input stream for the next iteration, Huntley created a \"contextual pressure cooker.\"This philosophy was further dissected in a recent conversation with Dexter Horthy, co-founder and CEO of the enterprise AI engineering firm HumanLayer, posted on YouTube.Horthy and Huntley argue that the power of the original Ralph wasn&#x27;t just in the looping, but in its \"naive persistence\" — the unsanitized feedback, in which the LLM isn&#x27;t protected from its own mess; it is forced to confront it. It embodies the philosophy that if you press the model hard enough against its own failures without a safety net, it will eventually \"dream\" a correct solution just to escape the loop.By late 2025, Boris Cherny, Anthropic&#x27;s Head of Claude Code* formalized the hack into the official ralph-wiggum plugin. However, as noted by critics in the Horthy/Huntley discussion, the official release marked a shift in philosophy—a \"sterilization\" of the original chaotic concept.While Huntley’s script was about brute force, the official Anthropic plugin was designed around the principle that \"Failures Are Data.\" In the official documentation, the distinction is clear. The Anthropic implementation utilizes a specialized \"Stop Hook\"—a mechanism that intercepts the AI&#x27;s attempt to exit the CLI.Intercept the Exit: When Claude thinks it is done, the plugin pauses execution.Verify Promise: It checks for a specific \"Completion Promise\" (e.g., \"All tests passed\").Feedback Injection: If the promise isn&#x27;t met, the failure is formatted as a structured data object.The \"Tale of Two Ralphs\" offers a critical choice for modern power users:The \"Huntley Ralph\" (Bash Script/Community Forks): Best for chaotic, creative exploration where you want the AI to solve problems through sheer, unbridled persistence.The \"Official Ralph\" (Anthropic Plugin): The standard for enterprise workflows, strictly bound by token limits and safety hooks, designed to fix broken builds reliably without the risk of an infinite hallucination loop.In short: Huntley proved the loop was possible; Anthropic proved it could be safe.What It Offers: The Night Shift for CodersThe documentation is clear on where Ralph shines: new projects and tasks with automatic verification (like tests or linters). But for the \"boring stuff,\" the efficiency gains are becoming the stuff of legend. According to the official plugin documentation on GitHub, the technique has already logged some eye-watering wins. In one case, a developer reportedly completed a $50,000 contract for just $297 in API costs—essentially arbitraging the difference between an expensive human lawyer/coder and a relentless AI loop.The repository also highlights a Y Combinator hackathon stress test where the tool \"successfully generated 6 repositories overnight,\" effectively allowing a single developer to output a small team&#x27;s worth of boilerplate while asleep. Meanwhile, on X, community members like ynkzlk have shared screenshots of Ralph handling the kind of maintenance work engineers dread, such as a 14-hour autonomous session that upgraded a stale codebase from React v16 to v19 entirely without human input.To make this work safely, power users rely on a specific architecture. Matt Pocock, a prominent developer and educator who posted a recent YouTube video overview of why Ralph Wiggum is so powerful.As he states: \"One of the dreams of coding agents is that you can wake up in the morning to working code, that your coding agent has worked through your backlog and has just spit out a whole bunch of code for you to review and it works.\" In Pocock&#x27;s view, Wiggum (the plugin) is about as close as you can come to this dream. It&#x27;s \"a vast improvement over any other AI coding orchestration setup I&#x27;ve ever tried and allows you to actually ship working stuff with longrunning coding agents,\" he states.He advises using strong feedback loops like TypeScript and unit tests. If the code compiles and passes tests, the AI emits the completion promise; if not, the Stop Hook forces it to try again.The Core Innovation: The Stop HookAt its heart, the Ralph Wiggum technique is deceptively simple. As Huntley put it: \"Ralph is a Bash loop.\"However, the official plugin implements this in a clever, technically distinct way. Instead of just running a script on the outside, the plugin installs a \"Stop Hook\" inside your Claude session.You give Claude a task and a \"completion promise\" (e.g., <promise>COMPLETE</promise>).Claude works on the task and tries to exit when it thinks it&#x27;s done.The hook blocks the exit if the promise isn&#x27;t found, feeding the same prompt back into the system.This forces a \"self-referential feedback loop\" where Claude sees its previous work, reads the error logs or git history, and tries again.Pocock describes this as a shift from \"Waterfall\" planning to true \"Agile\" for AI. Instead of forcing the AI to follow a brittle, multi-step plan, Ralph allows the agent to simply \"grab a ticket off the board,\" finish it, and look for the next one.Community Reactions: &#x27;The Closest Thing to AGI&#x27;The reception among the AI builder and developer community on social media has been effusive. Dennison Bertram, CEO and founder of custom cryptocurrency and blockchain token creation platform Tally, posted on X on December 15: \"No joke, this might be the closest thing I&#x27;ve seen to AGI: This prompt is an absolute beast with Claude.\"Arvid Kahl, founder and CEO of automated podcast business intelligence extraction and brand detection tool Podscan, persuasively covered the benefits of Ralph&#x27;s persistent approach in his own X post yesterday:And as Chicago entrepreneur Hunter Hammonds put it: Opus 4.5 + Ralph Wiggum with XcodeBuild and playwright is going to mint millionaires. Mark my words. You’re not readyIn a meta-twist characteristic of the 2025 AI scene, the \"Ralph\" phenomenon didn&#x27;t just generate code—it generated a market.And earlier this week, someone — not Huntley, he says — launched a new $RALPH cryptocurrency token on the Solana blockchain to capitalize on the hype surrounding the plugin. The Catch: Costs and SafetyThe excitement comes with significant caveats. Software firm Better Stack warned users on X about the economic reality of infinite loops:\"The Ralph Wiggum plugin runs Claude Code in autonomous loops... But will those nonstop API calls break your token budget?\"Because the loop runs until success, the documentation advises using \"Escape Hatches.\" Users should always set a --max-iterations flag (e.g., 20 or 50) to prevent the AI from burning through cash on an impossible task.There is also a security dimension. To work effectively, Ralph often requires the --dangerously-skip-permissions flag, granting the AI full control over the terminal. Security experts strictly advise running Ralph sessions in sandboxed environments (like disposable cloud VMs) to prevent the AI from accidentally deleting local files.AvailabilityThe Ralph Wiggum technique is available now for Claude Code users:Official Plugin: Accessible inside Claude Code via /plugin ralph.Original Method: The \"OG\" bash scripts and community forks are available on GitHub.As 2026 begins, Ralph Wiggum has evolved from a Simpsons joke into a defining archetype for software development: Iteration > Perfection.*Correction: This article mistakenly characterized Boris Cherney&#x27;s title. The article has since been updated and corrected, and we regret the error.",
          "content": "In the fast-moving world of AI development, it is rare for a tool to be described as both \"a meme\" and AGI, artificial generalized intelligence, the \"holy grail\" of a model or system that can reliably outperform humans on economically valuable work. Yet, that is exactly where the Ralph Wiggum plugin for Claude Code now sits. Named after the infamously high-pitched, hapless yet persistent character on The Simpsons, this newish tool (released in summer 2025) — and the philosophy behind it — has set the developer community on X (formerly Twitter) into a tizzy of excitement over the last few weeks.For power users of Anthropic’s hit agentic, quasi-autonomous coding platform Claude Code, Wiggum represents a shift from \"chatting\" with AI to managing autonomous \"night shifts.\" It is a crude but effective step toward agentic coding, transforming the AI from a pair programmer into a relentless worker that doesn’t stop until the job is done.Origin Story: A Tale of Two RalphsTo understand the \"Ralph\" tool is to understand a new approach toward improving autonomous AI coding performance — one that relies on brute force, failure, and repetition as much as it does on raw intelligence and reasoning. Because Ralph Wiggum is not merely a Simpsons character anymore; it is a methodology born on a goat farm and refined in a San Francisco research lab, a divergence best documented in the conversations between its creator and the broader developer community.The story begins in roughly May 2025 with Geoffrey Huntley, a longtime open source software developer who pivoted to raising goats in rural Australia. Huntley was frustrated by a fundamental limitation in the agentic coding workflow: the \"human-in-the-loop\" bottleneck. He realized that while models were capable, they were hamstrung by the user’s need to manually review and re-prompt every error. Huntley’s solution was elegantly brutish. He wrote a 5-line Bash script that he jokingly named after Ralph Wiggum, the dim-witted but relentlessly optimistic and undeterred character from The Simpsons.As Huntley explained in his initial release blog post \"Ralph Wiggum as a &#x27;software engineer,&#x27;\" the idea relied on Context Engineering.By piping the model’s entire output—failures, stack traces, and hallucinations—back into its own input stream for the next iteration, Huntley created a \"contextual pressure cooker.\"This philosophy was further dissected in a recent conversation with Dexter Horthy, co-founder and CEO of the enterprise AI engineering firm HumanLayer, posted on YouTube.Horthy and Huntley argue that the power of the original Ralph wasn&#x27;t just in the looping, but in its \"naive persistence\" — the unsanitized feedback, in which the LLM isn&#x27;t protected from its own mess; it is forced to confront it. It embodies the philosophy that if you press the model hard enough against its own failures without a safety net, it will eventually \"dream\" a correct solution just to escape the loop.By late 2025, Boris Cherny, Anthropic&#x27;s Head of Claude Code* formalized the hack into the official ralph-wiggum plugin. However, as noted by critics in the Horthy/Huntley discussion, the official release marked a shift in philosophy—a \"sterilization\" of the original chaotic concept.While Huntley’s script was about brute force, the official Anthropic plugin was designed around the principle that \"Failures Are Data.\" In the official documentation, the distinction is clear. The Anthropic implementation utilizes a specialized \"Stop Hook\"—a mechanism that intercepts the AI&#x27;s attempt to exit the CLI.Intercept the Exit: When Claude thinks it is done, the plugin pauses execution.Verify Promise: It checks for a specific \"Completion Promise\" (e.g., \"All tests passed\").Feedback Injection: If the promise isn&#x27;t met, the failure is formatted as a structured data object.The \"Tale of Two Ralphs\" offers a critical choice for modern power users:The \"Huntley Ralph\" (Bash Script/Community Forks): Best for chaotic, creative exploration where you want the AI to solve problems through sheer, unbridled persistence.The \"Official Ralph\" (Anthropic Plugin): The standard for enterprise workflows, strictly bound by token limits and safety hooks, designed to fix broken builds reliably without the risk of an infinite hallucination loop.In short: Huntley proved the loop was possible; Anthropic proved it could be safe.What It Offers: The Night Shift for CodersThe documentation is clear on where Ralph shines: new projects and tasks with automatic verification (like tests or linters). But for the \"boring stuff,\" the efficiency gains are becoming the stuff of legend. According to the official plugin documentation on GitHub, the technique has already logged some eye-watering wins. In one case, a developer reportedly completed a $50,000 contract for just $297 in API costs—essentially arbitraging the difference between an expensive human lawyer/coder and a relentless AI loop.The repository also highlights a Y Combinator hackathon stress test where the tool \"successfully generated 6 repositories overnight,\" effectively allowing a single developer to output a small team&#x27;s worth of boilerplate while asleep. Meanwhile, on X, community members like ynkzlk have shared screenshots of Ralph handling the kind of maintenance work engineers dread, such as a 14-hour autonomous session that upgraded a stale codebase from React v16 to v19 entirely without human input.To make this work safely, power users rely on a specific architecture. Matt Pocock, a prominent developer and educator who posted a recent YouTube video overview of why Ralph Wiggum is so powerful.As he states: \"One of the dreams of coding agents is that you can wake up in the morning to working code, that your coding agent has worked through your backlog and has just spit out a whole bunch of code for you to review and it works.\" In Pocock&#x27;s view, Wiggum (the plugin) is about as close as you can come to this dream. It&#x27;s \"a vast improvement over any other AI coding orchestration setup I&#x27;ve ever tried and allows you to actually ship working stuff with longrunning coding agents,\" he states.He advises using strong feedback loops like TypeScript and unit tests. If the code compiles and passes tests, the AI emits the completion promise; if not, the Stop Hook forces it to try again.The Core Innovation: The Stop HookAt its heart, the Ralph Wiggum technique is deceptively simple. As Huntley put it: \"Ralph is a Bash loop.\"However, the official plugin implements this in a clever, technically distinct way. Instead of just running a script on the outside, the plugin installs a \"Stop Hook\" inside your Claude session.You give Claude a task and a \"completion promise\" (e.g., <promise>COMPLETE</promise>).Claude works on the task and tries to exit when it thinks it&#x27;s done.The hook blocks the exit if the promise isn&#x27;t found, feeding the same prompt back into the system.This forces a \"self-referential feedback loop\" where Claude sees its previous work, reads the error logs or git history, and tries again.Pocock describes this as a shift from \"Waterfall\" planning to true \"Agile\" for AI. Instead of forcing the AI to follow a brittle, multi-step plan, Ralph allows the agent to simply \"grab a ticket off the board,\" finish it, and look for the next one.Community Reactions: &#x27;The Closest Thing to AGI&#x27;The reception among the AI builder and developer community on social media has been effusive. Dennison Bertram, CEO and founder of custom cryptocurrency and blockchain token creation platform Tally, posted on X on December 15: \"No joke, this might be the closest thing I&#x27;ve seen to AGI: This prompt is an absolute beast with Claude.\"Arvid Kahl, founder and CEO of automated podcast business intelligence extraction and brand detection tool Podscan, persuasively covered the benefits of Ralph&#x27;s persistent approach in his own X post yesterday:And as Chicago entrepreneur Hunter Hammonds put it: Opus 4.5 + Ralph Wiggum with XcodeBuild and playwright is going to mint millionaires. Mark my words. You’re not readyIn a meta-twist characteristic of the 2025 AI scene, the \"Ralph\" phenomenon didn&#x27;t just generate code—it generated a market.And earlier this week, someone — not Huntley, he says — launched a new $RALPH cryptocurrency token on the Solana blockchain to capitalize on the hype surrounding the plugin. The Catch: Costs and SafetyThe excitement comes with significant caveats. Software firm Better Stack warned users on X about the economic reality of infinite loops:\"The Ralph Wiggum plugin runs Claude Code in autonomous loops... But will those nonstop API calls break your token budget?\"Because the loop runs until success, the documentation advises using \"Escape Hatches.\" Users should always set a --max-iterations flag (e.g., 20 or 50) to prevent the AI from burning through cash on an impossible task.There is also a security dimension. To work effectively, Ralph often requires the --dangerously-skip-permissions flag, granting the AI full control over the terminal. Security experts strictly advise running Ralph sessions in sandboxed environments (like disposable cloud VMs) to prevent the AI from accidentally deleting local files.AvailabilityThe Ralph Wiggum technique is available now for Claude Code users:Official Plugin: Accessible inside Claude Code via /plugin ralph.Original Method: The \"OG\" bash scripts and community forks are available on GitHub.As 2026 begins, Ralph Wiggum has evolved from a Simpsons joke into a defining archetype for software development: Iteration > Perfection.*Correction: This article mistakenly characterized Boris Cherney&#x27;s title. The article has since been updated and corrected, and we regret the error.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4noz34EAOxR22KmaNc7jXi/ea6fa9616bdd66f61253b5b69f662527/INsm1_lvrE4rQPmTkgC_N.png?w=300&q=30"
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/GE_Profile_Smart_Fridge_fridge_focus.jpg",
      "popularity_score": 2018.0661194444444
    },
    {
      "id": "cluster_52",
      "coverage": 2,
      "updated_at": "Thu, 08 Jan 2026 16:17:12 +0000",
      "title": "Elon Musk&#8217;s lawsuit against OpenAI will face a jury in March",
      "neutral_headline": "Elon Musk&#8217;s lawsuit against OpenAI will face a jury in March",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/08/elon-musks-lawsuit-against-openai-will-face-a-jury-in-march/",
          "published_at": "Thu, 08 Jan 2026 16:17:12 +0000",
          "title": "Elon Musk&#8217;s lawsuit against OpenAI will face a jury in March",
          "standfirst": "District Judge Yvonne Gonzalez Rogers said there was evidence suggesting OpenAI’s leaders made assurances that its original nonprofit structure would be maintained. The case will go to trial in March.",
          "content": "District Judge Yvonne Gonzalez Rogers said there was evidence suggesting OpenAI’s leaders made assurances that its original nonprofit structure would be maintained. The case will go to trial in March.",
          "feed_position": 11
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2026/jan/08/elon-musk-openai-lawsuit-for-profit-conversion-can-go-to-trial-us-judge-says",
          "published_at": "Thu, 08 Jan 2026 11:56:58 GMT",
          "title": "Musk lawsuit over OpenAI for-profit conversion can go to trial, US judge says",
          "standfirst": "Judge says there is plenty of evidence to suggest OpenAI’s leaders made assurances nonprofit structure would be keptBusiness live – latest updatesElon Musk’s lawsuit against OpenAI is to go to trial after a US judge said there is plenty of evidence to support the billionaire’s case.The world’s richest man, who co-founded OpenAI, is suing the ChatGPT developer and its chief executive, Sam Altman, over claims its leaders violated the organisation’s founding mission by shifting to a for-profit model. Continue reading...",
          "content": "Judge says there is plenty of evidence to suggest OpenAI’s leaders made assurances nonprofit structure would be keptBusiness live – latest updatesElon Musk’s lawsuit against OpenAI is to go to trial after a US judge said there is plenty of evidence to support the billionaire’s case.The world’s richest man, who co-founded OpenAI, is suing the ChatGPT developer and its chief executive, Sam Altman, over claims its leaders violated the organisation’s founding mission by shifting to a for-profit model. Continue reading...",
          "feed_position": 3
        }
      ],
      "popularity_score": 2016.9436194444445
    },
    {
      "id": "cluster_77",
      "coverage": 2,
      "updated_at": "Thu, 08 Jan 2026 13:00:26 +0000",
      "title": "Google announces AI Overviews in Gmail search, experimental AI-organized inbox",
      "neutral_headline": "Google announces AI Overviews in Gmail search, experimental AI-organized inbox",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/01/google-announces-ai-overviews-in-gmail-search-experimental-ai-organized-inbox/",
          "published_at": "Thu, 08 Jan 2026 13:00:26 +0000",
          "title": "Google announces AI Overviews in Gmail search, experimental AI-organized inbox",
          "standfirst": "Last year's premium Gmail AI features are also rolling out to free users.",
          "content": "Gmail made us all rethink how email could work when it debuted more than 20 years ago. Google thinks we're in the process of another email transformation courtesy of AI. The company has unveiled a new round of AI features that will make Gemini an even more integral part of Gmail. The new Gemini experiences are coming to paying subscribers starting today, and a collection of previously premium-only AI features are rolling out widely. AI Overviews first appeared in Gmail last year to summarize email chains, and now it's expanding to Gmail search. This is closer to the AI Overview experience to which you are accustomed in Google's web search. You can enter a natural language search, and the robot churns through your messages to generate a response. Gmail AI Overview Gmail AI Overview In the example above, the user looks up a past plumbing quote. Traditionally, Gmail would show emails that are likely matches for your search. With AI Overview, you instead get a nicely formatted AI answer that includes all the relevant information and cites the email. That sounds all well and good, assuming it works. AI Overviews in search is notoriously inaccurate when summarizing search results, but grounding it in your email could make it less likely to screw up. Maybe.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gmail-AI-Inbox-Image-1152x648.png"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/08/gmail-debuts-a-personalized-ai-inbox-ai-overviews-in-search-and-more/",
          "published_at": "Thu, 08 Jan 2026 13:00:00 +0000",
          "title": "Gmail debuts a personalized AI Inbox, AI Overviews in search, and more",
          "standfirst": "Gmail is also bringing several AI features that were previously available only to paid users to all users.",
          "content": "Gmail is also bringing several AI features that were previously available only to paid users to all users.",
          "feed_position": 14
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gmail-AI-Inbox-Image-1152x648.png",
      "popularity_score": 2013.664175
    },
    {
      "id": "cluster_21",
      "coverage": 1,
      "updated_at": "Thu, 08 Jan 2026 18:00:52 +0000",
      "title": "ChatGPT Health lets you connect medical records to an AI that makes things up",
      "neutral_headline": "ChatGPT Health lets you connect medical records to an AI that makes things up",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/chatgpt-health-lets-you-connect-medical-records-to-an-ai-that-makes-things-up/",
          "published_at": "Thu, 08 Jan 2026 18:00:52 +0000",
          "title": "ChatGPT Health lets you connect medical records to an AI that makes things up",
          "standfirst": "New feature will allow users to link medical and wellness records to AI chatbot.",
          "content": "On Wednesday, OpenAI announced ChatGPT Health, a dedicated section of the AI chatbot designed for \"health and wellness conversations\" intended to connect a user's health and medical records to the chatbot in a secure way. But mixing generative AI technology like ChatGPT with health advice or analysis of any kind has been a controversial idea since the launch of the service in late 2022. Just days ago, SFGate published an investigation detailing how a 19-year-old California man died of a drug overdose in May 2025 after 18 months of seeking recreational drug advice from ChatGPT. It's a telling example of what can go wrong when chatbot guardrails fail during long conversations and people follow erroneous AI guidance. Despite the known accuracy issues with AI chatbots, OpenAI's new Health feature will allow users to connect medical records and wellness apps like Apple Health and MyFitnessPal so that ChatGPT can provide personalized health responses like summarizing care instructions, preparing for doctor appointments, and understanding test results.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai_doctor-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai_doctor-1152x648.jpg",
      "popularity_score": 366.6713972222222
    },
    {
      "id": "cluster_9",
      "coverage": 1,
      "updated_at": "Thu, 08 Jan 2026 19:00:07 +0000",
      "title": "These dogs eavesdrop on their owners to learn new words",
      "neutral_headline": "These dogs eavesdrop on their owners to learn new words",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/science/2026/01/these-dogs-eavesdrop-on-their-owners-to-learn-new-words/",
          "published_at": "Thu, 08 Jan 2026 19:00:07 +0000",
          "title": "These dogs eavesdrop on their owners to learn new words",
          "standfirst": "“Under the right conditions, some dogs present behaviors strikingly similar to those of young children.”",
          "content": "When it comes to cognitive ability, not all dogs are created equal. Most dogs can learn simple action cues like “sit” or “down.\" But so-called “gifted word learner” (GWL) dogs exhibit a remarkable ability to learn the names of objects—for example, learning the names of specific toys so well that they can retrieve them from a large pile of toys on command. And according to a new study published in the journal Science, they can even learn labels for new toys just by overhearing their owners talking about those toys. Per the authors, this suggests that GWL dogs have sociocognitive skills that are functionally comparable to those of 18-month-old human toddlers. Co-author Claudia Fugazza of Eötvös Loránd University in Budapest, Hungary, has been studying canine behavior and cognition for several years as part of the Genius Dog Challenge. For instance, the group’s 2022 study discovered that dogs store key sensory features about their toys—notably what they look like and how they smell—and recall those features when searching for the named toy. Prior studies had suggested that dogs typically rely on vision, or a combination of sight and smell, to locate target objects. GWL dogs can also identify objects based on verbal labels. In that 2022 study, all the dogs—regardless of whether they were GWL dogs or typical dogs—successfully picked out the target toys in both light and dark conditions, though it took them longer to locate the toys in the dark. Most relied on visual cues, even though dogs possess an excellent sense of smell. However, the dogs sniffed more frequently and longer when searching for the toy in the dark.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/doggoes3-1152x648-1767717035.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/doggoes3-1152x648-1767717035.jpg",
      "popularity_score": 352.6588972222222
    },
    {
      "id": "cluster_13",
      "coverage": 1,
      "updated_at": "Thu, 08 Jan 2026 18:50:46 +0000",
      "title": "Grok assumes users seeking images of underage girls have “good intent”",
      "neutral_headline": "Grok assumes users seeking images of underage girls have “good intent”",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/tech-policy/2026/01/grok-assumes-users-seeking-images-of-underage-girls-have-good-intent/",
          "published_at": "Thu, 08 Jan 2026 18:50:46 +0000",
          "title": "Grok assumes users seeking images of underage girls have “good intent”",
          "standfirst": "Expert explains how simple it could be to tweak Grok to block CSAM outputs.",
          "content": "For weeks, xAI has faced backlash over undressing and sexualizing images of women and children generated by Grok. One researcher conducted a 24-hour analysis of the Grok account on X and estimated that the chatbot generated over 6,000 images an hour flagged as \"sexually suggestive or nudifying,\" Bloomberg reported. While the chatbot claimed that xAI supposedly \"identified lapses in safeguards\" that allowed outputs flagged as child sexual abuse material (CSAM) and was \"urgently fixing them,\" Grok has proven to be an unreliable spokesperson, and xAI has not announced any fixes. A quick look at Grok's safety guidelines on its public GitHub confirms they were last updated two months ago. The GitHub also indicates that, despite prohibiting such content, Grok maintains programming that could make it likely to generate CSAM.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/grok-the-ai-clown-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/grok-the-ai-clown-1152x648.jpg",
      "popularity_score": 342.5030638888889
    },
    {
      "id": "cluster_26",
      "coverage": 1,
      "updated_at": "Thu, 08 Jan 2026 17:44:36 +0000",
      "title": "Seasonal Switch 2 sales show significant slowing as annual cycle sunsets",
      "neutral_headline": "Seasonal Switch 2 sales show significant slowing as annual cycle sunsets",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/seasonal-switch-2-sales-show-significant-slowing-as-annual-cycle-sunsets/",
          "published_at": "Thu, 08 Jan 2026 17:44:36 +0000",
          "title": "Seasonal Switch 2 sales show significant slowing as annual cycle sunsets",
          "standfirst": "After record-setting launch, Western holiday sales are down compared to the first Switch.",
          "content": "Nintendo's Switch 2 was an unmitigated market success for Nintendo following its launch last June, selling a record-setting 3.5 million units worldwide in its first four days and reaching over 10 million shipments in just under four months. But a new report from The Game Business suggests that frenzied initial sales pace may have slowed significantly in many markets during the system's crucial first holiday season. The report suggests that US Switch 2 sales were down about 35 percent during November and December compared to sales of the original Switch in the same period in 2017. In the UK, Switch 2 sales were down 16 percent compared to the original Switch during the last eight weeks of the year. And in France, comparative Switch 2 sales were down 30 percent relative to the Switch for the same period, reflecting what The Game Business says is \"a slowdown in Switch 2 sales momentum over the Christmas sales window\" across \"all major European markets.\" The Switch 2's relative performance was a little better in Japan, where sales for the holiday period declined just 5.5 percent compared to the original Switch. For the full launch year, though, Japanese Switch 2 sales were up 11 percent compared to the Switch launch, thanks perhaps in part to a cheaper Japan-only version of the console that isn't subject to the vagaries of international currency valuations.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/switch2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/switch2-1152x648.jpg",
      "popularity_score": 341.4002861111111
    },
    {
      "id": "cluster_61",
      "coverage": 1,
      "updated_at": "Thu, 08 Jan 2026 14:51:44 +0000",
      "title": "Trump withdraws US from world’s most important climate treaty",
      "neutral_headline": "Trump withdraws US from world’s most important climate treaty",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/trump-withdraws-us-from-worlds-most-important-climate-treaty/",
          "published_at": "Thu, 08 Jan 2026 14:51:44 +0000",
          "title": "Trump withdraws US from world’s most important climate treaty",
          "standfirst": "US also pulling out of pacts promoting development, democracy, and human rights.",
          "content": "Donald Trump has decided to withdraw the US from the world’s most important climate treaty, as well as from dozens of other international organizations, as the president intensifies efforts to upend decades of global cooperation tackling rising temperatures. In a presidential memorandum issued on Wednesday evening, Trump said the US would withdraw from the UN Framework Convention on Climate Change and 65 additional UN and other multilateral groups, mostly linked to the environment, renewable energy, development, education, and the promotion of democracy and human rights. They include the Intergovernmental Panel on Climate Change, the global body of climate scientists, the International Trade Centre, the UN Population Fund, and the International Union for Conservation of Nature.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/01/la-fires-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/01/la-fires-1024x648.jpg",
      "popularity_score": 336.519175
    },
    {
      "id": "cluster_70",
      "coverage": 1,
      "updated_at": "Thu, 08 Jan 2026 14:05:52 +0000",
      "title": "Former Google CEO plans to singlehandedly fund a Hubble telescope replacement",
      "neutral_headline": "Former Google CEO plans to singlehandedly fund a Hubble telescope replacement",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/eric-schmidt-will-massively-invest-in-private-telescopes-including-hubble-replacement/",
          "published_at": "Thu, 08 Jan 2026 14:05:52 +0000",
          "title": "Former Google CEO plans to singlehandedly fund a Hubble telescope replacement",
          "standfirst": "“This is a very significant contribution to the astronomical community.\"",
          "content": "Prior to World War II the vast majority of telescopes built around the world were funded by wealthy people with an interest in the heavens above. However, after the war, two significant developments in the mid-20th century caused the burden of funding large astronomical instruments to largely shift to the government and academic institutions. First, as mirrors became larger and larger to see deeper into the universe, their costs grew exponentially. And then, with the advent of spaceflight, the expense of space-based telescopes expanded even further. But now the tide may be turning again.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/5-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/5-1152x648.jpg",
      "popularity_score": 329.75473055555557
    },
    {
      "id": "cluster_71",
      "coverage": 1,
      "updated_at": "Thu, 08 Jan 2026 14:00:07 +0000",
      "title": "ChatGPT falls to new data-pilfering attack as a vicious cycle in AI continues",
      "neutral_headline": "ChatGPT falls to new data-pilfering attack as a vicious cycle in AI continues",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/chatgpt-falls-to-new-data-pilfering-attack-as-a-vicious-cycle-in-ai-continues/",
          "published_at": "Thu, 08 Jan 2026 14:00:07 +0000",
          "title": "ChatGPT falls to new data-pilfering attack as a vicious cycle in AI continues",
          "standfirst": "Will LLMs ever be able to stamp out the root cause of these attacks? Possibly not.",
          "content": "There’s a well-worn pattern in the development of AI chatbots. Researchers discover a vulnerability and exploit it to do something bad. The platform introduces a guardrail that stops the attack from working. Then, researchers devise a simple tweak that once again imperils chatbot users. The reason more often than not is that AI is so inherently designed to comply with user requests that the guardrails are reactive and ad hoc, meaning they are built to foreclose a specific attack technique rather than the broader class of vulnerabilities that make it possible. It’s tantamount to putting a new highway guardrail in place in response to a recent crash of a compact car but failing to safeguard larger types of vehicles. Enter ZombieAgent, son of ShadowLeak One of the latest examples is a vulnerability recently discovered in ChatGPT. It allowed researchers at Radware to surreptitiously exfiltrate a user's private information. Their attack also allowed for the data to be sent directly from ChatGPT servers, a capability that gave it additional stealth, since there were no signs of breach on user machines, many of which are inside protected enterprises. Further, the exploit planted entries in the long-term memory that the AI assistant stores for the targeted user, giving it persistence.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/AI-chatbot-threat-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/AI-chatbot-threat-1152x648.jpg",
      "popularity_score": 322.6588972222222
    },
    {
      "id": "cluster_101",
      "coverage": 1,
      "updated_at": "Thu, 08 Jan 2026 01:58:33 +0000",
      "title": "NASA considers evacuating ailing crew member from International Space Station",
      "neutral_headline": "NASA considers evacuating ailing crew member from International Space Station",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/nasa-postpones-space-station-spacewalk-due-to-crew-members-medical-concern/",
          "published_at": "Thu, 08 Jan 2026 01:58:33 +0000",
          "title": "NASA considers evacuating ailing crew member from International Space Station",
          "standfirst": "\"The matter involved a single crew member who is stable,\" NASA said in a statement.",
          "content": "Someone on the International Space Station suffered an unspecified \"medical situation\" Wednesday, prompting the postponement of a planned spacewalk and raising the possibility of an early return for a portion of the lab's seven-person crew, NASA said in a statement. NASA has never ordered a medical evacuation from space before, but the option has always been available at the International Space Station with lifeboats ready for activation. The space agency announced the spacewalk postponement Wednesday afternoon due to a \"medical concern\" with a member of the space station's crew. NASA officials declined to identify the crew member or release further details about their condition, citing medical privacy restrictions.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/evahelmet-1152x648-1767837189.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/evahelmet-1152x648-1767837189.jpg",
      "popularity_score": 294.6327861111111
    },
    {
      "id": "cluster_92",
      "coverage": 1,
      "updated_at": "Thu, 08 Jan 2026 08:00:55 +0000",
      "title": "Volvo says new EX60 has 400-mile range, charges up to 400 kW",
      "neutral_headline": "Volvo says new EX60 has 400-mile range, charges up to 400 kW",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/volvo-says-new-ex60-has-400-mile-range-charges-up-to-400-kw/",
          "published_at": "Thu, 08 Jan 2026 08:00:55 +0000",
          "title": "Volvo says new EX60 has 400-mile range, charges up to 400 kW",
          "standfirst": "The new EX60 will be unveiled later this month; here's what we know.",
          "content": "Later this month, Volvo will unveil its new EX60 SUV. The Swedish automaker has adopted some of the latest trends in electric vehicle design for the EX60, like a structural battery pack and the use of very large castings. As always with automakers teasing a new car, concrete details are only emerging slowly ahead of the official reveal on January 21, but we can say that range and recharging speeds were a priority during the design process. \"With our new electric vehicle architecture, we directly address the main worries that customers have when considering a switch to a fully electric car. The result is class-leading range and fast charging speeds, marking the end of range anxiety,\" said Anders Bell, Volvo's CTO. Volvo says that its SUV will be best-in-class for range, which means 400 miles (644 km) from a fully charged battery under the EPA test cycle (although an official EPA range number isn't due yet). Fast charging should also live up to the name. Providing you plug into a 400 kW DC fast charger, the EX60 should add 168 miles (270 km) of range in 10 minutes, although we don't know how long it requires to fast charge from 10–80 percent.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/HERO-IMAGE-Volvo-EX60-Exterior-Front-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/HERO-IMAGE-Volvo-EX60-Exterior-Front-1152x648.jpg",
      "popularity_score": 281.67223055555553
    },
    {
      "id": "cluster_103",
      "coverage": 1,
      "updated_at": "Thu, 08 Jan 2026 00:00:33 +0000",
      "title": "Ford is getting ready to put AI assistants in its cars",
      "neutral_headline": "Ford is getting ready to put AI assistants in its cars",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/in-car-ai-assistant-coming-to-fords-and-lincolns-in-2027/",
          "published_at": "Thu, 08 Jan 2026 00:00:33 +0000",
          "title": "Ford is getting ready to put AI assistants in its cars",
          "standfirst": "The Blue Oval is also working on new hands-free driver assists.",
          "content": "The annual Consumer Electronics Show is currently raging in Las Vegas, and as has become traditional over the past decade, automakers and their suppliers now use the conference to announce their technology plans. Tonight it was Ford's turn, and it is very on-trend for 2026. If you guessed that means AI is coming to the Ford in-car experience, congratulations, you guessed right. Even though the company owes everything to mass-producing identical vehicles, it says that it wants AI to personalize your car to you. \"Our vision for the customer is simple, but not elementary: a seamless layer of intelligence that travels with you between your phone and your vehicle,\" said Doug Field, Ford's chief EV, design, and digital officer. \"Not generic intelligence—many people can do that better than we can. What customers need is intelligence that understands where you are, what you’re doing, and what your vehicle is capable of, and then makes the next decision simpler,\" Field wrote in a blog post Ford shared ahead of time with Ars.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2222907242-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2222907242-1152x648.jpg",
      "popularity_score": 268.66611944444446
    },
    {
      "id": "cluster_109",
      "coverage": 1,
      "updated_at": "Wed, 07 Jan 2026 22:50:10 +0000",
      "title": "Samsung’s Ballie home robot, once promised for summer 2025, gets grim update",
      "neutral_headline": "Samsung’s Ballie home robot, once promised for summer 2025, gets grim update",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/samsung-squashes-hopes-that-it-will-release-its-ballie-home-robot/",
          "published_at": "Wed, 07 Jan 2026 22:50:10 +0000",
          "title": "Samsung’s Ballie home robot, once promised for summer 2025, gets grim update",
          "standfirst": "Six years after its CES debut, Samsung has demoted Ballie to internal use.",
          "content": "Since 2020, Samsung has been dangling a yellow ball in front of us. That sphere is a robot named Ballie that Samsung has teased and demoed for home use, including serving as a smart speaker. Today, Ballie is confirmed to be facing an eternity as vaporware. At CES 2020, Ars Technica reported that Ballie was “the furthest-along concept” that Samsung demonstrated. At the time, we saw Ballie use facial recognition to follow its owner. A marketing video also portrayed the robot controlling smart home devices, including activating a smart vacuum when someone made a mess. Ballie rolled back onto the trade show scene at CES 2024. This time, it had a new, more spherical and larger build rolling upon its three wheels. Ballie also sported a light ring, and Samsung showed a video of the robot being used as a projector. The South Korean firm claimed that Ballie would provide “two to three hours of continued projector use” before needing a charge. Samsung's video also demonstrated Ballie connecting with a smartphone.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/floorp_L7Vva1B8JH-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/floorp_L7Vva1B8JH-1152x648.jpg",
      "popularity_score": 243
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Wed, 07 Jan 2026 16:30:56 +0000",
      "title": "EVs remain a niche choice in the US, according to survey",
      "neutral_headline": "EVs remain a niche choice in the US, according to survey",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/evs-remain-a-niche-choice-in-the-us-according-to-survey/",
          "published_at": "Wed, 07 Jan 2026 16:30:56 +0000",
          "title": "EVs remain a niche choice in the US, according to survey",
          "standfirst": "Consumers around the world told Deloitte what they want in their next vehicle.",
          "content": "The electric vehicle transition might not be moving ahead with the same gusto it showed in the early 2020s, but it's still happening. According to Deloitte's 2026 Global Automotive Consumer Study, 7 percent of US car buyers want an electric vehicle for their next car. While that might sound rather meager, it's a 40 percent increase from 2025's survey, which found just 5 percent of car buyers wanted an EV. Plain old internal combustion remains Americans' first choice, with 61 percent telling the survey that's how their next ride will be powered. Twenty-one percent want a hybrid, up from 20 percent last year. Just 5 percent indicated a desire for a plug-in hybrid (down from 6 percent last year), with the remaining confused souls either unsure of what to buy next (4 percent) or some other option, presumably hydrogen (1 percent). A graph showing preference for engine type in car buyers' next vehicle. Credit: Deloitte The high demand for internal combustion engines makes the US an outlier among large car-buying markets. Fewer than half of German car buyers want another gas-powered vehicle, and that number falls to just 41 percent in China, Japan, and South Korea. But those consumers aren't all fleeing internal combustion for battery EVs. Well, they mostly are in China, where EV demand is now 20 percent. But in Japan, only 5 percent of consumers want a battery EV, versus 37 percent indicating their next car would be a hybrid.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2166522883-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2166522883-1152x648.jpg",
      "popularity_score": 154
    },
    {
      "id": "cluster_110",
      "coverage": 1,
      "updated_at": "Wed, 07 Jan 2026 22:20:08 +0000",
      "title": "AI starts autonomously writing prescription refills in Utah",
      "neutral_headline": "AI starts autonomously writing prescription refills in Utah",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/utah-allows-ai-to-autonomously-prescribe-medication-refills/",
          "published_at": "Wed, 07 Jan 2026 22:20:08 +0000",
          "title": "AI starts autonomously writing prescription refills in Utah",
          "standfirst": "The program allows patients in the state to get prescription refills for 190 common meds.",
          "content": "The state of Utah is allowing artificial intelligence to prescribe medication refills to patients without direct human oversight in a pilot program public advocates call \"dangerous.\" The program is through the state's \"regulatory sandbox\" framework, which allows businesses to trial \"innovative\" products or services with state regulations temporarily waived. The Utah Department of Commerce partnered with Doctronic, a telehealth startup with an AI chatbot. Doctronic offers a nationwide service that allows patients to chat with its \"AI doctor\" for free, then, for $39, book a virtual appointment with a real doctor licensed in their state. But patients must go through the AI chatbot first to get an appointment.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_118",
      "coverage": 1,
      "updated_at": "Wed, 07 Jan 2026 20:12:25 +0000",
      "title": "Warner Bros. sticks with Netflix merger, calls Paramount’s $108B bid “illusory”",
      "neutral_headline": "Warner Bros. sticks with Netflix merger, calls Paramount’s $108B bid “illusory”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/warner-bros-sticks-with-netflix-merger-calls-paramounts-108b-bid-illusory/",
          "published_at": "Wed, 07 Jan 2026 20:12:25 +0000",
          "title": "Warner Bros. sticks with Netflix merger, calls Paramount’s $108B bid “illusory”",
          "standfirst": "Larry Ellison pledged $40B, but \"he didn’t raise the price,\" Warner chair says.",
          "content": "The Warner Bros. Discovery board has unanimously voted to rebuff Paramount's $108.4 billion offer and urged shareholders to reject the hostile takeover bid. The board is continuing to support Netflix's pending $82.7 billion purchase of its streaming and movie studios businesses along with a separate spinoff of the Warner Bros. cable TV division. Warner Bros. called the Paramount bid \"illusory\" in a presentation for shareholders today, saying the offer requires an \"extraordinary amount of debt financing\" and other terms that make it less likely to be completed than a Netflix merger. It would be the largest leveraged buyout ever, \"with $87B of total pro forma gross debt,\" and is \"effectively a one-sided option for PSKY [Paramount Skydance] as the offer can be terminated or amended by PSKY at any time,\" Warner Bros. said. The Warner Bros. presentation touted Netflix's financial strength while saying that Paramount \"is a $14B market cap company with a 'junk' credit rating, negative free cash flows, significant fixed financial obligations, and a high degree of dependency on its linear business.\" The Paramount \"offer is illusory as it cannot be completed before it is currently scheduled to expire,\" Warner Bros. said.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/netflix-paramount-wb-icons-1152x648-1767815429.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/netflix-paramount-wb-icons-1152x648-1767815429.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_124",
      "coverage": 1,
      "updated_at": "Wed, 07 Jan 2026 18:51:37 +0000",
      "title": "Bose open-sources its SoundTouch home theater smart speakers ahead of end-of-life",
      "neutral_headline": "Bose open-sources its SoundTouch home theater smart speakers ahead of end-of-life",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/bose-open-sources-its-soundtouch-home-theater-smart-speakers-ahead-of-eol/",
          "published_at": "Wed, 07 Jan 2026 18:51:37 +0000",
          "title": "Bose open-sources its SoundTouch home theater smart speakers ahead of end-of-life",
          "standfirst": "If companies insist on bricking gadgets, this is a better way to do it.",
          "content": "Bose released the Application Programming Interface (API) documentation for its SoundTouch speakers today, putting a silver lining around the impending end-of-life (EoL) of the expensive home theater devices. In October, Bose announced that its SoundTouch Wi-Fi speakers and soundbars would become dumb speakers on February 18. At the time, Bose said that the speakers would only work if a device was connected via AUX, HDMI, or Bluetooth (which has higher latency than Wi-Fi). After that date, the speakers would stop receiving security and software updates and lose cloud connectivity and their companion app, the Framingham, Massachusetts-based company said. Without the app, users would no longer be able to integrate the device with music services, such as Spotify, have multiple SoundTouch devices play the same audio simultaneously, or use or edit saved presets.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Bose_SoundTouch_30_Series_III_1640_26-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Bose_SoundTouch_30_Series_III_1640_26-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_128",
      "coverage": 1,
      "updated_at": "Wed, 07 Jan 2026 18:15:27 +0000",
      "title": "Expired certificate completely breaks macOS Logitech apps, user customizations",
      "neutral_headline": "Expired certificate completely breaks macOS Logitech apps, user customizations",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/expired-certificate-completely-breaks-macos-logitech-apps-user-customizations/",
          "published_at": "Wed, 07 Jan 2026 18:15:27 +0000",
          "title": "Expired certificate completely breaks macOS Logitech apps, user customizations",
          "standfirst": "Even with a fix available, broken apps won't be able to update themselves.",
          "content": "If you're a Mac user with Logitech accessories and you've noticed that your settings and customizations seem to have gone away this week, you're not alone. The company's Logi Options+ and G Hub apps for macOS abruptly stopped functioning on Monday, refusing to launch and reverting all accessories' settings to their built-in defaults. The culprit, according to both a Logitech support page and Reddit posts from Logitech Head of Global Marketing Joe Santucci, was a security certificate that was inadvertently allowed to expire, rendering both apps non-functional.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/mx-key-s-combo-mac-intro-cover-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/mx-key-s-combo-mac-intro-cover-1152x648.jpeg",
      "popularity_score": 133
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Wed, 07 Jan 2026 17:31:30 +0000",
      "title": "SteamOS continues its slow spread across the PC gaming landscape",
      "neutral_headline": "SteamOS continues its slow spread across the PC gaming landscape",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/steamos-continues-its-slow-spread-across-the-pc-gaming-landscape/",
          "published_at": "Wed, 07 Jan 2026 17:31:30 +0000",
          "title": "SteamOS continues its slow spread across the PC gaming landscape",
          "standfirst": "Legion Go 2 support announced at CES, wide support for Arm hardware coming soon.",
          "content": "SteamOS's slow march across the Windows-dominated PC gaming landscape is continuing to creep along. At CES this week, Lenovo announced it will launch a version of last year's high-priced, high-powered Legion Go 2 handheld with Valve's gaming-focused, Linux-based OS pre-installed starting in June. And there are some intriguing signs from Valve that SteamOS could come to non-AMD devices in the not-too-distant future as well. A new SteamOS-powered Legion Go 2 isn't exactly shocking news given how things have been going in the world of PC gaming handhelds. Lenovo became the first non-Valve hardware maker to embrace the Windows alternative when it announced a SteamOS-compatible version of the lower-end Legion Go S almost exactly a year ago. When that version hit the market last spring, Ars testing found it actually performed better than the Windows-based version of the same hardware on many popular games. Valve has also been working behind the scenes to expand SteamOS's footprint beyond its own hardware. After rolling out the SteamOS Compatible software label last May, SteamOS version 3.7 offered support for manual installation on AMD-powered handhelds like the ROG Ally and the original Legion Go.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/legiongo2-975x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/legiongo2-975x648.png",
      "popularity_score": 133
    },
    {
      "id": "cluster_132",
      "coverage": 1,
      "updated_at": "Wed, 07 Jan 2026 17:17:02 +0000",
      "title": "Japanese nuclear plant operator fabricated seismic risk data",
      "neutral_headline": "Japanese nuclear plant operator fabricated seismic risk data",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/japanese-nuclear-plant-operator-fabricated-seismic-risk-data/",
          "published_at": "Wed, 07 Jan 2026 17:17:02 +0000",
          "title": "Japanese nuclear plant operator fabricated seismic risk data",
          "standfirst": "Company staff were very selective about how they modeled earthquake dangers.",
          "content": "On Wednesday, Japan's Nuclear Regulation Authority announced that it is halting the relicensing process for two reactors at the Hamaoka plant after revelations that the plant's chosen operator fabricated seismic hazard data. Japan has been slowly reactivating its extensive nuclear power plant collection after it was shut down following the Fukushima Daiichi disaster. The latest scandal is especially shocking, given that the Hamaoka plant is located on the coast near an active subduction fault—just as Fukushima Daiichi is. A whistleblower reportedly alerted the Nuclear Regulation Authority in February of last year, but the issue became public this week when the regulators halted an evaluation process that could have led to a reactor restart at Hamaoka. This prompted the company that operates the plants, the Chubu Electric Power Co., to issue a press release describing in detail how the company manipulated the seismic safety data. Based on an English translation, it appears that seismic risks were evaluated at least in part by scaling up the ground motion using data from smaller earthquakes. This is an inexact process, so the standard approach is to create a group of 20 different upscaled earthquake motions and find the one that best represents the average among the 20.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-114113332-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-114113332-1024x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_138",
      "coverage": 1,
      "updated_at": "Wed, 07 Jan 2026 16:02:21 +0000",
      "title": "New battery idea gets lots of power out of unusual sulfur chemistry",
      "neutral_headline": "New battery idea gets lots of power out of unusual sulfur chemistry",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/new-battery-idea-gets-lots-of-power-out-of-unusual-sulfur-chemistry/",
          "published_at": "Wed, 07 Jan 2026 16:02:21 +0000",
          "title": "New battery idea gets lots of power out of unusual sulfur chemistry",
          "standfirst": "Rather than being used as a storage material, the sulfur gives up electrons.",
          "content": "Anyone paying attention to battery research sees sulfur come up frequently. That's mostly because sulfur is a great storage material for lithium, and it could lead to lithium batteries with impressive power densities. But sulfur can participate in a wide range of chemical reactions, which has made it difficult to prevent lithium-sulfur batteries from decaying rapidly as the sulfur forms all sorts of unwanted materials. As a result, despite decades of research, very few lithium-sulfur batteries have made it to market. But a team of Chinese researchers has managed to turn sulfur's complex chemistry into a strength, making it the primary electron donor in a sodium-sulfur battery that also relies on chlorine for its chemistry. The result, at least in the lab, is an impressive energy per weight with extremely inexpensive materials. Sulfur chemistry Sulfur sits immediately below oxygen on the periodic table, so you might think its chemistry would look similar. But that's not the case. Like oxygen, it can participate in covalent bonding in biological chemistry, including in two essential amino acids. Also, like oxygen, it can accept electrons from metals, as seen in some atomically thin materials that have been studied. But it's also willing to give electrons up, forming chemical compounds with things like chlorine and oxygen.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2193745381-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2193745381-1024x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_139",
      "coverage": 1,
      "updated_at": "Wed, 07 Jan 2026 16:00:23 +0000",
      "title": "We have a fossil closer to our split with Neanderthals and Denisovans",
      "neutral_headline": "We have a fossil closer to our split with Neanderthals and Denisovans",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/weve-got-a-fossil-closer-to-our-split-with-neanderthals-and-denisovans/",
          "published_at": "Wed, 07 Jan 2026 16:00:23 +0000",
          "title": "We have a fossil closer to our split with Neanderthals and Denisovans",
          "standfirst": "A recent study suggests that North Africa may be a key place to look.",
          "content": "A group of 773,000-year-old hominin fossils from Morocco may shed new light on when our species branched off from the ancestors of Neanderthals and Denisovans. A team of anthropologists recently examined a collection of fossil hominin jawbones, teeth, and vertebrae that belong to hominins who probably lived very close in time to our species’ last common ancestor with Neanderthals and Denisovans. They reveal a little more about a murky but important moment in our evolutionary history. From predators’ quarry to rock quarry Archaeologists unearthed the 773,000-year-old bones just southwest of Casablanca in a cave aptly named Grotte à Hominidés. They’re just fragments of what used to be hominins: an adult’s lower jawbone, plus the partial lower jaw from another adult and a very young child, along with a handful of teeth and vertebrae. A hominin femur from the same layer of sediment in the cave has clear gnaw marks from sharp carnivore teeth, offering a chilling clue about how the bones got there.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/excavation-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/excavation-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_142",
      "coverage": 1,
      "updated_at": "Wed, 07 Jan 2026 15:06:53 +0000",
      "title": "Computer scientist Yann LeCun: “Intelligence really is about learning”",
      "neutral_headline": "Computer scientist Yann LeCun: “Intelligence really is about learning”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/computer-scientist-yann-lecun-intelligence-really-is-about-learning/",
          "published_at": "Wed, 07 Jan 2026 15:06:53 +0000",
          "title": "Computer scientist Yann LeCun: “Intelligence really is about learning”",
          "standfirst": "The AI pioneer talks about stepping down from Meta, limits of large language models.",
          "content": "I arrive 10 minutes ahead of schedule from an early morning Eurostar and see Yann LeCun is already waiting for me, nestled between two plastic Christmas trees in the nearly empty winter garden of Michelin-starred restaurant Pavyllon. The restaurant is next to Paris’s Grand Palais, where President Emmanuel Macron kick-started 2025 by hosting an international AI summit, a glitzy showcase packed with French exceptionalism and international tech luminaries including LeCun, who is considered one of the “godfathers” of modern AI. LeCun gets up to hug me in greeting, wearing his signature black Ray-Ban Wayfarer glasses. He looks well rested for a man who has spent nearly a week running around town plotting world domination. Or, more precisely, “total world assistance” or “intelligent amplification, if you want.” Domination “sounds scary with AI,” he acknowledges.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/lecun-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/lecun-1152x648.jpg",
      "popularity_score": 133
    }
  ]
}