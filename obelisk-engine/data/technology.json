{
  "updated_at": "2026-01-21T23:26:25.403Z",
  "clusters": [
    {
      "id": "cluster_1",
      "coverage": 3,
      "updated_at": "2026-01-21T18:22:57-05:00",
      "title": "Blue Origin’s Starlink rival TeraWave promises 6 terabit satellite internet",
      "neutral_headline": "Blue Origin’s Starlink rival TeraWave promises 6 terabit satellite internet",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/865282/blue-origin-terawave-satellite-6tb",
          "published_at": "2026-01-21T18:22:57-05:00",
          "title": "Blue Origin’s Starlink rival TeraWave promises 6 terabit satellite internet",
          "standfirst": "SpaceX has the most internet-beaming satellites in its constellation, but the competition is coming, and now Jeff Bezos' space company Blue Origin, has announced the TeraWave network. It says TeraWave will offer bandwidth of up to 6Tb available anywhere on Earth, for both upload and download. The only wrinkle? Even after satellite deployments are scheduled [&#8230;]",
          "content": "The Blue Origin New Glenn rocket lifts off at Launch Complex 36 in its second launch attempt at Cape Canaveral Space Force Station on November 13, 2025 in Cape Canaveral, Florida. | Miguel J. Rodriguez Carrillo/Getty Images SpaceX has the most internet-beaming satellites in its constellation, but the competition is coming, and now Jeff Bezos' space company Blue Origin, has announced the TeraWave network. It says TeraWave will offer bandwidth of up to 6Tb available anywhere on Earth, for both upload and download. The only wrinkle? Even after satellite deployments are scheduled to start near the end of 2027, you probably won't be able to connect directly. That's by design, as former Amazon Alexa boss and current Blue Origin CEO Dave Limp said in a post that it's \"purpose-built for enterprise customers.\" Blue Origin's network has a \"multi-orbit\" design of 5,408 … Read the full story at The Verge.",
          "feed_position": 0
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260121/p43#a260121p43",
          "published_at": "Wed, 21 Jan 2026 16:50:02 -0500",
          "title": "Blue Origin unveils TeraWave, a satellite communications network for enterprise, data center, and government customers, and plans to begin deployment in Q4 2027 (Annie Palmer/CNBC)",
          "standfirst": "Annie Palmer / CNBC: Blue Origin unveils TeraWave, a satellite communications network for enterprise, data center, and government customers, and plans to begin deployment in Q4 2027 &mdash; Jeff Bezos' space venture Blue Origin announced Wednesday it plans to deploy 5,408 satellites in space for a communications network that will take on SpaceX and Amazon.",
          "content": "Annie Palmer / CNBC: Blue Origin unveils TeraWave, a satellite communications network for enterprise, data center, and government customers, and plans to begin deployment in Q4 2027 &mdash; Jeff Bezos' space venture Blue Origin announced Wednesday it plans to deploy 5,408 satellites in space for a communications network that will take on SpaceX and Amazon.",
          "feed_position": 4,
          "image_url": "http://www.techmeme.com/260121/i43.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/21/blue-origins-satellite-internet-network-terawave-will-move-data-at-6tbps/",
          "published_at": "Wed, 21 Jan 2026 18:36:48 +0000",
          "title": "Blue Origin&#8217;s satellite internet network TeraWave will move data at 6 Tbps",
          "standfirst": "The network will be designed for enterprise, data center, and government customers and could offer an alternative to SpaceX's Starlink service.",
          "content": "The network will be designed for enterprise, data center, and government customers and could offer an alternative to SpaceX's Starlink service.",
          "feed_position": 8
        }
      ],
      "featured_image": "http://www.techmeme.com/260121/i43.jpg",
      "popularity_score": 3019.9421105555557
    },
    {
      "id": "cluster_17",
      "coverage": 2,
      "updated_at": "2026-01-21T16:43:27-05:00",
      "title": "Apple is reportedly working on an AirTag-sized AI wearable",
      "neutral_headline": "Apple is reportedly working on an AirTag-sized AI wearable",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/865212/apple-ai-pin-wearable-airtag-rumor",
          "published_at": "2026-01-21T16:43:27-05:00",
          "title": "Apple is reportedly working on an AirTag-sized AI wearable",
          "standfirst": "Apple is working on an AI-powered wearable pin with cameras and microphones designed to pick up a user's surroundings, according to a report from The Information. The rumored device is reportedly the size of an AirTag, with \"thin, flat, circular\" housing made from aluminium and glass. The Information reports that Apple's rumored AI pin will [&#8230;]",
          "content": "Apple is working on an AI-powered wearable pin with cameras and microphones designed to pick up a user's surroundings, according to a report from The Information. The rumored device is reportedly the size of an AirTag, with \"thin, flat, circular\" housing made from aluminium and glass. The Information reports that Apple's rumored AI pin will have a standard lens and a wide-angle lens, along with three microphones, a speaker, a physical button on one of its sides, and support for wireless charging. The device is still in the \"early stages\" of development and could arrive as soon as 2027, according to The Information. Along with this rumored … Read the full story at The Verge.",
          "feed_position": 2
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260121/p40#a260121p40",
          "published_at": "Wed, 21 Jan 2026 15:06:42 -0500",
          "title": "Sources: Apple is developing an AirTag-sized AI wearable pin with cameras, a speaker, microphones, and wireless charging that could be released as early as 2027 (The Information)",
          "standfirst": "The Information: Sources: Apple is developing an AirTag-sized AI wearable pin with cameras, a speaker, microphones, and wireless charging that could be released as early as 2027 &mdash; Apple is developing an AI-powered wearable pin the size of an AirTag that is equipped with multiple cameras, a speaker &hellip;",
          "content": "The Information: Sources: Apple is developing an AirTag-sized AI wearable pin with cameras, a speaker, microphones, and wireless charging that could be released as early as 2027 &mdash; Apple is developing an AI-powered wearable pin the size of an AirTag that is equipped with multiple cameras, a speaker &hellip;",
          "feed_position": 7,
          "image_url": "http://www.techmeme.com/260121/i40.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260121/i40.jpg",
      "popularity_score": 2018.2837772222222
    },
    {
      "id": "cluster_33",
      "coverage": 2,
      "updated_at": "2026-01-21T15:26:47-05:00",
      "title": "Apple is turning Siri into an AI bot that&#8217;s more like ChatGPT",
      "neutral_headline": "Apple is turning Siri into an AI bot that&#8217;s more like ChatGPT",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/865172/apple-siri-ai-chatbot-chatgpt",
          "published_at": "2026-01-21T15:26:47-05:00",
          "title": "Apple is turning Siri into an AI bot that&#8217;s more like ChatGPT",
          "standfirst": "Apple is planning a big Siri overhaul that will transform the voice assistant into an AI chatbot built directly into its iPhone and Mac, according to Bloomberg reporter Mark Gurman. The update is reportedly coming later this year and will replace the existing Siri interface, allowing users to interact with the assistant by both typing [&#8230;]",
          "content": "Apple is planning a big Siri overhaul that will transform the voice assistant into an AI chatbot built directly into its iPhone and Mac, according to Bloomberg reporter Mark Gurman. The update is reportedly coming later this year and will replace the existing Siri interface, allowing users to interact with the assistant by both typing and talking, similar to the chatbots available from Google, OpenAI, Anthropic, and others. As noted by Bloomberg, this change is separate from the AI-powered personalization features coming to Siri in the next few months. Like that updated version of Siri, the chatbot will reportedly use a custom Google Gemini … Read the full story at The Verge.",
          "feed_position": 4
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260121/p39#a260121p39",
          "published_at": "Wed, 21 Jan 2026 14:56:44 -0500",
          "title": "Sources: Apple plans to revamp Siri this fall in iOS 27 and macOS 27 by turning it into the company's first AI chatbot, replacing the current Siri interface (Mark Gurman/Bloomberg)",
          "standfirst": "Mark Gurman / Bloomberg: Sources: Apple plans to revamp Siri this fall in iOS 27 and macOS 27 by turning it into the company's first AI chatbot, replacing the current Siri interface &mdash; Apple Inc. plans to revamp Siri later this year by turning the digital assistant into the company's first artificial intelligence chatbot &hellip;",
          "content": "Mark Gurman / Bloomberg: Sources: Apple plans to revamp Siri this fall in iOS 27 and macOS 27 by turning it into the company's first AI chatbot, replacing the current Siri interface &mdash; Apple Inc. plans to revamp Siri later this year by turning the digital assistant into the company's first artificial intelligence chatbot &hellip;",
          "feed_position": 8,
          "image_url": "http://www.techmeme.com/260121/i39.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260121/i39.jpg",
      "popularity_score": 2017.0059994444443
    },
    {
      "id": "cluster_55",
      "coverage": 2,
      "updated_at": "Wed, 21 Jan 2026 18:09:00 GMT",
      "title": "CFOs are now getting their own 'vibe coding' moment thanks to Datarails",
      "neutral_headline": "CFOs are now getting their own 'vibe coding' moment thanks to Datarails",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/cfos-are-now-getting-their-own-vibe-coding-moment-thanks-to-datarails",
          "published_at": "Wed, 21 Jan 2026 18:09:00 GMT",
          "title": "CFOs are now getting their own 'vibe coding' moment thanks to Datarails",
          "standfirst": "For the modern CFO, the hardest part of the job often isn&#x27;t the math—it&#x27;s the storytelling. After the books are closed and the variances calculated, finance teams spend days, sometimes weeks, manually copy-pasting charts into PowerPoint slides to explain why the numbers moved.Today, 11-year-old Israeli fintech company Datarails announced a set of new generative AI tools designed to automate that \"last mile\" of financial reporting, effectively allowing finance leaders to \"vibe code\" their way to a board deck.Launching today to accompany the firm&#x27;s newly announced $70 million Series C funding round, the company’s new Strategy, Planning, and Reporting AI Finance Agents promise to answer complex financial questions with fully formatted assets, not just text. A finance professional can now ask, \"What’s driving our profitability changes this year?\" or \"Why did Marketing go over budget last month?\" and the system will instantly generate board-ready PowerPoint slides, PDF reports, or Excel files containing the answer.The deployment of these agents marks a fundamental shift in how the \"Office of the CFO\" interacts with data.Beyond the chatbotThe promise of the new agents is to solve the fragmentation problem that plagues finance departments. Unlike a sales leader who lives in Salesforce, or a CIO who relies on ServiceNow, the CFO has no single \"system of truth\". Data is scattered across ERPs, HRIS, CRMs, and bank portals.A major barrier to AI adoption in finance has been security. CFOs are rightfully hesitant to plug P&L data into public models.Datarails has addressed this by leveraging Microsoft’s Azure OpenAI Service. \"We use the OpenAI in Azure to ensure the privacy and the security for our customers, they don&#x27;t like to share the data in [an] open LLM,\" Gurfinkel noted. This allows the platform to utilize state-of-the-art models while keeping data within a secure enterprise perimeter.Datarails’ new agents sit on top of a unified data layer that connects these disparate systems. Because the AI is grounded in the company’s own unified internal data, it avoids the hallucinations common in generic LLMs while offering a level of privacy required for sensitive financial data.\"If the CFO wants to leverage AI on the CFO level or the organization data, they need to consolidate the data,\" explained Datarails CEO and co-founder Didi Gurfinkel in an interview with VentureBeat.By solving that consolidation problem first, Datarails can now offer agents that understand the context of the business. \"Now the CFO can use our agents to run analysis, get insights, create reports... because now the data is ready,\" Gurfinkel said.&#x27;Vibe coding&#x27; for financeThe launch taps into a broader trend in software development where natural language prompts replace complex coding or manual configuration—a concept tech circles refer to as \"vibe coding.\" Gurfinkel believes this is the future of financial engineering.\"Very soon, the CFO and the financial team themselves will be able to develop applications,\" Gurfinkel predicted. \"The LLMs become so strong that in one prompt, they can replace full product runs.\"He described a workflow where a user could simply prompt: \"That was my budget and my actual of the past year. Now build me the budget for the next year.\"The new agents are designed to handle exactly these types of complex, multi-variable scenarios. For example, a user could ask, \"What happens if revenue grows slower next quarter?\" and receive a scenario analysis in return.Because the output can be delivered as an Excel file, finance teams can verify the formulas and assumptions, maintaining the audit trail that generic AI tools often lack.Ease of adoption: The &#x27;anti-implementation&#x27;For most engineering teams, the arrival of a new enterprise financial platform signals a looming headache: months of data migration, schema redesigns, and the inevitable friction of forcing non-technical users to abandon their preferred workflows. Datarails has engineered its way around this friction by building what might be best described as an \"anti-implementation.\"Instead of demanding a \"rip and replace\" of legacy systems, the platform accepts the messy reality of the modern finance stack. The architecture is designed to decouple the data storage from the presentation layer, effectively treating the organization&#x27;s existing Excel files as a frontend interface while Datarails acts as the backend database.\"We are not replacing anything,\" Gurfinkel explained. \"The implementation can be very fast, from a few hours to maybe a few days\".From a technical perspective, this means the \"engineering\" requirement is almost entirely stripped away. There are no ETL pipelines to build or Python scripts to maintain. The system comes pre-wired with over 200 native connectors—linking directly to ERPs like NetSuite and Sage, CRMs like Salesforce, and various HRIS and bank portals.The heavy lifting is replaced by a \"no-code\" mapping process. A finance analyst, not a developer, maps the fields from their General Ledger to their Excel models in a self-service workflow. For modules like Month-End Close, the company explicitly promises that \"no IT support is needed,\" a phrase that likely comes as a relief to stretched CTOs. Even complex setups, such as the new Cash Management module which requires banking integrations, are typically fully operational within two to three weeks.The result is a system where the \"technical debt\" usually associated with financial transformation is rendered obsolete. The finance team gets their \"single source of truth\" without ever asking engineering to provision a database.From version Control to vision control: a pivot that paid offDatarails wasn&#x27;t always the \"FinanceOS\" for the AI era. Founded in 2015 by Gurfinkel alongside co-founders Eyal Cohen (COO) and Oded Har-Tal (CTO), the Tel Aviv-based startup spent its early years tackling a dryer problem: version control for Excel. The initial premise was to synchronize and manage spreadsheets across enterprises, but adoption was sluggish as the team struggled to find the right product-market fit.The breakthrough came in 2020 with a strategic pivot. The team realized that finance professionals didn&#x27;t want to replace Excel with a new dashboard; they wanted to fix Excel&#x27;s limitations—specifically manual consolidation and data fragmentation. By shifting focus to SMB finance teams and embracing an \"Excel-native\" automation philosophy, the company found its stride.This alignment led to rapid scaling, fueled by a $55 million Series A in June 2021 led by Zeev Ventures, followed quickly by a $50 million Series B in March 2022 led by Qumra Capital. While the company faced headwinds during the tech downturn—resulting in an 18% workforce reduction in late 2022—it has since rebounded aggressively. By 2025, Datarails had nearly doubled its workforce to over 400 employees globally, driven by a multi-product expansion strategy that now includes Month-End Close and Cash Management solutions.Fueling the expansionThe new AI capabilities are supported by the $70 million Series C injection from One Peak, along with existing investors Vertex Growth, Vintage Investment Partners, and others. The funding arrives after a year of 70% revenue growth for Datarails, driven largely by the expansion of its product suite.More than 50% of the company&#x27;s growth in 2025 came from solutions launched in the last 12 months, including Datarails Month-End Close (a tool for automating reconciliations and workflow management) and Datarails Cash Management (for real-time liquidity monitoring).These products serve as the \"plumbing\" that makes the new AI agents effective. By automating the month-end close and unifying cash data, Datarails ensures that when a CFO asks the AI a question, the underlying numbers are accurate and up-to-date.For Gurfinkel, the goal is to make the finance office \"AI-native\" without forcing users to abandon their favorite tool: Excel.\"We are not replacing anything,\" Gurfinkel said. \"We connect the Excel so Excel now becomes the calculation and the presentation.\"With the launch of these new agents, Datarails is betting that the future of finance isn&#x27;t about learning new software, but about having a conversation with the data you already have.",
          "content": "For the modern CFO, the hardest part of the job often isn&#x27;t the math—it&#x27;s the storytelling. After the books are closed and the variances calculated, finance teams spend days, sometimes weeks, manually copy-pasting charts into PowerPoint slides to explain why the numbers moved.Today, 11-year-old Israeli fintech company Datarails announced a set of new generative AI tools designed to automate that \"last mile\" of financial reporting, effectively allowing finance leaders to \"vibe code\" their way to a board deck.Launching today to accompany the firm&#x27;s newly announced $70 million Series C funding round, the company’s new Strategy, Planning, and Reporting AI Finance Agents promise to answer complex financial questions with fully formatted assets, not just text. A finance professional can now ask, \"What’s driving our profitability changes this year?\" or \"Why did Marketing go over budget last month?\" and the system will instantly generate board-ready PowerPoint slides, PDF reports, or Excel files containing the answer.The deployment of these agents marks a fundamental shift in how the \"Office of the CFO\" interacts with data.Beyond the chatbotThe promise of the new agents is to solve the fragmentation problem that plagues finance departments. Unlike a sales leader who lives in Salesforce, or a CIO who relies on ServiceNow, the CFO has no single \"system of truth\". Data is scattered across ERPs, HRIS, CRMs, and bank portals.A major barrier to AI adoption in finance has been security. CFOs are rightfully hesitant to plug P&L data into public models.Datarails has addressed this by leveraging Microsoft’s Azure OpenAI Service. \"We use the OpenAI in Azure to ensure the privacy and the security for our customers, they don&#x27;t like to share the data in [an] open LLM,\" Gurfinkel noted. This allows the platform to utilize state-of-the-art models while keeping data within a secure enterprise perimeter.Datarails’ new agents sit on top of a unified data layer that connects these disparate systems. Because the AI is grounded in the company’s own unified internal data, it avoids the hallucinations common in generic LLMs while offering a level of privacy required for sensitive financial data.\"If the CFO wants to leverage AI on the CFO level or the organization data, they need to consolidate the data,\" explained Datarails CEO and co-founder Didi Gurfinkel in an interview with VentureBeat.By solving that consolidation problem first, Datarails can now offer agents that understand the context of the business. \"Now the CFO can use our agents to run analysis, get insights, create reports... because now the data is ready,\" Gurfinkel said.&#x27;Vibe coding&#x27; for financeThe launch taps into a broader trend in software development where natural language prompts replace complex coding or manual configuration—a concept tech circles refer to as \"vibe coding.\" Gurfinkel believes this is the future of financial engineering.\"Very soon, the CFO and the financial team themselves will be able to develop applications,\" Gurfinkel predicted. \"The LLMs become so strong that in one prompt, they can replace full product runs.\"He described a workflow where a user could simply prompt: \"That was my budget and my actual of the past year. Now build me the budget for the next year.\"The new agents are designed to handle exactly these types of complex, multi-variable scenarios. For example, a user could ask, \"What happens if revenue grows slower next quarter?\" and receive a scenario analysis in return.Because the output can be delivered as an Excel file, finance teams can verify the formulas and assumptions, maintaining the audit trail that generic AI tools often lack.Ease of adoption: The &#x27;anti-implementation&#x27;For most engineering teams, the arrival of a new enterprise financial platform signals a looming headache: months of data migration, schema redesigns, and the inevitable friction of forcing non-technical users to abandon their preferred workflows. Datarails has engineered its way around this friction by building what might be best described as an \"anti-implementation.\"Instead of demanding a \"rip and replace\" of legacy systems, the platform accepts the messy reality of the modern finance stack. The architecture is designed to decouple the data storage from the presentation layer, effectively treating the organization&#x27;s existing Excel files as a frontend interface while Datarails acts as the backend database.\"We are not replacing anything,\" Gurfinkel explained. \"The implementation can be very fast, from a few hours to maybe a few days\".From a technical perspective, this means the \"engineering\" requirement is almost entirely stripped away. There are no ETL pipelines to build or Python scripts to maintain. The system comes pre-wired with over 200 native connectors—linking directly to ERPs like NetSuite and Sage, CRMs like Salesforce, and various HRIS and bank portals.The heavy lifting is replaced by a \"no-code\" mapping process. A finance analyst, not a developer, maps the fields from their General Ledger to their Excel models in a self-service workflow. For modules like Month-End Close, the company explicitly promises that \"no IT support is needed,\" a phrase that likely comes as a relief to stretched CTOs. Even complex setups, such as the new Cash Management module which requires banking integrations, are typically fully operational within two to three weeks.The result is a system where the \"technical debt\" usually associated with financial transformation is rendered obsolete. The finance team gets their \"single source of truth\" without ever asking engineering to provision a database.From version Control to vision control: a pivot that paid offDatarails wasn&#x27;t always the \"FinanceOS\" for the AI era. Founded in 2015 by Gurfinkel alongside co-founders Eyal Cohen (COO) and Oded Har-Tal (CTO), the Tel Aviv-based startup spent its early years tackling a dryer problem: version control for Excel. The initial premise was to synchronize and manage spreadsheets across enterprises, but adoption was sluggish as the team struggled to find the right product-market fit.The breakthrough came in 2020 with a strategic pivot. The team realized that finance professionals didn&#x27;t want to replace Excel with a new dashboard; they wanted to fix Excel&#x27;s limitations—specifically manual consolidation and data fragmentation. By shifting focus to SMB finance teams and embracing an \"Excel-native\" automation philosophy, the company found its stride.This alignment led to rapid scaling, fueled by a $55 million Series A in June 2021 led by Zeev Ventures, followed quickly by a $50 million Series B in March 2022 led by Qumra Capital. While the company faced headwinds during the tech downturn—resulting in an 18% workforce reduction in late 2022—it has since rebounded aggressively. By 2025, Datarails had nearly doubled its workforce to over 400 employees globally, driven by a multi-product expansion strategy that now includes Month-End Close and Cash Management solutions.Fueling the expansionThe new AI capabilities are supported by the $70 million Series C injection from One Peak, along with existing investors Vertex Growth, Vintage Investment Partners, and others. The funding arrives after a year of 70% revenue growth for Datarails, driven largely by the expansion of its product suite.More than 50% of the company&#x27;s growth in 2025 came from solutions launched in the last 12 months, including Datarails Month-End Close (a tool for automating reconciliations and workflow management) and Datarails Cash Management (for real-time liquidity monitoring).These products serve as the \"plumbing\" that makes the new AI agents effective. By automating the month-end close and unifying cash data, Datarails ensures that when a CFO asks the AI a question, the underlying numbers are accurate and up-to-date.For Gurfinkel, the goal is to make the finance office \"AI-native\" without forcing users to abandon their favorite tool: Excel.\"We are not replacing anything,\" Gurfinkel said. \"We connect the Excel so Excel now becomes the calculation and the presentation.\"With the launch of these new agents, Datarails is betting that the future of finance isn&#x27;t about learning new software, but about having a conversation with the data you already have.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2JKMdzG9HS26opXgs2P44p/b3ca78544561a561c34b4c3a849fedbe/Left_to_right__Oded_Har-Tal_Co-Founder___CTO__Datarails-_mascot__Bob_Sheetner___Didi_Gurfinkel__Co-Founder___CEO_and_Eyal_Co.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/what-servicenow-and-openai-signal-for-enterprises-as-ai-moves-from-advice-to",
          "published_at": "Wed, 21 Jan 2026 17:30:00 GMT",
          "title": "ServiceNow positions itself as the control layer for enterprise AI execution",
          "standfirst": "ServiceNow announced a multi-year partnership with OpenAI to bring GPT-5.2 into its AI Control Tower and Xanadu platform, reinforcing ServiceNow’s strategy to focus on enterprise workflows, guardrails, and orchestration rather than building frontier models itself.For enterprise buyers, the deal underscores a broader shift: general-purpose models are becoming interchangeable, while the platforms that control how they’re deployed and governed are where differentiation now lives.ServiceNow lets enterprises develop agents and applications, plug them into existing workflows, and manage orchestration and monitoring through its unified AI Control Tower. The partnership does not mean ServiceNow will no longer use other models to power its services, said John Aisien, senior vice president of product management at ServiceNow.\"We will remain an open platform. There are things we will partner on with each of the model providers, depending on their expertise. Still, ServiceNow will continue to support a hybrid, multi-model AI strategy where customers can bring any model to our AI platform,” Aisien said in an email to VentureBeat. “Instead of exclusivity, we give enterprise customers maximum flexibility by combining powerful general-purpose models with our own LLMs built for ServiceNow workflows.”What the OpenAI partnership unlocks for ServiceNow customersServiceNow customers get:Voice-first agents: Speech-to-speech and voice-to-text supportEnterprise knowledge access: Q&A grounded in enterprise data, with improved search and discoveryOperational automation: Incident summarization and resolution supportServiceNow said it plans to work directly with OpenAI to build “real-time speech-to-speech AI agents that can listen, reason and respond naturally without text intermediation.” The company is also interested in tapping OpenAI’s computer use models to automate actions across enterprise tools such as email and chat.The enterprise playbookThe partnership reinforces ServiceNow’s positioning as a control layer for enterprise AI, separating general-purpose models from the services that govern how they’re deployed, monitored, and secured. Rather than owning the models, ServiceNow is emphasizing orchestration and guardrails — the layers enterprises increasingly need to scale AI safely.Some companies that work with enterprises see the partnership as a positive. Tom Bachant, co-founder and CEO of AI workflow and support platform Unthread, said this could further reduce integration friction. “Deeply integrated systems often lower the barrier to entry and simplify initial deployment,\" he told VentureBeat in an email. \"However, as organizations scale AI across core business systems, flexibility becomes more important than standardization. Enterprises ultimately need the ability to adapt performance benchmarks, pricing models, and internal risk postures; none of which remain static over time.”As enterprise AI adoption accelerates, partnerships like this suggest the real battleground is shifting away from the models themselves and toward the platforms that control how those models are used in production.",
          "content": "ServiceNow announced a multi-year partnership with OpenAI to bring GPT-5.2 into its AI Control Tower and Xanadu platform, reinforcing ServiceNow’s strategy to focus on enterprise workflows, guardrails, and orchestration rather than building frontier models itself.For enterprise buyers, the deal underscores a broader shift: general-purpose models are becoming interchangeable, while the platforms that control how they’re deployed and governed are where differentiation now lives.ServiceNow lets enterprises develop agents and applications, plug them into existing workflows, and manage orchestration and monitoring through its unified AI Control Tower. The partnership does not mean ServiceNow will no longer use other models to power its services, said John Aisien, senior vice president of product management at ServiceNow.\"We will remain an open platform. There are things we will partner on with each of the model providers, depending on their expertise. Still, ServiceNow will continue to support a hybrid, multi-model AI strategy where customers can bring any model to our AI platform,” Aisien said in an email to VentureBeat. “Instead of exclusivity, we give enterprise customers maximum flexibility by combining powerful general-purpose models with our own LLMs built for ServiceNow workflows.”What the OpenAI partnership unlocks for ServiceNow customersServiceNow customers get:Voice-first agents: Speech-to-speech and voice-to-text supportEnterprise knowledge access: Q&A grounded in enterprise data, with improved search and discoveryOperational automation: Incident summarization and resolution supportServiceNow said it plans to work directly with OpenAI to build “real-time speech-to-speech AI agents that can listen, reason and respond naturally without text intermediation.” The company is also interested in tapping OpenAI’s computer use models to automate actions across enterprise tools such as email and chat.The enterprise playbookThe partnership reinforces ServiceNow’s positioning as a control layer for enterprise AI, separating general-purpose models from the services that govern how they’re deployed, monitored, and secured. Rather than owning the models, ServiceNow is emphasizing orchestration and guardrails — the layers enterprises increasingly need to scale AI safely.Some companies that work with enterprises see the partnership as a positive. Tom Bachant, co-founder and CEO of AI workflow and support platform Unthread, said this could further reduce integration friction. “Deeply integrated systems often lower the barrier to entry and simplify initial deployment,\" he told VentureBeat in an email. \"However, as organizations scale AI across core business systems, flexibility becomes more important than standardization. Enterprises ultimately need the ability to adapt performance benchmarks, pricing models, and internal risk postures; none of which remain static over time.”As enterprise AI adoption accelerates, partnerships like this suggest the real battleground is shifting away from the models themselves and toward the platforms that control how those models are used in production.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/55ywB5pweRdcKS0AR7NkuG/cfb973781feb2a8313a171ab19f06703/crimedy7_illustration_of_a_partnership_between_robots_abstrac_ee1e138f-dc4a-4f66-9dd7-94c1d5216de3_3.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/evs/volvo-ex60-suv-preview-400-mile-range-670-hp-and-google-gemini-onboard-173000033.html",
          "published_at": "Wed, 21 Jan 2026 17:30:00 +0000",
          "title": "Volvo EX60 SUV preview: 400-mile range, 670 hp and Google Gemini onboard",
          "standfirst": "Volvo hasn't exactly had a great run of EVs lately. The rollout of its flagship EX90 was stymied out of the gate by a bevy of software glitches. The EX30, meanwhile, was too expensive when it launched — the promised $35,000 model was incompatible with the currently chaotic global tariff situation.Now, it's time for a new generation of EV from Volvo, one that's radically different at its core with a gigacast frame, a much higher-density battery and enough digital and literal horsepower to impress the most jaded of automotive enthusiasts. Mix in high-performance chipsets from both NVIDIA and Qualcomm, plus Google's Gemini AI onboard, and on paper, it has a lot to offer. After getting an early look at the thing at its unveiling in Sweden, I feel like this EV is ready and able to face off against BMW's new iX3 and Mercedes-Benz's upcoming GLC.Let's start with the basics: The EX60 slots in the Volvo product lineup right alongside the existing XC60, Volvo's most popular model in the U.S. It's a two-row, mid-size SUV that seats five, the sort of thing perfect for those with small families or big dogs. It'll be available in three different basic configurations, starting with the single-motor, rear-drive, 369-horsepower, 310-mile EX60 P6. Next up is the AWD dual-motor, 503-hp, 320-mile P10, and finally the top-shelf, 670-hp, 400-mile P12.670 horsepower in an SUV of this size seems frankly excessive to me, but then it does have a lot of weight to move around — 5,137 pounds to be exact. That’s thanks in large part to the P12's 112-kilowatt-hour net battery pack which is about 50 percent bigger than the one inside a Tesla Model Y. The P6 is a relatively svelte 4,663 pounds thanks to its smaller 80-kWh net battery pack, while the P10 has 91 kWh.Volvo EX60VolvoBeyond the powertrain divisions, the Volvo EX60 will also be available in a variety of different trims with varying amounts of equipment, including the Volvo Cross Country edition with air suspension and a 20mm boost of ride height. Prices are said to start \"around $60k\" for an EX60 P10 Plus with a 21-speaker Bose system, but a 28-speaker Bowers & Wilkins system with Dolby Atmos will be available for those who really need all the channels.Of course, Atmos support is no good without a good source, and to that end, the EX60 will be the first Volvo with Apple Music built in. That'll be part of the company's Android Automotive-based infotainment system, running on a curved 15-inch OLED screen and powered by a Qualcomm 8255 chipset. It’s paired with a low, wide gauge cluster set far back on the dashboard behind the steering wheel.This will also be Volvo's first car with integrated Gemini, and indeed one of the first cars on the road with Google's smart agent. You can, of course, do typical Gemini things like ask about the weather or the nuances of René Descartes's concepts on dualism. Beyond that, Volvo CTO Anders Bell said that it will eventually gain access to the car's outward-looking cameras, meaning you'll be able to ask for more details on whatever it is you can see looming on the horizon.Volvo EX60VolvoVolvo calls the car's software-defined architecture and the hardware that powers it HuginCore, named for Huginn, the raven of Norse mythology and represents Odin's mind and senses. Qualcomm powers the infotainment side of the avian experience, but when it comes to active safety, the EX60 relies on an NVIDIA Drive AGX Orin chipset. Unlike the EX90, the EX60 will not use a LiDAR sensor.Volvo CTO Bell downplayed the absence of the sensor. \"We realized we can now achieve many more meaningful and safe automated functions without LiDAR than we could have years ago,\" he said. Per Bell, LiDAR was never really in the plan for the EX60 anyway, a decision looking all the brighter given the recent bankruptcy of Volvo's former LiDAR partner Luminar.The car's cameras and radar sensors all tuck nicely into the new exterior of the EX60, which certainly doesn't look miles off from the EX90 or indeed the current, gas-powered XC60. But the pronounced flares on the front fenders are a nice touch of personality on an otherwise understated SUV.At the core of the EX60 is a new platform Volvo calls SPA3, with a chassis made using gigacasting. This refers to the force required to inject molten aluminum into massive castings, allowing more of the car to be made from fewer components. Volvo says the carbon footprint of the EX60 is lower even than that of the much smaller EX30.The battery packs use the on-trend cell-to-pack construction method, which means all the cells are lumped together into a single unit. Typically, this boosts density at the cost of repairability, a tradeoff most manufacturers seem willing to make in pursuit of higher range and lower costs. However, Bell said that the company has actually made pack maintenance easier by optimizing the layout of the ancillary equipment.Volvo EX60Volvo\"The absolute vast majority, 90 percent of anything that ever needs to be repaired on a battery pack is electronics,\" he said. In the EX60, Volvo positioned the battery electronics beneath the rear seat to make them even easier to access. \"We save a lot of weight, save a lot of cost.\"The EX60 will be Volvo's first car to use the Tesla-style NACS charging standard, and the largest two packs will support charging speeds up to 370 kW. That drops to 320 kW on the 80-kWh net P6.In practical terms, though, they're all roughly the same. Each model charges from 10 to 80 percent in less than 20 minutes, adding between 160 and 173 miles of range in 10 minutes. That's not quite the 200 miles BMW's iX3 can manage in the same time, but it is close.The iX3 will probably be the EX60's fiercest competition when Volvo opens up orders later this spring. The EX60's $60,000 price for a midrange P10 Plus puts it right in line with the $60,000 that BMW says to expect for its iX3. Mercedes hasn't set American pricing for its GLC yet, but that, too, will be on a lot of shoppers' lists to compare.I've already been impressed by how both the iX3 and the GLC drive. Sadly, Volvo wouldn't let me behind the wheel of its EX60 just yet, but hopefully I can report back with impressions soon to start to see how all these stack up on the road. This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/volvo-ex60-suv-preview-400-mile-range-670-hp-and-google-gemini-onboard-173000033.html?src=rss",
          "content": "Volvo hasn't exactly had a great run of EVs lately. The rollout of its flagship EX90 was stymied out of the gate by a bevy of software glitches. The EX30, meanwhile, was too expensive when it launched — the promised $35,000 model was incompatible with the currently chaotic global tariff situation.Now, it's time for a new generation of EV from Volvo, one that's radically different at its core with a gigacast frame, a much higher-density battery and enough digital and literal horsepower to impress the most jaded of automotive enthusiasts. Mix in high-performance chipsets from both NVIDIA and Qualcomm, plus Google's Gemini AI onboard, and on paper, it has a lot to offer. After getting an early look at the thing at its unveiling in Sweden, I feel like this EV is ready and able to face off against BMW's new iX3 and Mercedes-Benz's upcoming GLC.Let's start with the basics: The EX60 slots in the Volvo product lineup right alongside the existing XC60, Volvo's most popular model in the U.S. It's a two-row, mid-size SUV that seats five, the sort of thing perfect for those with small families or big dogs. It'll be available in three different basic configurations, starting with the single-motor, rear-drive, 369-horsepower, 310-mile EX60 P6. Next up is the AWD dual-motor, 503-hp, 320-mile P10, and finally the top-shelf, 670-hp, 400-mile P12.670 horsepower in an SUV of this size seems frankly excessive to me, but then it does have a lot of weight to move around — 5,137 pounds to be exact. That’s thanks in large part to the P12's 112-kilowatt-hour net battery pack which is about 50 percent bigger than the one inside a Tesla Model Y. The P6 is a relatively svelte 4,663 pounds thanks to its smaller 80-kWh net battery pack, while the P10 has 91 kWh.Volvo EX60VolvoBeyond the powertrain divisions, the Volvo EX60 will also be available in a variety of different trims with varying amounts of equipment, including the Volvo Cross Country edition with air suspension and a 20mm boost of ride height. Prices are said to start \"around $60k\" for an EX60 P10 Plus with a 21-speaker Bose system, but a 28-speaker Bowers & Wilkins system with Dolby Atmos will be available for those who really need all the channels.Of course, Atmos support is no good without a good source, and to that end, the EX60 will be the first Volvo with Apple Music built in. That'll be part of the company's Android Automotive-based infotainment system, running on a curved 15-inch OLED screen and powered by a Qualcomm 8255 chipset. It’s paired with a low, wide gauge cluster set far back on the dashboard behind the steering wheel.This will also be Volvo's first car with integrated Gemini, and indeed one of the first cars on the road with Google's smart agent. You can, of course, do typical Gemini things like ask about the weather or the nuances of René Descartes's concepts on dualism. Beyond that, Volvo CTO Anders Bell said that it will eventually gain access to the car's outward-looking cameras, meaning you'll be able to ask for more details on whatever it is you can see looming on the horizon.Volvo EX60VolvoVolvo calls the car's software-defined architecture and the hardware that powers it HuginCore, named for Huginn, the raven of Norse mythology and represents Odin's mind and senses. Qualcomm powers the infotainment side of the avian experience, but when it comes to active safety, the EX60 relies on an NVIDIA Drive AGX Orin chipset. Unlike the EX90, the EX60 will not use a LiDAR sensor.Volvo CTO Bell downplayed the absence of the sensor. \"We realized we can now achieve many more meaningful and safe automated functions without LiDAR than we could have years ago,\" he said. Per Bell, LiDAR was never really in the plan for the EX60 anyway, a decision looking all the brighter given the recent bankruptcy of Volvo's former LiDAR partner Luminar.The car's cameras and radar sensors all tuck nicely into the new exterior of the EX60, which certainly doesn't look miles off from the EX90 or indeed the current, gas-powered XC60. But the pronounced flares on the front fenders are a nice touch of personality on an otherwise understated SUV.At the core of the EX60 is a new platform Volvo calls SPA3, with a chassis made using gigacasting. This refers to the force required to inject molten aluminum into massive castings, allowing more of the car to be made from fewer components. Volvo says the carbon footprint of the EX60 is lower even than that of the much smaller EX30.The battery packs use the on-trend cell-to-pack construction method, which means all the cells are lumped together into a single unit. Typically, this boosts density at the cost of repairability, a tradeoff most manufacturers seem willing to make in pursuit of higher range and lower costs. However, Bell said that the company has actually made pack maintenance easier by optimizing the layout of the ancillary equipment.Volvo EX60Volvo\"The absolute vast majority, 90 percent of anything that ever needs to be repaired on a battery pack is electronics,\" he said. In the EX60, Volvo positioned the battery electronics beneath the rear seat to make them even easier to access. \"We save a lot of weight, save a lot of cost.\"The EX60 will be Volvo's first car to use the Tesla-style NACS charging standard, and the largest two packs will support charging speeds up to 370 kW. That drops to 320 kW on the 80-kWh net P6.In practical terms, though, they're all roughly the same. Each model charges from 10 to 80 percent in less than 20 minutes, adding between 160 and 173 miles of range in 10 minutes. That's not quite the 200 miles BMW's iX3 can manage in the same time, but it is close.The iX3 will probably be the EX60's fiercest competition when Volvo opens up orders later this spring. The EX60's $60,000 price for a midrange P10 Plus puts it right in line with the $60,000 that BMW says to expect for its iX3. Mercedes hasn't set American pricing for its GLC yet, but that, too, will be on a lot of shoppers' lists to compare.I've already been impressed by how both the iX3 and the GLC drive. Sadly, Volvo wouldn't let me behind the wheel of its EX60 just yet, but hopefully I can report back with impressions soon to start to see how all these stack up on the road. This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/volvo-ex60-suv-preview-400-mile-range-670-hp-and-google-gemini-onboard-173000033.html?src=rss",
          "feed_position": 8,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/JPG_Full-vin0490_34FrontAlt_746_EX60_ROW.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/sony-linkbuds-clip-review-open-fit-benefits-arent-enough-to-stand-out-160000140.html",
          "published_at": "Wed, 21 Jan 2026 16:00:00 +0000",
          "title": "Sony LinkBuds Clip review: Open-fit benefits aren't enough to stand out",
          "standfirst": "I vividly remember when Bose announced the Ultra Open Earbuds. While I applauded the company for trying something different, I wasn’t sure if the clip-on design would take hold. Well, here we are almost two years later and most earbud makers now have something akin to Bose’s fashion experiment. You can now count Sony among those as the company revealed its LinkBuds Clip ($230) open-fit earbuds today. These aren’t the first open-wear earbuds in Sony’s LinkBuds lineup. The company has two generations of the LinkBuds Open (originally called just LinkBuds) under its belt, giving users a more traditional earbud fit with donut-shaped drivers that let ambient sounds in. Now Sony is taking a cue from Bose and others with a clip-on design that attaches securely and comfortably to the ear while leaving the ear canal unobstructed. It’s clear companies believe customers like this type of earbuds, but Sony’s challenge is to make the LinkBuds Clip unique among the growing list of alternatives. Design and fit Sony isn’t offering anything distinctive in terms of design here, but that’s okay. To be fair, I haven’t seen too much innovation in terms of aesthetics in these clip-on-style earbuds. For the most part, they all have similar shapes: two cylindrical cases connected by short, flexible cable. True to its predecessors, Sony put the drivers in a squatty housing while the bulk of the components are in a larger one that sits behind your ear lobe. Sony kept the weight of the LinkBuds Clip low, and it avoided the bulk of the Ultra Open Earbuds. Both of these factors contribute to a very comfortable fit, so the IPX4-rated earbuds can be easily worn all day without becoming a burden. And while I didn’t need them, Sony includes a pair of flexible silicone “fitting cushions” in the box. These clip on to the short, flat cable of the newest LinkBuds for a more secure fit. During my tests, the LinkBuds Clip stayed in place just fine without them, but there also wasn’t any decreased comfort when I did install them. The last design-related item I’ll mention is the touch controls. On the LinkBuds Clip, the flat connector between the two housings accepts taps for playback controls, volume changes, cycling through sound modes and more. You can tap along this area to make an adjustment, and you don’t have to do so right in the center. The LinkBuds Clip were pleasantly responsive during this review, quickly completing the task without delay or repeated taps. That is, except for volume, because you have to keep tapping for that change to happen. LinkBuds Clip features Controls are situated along the connector between the two cylindrical housings Billy Steele for Engadget Sony typically throws a whole host of features at its earbuds. Even though they’re technically the company’s midrange line, the LinkBuds family has a robust set of conveniences that make them well suited for both productivity and leisure. Unfortunately, the LinkBuds Clip doesn’t have as much to offer here. The company gives you the basics, like the ability to fine-tune the tap controls or customize the EQ, and there’s even the Adaptive Audio tool that lets you customize settings based on activity or location (Sony calls them “scenes”). But there are some handy features I’ve come to expect from Sony that are notably absent. The LinkBuds Clip doesn’t support speak-to-chat, Sony’s voice recognition feature that pauses audio and activates ambient sound when you start talking. Quick attention mode, the tool that lowers the volume and lets in ambient sound for brief chats, isn’t here either. These earbuds don’t even have wear detection, and you have to settle for regular ol’ DSEE audio upscaling instead of an enhanced version of that tech. Sony did equip the LinkBuds Clip with unique listening modes meant to enhance the audio performance in two scenarios. First, Voice Boost increases the volume of voices when you’re on a call or listening to podcasts or audiobooks. The company says this is designed for noisy environments where the ambient sound is overly raucous. During my testing, I found the setting to be an extreme treble boost and volume increase — something that’s definitely not well-suited for music. Next, Sound Leakage Reduction dials back high-pitched tones to avoid annoying your neighbors in the office or coffee shop. To me, this is the opposite of Voice Boost, removing the highs for a more mid- and bass-heavy tuning, but it doesn’t sound very good compared to the default setting. Plus, my family wasn’t really able to hear any leakage on the LinkBuds Clip anyway, unless I had the volume cranked uncomfortably high. I’ll also note that any EQ customization/presets and DSEE upscaling are only available in Standard (default) listening mode. Sound and call quality The LinkBuds Clip have both noise reduction and bone conduction tech for calls Billy Steele for Engadget Open-fit earbuds typically struggle to muster adequate low-end tone, and the LinkBuds Clip meets the same fate. However, it’s not all bad in the audio department as these earbuds have great clarity and provide a solid soundstage so overall quality doesn’t suffer to the point of being unpleasant. The lack of bass is most apparent in booming genres, like hip-hop and synth-heavy electronic tunes. The LinkBuds Clip doesn’t fare much better with more chaotic music styles like rock and metal. Spiritbox’s “Holy Roller” doesn’t have the depth that it does on closed-fit earbuds like the AirPods Pro 3 or over-ear headphones like Sony’s WH-1000XM6. As such, the band’s songs aren’t nearly as immersive or impactful without adequate amounts of bass. So if pristine, enveloping sound quality is your primary aim, you’ll want to look elsewhere, and you’ll want to tread carefully with any other open-type earbuds. The open nature of the LinkBuds Clip makes them well-suited for calls. Since your ears aren’t plugged, you can clearly hear your own voice so you never feel like you need to shout. Sony says these earbuds have AI noise reduction and a bone conduction sensor for voice pickup, both of which are supposed to keep you sounding good. During the course of this review, I found the background noise reduction worked well without making me sound overly processed. However, the overall voice quality is average at best, which means you can get by with using these for calls, but there are better options if you really value clarity here. Battery life on the LinkBuds Clip When it comes to battery life, Sony says you can expect up to nine hours of use on a charge with up to 37 hours when you factor in the case. That means the LinkBuds Clip alone is enough to get you through a full workday, especially if you’re pausing for the occasional office chat or in-person meeting. And you’ll get more if you’re docking the earbuds in their case once or twice a day. If you do find yourself with a depleted battery though, a three-minute charge will give you an hour of play time. In multiple attempts at a full, nine-hour run down, I wasn’t able to hit Sony’s stated figure. In Standard mode with DSEE upscaling set to automatic and volume at about 60-70 percent, the LinkBuds Clip lasted just over six hours. This timeframe included a mix of music, podcasts and calls — typical work day activities. The competition The including \"fitting cushion\" (left) can help with a secure fit Billy Steele for Engadget Based on my testing, the Bose Ultra Open Earbuds are still the best in this emerging clip-on category. However, they’re the bulkiest and the most expensive at $299. While they offer all the perks of open wear, sound quality can vary based on how they fit your ears and the lack of multipoint Bluetooth could be a deal breaker for some. If you’re hoping to pay less than either Bose or Sony, Anker’s Soundcore line offers the AeroClip for $170. Or if you’re truly ballin’ on a budget, JLab has the Flex Open Earbuds that are now just $40. JBL just announced a new $150 set during CES too, but those won’t be available until March. I’ve only given these two a casual listen without any in-depth testing, so I won’t make a definitive call on which one stacks up best against the LinkBuds Clip. But they’re also just three of currently available options, and there are many more if none of these seem compelling. Wrap-up The LinkBuds Clip expands Sony’s midrange lineup with a completely different design that comes with inherent perks. They’re plenty comfortable and exploit the benefits of open-type designs while doing basic earbud functionality well. Subpar bass performance and the omission of some of Sony’s more attractive features (and even some basic ones) mean the company hasn’t done enough to distinguish the Clip from the competition in an obvious way. Sure, these earbuds work as intended without being flashy or overly complicated, but there are plenty of other options that do that too. Update, January 21 2026, 4:45PM ET: After conducting additional battery testing, I still wasn’t able to meet the nine hour figure Sony promises. Due to this, I’ve adjusted the score from a 72 to a 70 to reflect the performance in this area. I’ve also updated the battery life section with more detailed impressions. This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/sony-linkbuds-clip-review-open-fit-benefits-arent-enough-to-stand-out-160000140.html?src=rss",
          "content": "I vividly remember when Bose announced the Ultra Open Earbuds. While I applauded the company for trying something different, I wasn’t sure if the clip-on design would take hold. Well, here we are almost two years later and most earbud makers now have something akin to Bose’s fashion experiment. You can now count Sony among those as the company revealed its LinkBuds Clip ($230) open-fit earbuds today. These aren’t the first open-wear earbuds in Sony’s LinkBuds lineup. The company has two generations of the LinkBuds Open (originally called just LinkBuds) under its belt, giving users a more traditional earbud fit with donut-shaped drivers that let ambient sounds in. Now Sony is taking a cue from Bose and others with a clip-on design that attaches securely and comfortably to the ear while leaving the ear canal unobstructed. It’s clear companies believe customers like this type of earbuds, but Sony’s challenge is to make the LinkBuds Clip unique among the growing list of alternatives. Design and fit Sony isn’t offering anything distinctive in terms of design here, but that’s okay. To be fair, I haven’t seen too much innovation in terms of aesthetics in these clip-on-style earbuds. For the most part, they all have similar shapes: two cylindrical cases connected by short, flexible cable. True to its predecessors, Sony put the drivers in a squatty housing while the bulk of the components are in a larger one that sits behind your ear lobe. Sony kept the weight of the LinkBuds Clip low, and it avoided the bulk of the Ultra Open Earbuds. Both of these factors contribute to a very comfortable fit, so the IPX4-rated earbuds can be easily worn all day without becoming a burden. And while I didn’t need them, Sony includes a pair of flexible silicone “fitting cushions” in the box. These clip on to the short, flat cable of the newest LinkBuds for a more secure fit. During my tests, the LinkBuds Clip stayed in place just fine without them, but there also wasn’t any decreased comfort when I did install them. The last design-related item I’ll mention is the touch controls. On the LinkBuds Clip, the flat connector between the two housings accepts taps for playback controls, volume changes, cycling through sound modes and more. You can tap along this area to make an adjustment, and you don’t have to do so right in the center. The LinkBuds Clip were pleasantly responsive during this review, quickly completing the task without delay or repeated taps. That is, except for volume, because you have to keep tapping for that change to happen. LinkBuds Clip features Controls are situated along the connector between the two cylindrical housings Billy Steele for Engadget Sony typically throws a whole host of features at its earbuds. Even though they’re technically the company’s midrange line, the LinkBuds family has a robust set of conveniences that make them well suited for both productivity and leisure. Unfortunately, the LinkBuds Clip doesn’t have as much to offer here. The company gives you the basics, like the ability to fine-tune the tap controls or customize the EQ, and there’s even the Adaptive Audio tool that lets you customize settings based on activity or location (Sony calls them “scenes”). But there are some handy features I’ve come to expect from Sony that are notably absent. The LinkBuds Clip doesn’t support speak-to-chat, Sony’s voice recognition feature that pauses audio and activates ambient sound when you start talking. Quick attention mode, the tool that lowers the volume and lets in ambient sound for brief chats, isn’t here either. These earbuds don’t even have wear detection, and you have to settle for regular ol’ DSEE audio upscaling instead of an enhanced version of that tech. Sony did equip the LinkBuds Clip with unique listening modes meant to enhance the audio performance in two scenarios. First, Voice Boost increases the volume of voices when you’re on a call or listening to podcasts or audiobooks. The company says this is designed for noisy environments where the ambient sound is overly raucous. During my testing, I found the setting to be an extreme treble boost and volume increase — something that’s definitely not well-suited for music. Next, Sound Leakage Reduction dials back high-pitched tones to avoid annoying your neighbors in the office or coffee shop. To me, this is the opposite of Voice Boost, removing the highs for a more mid- and bass-heavy tuning, but it doesn’t sound very good compared to the default setting. Plus, my family wasn’t really able to hear any leakage on the LinkBuds Clip anyway, unless I had the volume cranked uncomfortably high. I’ll also note that any EQ customization/presets and DSEE upscaling are only available in Standard (default) listening mode. Sound and call quality The LinkBuds Clip have both noise reduction and bone conduction tech for calls Billy Steele for Engadget Open-fit earbuds typically struggle to muster adequate low-end tone, and the LinkBuds Clip meets the same fate. However, it’s not all bad in the audio department as these earbuds have great clarity and provide a solid soundstage so overall quality doesn’t suffer to the point of being unpleasant. The lack of bass is most apparent in booming genres, like hip-hop and synth-heavy electronic tunes. The LinkBuds Clip doesn’t fare much better with more chaotic music styles like rock and metal. Spiritbox’s “Holy Roller” doesn’t have the depth that it does on closed-fit earbuds like the AirPods Pro 3 or over-ear headphones like Sony’s WH-1000XM6. As such, the band’s songs aren’t nearly as immersive or impactful without adequate amounts of bass. So if pristine, enveloping sound quality is your primary aim, you’ll want to look elsewhere, and you’ll want to tread carefully with any other open-type earbuds. The open nature of the LinkBuds Clip makes them well-suited for calls. Since your ears aren’t plugged, you can clearly hear your own voice so you never feel like you need to shout. Sony says these earbuds have AI noise reduction and a bone conduction sensor for voice pickup, both of which are supposed to keep you sounding good. During the course of this review, I found the background noise reduction worked well without making me sound overly processed. However, the overall voice quality is average at best, which means you can get by with using these for calls, but there are better options if you really value clarity here. Battery life on the LinkBuds Clip When it comes to battery life, Sony says you can expect up to nine hours of use on a charge with up to 37 hours when you factor in the case. That means the LinkBuds Clip alone is enough to get you through a full workday, especially if you’re pausing for the occasional office chat or in-person meeting. And you’ll get more if you’re docking the earbuds in their case once or twice a day. If you do find yourself with a depleted battery though, a three-minute charge will give you an hour of play time. In multiple attempts at a full, nine-hour run down, I wasn’t able to hit Sony’s stated figure. In Standard mode with DSEE upscaling set to automatic and volume at about 60-70 percent, the LinkBuds Clip lasted just over six hours. This timeframe included a mix of music, podcasts and calls — typical work day activities. The competition The including \"fitting cushion\" (left) can help with a secure fit Billy Steele for Engadget Based on my testing, the Bose Ultra Open Earbuds are still the best in this emerging clip-on category. However, they’re the bulkiest and the most expensive at $299. While they offer all the perks of open wear, sound quality can vary based on how they fit your ears and the lack of multipoint Bluetooth could be a deal breaker for some. If you’re hoping to pay less than either Bose or Sony, Anker’s Soundcore line offers the AeroClip for $170. Or if you’re truly ballin’ on a budget, JLab has the Flex Open Earbuds that are now just $40. JBL just announced a new $150 set during CES too, but those won’t be available until March. I’ve only given these two a casual listen without any in-depth testing, so I won’t make a definitive call on which one stacks up best against the LinkBuds Clip. But they’re also just three of currently available options, and there are many more if none of these seem compelling. Wrap-up The LinkBuds Clip expands Sony’s midrange lineup with a completely different design that comes with inherent perks. They’re plenty comfortable and exploit the benefits of open-type designs while doing basic earbud functionality well. Subpar bass performance and the omission of some of Sony’s more attractive features (and even some basic ones) mean the company hasn’t done enough to distinguish the Clip from the competition in an obvious way. Sure, these earbuds work as intended without being flashy or overly complicated, but there are plenty of other options that do that too. Update, January 21 2026, 4:45PM ET: After conducting additional battery testing, I still wasn’t able to meet the nine hour figure Sony promises. Due to this, I’ve adjusted the score from a 72 to a 70 to reflect the performance in this area. I’ve also updated the battery life section with more detailed impressions. This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/sony-linkbuds-clip-review-open-fit-benefits-arent-enough-to-stand-out-160000140.html?src=rss",
          "feed_position": 12,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/DSC_5728.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/truefoundry-launches-truefailover-to-automatically-reroute-enterprise-ai",
          "published_at": "Wed, 21 Jan 2026 14:00:00 GMT",
          "title": "TrueFoundry launches TrueFailover to automatically reroute enterprise AI traffic during model outages",
          "standfirst": "When OpenAI went down in December, one of TrueFoundry’s customers faced a crisis that had nothing to do with chatbots or content generation. The company uses large language models to help refill prescriptions. Every second of downtime meant thousands of dollars in lost revenue — and patients who could not access their medications on time.TrueFoundry, an enterprise AI infrastructure company, announced Wednesday a new product called TrueFailover designed to prevent exactly that scenario. The system automatically detects when AI providers experience outages, slowdowns, or quality degradation, then seamlessly reroutes traffic to backup models and regions before users notice anything went wrong.\"The challenge is that in the AI world, failover is no longer that simple,\" said Nikunj Bajaj, co-founder and chief executive of TrueFoundry, in an exclusive interview with VentureBeat. \"When you move from one model to another, you also have to consider things like output quality, latency, and whether the prompt even works the same way. In many cases, the prompt needs to be adjusted in real-time to prevent results from degrading. That is not something most teams are set up to manage manually.\"The announcement arrives at a pivotal moment for enterprise AI adoption. Companies have moved far beyond experimentation. AI now powers prescription refills at pharmacies, generates sales proposals, assists software developers, and handles customer support inquiries. When these systems fail, the consequences ripple through entire organizations.Why enterprise AI systems remain dangerously dependent on single providersLarge language models from OpenAI, Anthropic, Google, and other providers have become essential infrastructure for thousands of businesses. But unlike traditional cloud services from Amazon Web Services or Microsoft Azure — which offer robust uptime guarantees backed by decades of operational experience — AI providers operate complex, resource-intensive systems that remain prone to unexpected failures.\"Major LLM providers experience outages, slowdowns, or latency spikes every few weeks or months, and we regularly see the downstream impact on businesses that rely on a single provider,\" Bajaj told VentureBeat.The December OpenAI outage that affected TrueFoundry&#x27;s pharmacy customer illustrates the stakes. \"At their scale, even seconds of downtime can translate into thousands of dollars in lost revenue,\" Bajaj explained. \"Beyond the economic impact, there is also a human consequence when patients cannot access prescriptions on time. Because this customer had our failover solution in place, they were able to reroute requests to another model provider within minutes of detecting the outage. Without that setup, recovery would likely have taken hours.\"The problem extends beyond complete outages. Partial failures — where a model slows down or produces lower-quality responses without going fully offline — can quietly destroy user experience and violate service-level agreements. These \"slow but technically up\" scenarios often prove more damaging than dramatic crashes because they evade traditional monitoring systems while steadily eroding performance.Inside the technology that keeps AI applications online when providers failTrueFailover operates as a resilience layer on top of TrueFoundry&#x27;s AI Gateway, which already processes more than 10 billion requests per month for Fortune 1000 companies. The system weaves together several interconnected capabilities into a unified safety net for enterprise AI.At its core, the product enables multi-model failover by allowing enterprises to define primary and backup models across providers. If OpenAI becomes unavailable, traffic automatically shifts to Anthropic, Google&#x27;s Gemini, Mistral, or self-hosted alternatives. The routing happens transparently, without requiring application teams to rewrite code or manually intervene.The system extends this protection across geographic boundaries through multi-region and multi-cloud resilience. By distributing AI endpoints across zones and cloud providers, health-based routing can detect problems in specific regions and divert traffic to healthy alternatives. What would otherwise become a global incident transforms into an invisible infrastructure adjustment that users never perceive.Perhaps most critically, TrueFailover employs degradation-aware routing that continuously monitors latency, error rates, and quality signals. \"We look at a combination of signals that together indicate when a model&#x27;s performance is starting to degrade,\" Bajaj explained. \"Large language models are shared resources. Providers run the same model instance across many customers, so when demand spikes for one user or workload, it can affect everyone else using that model.\"The system watches for rising response times, increasing error rates, and patterns suggesting instability. \"Individually, none of these signals tell the full story,\" Bajaj said. \"But taken together, they allow us to detect early signs that a model is slowing down or becoming unreliable. Those signals feed into an AI-driven system that can decide when and how to reroute traffic before users experience a noticeable drop in quality.\"Strategic caching rounds out the protection by shielding providers from sudden traffic spikes and preventing rate-limit cascades during high-demand periods. This allows systems to absorb demand surges and provider limits without brownouts or throttling surprises.The approach represents a fundamental shift in how enterprises should think about AI reliability. \"TrueFailover is designed to handle that complexity automatically,\" Bajaj said. \"It continuously monitors how models behave across many customers and use cases, looks for early warning signs like rising latency, and takes action before things break. Most individual enterprises do not have that kind of visibility because they are only able to see their own systems.\"The engineering challenge of switching models without sacrificing output qualityOne of the thorniest challenges in AI failover involves maintaining consistent output quality when switching between models. A prompt optimized for GPT-5 may produce different results on Claude or Gemini. TrueFoundry addresses this through several mechanisms that balance speed against precision.\"Some teams rely on the fact that large models have become good enough that small differences in prompts do not materially affect the output,\" Bajaj explained. \"In those cases, switching from one provider to another can happen with some visible impact — that&#x27;s not ideal, but some teams choose to do it.\"More sophisticated implementations maintain provider-specific prompts for the same application. \"When traffic shifts from one model to another, the prompt shifts with it,\" Bajaj said. \"In that case, failover is not just switching models. It is switching to a configuration that has already been tested.\"TrueFailover automates this process. The system dynamically routes requests and adjusts prompts based on which model handles the query, keeping quality within acceptable ranges without manual intervention. The key, Bajaj emphasized, is that \"failover is planned, not reactive. The logic, prompts, and guardrails are defined ahead of time, which is why end users typically do not notice when a switch happens.\"Importantly, many failover scenarios do not require changing providers at all. \"It can be routing traffic from the same model in one region to another region, such as from the East Coast to the West Coast, where no prompt changes are required,\" Bajaj noted. This geographic flexibility provides a first line of defense before more complex cross-provider switches become necessary.How regulated industries can use AI failover without compromising complianceFor enterprises in healthcare, financial services, and other regulated sectors, the prospect of AI traffic automatically routing to different providers raises immediate compliance concerns. Patient data cannot simply flow to whichever model happens to be available. Financial records require strict controls over where they travel. TrueFoundry built explicit guardrails to address these constraints.\"TrueFailover will never route data to a model or provider that an enterprise has not explicitly approved,\" Bajaj said. \"Everything is controlled through an admin configuration layer where teams set clear guardrails upfront.\"Enterprises define exactly which models qualify for failover, which providers can receive traffic, and even which regions or model categories — such as closed-source versus open-source — are acceptable. Once those rules take effect, TrueFailover operates only within them.\"If a model is not on the approved list, it is simply not an option for routing,\" Bajaj emphasized. \"There is no scenario where traffic is automatically sent somewhere unexpected. The idea is to give teams full control over compliance and data boundaries, while still allowing the system to respond quickly when something goes wrong. That way, reliability improves without compromising security or regulatory requirements.\"This design reflects lessons learned from TrueFoundry&#x27;s existing enterprise deployments. A Fortune 50 healthcare company already uses the platform to handle more than 500 million IVR calls annually through an agentic AI system. That customer required the ability to run workloads across both cloud and on-premise infrastructure while maintaining strict data residency controls — exactly the kind of hybrid environment where failover policies must be precisely defined.Where automatic failover cannot help and what enterprises must plan forTrueFoundry acknowledges that TrueFailover cannot solve every reliability problem. The system operates within the guardrails enterprises configure, and those configurations determine what protection is possible.\"If a team allows failover from a large, high-capacity model to a much smaller model without adjusting prompts or expectations, TrueFailover cannot guarantee the same output quality,\" Bajaj explained. \"The system can route traffic, but it cannot make a smaller model behave like a larger one without appropriate configuration.\"Infrastructure constraints also limit protection. If an enterprise hosts its own models and all of them run on the same GPU cluster, TrueFailover cannot help when that infrastructure fails. \"When there is no alternate infrastructure available, there is nothing to fail over to,\" Bajaj said.The question of simultaneous multi-provider failures occasionally surfaces in enterprise risk discussions. Bajaj argues this scenario, while theoretically possible, rarely matches reality. \"In practice, &#x27;going down&#x27; usually does not mean an entire provider is offline across all models and regions,\" he explained. \"What happens far more often is a slowdown or disruption in a specific model or region because of traffic spikes or capacity issues.\"When that occurs, failover can happen at multiple levels — from on-premise to cloud, cloud to on-premise, one region to another, one model to another, or even within the same provider before switching providers entirely. \"That alone makes it very unlikely that everything fails at once,\" Bajaj said. \"The key point is that reliability is built on layers of redundancy. The more providers, regions, and models that are included in the guardrails, the smaller the chance that users experience a complete outage.\"A startup that built its platform inside Fortune 500 AI deploymentsTrueFoundry has established itself as infrastructure for some of the world&#x27;s largest AI deployments, providing crucial context for its failover ambitions. The company raised $19 million in Series A funding in February 2025, led by Intel Capital with participation from Eniac Ventures, Peak XV Partners, and Jump Capital. Angel investors including Gokul Rajaram and Mohit Aron also joined the round, bringing total funding to $21 million.The San Francisco-based company was founded in 2021 by Bajaj and co-founders Abhishek Choudhary and Anuraag Gutgutia, all former Meta engineers who met as classmates at IIT Kharagpur. Initially focused on accelerating machine learning deployments, TrueFoundry pivoted to support generative AI capabilities as the technology went mainstream in 2023.The company&#x27;s customer roster demonstrates enterprise-scale adoption that few AI infrastructure startups can match. Nvidia employs TrueFoundry to build multi-agent systems that optimize GPU cluster utilization across data centers worldwide — a use case where even small improvements in utilization translate into substantial business impact given the insatiable demand for GPU capacity. Adopt AI routes more than 15 million requests and 40 billion input tokens through TrueFoundry&#x27;s AI Gateway to power its enterprise agentic workflows.Gaming company Games 24x7 serves machine learning models to more than 100 million users through the platform at scales exceeding 200 requests per second. Digital adoption platform Whatfix migrated to a microservices architecture on TrueFoundry, reducing its release cycle sixfold and cutting testing time by 40 percent.TrueFoundry currently reports more than 30 paid customers worldwide and has indicated it exceeded $1.5 million in annual recurring revenue last year while quadrupling its customer base. The company manages more than 1,000 clusters for machine learning workloads across its client base.TrueFailover will be offered as an add-on module on top of the existing TrueFoundry AI Gateway and platform, with pricing following a usage-based model tied to traffic volume along with the number of users, models, providers, and regions involved. An early access program for design partners opens in the coming weeks.Why traditional cloud uptime guarantees may never apply to AI providersEnterprise technology buyers have long demanded uptime commitments from infrastructure providers. Amazon Web Services, Microsoft Azure, and Google Cloud all offer service-level agreements with financial penalties for failures. Will AI providers eventually face similar expectations?Bajaj sees fundamental constraints that make traditional SLAs difficult to achieve in the current generation of AI infrastructure. \"Most foundational LLMs today operate as shared resources, which is what enables the standard pricing you see publicly advertised,\" he explained. \"Providers do offer higher uptime commitments, but that usually means dedicated capacity or reserved infrastructure, and the cost increases significantly.\"Even with substantial budgets, enterprises face usage quotas that create unexpected exposure. \"If traffic spikes beyond those limits, requests can still spill back into shared infrastructure,\" Bajaj said. \"That makes it hard to achieve the kind of hard guarantees enterprises are used to with cloud providers.\"The economics of running large language models create additional barriers that may persist for years. \"LLMs are still extremely complex and expensive to run. They require massive infrastructure and energy, and we do not expect a near-term future where most companies run multiple, fully dedicated model instances just to guarantee uptime.\"This reality drives demand for solutions like TrueFailover that provide resilience regardless of what individual providers can promise. \"Enterprises are realizing that reliability cannot come from the model provider alone,\" Bajaj said. \"It requires additional layers of protection to handle the realities of how these systems operate today.\"The new calculus for companies that built AI into critical business processesThe timing of TrueFoundry&#x27;s announcement reflects a fundamental shift in how enterprises use AI — and what they stand to lose when it fails. What began as internal experimentation has evolved into customer-facing applications where disruptions directly affect revenue and reputation.\"Many enterprises experimented with Gen AI and agentic systems in the past, and production use cases were largely internal-facing,\" Bajaj observed. \"There was no immediate impact on their top line or the public perception of the enterprise.\"That era has ended. \"Now that these enterprises have launched public-facing applications, where both the top line and public perception can be impacted if an outage occurs, the stakes are much higher than they were even six months ago. That&#x27;s why we are seeing more and more attention on this now.\"For companies that have woven AI into critical business processes — from prescription refills to customer support to sales operations — the calculus has changed entirely. The question is no longer which model performs best on benchmarks or which provider offers the most compelling features. The question that now keeps technology leaders awake is far simpler and far more urgent: what happens when the AI disappears at the worst possible moment?Somewhere, a pharmacist is filling a prescription. A customer support agent is resolving a complaint. A sales team is generating a proposal for a deal that closes tomorrow. All of them depend on AI systems that depend on providers that, despite their scale and sophistication, still go dark without warning.TrueFoundry is betting that enterprises will pay handsomely to ensure those moments of darkness never reach the people who matter most — their customers.",
          "content": "When OpenAI went down in December, one of TrueFoundry’s customers faced a crisis that had nothing to do with chatbots or content generation. The company uses large language models to help refill prescriptions. Every second of downtime meant thousands of dollars in lost revenue — and patients who could not access their medications on time.TrueFoundry, an enterprise AI infrastructure company, announced Wednesday a new product called TrueFailover designed to prevent exactly that scenario. The system automatically detects when AI providers experience outages, slowdowns, or quality degradation, then seamlessly reroutes traffic to backup models and regions before users notice anything went wrong.\"The challenge is that in the AI world, failover is no longer that simple,\" said Nikunj Bajaj, co-founder and chief executive of TrueFoundry, in an exclusive interview with VentureBeat. \"When you move from one model to another, you also have to consider things like output quality, latency, and whether the prompt even works the same way. In many cases, the prompt needs to be adjusted in real-time to prevent results from degrading. That is not something most teams are set up to manage manually.\"The announcement arrives at a pivotal moment for enterprise AI adoption. Companies have moved far beyond experimentation. AI now powers prescription refills at pharmacies, generates sales proposals, assists software developers, and handles customer support inquiries. When these systems fail, the consequences ripple through entire organizations.Why enterprise AI systems remain dangerously dependent on single providersLarge language models from OpenAI, Anthropic, Google, and other providers have become essential infrastructure for thousands of businesses. But unlike traditional cloud services from Amazon Web Services or Microsoft Azure — which offer robust uptime guarantees backed by decades of operational experience — AI providers operate complex, resource-intensive systems that remain prone to unexpected failures.\"Major LLM providers experience outages, slowdowns, or latency spikes every few weeks or months, and we regularly see the downstream impact on businesses that rely on a single provider,\" Bajaj told VentureBeat.The December OpenAI outage that affected TrueFoundry&#x27;s pharmacy customer illustrates the stakes. \"At their scale, even seconds of downtime can translate into thousands of dollars in lost revenue,\" Bajaj explained. \"Beyond the economic impact, there is also a human consequence when patients cannot access prescriptions on time. Because this customer had our failover solution in place, they were able to reroute requests to another model provider within minutes of detecting the outage. Without that setup, recovery would likely have taken hours.\"The problem extends beyond complete outages. Partial failures — where a model slows down or produces lower-quality responses without going fully offline — can quietly destroy user experience and violate service-level agreements. These \"slow but technically up\" scenarios often prove more damaging than dramatic crashes because they evade traditional monitoring systems while steadily eroding performance.Inside the technology that keeps AI applications online when providers failTrueFailover operates as a resilience layer on top of TrueFoundry&#x27;s AI Gateway, which already processes more than 10 billion requests per month for Fortune 1000 companies. The system weaves together several interconnected capabilities into a unified safety net for enterprise AI.At its core, the product enables multi-model failover by allowing enterprises to define primary and backup models across providers. If OpenAI becomes unavailable, traffic automatically shifts to Anthropic, Google&#x27;s Gemini, Mistral, or self-hosted alternatives. The routing happens transparently, without requiring application teams to rewrite code or manually intervene.The system extends this protection across geographic boundaries through multi-region and multi-cloud resilience. By distributing AI endpoints across zones and cloud providers, health-based routing can detect problems in specific regions and divert traffic to healthy alternatives. What would otherwise become a global incident transforms into an invisible infrastructure adjustment that users never perceive.Perhaps most critically, TrueFailover employs degradation-aware routing that continuously monitors latency, error rates, and quality signals. \"We look at a combination of signals that together indicate when a model&#x27;s performance is starting to degrade,\" Bajaj explained. \"Large language models are shared resources. Providers run the same model instance across many customers, so when demand spikes for one user or workload, it can affect everyone else using that model.\"The system watches for rising response times, increasing error rates, and patterns suggesting instability. \"Individually, none of these signals tell the full story,\" Bajaj said. \"But taken together, they allow us to detect early signs that a model is slowing down or becoming unreliable. Those signals feed into an AI-driven system that can decide when and how to reroute traffic before users experience a noticeable drop in quality.\"Strategic caching rounds out the protection by shielding providers from sudden traffic spikes and preventing rate-limit cascades during high-demand periods. This allows systems to absorb demand surges and provider limits without brownouts or throttling surprises.The approach represents a fundamental shift in how enterprises should think about AI reliability. \"TrueFailover is designed to handle that complexity automatically,\" Bajaj said. \"It continuously monitors how models behave across many customers and use cases, looks for early warning signs like rising latency, and takes action before things break. Most individual enterprises do not have that kind of visibility because they are only able to see their own systems.\"The engineering challenge of switching models without sacrificing output qualityOne of the thorniest challenges in AI failover involves maintaining consistent output quality when switching between models. A prompt optimized for GPT-5 may produce different results on Claude or Gemini. TrueFoundry addresses this through several mechanisms that balance speed against precision.\"Some teams rely on the fact that large models have become good enough that small differences in prompts do not materially affect the output,\" Bajaj explained. \"In those cases, switching from one provider to another can happen with some visible impact — that&#x27;s not ideal, but some teams choose to do it.\"More sophisticated implementations maintain provider-specific prompts for the same application. \"When traffic shifts from one model to another, the prompt shifts with it,\" Bajaj said. \"In that case, failover is not just switching models. It is switching to a configuration that has already been tested.\"TrueFailover automates this process. The system dynamically routes requests and adjusts prompts based on which model handles the query, keeping quality within acceptable ranges without manual intervention. The key, Bajaj emphasized, is that \"failover is planned, not reactive. The logic, prompts, and guardrails are defined ahead of time, which is why end users typically do not notice when a switch happens.\"Importantly, many failover scenarios do not require changing providers at all. \"It can be routing traffic from the same model in one region to another region, such as from the East Coast to the West Coast, where no prompt changes are required,\" Bajaj noted. This geographic flexibility provides a first line of defense before more complex cross-provider switches become necessary.How regulated industries can use AI failover without compromising complianceFor enterprises in healthcare, financial services, and other regulated sectors, the prospect of AI traffic automatically routing to different providers raises immediate compliance concerns. Patient data cannot simply flow to whichever model happens to be available. Financial records require strict controls over where they travel. TrueFoundry built explicit guardrails to address these constraints.\"TrueFailover will never route data to a model or provider that an enterprise has not explicitly approved,\" Bajaj said. \"Everything is controlled through an admin configuration layer where teams set clear guardrails upfront.\"Enterprises define exactly which models qualify for failover, which providers can receive traffic, and even which regions or model categories — such as closed-source versus open-source — are acceptable. Once those rules take effect, TrueFailover operates only within them.\"If a model is not on the approved list, it is simply not an option for routing,\" Bajaj emphasized. \"There is no scenario where traffic is automatically sent somewhere unexpected. The idea is to give teams full control over compliance and data boundaries, while still allowing the system to respond quickly when something goes wrong. That way, reliability improves without compromising security or regulatory requirements.\"This design reflects lessons learned from TrueFoundry&#x27;s existing enterprise deployments. A Fortune 50 healthcare company already uses the platform to handle more than 500 million IVR calls annually through an agentic AI system. That customer required the ability to run workloads across both cloud and on-premise infrastructure while maintaining strict data residency controls — exactly the kind of hybrid environment where failover policies must be precisely defined.Where automatic failover cannot help and what enterprises must plan forTrueFoundry acknowledges that TrueFailover cannot solve every reliability problem. The system operates within the guardrails enterprises configure, and those configurations determine what protection is possible.\"If a team allows failover from a large, high-capacity model to a much smaller model without adjusting prompts or expectations, TrueFailover cannot guarantee the same output quality,\" Bajaj explained. \"The system can route traffic, but it cannot make a smaller model behave like a larger one without appropriate configuration.\"Infrastructure constraints also limit protection. If an enterprise hosts its own models and all of them run on the same GPU cluster, TrueFailover cannot help when that infrastructure fails. \"When there is no alternate infrastructure available, there is nothing to fail over to,\" Bajaj said.The question of simultaneous multi-provider failures occasionally surfaces in enterprise risk discussions. Bajaj argues this scenario, while theoretically possible, rarely matches reality. \"In practice, &#x27;going down&#x27; usually does not mean an entire provider is offline across all models and regions,\" he explained. \"What happens far more often is a slowdown or disruption in a specific model or region because of traffic spikes or capacity issues.\"When that occurs, failover can happen at multiple levels — from on-premise to cloud, cloud to on-premise, one region to another, one model to another, or even within the same provider before switching providers entirely. \"That alone makes it very unlikely that everything fails at once,\" Bajaj said. \"The key point is that reliability is built on layers of redundancy. The more providers, regions, and models that are included in the guardrails, the smaller the chance that users experience a complete outage.\"A startup that built its platform inside Fortune 500 AI deploymentsTrueFoundry has established itself as infrastructure for some of the world&#x27;s largest AI deployments, providing crucial context for its failover ambitions. The company raised $19 million in Series A funding in February 2025, led by Intel Capital with participation from Eniac Ventures, Peak XV Partners, and Jump Capital. Angel investors including Gokul Rajaram and Mohit Aron also joined the round, bringing total funding to $21 million.The San Francisco-based company was founded in 2021 by Bajaj and co-founders Abhishek Choudhary and Anuraag Gutgutia, all former Meta engineers who met as classmates at IIT Kharagpur. Initially focused on accelerating machine learning deployments, TrueFoundry pivoted to support generative AI capabilities as the technology went mainstream in 2023.The company&#x27;s customer roster demonstrates enterprise-scale adoption that few AI infrastructure startups can match. Nvidia employs TrueFoundry to build multi-agent systems that optimize GPU cluster utilization across data centers worldwide — a use case where even small improvements in utilization translate into substantial business impact given the insatiable demand for GPU capacity. Adopt AI routes more than 15 million requests and 40 billion input tokens through TrueFoundry&#x27;s AI Gateway to power its enterprise agentic workflows.Gaming company Games 24x7 serves machine learning models to more than 100 million users through the platform at scales exceeding 200 requests per second. Digital adoption platform Whatfix migrated to a microservices architecture on TrueFoundry, reducing its release cycle sixfold and cutting testing time by 40 percent.TrueFoundry currently reports more than 30 paid customers worldwide and has indicated it exceeded $1.5 million in annual recurring revenue last year while quadrupling its customer base. The company manages more than 1,000 clusters for machine learning workloads across its client base.TrueFailover will be offered as an add-on module on top of the existing TrueFoundry AI Gateway and platform, with pricing following a usage-based model tied to traffic volume along with the number of users, models, providers, and regions involved. An early access program for design partners opens in the coming weeks.Why traditional cloud uptime guarantees may never apply to AI providersEnterprise technology buyers have long demanded uptime commitments from infrastructure providers. Amazon Web Services, Microsoft Azure, and Google Cloud all offer service-level agreements with financial penalties for failures. Will AI providers eventually face similar expectations?Bajaj sees fundamental constraints that make traditional SLAs difficult to achieve in the current generation of AI infrastructure. \"Most foundational LLMs today operate as shared resources, which is what enables the standard pricing you see publicly advertised,\" he explained. \"Providers do offer higher uptime commitments, but that usually means dedicated capacity or reserved infrastructure, and the cost increases significantly.\"Even with substantial budgets, enterprises face usage quotas that create unexpected exposure. \"If traffic spikes beyond those limits, requests can still spill back into shared infrastructure,\" Bajaj said. \"That makes it hard to achieve the kind of hard guarantees enterprises are used to with cloud providers.\"The economics of running large language models create additional barriers that may persist for years. \"LLMs are still extremely complex and expensive to run. They require massive infrastructure and energy, and we do not expect a near-term future where most companies run multiple, fully dedicated model instances just to guarantee uptime.\"This reality drives demand for solutions like TrueFailover that provide resilience regardless of what individual providers can promise. \"Enterprises are realizing that reliability cannot come from the model provider alone,\" Bajaj said. \"It requires additional layers of protection to handle the realities of how these systems operate today.\"The new calculus for companies that built AI into critical business processesThe timing of TrueFoundry&#x27;s announcement reflects a fundamental shift in how enterprises use AI — and what they stand to lose when it fails. What began as internal experimentation has evolved into customer-facing applications where disruptions directly affect revenue and reputation.\"Many enterprises experimented with Gen AI and agentic systems in the past, and production use cases were largely internal-facing,\" Bajaj observed. \"There was no immediate impact on their top line or the public perception of the enterprise.\"That era has ended. \"Now that these enterprises have launched public-facing applications, where both the top line and public perception can be impacted if an outage occurs, the stakes are much higher than they were even six months ago. That&#x27;s why we are seeing more and more attention on this now.\"For companies that have woven AI into critical business processes — from prescription refills to customer support to sales operations — the calculus has changed entirely. The question is no longer which model performs best on benchmarks or which provider offers the most compelling features. The question that now keeps technology leaders awake is far simpler and far more urgent: what happens when the AI disappears at the worst possible moment?Somewhere, a pharmacist is filling a prescription. A customer support agent is resolving a complaint. A sales team is generating a proposal for a deal that closes tomorrow. All of them depend on AI systems that depend on providers that, despite their scale and sophistication, still go dark without warning.TrueFoundry is betting that enterprises will pay handsomely to ensure those moments of darkness never reach the people who matter most — their customers.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6RXfga7DhprWJByZbNoNyJ/54c08868d8100860ecfb2ea2d9ddd918/nuneybits_Vector_art_of_highway_interchange_at_night_one_road_c_0553d47b-482b-4521-9f16-54b3a908db80.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/what-to-expect-at-samsung-galaxy-unpacked-2026-130000003.html",
          "published_at": "Wed, 21 Jan 2026 13:00:00 +0000",
          "title": "What to expect at Samsung Galaxy Unpacked 2026",
          "standfirst": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company is expected to host its first Galaxy Unpacked of the year in February to introduce the Galaxy S26 lineup.Engadget will be covering Galaxy Unpacked live, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for an official invite, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025 One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. Considering the company had the new device available for hands-on demos at CES 2026, it seems possible it could share more information about when the Galaxy Z TriFold will be widely available at Galaxy Unpacked.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/what-to-expect-at-samsung-galaxy-unpacked-2026-130000003.html?src=rss",
          "content": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company is expected to host its first Galaxy Unpacked of the year in February to introduce the Galaxy S26 lineup.Engadget will be covering Galaxy Unpacked live, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for an official invite, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025 One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. Considering the company had the new device available for hands-on demos at CES 2026, it seems possible it could share more information about when the Galaxy Z TriFold will be widely available at Galaxy Unpacked.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/what-to-expect-at-samsung-galaxy-unpacked-2026-130000003.html?src=rss",
          "feed_position": 19,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-01/59db82d0-d8d0-11ef-babd-deb856accfc5"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/how-to-check-if-your-vpn-is-working-130000817.html",
          "published_at": "Wed, 21 Jan 2026 13:00:00 +0000",
          "title": "How to check if your VPN is working",
          "standfirst": "One of the disconcerting things about using a virtual private network (VPN) is that it can be hard to tell when it's doing its job. The best VPNs all work in the background to keep your IP address hidden and your communications with their servers encrypted. The better the VPN, the less you notice it, which can make a top-performing VPN feel (uncomfortably) like one that isn't working at all.Luckily, you've got options for checking whether your VPN is working — other than just taking the app at its word. In this article, I'll cover the basics, then go through five different tests you can run to make sure you're actually using an encrypted VPN server. For each test, I'll explain what kind of problem it's looking for, how to run it and what to do in case it fails.Make sure your VPN is turned onBefore you do anything else, though, it's not a bad idea to check your VPN app and make sure you remembered to connect. It's all too easy to open up the client app, choose a server, tweak some preferences and feel like your work is done. On top of that, we don't always remember to tell VPN beginners that simply opening the client isn't enough.To check that your VPN is turned on, open the app on your desktop or mobile home screen. Each VPN designs its apps differently, but common signs include the color green, the word Connected and information on what server location you're connected to.The main UI for Proton VPN, with the connection button visible at top-left and the server location menu below it.Sam Chapman for EngadgetIf you don't see anything like that, click the On button, which should be on the first page that appears when you log into the app. Most VPNs also connect whenever you click the name of a server location.For those of you on iPhone or iPad, I've just written an explainer on how to turn a VPN off and on. For all the tests I'll discuss across the rest of this article, make sure you're connected to a VPN server before you run them. Also, make sure your internet connection is active — a VPN can only work when there's internet.5 tests to check if your VPN worksEach of these tests investigates a different reason your VPN might not be working. We'll start by looking for connection problems that might not be obvious, check for DNS leaks, WebRTC leaks and IPv6 leaks, then finally make sure an apparently active VPN is managing to change your virtual location.1. Has your IP address changed?Websites and internet service providers (ISPs) use IP addresses to identify devices and their owners online. A VPN's most important job is to change your IP address to one matching its own server, which disassociates your identity from your online activities. Not doing this indicates a failure on a fundamental level: either the VPN says it's connected when it isn't, or its technology is active but somehow not sending you through the proper encrypted tunnel.To check whether your VPN has changed your IP address, start by going to an IP address checker like whatismyipaddress.com or ipleak.net. This will show you the public IP address that everyone sees when you get online without a VPN, including the ISP that holds it and the geographic location it's associated with. Write that down or take a screenshot.A censored report from WhatIsMyIPAddress.com.Sam Chapman for EngadgetNext, connect to your VPN. Remember the location you connect to, and note down the new server IP address if the VPN tells you what it is. Go back to your IP tester tool and refresh the page. You should now see an IP address and location that match the one you connected to through the VPN, including a different ISP.If your IP address is the same as before, your VPN isn't working. To fix this, try disconnecting from the server, waiting about 10 seconds, then connecting to the same location and trying the test again. This will show you whether the problem was with one individual server or an entire location.If the problem persists, try a different server location, then a different VPN protocol. If it's still leaking, try restarting your VPN client, your device and your modem (in that order). This should fix the problem, but if it doesn't, move on to the remaining tests or get in touch with the VPN's tech support.2. Are you leaking DNS requests?A domain name system (DNS) server is an important step in getting a website to appear on your browser. DNS holds the information that connects URLs to the IP addresses of destination servers. If a VPN client lets your device contact a DNS server owned by your internet service provider without routing it through an encrypted tunnel first, the DNS request might reveal your real IP address to the ISP.You can check for DNS leaks by connecting to your VPN, then going to dnsleaktest.com or another tool of your choice. The tester sends several innocuous DNS requests, then scans to see which servers resolve them. If you see your real ISP at all, you've got DNS leaks.A DNS leak test run without a VPN. With one active, my real ISP (Comcast) should not appear on the list.Sam Chapman for EngadgetThe fix for DNS leaks is more intensive than the fixes in step #1. Check your VPN's control panel to activate any DNS leak protections and try again. IPv6 leaks can also appear as DNS leaks, so try disabling IPv6 in your browser (see #4 below for instructions). If you keep seeing leaks, you can also try clearing your computer's DNS cache.Here's how to do that. On Windows, go to the Command Prompt (on Windows 10) or the Windows Terminal (on Windows 11). Enter the phrase ipconfig/flushdns. On Mac, open Terminal from the Utilities folder, then paste in the phrase sudo dscacheutil -flushcache; sudo killall -HUP mDNSResponder and hit Enter. Test the VPN once more to see if it's still leaking.3. Are you leaking information through WebRTC?WebRTC, which stands for Web Real-Time Communication, is a technology that lets browsers exchange information directly with each other. This is useful for text and video chats, streaming and more, but it's also a potential security risk. WebRTC can serve as a backchannel that inadvertently sends your real IP address outside the VPN tunnel.It's pretty easy to test for WebRTC leaks. I recommend the tool ipleak.net, which checks for them as a matter of course. You can also use browserleaks.com/webrtc to run a test that's particular to this kind of leak. These tools establish dummy connections through WebRTC, then test to see if the VPN still works when they're active. As usual, if you see your real IP address, there's a problem.Your WebRTC IP not matching your Remote IP is a potential red flag.Sam Chapman for EngadgetThe fixes for a WebRTC leak are the usual ones: try different servers, locations and protocols, reset your VPN, device and modem, then try another VPN provider. However, if nothing is working, you can also disable WebRTC on your browser altogether. This means you won't be able to do any real-time chatting (that's Zoom, Google Meet, Teams and so on), so it's a last-resort solution.To disable WebRTC on Firefox, type about:config in the URL bar, click the message to accept the risk, type media.peerconnection.enabled in the search bar, then double-click the word True to change it to False. To turn WebRTC back on, just double-click False again.On Edge, you can disable WebRTC by entering edge://flags in the URL bar, scrolling down to the option \"Anonymize local IPs exposed by WebRTC\" and making sure the dropdown next to it is set to Enable. There's no built-in way to turn off WebRTC on Chrome, but you can install the WebRTC Control extension to switch it off and on yourself.4. Is your IPv6 address leaking?Next up, it's possible that your real location is leaking through your IPv6 address, not IPv4. To make a long explanation short, IPv6 is a new way of formatting IP addresses that leaves more options available for the future. Since we haven't yet hit the crisis point of IPv4 shortage, very few websites are restricted to IPv6 alone.The problem is that most VPN apps were designed in the IPv4 era and aren't built to protect IPv6 traffic. There are some exceptions, including NordVPN, but most VPNs block IPv6 traffic completely rather than retrofit themselves to work with it. However, if a VPN of that sort isn't blocking IPv6 entirely, your IPv6 address and associated location can leak.Any IP address checker can reveal an IPv6 leak, but you can find a specific test at test-ipv6.com. This site runs several exams that look for IPv6 readiness, but the most important line is the one that shows your current IPv6 address. This will probably say you don't have one, since most ISPs don't work through IPv6 yet — but if you do have one, it should match your active VPN's location, not your real one.If your IPv4 address matches the VPN server but your IPv6 address does not, IPv6 is the likely cause of your leak.Sam Chapman for EngadgetShould it turn out that you're leaking IPv6 requests, the easiest solution is to disable IPv6 on your computer. On Windows, you can do this through the network adapter options page of your control panel. Here's how to get there:Windows 10: Start -> Settings -> Network & internet -> Status -> Change -> Advanced network settings -> Change adapter options.Windows 11: Settings app -> Network & internet -> Advanced network settings -> Related settings -> More network adapter options.On both OSes, finish the job by right-clicking the name of your internet connection, selecting Properties from the dropdown and unchecking the box next to Internet Protocol Version 6. Of course, you can always switch to another VPN that blocks IPv6 altogether, but you might find that to be a bigger hassle.If you're on Mac, open System Settings, click the Network tab and then click the Details... button next to your network name. In the new window, click the TCP/IP tab on the left, find the entry labeled Configure IPv6 and set the dropdown to Link-Local Only.5. Do streaming sites show different content?A VPN can be working perfectly and still fail to unblock streaming sites. Netflix, HBO Max and the others block VPN traffic because VPNs can make them show material in regions where they don't hold the copyright. To avoid legal trouble, they set up their firewalls to block IP addresses known to belong to VPN servers.If your VPN can't get into a streaming platform, it'll usually be obvious; the site will either display a proxy error message or simply refuse to load. However, in rare cases, the streaming site will load fine but show you the same shows you normally see. This indicates that you might be dealing with a VPN leak.If that happens, follow the usual steps. Disconnect and reconnect to the same location to get a different server, then try different server locations. It's also possible that the streaming site is getting your real location from your browser cache, so if the problem persists, clear your cache and cookies and try again.How to test a VPN kill switchThere's one more important step to make sure your VPN is working: test the kill switch. This common feature cuts off your internet connection if you lose touch with your VPN server. With your kill switch active, you shouldn't be at any risk of accidentally broadcasting your real IP address, location or online activity.To test your kill switch, you'll need to simulate an abrupt loss of VPN connectivity. Open your VPN, make sure the kill switch is turned on, then connect to a server. Next, quit the VPN app without disconnecting. At this point, the kill switch should make it impossible for you to get online — if you can still browse the internet as normal, the switch might be faulty.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-check-if-your-vpn-is-working-130000817.html?src=rss",
          "content": "One of the disconcerting things about using a virtual private network (VPN) is that it can be hard to tell when it's doing its job. The best VPNs all work in the background to keep your IP address hidden and your communications with their servers encrypted. The better the VPN, the less you notice it, which can make a top-performing VPN feel (uncomfortably) like one that isn't working at all.Luckily, you've got options for checking whether your VPN is working — other than just taking the app at its word. In this article, I'll cover the basics, then go through five different tests you can run to make sure you're actually using an encrypted VPN server. For each test, I'll explain what kind of problem it's looking for, how to run it and what to do in case it fails.Make sure your VPN is turned onBefore you do anything else, though, it's not a bad idea to check your VPN app and make sure you remembered to connect. It's all too easy to open up the client app, choose a server, tweak some preferences and feel like your work is done. On top of that, we don't always remember to tell VPN beginners that simply opening the client isn't enough.To check that your VPN is turned on, open the app on your desktop or mobile home screen. Each VPN designs its apps differently, but common signs include the color green, the word Connected and information on what server location you're connected to.The main UI for Proton VPN, with the connection button visible at top-left and the server location menu below it.Sam Chapman for EngadgetIf you don't see anything like that, click the On button, which should be on the first page that appears when you log into the app. Most VPNs also connect whenever you click the name of a server location.For those of you on iPhone or iPad, I've just written an explainer on how to turn a VPN off and on. For all the tests I'll discuss across the rest of this article, make sure you're connected to a VPN server before you run them. Also, make sure your internet connection is active — a VPN can only work when there's internet.5 tests to check if your VPN worksEach of these tests investigates a different reason your VPN might not be working. We'll start by looking for connection problems that might not be obvious, check for DNS leaks, WebRTC leaks and IPv6 leaks, then finally make sure an apparently active VPN is managing to change your virtual location.1. Has your IP address changed?Websites and internet service providers (ISPs) use IP addresses to identify devices and their owners online. A VPN's most important job is to change your IP address to one matching its own server, which disassociates your identity from your online activities. Not doing this indicates a failure on a fundamental level: either the VPN says it's connected when it isn't, or its technology is active but somehow not sending you through the proper encrypted tunnel.To check whether your VPN has changed your IP address, start by going to an IP address checker like whatismyipaddress.com or ipleak.net. This will show you the public IP address that everyone sees when you get online without a VPN, including the ISP that holds it and the geographic location it's associated with. Write that down or take a screenshot.A censored report from WhatIsMyIPAddress.com.Sam Chapman for EngadgetNext, connect to your VPN. Remember the location you connect to, and note down the new server IP address if the VPN tells you what it is. Go back to your IP tester tool and refresh the page. You should now see an IP address and location that match the one you connected to through the VPN, including a different ISP.If your IP address is the same as before, your VPN isn't working. To fix this, try disconnecting from the server, waiting about 10 seconds, then connecting to the same location and trying the test again. This will show you whether the problem was with one individual server or an entire location.If the problem persists, try a different server location, then a different VPN protocol. If it's still leaking, try restarting your VPN client, your device and your modem (in that order). This should fix the problem, but if it doesn't, move on to the remaining tests or get in touch with the VPN's tech support.2. Are you leaking DNS requests?A domain name system (DNS) server is an important step in getting a website to appear on your browser. DNS holds the information that connects URLs to the IP addresses of destination servers. If a VPN client lets your device contact a DNS server owned by your internet service provider without routing it through an encrypted tunnel first, the DNS request might reveal your real IP address to the ISP.You can check for DNS leaks by connecting to your VPN, then going to dnsleaktest.com or another tool of your choice. The tester sends several innocuous DNS requests, then scans to see which servers resolve them. If you see your real ISP at all, you've got DNS leaks.A DNS leak test run without a VPN. With one active, my real ISP (Comcast) should not appear on the list.Sam Chapman for EngadgetThe fix for DNS leaks is more intensive than the fixes in step #1. Check your VPN's control panel to activate any DNS leak protections and try again. IPv6 leaks can also appear as DNS leaks, so try disabling IPv6 in your browser (see #4 below for instructions). If you keep seeing leaks, you can also try clearing your computer's DNS cache.Here's how to do that. On Windows, go to the Command Prompt (on Windows 10) or the Windows Terminal (on Windows 11). Enter the phrase ipconfig/flushdns. On Mac, open Terminal from the Utilities folder, then paste in the phrase sudo dscacheutil -flushcache; sudo killall -HUP mDNSResponder and hit Enter. Test the VPN once more to see if it's still leaking.3. Are you leaking information through WebRTC?WebRTC, which stands for Web Real-Time Communication, is a technology that lets browsers exchange information directly with each other. This is useful for text and video chats, streaming and more, but it's also a potential security risk. WebRTC can serve as a backchannel that inadvertently sends your real IP address outside the VPN tunnel.It's pretty easy to test for WebRTC leaks. I recommend the tool ipleak.net, which checks for them as a matter of course. You can also use browserleaks.com/webrtc to run a test that's particular to this kind of leak. These tools establish dummy connections through WebRTC, then test to see if the VPN still works when they're active. As usual, if you see your real IP address, there's a problem.Your WebRTC IP not matching your Remote IP is a potential red flag.Sam Chapman for EngadgetThe fixes for a WebRTC leak are the usual ones: try different servers, locations and protocols, reset your VPN, device and modem, then try another VPN provider. However, if nothing is working, you can also disable WebRTC on your browser altogether. This means you won't be able to do any real-time chatting (that's Zoom, Google Meet, Teams and so on), so it's a last-resort solution.To disable WebRTC on Firefox, type about:config in the URL bar, click the message to accept the risk, type media.peerconnection.enabled in the search bar, then double-click the word True to change it to False. To turn WebRTC back on, just double-click False again.On Edge, you can disable WebRTC by entering edge://flags in the URL bar, scrolling down to the option \"Anonymize local IPs exposed by WebRTC\" and making sure the dropdown next to it is set to Enable. There's no built-in way to turn off WebRTC on Chrome, but you can install the WebRTC Control extension to switch it off and on yourself.4. Is your IPv6 address leaking?Next up, it's possible that your real location is leaking through your IPv6 address, not IPv4. To make a long explanation short, IPv6 is a new way of formatting IP addresses that leaves more options available for the future. Since we haven't yet hit the crisis point of IPv4 shortage, very few websites are restricted to IPv6 alone.The problem is that most VPN apps were designed in the IPv4 era and aren't built to protect IPv6 traffic. There are some exceptions, including NordVPN, but most VPNs block IPv6 traffic completely rather than retrofit themselves to work with it. However, if a VPN of that sort isn't blocking IPv6 entirely, your IPv6 address and associated location can leak.Any IP address checker can reveal an IPv6 leak, but you can find a specific test at test-ipv6.com. This site runs several exams that look for IPv6 readiness, but the most important line is the one that shows your current IPv6 address. This will probably say you don't have one, since most ISPs don't work through IPv6 yet — but if you do have one, it should match your active VPN's location, not your real one.If your IPv4 address matches the VPN server but your IPv6 address does not, IPv6 is the likely cause of your leak.Sam Chapman for EngadgetShould it turn out that you're leaking IPv6 requests, the easiest solution is to disable IPv6 on your computer. On Windows, you can do this through the network adapter options page of your control panel. Here's how to get there:Windows 10: Start -> Settings -> Network & internet -> Status -> Change -> Advanced network settings -> Change adapter options.Windows 11: Settings app -> Network & internet -> Advanced network settings -> Related settings -> More network adapter options.On both OSes, finish the job by right-clicking the name of your internet connection, selecting Properties from the dropdown and unchecking the box next to Internet Protocol Version 6. Of course, you can always switch to another VPN that blocks IPv6 altogether, but you might find that to be a bigger hassle.If you're on Mac, open System Settings, click the Network tab and then click the Details... button next to your network name. In the new window, click the TCP/IP tab on the left, find the entry labeled Configure IPv6 and set the dropdown to Link-Local Only.5. Do streaming sites show different content?A VPN can be working perfectly and still fail to unblock streaming sites. Netflix, HBO Max and the others block VPN traffic because VPNs can make them show material in regions where they don't hold the copyright. To avoid legal trouble, they set up their firewalls to block IP addresses known to belong to VPN servers.If your VPN can't get into a streaming platform, it'll usually be obvious; the site will either display a proxy error message or simply refuse to load. However, in rare cases, the streaming site will load fine but show you the same shows you normally see. This indicates that you might be dealing with a VPN leak.If that happens, follow the usual steps. Disconnect and reconnect to the same location to get a different server, then try different server locations. It's also possible that the streaming site is getting your real location from your browser cache, so if the problem persists, clear your cache and cookies and try again.How to test a VPN kill switchThere's one more important step to make sure your VPN is working: test the kill switch. This common feature cuts off your internet connection if you lose touch with your VPN server. With your kill switch active, you shouldn't be at any risk of accidentally broadcasting your real IP address, location or online activity.To test your kill switch, you'll need to simulate an abrupt loss of VPN connectivity. Open your VPN, make sure the kill switch is turned on, then connect to a server. Next, quit the VPN app without disconnecting. At this point, the kill switch should make it impossible for you to get online — if you can still browse the internet as normal, the switch might be faulty.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-check-if-your-vpn-is-working-130000817.html?src=rss",
          "feed_position": 20,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Proton_VPN_Mac_interface.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/best-robot-vacuums-130010426.html",
          "published_at": "Wed, 21 Jan 2026 10:02:26 +0000",
          "title": "The best robot vacuum for 2026",
          "standfirst": "Looking to keep your home clean without having to vacuum and mop every day, pick up dirt, the dinner your child threw on the floor or your furry friend’s endless pet hair? Join the club. Smart home gadgets have come a long way over the years, and that includes robot vacuums. With newer technology including voice controls, object detection and more automation features, investing in a robot vacuum cleaner makes more sense now than ever before. Some of the best robot vacuum cleaners even have mopping capabilities, roller brush options and self-emptying bases, too, and there are plenty that don't cost a fortune either. If you’re ready to adopt a less hands-on approach and let a robot vacuum cleaner do the hard work for you, consider our recommendations below. Best robot vacuums 2026 Latest robot vacuum news CES is typically a time for robovac manufacturers to unveil new innovations and this year was no different. Companies like Eufy announced new models, many of which are on the higher end of the price spectrum. Those flagship announcements are often paired with more minor ones that usher in mildly upgraded versions of midrange and entry-level machines. Now that robot vacuums are ubiquitous, the new models that make headlines tend to have some sort of gimmick like a built-in arm for picking up clothes, or offer (supposedly) top-tier suction power and a slew of extras. They also tend to be super expensive. However, most people will be served just fine with a robot vacuum that doesn’t choke at the first sign of dust bunnies or pet hair, and maybe has mopping capabilities if you want a machine that can tackle hard floors in addition to carpet. Those other innovations are nice-to-haves, not necessities. Arguably even bigger than CES announcements is the fact that iRobot, a name synonymous with smart cleaning robots, filed for Chapter 11 bankruptcy at the end of 2025. What does that mean for Roomba owners? Not too much immediately, as the company stated that it will continue to operate with “no anticipated disruption to its app functionality, customer programs, global partners, supply chain relationships or ongoing product support.\" However, this also means that buying a new Roomba in 2026 is a questionable decision. What to look for in the best robot vacuums TLDR Despite companies coming out with gimmicky extras and new software perks in their robot vacuum lineups, the core competency of these devices have remained the same for years: sucking up dirt without needing your attention. You want a robot vacuum with the strongest suction power you can afford. Those with tile and hardwood floors can consider robovacs with mopping capabilities, and those who want peak convenience should opt for a model with a self-emptying base. However, both of those extra features will cost extra. Floor type First and foremost, we recommend considering the floors in your home: Do you have carpet throughout, or tile and hardwood floors, or a mix? Robots with stronger suction power will do a better job picking up dirt on carpets as they can get into high piles more easily. Some machines have “max” modes as well, which ups suction power, but also typically eats battery life faster than the “normal” floor cleaning mode. Vacuum suction Suction power is an important factor to consider. Unfortunately, there isn’t a standard power scale that all robovacs adhere to, so it’s difficult to compare among a bunch of devices. Some companies provide Pascal (Pa) levels and generally the higher the Pa, the stronger the vacuum cleaner will be. But other companies don’t rely on Pa and simply say their robots have X-times more suction than other robots. If you’re looking for the best vacuum for your needs, it’s helpful to pay attention to real-world testing and how well the machine can pick up fine dust, crumbs and pet hair in an environment similar to that of your home. Wi-Fi connectivity Wi-Fi connectivity is a key feature for most robot vacuums. Some of the affordable devices aren’t Wi-Fi connected, so it’s best to double check before you buy something on the low end of affordable. Wi-Fi lets a robot vacuum cleaner do things like communicate with a mobile app, which then allows you to control the device from your phone. Mapping features and object detection Past a certain price threshold, you’ll find advanced perks like home mapping features and improved object detection. Home mapping is exactly what it sounds like: The vacuum uses sensors to map your home’s layout as it cleans, allowing you to send it to particular rooms or avoid no-go zones where you don’t want it to roam. Most robo-vacs have object detection, but some will be better than others at actually avoiding things like chair legs and children’s toys. High-end models even go so far as to promise obstacle avoidance to steer clear of things like pet poop that can potentially ruin your machine. Mopping capabilities Mopping features are much more common now in robot vacuums than they were just five years ago. Machines that support this will have a water tank either built into the robot’s chassis, the auto-empty bin or as a separate piece that you swap in for the dustbin when you want to mop your floors. It makes the robo-vac more useful if you have hard floors in your home that you like to keep squeaky clean, but it does require more work on your part. Filling and emptying the reservoir remains a human’s job for the most part (except on the most expensive machines), as does adding cleaning solutions if the mopping robot comes with this feature to ensure it uses clean water for every cycle. Self-empty station inclusion Finally, for peak convenience, consider a robot vacuum that comes with a self-empty station. These are basically garbage bins attached to the machine’s docking station. At the end of each job, the robo-vac automatically empties its small dustbin into the large clean base – that means you won’t have to empty the dustbin yourself and you’ll only have to tend to the base once every few weeks. Just keep in mind that many self-emptying bins require proprietary garbage bags – another long-term expense you’ll have to factor in (look for mentions of “bagless” to avoid this all together). Also, any vac-and-mop robot with a water tank will not dump its dirty water into the clean base, so you’ll still have to clean up that yourself. Robot vacuum maintenance tips First and foremost, always empty your robot vacuum’s dustbin after every cleaning job. If you have a model with a self-emptying base, there’s less work for you to do yourself. If not, simply detach and empty the dustbin as soon as the robot is done cleaning. It’s also a good idea to take a dry cloth to the inside of the dustbin every once in a while to remove any small dust and dirt particles clinging to the insides. In addition, you’ll want to regularly examine the machine’s brush roll to see if any hair has wrapped around them, or if any large debris is preventing them from working properly. Some brushes are better than others at not succumbing to tangled hair, but it’s a good idea to check your robot’s brushes regardless — both their main brush and any smaller roller brushes or corner brushes they have. These parts are often easy to pop off of the machine (because they do require replacements eventually) so we recommend removing each brush entirely, getting rid of any tangled hair or other debris attached to them and reinstalling them afterwards. Robot vacuums also have filters that need replacing every couple of months. Check your machine’s user manual or the manufacturer’s website to see how long they recommend going in between filter replacements. Most of the time, these filters cannot be washed, so you will need to buy new ones either directly from the manufacturer or from other retailers like Amazon or Walmart. How we test robot vacuums We primarily test robot vacuums by using them as they are intended to be used: in a home, across different types of flooring and in the face of all sorts of messes including pet hair, spilt coffee grounds and other food debris, dust bunnies, stairs (gasp) and more. We set up all robot vacuums according to their provided instructions and run multiple cleaning jobs during a testing period of at least one to two weeks per machine. If the robot has mopping capabilities, we also test those as well on hardwood and tile flooring. For models with self-emptying bases, we rely on those built-in trash cans for all post-job cleaning, and we make sure to test the robot vacuum's mobile app for usability and convenience. As we're testing, we make note of things like how loud the robot and its components are, how much human attention the robot needs on a regular basis, how the robot handles large messes and big dust bunnies, if the robot gets stuck on rugs, doormats or other furniture and more. Robot vacuum FAQs Are robot vacuums worth it? We tackled this question when we reviewed budget robot vacuums and the answer is yes, especially if vacuuming is one of your least favorite chores. Robots take the hard work out of cleaning your floors – just turn the thing on and watch it go. Any robot vacuum cleaner worth buying is semi-autonomous in that it will suck up dirt around your home until its battery is low and then make its way back to its charging dock. Unlike a regular vacuum, you should only have to interact with it to turn it on, empty its dustbin and untangle it if it were to get stuck somewhere. That’s not to say robot vacuums are perfect. They’re almost always less powerful and less flexible than traditional vacuums. Since most robo-vacs are much smaller than traditional models, they often don’t have the same level of suction you’ll get in an upright machine. Plus, their dustbins are smaller, so they will need to be emptied more frequently. While Wi-Fi-connected robot vacuums give you the flexibility to start a cleaning job from anywhere using an app, targeting a small area of your home can be more complicated. Some robo-vacs have spot-cleaning features that focus the machine’s attention on a specific area, which almost – but not quite – mimics the spot-cleaning you’d be able to do yourself with a regular or cordless vacuum. How long do robot vacuums last? Robot vacuums can last many years, if you take care of them properly. Check out our recommendations for robot vacuum maintenance above, but in a nutshell, you should make sure that you're emptying the machine's bin after every job and periodically cleaning the interior of the bin and the brushes. It's also a good idea to check the user manual to see how often your robot vacuum's filter needs changing. Do robot vacuums work better than handheld vacuums? There's no straight answer to this question. Robot vacuums offer more convenience than handheld vacuums, so for those who are looking to automate a chore, that could mean one of these devices works better for them than a standard vacuum. However, handheld vacuum cleaners often have stronger suction power, and they give the user a bit more control. It ultimately depends on how you intend to use your main vacuum cleaner and what you want to prioritize most. How often do you have to clean a robot vacuum? Cleaning a robot vacuum isn’t too much of a chore, but you’ll want to give it a little TLC every few weeks or so, depending on how often you’re running it and how much dirt it’s picking up. The dustbin usually needs to be emptied after each cleaning run, especially if you have pets or lots of carpet where dirt can hide. Many newer models have self-emptying docks, which means you won’t have to empty the dustbin yourself after every use, but the main bin will still need a good clean once a month or so. Also, it’s a good idea to check the side brushes and main brush for any hair tangles or debris every couple of weeks to keep things running smoothly. What are the negatives of robot vacuums? Robot vacuums won’t work for everyone. One of the biggest drawbacks is that they usually don’t have the same suction power as a full-sized upright vacuum or even a cordless stick vacuum, so they might struggle with deep-cleaning thick carpets. They’re also designed for floors only, so if you’re looking to clean furniture, stairs or other tricky spots, you’ll still need a traditional vacuum to do that. Plus, they can sometimes get stuck or miss spots, especially if you’ve got a lot of furniture or obstacles in the way. While their sensors help, they might still bump into things or need a little help getting out of tight spots. And while most have decent dirt detection features, they’re best for keeping things tidy rather than doing heavy-duty cleaning. Check out more from our spring cleaning guide.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-robot-vacuums-130010426.html?src=rss",
          "content": "Looking to keep your home clean without having to vacuum and mop every day, pick up dirt, the dinner your child threw on the floor or your furry friend’s endless pet hair? Join the club. Smart home gadgets have come a long way over the years, and that includes robot vacuums. With newer technology including voice controls, object detection and more automation features, investing in a robot vacuum cleaner makes more sense now than ever before. Some of the best robot vacuum cleaners even have mopping capabilities, roller brush options and self-emptying bases, too, and there are plenty that don't cost a fortune either. If you’re ready to adopt a less hands-on approach and let a robot vacuum cleaner do the hard work for you, consider our recommendations below. Best robot vacuums 2026 Latest robot vacuum news CES is typically a time for robovac manufacturers to unveil new innovations and this year was no different. Companies like Eufy announced new models, many of which are on the higher end of the price spectrum. Those flagship announcements are often paired with more minor ones that usher in mildly upgraded versions of midrange and entry-level machines. Now that robot vacuums are ubiquitous, the new models that make headlines tend to have some sort of gimmick like a built-in arm for picking up clothes, or offer (supposedly) top-tier suction power and a slew of extras. They also tend to be super expensive. However, most people will be served just fine with a robot vacuum that doesn’t choke at the first sign of dust bunnies or pet hair, and maybe has mopping capabilities if you want a machine that can tackle hard floors in addition to carpet. Those other innovations are nice-to-haves, not necessities. Arguably even bigger than CES announcements is the fact that iRobot, a name synonymous with smart cleaning robots, filed for Chapter 11 bankruptcy at the end of 2025. What does that mean for Roomba owners? Not too much immediately, as the company stated that it will continue to operate with “no anticipated disruption to its app functionality, customer programs, global partners, supply chain relationships or ongoing product support.\" However, this also means that buying a new Roomba in 2026 is a questionable decision. What to look for in the best robot vacuums TLDR Despite companies coming out with gimmicky extras and new software perks in their robot vacuum lineups, the core competency of these devices have remained the same for years: sucking up dirt without needing your attention. You want a robot vacuum with the strongest suction power you can afford. Those with tile and hardwood floors can consider robovacs with mopping capabilities, and those who want peak convenience should opt for a model with a self-emptying base. However, both of those extra features will cost extra. Floor type First and foremost, we recommend considering the floors in your home: Do you have carpet throughout, or tile and hardwood floors, or a mix? Robots with stronger suction power will do a better job picking up dirt on carpets as they can get into high piles more easily. Some machines have “max” modes as well, which ups suction power, but also typically eats battery life faster than the “normal” floor cleaning mode. Vacuum suction Suction power is an important factor to consider. Unfortunately, there isn’t a standard power scale that all robovacs adhere to, so it’s difficult to compare among a bunch of devices. Some companies provide Pascal (Pa) levels and generally the higher the Pa, the stronger the vacuum cleaner will be. But other companies don’t rely on Pa and simply say their robots have X-times more suction than other robots. If you’re looking for the best vacuum for your needs, it’s helpful to pay attention to real-world testing and how well the machine can pick up fine dust, crumbs and pet hair in an environment similar to that of your home. Wi-Fi connectivity Wi-Fi connectivity is a key feature for most robot vacuums. Some of the affordable devices aren’t Wi-Fi connected, so it’s best to double check before you buy something on the low end of affordable. Wi-Fi lets a robot vacuum cleaner do things like communicate with a mobile app, which then allows you to control the device from your phone. Mapping features and object detection Past a certain price threshold, you’ll find advanced perks like home mapping features and improved object detection. Home mapping is exactly what it sounds like: The vacuum uses sensors to map your home’s layout as it cleans, allowing you to send it to particular rooms or avoid no-go zones where you don’t want it to roam. Most robo-vacs have object detection, but some will be better than others at actually avoiding things like chair legs and children’s toys. High-end models even go so far as to promise obstacle avoidance to steer clear of things like pet poop that can potentially ruin your machine. Mopping capabilities Mopping features are much more common now in robot vacuums than they were just five years ago. Machines that support this will have a water tank either built into the robot’s chassis, the auto-empty bin or as a separate piece that you swap in for the dustbin when you want to mop your floors. It makes the robo-vac more useful if you have hard floors in your home that you like to keep squeaky clean, but it does require more work on your part. Filling and emptying the reservoir remains a human’s job for the most part (except on the most expensive machines), as does adding cleaning solutions if the mopping robot comes with this feature to ensure it uses clean water for every cycle. Self-empty station inclusion Finally, for peak convenience, consider a robot vacuum that comes with a self-empty station. These are basically garbage bins attached to the machine’s docking station. At the end of each job, the robo-vac automatically empties its small dustbin into the large clean base – that means you won’t have to empty the dustbin yourself and you’ll only have to tend to the base once every few weeks. Just keep in mind that many self-emptying bins require proprietary garbage bags – another long-term expense you’ll have to factor in (look for mentions of “bagless” to avoid this all together). Also, any vac-and-mop robot with a water tank will not dump its dirty water into the clean base, so you’ll still have to clean up that yourself. Robot vacuum maintenance tips First and foremost, always empty your robot vacuum’s dustbin after every cleaning job. If you have a model with a self-emptying base, there’s less work for you to do yourself. If not, simply detach and empty the dustbin as soon as the robot is done cleaning. It’s also a good idea to take a dry cloth to the inside of the dustbin every once in a while to remove any small dust and dirt particles clinging to the insides. In addition, you’ll want to regularly examine the machine’s brush roll to see if any hair has wrapped around them, or if any large debris is preventing them from working properly. Some brushes are better than others at not succumbing to tangled hair, but it’s a good idea to check your robot’s brushes regardless — both their main brush and any smaller roller brushes or corner brushes they have. These parts are often easy to pop off of the machine (because they do require replacements eventually) so we recommend removing each brush entirely, getting rid of any tangled hair or other debris attached to them and reinstalling them afterwards. Robot vacuums also have filters that need replacing every couple of months. Check your machine’s user manual or the manufacturer’s website to see how long they recommend going in between filter replacements. Most of the time, these filters cannot be washed, so you will need to buy new ones either directly from the manufacturer or from other retailers like Amazon or Walmart. How we test robot vacuums We primarily test robot vacuums by using them as they are intended to be used: in a home, across different types of flooring and in the face of all sorts of messes including pet hair, spilt coffee grounds and other food debris, dust bunnies, stairs (gasp) and more. We set up all robot vacuums according to their provided instructions and run multiple cleaning jobs during a testing period of at least one to two weeks per machine. If the robot has mopping capabilities, we also test those as well on hardwood and tile flooring. For models with self-emptying bases, we rely on those built-in trash cans for all post-job cleaning, and we make sure to test the robot vacuum's mobile app for usability and convenience. As we're testing, we make note of things like how loud the robot and its components are, how much human attention the robot needs on a regular basis, how the robot handles large messes and big dust bunnies, if the robot gets stuck on rugs, doormats or other furniture and more. Robot vacuum FAQs Are robot vacuums worth it? We tackled this question when we reviewed budget robot vacuums and the answer is yes, especially if vacuuming is one of your least favorite chores. Robots take the hard work out of cleaning your floors – just turn the thing on and watch it go. Any robot vacuum cleaner worth buying is semi-autonomous in that it will suck up dirt around your home until its battery is low and then make its way back to its charging dock. Unlike a regular vacuum, you should only have to interact with it to turn it on, empty its dustbin and untangle it if it were to get stuck somewhere. That’s not to say robot vacuums are perfect. They’re almost always less powerful and less flexible than traditional vacuums. Since most robo-vacs are much smaller than traditional models, they often don’t have the same level of suction you’ll get in an upright machine. Plus, their dustbins are smaller, so they will need to be emptied more frequently. While Wi-Fi-connected robot vacuums give you the flexibility to start a cleaning job from anywhere using an app, targeting a small area of your home can be more complicated. Some robo-vacs have spot-cleaning features that focus the machine’s attention on a specific area, which almost – but not quite – mimics the spot-cleaning you’d be able to do yourself with a regular or cordless vacuum. How long do robot vacuums last? Robot vacuums can last many years, if you take care of them properly. Check out our recommendations for robot vacuum maintenance above, but in a nutshell, you should make sure that you're emptying the machine's bin after every job and periodically cleaning the interior of the bin and the brushes. It's also a good idea to check the user manual to see how often your robot vacuum's filter needs changing. Do robot vacuums work better than handheld vacuums? There's no straight answer to this question. Robot vacuums offer more convenience than handheld vacuums, so for those who are looking to automate a chore, that could mean one of these devices works better for them than a standard vacuum. However, handheld vacuum cleaners often have stronger suction power, and they give the user a bit more control. It ultimately depends on how you intend to use your main vacuum cleaner and what you want to prioritize most. How often do you have to clean a robot vacuum? Cleaning a robot vacuum isn’t too much of a chore, but you’ll want to give it a little TLC every few weeks or so, depending on how often you’re running it and how much dirt it’s picking up. The dustbin usually needs to be emptied after each cleaning run, especially if you have pets or lots of carpet where dirt can hide. Many newer models have self-emptying docks, which means you won’t have to empty the dustbin yourself after every use, but the main bin will still need a good clean once a month or so. Also, it’s a good idea to check the side brushes and main brush for any hair tangles or debris every couple of weeks to keep things running smoothly. What are the negatives of robot vacuums? Robot vacuums won’t work for everyone. One of the biggest drawbacks is that they usually don’t have the same suction power as a full-sized upright vacuum or even a cordless stick vacuum, so they might struggle with deep-cleaning thick carpets. They’re also designed for floors only, so if you’re looking to clean furniture, stairs or other tricky spots, you’ll still need a traditional vacuum to do that. Plus, they can sometimes get stuck or miss spots, especially if you’ve got a lot of furniture or obstacles in the way. While their sensors help, they might still bump into things or need a little help getting out of tight spots. And while most have decent dirt detection features, they’re best for keeping things tidy rather than doing heavy-duty cleaning. Check out more from our spring cleaning guide.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-robot-vacuums-130010426.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/mits-new-recursive-framework-lets-llms-process-10-million-tokens-without",
          "published_at": "Tue, 20 Jan 2026 20:30:00 GMT",
          "title": "MIT’s new ‘recursive’ framework lets LLMs process 10 million tokens without context rot",
          "standfirst": "Recursive language models (RLMs) are an inference technique developed by researchers at MIT CSAIL that treat long prompts as an external environment to the model. Instead of forcing the entire prompt into the model&#x27;s context window, the framework allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the text.Rather than expanding context windows or summarizing old information, the MIT team reframes long-context reasoning as a systems problem. By letting models treat prompts as something they can inspect with code, recursive language models allow LLMs to reason over millions of tokens without retraining. This offers enterprises a practical path to long-horizon tasks like codebase analysis, legal review, and multi-step reasoning that routinely break today’s models.Because the framework is designed as a wrapper around existing models, it can serve as a drop-in replacement for applications that make direct calls to LLMs.The LLM context problemWhile frontier models are becoming increasingly sophisticated at reasoning, their ability to process massive amounts of information is not scaling at the same rate. This bottleneck is driven by two distinct limitations: the hard physical constraint on how much text a model can process at once (context length) and \"context rot.\"The challenge, the researchers argue, is whether it’s possible to scale the effective context size of general-purpose LLMs by orders of magnitude without retraining them. This capability is becoming increasingly important for enterprise applications, where LLMs are adopted for long-horizon tasks requiring the processing of millions of tokens — a challenge Zhang argues can’t be solved by simply expanding context windows.\"There is an entropy argument that implies you need exponentially more data samples as you increase the effective context window size,\" Alex Zhang, a co-author of the paper, told VentureBeat. Current approaches to extending context often rely on compaction, where the model summarizes older parts of the conversation to free up space. However, this method fails for tasks requiring random access to specific details located in earlier parts of the prompt.How RLMs workThe concept behind RLMs is drawn from \"out-of-core\" algorithms used in classical computing. These algorithms are designed to process datasets too large to fit into a computer&#x27;s main memory by keeping the data on a hard drive and fetching only the necessary chunks as needed.RLMs apply this logic to generative AI. Instead of feeding a long prompt directly into the neural network, the framework loads the text as a string variable inside a Python coding environment. The LLM is given general context about the data (such as the total character count) but does not \"see\" the text initially.Once the prompt is stored as a variable, the LLM acts as a programmer. It writes Python code to interact with the external variable, using standard commands to peek into the data. For example, the model might use regular expressions to search for specific keywords like \"Chapter 1\" or \"financial results.\"When the code execution finds a relevant snippet, the RLM pulls only that specific chunk into its active context window for analysis.For example, if the prompt is a massive book, the LLM might write a loop that identifies chapter boundaries and then triggers a sub-call to summarize each chapter individually.The architecture typically involves two agents. A \"root language model,\" often a capability-heavy model like GPT-5, acts as the orchestrator. It plans the approach, writes the code, and manages the data flow within the REPL environment. A \"recursive language model,\" often a faster and cheaper model, acts as the worker. The root LM calls this worker to process the specific text snippets isolated by the code.Because the prompt resides in the environment&#x27;s memory rather than the model&#x27;s context window, the system can handle inputs far larger than the model&#x27;s training limit. Importantly, to the end-user, the RLM behaves exactly like a standard model: It accepts a string and returns an answer. This allows enterprise teams to swap standard API calls for RLMs. For developers looking to experiment, the RLM code is currently available on GitHub. \"A key argument for RLMs is that most complex tasks can be decomposed into smaller, &#x27;local&#x27; sub-tasks,\" Zhang said. \"However, how to perform this context/problem decomposition is non-trivial, and the model must be capable of performing this.\"RLMs in actionTo validate the framework, the researchers tested RLMs against base models and other agentic approaches like CodeAct and summary agents across a variety of long-context tasks, including retrieval and multi-hop question answering.The results demonstrated strong performance gains at the 10 million+ token scale. On BrowseComp-Plus, a benchmark involving inputs of 6 to 11 million tokens, standard base models failed completely, scoring 0%. In contrast, the RLM powered by GPT-5 achieved a score of 91.33%, significantly outperforming the Summary Agent (70.47%) and CodeAct (51%).The framework also excelled at tasks with high computational complexity. On OOLONG-Pairs, an information-dense reasoning benchmark where the difficulty scales quadratically with input length, base GPT-5 models failed catastrophically with a score of just 0.04%. The RLM achieved an F1 score (a balanced measure of precision and recall) of 58%, demonstrating emergent capabilities to handle dense tasks that paralyze standard models. Similarly, on code understanding tasks (CodeQA benchmark), the RLM more than doubled the performance of the base GPT-5 model, jumping from 24% to 62%.Regarding the context rot problem, the data showed that while the base GPT-5 performance degrades rapidly as task complexity increases, RLM performance holds steady, consistently outperforming the base model on contexts longer than 16,000 tokens.Despite the increased complexity of the workflow, RLMs often maintained comparable or lower average costs than the baselines. On the BrowseComp-Plus benchmark, the RLM was up to three times cheaper than the summarization baseline. However, the researchers noted that while median costs are low, RLM trajectories are \"long-tailed.\" Outlier runs can become expensive if the model gets stuck in loops or performs redundant verifications. While GPT-5 was conservative in its sub-calls, the open-source Qwen3-Coder model sometimes attempted thousands of sub-calls for simple tasks.\"Today, you likely will have to implement your own guardrails and logic to control RLM behavior,\" Zhang said. However, he hypothesizes that future models could be trained to manage their own compute budgets more effectively. Companies like Prime Intellect are planning to integrate RLM into the training process of models, possibly addressing the edge cases where the model’s inference budget spikes.For enterprise architects deciding where to place their bets, the RLM framework offers a new tool for handling information-dense problems.\"I think RLMs are still extremely useful for chatbots (think long chat histories), but ultimately they argue for an alternative way of using LMs,\" Zhang said. \"I think RLMs work in tandem with standard retrieval methods like RAG; they do not serve as a replacement, and can be used in different settings or together.\"",
          "content": "Recursive language models (RLMs) are an inference technique developed by researchers at MIT CSAIL that treat long prompts as an external environment to the model. Instead of forcing the entire prompt into the model&#x27;s context window, the framework allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the text.Rather than expanding context windows or summarizing old information, the MIT team reframes long-context reasoning as a systems problem. By letting models treat prompts as something they can inspect with code, recursive language models allow LLMs to reason over millions of tokens without retraining. This offers enterprises a practical path to long-horizon tasks like codebase analysis, legal review, and multi-step reasoning that routinely break today’s models.Because the framework is designed as a wrapper around existing models, it can serve as a drop-in replacement for applications that make direct calls to LLMs.The LLM context problemWhile frontier models are becoming increasingly sophisticated at reasoning, their ability to process massive amounts of information is not scaling at the same rate. This bottleneck is driven by two distinct limitations: the hard physical constraint on how much text a model can process at once (context length) and \"context rot.\"The challenge, the researchers argue, is whether it’s possible to scale the effective context size of general-purpose LLMs by orders of magnitude without retraining them. This capability is becoming increasingly important for enterprise applications, where LLMs are adopted for long-horizon tasks requiring the processing of millions of tokens — a challenge Zhang argues can’t be solved by simply expanding context windows.\"There is an entropy argument that implies you need exponentially more data samples as you increase the effective context window size,\" Alex Zhang, a co-author of the paper, told VentureBeat. Current approaches to extending context often rely on compaction, where the model summarizes older parts of the conversation to free up space. However, this method fails for tasks requiring random access to specific details located in earlier parts of the prompt.How RLMs workThe concept behind RLMs is drawn from \"out-of-core\" algorithms used in classical computing. These algorithms are designed to process datasets too large to fit into a computer&#x27;s main memory by keeping the data on a hard drive and fetching only the necessary chunks as needed.RLMs apply this logic to generative AI. Instead of feeding a long prompt directly into the neural network, the framework loads the text as a string variable inside a Python coding environment. The LLM is given general context about the data (such as the total character count) but does not \"see\" the text initially.Once the prompt is stored as a variable, the LLM acts as a programmer. It writes Python code to interact with the external variable, using standard commands to peek into the data. For example, the model might use regular expressions to search for specific keywords like \"Chapter 1\" or \"financial results.\"When the code execution finds a relevant snippet, the RLM pulls only that specific chunk into its active context window for analysis.For example, if the prompt is a massive book, the LLM might write a loop that identifies chapter boundaries and then triggers a sub-call to summarize each chapter individually.The architecture typically involves two agents. A \"root language model,\" often a capability-heavy model like GPT-5, acts as the orchestrator. It plans the approach, writes the code, and manages the data flow within the REPL environment. A \"recursive language model,\" often a faster and cheaper model, acts as the worker. The root LM calls this worker to process the specific text snippets isolated by the code.Because the prompt resides in the environment&#x27;s memory rather than the model&#x27;s context window, the system can handle inputs far larger than the model&#x27;s training limit. Importantly, to the end-user, the RLM behaves exactly like a standard model: It accepts a string and returns an answer. This allows enterprise teams to swap standard API calls for RLMs. For developers looking to experiment, the RLM code is currently available on GitHub. \"A key argument for RLMs is that most complex tasks can be decomposed into smaller, &#x27;local&#x27; sub-tasks,\" Zhang said. \"However, how to perform this context/problem decomposition is non-trivial, and the model must be capable of performing this.\"RLMs in actionTo validate the framework, the researchers tested RLMs against base models and other agentic approaches like CodeAct and summary agents across a variety of long-context tasks, including retrieval and multi-hop question answering.The results demonstrated strong performance gains at the 10 million+ token scale. On BrowseComp-Plus, a benchmark involving inputs of 6 to 11 million tokens, standard base models failed completely, scoring 0%. In contrast, the RLM powered by GPT-5 achieved a score of 91.33%, significantly outperforming the Summary Agent (70.47%) and CodeAct (51%).The framework also excelled at tasks with high computational complexity. On OOLONG-Pairs, an information-dense reasoning benchmark where the difficulty scales quadratically with input length, base GPT-5 models failed catastrophically with a score of just 0.04%. The RLM achieved an F1 score (a balanced measure of precision and recall) of 58%, demonstrating emergent capabilities to handle dense tasks that paralyze standard models. Similarly, on code understanding tasks (CodeQA benchmark), the RLM more than doubled the performance of the base GPT-5 model, jumping from 24% to 62%.Regarding the context rot problem, the data showed that while the base GPT-5 performance degrades rapidly as task complexity increases, RLM performance holds steady, consistently outperforming the base model on contexts longer than 16,000 tokens.Despite the increased complexity of the workflow, RLMs often maintained comparable or lower average costs than the baselines. On the BrowseComp-Plus benchmark, the RLM was up to three times cheaper than the summarization baseline. However, the researchers noted that while median costs are low, RLM trajectories are \"long-tailed.\" Outlier runs can become expensive if the model gets stuck in loops or performs redundant verifications. While GPT-5 was conservative in its sub-calls, the open-source Qwen3-Coder model sometimes attempted thousands of sub-calls for simple tasks.\"Today, you likely will have to implement your own guardrails and logic to control RLM behavior,\" Zhang said. However, he hypothesizes that future models could be trained to manage their own compute budgets more effectively. Companies like Prime Intellect are planning to integrate RLM into the training process of models, possibly addressing the edge cases where the model’s inference budget spikes.For enterprise architects deciding where to place their bets, the RLM framework offers a new tool for handling information-dense problems.\"I think RLMs are still extremely useful for chatbots (think long chat histories), but ultimately they argue for an alternative way of using LMs,\" Zhang said. \"I think RLMs work in tandem with standard retrieval methods like RAG; they do not serve as a replacement, and can be used in different settings or together.\"",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5Ybr6R81VAO6yoTI3fLOlG/9a42cc8ccddba84b036b42d27f769789/Recursive_language_model.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/x-open-sources-its-algorithm-5-ways-businesses-can-benefit",
          "published_at": "Tue, 20 Jan 2026 18:33:00 GMT",
          "title": "X open sources its algorithm: 5 ways business analysts can benefit",
          "standfirst": "Elon Musk&#x27;s social network X (formerly known as Twitter) last night released some of the code and architecture of its overhauled social recommendation algorithm under a permissive, enterprise-friendly open source license (Apache 2.0) on Github, allowing for commercial usage and modification. This is the algorithm that decides which X posts and accounts to show to which users on the social network.The new X algorithm, as opposed to the manual heuristic rules and legacy models in the past, is based on a \"Transformer\" architecture powered by its parent company, xAI’s, Grok AI language model. This is a significant release for enterprises who have brand accounts on X, or whose leaders and employees use X to post company promotional messages, links, content, etc — as it now provides a look at how X evaluates posts and accounts on the platform, and what criteria go into it deciding to show a post or specific account to users. Therefore, it&#x27;s imperative for any businesses using X to post promotional and informational content to understand how the X algorithm works as best as they can, in order to maximize their usage of the platform. To analogize: imagine trying to navigate a hike through a massive woods without a map. You&#x27;d likely end up lost and waste time and energy (resources) trying to get to your destination. But with a map, you could plot your route, look for the appropriate landmarks, check your progress along the way, and revise your path as necessary to stay on track. X open sourcing its new transformer-based recommendation algorithm is in many ways just this — providing a \"map\" to all those who use the platform on how to achieve the best performance they (and their brands) can.Here is the technical breakdown of the new architecture and five data-backed strategies to leverage it for commercial growth.The \"Red Herring\" of 2023 vs. The \"Grok\" Reality of 2026In March 2023, shortly after it was acquired by Musk, X also open sourced its recommendation algorithm.However, the release revealed a tangled web of \"spaghetti code\" and manual heuristics and was criticized by outlets like Wired (where my wife works, full disclosure) and organizations including the Center for Democracy and Technology, as being too heavily redacted to be useful. It was seen as a static snapshot of a decaying system.The code released on January 19, 2026, confirms that the spaghetti is gone. X has replaced the manual filtering layers with a unified, AI-driven Transformer architecture. The system uses a RecsysBatch input model that ingests user history and action probabilities to output a raw score. It is cleaner, faster, and infinitely more ruthless.But there is a catch: The specific \"weighting constants\"—the magic numbers that tell us exactly how much a Like or Reply is worth—have been redacted from this release.Here are the five strategic imperatives for brands operating in this new, Grok-mediated environment.1. The \"velocity\" window: you have 30 minutes to live or dieIn the 2023 legacy code, content drifted through complex clusters, often finding life hours after posting. The new Grok architecture is designed for immediate signal processing.Community analysis of the new Rust-based scoring functions reveals a strict \"Velocity\" mechanic. The lifecycle of a corporate post is determined in the first half-hour. If engagement signals (clicks, dwells, replies) fail to exceed a dynamic threshold in the first 15 minutes, the post is mathematically unlikely to breach the general \"For You\" pool.The architecture includes a specific scorer that penalizes multiple posts from the same user in a short window. Posting 10 times a day yields diminishing returns; the algorithm actively downranks your 3rd, 4th, and 5th posts to force variety into the feed. Space your announcements out.Thus, the takeaway for business data leads is to coordinate your internal comms and advocacy programs with military precision. \"Employee advocacy\" can no longer be asynchronous. If your employees or partners engage with a company announcement two hours later, the mathematical window has likely closed. You must front-load engagement in the first 10 minutes to artificially spike the velocity signal.2. The \"reply\" trap: Why engagement bait is deadIn 2023, data suggested that an author replying to comments was a \"cheat code\" for visibility. In 2026, this strategy has become a trap.While early analysis circulated rumors of a \"75x\" boost for replies, developers examining the new repository have confirmed that the actual weighting constants are hidden. More importantly, X’s Head of Product, Nikita Bier, has explicitly stated that \"Replies don&#x27;t count anymore\" for revenue sharing, in a move designed to kill \"reply rings\" and spam farms.Bier clarified that replies only generate value if they are high-quality enough to generate \"Home Timeline impressions\" on their own merit.As this is the case, businesses should stop optimizing for \"reply volume\" and start optimizing for \"reply quality.\" The algorithm is actively hostile toward low-effort engagement rings. Businesses and individuals should not reply incessantly to every comment with emojis or generic thanks. They should only reply if the response adds enough value to stand alone as a piece of content in a user’s feed.With replies devalued, focus on the other positive signals visible in the code: dwell_time (how long a user freezes on your post) and share_via_dm. Long-form threads or visual data that force a user to stop scrolling are now mathematically safer bets than controversial questions.3. X is basically pay-to-play, nowThe 2023 algorithm used X paid subscription status as one of many variables. The 2026 architecture simplifies this into a brutal base-score reality.Code analysis reveals that before a post is evaluated for quality, the account is assigned a base score. X accounts that are \"verified\" by paying the monthly \"Premium\" subscription ($3 per month for individual account Premium Basic, $200/month for businesses) receive a significantly higher ceiling (up to +100) compared to unverified accounts, which are capped (max +55).Therefore, if your brand, executives, or key spokespeople are not verified (X Premium or Verified Organizations), you are competing with a handicap. For a business looking to acquire customers or leads via X, verification is a mandatory infrastructure cost to remove a programmatic throttle on your reach.4. The \"report\" penalty: brand safety requires de-escalationThe Grok model has replaced complex \"toxicity\" rules with a simplified feedback loop. While the exact weight of someone filing a \"Report\" on your X post or account over objectionable or false material is hidden in the new config files, it remains the ultimate negative signal. But it isn&#x27;t the only one. The model also outputs probabilities for P(not_interested) and P(mute_author). Irrelevant clickbait doesn&#x27;t just get ignored; it actively trains the model to predict that users will mute you, permanently suppressing your future reach.In a system driven by AI probabilities, a \"Report\" or \"Block\" signal trains the model to permanently dissociate your brand from that user&#x27;s entire cluster.In practice, this means \"rage bait\" or controversial takes are now incredibly dangerous for brands. It takes only a tiny fraction of users utilizing the \"Report\" function to tank a post&#x27;s visibility entirely. Your content strategy must prioritize engagement that excites users enough to reply, but never enough to report.5. OSINT as a competency: watch the execs, not just the repoThe most significant takeaway from today&#x27;s release is what is missing. The repository provides the architecture (the \"car\"), but it hides the weights (the \"fuel\").As X user @Tenobrus noted, the repo is \"barebones\" regarding constants. This means you cannot rely solely on the code to dictate strategy. You must triangulate the code with executive communications. When Bier announces a change to \"revenue share\" logic, you must assume it mirrors a change in the \"ranking\" logic.Therefore, data decision makers should assign a technical lead to monitor both the xai-org/x-algorithm repository and the public statements of the Engineering team. The code tells you *how* the system thinks; the executives tell you *what* it is currently rewarding.Summary: The code is the strategyThe Grok-based transformer architecture is cleaner, faster, and more logical than its predecessor. It does not care about your legacy or your follower count. It cares about Velocity and Quality.The Winning Formula:1. Verify to secure the base score. 2. Front-load engagement to survive the 30-minute velocity check. 3. Avoid \"spammy\" replies; focus on standalone value. 4. Monitor executive comms to fill in the gaps left by the code.In the era of Grok, the algorithm is smarter. Your data and business strategy using X ought to be, too.",
          "content": "Elon Musk&#x27;s social network X (formerly known as Twitter) last night released some of the code and architecture of its overhauled social recommendation algorithm under a permissive, enterprise-friendly open source license (Apache 2.0) on Github, allowing for commercial usage and modification. This is the algorithm that decides which X posts and accounts to show to which users on the social network.The new X algorithm, as opposed to the manual heuristic rules and legacy models in the past, is based on a \"Transformer\" architecture powered by its parent company, xAI’s, Grok AI language model. This is a significant release for enterprises who have brand accounts on X, or whose leaders and employees use X to post company promotional messages, links, content, etc — as it now provides a look at how X evaluates posts and accounts on the platform, and what criteria go into it deciding to show a post or specific account to users. Therefore, it&#x27;s imperative for any businesses using X to post promotional and informational content to understand how the X algorithm works as best as they can, in order to maximize their usage of the platform. To analogize: imagine trying to navigate a hike through a massive woods without a map. You&#x27;d likely end up lost and waste time and energy (resources) trying to get to your destination. But with a map, you could plot your route, look for the appropriate landmarks, check your progress along the way, and revise your path as necessary to stay on track. X open sourcing its new transformer-based recommendation algorithm is in many ways just this — providing a \"map\" to all those who use the platform on how to achieve the best performance they (and their brands) can.Here is the technical breakdown of the new architecture and five data-backed strategies to leverage it for commercial growth.The \"Red Herring\" of 2023 vs. The \"Grok\" Reality of 2026In March 2023, shortly after it was acquired by Musk, X also open sourced its recommendation algorithm.However, the release revealed a tangled web of \"spaghetti code\" and manual heuristics and was criticized by outlets like Wired (where my wife works, full disclosure) and organizations including the Center for Democracy and Technology, as being too heavily redacted to be useful. It was seen as a static snapshot of a decaying system.The code released on January 19, 2026, confirms that the spaghetti is gone. X has replaced the manual filtering layers with a unified, AI-driven Transformer architecture. The system uses a RecsysBatch input model that ingests user history and action probabilities to output a raw score. It is cleaner, faster, and infinitely more ruthless.But there is a catch: The specific \"weighting constants\"—the magic numbers that tell us exactly how much a Like or Reply is worth—have been redacted from this release.Here are the five strategic imperatives for brands operating in this new, Grok-mediated environment.1. The \"velocity\" window: you have 30 minutes to live or dieIn the 2023 legacy code, content drifted through complex clusters, often finding life hours after posting. The new Grok architecture is designed for immediate signal processing.Community analysis of the new Rust-based scoring functions reveals a strict \"Velocity\" mechanic. The lifecycle of a corporate post is determined in the first half-hour. If engagement signals (clicks, dwells, replies) fail to exceed a dynamic threshold in the first 15 minutes, the post is mathematically unlikely to breach the general \"For You\" pool.The architecture includes a specific scorer that penalizes multiple posts from the same user in a short window. Posting 10 times a day yields diminishing returns; the algorithm actively downranks your 3rd, 4th, and 5th posts to force variety into the feed. Space your announcements out.Thus, the takeaway for business data leads is to coordinate your internal comms and advocacy programs with military precision. \"Employee advocacy\" can no longer be asynchronous. If your employees or partners engage with a company announcement two hours later, the mathematical window has likely closed. You must front-load engagement in the first 10 minutes to artificially spike the velocity signal.2. The \"reply\" trap: Why engagement bait is deadIn 2023, data suggested that an author replying to comments was a \"cheat code\" for visibility. In 2026, this strategy has become a trap.While early analysis circulated rumors of a \"75x\" boost for replies, developers examining the new repository have confirmed that the actual weighting constants are hidden. More importantly, X’s Head of Product, Nikita Bier, has explicitly stated that \"Replies don&#x27;t count anymore\" for revenue sharing, in a move designed to kill \"reply rings\" and spam farms.Bier clarified that replies only generate value if they are high-quality enough to generate \"Home Timeline impressions\" on their own merit.As this is the case, businesses should stop optimizing for \"reply volume\" and start optimizing for \"reply quality.\" The algorithm is actively hostile toward low-effort engagement rings. Businesses and individuals should not reply incessantly to every comment with emojis or generic thanks. They should only reply if the response adds enough value to stand alone as a piece of content in a user’s feed.With replies devalued, focus on the other positive signals visible in the code: dwell_time (how long a user freezes on your post) and share_via_dm. Long-form threads or visual data that force a user to stop scrolling are now mathematically safer bets than controversial questions.3. X is basically pay-to-play, nowThe 2023 algorithm used X paid subscription status as one of many variables. The 2026 architecture simplifies this into a brutal base-score reality.Code analysis reveals that before a post is evaluated for quality, the account is assigned a base score. X accounts that are \"verified\" by paying the monthly \"Premium\" subscription ($3 per month for individual account Premium Basic, $200/month for businesses) receive a significantly higher ceiling (up to +100) compared to unverified accounts, which are capped (max +55).Therefore, if your brand, executives, or key spokespeople are not verified (X Premium or Verified Organizations), you are competing with a handicap. For a business looking to acquire customers or leads via X, verification is a mandatory infrastructure cost to remove a programmatic throttle on your reach.4. The \"report\" penalty: brand safety requires de-escalationThe Grok model has replaced complex \"toxicity\" rules with a simplified feedback loop. While the exact weight of someone filing a \"Report\" on your X post or account over objectionable or false material is hidden in the new config files, it remains the ultimate negative signal. But it isn&#x27;t the only one. The model also outputs probabilities for P(not_interested) and P(mute_author). Irrelevant clickbait doesn&#x27;t just get ignored; it actively trains the model to predict that users will mute you, permanently suppressing your future reach.In a system driven by AI probabilities, a \"Report\" or \"Block\" signal trains the model to permanently dissociate your brand from that user&#x27;s entire cluster.In practice, this means \"rage bait\" or controversial takes are now incredibly dangerous for brands. It takes only a tiny fraction of users utilizing the \"Report\" function to tank a post&#x27;s visibility entirely. Your content strategy must prioritize engagement that excites users enough to reply, but never enough to report.5. OSINT as a competency: watch the execs, not just the repoThe most significant takeaway from today&#x27;s release is what is missing. The repository provides the architecture (the \"car\"), but it hides the weights (the \"fuel\").As X user @Tenobrus noted, the repo is \"barebones\" regarding constants. This means you cannot rely solely on the code to dictate strategy. You must triangulate the code with executive communications. When Bier announces a change to \"revenue share\" logic, you must assume it mirrors a change in the \"ranking\" logic.Therefore, data decision makers should assign a technical lead to monitor both the xai-org/x-algorithm repository and the public statements of the Engineering team. The code tells you *how* the system thinks; the executives tell you *what* it is currently rewarding.Summary: The code is the strategyThe Grok-based transformer architecture is cleaner, faster, and more logical than its predecessor. It does not care about your legacy or your follower count. It cares about Velocity and Quality.The Winning Formula:1. Verify to secure the base score. 2. Front-load engagement to survive the 30-minute velocity check. 3. Avoid \"spammy\" replies; focus on standalone value. 4. Monitor executive comms to fill in the gaps left by the code.In the era of Grok, the algorithm is smarter. Your data and business strategy using X ought to be, too.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/16AQsBHmZwamZhEThe81IE/c62d8f72d2a927091292807e176cbf7c/1c3ad1be-18a5-42ae-9e71-8e1407640d0f.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-wireless-charger-140036359.html",
          "published_at": "Tue, 20 Jan 2026 10:01:26 +0000",
          "title": "The best wireless chargers for 2026",
          "standfirst": "If you’ve upgraded your phone recently, there’s a good chance it supports wireless charging. Battery life can be one of the first things to deteriorate as your phone ages, so you’ll need quick and easy ways to power up wherever you are. You may not always be able to have a cable on your person, but investing in a wireless phone charger (or a few) can make it more convenient to plop your phone down and know it’ll have more juice when you pick it back up again.While you’re not going to get the same charging speed with a wireless charger that you would with a power cable, the convenience of a power source like this is undeniable. Stick a wireless charger on your bedside, on your desk at work, in your kitchen or wherever you spend a good chunk of your time and you’ll have a reliable way to power up your phone, sans bulky, messy cables. Needless to say, there are a ton of options out there with different charging capabilities and price ranges. Below, we’ve collected the best wireless chargers we’ve tested to make your search a little easier. Table of contents Best wireless chargers for 2026 What to look for in a wireless charger Where and how will you use your charger? Wireless charging performance Quality and box contents Wireless chargers FAQs Best wireless chargers for 2026 What to look for in a wireless charger While it’s tempting to buy a wireless charging pad optimized for the specific phone you have now, resist that urge. Instead, think about the types of devices (phones included) that you could see yourself using in the near future. If you’re sure you’ll use iPhones for a long time, an Apple MagSafe-compatible magnetic wireless charger will be faster and more convenient. If you use Android phones or think you might switch sides, however, you’ll want a more universal design. If you have other accessories like wireless earbuds or a smartwatch that supports wireless charging, maybe you’d be better off with a 3-in-1 wireless charger or full wireless charging station. Where and how will you use your charger? Odds are that you have a specific use case in mind for your charger. You may want it by your bedside on your nightstand for a quick charge in the morning, or on your desk for at-a-glance notifications. You might even keep it in your bag for convenient travel charging instead of bulky portable chargers or power banks. Think about where you want to use this accessory and what you want to do with the device(s) it charges while it’s powering up. For example, a wireless charging pad might be better for bedside use if you just want to be able to drop your phone down at the end of a long day and know it’ll be powered up in the morning. However, a stand will be better if you have an iPhone and want to make use of the Standby feature during the nighttime hours. For a desk wireless charger, a stand lets you more easily glance at phone notifications throughout the day. For traveling, undoubtedly, a puck-style charging pad is best since it will take up much less space in your bag than a stand would. Many power banks also include wireless charging pads built in, so one of those might make even more sense for those who are always on the go. Some foldable chargers are also designed for travel, collapsing flat to take up less space. Wireless charging performance Although wireless charging is usually slower than its wired equivalent, speed and wattage are still important considerations. A fast charger can supply enough power for a long night out in the time it takes to change outfits. Look for options that promise faster charging and support standards like Qi2 certified charging for the best balance of efficiency and compatibility. In general, a 15W charger is more than quick enough for most situations, and you’ll need a MagSafe-compatible charger to extract that level of performance from an iPhone. With that said, even the slower 7.5W and 10W chargers are fast enough for an overnight power-up. If anything, you’ll want to worry more about support for cases. While many models can deliver power through a reasonably thick case (typically 3mm to 5mm), you’ll occasionally run into examples that only work with naked phones. There are some proprietary chargers that smash the 15W barrier if you have the right phone. Apple’s latest MagSafe charging pad can provide up to 25W of wireless power to compatible iPhones when paired with a 30W or 35W adapter — the latter being another component you’ll have to get right to make sure the whole equation works as fast as it possibly can. Quality and box contents Pay attention to what’s included in the box. Some wireless chargers don’t include power adapters, and others may even ask you to reuse your phone’s USB-C charging cable. What may seem to be a bargain may prove expensive if you have to buy extras just to use it properly. As mentioned above, you’ll want to make sure all of the components needed to use the wireless charger can provide the level of power you need — you’re only as strong (or in this case, fast) as your weakest link. Fit and finish is also worth considering. You’re likely going to use your wireless charger every day, so even small differences in build quality could make the difference between joy and frustration. If your charger doesn’t use MagSafe-compatible tech, textured surfaces like fabric or rubberized plastic are more likely to keep your phone in place. The base should be grippy or weighty enough that the charger won’t slide around. Also double check that the wireless charger you’re considering can support phones outfitted with cases — the specifications are usually listed in the charger’s description or specs. You’ll also want to think about the minor conveniences. Status lights are useful for indicating correct phone placement, but an overly bright light can be distracting. Ideally, the light dims or shuts off after a certain period of time. And while we caution against lips and trays that limit compatibility, you may still want some barriers to prevent your device falling off its perch on the charging station. Wireless chargers FAQs Do wireless chargers work if you have a phone case? Many wireless chargers do work if you leave the case on your phone. Generally, a case up to 3mm thick should be compatible with most wireless chargers. However, you should check the manufacturer’s guide to ensure a case is supported. How do I know if my phone supports wireless charging? Checking the phone’s specification should tell you if your phone is compatible with wireless charging. You might see words like “Qi wireless charging” or “wireless charging compatible.” Do cords charge your phone faster? Most often, wired charging will be faster than wireless charging. However, wired charging also depends on what the charging cable’s speed is and how much power it’s designed to carry. A quick-charging cable that can transmit up to 120W of power is going to be faster than a wireless charger.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-wireless-charger-140036359.html?src=rss",
          "content": "If you’ve upgraded your phone recently, there’s a good chance it supports wireless charging. Battery life can be one of the first things to deteriorate as your phone ages, so you’ll need quick and easy ways to power up wherever you are. You may not always be able to have a cable on your person, but investing in a wireless phone charger (or a few) can make it more convenient to plop your phone down and know it’ll have more juice when you pick it back up again.While you’re not going to get the same charging speed with a wireless charger that you would with a power cable, the convenience of a power source like this is undeniable. Stick a wireless charger on your bedside, on your desk at work, in your kitchen or wherever you spend a good chunk of your time and you’ll have a reliable way to power up your phone, sans bulky, messy cables. Needless to say, there are a ton of options out there with different charging capabilities and price ranges. Below, we’ve collected the best wireless chargers we’ve tested to make your search a little easier. Table of contents Best wireless chargers for 2026 What to look for in a wireless charger Where and how will you use your charger? Wireless charging performance Quality and box contents Wireless chargers FAQs Best wireless chargers for 2026 What to look for in a wireless charger While it’s tempting to buy a wireless charging pad optimized for the specific phone you have now, resist that urge. Instead, think about the types of devices (phones included) that you could see yourself using in the near future. If you’re sure you’ll use iPhones for a long time, an Apple MagSafe-compatible magnetic wireless charger will be faster and more convenient. If you use Android phones or think you might switch sides, however, you’ll want a more universal design. If you have other accessories like wireless earbuds or a smartwatch that supports wireless charging, maybe you’d be better off with a 3-in-1 wireless charger or full wireless charging station. Where and how will you use your charger? Odds are that you have a specific use case in mind for your charger. You may want it by your bedside on your nightstand for a quick charge in the morning, or on your desk for at-a-glance notifications. You might even keep it in your bag for convenient travel charging instead of bulky portable chargers or power banks. Think about where you want to use this accessory and what you want to do with the device(s) it charges while it’s powering up. For example, a wireless charging pad might be better for bedside use if you just want to be able to drop your phone down at the end of a long day and know it’ll be powered up in the morning. However, a stand will be better if you have an iPhone and want to make use of the Standby feature during the nighttime hours. For a desk wireless charger, a stand lets you more easily glance at phone notifications throughout the day. For traveling, undoubtedly, a puck-style charging pad is best since it will take up much less space in your bag than a stand would. Many power banks also include wireless charging pads built in, so one of those might make even more sense for those who are always on the go. Some foldable chargers are also designed for travel, collapsing flat to take up less space. Wireless charging performance Although wireless charging is usually slower than its wired equivalent, speed and wattage are still important considerations. A fast charger can supply enough power for a long night out in the time it takes to change outfits. Look for options that promise faster charging and support standards like Qi2 certified charging for the best balance of efficiency and compatibility. In general, a 15W charger is more than quick enough for most situations, and you’ll need a MagSafe-compatible charger to extract that level of performance from an iPhone. With that said, even the slower 7.5W and 10W chargers are fast enough for an overnight power-up. If anything, you’ll want to worry more about support for cases. While many models can deliver power through a reasonably thick case (typically 3mm to 5mm), you’ll occasionally run into examples that only work with naked phones. There are some proprietary chargers that smash the 15W barrier if you have the right phone. Apple’s latest MagSafe charging pad can provide up to 25W of wireless power to compatible iPhones when paired with a 30W or 35W adapter — the latter being another component you’ll have to get right to make sure the whole equation works as fast as it possibly can. Quality and box contents Pay attention to what’s included in the box. Some wireless chargers don’t include power adapters, and others may even ask you to reuse your phone’s USB-C charging cable. What may seem to be a bargain may prove expensive if you have to buy extras just to use it properly. As mentioned above, you’ll want to make sure all of the components needed to use the wireless charger can provide the level of power you need — you’re only as strong (or in this case, fast) as your weakest link. Fit and finish is also worth considering. You’re likely going to use your wireless charger every day, so even small differences in build quality could make the difference between joy and frustration. If your charger doesn’t use MagSafe-compatible tech, textured surfaces like fabric or rubberized plastic are more likely to keep your phone in place. The base should be grippy or weighty enough that the charger won’t slide around. Also double check that the wireless charger you’re considering can support phones outfitted with cases — the specifications are usually listed in the charger’s description or specs. You’ll also want to think about the minor conveniences. Status lights are useful for indicating correct phone placement, but an overly bright light can be distracting. Ideally, the light dims or shuts off after a certain period of time. And while we caution against lips and trays that limit compatibility, you may still want some barriers to prevent your device falling off its perch on the charging station. Wireless chargers FAQs Do wireless chargers work if you have a phone case? Many wireless chargers do work if you leave the case on your phone. Generally, a case up to 3mm thick should be compatible with most wireless chargers. However, you should check the manufacturer’s guide to ensure a case is supported. How do I know if my phone supports wireless charging? Checking the phone’s specification should tell you if your phone is compatible with wireless charging. You might see words like “Qi wireless charging” or “wireless charging compatible.” Do cords charge your phone faster? Most often, wired charging will be faster than wireless charging. However, wired charging also depends on what the charging cable’s speed is and how much power it’s designed to carry. A quick-charging cable that can transmit up to 120W of power is going to be faster than a wireless charger.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-wireless-charger-140036359.html?src=rss",
          "feed_position": 38,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-02/c9a24a20-b7a0-11ed-b3cd-16d5d607f8d1"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/2JKMdzG9HS26opXgs2P44p/b3ca78544561a561c34b4c3a849fedbe/Left_to_right__Oded_Har-Tal_Co-Founder___CTO__Datarails-_mascot__Bob_Sheetner___Didi_Gurfinkel__Co-Founder___CEO_and_Eyal_Co.jpg?w=300&q=30",
      "popularity_score": 2014.7096105555556
    },
    {
      "id": "cluster_21",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 21:03:02 +0000",
      "title": "Why adding modern controls to 1996's Tomb Raider simply doesn't work",
      "neutral_headline": "Why adding modern controls to 1996's Tomb Raider simply doesn't work",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/the-problem-with-revisiting-tomb-raider-reacclimating-to-tank-controls/",
          "published_at": "Wed, 21 Jan 2026 21:03:02 +0000",
          "title": "Why adding modern controls to 1996's Tomb Raider simply doesn't work",
          "standfirst": "For our C:\\ArsGames series, we look at the controls conundrum of early 3D.",
          "content": "For a lot of the games I've written about in the C:\\ArsGames series, I've come to the conclusion that the games hold up pretty well, despite their age—Master of Orion II, Jill of the Jungle, and Wing Commander Privateer, for example. Each of those have flaws that show now more than ever, but I still had a blast revisiting each of them. This time I'd like to write about one that I think doesn't hold up quite as well for me: For the first time in almost 30 years, I revisited the original Tomb Raider via 2024's Tomb Raider I-III Remastered collection. You might be thinking this is going to be a dunk on the work done on the remaster, but that's not the case, because the core issue with playing 1996's Tomb Raider in 2026 is actually unsolvable, no matter how much care is put into a remaster.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Tomb-Raider-hero-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Tomb-Raider-hero-1152x648.jpg",
      "popularity_score": 355.6101661111111
    },
    {
      "id": "cluster_2",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 23:22:14 +0000",
      "title": "Millions of people imperiled through sign-in links sent by SMS",
      "neutral_headline": "Millions of people imperiled through sign-in links sent by SMS",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/security/2026/01/millions-of-people-imperiled-through-sign-in-links-sent-by-sms/",
          "published_at": "Wed, 21 Jan 2026 23:22:14 +0000",
          "title": "Millions of people imperiled through sign-in links sent by SMS",
          "standfirst": "Even well-known services with millions of users are exposing sensitive data.",
          "content": "Websites that authenticate users through links and codes sent in text messages are imperiling the privacy of millions of people, leaving them vulnerable to scams, identity theft, and other crimes, recently published research has found. The links are sent to people seeking a range of services, including those offering insurance quotes, job listings, and referrals for pet sitters and tutors. To eliminate the hassle of collecting usernames and passwords—and for users to create and enter them—many such services instead require users to provide a cell phone number when signing up for an account. The services then send authentication links or passcodes by SMS when the users want to log in. Easy to execute at scale A paper published last week has found more than 700 endpoints delivering such texts on behalf of more than 175 services that put user security and privacy at risk. One practice that jeopardizes users is the use of links that are easily enumerated, meaning scammers can guess them by simply modifying the security token, which usually appears at the right of a URL. By incrementing the token—for instance, by first changing 123 to 124 or ABC to ABD and so on—the researchers were able to access accounts belonging to other users. From there, the researchers could view personal details, such as partially completed insurance applications.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/sms-phone-risk-trap-privacy-security-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/sms-phone-risk-trap-privacy-security-1152x648.jpg",
      "popularity_score": 352.93016611111113
    },
    {
      "id": "cluster_16",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 21:50:21 +0000",
      "title": "Trump FCC threatens to enforce equal-time rule on late-night talk shows",
      "neutral_headline": "Trump FCC threatens to enforce equal-time rule on late-night talk shows",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/trump-fcc-tries-to-get-more-republicans-on-late-night-and-daytime-talk-shows/",
          "published_at": "Wed, 21 Jan 2026 21:50:21 +0000",
          "title": "Trump FCC threatens to enforce equal-time rule on late-night talk shows",
          "standfirst": "FCC disputes long-standing view that the shows are exempt from equal-time rule.",
          "content": "The Federal Communications Commission today issued a warning to late-night and daytime talk shows, saying these shows may no longer qualify for an exemption to the FCC's equal-time rule. Because the FCC is chaired by vocal Trump supporter Brendan Carr, changing how the rule is enforced could pressure shows into seeking out more interviews with Republican candidates. The public notice providing what the FCC calls \"guidance on political equal opportunities requirement for broadcast television stations\" appears to be part of the Trump administration's campaign against alleged liberal bias on broadcast TV. Carr, who has eroded the FCC's historical independence from the White House, previously pressured ABC to suspend Jimmy Kimmel and threatened ABC’s The View with the equal-time rule. The Carr FCC's public notice today said that federal rules \"prevent broadcast television stations, which have been given access to a valuable public resource (namely, spectrum), from unfairly putting their thumbs on the scale for one political candidate or set of candidates over another.\" These rules come from \"the decision by Congress that broadcast television stations have an obligation to operate in the public interest—not in any narrow partisan, political interest,\" the Carr FCC said.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/jimmy-kimmel-return-1152x648-1758739114.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/jimmy-kimmel-return-1152x648-1758739114.jpg",
      "popularity_score": 351.39877722222224
    },
    {
      "id": "cluster_7",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 22:51:26 +0000",
      "title": "mRNA cancer vaccine shows protection at 5-year follow-up, Moderna and Merck say",
      "neutral_headline": "MRNA cancer vaccine shows protection at 5-year follow-up, Moderna and Merck say",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/health/2026/01/mrna-cancer-vaccine-shows-protection-at-5-year-follow-up-moderna-and-merck-say/",
          "published_at": "Wed, 21 Jan 2026 22:51:26 +0000",
          "title": "mRNA cancer vaccine shows protection at 5-year follow-up, Moderna and Merck say",
          "standfirst": "The vaccines are tailor-made to target each patient's unique cancer.",
          "content": "In a small clinical trial, customized mRNA vaccines against high-risk skin cancers appeared to reduce the risk of cancer recurrence and death by nearly 50 percent over five years when compared with standard treatment alone. That's according to Moderna and Merck, the two pharmaceutical companies that have collaborated on the experimental cancer vaccine, called intismeran autogene (mRNA-4157 or V940). So far, the companies have only reported the top-line results in a press release this week. However, the results align closely with previous, more detailed analyses from the trial, which examined rates of recurrence and death at earlier time points, specifically at two years and three years after the treatment. More data from the trial—a Phase 2 trial—will soon be presented at a medical conference, the companies said. A Phase 3 trial is also underway, with enrollment complete. The ongoing Phase 2 trial included 157 patients who were diagnosed with stage 3 or stage 4 melanoma and were at high risk of having it recur after surgical removal. A standard treatment to prevent recurrence after such surgery is immunotherapy, including Merck's Keytruda (pembrolizumab). This drug essentially enables immune cells, specifically T cells, to attack and kill cancer cells—something they normally do. But, in many types of cancers, including melanoma, cancer cells have the ability to bind to receptors on T cells (called PD-1 receptors), which basically shuts the T cells down. Keytruda works by physically blocking the PD-1 receptors, preventing cancer cells from binding and keeping the T cells activated so they can kill the cancer.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2020/12/GettyImages-1290558683.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2020/12/GettyImages-1290558683.jpg",
      "popularity_score": 342.41683277777776
    },
    {
      "id": "cluster_28",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 20:37:00 +0000",
      "title": "Kioxia's memory is \"sold out\" for 2026, prolonging a \"high-end and expensive phase\"",
      "neutral_headline": "Kioxia's memory is \"sold out\" for 2026, prolonging a \"high-end and expensive phase\"",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/kioxias-memory-is-sold-out-for-2026-prolonging-a-high-end-and-expensive-phase/",
          "published_at": "Wed, 21 Jan 2026 20:37:00 +0000",
          "title": "Kioxia's memory is \"sold out\" for 2026, prolonging a \"high-end and expensive phase\"",
          "standfirst": "Kioxia is spinning up more manufacturing capacity, but relief will come slowly.",
          "content": "The companies that make RAM and flash memory chips are enjoying record profits because of the AI-induced memory crunch—and they’re also indicating that they don’t expect conditions to improve much if at all in 2026. And while RAM kits have been hit the fastest and hardest by shortages and price increases, we shouldn't expect SSD pricing to improve any time soon, either. That's the message from Shunsuke Nakato (via PC Gamer), managing director of the memory division of Kioxia, the Japanese memory company that was spun off from Toshiba at the end of the 2010s. Nakato says that Kioxia’s manufacturing capacity is sold out through the rest of 2026, driving the market for both enterprise and consumer SSDs to a “high-end and expensive phase.” “There is a sense of crisis that companies will be eliminated the moment they stop investing in AI, so they have no choice but to continue investing,” said Nakato, as reported by the Korean-language publication Digital Daily. Absent a big change in the demand for generative AI data centers, that cycle of investments will keep prices high for the foreseeable future.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/kioxia-ssds-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/kioxia-ssds-1152x648.jpg",
      "popularity_score": 330.1762772222222
    },
    {
      "id": "cluster_40",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 19:34:14 +0000",
      "title": "Spotify won court order against Anna’s Archive, taking down .org domain",
      "neutral_headline": "Spotify won court order against Anna’s Archive, taking down .org domain",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/annas-archive-said-spotify-scrape-didnt-cause-domain-suspension-it-was-wrong/",
          "published_at": "Wed, 21 Jan 2026 19:34:14 +0000",
          "title": "Spotify won court order against Anna’s Archive, taking down .org domain",
          "standfirst": "Lawsuit was filed under seal; Anna's Archive wasn't notified until after takedown.",
          "content": "When shadow library Anna's Archive lost its .org domain in early January, the controversial site's operator said the suspension didn't appear to have anything to do with its recent mass scraping of Spotify. But it turns out, probably not surprisingly to most people, that the domain suspension resulted from a lawsuit filed by Spotify, along with major record labels Sony, Warner, and Universal Music Group (UMG). The music companies sued Anna's Archive in late December in US District Court for the Southern District of New York, and the case was initially sealed. A judge ordered the case unsealed on January 16 \"because the purpose for which sealing was ordered has been fulfilled.\" Numerous documents were made public on the court docket yesterday, and they explain events around the domain suspension.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/spotify-logos-1152x648-1767642275.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/spotify-logos-1152x648-1767642275.jpg",
      "popularity_score": 324.1301658333333
    },
    {
      "id": "cluster_37",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 19:47:27 +0000",
      "title": "Watch a robot swarm \"bloom\" like a garden",
      "neutral_headline": "Watch a robot swarm \"bloom\" like a garden",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/watch-a-robot-swarm-bloom-like-a-garden/",
          "published_at": "Wed, 21 Jan 2026 19:47:27 +0000",
          "title": "Watch a robot swarm \"bloom\" like a garden",
          "standfirst": "The Swarm Garden: An array of modular robot agents that adapt to changing conditions for living architecture.",
          "content": "Researchers at Princeton University have built a swarm of interconnected mini-robots that \"bloom\" like flowers in response to changing light levels in an office. According to their new paper published in the journal Science Robotics, such robotic swarms could one day be used as dynamic facades in architectural designs, enabling buildings to adapt to changing climate conditions as well as interact with humans in creative ways. The authors drew inspiration from so-called \"living architectures,\" such as beehives. Fire ants provide a textbook example of this kind of collective behavior. A few ants spaced well apart behave like individual ants. But pack enough of them closely together, and they behave more like a single unit, exhibiting both solid and liquid properties. You can pour them from a teapot like ants, as Goldman’s lab demonstrated several years ago, or they can link together to build towers or floating rafts—a handy survival skill when, say, a hurricane floods Houston. They also excel at regulating their own traffic flow. You almost never see an ant traffic jam. Naturally scientists are keen to mimic such systems. For instance, in 2018, Georgia Tech researchers built ant-like robots and programmed them to dig through 3D-printed magnetic plastic balls designed to simulate moist soil. Robot swarms capable of efficiently digging underground without jamming would be super beneficial for mining or disaster recovery efforts, where using human beings might not be feasible.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/swarm1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/swarm1-1152x648.jpg",
      "popularity_score": 316.3504438888889
    },
    {
      "id": "cluster_48",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 18:40:21 +0000",
      "title": "Another Jeff Bezos company has announced plans to develop a megaconstellation",
      "neutral_headline": "Another Jeff Bezos company has announced plans to develop a megaconstellation",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/blue-origin-we-want-to-have-a-megaconstellation-too/",
          "published_at": "Wed, 21 Jan 2026 18:40:21 +0000",
          "title": "Another Jeff Bezos company has announced plans to develop a megaconstellation",
          "standfirst": "With data speeds of up to 6Tbps, one could stream a lot of HD movies.",
          "content": "The announcement came out of the blue, from Blue, on Wednesday. The space company founded by Jeff Bezos, Blue Origin, said it was developing a new megaconstellation named TeraWave to deliver data speeds of up to 6Tbps anywhere on Earth. The constellation will consist of 5,408 optically interconnected satellites, with a majority in low-Earth orbit and the remainder in medium-Earth orbit. The satellites in low-Earth orbit will provide up to 144Gbps through radio spectrum, whereas those in medium-Earth orbit will provide higher data rates through optical links.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/G_NEl2bbgAAr100-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/G_NEl2bbgAAr100-1152x648.jpg",
      "popularity_score": 304.2321102777778
    },
    {
      "id": "cluster_89",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 15:03:39 +0000",
      "title": "Has Gemini surpassed ChatGPT? We put the AI models to the test.",
      "neutral_headline": "Has Gemini surpassed ChatGPT? We put the AI models to the test.",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/features/2026/01/has-gemini-surpassed-chatgpt-we-put-the-ai-models-to-the-test/",
          "published_at": "Wed, 21 Jan 2026 15:03:39 +0000",
          "title": "Has Gemini surpassed ChatGPT? We put the AI models to the test.",
          "standfirst": "Did Apple make the right choice in partnering with Google for Siri's AI features?",
          "content": "The last time we did comparative tests of AI models from OpenAI and Google at Ars was in late 2023, when Google's offering was still called Bard. In the roughly two years since, a lot has happened in the world of artificial intelligence. And now that Apple has made the consequential decision to partner with Google Gemini to power the next generation of its Siri voice assistant, we thought it was high time to do some new tests to see where the models from these AI giants stand today. For this test, we're comparing the default models that both OpenAI and Google present to users who don't pay for a regular subscription—ChatGPT 5.2 for OpenAI and Gemini 3.2 Fast for Google. While other models might be more powerful, we felt this test best recreates the AI experience as it would work for the vast majority of Siri users, who don't pay to subscribe to either company's services. As in the past, we'll feed the same prompts to both models and evaluate the results using a combination of objective evaluation and subjective feel. Rather than re-using the relatively simple prompts we ran back in 2023, though, we'll be running these models on an updated set of more complex prompts that we first used when pitting GPT-5 against GPT-4o last summer.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/chatgpt-vs-gemini-apple-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/chatgpt-vs-gemini-apple-1152x648.jpg",
      "popularity_score": 294.6204436111111
    },
    {
      "id": "cluster_66",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 17:30:58 +0000",
      "title": "Here's Volvo's new EX60 $60,000 electric midsize SUV",
      "neutral_headline": "Here's Volvo's new EX60 $60,000 electric midsize SUV",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/heres-volvos-new-ex60-60000-electric-midsize-suv/",
          "published_at": "Wed, 21 Jan 2026 17:30:58 +0000",
          "title": "Here's Volvo's new EX60 $60,000 electric midsize SUV",
          "standfirst": "The EX60 goes into production in April 2026.",
          "content": "After a teaser campaign that included a world exclusive with Ars, Volvo has officially unveiled its next electric vehicle, the EX60. We already knew it would have up to 400 miles of range, according to the US EPA test cycle, and be capable of charging at rates of up to 400 kW. And we learned last week that the EX60 is packed full of powerful computer hardware from Nvidia and Qualcomm, enabling both advanced driver assistance systems and a new AI personal assistant. Today, we got full tech specs for the three different EX60 powertrain variants, as well as a pair of rugged EX60 Cross Country models. P6, P10, P12 The entry-level version of Volvo's next midsize crossover is the EX60 P6. This is a single-motor variant, with 369 hp (275 kW), 354 lb-ft (480 Nm) on tap at the rear wheels. The 80 kWh (usable, 83 kWH gross) battery pack can charge at up to 320 kW and can take as little as 18 minutes to DC charge from 10 to 80 percent. The EX60 will also be the first Volvo model on sale in the US with a built-in NACS port. Range for the P6 version is 310 miles (490 km) when fitted with 20-inch wheels; subtract 10 miles (16 km) for the 21-inch wheels and 20 miles (32 km) for the 22-inch wheels. 0–60 mph (0–98 km/h) takes 5.7 seconds, and like all modern Volvos, the EX60 is speed-limited to 112 mph (180 km/h). (Again, all range estimates are based on the US EPA test cycle; if you see different numbers online at non-US publications, those are using Europe's WLTP test.)Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/JPG-Full-TIM_1154_EX60_DETAIL_HIGH_FRONT-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/JPG-Full-TIM_1154_EX60_DETAIL_HIGH_FRONT-1152x648.jpg",
      "popularity_score": 293.0757213888889
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 14:33:00 +0000",
      "title": "Zillow removed climate risk scores. This climate expert is restoring them.",
      "neutral_headline": "Zillow removed climate risk scores. This climate expert is restoring them.",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/zillow-removed-climate-risk-scores-this-climate-expert-is-restoring-them/",
          "published_at": "Wed, 21 Jan 2026 14:33:00 +0000",
          "title": "Zillow removed climate risk scores. This climate expert is restoring them.",
          "standfirst": "Real estate website scrubbed data under pressure from California real estate brokers.",
          "content": "Even as exposure to floods, fire, and extreme heat increase in the face of climate change, a popular tool for evaluating risk has disappeared from the nation’s leading real estate website. Zillow removed the feature displaying climate risk data to home buyers in November after the California Regional Multiple Listing Service, which provides a database of real estate listings to real estate agents and brokers in the state, questioned the accuracy of the flood risk models on the site. Now, a climate policy expert in California is working to put data back in buyers’ hands.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/floods-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/floods-1152x648.jpg",
      "popularity_score": 272.1096102777778
    },
    {
      "id": "cluster_100",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 12:15:23 +0000",
      "title": "Wikipedia volunteers spent years cataloging AI tells. Now there's a plugin to avoid them.",
      "neutral_headline": "Wikipedia volunteers spent years cataloging AI tells. Now there's...",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/new-ai-plugin-uses-wikipedias-ai-writing-detection-rules-to-help-it-sound-human/",
          "published_at": "Wed, 21 Jan 2026 12:15:23 +0000",
          "title": "Wikipedia volunteers spent years cataloging AI tells. Now there's a plugin to avoid them.",
          "standfirst": "The web's best guide to spotting AI writing has become a manual for hiding it.",
          "content": "On Saturday, tech entrepreneur Siqi Chen released an open source plugin for Anthropic's Claude Code AI assistant that instructs the AI model to stop writing like an AI model. Called \"Humanizer,\" the simple prompt plugin feeds Claude a list of 24 language and formatting patterns that Wikipedia editors have listed as chatbot giveaways. Chen published the plugin on GitHub, where it has picked up over 1,600 stars as of Monday. \"It's really handy that Wikipedia went and collated a detailed list of 'signs of AI writing,'\" Chen wrote on X. \"So much so that you can just tell your LLM to... not do that.\" The source material is a guide from WikiProject AI Cleanup, a group of Wikipedia editors who have been hunting AI-generated articles since late 2023. French Wikipedia editor Ilyas Lebleu founded the project. The volunteers have tagged over 500 articles for review and, in August 2025, published a formal list of the patterns they kept seeing.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/10/ai_typewriter_getty-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/10/ai_typewriter_getty-1152x648.jpg",
      "popularity_score": 266.81599916666664
    },
    {
      "id": "cluster_117",
      "coverage": 1,
      "updated_at": "Tue, 20 Jan 2026 22:35:32 +0000",
      "title": "Verizon starts requiring 365 days of paid service before it will unlock phones",
      "neutral_headline": "Verizon starts requiring 365 days of paid service before it will unlock phones",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/verizon-starts-requiring-365-days-of-paid-service-before-it-will-unlock-phones/",
          "published_at": "Tue, 20 Jan 2026 22:35:32 +0000",
          "title": "Verizon starts requiring 365 days of paid service before it will unlock phones",
          "standfirst": "Verizon changed prepaid brands' policy a week after FCC waived unlocking rule.",
          "content": "Verizon has started enforcing a 365-day lock period on phones purchased through its TracFone division, one week after the Federal Communications Commission waived a requirement that Verizon unlock handsets 60 days after they are activated on its network. Verizon was previously required to unlock phones automatically after 60 days due to restrictions imposed on its spectrum licenses and merger conditions that helped Verizon obtain approval of its purchase of TracFone. But an update applied today to the TracFone unlocking policy said new phones will be locked for at least a year and that each customer will have to request an unlock instead of getting it automatically. The \"new\" TracFone policy is basically a return to the yearlong locking it imposed before Verizon bought the company in 2021. TracFone first agreed to provide unlocking in a 2015 settlement with the Obama-era FCC, which alleged that TracFone failed to comply with a commitment to unlock phones for customers enrolled in the Lifeline subsidy program. TracFone later shortened the locking period from a year to 60 days as a condition of the Verizon merger.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/verizon-1152x648-1752087139.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/verizon-1152x648-1752087139.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_120",
      "coverage": 1,
      "updated_at": "Tue, 20 Jan 2026 22:17:02 +0000",
      "title": "Google temporarily disabled YouTube's advanced captions without warning",
      "neutral_headline": "Google temporarily disabled YouTube's advanced captions without warning",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/google-temporarily-disabled-youtubes-advanced-captions-without-warning/",
          "published_at": "Tue, 20 Jan 2026 22:17:02 +0000",
          "title": "Google temporarily disabled YouTube's advanced captions without warning",
          "standfirst": "Google says SRV3 captions were causing playback errors, so it has \"temporarily\" disabled them.",
          "content": "YouTubers have been increasingly frustrated with Google's management of the platform, with disinformation welcomed back and an aggressive push for more AI (except where Google doesn't like it). So it's no surprise that creators have been up in arms over the suspicious removal of YouTube's advanced SRV3 caption format. You don't have to worry too much just yet—Google says this is only temporary, and it's working on a fix for the underlying bug. Google added support for this custom subtitle format around 2018, giving creators more customization options than with traditional captions. SRV3 (also known as YTT or YouTube Timed Text) allows for custom colors, transparency, animations, fonts, and precise positioning in videos. Uploaders using this format can color-code and position captions to help separate multiple speakers, create sing-along animations, or style them to match the video. Over the last several days, creators who have become accustomed to this level of control have been dismayed to see that YouTube is no longer accepting videos with this Google-created format. Many worried Google had ditched the format entirely, which could be problematic for all those previously uploaded videos.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-1152x648.jpg",
      "popularity_score": 145
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Tue, 20 Jan 2026 15:00:04 +0000",
      "title": "The first commercial space station, Haven-1, is now undergoing assembly for launch",
      "neutral_headline": "The first commercial space station, Haven-1, is now undergoing assembly for launch",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/the-first-commercial-space-station-haven-1-is-now-undergoing-assembly-for-launch/",
          "published_at": "Tue, 20 Jan 2026 15:00:04 +0000",
          "title": "The first commercial space station, Haven-1, is now undergoing assembly for launch",
          "standfirst": "\"We have a very strong incentive to send a crew as quickly as we can safely do so.\"",
          "content": "As Ars reported last week, NASA's plan to replace the International Space Station with commercial space stations is running into a time crunch. The sprawling International Space Station is due to be decommissioned less than five years from now, and the US space agency has yet to formally publish rules and requirements for the follow-on stations being designed and developed by several different private companies. Although there are expected to be multiple bidders in \"phase two\" of NASA's commercial space station program, there are at present four main contenders: Voyager Technologies, Axiom Space, Blue Origin, and Vast Space. At some point later this year, the space agency is expected to select one, or more likely two, of these companies for larger contracts that will support their efforts to build their stations.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Vast_Haven-1_Integration_Phase-1_ISO8_Cleanroom_Spring_2026-01-15-DSC_1375-3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Vast_Haven-1_Integration_Phase-1_ISO8_Cleanroom_Spring_2026-01-15-DSC_1375-3-1152x648.jpg",
      "popularity_score": 141
    },
    {
      "id": "cluster_114",
      "coverage": 1,
      "updated_at": "Tue, 20 Jan 2026 23:33:57 +0000",
      "title": "Webb reveals a planetary nebula with phenomenal clarity, and it is spectacular",
      "neutral_headline": "Webb reveals a planetary nebula with phenomenal clarity, and it is spectacular",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/webb-has-given-us-with-a-stunning-new-view-of-a-well-known-planetary-nebula/",
          "published_at": "Tue, 20 Jan 2026 23:33:57 +0000",
          "title": "Webb reveals a planetary nebula with phenomenal clarity, and it is spectacular",
          "standfirst": "The colors show the star’s final breath transforming into the raw ingredients for new worlds.",
          "content": "The Helix Nebula is one of the most well-known and commonly photographed planetary nebulae because it resembles the \"Eye of Sauron.\" It is also one of the closest bright nebulae to Earth, located approximately 655 light-years from our Solar System. You may not know what this particular nebula looks like when reading its name, but the Hubble Space Telescope has taken some iconic images of it over the years. And almost certainly, you'll recognize a photograph of the Helix Nebula, shown below. Like many objects in astronomy, planetary nebulae have a confusing name, since they are formed not by planets but by stars like our own Sun, though a little larger. Near the end of their lives, these stars shed large amounts of gas in an expanding shell that, however briefly in cosmological time, put on a grand show.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/STScI-01KCMAMZ8ZSMRTR9KKD8Y6EMRJ-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/STScI-01KCMAMZ8ZSMRTR9KKD8Y6EMRJ-1152x648.png",
      "popularity_score": 139
    },
    {
      "id": "cluster_115",
      "coverage": 1,
      "updated_at": "Tue, 20 Jan 2026 23:22:26 +0000",
      "title": "Zuck stuck on Trump’s bad side: FTC appeals loss in Meta monopoly case",
      "neutral_headline": "Zuck stuck on Trump’s bad side: FTC appeals loss in Meta monopoly case",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/zuck-stuck-on-trumps-bad-side-ftc-appeals-loss-in-meta-monopoly-case/",
          "published_at": "Tue, 20 Jan 2026 23:22:26 +0000",
          "title": "Zuck stuck on Trump’s bad side: FTC appeals loss in Meta monopoly case",
          "standfirst": "FTC will appeal ruling that found Meta has no monopoly in social networking.",
          "content": "Still feeling uneasy about Meta's acquisition of Instagram in 2012 and WhatsApp in 2014, the Federal Trade Commission will be appealing a November ruling that cleared Meta of allegations that it holds an illegal monopoly in a market dubbed \"personal social networking.\" The FTC hopes the US Court of Appeals for the District of Columbia will agree that \"robust evidence at trial\" showed that Meta's acquisitions were improper. In the initial trial, the FTC sought a breakup of Meta's apps, with Meta risking forced divestments of Instagram or WhatsApp. In a press release Tuesday, the FTC confirmed that it \"continues to allege\" that \"for over a decade Meta has illegally maintained a monopoly in personal social networking services through anticompetitive conduct—by buying the significant competitive threats it identified in Instagram and WhatsApp.\"Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/zuck-the-monopolist-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/zuck-the-monopolist-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_121",
      "coverage": 1,
      "updated_at": "Tue, 20 Jan 2026 21:59:38 +0000",
      "title": "Flesh-eating flies are eating their way through Mexico, CDC warns",
      "neutral_headline": "Flesh-eating flies are eating their way through Mexico, CDC warns",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/be-on-the-lookout-for-flesh-eating-flies-cdc-tells-clinicians-in-alert/",
          "published_at": "Tue, 20 Jan 2026 21:59:38 +0000",
          "title": "Flesh-eating flies are eating their way through Mexico, CDC warns",
          "standfirst": "Eight animal cases in Mexico's Tamaulipas spur CDC to warn doctors of festering wounds.",
          "content": "The US Centers for Disease Control and Prevention issued a health alert to clinicians Tuesday, warning that the savage, flesh-eating parasitic fly—the New World Screwworm—is not only approaching the Texas border, but also felling an increasing number of animals in the bordering Mexican state of Tamaulipas. The advisory, released through the agency's Health Alert Network, directs doctors, veterinarians, and other health workers to be on the lookout for patients with wounds teeming with ferocious maggots burrowing into their living flesh. The alert also provides guidance on what to do if any such festering wounds are encountered—namely, remove each and every maggot to prevent the patient from dying, and, under no circumstance allow any of the parasites to survive and escape. The New World Screwworm (NWS) is a fly that lays its eggs—up to 400 at a time—in the wounds, orifices, and mucus membranes of any warm-blooded animal. The eggs hatch into flesh-eating maggots, which look and act much like screws, twisting and boring into their victims while eating them alive.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2016/11/CSIRO_ScienceImage_115_The_Tip_of_a_Screw_Worm_Fly_Larvae.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2016/11/CSIRO_ScienceImage_115_The_Tip_of_a_Screw_Worm_Fly_Larvae.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_122",
      "coverage": 1,
      "updated_at": "Tue, 20 Jan 2026 21:25:30 +0000",
      "title": "Macaque facial gestures are more than just a reflex, study finds",
      "neutral_headline": "Macaque facial gestures are more than just a reflex, study finds",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/macaque-facial-gestures-are-more-than-just-a-reflex-study-finds/",
          "published_at": "Tue, 20 Jan 2026 21:25:30 +0000",
          "title": "Macaque facial gestures are more than just a reflex, study finds",
          "standfirst": "Study is first to implant micro-electrode arrays to record neurons as they produce facial gestures.",
          "content": "Recent advances in brain-computer interfaces have made it possible to more accurately extract speech from neural signals in humans, but language is just one of the tools we use to communicate. “When my young nephew asks for ice cream before dinner and I say ‘no,’ the meaning is entirely dictated by whether the word is punctuated with a smirk or a stern frown,” says Geena Ianni, a neuroscientist at the University of Pennsylvania. That’s why in the future, she thinks, neural prostheses meant for patients with a stroke or paralysis will decode facial gestures from brain signals in the same way they decode speech. To lay a foundation for these future facial gesture decoders, Ianni and her colleagues designed an experiment to find out how neural circuitry responsible for making faces really works. “Although in recent years neuroscience got a good handle on how the brain perceives facial expressions, we know relatively little about how they are generated,” Ianni says. And it turned out that a surprisingly large part of what neuroscientists assumed about facial gestures was wrong. The natural way For a long time, neuroscientists thought facial gestures in primates stemmed from a neat division of labor in the brain. “Case reports of patients with brain lesions suggested some brain regions were responsible for certain types of emotional expressions while other regions were responsible for volitional movements like speech,” Ianni explains. We’ve developed a clearer picture of speech by tracing the origin of these movements down to the level of individual neurons. But we’ve not done the same for facial expressions. To fill this gap, Ianni and her team designed a study using macaques—social primates that share most of their complex facial musculature with humans.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2243934190-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2243934190-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Tue, 20 Jan 2026 19:24:12 +0000",
      "title": "Netflix to pay all cash for Warner Bros. to fend off Paramount hostile takeover",
      "neutral_headline": "Netflix to pay all cash for Warner Bros. to fend off Paramount hostile takeover",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/netflix-to-pay-all-cash-for-warner-bros-to-fend-off-paramount-hostile-takeover/",
          "published_at": "Tue, 20 Jan 2026 19:24:12 +0000",
          "title": "Netflix to pay all cash for Warner Bros. to fend off Paramount hostile takeover",
          "standfirst": "Netflix and Warner seek quick shareholder vote as Paramount tries to upend deal.",
          "content": "Netflix agreed to pay all cash for Warner Bros. Discovery, amending its $72 billion deal in an attempt to fight off Paramount's hostile takeover bid. Netflix originally agreed to buy the company with a mix of cash and stock. To sweeten the offer for shareholders, Netflix and Warner Bros. today announced that Netflix will pay all cash instead. If successful, Netflix's purchase will include HBO Max, WB Studios, and other assets. The price is unchanged at $27.75 per share, and Warner Bros. is targeting an April 2026 shareholder vote. The original plan was for Netflix to buy each Warner Bros. share with $23.25 in cash and $4.50 in Netflix stock.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/netflix-paramount-wb-icons-1152x648-1767815429.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/netflix-paramount-wb-icons-1152x648-1767815429.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_128",
      "coverage": 1,
      "updated_at": "Tue, 20 Jan 2026 18:58:22 +0000",
      "title": "Sony is giving TCL control over its high-end Bravia TVs",
      "neutral_headline": "Sony is giving TCL control over its high-end Bravia TVs",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/tcl-to-gain-majority-ownership-over-sonys-bravia-tvs/",
          "published_at": "Tue, 20 Jan 2026 18:58:22 +0000",
          "title": "Sony is giving TCL control over its high-end Bravia TVs",
          "standfirst": "TCL will own 51 percent of the high-end TVs.",
          "content": "TCL is taking majority ownership of Sony’s Bravia series of TVs, the two companies announced today. The two firms said they have signed a memorandum of understanding and aim to sign binding agreements by the end of March. Pending “relevant regulatory approvals and other conditions,” the joint venture is expected to launch in April 2027. Under a new joint venture, Huizhou, China-headquartered TCL will own 51 percent of Tokyo, Japan-headquartered Sony’s “home entertainment business,” and Sony will own 49 percent, per an announcement today, adding:Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1236174910-1152x648-1768934089.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1236174910-1152x648-1768934089.jpg",
      "popularity_score": 133
    }
  ]
}