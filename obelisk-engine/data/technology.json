{
  "updated_at": "2025-10-29T07:19:56.641Z",
  "clusters": [
    {
      "id": "cluster_3",
      "coverage": 2,
      "updated_at": "Wed, 29 Oct 2025 01:45:35 -0400",
      "title": "All three major South Korean telcos, SK Telecom, KT Telecom, and now LG Uplus, have reported cybersecurity incidents to the government over the past six months (Kate Park/TechCrunch)",
      "neutral_headline": "All three major South Korean telcos, SK Telecom, KT Telecom, and now LG Uplus, have reported cybersecurity incidents to the government over the past six months (Kate Park/TechCrunch)",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251029/p8#a251029p8",
          "published_at": "Wed, 29 Oct 2025 01:45:35 -0400",
          "title": "All three major South Korean telcos, SK Telecom, KT Telecom, and now LG Uplus, have reported cybersecurity incidents to the government over the past six months (Kate Park/TechCrunch)",
          "standfirst": "Kate Park / TechCrunch: All three major South Korean telcos, SK Telecom, KT Telecom, and now LG Uplus, have reported cybersecurity incidents to the government over the past six months &mdash; LG Uplus, one of the largest telecom operators in South Korea, has confirmed to TechCrunch that it has reported a suspected data breach &hellip;",
          "content": "Kate Park / TechCrunch: All three major South Korean telcos, SK Telecom, KT Telecom, and now LG Uplus, have reported cybersecurity incidents to the government over the past six months &mdash; LG Uplus, one of the largest telecom operators in South Korea, has confirmed to TechCrunch that it has reported a suspected data breach &hellip;",
          "feed_position": 2,
          "image_url": "http://www.techmeme.com/251029/i8.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/28/lg-uplus-is-latest-south-korean-telco-to-confirm-cybersecurity-incident/",
          "published_at": "Wed, 29 Oct 2025 03:55:08 +0000",
          "title": "LG Uplus is latest South Korean telco to confirm cybersecurity incident",
          "standfirst": "Korean telecom giant LG Uplus is the third major phone provider in the past six months to report a cybersecurity incident.",
          "content": "Korean telecom giant LG Uplus is the third major phone provider in the past six months to report a cybersecurity incident.",
          "feed_position": 1
        }
      ],
      "featured_image": "http://www.techmeme.com/251029/i8.jpg",
      "popularity_score": 2018.4273219444444,
      "ai_summary": [
        "LG Uplus confirmed a suspected data breach to TechCrunch.",
        "LG Uplus is one of South Korea's largest telecom operators.",
        "All three major South Korean telcos reported incidents.",
        "The incidents were reported to the government.",
        "The incidents occurred over the past six months."
      ]
    },
    {
      "id": "cluster_33",
      "coverage": 2,
      "updated_at": "Tue, 28 Oct 2025 23:23:00 GMT",
      "title": "IBM's open source Granite 4.0 Nano AI models are small enough to run locally directly in your browser",
      "neutral_headline": "IBM's open source Granite 4.0 Nano AI models are small enough to run locally directly in your browser",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/ibms-open-source-granite-4-0-nano-ai-models-are-small-enough-to-run-locally",
          "published_at": "Tue, 28 Oct 2025 23:23:00 GMT",
          "title": "IBM's open source Granite 4.0 Nano AI models are small enough to run locally directly in your browser",
          "standfirst": "In an industry where model size is often seen as a proxy for intelligence, IBM is charting a different course — one that values efficiency over enormity, and accessibility over abstraction.The 114-year-old tech giant&#x27;s four new Granite 4.0 Nano models, released today, range from just 350 million to 1.5 billion parameters, a fraction of the size of their server-bound cousins from the likes of OpenAI, Anthropic, and Google. These models are designed to be highly accessible: the 350M variants can run comfortably on a modern laptop CPU with 8–16GB of RAM, while the 1.5B models typically require a GPU with at least 6–8GB of VRAM for smooth performance — or sufficient system RAM and swap for CPU-only inference. This makes them well-suited for developers building applications on consumer hardware or at the edge, without relying on cloud compute.In fact, the smallest ones can even run locally on your own web browser, as Joshua Lochner aka Xenova, creator of Transformer.js and a machine learning engineer at Hugging Face, wrote on the social network X.All the Granite 4.0 Nano models are released under the Apache 2.0 license — perfect for use by researchers and enterprise or indie developers, even for commercial usage. They are natively compatible with llama.cpp, vLLM, and MLX and are certified under ISO 42001 for responsible AI development — a standard IBM helped pioneer.But in this case, small doesn&#x27;t mean less capable — it might just mean smarter design.These compact models are built not for data centers, but for edge devices, laptops, and local inference, where compute is scarce and latency matters. And despite their small size, the Nano models are showing benchmark results that rival or even exceed the performance of larger models in the same category. The release is a signal that a new AI frontier is rapidly forming — one not dominated by sheer scale, but by strategic scaling.What Exactly Did IBM Release?The Granite 4.0 Nano family includes four open-source models now available on Hugging Face:Granite-4.0-H-1B (~1.5B parameters) – Hybrid-SSM architectureGranite-4.0-H-350M (~350M parameters) – Hybrid-SSM architectureGranite-4.0-1B – Transformer-based variant, parameter count closer to 2BGranite-4.0-350M – Transformer-based variantThe H-series models — Granite-4.0-H-1B and H-350M — use a hybrid state space architecture (SSM) that combines efficiency with strong performance, ideal for low-latency edge environments. Meanwhile, the standard transformer variants — Granite-4.0-1B and 350M — offer broader compatibility with tools like llama.cpp, designed for use cases where hybrid architecture isn’t yet supported. In practice, the transformer 1B model is closer to 2B parameters, but aligns performance-wise with its hybrid sibling, offering developers flexibility based on their runtime constraints.“The hybrid variant is a true 1B model. However, the non-hybrid variant is closer to 2B, but we opted to keep the naming aligned to the hybrid variant to make the connection easily visible,” explained Emma, Product Marketing lead for Granite, during a Reddit \"Ask Me Anything\" (AMA) session on r/LocalLLaMA.A Competitive Class of Small ModelsIBM is entering a crowded and rapidly evolving market of small language models (SLMs), competing with offerings like Qwen3, Google&#x27;s Gemma, LiquidAI’s LFM2, and even Mistral’s dense models in the sub-2B parameter space.While OpenAI and Anthropic focus on models that require clusters of GPUs and sophisticated inference optimization, IBM’s Nano family is aimed squarely at developers who want to run performant LLMs on local or constrained hardware.In benchmark testing, IBM’s new models consistently top the charts in their class. According to data shared on X by David Cox, VP of AI Models at IBM Research:On IFEval (instruction following), Granite-4.0-H-1B scored 78.5, outperforming Qwen3-1.7B (73.1) and other 1–2B models.On BFCLv3 (function/tool calling), Granite-4.0-1B led with a score of 54.8, the highest in its size class.On safety benchmarks (SALAD and AttaQ), the Granite models scored over 90%, surpassing similarly sized competitors.Overall, the Granite-4.0-1B achieved a leading average benchmark score of 68.3% across general knowledge, math, code, and safety domains.This performance is especially significant given the hardware constraints these models are designed for. They require less memory, run faster on CPUs or mobile devices, and don’t need cloud infrastructure or GPU acceleration to deliver usable results.Why Model Size Still Matters — But Not Like It Used ToIn the early wave of LLMs, bigger meant better — more parameters translated to better generalization, deeper reasoning, and richer output. But as transformer research matured, it became clear that architecture, training quality, and task-specific tuning could allow smaller models to punch well above their weight class.IBM is banking on this evolution. By releasing open, small models that are competitive in real-world tasks, the company is offering an alternative to the monolithic AI APIs that dominate today’s application stack.In fact, the Nano models address three increasingly important needs:Deployment flexibility — they run anywhere, from mobile to microservers.Inference privacy — users can keep data local with no need to call out to cloud APIs.Openness and auditability — source code and model weights are publicly available under an open license.Community Response and Roadmap SignalsIBM’s Granite team didn’t just launch the models and walk away — they took to Reddit’s open source community r/LocalLLaMA to engage directly with developers. In an AMA-style thread, Emma (Product Marketing, Granite) answered technical questions, addressed concerns about naming conventions, and dropped hints about what’s next.Notable confirmations from the thread:A larger Granite 4.0 model is currently in trainingReasoning-focused models (\"thinking counterparts\") are in the pipelineIBM will release fine-tuning recipes and a full training paper soonMore tooling and platform compatibility is on the roadmapUsers responded enthusiastically to the models’ capabilities, especially in instruction-following and structured response tasks. One commenter summed it up:“This is big if true for a 1B model — if quality is nice and it gives consistent outputs. Function-calling tasks, multilingual dialog, FIM completions… this could be a real workhorse.”Another user remarked:“The Granite Tiny is already my go-to for web search in LM Studio — better than some Qwen models. Tempted to give Nano a shot.”Background: IBM Granite and the Enterprise AI RaceIBM’s push into large language models began in earnest in late 2023 with the debut of the Granite foundation model family, starting with models like Granite.13b.instruct and Granite.13b.chat. Released for use within its Watsonx platform, these initial decoder-only models signaled IBM’s ambition to build enterprise-grade AI systems that prioritize transparency, efficiency, and performance. The company open-sourced select Granite code models under the Apache 2.0 license in mid-2024, laying the groundwork for broader adoption and developer experimentation.The real inflection point came with Granite 3.0 in October 2024 — a fully open-source suite of general-purpose and domain-specialized models ranging from 1B to 8B parameters. These models emphasized efficiency over brute scale, offering capabilities like longer context windows, instruction tuning, and integrated guardrails. IBM positioned Granite 3.0 as a direct competitor to Meta’s Llama, Alibaba’s Qwen, and Google&#x27;s Gemma — but with a uniquely enterprise-first lens. Later versions, including Granite 3.1 and Granite 3.2, introduced even more enterprise-friendly innovations: embedded hallucination detection, time-series forecasting, document vision models, and conditional reasoning toggles.The Granite 4.0 family, launched in October 2025, represents IBM’s most technically ambitious release yet. It introduces a hybrid architecture that blends transformer and Mamba-2 layers — aiming to combine the contextual precision of attention mechanisms with the memory efficiency of state-space models. This design allows IBM to significantly reduce memory and latency costs for inference, making Granite models viable on smaller hardware while still outperforming peers in instruction-following and function-calling tasks. The launch also includes ISO 42001 certification, cryptographic model signing, and distribution across platforms like Hugging Face, Docker, LM Studio, Ollama, and watsonx.ai.Across all iterations, IBM’s focus has been clear: build trustworthy, efficient, and legally unambiguous AI models for enterprise use cases. With a permissive Apache 2.0 license, public benchmarks, and an emphasis on governance, the Granite initiative not only responds to rising concerns over proprietary black-box models but also offers a Western-aligned open alternative to the rapid progress from teams like Alibaba’s Qwen. In doing so, Granite positions IBM as a leading voice in what may be the next phase of open-weight, production-ready AI.A Shift Toward Scalable EfficiencyIn the end, IBM’s release of Granite 4.0 Nano models reflects a strategic shift in LLM development: from chasing parameter count records to optimizing usability, openness, and deployment reach.By combining competitive performance, responsible development practices, and deep engagement with the open-source community, IBM is positioning Granite as not just a family of models — but a platform for building the next generation of lightweight, trustworthy AI systems.For developers and researchers looking for performance without overhead, the Nano release offers a compelling signal: you don’t need 70 billion parameters to build something powerful — just the right ones.",
          "content": "In an industry where model size is often seen as a proxy for intelligence, IBM is charting a different course — one that values efficiency over enormity, and accessibility over abstraction.The 114-year-old tech giant&#x27;s four new Granite 4.0 Nano models, released today, range from just 350 million to 1.5 billion parameters, a fraction of the size of their server-bound cousins from the likes of OpenAI, Anthropic, and Google. These models are designed to be highly accessible: the 350M variants can run comfortably on a modern laptop CPU with 8–16GB of RAM, while the 1.5B models typically require a GPU with at least 6–8GB of VRAM for smooth performance — or sufficient system RAM and swap for CPU-only inference. This makes them well-suited for developers building applications on consumer hardware or at the edge, without relying on cloud compute.In fact, the smallest ones can even run locally on your own web browser, as Joshua Lochner aka Xenova, creator of Transformer.js and a machine learning engineer at Hugging Face, wrote on the social network X.All the Granite 4.0 Nano models are released under the Apache 2.0 license — perfect for use by researchers and enterprise or indie developers, even for commercial usage. They are natively compatible with llama.cpp, vLLM, and MLX and are certified under ISO 42001 for responsible AI development — a standard IBM helped pioneer.But in this case, small doesn&#x27;t mean less capable — it might just mean smarter design.These compact models are built not for data centers, but for edge devices, laptops, and local inference, where compute is scarce and latency matters. And despite their small size, the Nano models are showing benchmark results that rival or even exceed the performance of larger models in the same category. The release is a signal that a new AI frontier is rapidly forming — one not dominated by sheer scale, but by strategic scaling.What Exactly Did IBM Release?The Granite 4.0 Nano family includes four open-source models now available on Hugging Face:Granite-4.0-H-1B (~1.5B parameters) – Hybrid-SSM architectureGranite-4.0-H-350M (~350M parameters) – Hybrid-SSM architectureGranite-4.0-1B – Transformer-based variant, parameter count closer to 2BGranite-4.0-350M – Transformer-based variantThe H-series models — Granite-4.0-H-1B and H-350M — use a hybrid state space architecture (SSM) that combines efficiency with strong performance, ideal for low-latency edge environments. Meanwhile, the standard transformer variants — Granite-4.0-1B and 350M — offer broader compatibility with tools like llama.cpp, designed for use cases where hybrid architecture isn’t yet supported. In practice, the transformer 1B model is closer to 2B parameters, but aligns performance-wise with its hybrid sibling, offering developers flexibility based on their runtime constraints.“The hybrid variant is a true 1B model. However, the non-hybrid variant is closer to 2B, but we opted to keep the naming aligned to the hybrid variant to make the connection easily visible,” explained Emma, Product Marketing lead for Granite, during a Reddit \"Ask Me Anything\" (AMA) session on r/LocalLLaMA.A Competitive Class of Small ModelsIBM is entering a crowded and rapidly evolving market of small language models (SLMs), competing with offerings like Qwen3, Google&#x27;s Gemma, LiquidAI’s LFM2, and even Mistral’s dense models in the sub-2B parameter space.While OpenAI and Anthropic focus on models that require clusters of GPUs and sophisticated inference optimization, IBM’s Nano family is aimed squarely at developers who want to run performant LLMs on local or constrained hardware.In benchmark testing, IBM’s new models consistently top the charts in their class. According to data shared on X by David Cox, VP of AI Models at IBM Research:On IFEval (instruction following), Granite-4.0-H-1B scored 78.5, outperforming Qwen3-1.7B (73.1) and other 1–2B models.On BFCLv3 (function/tool calling), Granite-4.0-1B led with a score of 54.8, the highest in its size class.On safety benchmarks (SALAD and AttaQ), the Granite models scored over 90%, surpassing similarly sized competitors.Overall, the Granite-4.0-1B achieved a leading average benchmark score of 68.3% across general knowledge, math, code, and safety domains.This performance is especially significant given the hardware constraints these models are designed for. They require less memory, run faster on CPUs or mobile devices, and don’t need cloud infrastructure or GPU acceleration to deliver usable results.Why Model Size Still Matters — But Not Like It Used ToIn the early wave of LLMs, bigger meant better — more parameters translated to better generalization, deeper reasoning, and richer output. But as transformer research matured, it became clear that architecture, training quality, and task-specific tuning could allow smaller models to punch well above their weight class.IBM is banking on this evolution. By releasing open, small models that are competitive in real-world tasks, the company is offering an alternative to the monolithic AI APIs that dominate today’s application stack.In fact, the Nano models address three increasingly important needs:Deployment flexibility — they run anywhere, from mobile to microservers.Inference privacy — users can keep data local with no need to call out to cloud APIs.Openness and auditability — source code and model weights are publicly available under an open license.Community Response and Roadmap SignalsIBM’s Granite team didn’t just launch the models and walk away — they took to Reddit’s open source community r/LocalLLaMA to engage directly with developers. In an AMA-style thread, Emma (Product Marketing, Granite) answered technical questions, addressed concerns about naming conventions, and dropped hints about what’s next.Notable confirmations from the thread:A larger Granite 4.0 model is currently in trainingReasoning-focused models (\"thinking counterparts\") are in the pipelineIBM will release fine-tuning recipes and a full training paper soonMore tooling and platform compatibility is on the roadmapUsers responded enthusiastically to the models’ capabilities, especially in instruction-following and structured response tasks. One commenter summed it up:“This is big if true for a 1B model — if quality is nice and it gives consistent outputs. Function-calling tasks, multilingual dialog, FIM completions… this could be a real workhorse.”Another user remarked:“The Granite Tiny is already my go-to for web search in LM Studio — better than some Qwen models. Tempted to give Nano a shot.”Background: IBM Granite and the Enterprise AI RaceIBM’s push into large language models began in earnest in late 2023 with the debut of the Granite foundation model family, starting with models like Granite.13b.instruct and Granite.13b.chat. Released for use within its Watsonx platform, these initial decoder-only models signaled IBM’s ambition to build enterprise-grade AI systems that prioritize transparency, efficiency, and performance. The company open-sourced select Granite code models under the Apache 2.0 license in mid-2024, laying the groundwork for broader adoption and developer experimentation.The real inflection point came with Granite 3.0 in October 2024 — a fully open-source suite of general-purpose and domain-specialized models ranging from 1B to 8B parameters. These models emphasized efficiency over brute scale, offering capabilities like longer context windows, instruction tuning, and integrated guardrails. IBM positioned Granite 3.0 as a direct competitor to Meta’s Llama, Alibaba’s Qwen, and Google&#x27;s Gemma — but with a uniquely enterprise-first lens. Later versions, including Granite 3.1 and Granite 3.2, introduced even more enterprise-friendly innovations: embedded hallucination detection, time-series forecasting, document vision models, and conditional reasoning toggles.The Granite 4.0 family, launched in October 2025, represents IBM’s most technically ambitious release yet. It introduces a hybrid architecture that blends transformer and Mamba-2 layers — aiming to combine the contextual precision of attention mechanisms with the memory efficiency of state-space models. This design allows IBM to significantly reduce memory and latency costs for inference, making Granite models viable on smaller hardware while still outperforming peers in instruction-following and function-calling tasks. The launch also includes ISO 42001 certification, cryptographic model signing, and distribution across platforms like Hugging Face, Docker, LM Studio, Ollama, and watsonx.ai.Across all iterations, IBM’s focus has been clear: build trustworthy, efficient, and legally unambiguous AI models for enterprise use cases. With a permissive Apache 2.0 license, public benchmarks, and an emphasis on governance, the Granite initiative not only responds to rising concerns over proprietary black-box models but also offers a Western-aligned open alternative to the rapid progress from teams like Alibaba’s Qwen. In doing so, Granite positions IBM as a leading voice in what may be the next phase of open-weight, production-ready AI.A Shift Toward Scalable EfficiencyIn the end, IBM’s release of Granite 4.0 Nano models reflects a strategic shift in LLM development: from chasing parameter count records to optimizing usability, openness, and deployment reach.By combining competitive performance, responsible development practices, and deep engagement with the open-source community, IBM is positioning Granite as not just a family of models — but a platform for building the next generation of lightweight, trustworthy AI systems.For developers and researchers looking for performance without overhead, the Nano release offers a compelling signal: you don’t need 70 billion parameters to build something powerful — just the right ones.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4rwJWqsHkQ8TmY86sokH5j/cf400e028ed640c8e65f6bec9134c149/cfr0z3n_Flat_illustration_neon_pink_and_oranges_on_blue_backdro_3059ee39-d179-4b1b-9d52-a4264f21e970.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/microsofts-copilot-can-now-build-apps-and-automate-your-job-heres-how-it",
          "published_at": "Tue, 28 Oct 2025 20:30:00 GMT",
          "title": "Microsoft’s Copilot can now build apps and automate your job — here’s how it works",
          "standfirst": "Microsoft is launching a significant expansion of its Copilot AI assistant on Tuesday, introducing tools that let employees build applications, automate workflows, and create specialized AI agents using only conversational prompts — no coding required.The new capabilities, called App Builder and Workflows, mark Microsoft&#x27;s most aggressive attempt yet to merge artificial intelligence with software development, enabling the estimated 100 million Microsoft 365 users to create business tools as easily as they currently draft emails or build spreadsheets.\"We really believe that a main part of an AI-forward employee, not just developers, will be to create agents, workflows and apps,\" Charles Lamanna, Microsoft&#x27;s president of business and industry Copilot, said in an interview with VentureBeat. \"Part of the job will be to build and create these things.\"The announcement comes as Microsoft deepens its commitment to AI-powered productivity tools while navigating a complex partnership with OpenAI, the creator of the underlying technology that powers Copilot. On the same day, OpenAI completed its restructuring into a for-profit entity, with Microsoft receiving a 27% ownership stake valued at approximately $135 billion.How natural language prompts now create fully functional business applicationsThe new features transform Copilot from a conversational assistant into what Microsoft envisions as a comprehensive development environment accessible to non-technical workers. Users can now describe an application they need — such as a project tracker with dashboards and task assignments — and Copilot will generate a working app complete with a database backend, user interface, and security controls.\"If you&#x27;re right inside of Copilot, you can now have a conversation to build an application complete with a backing database and a security model,\" Lamanna explained. \"You can make edit requests and update requests and change requests so you can tune the app to get exactly the experience you want before you share it with other users.\"The App Builder stores data in Microsoft Lists, the company&#x27;s lightweight database system, and allows users to share finished applications via a simple link—similar to sharing a document. The Workflows agent, meanwhile, automates routine tasks across Microsoft&#x27;s ecosystem of products, including Outlook, Teams, SharePoint, and Planner, by converting natural language descriptions into automated processes.A third component, a simplified version of Microsoft&#x27;s Copilot Studio agent-building platform, lets users create specialized AI assistants tailored to specific tasks or knowledge domains, drawing from SharePoint documents, meeting transcripts, emails, and external systems.All three capabilities are included in the existing $30-per-month Microsoft 365 Copilot subscription at no additional cost — a pricing decision Lamanna characterized as consistent with Microsoft&#x27;s historical approach of bundling significant value into its productivity suite.\"That&#x27;s what Microsoft always does. We try to do a huge amount of value at a low price,\" he said. \"If you go look at Office, you think about Excel, Word, PowerPoint, Exchange, all that for like eight bucks a month. That&#x27;s a pretty good deal.\"Why Microsoft&#x27;s nine-year bet on low-code development is finally paying offThe new tools represent the culmination of a nine-year effort by Microsoft to democratize software development through its Power Platform — a collection of low-code and no-code development tools that has grown to 56 million monthly active users, according to figures the company disclosed in recent earnings reports.Lamanna, who has led the Power Platform initiative since its inception, said the integration into Copilot marks a fundamental shift in how these capabilities reach users. Rather than requiring workers to visit a separate website or learn a specialized interface, the development tools now exist within the same conversational window they already use for AI-assisted tasks.\"One of the big things that we&#x27;re excited about is Copilot — that&#x27;s a tool for literally every office worker,\" Lamanna said. \"Every office worker, just like they research data, they analyze data, they reason over topics, they also will be creating apps, agents and workflows.\"The integration offers significant technical advantages, he argued. Because Copilot already indexes a user&#x27;s Microsoft 365 content — emails, documents, meetings, and organizational data — it can incorporate that context into the applications and workflows it builds. If a user asks for \"an app for Project Spartan,\" Copilot can draw from existing communications to understand what that project entails and suggest relevant features.\"If you go to those other tools, they have no idea what the heck Project Spartan is,\" Lamanna said, referencing competing low-code platforms from companies like Google, Salesforce, and ServiceNow. \"But if you do it inside of Copilot and inside of the App Builder, it&#x27;s able to draw from all that information and context.\"Microsoft claims the apps created through these tools are \"full-stack applications\" with proper databases secured through the same identity systems used across its enterprise products — distinguishing them from simpler front-end tools offered by competitors. The company also emphasized that its existing governance, security, and data loss prevention policies automatically apply to apps and workflows created through Copilot.Where professional developers still matter in an AI-powered workplaceWhile Microsoft positions the new capabilities as accessible to all office workers, Lamanna was careful to delineate where professional developers remain essential. His dividing line centers on whether a system interacts with parties outside the organization.\"Anything that leaves the boundaries of your company warrants developer involvement,\" he said. \"If you want to build an agent and put it on your website, you should have developers involved. Or if you want to build an automation which interfaces directly with your customers, or an app or a website which interfaces directly with your customers, you want professionals involved.\"The reasoning is risk-based: external-facing systems carry greater potential for data breaches, security vulnerabilities, or business errors. \"You don&#x27;t want people getting refunds they shouldn&#x27;t,\" Lamanna noted.For internal use cases — approval workflows, project tracking, team dashboards — Microsoft believes the new tools can handle the majority of needs without IT department involvement. But the company has built \"no cliffs,\" in Lamanna&#x27;s terminology, allowing users to migrate simple apps to more sophisticated platforms as needs grow.Apps created in the conversational App Builder can be opened in Power Apps, Microsoft&#x27;s full development environment, where they can be connected to Dataverse, the company&#x27;s enterprise database, or extended with custom code. Similarly, simple workflows can graduate to the full Power Automate platform, and basic agents can be enhanced in the complete Copilot Studio.\"We have this mantra called no cliffs,\" Lamanna said. \"If your app gets too complicated for the App Builder, you can always edit and open it in Power Apps. You can jump over to the richer experience, and if you&#x27;re really sophisticated, you can even go from those experiences into Azure.\"This architecture addresses a problem that has plagued previous generations of easy-to-use development tools: users who outgrow the simplified environment often must rebuild from scratch on professional platforms. \"People really do not like easy-to-use development tools if I have to throw everything away and start over,\" Lamanna said.What happens when every employee can build apps without IT approvalThe democratization of software development raises questions about governance, maintenance, and organizational complexity — issues Microsoft has worked to address through administrative controls.IT administrators can view all applications, workflows, and agents created within their organization through a centralized inventory in the Microsoft 365 admin center. They can reassign ownership, disable access at the group level, or \"promote\" particularly useful employee-created apps to officially supported status.\"We have a bunch of customers who have this approach where it&#x27;s like, let 1,000 apps bloom, and then the best ones, I go upgrade and make them IT-governed or central,\" Lamanna said.The system also includes provisions for when employees leave. Apps and workflows remain accessible for 60 days, during which managers can claim ownership — similar to how OneDrive files are handled when someone departs.Lamanna argued that most employee-created apps don&#x27;t warrant significant IT oversight. \"It&#x27;s just not worth inspecting an app that John, Susie, and Bob use to do their job,\" he said. \"It should concern itself with the app that ends up being used by 2,000 people, and that will pop up in that dashboard.\"Still, the proliferation of employee-created applications could create challenges. Users have expressed frustration with Microsoft&#x27;s increasing emphasis on AI features across its products, with some giving the Microsoft 365 mobile app one-star ratings after a recent update prioritized Copilot over traditional file access.The tools also arrive as enterprises grapple with \"shadow IT\" — unsanctioned software and systems that employees adopt without official approval. While Microsoft&#x27;s governance controls aim to provide visibility, the ease of creating new applications could accelerate the pace at which these systems multiply.The ambitious plan to turn 500 million workers into software buildersMicrosoft&#x27;s ambitions for the technology extend far beyond incremental productivity gains. Lamanna envisions a fundamental transformation of what it means to be an office worker — one where building software becomes as routine as creating spreadsheets.\"Just like how 20 years ago you put on your resume that you could use pivot tables in Excel, people are going to start saying that they can use App Builder and workflow agents, even if they&#x27;re just in the finance department or the sales department,\" he said.The numbers he&#x27;s targeting are staggering. With 56 million people already using Power Platform, Lamanna believes the integration into Copilot could eventually reach 500 million builders. \"Early days still, but I think it&#x27;s certainly encouraging,\" he said.The features are currently available only to customers in Microsoft&#x27;s Frontier Program — an early access initiative for Microsoft 365 Copilot subscribers. The company has not disclosed how many organizations participate in the program or when the tools will reach general availability.The announcement fits within Microsoft&#x27;s larger strategy of embedding AI capabilities throughout its product portfolio, driven by its partnership with OpenAI. Under the restructured agreement announced Tuesday, Microsoft will have access to OpenAI&#x27;s technology through 2032, including models that achieve artificial general intelligence (AGI) — though such systems do not yet exist. Microsoft has also begun integrating Copilot into its new companion apps for Windows 11, which provide quick access to contacts, files, and calendar information.The aggressive integration of AI features across Microsoft&#x27;s ecosystem has drawn mixed reactions. While enterprise customers have shown interest in productivity gains, the rapid pace of change and ubiquity of AI prompts have frustrated some users who prefer traditional workflows.For Microsoft, however, the calculation is clear: if even a fraction of its user base begins creating applications and automations, it would represent a massive expansion of the effective software development workforce — and further entrench customers in Microsoft&#x27;s ecosystem. The company is betting that the same natural language interface that made ChatGPT accessible to millions can finally unlock the decades-old promise of empowering everyday workers to build their own tools.The App Builder and Workflows agents are available starting today through the Microsoft 365 Copilot Agent Store for Frontier Program participants.Whether that future arrives depends not just on the technology&#x27;s capabilities, but on a more fundamental question: Do millions of office workers actually want to become part-time software developers? Microsoft is about to find out if the answer is yes — or if some jobs are better left to the professionals.",
          "content": "Microsoft is launching a significant expansion of its Copilot AI assistant on Tuesday, introducing tools that let employees build applications, automate workflows, and create specialized AI agents using only conversational prompts — no coding required.The new capabilities, called App Builder and Workflows, mark Microsoft&#x27;s most aggressive attempt yet to merge artificial intelligence with software development, enabling the estimated 100 million Microsoft 365 users to create business tools as easily as they currently draft emails or build spreadsheets.\"We really believe that a main part of an AI-forward employee, not just developers, will be to create agents, workflows and apps,\" Charles Lamanna, Microsoft&#x27;s president of business and industry Copilot, said in an interview with VentureBeat. \"Part of the job will be to build and create these things.\"The announcement comes as Microsoft deepens its commitment to AI-powered productivity tools while navigating a complex partnership with OpenAI, the creator of the underlying technology that powers Copilot. On the same day, OpenAI completed its restructuring into a for-profit entity, with Microsoft receiving a 27% ownership stake valued at approximately $135 billion.How natural language prompts now create fully functional business applicationsThe new features transform Copilot from a conversational assistant into what Microsoft envisions as a comprehensive development environment accessible to non-technical workers. Users can now describe an application they need — such as a project tracker with dashboards and task assignments — and Copilot will generate a working app complete with a database backend, user interface, and security controls.\"If you&#x27;re right inside of Copilot, you can now have a conversation to build an application complete with a backing database and a security model,\" Lamanna explained. \"You can make edit requests and update requests and change requests so you can tune the app to get exactly the experience you want before you share it with other users.\"The App Builder stores data in Microsoft Lists, the company&#x27;s lightweight database system, and allows users to share finished applications via a simple link—similar to sharing a document. The Workflows agent, meanwhile, automates routine tasks across Microsoft&#x27;s ecosystem of products, including Outlook, Teams, SharePoint, and Planner, by converting natural language descriptions into automated processes.A third component, a simplified version of Microsoft&#x27;s Copilot Studio agent-building platform, lets users create specialized AI assistants tailored to specific tasks or knowledge domains, drawing from SharePoint documents, meeting transcripts, emails, and external systems.All three capabilities are included in the existing $30-per-month Microsoft 365 Copilot subscription at no additional cost — a pricing decision Lamanna characterized as consistent with Microsoft&#x27;s historical approach of bundling significant value into its productivity suite.\"That&#x27;s what Microsoft always does. We try to do a huge amount of value at a low price,\" he said. \"If you go look at Office, you think about Excel, Word, PowerPoint, Exchange, all that for like eight bucks a month. That&#x27;s a pretty good deal.\"Why Microsoft&#x27;s nine-year bet on low-code development is finally paying offThe new tools represent the culmination of a nine-year effort by Microsoft to democratize software development through its Power Platform — a collection of low-code and no-code development tools that has grown to 56 million monthly active users, according to figures the company disclosed in recent earnings reports.Lamanna, who has led the Power Platform initiative since its inception, said the integration into Copilot marks a fundamental shift in how these capabilities reach users. Rather than requiring workers to visit a separate website or learn a specialized interface, the development tools now exist within the same conversational window they already use for AI-assisted tasks.\"One of the big things that we&#x27;re excited about is Copilot — that&#x27;s a tool for literally every office worker,\" Lamanna said. \"Every office worker, just like they research data, they analyze data, they reason over topics, they also will be creating apps, agents and workflows.\"The integration offers significant technical advantages, he argued. Because Copilot already indexes a user&#x27;s Microsoft 365 content — emails, documents, meetings, and organizational data — it can incorporate that context into the applications and workflows it builds. If a user asks for \"an app for Project Spartan,\" Copilot can draw from existing communications to understand what that project entails and suggest relevant features.\"If you go to those other tools, they have no idea what the heck Project Spartan is,\" Lamanna said, referencing competing low-code platforms from companies like Google, Salesforce, and ServiceNow. \"But if you do it inside of Copilot and inside of the App Builder, it&#x27;s able to draw from all that information and context.\"Microsoft claims the apps created through these tools are \"full-stack applications\" with proper databases secured through the same identity systems used across its enterprise products — distinguishing them from simpler front-end tools offered by competitors. The company also emphasized that its existing governance, security, and data loss prevention policies automatically apply to apps and workflows created through Copilot.Where professional developers still matter in an AI-powered workplaceWhile Microsoft positions the new capabilities as accessible to all office workers, Lamanna was careful to delineate where professional developers remain essential. His dividing line centers on whether a system interacts with parties outside the organization.\"Anything that leaves the boundaries of your company warrants developer involvement,\" he said. \"If you want to build an agent and put it on your website, you should have developers involved. Or if you want to build an automation which interfaces directly with your customers, or an app or a website which interfaces directly with your customers, you want professionals involved.\"The reasoning is risk-based: external-facing systems carry greater potential for data breaches, security vulnerabilities, or business errors. \"You don&#x27;t want people getting refunds they shouldn&#x27;t,\" Lamanna noted.For internal use cases — approval workflows, project tracking, team dashboards — Microsoft believes the new tools can handle the majority of needs without IT department involvement. But the company has built \"no cliffs,\" in Lamanna&#x27;s terminology, allowing users to migrate simple apps to more sophisticated platforms as needs grow.Apps created in the conversational App Builder can be opened in Power Apps, Microsoft&#x27;s full development environment, where they can be connected to Dataverse, the company&#x27;s enterprise database, or extended with custom code. Similarly, simple workflows can graduate to the full Power Automate platform, and basic agents can be enhanced in the complete Copilot Studio.\"We have this mantra called no cliffs,\" Lamanna said. \"If your app gets too complicated for the App Builder, you can always edit and open it in Power Apps. You can jump over to the richer experience, and if you&#x27;re really sophisticated, you can even go from those experiences into Azure.\"This architecture addresses a problem that has plagued previous generations of easy-to-use development tools: users who outgrow the simplified environment often must rebuild from scratch on professional platforms. \"People really do not like easy-to-use development tools if I have to throw everything away and start over,\" Lamanna said.What happens when every employee can build apps without IT approvalThe democratization of software development raises questions about governance, maintenance, and organizational complexity — issues Microsoft has worked to address through administrative controls.IT administrators can view all applications, workflows, and agents created within their organization through a centralized inventory in the Microsoft 365 admin center. They can reassign ownership, disable access at the group level, or \"promote\" particularly useful employee-created apps to officially supported status.\"We have a bunch of customers who have this approach where it&#x27;s like, let 1,000 apps bloom, and then the best ones, I go upgrade and make them IT-governed or central,\" Lamanna said.The system also includes provisions for when employees leave. Apps and workflows remain accessible for 60 days, during which managers can claim ownership — similar to how OneDrive files are handled when someone departs.Lamanna argued that most employee-created apps don&#x27;t warrant significant IT oversight. \"It&#x27;s just not worth inspecting an app that John, Susie, and Bob use to do their job,\" he said. \"It should concern itself with the app that ends up being used by 2,000 people, and that will pop up in that dashboard.\"Still, the proliferation of employee-created applications could create challenges. Users have expressed frustration with Microsoft&#x27;s increasing emphasis on AI features across its products, with some giving the Microsoft 365 mobile app one-star ratings after a recent update prioritized Copilot over traditional file access.The tools also arrive as enterprises grapple with \"shadow IT\" — unsanctioned software and systems that employees adopt without official approval. While Microsoft&#x27;s governance controls aim to provide visibility, the ease of creating new applications could accelerate the pace at which these systems multiply.The ambitious plan to turn 500 million workers into software buildersMicrosoft&#x27;s ambitions for the technology extend far beyond incremental productivity gains. Lamanna envisions a fundamental transformation of what it means to be an office worker — one where building software becomes as routine as creating spreadsheets.\"Just like how 20 years ago you put on your resume that you could use pivot tables in Excel, people are going to start saying that they can use App Builder and workflow agents, even if they&#x27;re just in the finance department or the sales department,\" he said.The numbers he&#x27;s targeting are staggering. With 56 million people already using Power Platform, Lamanna believes the integration into Copilot could eventually reach 500 million builders. \"Early days still, but I think it&#x27;s certainly encouraging,\" he said.The features are currently available only to customers in Microsoft&#x27;s Frontier Program — an early access initiative for Microsoft 365 Copilot subscribers. The company has not disclosed how many organizations participate in the program or when the tools will reach general availability.The announcement fits within Microsoft&#x27;s larger strategy of embedding AI capabilities throughout its product portfolio, driven by its partnership with OpenAI. Under the restructured agreement announced Tuesday, Microsoft will have access to OpenAI&#x27;s technology through 2032, including models that achieve artificial general intelligence (AGI) — though such systems do not yet exist. Microsoft has also begun integrating Copilot into its new companion apps for Windows 11, which provide quick access to contacts, files, and calendar information.The aggressive integration of AI features across Microsoft&#x27;s ecosystem has drawn mixed reactions. While enterprise customers have shown interest in productivity gains, the rapid pace of change and ubiquity of AI prompts have frustrated some users who prefer traditional workflows.For Microsoft, however, the calculation is clear: if even a fraction of its user base begins creating applications and automations, it would represent a massive expansion of the effective software development workforce — and further entrench customers in Microsoft&#x27;s ecosystem. The company is betting that the same natural language interface that made ChatGPT accessible to millions can finally unlock the decades-old promise of empowering everyday workers to build their own tools.The App Builder and Workflows agents are available starting today through the Microsoft 365 Copilot Agent Store for Frontier Program participants.Whether that future arrives depends not just on the technology&#x27;s capabilities, but on a more fundamental question: Do millions of office workers actually want to become part-time software developers? Microsoft is about to find out if the answer is yes — or if some jobs are better left to the professionals.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/33TsQdgl9KxQ34lyEgCUfW/9faff55fd9a871ab3cd21f735ed87cba/nuneybits_Vector_art_of_Microsoft_Windows_desktop_computer_mode_5869d092-9156-48dc-bf50-37d2ff6b0cf3.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/fortanix-and-nvidia-partner-on-ai-security-platform-for-highly-regulated",
          "published_at": "Tue, 28 Oct 2025 18:57:00 GMT",
          "title": "Fortanix and NVIDIA partner on AI security platform for highly regulated industries",
          "standfirst": "Data security company Fortanix Inc. announced a new joint solution with NVIDIA: a turnkey platform that allows organizations to deploy agentic AI within their own data centers or sovereign environments, backed by NVIDIA’s \"confidential computing\" GPUs.“Our goal is to make AI trustworthy by securing every layer—from the chip to the model to the data,\" said Fortanix CEO and co-founder Anand Kashyap, in a recent video call interview with VentureBeat. \"Confidential computing gives you that end-to-end trust so you can confidently use AI with sensitive or regulated information.”The solution arrives at a pivotal moment for industries such as healthcare, finance, and government — sectors eager to embrace AI but constrained by strict privacy and regulatory requirements.Fortanix’s new platform, powered by NVIDIA Confidential Computing, enables enterprises to build and run AI systems on sensitive data without sacrificing security or control.“Enterprises in finance, healthcare and government want to harness the power of AI, but compromising on trust, compliance, or control creates insurmountable risk,” said Anuj Jaiswal, chief product officer at Fortanix, in a press release. “We’re giving enterprises a sovereign, on-prem platform for AI agents—one that proves what’s running, protects what matters, and gets them to production faster.”Secure AI, Verified from Chip to ModelAt the heart of the Fortanix–NVIDIA collaboration is a confidential AI pipeline that ensures data, models, and workflows remain protected throughout their lifecycle. The system uses a combination of Fortanix Data Security Manager (DSM) and Fortanix Confidential Computing Manager (CCM), integrated directly into NVIDIA’s GPU architecture.“You can think of DSM as the vault that holds your keys, and CCM as the gatekeeper that verifies who’s allowed to use them,\" Kashyap said. \"DSM enforces policy, CCM enforces trust.”DSM serves as a FIPS 140-2 Level 3 hardware security module that manages encryption keys and enforces strict access controls. CCM, introduced alongside this announcement, verifies the trustworthiness of AI workloads and infrastructure using composite attestation—a process that validates both CPUs and GPUs before allowing access to sensitive data.Only when a workload is verified by CCM does DSM release the cryptographic keys necessary to decrypt and process data. “The Confidential Computing Manager checks that the workload, the CPU, and the GPU are running in a trusted state,\" explained Kashyap. \"It issues a certificate that DSM validates before releasing the key. That ensures the right workload is running on the right hardware before any sensitive data is decrypted.”This “attestation-gated” model creates what Fortanix describes as a provable chain of trust extending from the hardware chip to the application layer. It’s an approach aimed squarely at industries where confidentiality and compliance are non-negotiable.From Pilot to Production—Without the Security Trade-OffAccording to Kashyap, the partnership marks a step forward from traditional data encryption and key management toward securing entire AI workloads. Kashyap explained that enterprises can deploy the Fortanix–NVIDIA solution incrementally, using a lift-and-shift model to migrate existing AI workloads into a confidential environment. “We offer two form factors: SaaS with zero footprint, and self-managed. Self-managed can be a virtual appliance or a 1U physical FIPS 140-2 Level 3 appliance,\" he noted. \"The smallest deployment is a three-node cluster, with larger clusters of 20–30 nodes or more.” Customers already running AI models—whether open-source or proprietary—can move them onto NVIDIA’s Hopper or Blackwell GPU architectures with minimal reconfiguration. For organizations building out new AI infrastructure, Fortanix’s Armet AI platform provides orchestration, observability, and built-in guardrails to speed up time to production. “The result is that enterprises can move from pilot projects to trusted, production-ready AI in days rather than months,” Jaiswal said.Compliance by DesignCompliance remains a key driver behind the new platform’s design. Fortanix’s DSM enforces role-based access control, detailed audit logging, and secure key custody—elements that help enterprises demonstrate compliance with stringent data protection regulations. These controls are essential for regulated industries such as banking, healthcare, and government contracting.The company emphasizes that the solution is built for both confidentiality and sovereignty. For governments and enterprises that must retain local control over their AI environments, the system supports fully on-premises or air-gapped deployment options. Fortanix and NVIDIA have jointly integrated these technologies into the NVIDIA AI Factory Reference Design for Government, a blueprint for building secure national or enterprise-level AI systems.Future-Proofed for a Post-Quantum EraIn addition to current encryption standards such as AES, Fortanix supports post-quantum cryptography (PQC) within its DSM product. As global research in quantum computing accelerates, PQC algorithms are expected to become a critical component of secure computing frameworks. “We don’t invent cryptography; we implement what’s proven,” Kashyap said. “But we also make sure our customers are ready for the post-quantum era when it arrives.”Real-World FlexibilityWhile the platform is designed for on-premises and sovereign use cases, Kashyap emphasized that it can also run in major cloud environments that already support confidential computing. Enterprises operating across multiple regions can maintain consistent key management and encryption controls, either through centralized key hosting or replicated key clusters. This flexibility allows organizations to shift AI workloads between data centers or cloud regions—whether for performance optimization, redundancy, or regulatory reasons—without losing control over their sensitive information.Fortanix converts usage into “credits,” which correspond to the number of AI instances running within a factory environment. The structure allows enterprises to scale incrementally as their AI projects grow.Fortanix will showcase the joint platform at NVIDIA GTC, held October 27–29, 2025, at the Walter E. Washington Convention Center in Washington, D.C. Visitors can find Fortanix at booth I-7 for live demonstrations and discussions on securing AI workloads in highly regulated environments.About FortanixFortanix Inc. was founded in 2016 in Mountain View, California, by Anand Kashyap and Ambuj Kumar, both former Intel engineers who worked on trusted execution and encryption technologies. The company was created to commercialize confidential computing—then an emerging concept—by extending the security of encrypted data beyond storage and transmission to data in active use, according to TechCrunch and the company’s own About page.Kashyap, who previously served as a senior security architect at Intel and VMware, and Kumar, a former engineering lead at Intel, drew on years of work in trusted hardware and virtualization systems. Their shared insight into the gap between research-grade cryptography and enterprise adoption drove them to found Fortanix, according to Forbes and Crunchbase.Today, Fortanix is recognized as a global leader in confidential computing and data security, offering solutions that protect data across its lifecycle—at rest, in transit, and in use. Fortanix serves enterprises and governments worldwide with deployments ranging from cloud-native services to high-security, air-gapped systems.\"Historically we provided encryption and key-management capabilities,\" Kashyap said. \"Now we’re going further to secure the workload itself—specifically AI—so an entire AI pipeline can run protected with confidential computing. That applies whether the AI runs in the cloud or in a sovereign environment handling sensitive or regulated data.",
          "content": "Data security company Fortanix Inc. announced a new joint solution with NVIDIA: a turnkey platform that allows organizations to deploy agentic AI within their own data centers or sovereign environments, backed by NVIDIA’s \"confidential computing\" GPUs.“Our goal is to make AI trustworthy by securing every layer—from the chip to the model to the data,\" said Fortanix CEO and co-founder Anand Kashyap, in a recent video call interview with VentureBeat. \"Confidential computing gives you that end-to-end trust so you can confidently use AI with sensitive or regulated information.”The solution arrives at a pivotal moment for industries such as healthcare, finance, and government — sectors eager to embrace AI but constrained by strict privacy and regulatory requirements.Fortanix’s new platform, powered by NVIDIA Confidential Computing, enables enterprises to build and run AI systems on sensitive data without sacrificing security or control.“Enterprises in finance, healthcare and government want to harness the power of AI, but compromising on trust, compliance, or control creates insurmountable risk,” said Anuj Jaiswal, chief product officer at Fortanix, in a press release. “We’re giving enterprises a sovereign, on-prem platform for AI agents—one that proves what’s running, protects what matters, and gets them to production faster.”Secure AI, Verified from Chip to ModelAt the heart of the Fortanix–NVIDIA collaboration is a confidential AI pipeline that ensures data, models, and workflows remain protected throughout their lifecycle. The system uses a combination of Fortanix Data Security Manager (DSM) and Fortanix Confidential Computing Manager (CCM), integrated directly into NVIDIA’s GPU architecture.“You can think of DSM as the vault that holds your keys, and CCM as the gatekeeper that verifies who’s allowed to use them,\" Kashyap said. \"DSM enforces policy, CCM enforces trust.”DSM serves as a FIPS 140-2 Level 3 hardware security module that manages encryption keys and enforces strict access controls. CCM, introduced alongside this announcement, verifies the trustworthiness of AI workloads and infrastructure using composite attestation—a process that validates both CPUs and GPUs before allowing access to sensitive data.Only when a workload is verified by CCM does DSM release the cryptographic keys necessary to decrypt and process data. “The Confidential Computing Manager checks that the workload, the CPU, and the GPU are running in a trusted state,\" explained Kashyap. \"It issues a certificate that DSM validates before releasing the key. That ensures the right workload is running on the right hardware before any sensitive data is decrypted.”This “attestation-gated” model creates what Fortanix describes as a provable chain of trust extending from the hardware chip to the application layer. It’s an approach aimed squarely at industries where confidentiality and compliance are non-negotiable.From Pilot to Production—Without the Security Trade-OffAccording to Kashyap, the partnership marks a step forward from traditional data encryption and key management toward securing entire AI workloads. Kashyap explained that enterprises can deploy the Fortanix–NVIDIA solution incrementally, using a lift-and-shift model to migrate existing AI workloads into a confidential environment. “We offer two form factors: SaaS with zero footprint, and self-managed. Self-managed can be a virtual appliance or a 1U physical FIPS 140-2 Level 3 appliance,\" he noted. \"The smallest deployment is a three-node cluster, with larger clusters of 20–30 nodes or more.” Customers already running AI models—whether open-source or proprietary—can move them onto NVIDIA’s Hopper or Blackwell GPU architectures with minimal reconfiguration. For organizations building out new AI infrastructure, Fortanix’s Armet AI platform provides orchestration, observability, and built-in guardrails to speed up time to production. “The result is that enterprises can move from pilot projects to trusted, production-ready AI in days rather than months,” Jaiswal said.Compliance by DesignCompliance remains a key driver behind the new platform’s design. Fortanix’s DSM enforces role-based access control, detailed audit logging, and secure key custody—elements that help enterprises demonstrate compliance with stringent data protection regulations. These controls are essential for regulated industries such as banking, healthcare, and government contracting.The company emphasizes that the solution is built for both confidentiality and sovereignty. For governments and enterprises that must retain local control over their AI environments, the system supports fully on-premises or air-gapped deployment options. Fortanix and NVIDIA have jointly integrated these technologies into the NVIDIA AI Factory Reference Design for Government, a blueprint for building secure national or enterprise-level AI systems.Future-Proofed for a Post-Quantum EraIn addition to current encryption standards such as AES, Fortanix supports post-quantum cryptography (PQC) within its DSM product. As global research in quantum computing accelerates, PQC algorithms are expected to become a critical component of secure computing frameworks. “We don’t invent cryptography; we implement what’s proven,” Kashyap said. “But we also make sure our customers are ready for the post-quantum era when it arrives.”Real-World FlexibilityWhile the platform is designed for on-premises and sovereign use cases, Kashyap emphasized that it can also run in major cloud environments that already support confidential computing. Enterprises operating across multiple regions can maintain consistent key management and encryption controls, either through centralized key hosting or replicated key clusters. This flexibility allows organizations to shift AI workloads between data centers or cloud regions—whether for performance optimization, redundancy, or regulatory reasons—without losing control over their sensitive information.Fortanix converts usage into “credits,” which correspond to the number of AI instances running within a factory environment. The structure allows enterprises to scale incrementally as their AI projects grow.Fortanix will showcase the joint platform at NVIDIA GTC, held October 27–29, 2025, at the Walter E. Washington Convention Center in Washington, D.C. Visitors can find Fortanix at booth I-7 for live demonstrations and discussions on securing AI workloads in highly regulated environments.About FortanixFortanix Inc. was founded in 2016 in Mountain View, California, by Anand Kashyap and Ambuj Kumar, both former Intel engineers who worked on trusted execution and encryption technologies. The company was created to commercialize confidential computing—then an emerging concept—by extending the security of encrypted data beyond storage and transmission to data in active use, according to TechCrunch and the company’s own About page.Kashyap, who previously served as a senior security architect at Intel and VMware, and Kumar, a former engineering lead at Intel, drew on years of work in trusted hardware and virtualization systems. Their shared insight into the gap between research-grade cryptography and enterprise adoption drove them to found Fortanix, according to Forbes and Crunchbase.Today, Fortanix is recognized as a global leader in confidential computing and data security, offering solutions that protect data across its lifecycle—at rest, in transit, and in use. Fortanix serves enterprises and governments worldwide with deployments ranging from cloud-native services to high-security, air-gapped systems.\"Historically we provided encryption and key-management capabilities,\" Kashyap said. \"Now we’re going further to secure the workload itself—specifically AI—so an entire AI pipeline can run protected with confidential computing. That applies whether the AI runs in the cloud or in a sovereign environment handling sensitive or regulated data.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5RwQsTWQJtGQzJXeCx49eu/b3b8a5c44561cbc75359f26bbfa75bf0/cfr0z3n_close_up_on_nvidia_hopper_gpu_with_glowing_lock_icons_o_ea53bf0c-165f-46d9-920c-846fd894417d.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/githubs-agent-hq-aims-to-solve-enterprises-biggest-ai-coding-problem-too",
          "published_at": "Tue, 28 Oct 2025 16:10:00 GMT",
          "title": "GitHub's Agent HQ aims to solve enterprises' biggest AI coding problem: Too many agents, no central control",
          "standfirst": "GitHub is making a bold bet that enterprises don&#x27;t need another proprietary coding agent: They need a way to manage all of them.At its Universe 2025 conference, the Microsoft-owned developer platform announced Agent HQ. The new architecture transforms GitHub into a unified control plane for managing multiple AI coding agents from competitors including Anthropic, OpenAI, Google, Cognition and xAI. Rather than forcing developers into a single agent experience, the company is positioning itself as the essential orchestration layer beneath them all.Agent HQ represents GitHub&#x27;s attempt to apply its collaboration platform approach to AI agents. Just as the company transformed Git, pull requests and CI/CD into collaborative workflows, it&#x27;s now trying to do the same with a fragmented AI coding landscape.The announcement marks what GitHub calls the transition from \"wave one\" to \"wave two\" of AI-assisted development. According to GitHub&#x27;s Octoverse report, 80% of new developers use Copilot in their first week and AI has helped to lead to a large increase overall in the use of the GitHub platform.\"Last year, the big announcements for us, and what we were saying as a company, is wave one is done, that was kind of code completion,\" GitHub&#x27;s COO Mario Rodriguez told VentureBeat. \"We&#x27;re into this wave two era, [which] is going to be multimodal, it&#x27;s going to be agentic and it&#x27;s going to have these new experiences that will feel AI native.\"What is Agent HQ?GitHub already updated its GitHub Copilot coding tool for the agentic era with the debut of GitHub Copilot Agent in May.Agent HQ transforms GitHub into an open ecosystem that unites multiple AI coding agents on a single platform. Over the coming months, coding agents from Anthropic, OpenAI, Google, Cognition, xAI and others will become available directly within GitHub as part of existing paid GitHub Copilot subscriptions.The architecture maintains GitHub&#x27;s core primitives. Developers still work with Git, pull requests and issues. They still use their preferred compute, whether GitHub Actions or self-hosted runners. What changes is the layer above: agents from multiple vendors can now operate within GitHub&#x27;s security perimeter, using the same identity controls, branch permissions and audit logging that enterprises already trust for human developers.This approach differs fundamentally from standalone tools. When developers use Cursor or grant repository access to Claude, those agents typically receive broad permissions across entire repositories. Agent HQ compartmentalizes access at the branch level and wraps all agent activity in enterprise-grade governance controls.Mission Control: One interface for all agentsAt the heart of Agent HQ is Mission Control. It&#x27;s a unified command center that appears consistently across GitHub&#x27;s web interface, VS Code, mobile apps and the command line. Through Mission Control, developers can assign work to multiple agents simultaneously. They can track progress and manage permissions, all from a single pane of glass.The technical architecture addresses a critical enterprise concern: Security. Unlike standalone agent implementations where users must grant broad repository access, GitHub&#x27;s Agent HQ implements granular controls at the platform level.\"Our coding agent has a set of security controls and capabilities that are built natively into the platform, and that&#x27;s what we&#x27;re providing to all of these other agents as well,\" Rodriguez explained. \"It runs with a GitHub token that is very locked down to what it can actually do.\"Agents operating through Agent HQ can only commit to designated branches. They run within sandboxed GitHub Actions environments with firewall protections. They operate under strict identity controls. Rodriguez explained that even if an agent goes rogue, the firewall prevents it from accessing external networks or exfiltrating data unless those protections are explicitly disabled.Technical differentiation: MCP integration and custom agentsBeyond managing third-party agents, GitHub is introducing two technical capabilities that set Agent HQ apart from alternative approaches like Cursor&#x27;s standalone editor or Anthropic&#x27;s Claude integration.Custom agents via AGENTS.md files: Enterprises can now create source-controlled configuration files that define specific rules, tools and guardrails for how Copilot behaves. For example, a company could specify \"prefer this logger\" or \"use table-driven tests for all handlers.\" This permanently encodes organizational standards without requiring developers to re-prompt every time.\"Custom agents have an immense amount of product market fit within enterprises, because they could just codify a set of skills that the coordination can do, then standardize on those and get really high quality output,\" Rodriguez said.The AGENTS.md specification allows teams to version control their agent behavior alongside their code. When a developer clones a repository, they automatically inherit the custom agent rules. This solves a persistent problem with AI coding tools: Inconsistent output quality when different team members use different prompting strategies.Native Model Context Protocol (MCP) support: VS Code now includes a GitHub MCP Registry. Developers can discover, install and enable MCP servers with a single click. They can then create custom agents that combine these tools with specific system prompts.This positions GitHub as the integration point between the emerging MCP ecosystem and actual developer workflows. MCP, introduced by Anthropic but rapidly gaining industry support, is becoming a de facto standard for agent-to-tool communication. By supporting the full specification, GitHub can orchestrate agents that need access to external services without each agent implementing its own integration logic.Plan Mode and agentic code reviewGitHub is also shipping new capabilities within VS Code itself. Plan Mode allows developers to collaborate with Copilot on building step-by-step project approaches. The AI asks clarifying questions before any code is written. Once approved, the plan can be executed either locally in VS Code or by cloud-based agents.The feature addresses a common failure mode in AI coding: Beginning implementation before requirements are fully understood. By forcing an explicit planning phase, GitHub aims to reduce wasted effort and improve output quality.More significantly, GitHub&#x27;s code review feature is becoming agentic. The new implementation will use GitHub&#x27;s CodeQL engine, which previously largely focused on security vulnerabilities to identify bugs and maintainability issues. The code review agent will automatically scan agent-generated pull requests before human review. This creates a two-stage quality gate.\"Our code review agent will be able to make calls into the CodeQL engine to then find a set of bugs,\" Rodriguez explained. \"We&#x27;re extending the engine and we&#x27;re going to be able to tap into that engine also to find bugs.\"Enterprise considerations: What to do nowFor enterprises already deploying multiple AI coding tools, Agent HQ offers a path to consolidation without forcing tool elimination.GitHub&#x27;s multi-agent approach provides vendor flexibility and reduces lock-in risk. Organizations can test multiple agents within a unified security perimeter and switch providers without retraining developers. The tradeoff is potentially less optimized experiences compared to specialized tools that tightly integrate UI and agent behavior.Rodriguez&#x27;s recommendation is clear: Begin with custom agents. This allows enterprises to codify organizational standards that agents follow consistently. Once established, organizations can layer in additional third-party agents to expand capabilities.\"Go and do agent coding, custom agents and start playing with that,\" he said. \"That is a capability available tomorrow, and it allows you to really start shaping your SDLC to be personalized to you, your organization and your people.\"",
          "content": "GitHub is making a bold bet that enterprises don&#x27;t need another proprietary coding agent: They need a way to manage all of them.At its Universe 2025 conference, the Microsoft-owned developer platform announced Agent HQ. The new architecture transforms GitHub into a unified control plane for managing multiple AI coding agents from competitors including Anthropic, OpenAI, Google, Cognition and xAI. Rather than forcing developers into a single agent experience, the company is positioning itself as the essential orchestration layer beneath them all.Agent HQ represents GitHub&#x27;s attempt to apply its collaboration platform approach to AI agents. Just as the company transformed Git, pull requests and CI/CD into collaborative workflows, it&#x27;s now trying to do the same with a fragmented AI coding landscape.The announcement marks what GitHub calls the transition from \"wave one\" to \"wave two\" of AI-assisted development. According to GitHub&#x27;s Octoverse report, 80% of new developers use Copilot in their first week and AI has helped to lead to a large increase overall in the use of the GitHub platform.\"Last year, the big announcements for us, and what we were saying as a company, is wave one is done, that was kind of code completion,\" GitHub&#x27;s COO Mario Rodriguez told VentureBeat. \"We&#x27;re into this wave two era, [which] is going to be multimodal, it&#x27;s going to be agentic and it&#x27;s going to have these new experiences that will feel AI native.\"What is Agent HQ?GitHub already updated its GitHub Copilot coding tool for the agentic era with the debut of GitHub Copilot Agent in May.Agent HQ transforms GitHub into an open ecosystem that unites multiple AI coding agents on a single platform. Over the coming months, coding agents from Anthropic, OpenAI, Google, Cognition, xAI and others will become available directly within GitHub as part of existing paid GitHub Copilot subscriptions.The architecture maintains GitHub&#x27;s core primitives. Developers still work with Git, pull requests and issues. They still use their preferred compute, whether GitHub Actions or self-hosted runners. What changes is the layer above: agents from multiple vendors can now operate within GitHub&#x27;s security perimeter, using the same identity controls, branch permissions and audit logging that enterprises already trust for human developers.This approach differs fundamentally from standalone tools. When developers use Cursor or grant repository access to Claude, those agents typically receive broad permissions across entire repositories. Agent HQ compartmentalizes access at the branch level and wraps all agent activity in enterprise-grade governance controls.Mission Control: One interface for all agentsAt the heart of Agent HQ is Mission Control. It&#x27;s a unified command center that appears consistently across GitHub&#x27;s web interface, VS Code, mobile apps and the command line. Through Mission Control, developers can assign work to multiple agents simultaneously. They can track progress and manage permissions, all from a single pane of glass.The technical architecture addresses a critical enterprise concern: Security. Unlike standalone agent implementations where users must grant broad repository access, GitHub&#x27;s Agent HQ implements granular controls at the platform level.\"Our coding agent has a set of security controls and capabilities that are built natively into the platform, and that&#x27;s what we&#x27;re providing to all of these other agents as well,\" Rodriguez explained. \"It runs with a GitHub token that is very locked down to what it can actually do.\"Agents operating through Agent HQ can only commit to designated branches. They run within sandboxed GitHub Actions environments with firewall protections. They operate under strict identity controls. Rodriguez explained that even if an agent goes rogue, the firewall prevents it from accessing external networks or exfiltrating data unless those protections are explicitly disabled.Technical differentiation: MCP integration and custom agentsBeyond managing third-party agents, GitHub is introducing two technical capabilities that set Agent HQ apart from alternative approaches like Cursor&#x27;s standalone editor or Anthropic&#x27;s Claude integration.Custom agents via AGENTS.md files: Enterprises can now create source-controlled configuration files that define specific rules, tools and guardrails for how Copilot behaves. For example, a company could specify \"prefer this logger\" or \"use table-driven tests for all handlers.\" This permanently encodes organizational standards without requiring developers to re-prompt every time.\"Custom agents have an immense amount of product market fit within enterprises, because they could just codify a set of skills that the coordination can do, then standardize on those and get really high quality output,\" Rodriguez said.The AGENTS.md specification allows teams to version control their agent behavior alongside their code. When a developer clones a repository, they automatically inherit the custom agent rules. This solves a persistent problem with AI coding tools: Inconsistent output quality when different team members use different prompting strategies.Native Model Context Protocol (MCP) support: VS Code now includes a GitHub MCP Registry. Developers can discover, install and enable MCP servers with a single click. They can then create custom agents that combine these tools with specific system prompts.This positions GitHub as the integration point between the emerging MCP ecosystem and actual developer workflows. MCP, introduced by Anthropic but rapidly gaining industry support, is becoming a de facto standard for agent-to-tool communication. By supporting the full specification, GitHub can orchestrate agents that need access to external services without each agent implementing its own integration logic.Plan Mode and agentic code reviewGitHub is also shipping new capabilities within VS Code itself. Plan Mode allows developers to collaborate with Copilot on building step-by-step project approaches. The AI asks clarifying questions before any code is written. Once approved, the plan can be executed either locally in VS Code or by cloud-based agents.The feature addresses a common failure mode in AI coding: Beginning implementation before requirements are fully understood. By forcing an explicit planning phase, GitHub aims to reduce wasted effort and improve output quality.More significantly, GitHub&#x27;s code review feature is becoming agentic. The new implementation will use GitHub&#x27;s CodeQL engine, which previously largely focused on security vulnerabilities to identify bugs and maintainability issues. The code review agent will automatically scan agent-generated pull requests before human review. This creates a two-stage quality gate.\"Our code review agent will be able to make calls into the CodeQL engine to then find a set of bugs,\" Rodriguez explained. \"We&#x27;re extending the engine and we&#x27;re going to be able to tap into that engine also to find bugs.\"Enterprise considerations: What to do nowFor enterprises already deploying multiple AI coding tools, Agent HQ offers a path to consolidation without forcing tool elimination.GitHub&#x27;s multi-agent approach provides vendor flexibility and reduces lock-in risk. Organizations can test multiple agents within a unified security perimeter and switch providers without retraining developers. The tradeoff is potentially less optimized experiences compared to specialized tools that tightly integrate UI and agent behavior.Rodriguez&#x27;s recommendation is clear: Begin with custom agents. This allows enterprises to codify organizational standards that agents follow consistently. Once established, organizations can layer in additional third-party agents to expand capabilities.\"Go and do agent coding, custom agents and start playing with that,\" he said. \"That is a capability available tomorrow, and it allows you to really start shaping your SDLC to be personalized to you, your organization and your people.\"",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4O4T83wUSzVSPKnuWWf4dZ/bea55829b728586b10a802f9f281a1ec/github-agentht-smk.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/oppos-find-x9-pro-hands-on-detachable-telephoto-lens-7000mah-battery-160006373.html",
          "published_at": "Tue, 28 Oct 2025 16:00:23 +0000",
          "title": "Oppo’s Find X9 Pro has a detachable telephoto lens and a gigantic battery",
          "standfirst": "Oppo’s latest flagship phone, like the sleek (but hard to buy) Find N5 foldable, goes hard on the tech specifications. In fact, the Find X9 Pro’s specs read like a wishlist of what many want to see in their phones, with a huge 7,500mAh battery, a 200-megapixel telephoto camera and a bright 6.78-inch screen with tiny, almost one-millimeter bezels, all while still measuring in at 8.25mm in thickness. Oh, and an optional telephoto lens add-on that boosts camera zoom to 10x. The Find X9 Pro will be priced at £1,099 (roughly $1,459). The biggest drawback may be that, despite the Find X9 series being Oppo’s biggest phone launch yet, it won’t be available in the US. Still, with everything that’s crammed into this phone, I had to try it out. Do I really want a thinner smartphone? Or one that lasts multiple days before it needs recharging? And man, this telephoto lens is certainly eye-catching. Display and design Image by Mat Smith for Engadget The Find X9 Pro has a 6.78-inch display, with peak outdoor brightness at 3,600 nits. On paper, that beats the iPhone 17 Pro, but most people with phones older than a year or two will notice how much brighter phones like the X9 Pro are. Another notable feature is a 1-nit minimal brightness to reduce eye strain when using the phone in the dark. Or in bed. Which we shouldn’t do, but we all do. Oppo has also included high-frequency pixel dimming to further reduce the screen's harshness. Like recent phones from its business cousin, OnePlus, Oppo has added a new button on this year’s Find X model. The Snap key is on the left of the device, and can be customized to launch apps like the voice recorder, translation apps and flashlight. Meanwhile, the right edge houses the Find X9’s Quick Button, which is ostensibly the camera button. Double-tapping it launches the camera app. While it’s not as elaborate as the iPhone’s Camera Control, you can swipe on the button to zoom in and out while using the camera, which is a simple, welcome addition. Alongside Mediatek's new Dimensity 9500 chip, the Find X9 Pro is another flagship phone with a silicon-carbon battery. With a higher energy density than graphite-based batteries, this means longer battery life without making the phone bigger or thicker. At 7,000mAh, the battery is huge. That’s far bigger than the battery found in foldables like Samsung’s Z Fold 7 (4,400 mAh) and the Pixel 9 Pro Fold (4,650 mAh). It’s even bigger than the one in the OnePlus 13 (6,000 mAh). Fortunately, the Find X9 supports suitably swift charging speeds, with support for 80W SUPERVOOC and 50W wireless charging. During my time with the phone, it would often last two days on a charge. Even after a day of heavy camera use, Google Maps and streaming video, I didn’t need to recharge the Find X9 Pro until late afternoon on the second day. Cameras Image by Mat Smith for Engadget The Find X9 Pro’s camera consists of a 50-megapixel main sensor with f/1.5 lens and optical image stabilization. There’s also a 50MP ultrawide camera and arguably the most technically impressive part: a 200MP periscope camera with an f/2.1 lens and OIS. This is further augmented with an attachable teleconverter lens — more on that later. Oppo’s Hasselblad collaboration focuses on telephoto, though the company calls its entire camera setup the Hasselblad Master Camera System. I’m not sure it needed such a label.To make the most of the high-resolution sensor, the camera app includes a new Hi-Res mode to capture at 200MP for the telephoto lens and 50MP when using the other two camera sensors. The company warns that the mode is best used in well-lit environments, as it strips out pixel binning and other computational photography techniques that are used when there’s limited light. But that’s not really the point: it’s all about the zoom. The telephoto has a base 3x optical zoom, which can be cropped to a 6x zoom with a 50MP image. It’s worth noting that all the cameras on the Find X9 can capture at 50MP. If the phone detects more challenging shooting conditions, it automatically drops down to 25MP or 12MP shots. In reality, I didn’t notice the resolution jump in most photos I took, although the rich foliage in some of my landscape shots showcases how much detail the camera system is able to capture. Image by Mat Smith for Engadget Oppo says its computational photography know-how pushes the zoom here to 13.2x, but its algorithms can get a little aggressive and messy with faces and detail at the higher digital zoom settings. Take a look at these pictures taken across a hillside. While the foliage appears crisp and detailed, the walkers are blurry and there’s a halo effect around them. At other times, computational photography turned pedestrians into nightmarish faces. In yet another opportunity to mention the Hasselblad collab, there’s also an XPAN shooting mode for cinematic 65:24 images. Conversely, if you’re into a disposable camera aesthetic, the Find X9 series can also trigger an aggressive double-flash to mimic ‘00s photography. The same zoom capabilities are available in video capture, too, and the company has added a new Sound Focus mode to strip out ambient noise, which worked better than I expected it to. There are several more video recording upgrades, including full LOG recording (activated in settings) and an integrated LUT preview to check color grading in real time. Image by Mat Smith for Engadget Then there’s the attachable lens. Oppo’s Hasselblad Teleconverter is a solid, premium peripheral, with a metal barrel and some heft. It extends the Find X9’s optical zoom to 10x, with an equivalent focal length of 230mm. Thanks to the high-res 200MP Telephoto camera sensor, you can punch in at up to 200x digital zoom for stills and 50x zoom for video, although the sweet spot is certainly more in the middle. The add-on teleconverter lens, while not entirely new (Vivo did it first), may be the most intriguing part. You need to use a specific case and mounting plate to securely attach the lens to the phone, but when it’s locked in, it feels solid and very secure. It also looks, well, how it looks. Because it’s such a slender lens, it looks like something you might use for espionage. It doesn’t even look like a point-and-shoot camera. It’s… eye-catching, but also so much fun. Image by Mat Smith for Engadget I’ve been testing the Find X9’s camera chops for a few weeks, and it’s been a lot of fun to zoom in with optical zoom clarity, whether at concerts, movie premieres or taking pictures of my nieces during hectic Play-Doh sessions. What’s particularly attractive is the combination of high detail and bokeh effect. With the leap in zoom, I had to ensure I was far enough away in order to use the teleconverter, or it would struggle to focus. Image by Mat Smith for Engadget Oppo is pitching its new flagship as the ultimate phone for concerts and live events, and the zoom range is very impressive. Perhaps understandably, when zooming so much, there is a high risk of blurry shots. Oppo includes a special tripod mount that attaches to the lens barrel to ensure the whole thing doesn’t tip over, but it’s one step too far for me. Carrying around the teleconverter and mounting plate is already a lot. It’s also a bit of a chore to have to detach the plate when using the camera without the teleconverter. Oddly, the plate covers the other sensors, meaning that if you want a closer focal point (or want to use anything besides the telephoto sensor), it’s an additional pain point before you can take the photo. It’s unusual that a phone’s “main” camera isn’t the star of the show, but that may be the case with the Find X9 Pro. However, it’s still technically impressive. With a new 1/1.28 sensor codeveloped with Sony, the 50MP main camera can capture triple exposures on each frame before merging them. Oppo claims that it gives images 17 stops of dynamic range. There’s also a fourth camera, a True Color camera, dedicated to precisely measuring color temperatures across all the other sensors. Combined, it’s an impressive system, but you’ll get the most out of it if you’re willing to pay for the additional teleconverter. Image by Mat Smith for Engadget At £1,099 in the UK, Oppo has priced it identically to the iPhone 17 Pro, although we're still waiting to hear pricing for the teleconverter kit. I feared foldable prices, but this seems at least competitive here in Europe. What’s stopping Oppo from breaking into the US? Trade turbulence and competition, probably. If it can refine the experience (and maybe keep its next phone compatible with the same teleconverter), it has a good chance at charming the obsessive smartphone photographer away from their iPhones and Pixels.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/oppos-find-x9-pro-hands-on-detachable-telephoto-lens-7000mah-battery-160006373.html?src=rss",
          "content": "Oppo’s latest flagship phone, like the sleek (but hard to buy) Find N5 foldable, goes hard on the tech specifications. In fact, the Find X9 Pro’s specs read like a wishlist of what many want to see in their phones, with a huge 7,500mAh battery, a 200-megapixel telephoto camera and a bright 6.78-inch screen with tiny, almost one-millimeter bezels, all while still measuring in at 8.25mm in thickness. Oh, and an optional telephoto lens add-on that boosts camera zoom to 10x. The Find X9 Pro will be priced at £1,099 (roughly $1,459). The biggest drawback may be that, despite the Find X9 series being Oppo’s biggest phone launch yet, it won’t be available in the US. Still, with everything that’s crammed into this phone, I had to try it out. Do I really want a thinner smartphone? Or one that lasts multiple days before it needs recharging? And man, this telephoto lens is certainly eye-catching. Display and design Image by Mat Smith for Engadget The Find X9 Pro has a 6.78-inch display, with peak outdoor brightness at 3,600 nits. On paper, that beats the iPhone 17 Pro, but most people with phones older than a year or two will notice how much brighter phones like the X9 Pro are. Another notable feature is a 1-nit minimal brightness to reduce eye strain when using the phone in the dark. Or in bed. Which we shouldn’t do, but we all do. Oppo has also included high-frequency pixel dimming to further reduce the screen's harshness. Like recent phones from its business cousin, OnePlus, Oppo has added a new button on this year’s Find X model. The Snap key is on the left of the device, and can be customized to launch apps like the voice recorder, translation apps and flashlight. Meanwhile, the right edge houses the Find X9’s Quick Button, which is ostensibly the camera button. Double-tapping it launches the camera app. While it’s not as elaborate as the iPhone’s Camera Control, you can swipe on the button to zoom in and out while using the camera, which is a simple, welcome addition. Alongside Mediatek's new Dimensity 9500 chip, the Find X9 Pro is another flagship phone with a silicon-carbon battery. With a higher energy density than graphite-based batteries, this means longer battery life without making the phone bigger or thicker. At 7,000mAh, the battery is huge. That’s far bigger than the battery found in foldables like Samsung’s Z Fold 7 (4,400 mAh) and the Pixel 9 Pro Fold (4,650 mAh). It’s even bigger than the one in the OnePlus 13 (6,000 mAh). Fortunately, the Find X9 supports suitably swift charging speeds, with support for 80W SUPERVOOC and 50W wireless charging. During my time with the phone, it would often last two days on a charge. Even after a day of heavy camera use, Google Maps and streaming video, I didn’t need to recharge the Find X9 Pro until late afternoon on the second day. Cameras Image by Mat Smith for Engadget The Find X9 Pro’s camera consists of a 50-megapixel main sensor with f/1.5 lens and optical image stabilization. There’s also a 50MP ultrawide camera and arguably the most technically impressive part: a 200MP periscope camera with an f/2.1 lens and OIS. This is further augmented with an attachable teleconverter lens — more on that later. Oppo’s Hasselblad collaboration focuses on telephoto, though the company calls its entire camera setup the Hasselblad Master Camera System. I’m not sure it needed such a label.To make the most of the high-resolution sensor, the camera app includes a new Hi-Res mode to capture at 200MP for the telephoto lens and 50MP when using the other two camera sensors. The company warns that the mode is best used in well-lit environments, as it strips out pixel binning and other computational photography techniques that are used when there’s limited light. But that’s not really the point: it’s all about the zoom. The telephoto has a base 3x optical zoom, which can be cropped to a 6x zoom with a 50MP image. It’s worth noting that all the cameras on the Find X9 can capture at 50MP. If the phone detects more challenging shooting conditions, it automatically drops down to 25MP or 12MP shots. In reality, I didn’t notice the resolution jump in most photos I took, although the rich foliage in some of my landscape shots showcases how much detail the camera system is able to capture. Image by Mat Smith for Engadget Oppo says its computational photography know-how pushes the zoom here to 13.2x, but its algorithms can get a little aggressive and messy with faces and detail at the higher digital zoom settings. Take a look at these pictures taken across a hillside. While the foliage appears crisp and detailed, the walkers are blurry and there’s a halo effect around them. At other times, computational photography turned pedestrians into nightmarish faces. In yet another opportunity to mention the Hasselblad collab, there’s also an XPAN shooting mode for cinematic 65:24 images. Conversely, if you’re into a disposable camera aesthetic, the Find X9 series can also trigger an aggressive double-flash to mimic ‘00s photography. The same zoom capabilities are available in video capture, too, and the company has added a new Sound Focus mode to strip out ambient noise, which worked better than I expected it to. There are several more video recording upgrades, including full LOG recording (activated in settings) and an integrated LUT preview to check color grading in real time. Image by Mat Smith for Engadget Then there’s the attachable lens. Oppo’s Hasselblad Teleconverter is a solid, premium peripheral, with a metal barrel and some heft. It extends the Find X9’s optical zoom to 10x, with an equivalent focal length of 230mm. Thanks to the high-res 200MP Telephoto camera sensor, you can punch in at up to 200x digital zoom for stills and 50x zoom for video, although the sweet spot is certainly more in the middle. The add-on teleconverter lens, while not entirely new (Vivo did it first), may be the most intriguing part. You need to use a specific case and mounting plate to securely attach the lens to the phone, but when it’s locked in, it feels solid and very secure. It also looks, well, how it looks. Because it’s such a slender lens, it looks like something you might use for espionage. It doesn’t even look like a point-and-shoot camera. It’s… eye-catching, but also so much fun. Image by Mat Smith for Engadget I’ve been testing the Find X9’s camera chops for a few weeks, and it’s been a lot of fun to zoom in with optical zoom clarity, whether at concerts, movie premieres or taking pictures of my nieces during hectic Play-Doh sessions. What’s particularly attractive is the combination of high detail and bokeh effect. With the leap in zoom, I had to ensure I was far enough away in order to use the teleconverter, or it would struggle to focus. Image by Mat Smith for Engadget Oppo is pitching its new flagship as the ultimate phone for concerts and live events, and the zoom range is very impressive. Perhaps understandably, when zooming so much, there is a high risk of blurry shots. Oppo includes a special tripod mount that attaches to the lens barrel to ensure the whole thing doesn’t tip over, but it’s one step too far for me. Carrying around the teleconverter and mounting plate is already a lot. It’s also a bit of a chore to have to detach the plate when using the camera without the teleconverter. Oddly, the plate covers the other sensors, meaning that if you want a closer focal point (or want to use anything besides the telephoto sensor), it’s an additional pain point before you can take the photo. It’s unusual that a phone’s “main” camera isn’t the star of the show, but that may be the case with the Find X9 Pro. However, it’s still technically impressive. With a new 1/1.28 sensor codeveloped with Sony, the 50MP main camera can capture triple exposures on each frame before merging them. Oppo claims that it gives images 17 stops of dynamic range. There’s also a fourth camera, a True Color camera, dedicated to precisely measuring color temperatures across all the other sensors. Combined, it’s an impressive system, but you’ll get the most out of it if you’re willing to pay for the additional teleconverter. Image by Mat Smith for Engadget At £1,099 in the UK, Oppo has priced it identically to the iPhone 17 Pro, although we're still waiting to hear pricing for the teleconverter kit. I feared foldable prices, but this seems at least competitive here in Europe. What’s stopping Oppo from breaking into the US? Trade turbulence and competition, probably. If it can refine the experience (and maybe keep its next phone compatible with the same teleconverter), it has a good chance at charming the obsessive smartphone photographer away from their iPhones and Pixels.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/oppos-find-x9-pro-hands-on-detachable-telephoto-lens-7000mah-battery-160006373.html?src=rss",
          "feed_position": 15,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/f8a3c8b1-b3f8-11f0-bb3a-92d51df1faad"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/how-to-cancel-your-hbo-max-subscription-155047857.html",
          "published_at": "Tue, 28 Oct 2025 15:50:47 +0000",
          "title": "How to cancel your HBO Max subscription",
          "standfirst": "It keeps happening. HBO Max just raised prices again, around 16 months after the last price increase. If your debit card is feeling the pain, or if you're just not excited about that weird Harry Potter remake nobody asked for, you may decide to take a break from the perpetually renamed platform. Here's everything you need to know about canceling your HBO Max subscription, so you can streamline those entertainment options. How to cancel via web The simplest way to end your HBO Max subscription is if you're being billed directly by the company. You can follow these steps in a web or mobile browser to say goodbye to the house that Tony Soprano built. Go to max.com/subscription in a web browser. Sign in to your account. Click on your profile picture. Select Subscription. Click Cancel Your Subscription. This should be at the bottom of the page. Follow the prompts to confirm. That was pretty dang easy, but things get a bit more complicated if you originally subscribed via a third-party platform. How to cancel via third-party provider Like most modern streaming platforms, HBO Max has partnerships with third-party providers like Apple and Amazon. This lets users sign up for the service through a totally different platform, like Prime Video or directly through iOS. Cancelling has to also go through this third party. The basic idea here is to sign into that account and find a place to manage billing and subscriptions, looking for HBO Max. Here are specific steps for some of the more common providers. Cancel via Apple Go to the Settings app on your iOS device. Tap on your name at the top of the screen. Tap Subscriptions. Select HBO Max to manage and make changes. Cancel via Amazon Go to Amazon in a web browser. Sign in to your account. Click on Amazon Memberships and Subscriptions. Find the HBO Max subscription and hit Cancel Subscription. Follow the prompts. Cancel via Google Play Go to the Google Play store on a web browser. Confirm that you're signed in to your Google account. Click on Payment & Subscriptions, which should be on the top right. Click the Subscriptions tab. Select HBO Max. Click Manage. Select Cancel Subscription. How to cancel a bundle subscription There are a couple of bundles that include HBO Max, in addition to platforms like Disney+ and Hulu. It's corporate synergy at its finest. However, this does make cancelling slightly more complicated. If you previously had an HBO Max subscription and upgraded to a bundle, cancelling the bundle might not cancel HBO Max. It could just cancel the platforms that were added in the bundle. Just make sure to double-check that HBO Max went away along with the bundle. As for canceling the bundle itself, follow the steps above. Can I pause an HBO Max subscription? No, you can't pause a subscription to HBO Max. The best way to approximate this is to simply cancel a subscription and resubscribe at a later date. Whatever works, right? What happens after you cancel? Cancelling your subscription to HBO Max doesn't immediately end the service. There are no partial refunds in this world, so you'll have full access to the account until the next payment date. This means that if you change your mind before the next pay period, it'll be easy to get things going again. Just look for a Restart Subscription button somewhere on the Account page. After the next payment date passes, the service sails off into that Westeros sunset.This article originally appeared on Engadget at https://www.engadget.com/entertainment/how-to-cancel-your-hbo-max-subscription-155047857.html?src=rss",
          "content": "It keeps happening. HBO Max just raised prices again, around 16 months after the last price increase. If your debit card is feeling the pain, or if you're just not excited about that weird Harry Potter remake nobody asked for, you may decide to take a break from the perpetually renamed platform. Here's everything you need to know about canceling your HBO Max subscription, so you can streamline those entertainment options. How to cancel via web The simplest way to end your HBO Max subscription is if you're being billed directly by the company. You can follow these steps in a web or mobile browser to say goodbye to the house that Tony Soprano built. Go to max.com/subscription in a web browser. Sign in to your account. Click on your profile picture. Select Subscription. Click Cancel Your Subscription. This should be at the bottom of the page. Follow the prompts to confirm. That was pretty dang easy, but things get a bit more complicated if you originally subscribed via a third-party platform. How to cancel via third-party provider Like most modern streaming platforms, HBO Max has partnerships with third-party providers like Apple and Amazon. This lets users sign up for the service through a totally different platform, like Prime Video or directly through iOS. Cancelling has to also go through this third party. The basic idea here is to sign into that account and find a place to manage billing and subscriptions, looking for HBO Max. Here are specific steps for some of the more common providers. Cancel via Apple Go to the Settings app on your iOS device. Tap on your name at the top of the screen. Tap Subscriptions. Select HBO Max to manage and make changes. Cancel via Amazon Go to Amazon in a web browser. Sign in to your account. Click on Amazon Memberships and Subscriptions. Find the HBO Max subscription and hit Cancel Subscription. Follow the prompts. Cancel via Google Play Go to the Google Play store on a web browser. Confirm that you're signed in to your Google account. Click on Payment & Subscriptions, which should be on the top right. Click the Subscriptions tab. Select HBO Max. Click Manage. Select Cancel Subscription. How to cancel a bundle subscription There are a couple of bundles that include HBO Max, in addition to platforms like Disney+ and Hulu. It's corporate synergy at its finest. However, this does make cancelling slightly more complicated. If you previously had an HBO Max subscription and upgraded to a bundle, cancelling the bundle might not cancel HBO Max. It could just cancel the platforms that were added in the bundle. Just make sure to double-check that HBO Max went away along with the bundle. As for canceling the bundle itself, follow the steps above. Can I pause an HBO Max subscription? No, you can't pause a subscription to HBO Max. The best way to approximate this is to simply cancel a subscription and resubscribe at a later date. Whatever works, right? What happens after you cancel? Cancelling your subscription to HBO Max doesn't immediately end the service. There are no partial refunds in this world, so you'll have full access to the account until the next payment date. This means that if you change your mind before the next pay period, it'll be easy to get things going again. Just look for a Restart Subscription button somewhere on the Account page. After the next payment date passes, the service sails off into that Westeros sunset.This article originally appeared on Engadget at https://www.engadget.com/entertainment/how-to-cancel-your-hbo-max-subscription-155047857.html?src=rss",
          "feed_position": 16
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/intuit-learned-to-build-ai-agents-for-finance-the-hard-way-trust-lost-in",
          "published_at": "Tue, 28 Oct 2025 12:30:00 GMT",
          "title": "Intuit learned to build AI agents for finance the hard way: Trust lost in buckets, earned back in spoonfuls",
          "standfirst": "Building AI for financial software requires a different playbook than consumer AI, and Intuit&#x27;s latest QuickBooks release provides an example.The company has announced Intuit Intelligence, a system that orchestrates specialized AI agents across its QuickBooks platform to handle tasks including sales tax compliance and payroll processing. These new agents augment existing accounting and project management agents (which have also been updated) as well as a unified interface that lets users query data across QuickBooks, third-party systems and uploaded files using natural language. The new development follow years of investment and improvement in Intuit&#x27;s GenOS, allowing the company to build AI capabilities that reduce latency and improve accuracy.But the real news isn&#x27;t what Intuit built — it&#x27;s how they built it and why their design decisions will make AI more usable. The company&#x27;s latest AI rollout represents an evolution built on hard-won lessons about what works and what doesn&#x27;t when deploying AI in financial contexts.What the company learned is sobering: Even when its accounting agent improved transaction categorization accuracy by 20 percentage points on average, they still received complaints about errors.\"The use cases that we&#x27;re trying to solve for customers include tax and finance; if you make a mistake in this world, you lose trust with customers in buckets and we only get it back in spoonfuls,\" Joe Preston, Intuit&#x27;s VP of product and design, told VentureBeat.The architecture of trust: Real data queries over generative responsesIntuit&#x27;s technical strategy centers on a fundamental design decision. For financial queries and business intelligence, the system queries actual data, rather than generating responses through large language models (LLMs).Also critically important: That data isn&#x27;t all in one place. Intuit&#x27;s technical implementation allows QuickBooks to ingest data from multiple distinct sources: native Intuit data, OAuth-connected third-party systems like Square for payments and user-uploaded files such as spreadsheets containing vendor pricing lists or marketing campaign data. This creates a unified data layer that AI agents can query reliably.\"We&#x27;re actually querying your real data,\" Preston explained. \"That&#x27;s very different than if you were to just copy, paste out a spreadsheet or a PDF and paste into ChatGPT.\"This architectural choice means that the Intuit Intelligence system functions more as an orchestration layer. It&#x27;s a natural language interface to structured data operations. When a user asks about projected profitability or wants to run payroll, the system translates the natural language query into database operations against verified financial data.This matters because Intuit&#x27;s internal research has uncovered widespread shadow AI usage. When surveyed, 25% of accountants using QuickBooks admitted they were already copying and pasting data into ChatGPT or Google Gemini for analysis.Intuit&#x27;s approach treats AI as a query translation and orchestration mechanism, not a content generator. This reduces the hallucination risk that has plagued AI deployments in financial contexts.Explainability as a design requirement, not an afterthoughtBeyond the technical architecture, Intuit has made explainability a core user experience across its AI agents. This goes beyond simply providing correct answers: It means showing users the reasoning behind automated decisions.When Intuit&#x27;s accounting agent categorizes a transaction, it doesn&#x27;t just display the result; it shows the reasoning. This isn&#x27;t marketing copy about explainable AI, it&#x27;s actual UI displaying data points and logic.\"It&#x27;s about closing that trust loop and making sure customers understand the why,\" Alastair Simpson, Intuit&#x27;s VP of design, told VentureBeat.This becomes particularly critical when you consider Intuit&#x27;s user research: While half of small businesses describe AI as helpful, nearly a quarter haven&#x27;t used AI at all. The explanation layer serves both populations: Building confidence for newcomers, while giving experienced users the context to verify accuracy.The design also enforces human control at critical decision points. This approach extends beyond the interface. Intuit connects users directly with human experts, embedded in the same workflows, when automation reaches its limits or when users want validation.Navigating the transition from forms to conversationsOne of Intuit&#x27;s more interesting challenges involves managing a fundamental shift in user interfaces. Preston described it as having one foot in the past and one foot in the future.\"This isn&#x27;t just Intuit, this is the market as a whole,\" said Preston. \"Today we still have a lot of customers filling out forms and going through tables full of data. We&#x27;re investing a lot into leaning in and questioning the ways that we do it across our products today, where you&#x27;re basically just filling out, form after form, or table after table, because we see where the world is headed, which is really a different form of interacting with these products.\"This creates a product design challenge: How do you serve users who are comfortable with traditional interfaces while gradually introducing conversational and agentic capabilities?Intuit&#x27;s approach has been to embed AI agents directly into existing workflows. This means not forcing users to adopt entirely new interaction patterns. The payments agent appears alongside invoicing workflows; the accounting agent enhances the existing reconciliation process rather than replacing it. This incremental approach lets users experience AI benefits without abandoning familiar processes.What enterprise AI builders can learn from Intuit&#x27;s approachIntuit&#x27;s experience deploying AI in financial contexts surfaces several principles that apply broadly to enterprise AI initiatives. Architecture matters for trust: In domains where accuracy is critical, consider whether you need content generation or data query translation. Intuit&#x27;s decision to treat AI as an orchestration and natural language interface layer dramatically reduces hallucination risk and avoids using AI as a generative system.Explainability must be designed in, not bolted on: Showing users why the AI made a decision isn&#x27;t optional when trust is at stake. This requires deliberate UX design. It may constrain model choices.User control preserves trust during accuracy improvements: Intuit&#x27;s accounting agent improved categorization accuracy by 20 percentage points. Yet, maintaining user override capabilities was essential for adoption.Transition gradually from familiar interfaces: Don&#x27;t force users to abandon forms for conversations. Embed AI capabilities into existing workflows first. Let users experience benefits before asking them to change behavior.Be honest about what&#x27;s reactive versus proactive: Current AI agents primarily respond to prompts and automate defined tasks. True proactive intelligence that makes unprompted strategic recommendations remains an evolving capability. Address workforce concerns with tooling, not just messaging: If AI is meant to augment rather than replace workers, provide workers with AI tools. Show them how to leverage the technology.For enterprises navigating AI adoption, Intuit&#x27;s journey offers a clear directive. The winning approach prioritizes trustworthiness over capability demonstrations. In domains where mistakes have real consequences, that means investing in accuracy, transparency and human oversight before pursuing conversational sophistication or autonomous action.Simpson frames the challenge succinctly: \"We didn&#x27;t want it to be a bolted-on layer. We wanted customers to be in their natural workflow, and have agents doing work for customers, embedded in the workflow.\"",
          "content": "Building AI for financial software requires a different playbook than consumer AI, and Intuit&#x27;s latest QuickBooks release provides an example.The company has announced Intuit Intelligence, a system that orchestrates specialized AI agents across its QuickBooks platform to handle tasks including sales tax compliance and payroll processing. These new agents augment existing accounting and project management agents (which have also been updated) as well as a unified interface that lets users query data across QuickBooks, third-party systems and uploaded files using natural language. The new development follow years of investment and improvement in Intuit&#x27;s GenOS, allowing the company to build AI capabilities that reduce latency and improve accuracy.But the real news isn&#x27;t what Intuit built — it&#x27;s how they built it and why their design decisions will make AI more usable. The company&#x27;s latest AI rollout represents an evolution built on hard-won lessons about what works and what doesn&#x27;t when deploying AI in financial contexts.What the company learned is sobering: Even when its accounting agent improved transaction categorization accuracy by 20 percentage points on average, they still received complaints about errors.\"The use cases that we&#x27;re trying to solve for customers include tax and finance; if you make a mistake in this world, you lose trust with customers in buckets and we only get it back in spoonfuls,\" Joe Preston, Intuit&#x27;s VP of product and design, told VentureBeat.The architecture of trust: Real data queries over generative responsesIntuit&#x27;s technical strategy centers on a fundamental design decision. For financial queries and business intelligence, the system queries actual data, rather than generating responses through large language models (LLMs).Also critically important: That data isn&#x27;t all in one place. Intuit&#x27;s technical implementation allows QuickBooks to ingest data from multiple distinct sources: native Intuit data, OAuth-connected third-party systems like Square for payments and user-uploaded files such as spreadsheets containing vendor pricing lists or marketing campaign data. This creates a unified data layer that AI agents can query reliably.\"We&#x27;re actually querying your real data,\" Preston explained. \"That&#x27;s very different than if you were to just copy, paste out a spreadsheet or a PDF and paste into ChatGPT.\"This architectural choice means that the Intuit Intelligence system functions more as an orchestration layer. It&#x27;s a natural language interface to structured data operations. When a user asks about projected profitability or wants to run payroll, the system translates the natural language query into database operations against verified financial data.This matters because Intuit&#x27;s internal research has uncovered widespread shadow AI usage. When surveyed, 25% of accountants using QuickBooks admitted they were already copying and pasting data into ChatGPT or Google Gemini for analysis.Intuit&#x27;s approach treats AI as a query translation and orchestration mechanism, not a content generator. This reduces the hallucination risk that has plagued AI deployments in financial contexts.Explainability as a design requirement, not an afterthoughtBeyond the technical architecture, Intuit has made explainability a core user experience across its AI agents. This goes beyond simply providing correct answers: It means showing users the reasoning behind automated decisions.When Intuit&#x27;s accounting agent categorizes a transaction, it doesn&#x27;t just display the result; it shows the reasoning. This isn&#x27;t marketing copy about explainable AI, it&#x27;s actual UI displaying data points and logic.\"It&#x27;s about closing that trust loop and making sure customers understand the why,\" Alastair Simpson, Intuit&#x27;s VP of design, told VentureBeat.This becomes particularly critical when you consider Intuit&#x27;s user research: While half of small businesses describe AI as helpful, nearly a quarter haven&#x27;t used AI at all. The explanation layer serves both populations: Building confidence for newcomers, while giving experienced users the context to verify accuracy.The design also enforces human control at critical decision points. This approach extends beyond the interface. Intuit connects users directly with human experts, embedded in the same workflows, when automation reaches its limits or when users want validation.Navigating the transition from forms to conversationsOne of Intuit&#x27;s more interesting challenges involves managing a fundamental shift in user interfaces. Preston described it as having one foot in the past and one foot in the future.\"This isn&#x27;t just Intuit, this is the market as a whole,\" said Preston. \"Today we still have a lot of customers filling out forms and going through tables full of data. We&#x27;re investing a lot into leaning in and questioning the ways that we do it across our products today, where you&#x27;re basically just filling out, form after form, or table after table, because we see where the world is headed, which is really a different form of interacting with these products.\"This creates a product design challenge: How do you serve users who are comfortable with traditional interfaces while gradually introducing conversational and agentic capabilities?Intuit&#x27;s approach has been to embed AI agents directly into existing workflows. This means not forcing users to adopt entirely new interaction patterns. The payments agent appears alongside invoicing workflows; the accounting agent enhances the existing reconciliation process rather than replacing it. This incremental approach lets users experience AI benefits without abandoning familiar processes.What enterprise AI builders can learn from Intuit&#x27;s approachIntuit&#x27;s experience deploying AI in financial contexts surfaces several principles that apply broadly to enterprise AI initiatives. Architecture matters for trust: In domains where accuracy is critical, consider whether you need content generation or data query translation. Intuit&#x27;s decision to treat AI as an orchestration and natural language interface layer dramatically reduces hallucination risk and avoids using AI as a generative system.Explainability must be designed in, not bolted on: Showing users why the AI made a decision isn&#x27;t optional when trust is at stake. This requires deliberate UX design. It may constrain model choices.User control preserves trust during accuracy improvements: Intuit&#x27;s accounting agent improved categorization accuracy by 20 percentage points. Yet, maintaining user override capabilities was essential for adoption.Transition gradually from familiar interfaces: Don&#x27;t force users to abandon forms for conversations. Embed AI capabilities into existing workflows first. Let users experience benefits before asking them to change behavior.Be honest about what&#x27;s reactive versus proactive: Current AI agents primarily respond to prompts and automate defined tasks. True proactive intelligence that makes unprompted strategic recommendations remains an evolving capability. Address workforce concerns with tooling, not just messaging: If AI is meant to augment rather than replace workers, provide workers with AI tools. Show them how to leverage the technology.For enterprises navigating AI adoption, Intuit&#x27;s journey offers a clear directive. The winning approach prioritizes trustworthiness over capability demonstrations. In domains where mistakes have real consequences, that means investing in accuracy, transparency and human oversight before pursuing conversational sophistication or autonomous action.Simpson frames the challenge succinctly: \"We didn&#x27;t want it to be a bolted-on layer. We wanted customers to be in their natural workflow, and have agents doing work for customers, embedded in the workflow.\"",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/26uFKCJx7guEmpRjNxJdWl/bee15b7153fa921dc410f50175781a25/ai_trust_in_a_bucket-SMK.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/apples-macbook-air-m4-is-back-on-sale-for-799-183808431.html",
          "published_at": "Tue, 28 Oct 2025 12:14:35 +0000",
          "title": "Apple's MacBook Air M4 is back on sale for $799",
          "standfirst": "Now's a great time to pick up a new MacBook Air if you've been thinking about taking the plunge. Amazon has the M4-powered, 13-inch MacBook Air for a record-low price of $799 right now. The 20 percent discount applies to multiple colors, too. We ranked this as our favorite Apple laptop in our list of the best MacBook computers. Heck, it's even our very favorite laptop. Full stop. The performance is exceptionally snappy, thanks to the M4 chip. We appreciated the upgraded battery life, which now lasts for around 18 hours per charge. That's well beyond a full day of work. The design is lightweight, but sturdy. This has become a hallmark for modern MacBook Air computers. The screen is both gorgeous and roomy, even though it's technically just a 13-inch panel. There's support for the P3 wide color gamut and it can reach up to 500 nits of brightness. This is a near-perfect laptop, but there are a couple of nitpicks. There's no USB-C port on the right side, limiting how users can arrange accessories on a desk. Also, the screen is capped with a 60Hz refresh rate. Another potential complication is the looming specter of the M5 chip. The company has already released the MacBook Pro M5, so a new MacBook Air is likely coming in the nearish future. If you need more screen space, you'll find a similar discount on the 15-inch MacBook Air on Amazon, too. Most color options are $200 off and down to $999 for the base model. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apples-macbook-air-m4-is-back-on-sale-for-799-183808431.html?src=rss",
          "content": "Now's a great time to pick up a new MacBook Air if you've been thinking about taking the plunge. Amazon has the M4-powered, 13-inch MacBook Air for a record-low price of $799 right now. The 20 percent discount applies to multiple colors, too. We ranked this as our favorite Apple laptop in our list of the best MacBook computers. Heck, it's even our very favorite laptop. Full stop. The performance is exceptionally snappy, thanks to the M4 chip. We appreciated the upgraded battery life, which now lasts for around 18 hours per charge. That's well beyond a full day of work. The design is lightweight, but sturdy. This has become a hallmark for modern MacBook Air computers. The screen is both gorgeous and roomy, even though it's technically just a 13-inch panel. There's support for the P3 wide color gamut and it can reach up to 500 nits of brightness. This is a near-perfect laptop, but there are a couple of nitpicks. There's no USB-C port on the right side, limiting how users can arrange accessories on a desk. Also, the screen is capped with a 60Hz refresh rate. Another potential complication is the looming specter of the M5 chip. The company has already released the MacBook Pro M5, so a new MacBook Air is likely coming in the nearish future. If you need more screen space, you'll find a similar discount on the 15-inch MacBook Air on Amazon, too. Most color options are $200 off and down to $999 for the base model. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apples-macbook-air-m4-is-back-on-sale-for-799-183808431.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/adobes-new-photoshop-ai-assistant-can-automate-repetitive-tasks-120032017.html",
          "published_at": "Tue, 28 Oct 2025 12:00:32 +0000",
          "title": "Adobe's new Photoshop AI Assistant can automate repetitive tasks",
          "standfirst": "Among the usual slew of AI enhancements to its Creative Cloud apps, Adobe has introduced a new Photoshop AI Assistant to help automate repetitive chores and provide personalized recommendations. At Adobe Max 2025, the company also introduced new tools for Photoshop, Premiere and Lightroom, while launching a new AI generative model and bringing in new third party models from Topaz and others. A key new feature in Photoshop and Express (Adobe's all-in-one design, photo, and video tool) is the AI Assistant that lets you can chat with in a conversational manner to gain \"more control, power and potential time-savings,\" according to Adobe. With that, you can tell it to take on a series of creative tasks like color correction on resizing. You can easily switch between prompts with the agent and manual tools like sliders to adjust brightness and contrast. It can also provide personalized recommendations and offer tutorials on how to accomplish complex tasks. In a brief demo, Adobe showed that when you switch to Photoshop's \"agentic\" mode in those apps, it minimizes the usual complex interface and leaves you with a simple prompt-based UI. You can then type in the task you want to accomplish, and the agent will perform those steps automatically. You can then jump back into the full interface to fine tune the result by changing things like brightness or levels. Along with the AI Assistant, Adobe introduced a few other AI tools for Photoshop. Chief among those are new partner models for generative fill that lets you easily remove unwanted objects and fill in the hole left behind. Those include Google Gemini 2.5 f!ash, Black Forest Labs FLUX.1 Kontext and Adobe's latest Firefly Image Models. It also introduced Firefly Image Model 5, Adobe's most advanced image generation model yet. Photoshop also gains new Generative Upscale option that uses Topaz Lab's AI to upscale small, cropped and other low-resolution images into 4K with \"realistic detail,\" Adobe says. Another feature, Harmonize, lets you place objects or people into different environments in a realistic manner, eliminating much of work necessary for such compositing. Harmonize also matches the light, color and tone of foreground objects and people to the background. Adobe Premiere, meanwhile, introduced a similar feature called AI Object Mask that performs automatic identification and isolation of people and objects in video, so they can be edited and tracked without any manual rotoscoping. The app also gains new rectangle, ellipse and pen masking in Premiere to make targeted adjustments, along with a fast vector mask for quicker tracking. Finally, LIghtroom is getting a new feature called Assisted Culling. It lets you quickly and easily identify the best images in a large photo collection, with the ability to filter for things like focus level, angles and degrees of sharpness. Photoshop’s Generative Fill with Partner Models, Generative Upscale and Harmonize are now available to customers today. Premiere’s AI Object Mask, Rectangle, Ellipse and Pen Masking and Fast Vector Mask, along with Lightroom's AI Assisted Culling, launch today in beta. Adobe's Photoshop AI Assistant, meanwhile, will be available through a private beta waitlist. This article originally appeared on Engadget at https://www.engadget.com/apps/adobes-new-photoshop-ai-assistant-can-automate-repetitive-tasks-120032017.html?src=rss",
          "content": "Among the usual slew of AI enhancements to its Creative Cloud apps, Adobe has introduced a new Photoshop AI Assistant to help automate repetitive chores and provide personalized recommendations. At Adobe Max 2025, the company also introduced new tools for Photoshop, Premiere and Lightroom, while launching a new AI generative model and bringing in new third party models from Topaz and others. A key new feature in Photoshop and Express (Adobe's all-in-one design, photo, and video tool) is the AI Assistant that lets you can chat with in a conversational manner to gain \"more control, power and potential time-savings,\" according to Adobe. With that, you can tell it to take on a series of creative tasks like color correction on resizing. You can easily switch between prompts with the agent and manual tools like sliders to adjust brightness and contrast. It can also provide personalized recommendations and offer tutorials on how to accomplish complex tasks. In a brief demo, Adobe showed that when you switch to Photoshop's \"agentic\" mode in those apps, it minimizes the usual complex interface and leaves you with a simple prompt-based UI. You can then type in the task you want to accomplish, and the agent will perform those steps automatically. You can then jump back into the full interface to fine tune the result by changing things like brightness or levels. Along with the AI Assistant, Adobe introduced a few other AI tools for Photoshop. Chief among those are new partner models for generative fill that lets you easily remove unwanted objects and fill in the hole left behind. Those include Google Gemini 2.5 f!ash, Black Forest Labs FLUX.1 Kontext and Adobe's latest Firefly Image Models. It also introduced Firefly Image Model 5, Adobe's most advanced image generation model yet. Photoshop also gains new Generative Upscale option that uses Topaz Lab's AI to upscale small, cropped and other low-resolution images into 4K with \"realistic detail,\" Adobe says. Another feature, Harmonize, lets you place objects or people into different environments in a realistic manner, eliminating much of work necessary for such compositing. Harmonize also matches the light, color and tone of foreground objects and people to the background. Adobe Premiere, meanwhile, introduced a similar feature called AI Object Mask that performs automatic identification and isolation of people and objects in video, so they can be edited and tracked without any manual rotoscoping. The app also gains new rectangle, ellipse and pen masking in Premiere to make targeted adjustments, along with a fast vector mask for quicker tracking. Finally, LIghtroom is getting a new feature called Assisted Culling. It lets you quickly and easily identify the best images in a large photo collection, with the ability to filter for things like focus level, angles and degrees of sharpness. Photoshop’s Generative Fill with Partner Models, Generative Upscale and Harmonize are now available to customers today. Premiere’s AI Object Mask, Rectangle, Ellipse and Pen Masking and Fast Vector Mask, along with Lightroom's AI Assisted Culling, launch today in beta. Adobe's Photoshop AI Assistant, meanwhile, will be available through a private beta waitlist. This article originally appeared on Engadget at https://www.engadget.com/apps/adobes-new-photoshop-ai-assistant-can-automate-repetitive-tasks-120032017.html?src=rss",
          "feed_position": 23,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c006cdd0-b3d6-11f0-bfab-c6c8e3cf1ac7"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/adobes-firefly-can-now-use-ai-to-generate-soundtracks-speech-and-video-120018593.html",
          "published_at": "Tue, 28 Oct 2025 12:00:18 +0000",
          "title": "Adobe's Firefly can now use AI to generate soundtracks, speech and video",
          "standfirst": "Adobe has released the latest version of Firefly that now leans heavily on AI for nearly every facet of video and image post-production. The updated app can now use AI to generate narration, music, images and video clips, while even helping you to brainstorm ideas and piece together clips. Many creators may find it distasteful to lean on AI for nearly every aspect of production, but Adobe calls it \"a tool for, not a replacement of, human creativity.\" Firefly has mostly been a content generation tool until now, but Adobe has now introduced the Firefly video editor into private beta. It's a web-based multitrack timeline editor, not unlike Adobe Premiere Pro, that lets you generate, organize, trim and arrange clips, with tools to add voiceovers, soundtracks and titles. You can organize existing Firefly content or generate new ones inside the editor (with presets like claymation, anime and 2D), and combine that with captured media. All that can be edited with \"frame-by-frame precision or through a built-in transcript,\" Adobe said. On top of video, Firefly eliminates the need for humans to make voiceovers and music, too. Adobe's new Generate Soundtrack (public beta) is a Firefly Audio Model-powered AI music generator that lets you select a style or comes up with one to match any clip you upload. It then syncs and times it precisely with that footage. Generate Speech, meanwhile, does the same thing for voiceovers. It gives you a choice between Firefly's Speech Model and one for ElevenLabs, letting you generate \"lifelike voices in multiple languages, and fine-tune emotion, pacing and emphasis for natural, expressive delivery.\" Adobe Adobe is also expanding access to its Fire!y Creative Production tool directly in the Fire!y app as a private beta to start with. It's a complete AI-powered batch image editing system that lets creators piece together clips, automatically replace backgrounds, apply uniform color grading and crop in via a prompt-driven, no code interface. Then there's Fire!y Boards, an \"AI-powered ideation surface\" to brainstorm new concepts. A feature called \"Rotate Object\" helps you convert 2D images into 3D so you can position objects and people in different poses and rotate them to new perspectives. Two others, PDF exporting and bulk image downloading, speed the the process of sharing visual concepts across projects. Finally, Prompt to Edit (available now on Firefly) is a conversational editing interface that allows you to use everyday language to describe the edits you want to make to an image, much as you'd use text-to-image tools like Midjourney to create new images. It's available with Adobe's latest Fire!y Image Model 5 AI, along with partner models from Black Forest Labs, Google and OpenAI. With Firefly's AI now able to handle every aspect of production, you may be wondering if this will result in a wave of unwatchable AI \"slop\" appearing on YouTube and elsewhere. The answer is \"probably,\" but it won't necessarily be cheap. Standalone Firefly subscriptions are $10/month for the basic plan (20 five-second videos), $20/month for the the Pro plan (40 five-second videos) and $199 for the Premium plan (unlimited videos). However, Adobe is throwing in free image and video generation (with some restrictions) for all Firefly and Creative Cloud Pro customers until December 1st. All the new tools are now available either as part of the update, in public beta or in private beta as mentioned above. This article originally appeared on Engadget at https://www.engadget.com/apps/adobes-firefly-can-now-use-ai-to-generate-soundtracks-speech-and-video-120018593.html?src=rss",
          "content": "Adobe has released the latest version of Firefly that now leans heavily on AI for nearly every facet of video and image post-production. The updated app can now use AI to generate narration, music, images and video clips, while even helping you to brainstorm ideas and piece together clips. Many creators may find it distasteful to lean on AI for nearly every aspect of production, but Adobe calls it \"a tool for, not a replacement of, human creativity.\" Firefly has mostly been a content generation tool until now, but Adobe has now introduced the Firefly video editor into private beta. It's a web-based multitrack timeline editor, not unlike Adobe Premiere Pro, that lets you generate, organize, trim and arrange clips, with tools to add voiceovers, soundtracks and titles. You can organize existing Firefly content or generate new ones inside the editor (with presets like claymation, anime and 2D), and combine that with captured media. All that can be edited with \"frame-by-frame precision or through a built-in transcript,\" Adobe said. On top of video, Firefly eliminates the need for humans to make voiceovers and music, too. Adobe's new Generate Soundtrack (public beta) is a Firefly Audio Model-powered AI music generator that lets you select a style or comes up with one to match any clip you upload. It then syncs and times it precisely with that footage. Generate Speech, meanwhile, does the same thing for voiceovers. It gives you a choice between Firefly's Speech Model and one for ElevenLabs, letting you generate \"lifelike voices in multiple languages, and fine-tune emotion, pacing and emphasis for natural, expressive delivery.\" Adobe Adobe is also expanding access to its Fire!y Creative Production tool directly in the Fire!y app as a private beta to start with. It's a complete AI-powered batch image editing system that lets creators piece together clips, automatically replace backgrounds, apply uniform color grading and crop in via a prompt-driven, no code interface. Then there's Fire!y Boards, an \"AI-powered ideation surface\" to brainstorm new concepts. A feature called \"Rotate Object\" helps you convert 2D images into 3D so you can position objects and people in different poses and rotate them to new perspectives. Two others, PDF exporting and bulk image downloading, speed the the process of sharing visual concepts across projects. Finally, Prompt to Edit (available now on Firefly) is a conversational editing interface that allows you to use everyday language to describe the edits you want to make to an image, much as you'd use text-to-image tools like Midjourney to create new images. It's available with Adobe's latest Fire!y Image Model 5 AI, along with partner models from Black Forest Labs, Google and OpenAI. With Firefly's AI now able to handle every aspect of production, you may be wondering if this will result in a wave of unwatchable AI \"slop\" appearing on YouTube and elsewhere. The answer is \"probably,\" but it won't necessarily be cheap. Standalone Firefly subscriptions are $10/month for the basic plan (20 five-second videos), $20/month for the the Pro plan (40 five-second videos) and $199 for the Premium plan (unlimited videos). However, Adobe is throwing in free image and video generation (with some restrictions) for all Firefly and Creative Cloud Pro customers until December 1st. All the new tools are now available either as part of the update, in public beta or in private beta as mentioned above. This article originally appeared on Engadget at https://www.engadget.com/apps/adobes-firefly-can-now-use-ai-to-generate-soundtracks-speech-and-video-120018593.html?src=rss",
          "feed_position": 24,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/e4827a40-b3c9-11f0-bf5f-a1ecb94b73bd"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/lenovo-legion-go-2-review-the-utility-pc-gaming-handheld-120000533.html",
          "published_at": "Tue, 28 Oct 2025 12:00:00 +0000",
          "title": "Lenovo Legion Go 2 review: The utility PC gaming handheld",
          "standfirst": "When the first big wave of handheld PCs hit the market two to three years ago, they were designed as more travel-friendly and convenient alternatives to traditional gaming rigs. That meant reduced performance in exchange for increased portability. However, there will always be enthusiasts who want more: increased horsepower, better battery life and all sorts of extra features. Out of all the handhelds on the market today, there's practically no device with more tools and special equipment than the Lenovo Legion Go 2. However, just like a luxury SUV, this bucket of components commands a hefty premium and has capabilities that you might not use every day. But if you are the type of person who's looking for a flagship portable PC with all the bells and whistles, the Legion Go 2 is a true utility gaming handheld. Design The Legion Go 2 looks like a Switch 2 that's fattened up before hibernating for the winter. It has the same basic design with detachable controllers on either side and a screen in the middle; it's just way bigger and bulkier. The Legion Go 2 weighs two pounds and measures 11.6 inches wide (with its controllers attached) compared to 1.6 pounds and 11.4 inches for the ROG Xbox Ally X (and that's including its big, pronounced grips). Both devices make the Switch 2 look downright petite with its 1.2 pounds and 10.7-inch-wide frame. Both the Legion Go 2's left and right controllers can be detached. However, Lenovo used regular old latches instead of magnets, so removing them is clunkier compared to the Switch 2. Sam Rutherford for Engadget Unfortunately, without the magnets that Nintendo uses on the Joy-Con, disconnecting the gamepads on the Legion Go 2 isn't nearly as smooth or easy, but it's still relatively manageable. On the flipside, Lenovo uses Hall Effect sensors for its joysticks, which makes them super responsive, even though they're lighter to push around. I appreciate that, unlike many of its rivals, Lenovo kept the kickstand from its predecessor, as it's super handy if you want to prop the Legion Go 2 up and use it like a mini desktop. Elsewhere, there is a familiar layout for the Legion Go 2’s D-pad, face buttons and shoulder triggers/bumpers, along with two pairs of paddles around back. Critically, Lenovo retained the built-in touchpad on the right controller, which is super handy for those times when you need to mouse around in the Windows 11 desktop. And like its predecessor, you can detach the right gamepad, flick the hidden switch on the bottom into FPS mode and then combine it with Lenovo's included base to create a vertical mouse of sorts. Here's how the size of the Lenovo Legion Go 2 (top) compares to a major rival like the ROG Xbox Ally X (bottom). Sam Rutherford for Engadget Ostensibly, this setup is meant for people who want extra precision in shooters and there is even an extra set of mouse buttons and an embedded scroll wheel on the controller for that reason. The one hiccup for me is that the puck isn't that much smaller than a typical travel mouse. If I really want ultimate control in FPS games, I'm going to use one of those instead of Lenovo's more awkward alternative. As for connectivity, the Legion Go 2 features two USB-C ports (one on top and one on bottom) which support data (up to 40 Gbps), power delivery and display output. There's also a microSD card slot for expandable storage and a 3.5mm audio jack. While a lot of rival handhelds skip this feature, I appreciate that Lenovo still put a kickstand on the back of the Legion Go 2. Sam Rutherford for Engadget I have two small nitpicks with the Legion Go 2's design (aside from its size). First, the headphone port is on the bottom, which isn't ideal as I feel like the top USB-C connector is easier to use when gaming while plugged into the wall. Secondly, Lenovo's fingerprint reader (which is built into the power button) is rather finicky. I didn't have issues unlocking the device, but the sensor is so sensitive that often when I pressed the power button to put the Legion Go 2 into sleep mode, the screen turned off before turning itself on again. This resulted in multiple occasions where I thought I put the handheld to sleep inside the included case (kudos to Lenovo for that freebie) only to come back to a device that was very much awake and felt like it was on the verge of cooking itself inside its padded enclosure. Display One of the best features on the Legion Go 2 is its massive 8.8-inch OLED display. Sam Rutherford for Engadget If money and size are not an issue, Lenovo's massive OLED display is the biggest reason to choose the Legion Go 2 over rivals like the ROG Xbox Ally X. At 8.8 inches, it's significantly larger than the 7-inch panel on the ASUS or the 7.9-inch screen on a Switch 2. Not only are its colors super rich and saturated, it has a slightly higher 144Hz refresh rate and a taller 16:10 resolution (1,920 x 1,200). And at 500 nits, it's just as bright as the screen on the ROG Xbox Ally X. The downside is that if you want to game at the Legion Go 2's native res, it does take a little bit of extra performance to achieve stable, playable framerates. Performance and software The $1,100 base model of the Legion Go 2 comes with an AMD Ryzen Z2 chip with 16GB of memory and 1TB of storage. However, if you want even better performance, you'll need to upgrade to the $1,350 version that comes with a Z2 Extreme chip and 32GB of RAM, which is the configuration I tested for this review. Frankly, that is a lot of money to drop on a gaming handheld of any kind, though the Legion Go 2 does make up for it with class-leading performance. Well, almost. If you want big performance, the Z2 Extreme version of the Legion Go 2 is among the best on the market. Sam Rutherford for Engadget While the maxed SKUs of both the Legion Go 2 and ROG Xbox Ally x are based on the same Z2 Extreme chip, Microsoft was able to tweak some of Windows 11's tasks and services that run in the background on Lenovo’s' rival. And while there isn't a huge gap between the two, that optimization does make a difference. Generally, the ROG Xbox Ally produced framerates that were around seven percent higher than what I got from the Legion Go 2 at the same graphics settings and resolution. In Cyberpunk 2077 at 35 watts on medium, 1080p resolution and FSR set to performance, the Legion Go 2 hit 57.5 fps compared to 62.1 fps for the ROG Xbox Ally X. Meanwhile in Returnal at 17 watts on medium, the Lenovo reached 39 fps versus 42 for ASUS. Depending on the game and the exact resolution you're using, that could mean the difference between something being a good experience or not. For example, in Clair Obscur: Expedition 33 at 1080p on medium, the ROG Xbox Ally X hovered right around 30 fps. Granted, that isn't ideal, but it's not bad for a handheld running a relatively new title. But on the Legion Go 2 at its native res, its average framerate was closer to 25 fps, which forced me to drop down to low settings to get a smoother experience. This is what the Legion Go 2's controller looks like when you use it in FPS mode. Sam Rutherford for Engadget Like a lot of Windows-based handhelds, it's important to remember that you get more speed when connected to a power outlet. For example, the Legion Go 2's Performance mode tops out at 20 watts when not plugged in, but increases to 32 watts when it is. And if you want to go all out, you're best off using the Custom setting, which gives you a sustained TDP of 35 watts and the ability to boost to 45 watts for up to 10 seconds. As for the software, Lenovo's Legion Space app has come a long way and it's turned into a solid one-stop shop for launching games, adjusting settings and tweaking performance. As always with Windows-based handhelds, there's still a bit of awkwardness during setup when you're installing titles and having to switch between various menus. Thankfully, Lenovo's built-in touchpad helps smooth that out quite a bit. I'd also argue that because of that trackpad and the handheld's adaptable design, the Legion Go 2 is the most well-equipped portable for anyone who wants to use it like a mini PC. You can prop the display up with its kickstand, connect a display via USB-C and pair a wireless keyboard and mouse (or use the right controller in FPS mode) and suddenly you've got a little desktop for getting some real work done. (Who are we kidding, this is still going to be used for gaming, just on a bigger display with better controls.) Battery Life The top edge of the Legion Go 2 features one USB-C port and its power button/fingerprint reader, while the other is on the bottom along with a 3.5mm audio jack and a microSD card reader. Sam Rutherford for Engadget Thanks to a 74WHr cell and a more efficient chip, the Legion Go 2 has gotten a nice bump battery life over its predecessor. However, due to its big display, its longevity isn't quite as good compared to the ROG Xbox Ally X. I tested this by playing Clair Obscur: Expedition 33 at 1080p on medium graphics and max brightness. The Legion Go 2 did well, lasting almost three hours, though that was 30 minutes shy of what I got from the ROG Xbox Ally X. While you can game for a decent length of time untethered, for any longer trips or time away from an outlet, you'll definitely want to keep the included 65-watt power adapter close at hand. Wrap-up The Lenovo Legion Go 2 is large and in charge — both in price and size. The base model starts at $1,100, which is already $100 more than a fully kitted-out ROG Xbox Ally X with a Ryzen Z2 Extreme chip. Meanwhile, to get the same silicon on Lenovo's handheld, you have to shell out $1,350, and even then, its performance still lags just a tad behind Microsoft and ASUS' collab. But what the Legion Go 2 lacks in value, it makes up for in versatility. The Legion Go 2 comes with an included case and a puck that turns its right controller into a vertical mouse. Sam Rutherford for Engadget Its 8.8-inch OLED display is a huge upgrade in terms of both screen space and image quality, while features like its touchpad, detachable controllers and kickstand make this thing feel more like a portable hybrid PC than a single-purpose gaming machine. Just like an SUV that might go off-road once or twice a year, you might not use the Legion Go 2's full capabilities all the time, but when you do and everything comes together, you realize all that utility isn't just for show. While the ROG Xbox Ally X is the better value, I appreciate how Lenovo's handheld was made to handle a variety of battle conditions. This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/lenovo-legion-go-2-review-the-utility-pc-gaming-handheld-120000533.html?src=rss",
          "content": "When the first big wave of handheld PCs hit the market two to three years ago, they were designed as more travel-friendly and convenient alternatives to traditional gaming rigs. That meant reduced performance in exchange for increased portability. However, there will always be enthusiasts who want more: increased horsepower, better battery life and all sorts of extra features. Out of all the handhelds on the market today, there's practically no device with more tools and special equipment than the Lenovo Legion Go 2. However, just like a luxury SUV, this bucket of components commands a hefty premium and has capabilities that you might not use every day. But if you are the type of person who's looking for a flagship portable PC with all the bells and whistles, the Legion Go 2 is a true utility gaming handheld. Design The Legion Go 2 looks like a Switch 2 that's fattened up before hibernating for the winter. It has the same basic design with detachable controllers on either side and a screen in the middle; it's just way bigger and bulkier. The Legion Go 2 weighs two pounds and measures 11.6 inches wide (with its controllers attached) compared to 1.6 pounds and 11.4 inches for the ROG Xbox Ally X (and that's including its big, pronounced grips). Both devices make the Switch 2 look downright petite with its 1.2 pounds and 10.7-inch-wide frame. Both the Legion Go 2's left and right controllers can be detached. However, Lenovo used regular old latches instead of magnets, so removing them is clunkier compared to the Switch 2. Sam Rutherford for Engadget Unfortunately, without the magnets that Nintendo uses on the Joy-Con, disconnecting the gamepads on the Legion Go 2 isn't nearly as smooth or easy, but it's still relatively manageable. On the flipside, Lenovo uses Hall Effect sensors for its joysticks, which makes them super responsive, even though they're lighter to push around. I appreciate that, unlike many of its rivals, Lenovo kept the kickstand from its predecessor, as it's super handy if you want to prop the Legion Go 2 up and use it like a mini desktop. Elsewhere, there is a familiar layout for the Legion Go 2’s D-pad, face buttons and shoulder triggers/bumpers, along with two pairs of paddles around back. Critically, Lenovo retained the built-in touchpad on the right controller, which is super handy for those times when you need to mouse around in the Windows 11 desktop. And like its predecessor, you can detach the right gamepad, flick the hidden switch on the bottom into FPS mode and then combine it with Lenovo's included base to create a vertical mouse of sorts. Here's how the size of the Lenovo Legion Go 2 (top) compares to a major rival like the ROG Xbox Ally X (bottom). Sam Rutherford for Engadget Ostensibly, this setup is meant for people who want extra precision in shooters and there is even an extra set of mouse buttons and an embedded scroll wheel on the controller for that reason. The one hiccup for me is that the puck isn't that much smaller than a typical travel mouse. If I really want ultimate control in FPS games, I'm going to use one of those instead of Lenovo's more awkward alternative. As for connectivity, the Legion Go 2 features two USB-C ports (one on top and one on bottom) which support data (up to 40 Gbps), power delivery and display output. There's also a microSD card slot for expandable storage and a 3.5mm audio jack. While a lot of rival handhelds skip this feature, I appreciate that Lenovo still put a kickstand on the back of the Legion Go 2. Sam Rutherford for Engadget I have two small nitpicks with the Legion Go 2's design (aside from its size). First, the headphone port is on the bottom, which isn't ideal as I feel like the top USB-C connector is easier to use when gaming while plugged into the wall. Secondly, Lenovo's fingerprint reader (which is built into the power button) is rather finicky. I didn't have issues unlocking the device, but the sensor is so sensitive that often when I pressed the power button to put the Legion Go 2 into sleep mode, the screen turned off before turning itself on again. This resulted in multiple occasions where I thought I put the handheld to sleep inside the included case (kudos to Lenovo for that freebie) only to come back to a device that was very much awake and felt like it was on the verge of cooking itself inside its padded enclosure. Display One of the best features on the Legion Go 2 is its massive 8.8-inch OLED display. Sam Rutherford for Engadget If money and size are not an issue, Lenovo's massive OLED display is the biggest reason to choose the Legion Go 2 over rivals like the ROG Xbox Ally X. At 8.8 inches, it's significantly larger than the 7-inch panel on the ASUS or the 7.9-inch screen on a Switch 2. Not only are its colors super rich and saturated, it has a slightly higher 144Hz refresh rate and a taller 16:10 resolution (1,920 x 1,200). And at 500 nits, it's just as bright as the screen on the ROG Xbox Ally X. The downside is that if you want to game at the Legion Go 2's native res, it does take a little bit of extra performance to achieve stable, playable framerates. Performance and software The $1,100 base model of the Legion Go 2 comes with an AMD Ryzen Z2 chip with 16GB of memory and 1TB of storage. However, if you want even better performance, you'll need to upgrade to the $1,350 version that comes with a Z2 Extreme chip and 32GB of RAM, which is the configuration I tested for this review. Frankly, that is a lot of money to drop on a gaming handheld of any kind, though the Legion Go 2 does make up for it with class-leading performance. Well, almost. If you want big performance, the Z2 Extreme version of the Legion Go 2 is among the best on the market. Sam Rutherford for Engadget While the maxed SKUs of both the Legion Go 2 and ROG Xbox Ally x are based on the same Z2 Extreme chip, Microsoft was able to tweak some of Windows 11's tasks and services that run in the background on Lenovo’s' rival. And while there isn't a huge gap between the two, that optimization does make a difference. Generally, the ROG Xbox Ally produced framerates that were around seven percent higher than what I got from the Legion Go 2 at the same graphics settings and resolution. In Cyberpunk 2077 at 35 watts on medium, 1080p resolution and FSR set to performance, the Legion Go 2 hit 57.5 fps compared to 62.1 fps for the ROG Xbox Ally X. Meanwhile in Returnal at 17 watts on medium, the Lenovo reached 39 fps versus 42 for ASUS. Depending on the game and the exact resolution you're using, that could mean the difference between something being a good experience or not. For example, in Clair Obscur: Expedition 33 at 1080p on medium, the ROG Xbox Ally X hovered right around 30 fps. Granted, that isn't ideal, but it's not bad for a handheld running a relatively new title. But on the Legion Go 2 at its native res, its average framerate was closer to 25 fps, which forced me to drop down to low settings to get a smoother experience. This is what the Legion Go 2's controller looks like when you use it in FPS mode. Sam Rutherford for Engadget Like a lot of Windows-based handhelds, it's important to remember that you get more speed when connected to a power outlet. For example, the Legion Go 2's Performance mode tops out at 20 watts when not plugged in, but increases to 32 watts when it is. And if you want to go all out, you're best off using the Custom setting, which gives you a sustained TDP of 35 watts and the ability to boost to 45 watts for up to 10 seconds. As for the software, Lenovo's Legion Space app has come a long way and it's turned into a solid one-stop shop for launching games, adjusting settings and tweaking performance. As always with Windows-based handhelds, there's still a bit of awkwardness during setup when you're installing titles and having to switch between various menus. Thankfully, Lenovo's built-in touchpad helps smooth that out quite a bit. I'd also argue that because of that trackpad and the handheld's adaptable design, the Legion Go 2 is the most well-equipped portable for anyone who wants to use it like a mini PC. You can prop the display up with its kickstand, connect a display via USB-C and pair a wireless keyboard and mouse (or use the right controller in FPS mode) and suddenly you've got a little desktop for getting some real work done. (Who are we kidding, this is still going to be used for gaming, just on a bigger display with better controls.) Battery Life The top edge of the Legion Go 2 features one USB-C port and its power button/fingerprint reader, while the other is on the bottom along with a 3.5mm audio jack and a microSD card reader. Sam Rutherford for Engadget Thanks to a 74WHr cell and a more efficient chip, the Legion Go 2 has gotten a nice bump battery life over its predecessor. However, due to its big display, its longevity isn't quite as good compared to the ROG Xbox Ally X. I tested this by playing Clair Obscur: Expedition 33 at 1080p on medium graphics and max brightness. The Legion Go 2 did well, lasting almost three hours, though that was 30 minutes shy of what I got from the ROG Xbox Ally X. While you can game for a decent length of time untethered, for any longer trips or time away from an outlet, you'll definitely want to keep the included 65-watt power adapter close at hand. Wrap-up The Lenovo Legion Go 2 is large and in charge — both in price and size. The base model starts at $1,100, which is already $100 more than a fully kitted-out ROG Xbox Ally X with a Ryzen Z2 Extreme chip. Meanwhile, to get the same silicon on Lenovo's handheld, you have to shell out $1,350, and even then, its performance still lags just a tad behind Microsoft and ASUS' collab. But what the Legion Go 2 lacks in value, it makes up for in versatility. The Legion Go 2 comes with an included case and a puck that turns its right controller into a vertical mouse. Sam Rutherford for Engadget Its 8.8-inch OLED display is a huge upgrade in terms of both screen space and image quality, while features like its touchpad, detachable controllers and kickstand make this thing feel more like a portable hybrid PC than a single-purpose gaming machine. Just like an SUV that might go off-road once or twice a year, you might not use the Legion Go 2's full capabilities all the time, but when you do and everything comes together, you realize all that utility isn't just for show. While the ROG Xbox Ally X is the better value, I appreciate how Lenovo's handheld was made to handle a variety of battle conditions. This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/lenovo-legion-go-2-review-the-utility-pc-gaming-handheld-120000533.html?src=rss",
          "feed_position": 27,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/legion-Go-2-left-side.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-111545206.html",
          "published_at": "Tue, 28 Oct 2025 11:15:45 +0000",
          "title": "The Morning After: Rivian spinoff Also made a modular e-bike with a virtual drivetrain",
          "standfirst": "Spinning off from Rivian, the TM-B e-bike is Also’s attempt at a do-it-all e-bike. It’s pitching it as flexible enough for commuting, trail riding or kid- and cargo-hauling because its modular frame can swap in bench seats or cargo racks. But the frame only comes in a single size. Still, Also (hate that name) says the standard battery is good for 60 miles of riding and can be charged via USB-C. Engadget Besides the modularity, another unique feature is its drive system, called DreamRide. Instead of a mechanical connection between the bike’s rear wheel and the pedals, the TM-B uses “software-defined pedaling,” so pedaling transfers to the generator (and the battery) instead of simply pushing you forward. It’s a different take on e-bike riding, and I’m not entirely sold on it. From the people that brought you Rivian vehicles, there are plenty more tech touches, including a 5-inch touchscreen display and a built-in security system that automatically locks the frame and rear wheel when you walk away, a la Cowboy and VanMoof. The first model to ship will be the $4,500 TM-B Limited Launch Edition, which has a range of up to 100 miles. There’s also a $4,500 TM-B Performance model, with a slightly different color scheme, available in the “first half” of 2026. Finally, there’s a base-level TM-B model with a range of up to 60 miles, which only comes with standard ride modes. Also hasn’t announced an exact price but says it will cost less than $4,000 when it ships “later in 2026.” — Mat Smith Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed Federal investigators are looking into Tesla’s Mad Max mode, which reportedly defies speed limits Microsoft apparently ordered its Xbox division to boost profits to an unrealistic level How to improve your smartphone photography Cinemark is adding more 70mm IMAX screens ahead of Christopher Nolan’s The Odyssey How to cancel your Peacock subscription Google’s AI health coach will soon be available to some Fitbit Premium users You’ll chat with a bot. Google A preview version of Google’s long-awaited AI health coach launches tomorrow for some Fitbit Premium users in the US. Google says it’ll incorporate user feedback to “add, change or improve features and capabilities.” The company warns users that “initially, there will be some gaps” as it sort of beta tests the coach. The coach can be a sounding board for personal health, fitness and sleep goals and also acts as a personal trainer. Google says it can check progress, create workouts, give advice on trends and review and adjust fitness plans. Continue reading. US Customs and Border Protection will photograph visitors for facial recognition database Welcome to America. The US Customs and Border Protection (CBP) submitted a new measure that allows it — for facial recognition — to photograph any non-US citizen who enters or exits the country. CBP and the Department of Homeland Security want to crack down on threats of terrorism, fraudulent use of travel documents and anyone who exceeds their authorized stay, according to a filing with the government’s Federal Register. The government agency can already request photos and fingerprints from anyone entering the country, but this rule change would allow it to gather photos of anyone exiting as well. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111545206.html?src=rss",
          "content": "Spinning off from Rivian, the TM-B e-bike is Also’s attempt at a do-it-all e-bike. It’s pitching it as flexible enough for commuting, trail riding or kid- and cargo-hauling because its modular frame can swap in bench seats or cargo racks. But the frame only comes in a single size. Still, Also (hate that name) says the standard battery is good for 60 miles of riding and can be charged via USB-C. Engadget Besides the modularity, another unique feature is its drive system, called DreamRide. Instead of a mechanical connection between the bike’s rear wheel and the pedals, the TM-B uses “software-defined pedaling,” so pedaling transfers to the generator (and the battery) instead of simply pushing you forward. It’s a different take on e-bike riding, and I’m not entirely sold on it. From the people that brought you Rivian vehicles, there are plenty more tech touches, including a 5-inch touchscreen display and a built-in security system that automatically locks the frame and rear wheel when you walk away, a la Cowboy and VanMoof. The first model to ship will be the $4,500 TM-B Limited Launch Edition, which has a range of up to 100 miles. There’s also a $4,500 TM-B Performance model, with a slightly different color scheme, available in the “first half” of 2026. Finally, there’s a base-level TM-B model with a range of up to 60 miles, which only comes with standard ride modes. Also hasn’t announced an exact price but says it will cost less than $4,000 when it ships “later in 2026.” — Mat Smith Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed Federal investigators are looking into Tesla’s Mad Max mode, which reportedly defies speed limits Microsoft apparently ordered its Xbox division to boost profits to an unrealistic level How to improve your smartphone photography Cinemark is adding more 70mm IMAX screens ahead of Christopher Nolan’s The Odyssey How to cancel your Peacock subscription Google’s AI health coach will soon be available to some Fitbit Premium users You’ll chat with a bot. Google A preview version of Google’s long-awaited AI health coach launches tomorrow for some Fitbit Premium users in the US. Google says it’ll incorporate user feedback to “add, change or improve features and capabilities.” The company warns users that “initially, there will be some gaps” as it sort of beta tests the coach. The coach can be a sounding board for personal health, fitness and sleep goals and also acts as a personal trainer. Google says it can check progress, create workouts, give advice on trends and review and adjust fitness plans. Continue reading. US Customs and Border Protection will photograph visitors for facial recognition database Welcome to America. The US Customs and Border Protection (CBP) submitted a new measure that allows it — for facial recognition — to photograph any non-US citizen who enters or exits the country. CBP and the Department of Homeland Security want to crack down on threats of terrorism, fraudulent use of travel documents and anyone who exceeds their authorized stay, according to a filing with the government’s Federal Register. The government agency can already request photos and fingerprints from anyone entering the country, but this rule change would allow it to gather photos of anyone exiting as well. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111545206.html?src=rss",
          "feed_position": 28,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/60cd8d70-b3e2-11f0-b575-d427a31cf740"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/best-2-in-1-laptops-173038508.html",
          "published_at": "Tue, 28 Oct 2025 09:00:36 +0000",
          "title": "The best 2-in-1 laptops and tablets for 2025",
          "standfirst": "While the excitement around 2-in-1 systems has cooled a bit over the years, they’re still useful solutions for anyone who wants a device that can act as both a tablet and a traditional laptop. In tablet mode, they’re handy for jotting down notes and drawing pictures, and in their full laptop configurations, they can let you manage e-mail and write as you would with a traditional notebook. Whether you’re a student, creative or just want a more flexible setup, a 2-in-1 solution gives you the best of both worlds without having to carry multiple devices.We've tested and reviewed some of the top 2-in-1 options out there from brands like HP, Microsoft, Samsung and Apple. Whether you’re looking for a Windows PC that can occasionally act like a tablet, or traditional slates that can be empowered with keyboard accessories, we’ve rounded up the best models to consider. Factors to consider before buying a 2-in-1 laptop When you’re shopping for a 2-in-1 system, there are some basic criteria to keep in mind. First off, consider the type of machine you’re looking for. Do you want something that can look like a traditional Windows laptop, but also has a screen that can twist into different orientations? (We often call these convertibles.) Or do you want a standalone tablet that works with a separate keyboard attachment? Tablet setups are typically lighter, but they’re often harder to use on your lap since they rely on kickstands or awkward cases. Also, while some 2-in-1s offer built-in LTE or 5G connectivity, not everyone will want to pay the premium for it. An integrated cellular radio makes checking emails or replying to messages on the go far more convenient. But it also often costs more — and that’s on top of what you’ll pay for data. And as for 5G, you can hold off on it unless you live within range of a mmWave beacon. Coverage is still spotty and existing nationwide networks use the slower sub-6 technology that’s barely faster than LTE. For now, tethering a PC to your phone is still the best way to get online. When it comes to tablet keyboards, you’ll also have to make peace with the fact that they’ll never feel as responsive as full-fledged laptop options. Their keys are shallower, and their layouts are often a bit different than typical PCs. Again, there’s a cost for portability. See Also: Best Laptops for 2025 Best Gaming Laptops Best Cheap Windows Laptops for 2025 Best Chromebooks Best Laptops for College Students Sometimes, getting a third-party tablet keyboard might be just as good, and they’re often cheaper than first-party offerings. If you’re looking to save some money, Logitech’s Slim Folio is an affordable option for iPads, and if you don’t need your keyboard to attach to your tablet, Logitech’s K780 Multi-Device wireless keyboard is also a good pick. While we’ve typically made sure to include a budget 2-in-1 in previous years, this time there isn’t a great choice. We would usually pick a Surface Go, but the latest model is still too expensive. Other alternatives, like cheaper Android tablets, are underpowered and don’t offer a great multitasking interface. If you want something around $500 that’s thin, lightweight and long-lasting, you’re better off this year looking at a traditional laptop (like those on our best budget PCs list). Alternatively, you might consider one of our top picks for the best Chromebooks, either as a back-to-school option or for basic tasks. Best 2-in-1 laptops Recent updates October 2025: Updated to include the latest iPad Pro. February 2025: We’ve retitled this guide to “Best 2-in-1 laptops and tablets” to be more accurate, and we’ve also updated the introduction and “Factors to consider” section to refer to convertible laptops and detachable tablet options. June 2024: We updated our top picks to include the Microsoft Surface Pro Copilot+ edition. Nathan Ingraham contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-2-in-1-laptops-173038508.html?src=rss",
          "content": "While the excitement around 2-in-1 systems has cooled a bit over the years, they’re still useful solutions for anyone who wants a device that can act as both a tablet and a traditional laptop. In tablet mode, they’re handy for jotting down notes and drawing pictures, and in their full laptop configurations, they can let you manage e-mail and write as you would with a traditional notebook. Whether you’re a student, creative or just want a more flexible setup, a 2-in-1 solution gives you the best of both worlds without having to carry multiple devices.We've tested and reviewed some of the top 2-in-1 options out there from brands like HP, Microsoft, Samsung and Apple. Whether you’re looking for a Windows PC that can occasionally act like a tablet, or traditional slates that can be empowered with keyboard accessories, we’ve rounded up the best models to consider. Factors to consider before buying a 2-in-1 laptop When you’re shopping for a 2-in-1 system, there are some basic criteria to keep in mind. First off, consider the type of machine you’re looking for. Do you want something that can look like a traditional Windows laptop, but also has a screen that can twist into different orientations? (We often call these convertibles.) Or do you want a standalone tablet that works with a separate keyboard attachment? Tablet setups are typically lighter, but they’re often harder to use on your lap since they rely on kickstands or awkward cases. Also, while some 2-in-1s offer built-in LTE or 5G connectivity, not everyone will want to pay the premium for it. An integrated cellular radio makes checking emails or replying to messages on the go far more convenient. But it also often costs more — and that’s on top of what you’ll pay for data. And as for 5G, you can hold off on it unless you live within range of a mmWave beacon. Coverage is still spotty and existing nationwide networks use the slower sub-6 technology that’s barely faster than LTE. For now, tethering a PC to your phone is still the best way to get online. When it comes to tablet keyboards, you’ll also have to make peace with the fact that they’ll never feel as responsive as full-fledged laptop options. Their keys are shallower, and their layouts are often a bit different than typical PCs. Again, there’s a cost for portability. See Also: Best Laptops for 2025 Best Gaming Laptops Best Cheap Windows Laptops for 2025 Best Chromebooks Best Laptops for College Students Sometimes, getting a third-party tablet keyboard might be just as good, and they’re often cheaper than first-party offerings. If you’re looking to save some money, Logitech’s Slim Folio is an affordable option for iPads, and if you don’t need your keyboard to attach to your tablet, Logitech’s K780 Multi-Device wireless keyboard is also a good pick. While we’ve typically made sure to include a budget 2-in-1 in previous years, this time there isn’t a great choice. We would usually pick a Surface Go, but the latest model is still too expensive. Other alternatives, like cheaper Android tablets, are underpowered and don’t offer a great multitasking interface. If you want something around $500 that’s thin, lightweight and long-lasting, you’re better off this year looking at a traditional laptop (like those on our best budget PCs list). Alternatively, you might consider one of our top picks for the best Chromebooks, either as a back-to-school option or for basic tasks. Best 2-in-1 laptops Recent updates October 2025: Updated to include the latest iPad Pro. February 2025: We’ve retitled this guide to “Best 2-in-1 laptops and tablets” to be more accurate, and we’ve also updated the introduction and “Factors to consider” section to refer to convertible laptops and detachable tablet options. June 2024: We updated our top picks to include the Microsoft Surface Pro Copilot+ edition. Nathan Ingraham contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-2-in-1-laptops-173038508.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html",
          "published_at": "Tue, 28 Oct 2025 07:00:37 +0000",
          "title": "The best wireless headphones for 2025: Bluetooth options for every budget",
          "standfirst": "Wireless headphones have come a long way from the bulky designs of the past. Today’s models are lighter, smarter and packed with features that make them useful for everything from travel to long workdays at your desk. Many offer strong noise cancellation, quick pairing and reliable battery life — all of which makes them an easy upgrade if you want more freedom from your devices.Of course, not every listener has the same needs. Some people want portability, which is why our guide to the best earbuds is worth a look, while others want something more specialized like the best gaming headsets or the best budget earbuds. But if you’re after over-ear headphones that focus on comfort and immersive sound, this roundup of the best wireless headphones highlights the top choices we’ve tested. Table of contents Best wireless headphones for 2025 How to choose the best wireless headphones for you How we test over-ear headphones Other wireless headphones we tested Wireless headphones FAQs Best wireless headphones for 2025 How to choose the best wireless headphones for you When it comes to shopping for a good pair of wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of our buyer’s guide, we focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear designs are much more effective at blocking sound. Speaking of noise cancellation, you’ll want to determine early on if you even want that. If you frequently crank up the beats in noisy environments, you’ll want to not only make sure it’s there, but also make sure it’s good, preferably with adaptive ANC. If you plan to use your new headphones in quieter spaces, skipping ANC can save you some money. The next area to consider is features. We recommend trying to get the most bang for your buck, but as you’re shopping around you should determine which items are must-haves and what you can live without. And don’t take basic things like automatic pausing and Bluetooth multipoint connectivity for granted, as not all companies include them. We also suggest reading reviews to see how well a company’s more advanced features work. This will help you decide if those are something you’re willing to (likely) pay extra for. Keep an eye on better battery life estimates to avoid disappointment, as some manufacturers promise more hours than real-world testing delivers. And don’t be easily swayed by lofty promises about call quality without verifying them. Sound can be subjective, so we recommend trying before you buy if at all possible. We understand this isn’t easy at a time when we’re doing most of our shopping online. But trying on a set of headphones and listening to them for a few minutes can save you from an expensive case of buyer’s remorse. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all headphones support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you. If you plan to use your headphones for other media besides music, checking for latency is also a must — some delay can impact playback for things like movies or games, even if most true wireless headphones now offer minimal lag. How we test over-ear headphones The primary way we test wireless headphones is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for headphones can be 30 hours or more, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, we’ll typically power the headphones off several times and leave them during a review. This simulates real-world use and keeps us from having to constantly monitor the process for over 24 straight hours. To judge the best Bluetooth headphones, we focus on higher-quality audio by listening to a variety of genres and paying close attention to how each style sounds. We also test at both low and high volumes to check for consistency in the tuning. To assess the quality of phone calls, we’ll record audio samples with the headphones’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that we review. Other wireless headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancelation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor which is actually handy. All told, that’s not a lot in a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Sony WH-CH720N While the WH-CH720N are a great affordable option, we prefer the Audio-Technica in the budget category. Sony’s cans are lightweight with good sound quality, but ANC struggles at times and they’re made with a lot of plastic. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Bose QuietComfort Ultra headphones Bose’s latest flagship model has a lot to offer, but its trademark Immersive Audio feature can be inconsistent across different types of music. There’s still world-class ANC, excellent comfort and a clearer transparency mode, but for the price, the non-Ultra model is a better choice right now. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 are more expensive and not nearly as comfortable as the Px7 S2. Wireless headphones FAQs How can you tell the quality of wireless headphones? I typically look at three factors: design, sound quality and features. In terms of design, I’m usually looking to see if the build quality of the headphones feels cheap and plasticky. Plenty of companies use plastic, but they can do so in a way that doesn’t look or feel like budget models. For sound quality, I want to hear a nice, even tuning where highs, mids and lows are all well represented. No overly boomy bass or scooped out mids. I also want good clarity where you can pick up fine details and an open, immersive soundstage. Features is typically a distant third, but if a company doesn’t cover basic functionality (automatic pausing, transparency mode, multipoint Bluetooth, etc.) it can be an indication of overall quality. How do I choose the best quality wireless headphones? “Best” can be pretty subjective, but I always recommend going to a place where you can listen to the headphones you’re thinking about buying before you commit. Sometimes this isn’t possible, so you’ll want to check return policies. I also recommend doing some research to determine what your priorities are in a new set. Are you an audiophile who wants the best sound quality? Is powerful active noise cancellation (ANC) the most important? Would you rather have conveniences like automatic pausing? Which brand has the best wireless headphones? Sony consistently tops our list with its 1000X line. This is mostly due to the combination of sound quality, ANC performance and the truckload of features these headphones pack in. I’ll be the first to tell you that there are better sounding options and other companies, like Bose, offer more effective noise cancellation. But when you add everything up, no one comes close to the full slate of tools Sony puts in its premium headphone line. Do expensive wireless headphones sound better? Exorbitant price tags don’t mean better audio quality. Bowers & Wilkins’ headphones are on the high end for wireless noise-canceling models and they sound amazing. However, Audio-Technica’s M50xBT2 is much more affordable and doesn’t have ANC, but these headphones have a warm, natural sound profile that I find very inviting. At the end of the day, it will come down to personal preference, but you don’t need to spend a lot to find great headphones.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html?src=rss",
          "content": "Wireless headphones have come a long way from the bulky designs of the past. Today’s models are lighter, smarter and packed with features that make them useful for everything from travel to long workdays at your desk. Many offer strong noise cancellation, quick pairing and reliable battery life — all of which makes them an easy upgrade if you want more freedom from your devices.Of course, not every listener has the same needs. Some people want portability, which is why our guide to the best earbuds is worth a look, while others want something more specialized like the best gaming headsets or the best budget earbuds. But if you’re after over-ear headphones that focus on comfort and immersive sound, this roundup of the best wireless headphones highlights the top choices we’ve tested. Table of contents Best wireless headphones for 2025 How to choose the best wireless headphones for you How we test over-ear headphones Other wireless headphones we tested Wireless headphones FAQs Best wireless headphones for 2025 How to choose the best wireless headphones for you When it comes to shopping for a good pair of wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of our buyer’s guide, we focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear designs are much more effective at blocking sound. Speaking of noise cancellation, you’ll want to determine early on if you even want that. If you frequently crank up the beats in noisy environments, you’ll want to not only make sure it’s there, but also make sure it’s good, preferably with adaptive ANC. If you plan to use your new headphones in quieter spaces, skipping ANC can save you some money. The next area to consider is features. We recommend trying to get the most bang for your buck, but as you’re shopping around you should determine which items are must-haves and what you can live without. And don’t take basic things like automatic pausing and Bluetooth multipoint connectivity for granted, as not all companies include them. We also suggest reading reviews to see how well a company’s more advanced features work. This will help you decide if those are something you’re willing to (likely) pay extra for. Keep an eye on better battery life estimates to avoid disappointment, as some manufacturers promise more hours than real-world testing delivers. And don’t be easily swayed by lofty promises about call quality without verifying them. Sound can be subjective, so we recommend trying before you buy if at all possible. We understand this isn’t easy at a time when we’re doing most of our shopping online. But trying on a set of headphones and listening to them for a few minutes can save you from an expensive case of buyer’s remorse. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all headphones support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you. If you plan to use your headphones for other media besides music, checking for latency is also a must — some delay can impact playback for things like movies or games, even if most true wireless headphones now offer minimal lag. How we test over-ear headphones The primary way we test wireless headphones is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for headphones can be 30 hours or more, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, we’ll typically power the headphones off several times and leave them during a review. This simulates real-world use and keeps us from having to constantly monitor the process for over 24 straight hours. To judge the best Bluetooth headphones, we focus on higher-quality audio by listening to a variety of genres and paying close attention to how each style sounds. We also test at both low and high volumes to check for consistency in the tuning. To assess the quality of phone calls, we’ll record audio samples with the headphones’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that we review. Other wireless headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancelation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor which is actually handy. All told, that’s not a lot in a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Sony WH-CH720N While the WH-CH720N are a great affordable option, we prefer the Audio-Technica in the budget category. Sony’s cans are lightweight with good sound quality, but ANC struggles at times and they’re made with a lot of plastic. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Bose QuietComfort Ultra headphones Bose’s latest flagship model has a lot to offer, but its trademark Immersive Audio feature can be inconsistent across different types of music. There’s still world-class ANC, excellent comfort and a clearer transparency mode, but for the price, the non-Ultra model is a better choice right now. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 are more expensive and not nearly as comfortable as the Px7 S2. Wireless headphones FAQs How can you tell the quality of wireless headphones? I typically look at three factors: design, sound quality and features. In terms of design, I’m usually looking to see if the build quality of the headphones feels cheap and plasticky. Plenty of companies use plastic, but they can do so in a way that doesn’t look or feel like budget models. For sound quality, I want to hear a nice, even tuning where highs, mids and lows are all well represented. No overly boomy bass or scooped out mids. I also want good clarity where you can pick up fine details and an open, immersive soundstage. Features is typically a distant third, but if a company doesn’t cover basic functionality (automatic pausing, transparency mode, multipoint Bluetooth, etc.) it can be an indication of overall quality. How do I choose the best quality wireless headphones? “Best” can be pretty subjective, but I always recommend going to a place where you can listen to the headphones you’re thinking about buying before you commit. Sometimes this isn’t possible, so you’ll want to check return policies. I also recommend doing some research to determine what your priorities are in a new set. Are you an audiophile who wants the best sound quality? Is powerful active noise cancellation (ANC) the most important? Would you rather have conveniences like automatic pausing? Which brand has the best wireless headphones? Sony consistently tops our list with its 1000X line. This is mostly due to the combination of sound quality, ANC performance and the truckload of features these headphones pack in. I’ll be the first to tell you that there are better sounding options and other companies, like Bose, offer more effective noise cancellation. But when you add everything up, no one comes close to the full slate of tools Sony puts in its premium headphone line. Do expensive wireless headphones sound better? Exorbitant price tags don’t mean better audio quality. Bowers & Wilkins’ headphones are on the high end for wireless noise-canceling models and they sound amazing. However, Audio-Technica’s M50xBT2 is much more affordable and doesn’t have ANC, but these headphones have a warm, natural sound profile that I find very inviting. At the end of the day, it will come down to personal preference, but you don’t need to spend a lot to find great headphones.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/paypals-agentic-commerce-play-shows-why-flexibility-not-standards-will",
          "published_at": "Tue, 28 Oct 2025 04:00:00 GMT",
          "title": "PayPal’s agentic commerce play shows why flexibility, not standards, will define the eext c-commerce wave",
          "standfirst": "Enterprises looking to sell goods and services online are waiting for the backbone of agentic commerce to be hashed out; but PayPal is hoping its new features will bridge the gap.The payments company is launching a discoverability solution that allows enterprises to make its product available on any chat platform, regardless of the model or agent payment protocol. PayPal, which is a participant in Google’s Agent Payments Protocol (AP2), found that it can leverage its relationship with merchants and enterprises to help pave the way for an easier transition into agentic commerce and offer flexibility that will benefit the ecosystem. Michelle Gill, PayPal&#x27;s GM for small business and financial services, told VentureBeat that AI-powered shopping will continue to grow, so enterprises and brands must begin laying the groundwork early. “We think that merchants who&#x27;ve historically sold through web stores, particularly in the e-commerce space, are really going to need a way to get active on all of these large language models (LLMs),” Gill said. “The challenge is that no one really knows how fast all of this is going to move. We’re trying to help merchants think through how to do all of this as low-touch as possible while using the infrastructure they already have without doing a bazillion integrations.”She added that AI shopping would also bring about “a resurgence from consumers trying to ensure their investment is protected.”PayPal partnered with website builder Wix, Cymbio, Commerce and Shopware to bring products to chat platforms like Perplexity. Agent-powered shopping PayPal’s Agentic Commerce Services include two features. The first is Agent Ready, which would allow existing PayPal merchants to accept payments on AI platforms. The second is Shop Sync, which will enable companies’ product data to be discoverable through different AI chat interfaces. It takes a company’s catalog information and plug its inventory and fulfillment data to chat platforms. Gill said the data goes into a central repository where AI models can ingest the information. Right now, companies can access Shop Sync; Agent Ready is coming in 2026. Gill said Agentic Commerce Services is a one-to-many solution that would be helpful right now, as different LLMs scrape different data sources to surface information. Other benefits include:Fast integration with current and future partners;More product discovery over the traditional search, browse and cart experiences;Preserved customer insights and relationships where the brand continues to have control over their records and communications with customers. Right now, the service is only available through Perplexity, but Gill said more platforms will be added soon. Fragmented AI platforms Agentic commerce is still very much in the early stages. AI agents are just beginning to get better at reading a browser. while platforms like ChatGPT, Gemini and Perplexity can now surface products and services based on user queries, people cannot technically buy things from chat (yet).There’s a race right now to create a standard to enable agents to transact on behalf of users. Other than Google’s AP2, OpenAI and Stripe have the Agentic Commerce Protocol (ACP), and Visa recently launched its Trusted Agent Protocol. Beyond enabling a trust layer for agents to transact, enterprises struggle with fragmentation in agentic commerce. Different chat platforms use different models, which also interpret information in slightly different ways. Gill said PayPal learned that when it comes to working with merchants, flexibility is critical. “How do you decide if you&#x27;re going to spend your time integrating with Google, Microsoft, ChatGPT or Perplexity?\" Gill noted. \"And each one of them right now has a different protocol, a different catalog, config, a different everything. That is a lot of time to make a bet as to where you should spend your time.\"",
          "content": "Enterprises looking to sell goods and services online are waiting for the backbone of agentic commerce to be hashed out; but PayPal is hoping its new features will bridge the gap.The payments company is launching a discoverability solution that allows enterprises to make its product available on any chat platform, regardless of the model or agent payment protocol. PayPal, which is a participant in Google’s Agent Payments Protocol (AP2), found that it can leverage its relationship with merchants and enterprises to help pave the way for an easier transition into agentic commerce and offer flexibility that will benefit the ecosystem. Michelle Gill, PayPal&#x27;s GM for small business and financial services, told VentureBeat that AI-powered shopping will continue to grow, so enterprises and brands must begin laying the groundwork early. “We think that merchants who&#x27;ve historically sold through web stores, particularly in the e-commerce space, are really going to need a way to get active on all of these large language models (LLMs),” Gill said. “The challenge is that no one really knows how fast all of this is going to move. We’re trying to help merchants think through how to do all of this as low-touch as possible while using the infrastructure they already have without doing a bazillion integrations.”She added that AI shopping would also bring about “a resurgence from consumers trying to ensure their investment is protected.”PayPal partnered with website builder Wix, Cymbio, Commerce and Shopware to bring products to chat platforms like Perplexity. Agent-powered shopping PayPal’s Agentic Commerce Services include two features. The first is Agent Ready, which would allow existing PayPal merchants to accept payments on AI platforms. The second is Shop Sync, which will enable companies’ product data to be discoverable through different AI chat interfaces. It takes a company’s catalog information and plug its inventory and fulfillment data to chat platforms. Gill said the data goes into a central repository where AI models can ingest the information. Right now, companies can access Shop Sync; Agent Ready is coming in 2026. Gill said Agentic Commerce Services is a one-to-many solution that would be helpful right now, as different LLMs scrape different data sources to surface information. Other benefits include:Fast integration with current and future partners;More product discovery over the traditional search, browse and cart experiences;Preserved customer insights and relationships where the brand continues to have control over their records and communications with customers. Right now, the service is only available through Perplexity, but Gill said more platforms will be added soon. Fragmented AI platforms Agentic commerce is still very much in the early stages. AI agents are just beginning to get better at reading a browser. while platforms like ChatGPT, Gemini and Perplexity can now surface products and services based on user queries, people cannot technically buy things from chat (yet).There’s a race right now to create a standard to enable agents to transact on behalf of users. Other than Google’s AP2, OpenAI and Stripe have the Agentic Commerce Protocol (ACP), and Visa recently launched its Trusted Agent Protocol. Beyond enabling a trust layer for agents to transact, enterprises struggle with fragmentation in agentic commerce. Different chat platforms use different models, which also interpret information in slightly different ways. Gill said PayPal learned that when it comes to working with merchants, flexibility is critical. “How do you decide if you&#x27;re going to spend your time integrating with Google, Microsoft, ChatGPT or Perplexity?\" Gill noted. \"And each one of them right now has a different protocol, a different catalog, config, a different everything. That is a lot of time to make a bet as to where you should spend your time.\"",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7pKgIkX0gvCbEs132P6qBy/93b6eff0b869b8f047b79eed33e75a86/crimedy7_illustration_of_robot_paying_for_groceries_--ar_169__3d2a2c22-022a-4104-9070-fab8f94d73d5_0.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool",
          "published_at": "Mon, 27 Oct 2025 19:01:00 GMT",
          "title": "MiniMax-M2 is the new king of open source LLMs (especially for agentic tool calling)",
          "standfirst": "Watch out, DeepSeek and Qwen! There&#x27;s a new king of open source large language models (LLMs), especially when it comes to something enterprises are increasingly valuing: agentic tool use — that is, the ability to go off and use other software capabilities like web search or bespoke applications — without much human guidance. That model is none other than MiniMax-M2, the latest LLM from the Chinese startup of the same name. And in a big win for enterprises globally, the model is available under a permissive, enterprise-friendly MIT License, meaning it is made available freely for developers to take, deploy, retrain, and use how they see fit — even for commercial purposes. It can be found on Hugging Face, GitHub and ModelScope, as well as through MiniMax&#x27;s API here. It supports OpenAI and Anthropic API standards, as well, making it easy for customers of said proprietary AI startups to shift out their models to MiniMax&#x27;s API, if they want.According to independent evaluations by Artificial Analysis, a third-party generative AI model benchmarking and research organization, M2 now ranks first among all open-weight systems worldwide on the Intelligence Index—a composite measure of reasoning, coding, and task-execution performance. In agentic benchmarks that measure how well a model can plan, execute, and use external tools—skills that power coding assistants and autonomous agents—MiniMax’s own reported results, following the Artificial Analysis methodology, show τ²-Bench 77.2, BrowseComp 44.0, and FinSearchComp-global 65.5. These scores place it at or near the level of top proprietary systems like GPT-5 (thinking) and Claude Sonnet 4.5, making MiniMax-M2 the highest-performing open model yet released for real-world agentic and tool-calling tasks.What It Means For Enterprises and the AI RaceBuilt around an efficient Mixture-of-Experts (MoE) architecture, MiniMax-M2 delivers high-end capability for agentic and developer workflows while remaining practical for enterprise deployment.For technical decision-makers, the release marks an important turning point for open models in business settings. MiniMax-M2 combines frontier-level reasoning with a manageable activation footprint—just 10 billion active parameters out of 230 billion total. This design enables enterprises to operate advanced reasoning and automation workloads on fewer GPUs, achieving near-state-of-the-art results without the infrastructure demands or licensing costs associated with proprietary frontier systems.Artificial Analysis’ data show that MiniMax-M2’s strengths go beyond raw intelligence scores. The model leads or closely trails top proprietary systems such as GPT-5 (thinking) and Claude Sonnet 4.5 across benchmarks for end-to-end coding, reasoning, and agentic tool use. Its performance in τ²-Bench, SWE-Bench, and BrowseComp indicates particular advantages for organizations that depend on AI systems capable of planning, executing, and verifying complex workflows—key functions for agentic and developer tools inside enterprise environments.As LLM engineer Pierre-Carl Langlais aka Alexander Doria posted on X: \"MiniMax [is] making a case for mastering the technology end-to-end to get actual agentic automation.\"Compact Design, Scalable PerformanceMiniMax-M2’s technical architecture is a sparse Mixture-of-Experts model with 230 billion total parameters and 10 billion active per inference. This configuration significantly reduces latency and compute requirements while maintaining broad general intelligence. The design allows for responsive agent loops—compile–run–test or browse–retrieve–cite cycles—that execute faster and more predictably than denser models.For enterprise technology teams, this means easier scaling, lower cloud costs, and reduced deployment friction. According to Artificial Analysis, the model can be served efficiently on as few as four NVIDIA H100 GPUs at FP8 precision, a setup well within reach for mid-size organizations or departmental AI clusters.Benchmark Leadership Across Agentic and Coding WorkflowsMiniMax’s benchmark suite highlights strong real-world performance across developer and agent environments. The figure below, released with the model, compares MiniMax-M2 (in red) with several leading proprietary and open models, including GPT-5 (thinking), Claude Sonnet 4.5, Gemini 2.5 Pro, and DeepSeek-V3.2.MiniMax-M2 achieves top or near-top performance in many categories:SWE-bench Verified: 69.4 — close to GPT-5’s 74.9ArtifactsBench: 66.8 — above Claude Sonnet 4.5 and DeepSeek-V3.2τ²-Bench: 77.2 — approaching GPT-5’s 80.1GAIA (text only): 75.7 — surpassing DeepSeek-V3.2BrowseComp: 44.0 — notably stronger than other open modelsFinSearchComp-global: 65.5 — best among tested open-weight systemsThese results show MiniMax-M2’s capability in executing complex, tool-augmented tasks across multiple languages and environments—skills increasingly relevant for automated support, R&D, and data analysis inside enterprises.Strong Showing in Artificial Analysis’ Intelligence IndexThe model’s overall intelligence profile is confirmed in the latest Artificial Analysis Intelligence Index v3.0, which aggregates performance across ten reasoning benchmarks including MMLU-Pro, GPQA Diamond, AIME 2025, IFBench, and τ²-Bench Telecom.MiniMax-M2 scored 61 points, ranking as the highest open-weight model globally and following closely behind GPT-5 (high) and Grok 4. Artificial Analysis highlighted the model’s balance between technical accuracy, reasoning depth, and applied intelligence across domains. For enterprise users, this consistency indicates a reliable model foundation suitable for integration into software engineering, customer support, or knowledge automation systems.Designed for Developers and Agentic SystemsMiniMax engineered M2 for end-to-end developer workflows, enabling multi-file code edits, automated testing, and regression repair directly within integrated development environments or CI/CD pipelines. The model also excels in agentic planning—handling tasks that combine web search, command execution, and API calls while maintaining reasoning traceability.These capabilities make MiniMax-M2 especially valuable for enterprises exploring autonomous developer agents, data analysis assistants, or AI-augmented operational tools. Benchmarks such as Terminal-Bench and BrowseComp demonstrate the model’s ability to adapt to incomplete data and recover gracefully from intermediate errors, improving reliability in production settings.Interleaved Thinking and Structured Tool UseA distinctive aspect of MiniMax-M2 is its interleaved thinking format, which maintains visible reasoning traces between <think>...</think> tags.This enables the model to plan and verify steps across multiple exchanges, a critical feature for agentic reasoning. MiniMax advises retaining these segments when passing conversation history to preserve the model’s logic and continuity.The company also provides a Tool Calling Guide on Hugging Face, detailing how developers can connect external tools and APIs via structured XML-style calls. This functionality allows MiniMax-M2 to serve as the reasoning core for larger agent frameworks, executing dynamic tasks such as search, retrieval, and computation through external functions.Open Source Access and Enterprise Deployment OptionsEnterprises can access the model through the MiniMax Open Platform API and MiniMax Agent interface (a web chat similar to ChatGPT), both currently free for a limited time.MiniMax recommends SGLang and vLLM for efficient serving, each offering day-one support for the model’s unique interleaved reasoning and tool-calling structure. Deployment guides and parameter configurations are available through MiniMax’s documentation.Cost Efficiency and Token EconomicsAs Artificial Analysis noted, MiniMax’s API pricing is set at $0.30 per million input tokens and $1.20 per million output tokens, among the most competitive in the open-model ecosystem. ProviderModel (doc link)Input $/1MOutput $/1MNotesMiniMaxMiniMax-M2$0.30$1.20Listed under “Chat Completion v2” for M2. OpenAIGPT-5$1.25$10.00Flagship model pricing on OpenAI’s API pricing page. OpenAIGPT-5 mini$0.25$2.00Cheaper tier for well-defined tasks. AnthropicClaude Sonnet 4.5$3.00$15.00Anthropic’s current per-MTok list; long-context (>200K input) uses a premium tier. GoogleGemini 2.5 Flash (Preview)$0.30$2.50Prices include “thinking tokens”; page also lists cheaper Flash-Lite and 2.0 tiers. xAIGrok-4 Fast (reasoning)$0.20$0.50“Fast” tier; xAI also lists Grok-4 at $3 / $15. DeepSeekDeepSeek-V3.2 (chat)$0.28$0.42Cache-hit input is $0.028; table shows per-model details. Qwen (Alibaba)qwen-flash (Model Studio)from $0.022from $0.216Tiered by input size (≤128K, ≤256K, ≤1M tokens); listed “Input price / Output price per 1M”. CohereCommand R+ (Aug 2024)$2.50$10.00First-party pricing page also lists Command R ($0.50 / $1.50) and others. Notes & caveats (for readers):Prices are USD per million tokens and can change; check linked pages for updates and region/endpoint nuances (e.g., Anthropic long-context >200K input, Google Live API variants, cache discounts). Vendors may bill extra for server-side tools (web search, code execution) or offer batch/context-cache discounts. While the model produces longer, more explicit reasoning traces, its sparse activation and optimized compute design help maintain a favorable cost-performance balance—an advantage for teams deploying interactive agents or high-volume automation systems.Background on MiniMax — an Emerging Chinese PowerhouseMiniMax has quickly become one of the most closely watched names in China’s fast-rising AI sector. Backed by Alibaba and Tencent, the company moved from relative obscurity to international recognition within a year—first through breakthroughs in AI video generation, then through a series of open-weight large language models (LLMs) aimed squarely at developers and enterprises.The company first captured global attention in late 2024 with its AI video generation tool, “video-01,” which demonstrated the ability to create dynamic, cinematic scenes in seconds. VentureBeat described how the model’s launch sparked widespread interest after online creators began sharing lifelike, AI-generated footage—most memorably, a viral clip of a Star Wars lightsaber duel that drew millions of views in under two days. CEO Yan Junjie emphasized that the system outperformed leading Western tools in generating human movement and expression, an area where video AIs often struggle. The product, later commercialized through MiniMax’s Hailuo platform, showcased the startup’s technical confidence and creative reach, helping to establish China as a serious contender in generative video technology.By early 2025, MiniMax had turned its attention to long-context language modeling, unveiling the MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01. These open-weight models introduced an unprecedented 4-million-token context window, doubling the reach of Google’s Gemini 1.5 Pro and dwarfing OpenAI’s GPT-4o by more than twentyfold. The company continued its rapid cadence with the MiniMax-M1 release in June 2025, a model focused on long-context reasoning and reinforcement learning efficiency. M1 extended context capacity to 1 million tokens and introduced a hybrid Mixture-of-Experts design trained using a custom reinforcement-learning algorithm known as CISPO. Remarkably, VentureBeat reported that MiniMax trained M1 at a total cost of about $534,700, roughly one-tenth of DeepSeek’s R1 and far below the multimillion-dollar budgets typical for frontier-scale models. For enterprises and technical teams, MiniMax’s trajectory signals the arrival of a new generation of cost-efficient, open-weight models designed for real-world deployment. Its open licensing—ranging from Apache 2.0 to MIT—gives businesses freedom to customize, self-host, and fine-tune without vendor lock-in or compliance restrictions. Features such as structured function calling, long-context retention, and high-efficiency attention architectures directly address the needs of engineering groups managing multi-step reasoning systems and data-intensive pipelines.As MiniMax continues to expand its lineup, the company has emerged as a key global innovator in open-weight AI, combining ambitious research with pragmatic engineering. Open-Weight Leadership and Industry ContextThe release of MiniMax-M2 reinforces the growing leadership of Chinese AI research groups in open-weight model development. Following earlier contributions from DeepSeek, Alibaba’s Qwen series, and Moonshot AI, MiniMax’s entry continues the trend toward open, efficient systems designed for real-world use. Artificial Analysis observed that MiniMax-M2 exemplifies a broader shift in focus toward agentic capability and reinforcement-learning refinement, prioritizing controllable reasoning and real utility over raw model size.For enterprises, this means access to a state-of-the-art open model that can be audited, fine-tuned, and deployed internally with full transparency. By pairing strong benchmark performance with open licensing and efficient scaling, MiniMaxAI positions MiniMax-M2 as a practical foundation for intelligent systems that think, act, and assist with traceable logic—making it one of the most enterprise-ready open AI models available today.",
          "content": "Watch out, DeepSeek and Qwen! There&#x27;s a new king of open source large language models (LLMs), especially when it comes to something enterprises are increasingly valuing: agentic tool use — that is, the ability to go off and use other software capabilities like web search or bespoke applications — without much human guidance. That model is none other than MiniMax-M2, the latest LLM from the Chinese startup of the same name. And in a big win for enterprises globally, the model is available under a permissive, enterprise-friendly MIT License, meaning it is made available freely for developers to take, deploy, retrain, and use how they see fit — even for commercial purposes. It can be found on Hugging Face, GitHub and ModelScope, as well as through MiniMax&#x27;s API here. It supports OpenAI and Anthropic API standards, as well, making it easy for customers of said proprietary AI startups to shift out their models to MiniMax&#x27;s API, if they want.According to independent evaluations by Artificial Analysis, a third-party generative AI model benchmarking and research organization, M2 now ranks first among all open-weight systems worldwide on the Intelligence Index—a composite measure of reasoning, coding, and task-execution performance. In agentic benchmarks that measure how well a model can plan, execute, and use external tools—skills that power coding assistants and autonomous agents—MiniMax’s own reported results, following the Artificial Analysis methodology, show τ²-Bench 77.2, BrowseComp 44.0, and FinSearchComp-global 65.5. These scores place it at or near the level of top proprietary systems like GPT-5 (thinking) and Claude Sonnet 4.5, making MiniMax-M2 the highest-performing open model yet released for real-world agentic and tool-calling tasks.What It Means For Enterprises and the AI RaceBuilt around an efficient Mixture-of-Experts (MoE) architecture, MiniMax-M2 delivers high-end capability for agentic and developer workflows while remaining practical for enterprise deployment.For technical decision-makers, the release marks an important turning point for open models in business settings. MiniMax-M2 combines frontier-level reasoning with a manageable activation footprint—just 10 billion active parameters out of 230 billion total. This design enables enterprises to operate advanced reasoning and automation workloads on fewer GPUs, achieving near-state-of-the-art results without the infrastructure demands or licensing costs associated with proprietary frontier systems.Artificial Analysis’ data show that MiniMax-M2’s strengths go beyond raw intelligence scores. The model leads or closely trails top proprietary systems such as GPT-5 (thinking) and Claude Sonnet 4.5 across benchmarks for end-to-end coding, reasoning, and agentic tool use. Its performance in τ²-Bench, SWE-Bench, and BrowseComp indicates particular advantages for organizations that depend on AI systems capable of planning, executing, and verifying complex workflows—key functions for agentic and developer tools inside enterprise environments.As LLM engineer Pierre-Carl Langlais aka Alexander Doria posted on X: \"MiniMax [is] making a case for mastering the technology end-to-end to get actual agentic automation.\"Compact Design, Scalable PerformanceMiniMax-M2’s technical architecture is a sparse Mixture-of-Experts model with 230 billion total parameters and 10 billion active per inference. This configuration significantly reduces latency and compute requirements while maintaining broad general intelligence. The design allows for responsive agent loops—compile–run–test or browse–retrieve–cite cycles—that execute faster and more predictably than denser models.For enterprise technology teams, this means easier scaling, lower cloud costs, and reduced deployment friction. According to Artificial Analysis, the model can be served efficiently on as few as four NVIDIA H100 GPUs at FP8 precision, a setup well within reach for mid-size organizations or departmental AI clusters.Benchmark Leadership Across Agentic and Coding WorkflowsMiniMax’s benchmark suite highlights strong real-world performance across developer and agent environments. The figure below, released with the model, compares MiniMax-M2 (in red) with several leading proprietary and open models, including GPT-5 (thinking), Claude Sonnet 4.5, Gemini 2.5 Pro, and DeepSeek-V3.2.MiniMax-M2 achieves top or near-top performance in many categories:SWE-bench Verified: 69.4 — close to GPT-5’s 74.9ArtifactsBench: 66.8 — above Claude Sonnet 4.5 and DeepSeek-V3.2τ²-Bench: 77.2 — approaching GPT-5’s 80.1GAIA (text only): 75.7 — surpassing DeepSeek-V3.2BrowseComp: 44.0 — notably stronger than other open modelsFinSearchComp-global: 65.5 — best among tested open-weight systemsThese results show MiniMax-M2’s capability in executing complex, tool-augmented tasks across multiple languages and environments—skills increasingly relevant for automated support, R&D, and data analysis inside enterprises.Strong Showing in Artificial Analysis’ Intelligence IndexThe model’s overall intelligence profile is confirmed in the latest Artificial Analysis Intelligence Index v3.0, which aggregates performance across ten reasoning benchmarks including MMLU-Pro, GPQA Diamond, AIME 2025, IFBench, and τ²-Bench Telecom.MiniMax-M2 scored 61 points, ranking as the highest open-weight model globally and following closely behind GPT-5 (high) and Grok 4. Artificial Analysis highlighted the model’s balance between technical accuracy, reasoning depth, and applied intelligence across domains. For enterprise users, this consistency indicates a reliable model foundation suitable for integration into software engineering, customer support, or knowledge automation systems.Designed for Developers and Agentic SystemsMiniMax engineered M2 for end-to-end developer workflows, enabling multi-file code edits, automated testing, and regression repair directly within integrated development environments or CI/CD pipelines. The model also excels in agentic planning—handling tasks that combine web search, command execution, and API calls while maintaining reasoning traceability.These capabilities make MiniMax-M2 especially valuable for enterprises exploring autonomous developer agents, data analysis assistants, or AI-augmented operational tools. Benchmarks such as Terminal-Bench and BrowseComp demonstrate the model’s ability to adapt to incomplete data and recover gracefully from intermediate errors, improving reliability in production settings.Interleaved Thinking and Structured Tool UseA distinctive aspect of MiniMax-M2 is its interleaved thinking format, which maintains visible reasoning traces between <think>...</think> tags.This enables the model to plan and verify steps across multiple exchanges, a critical feature for agentic reasoning. MiniMax advises retaining these segments when passing conversation history to preserve the model’s logic and continuity.The company also provides a Tool Calling Guide on Hugging Face, detailing how developers can connect external tools and APIs via structured XML-style calls. This functionality allows MiniMax-M2 to serve as the reasoning core for larger agent frameworks, executing dynamic tasks such as search, retrieval, and computation through external functions.Open Source Access and Enterprise Deployment OptionsEnterprises can access the model through the MiniMax Open Platform API and MiniMax Agent interface (a web chat similar to ChatGPT), both currently free for a limited time.MiniMax recommends SGLang and vLLM for efficient serving, each offering day-one support for the model’s unique interleaved reasoning and tool-calling structure. Deployment guides and parameter configurations are available through MiniMax’s documentation.Cost Efficiency and Token EconomicsAs Artificial Analysis noted, MiniMax’s API pricing is set at $0.30 per million input tokens and $1.20 per million output tokens, among the most competitive in the open-model ecosystem. ProviderModel (doc link)Input $/1MOutput $/1MNotesMiniMaxMiniMax-M2$0.30$1.20Listed under “Chat Completion v2” for M2. OpenAIGPT-5$1.25$10.00Flagship model pricing on OpenAI’s API pricing page. OpenAIGPT-5 mini$0.25$2.00Cheaper tier for well-defined tasks. AnthropicClaude Sonnet 4.5$3.00$15.00Anthropic’s current per-MTok list; long-context (>200K input) uses a premium tier. GoogleGemini 2.5 Flash (Preview)$0.30$2.50Prices include “thinking tokens”; page also lists cheaper Flash-Lite and 2.0 tiers. xAIGrok-4 Fast (reasoning)$0.20$0.50“Fast” tier; xAI also lists Grok-4 at $3 / $15. DeepSeekDeepSeek-V3.2 (chat)$0.28$0.42Cache-hit input is $0.028; table shows per-model details. Qwen (Alibaba)qwen-flash (Model Studio)from $0.022from $0.216Tiered by input size (≤128K, ≤256K, ≤1M tokens); listed “Input price / Output price per 1M”. CohereCommand R+ (Aug 2024)$2.50$10.00First-party pricing page also lists Command R ($0.50 / $1.50) and others. Notes & caveats (for readers):Prices are USD per million tokens and can change; check linked pages for updates and region/endpoint nuances (e.g., Anthropic long-context >200K input, Google Live API variants, cache discounts). Vendors may bill extra for server-side tools (web search, code execution) or offer batch/context-cache discounts. While the model produces longer, more explicit reasoning traces, its sparse activation and optimized compute design help maintain a favorable cost-performance balance—an advantage for teams deploying interactive agents or high-volume automation systems.Background on MiniMax — an Emerging Chinese PowerhouseMiniMax has quickly become one of the most closely watched names in China’s fast-rising AI sector. Backed by Alibaba and Tencent, the company moved from relative obscurity to international recognition within a year—first through breakthroughs in AI video generation, then through a series of open-weight large language models (LLMs) aimed squarely at developers and enterprises.The company first captured global attention in late 2024 with its AI video generation tool, “video-01,” which demonstrated the ability to create dynamic, cinematic scenes in seconds. VentureBeat described how the model’s launch sparked widespread interest after online creators began sharing lifelike, AI-generated footage—most memorably, a viral clip of a Star Wars lightsaber duel that drew millions of views in under two days. CEO Yan Junjie emphasized that the system outperformed leading Western tools in generating human movement and expression, an area where video AIs often struggle. The product, later commercialized through MiniMax’s Hailuo platform, showcased the startup’s technical confidence and creative reach, helping to establish China as a serious contender in generative video technology.By early 2025, MiniMax had turned its attention to long-context language modeling, unveiling the MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01. These open-weight models introduced an unprecedented 4-million-token context window, doubling the reach of Google’s Gemini 1.5 Pro and dwarfing OpenAI’s GPT-4o by more than twentyfold. The company continued its rapid cadence with the MiniMax-M1 release in June 2025, a model focused on long-context reasoning and reinforcement learning efficiency. M1 extended context capacity to 1 million tokens and introduced a hybrid Mixture-of-Experts design trained using a custom reinforcement-learning algorithm known as CISPO. Remarkably, VentureBeat reported that MiniMax trained M1 at a total cost of about $534,700, roughly one-tenth of DeepSeek’s R1 and far below the multimillion-dollar budgets typical for frontier-scale models. For enterprises and technical teams, MiniMax’s trajectory signals the arrival of a new generation of cost-efficient, open-weight models designed for real-world deployment. Its open licensing—ranging from Apache 2.0 to MIT—gives businesses freedom to customize, self-host, and fine-tune without vendor lock-in or compliance restrictions. Features such as structured function calling, long-context retention, and high-efficiency attention architectures directly address the needs of engineering groups managing multi-step reasoning systems and data-intensive pipelines.As MiniMax continues to expand its lineup, the company has emerged as a key global innovator in open-weight AI, combining ambitious research with pragmatic engineering. Open-Weight Leadership and Industry ContextThe release of MiniMax-M2 reinforces the growing leadership of Chinese AI research groups in open-weight model development. Following earlier contributions from DeepSeek, Alibaba’s Qwen series, and Moonshot AI, MiniMax’s entry continues the trend toward open, efficient systems designed for real-world use. Artificial Analysis observed that MiniMax-M2 exemplifies a broader shift in focus toward agentic capability and reinforcement-learning refinement, prioritizing controllable reasoning and real utility over raw model size.For enterprises, this means access to a state-of-the-art open model that can be audited, fine-tuned, and deployed internally with full transparency. By pairing strong benchmark performance with open licensing and efficient scaling, MiniMaxAI positions MiniMax-M2 as a practical foundation for intelligent systems that think, act, and assist with traceable logic—making it one of the most enterprise-ready open AI models available today.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5ooQmDHIK8joIBWGcWySzH/e0d4c547081630465c4b8862570d0fd1/cfr0z3n_extremely_small_tiny_figurine_of_a_humanoid_robot_weari_47d6d5f6-f57a-4685-b6aa-d28c2657eef8.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/googles-ai-health-coach-will-soon-be-available-to-some-fitbit-premium-users-170022769.html",
          "published_at": "Mon, 27 Oct 2025 17:00:22 +0000",
          "title": "Google’s AI health coach will soon be available to some Fitbit Premium users",
          "standfirst": "Google’s long-awaited AI health coach is nearly upon us, as a preview version is launching tomorrow for some Fitbit Premium users in the US. This will only be for Android devices at first, but the company promises an iOS version is in the works. This is a Public Preview version of the software, so think of it like a beta release. Google says it'll incorporate user feedback to \"add, change or improve features and capabilities.\" The company warns users that this is a \"new experience, so initially, there will be some gaps.\" For the uninitiated, Google's AI health coach is exactly what it sounds like. This is an AI chatbot intended to help users reach fitness and health goals. The company boasts that the tech is \"secure, personalized and grounded in science.\" Everything starts with a five to ten minute conversation with the coach to assess health and fitness goals. The coach can be a sounding board for personal health, fitness and sleep goals, but also acts as a personal trainer. Google says it can be used to review and adjust fitness plans, check progress, get advice on trends and create workouts. To that last point, the company says the chatbot can create workouts based on pre-existing constraints. For instance, users can ask the bot to make a workout that can be done in a cramped hotel room. The coach can also be used to brainstorm questions to ask a doctor and to track and analyze a number of sleep metrics. The bot provides a \"detailed sleep analysis\" and can allegedly understand patterns and trends that can impact sleep. All of this data can be accessed via the app. Being as this is a preview build, it won't roll out to everyone tomorrow. Eligible Fitbit Premium users will receive notification that the software is ready to use. It works with any Pixel Watch or Fitbit device. Google The entire Fitbit app is being redesigned to focus more on AI and this is a large piece of the puzzle. Google promises integration with its health coach across every aspect of the app.This article originally appeared on Engadget at https://www.engadget.com/ai/googles-ai-health-coach-will-soon-be-available-to-some-fitbit-premium-users-170022769.html?src=rss",
          "content": "Google’s long-awaited AI health coach is nearly upon us, as a preview version is launching tomorrow for some Fitbit Premium users in the US. This will only be for Android devices at first, but the company promises an iOS version is in the works. This is a Public Preview version of the software, so think of it like a beta release. Google says it'll incorporate user feedback to \"add, change or improve features and capabilities.\" The company warns users that this is a \"new experience, so initially, there will be some gaps.\" For the uninitiated, Google's AI health coach is exactly what it sounds like. This is an AI chatbot intended to help users reach fitness and health goals. The company boasts that the tech is \"secure, personalized and grounded in science.\" Everything starts with a five to ten minute conversation with the coach to assess health and fitness goals. The coach can be a sounding board for personal health, fitness and sleep goals, but also acts as a personal trainer. Google says it can be used to review and adjust fitness plans, check progress, get advice on trends and create workouts. To that last point, the company says the chatbot can create workouts based on pre-existing constraints. For instance, users can ask the bot to make a workout that can be done in a cramped hotel room. The coach can also be used to brainstorm questions to ask a doctor and to track and analyze a number of sleep metrics. The bot provides a \"detailed sleep analysis\" and can allegedly understand patterns and trends that can impact sleep. All of this data can be accessed via the app. Being as this is a preview build, it won't roll out to everyone tomorrow. Eligible Fitbit Premium users will receive notification that the software is ready to use. It works with any Pixel Watch or Fitbit device. Google The entire Fitbit app is being redesigned to focus more on AI and this is a large piece of the puzzle. Google promises integration with its health coach across every aspect of the app.This article originally appeared on Engadget at https://www.engadget.com/ai/googles-ai-health-coach-will-soon-be-available-to-some-fitbit-premium-users-170022769.html?src=rss",
          "feed_position": 35,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/50186980-b353-11f0-bf79-fd9d3dc1c801"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/how-to-cancel-your-peacock-subscription-160047090.html",
          "published_at": "Mon, 27 Oct 2025 16:00:47 +0000",
          "title": "How to cancel your Peacock subscription",
          "standfirst": "It happened again. Peacock just raised subscription prices for its Premium and Premium Plus plans. This is the third price increase in as many years. If your bank account is feeling the pain, or if you're just looking to streamline your entertainment options, you may decide it's time to take a break from NBC's flagship platform. Here's everything you need to know about canceling your Peacock subscription. How to cancel via web The simplest way to end your Peacock Premium service is if you're being billed directly by the company. You can follow the same steps in a web or mobile browser. Log in to your Peacock Premium or Premium Plus account. Click on the Profile icon. Select Account or Plans & Payments. Click on Cancel Plan. Follow the prompts to confirm the cancellation. That's pretty simple, but things get a bit more complicated if you're not in a direct-billing situation. How to cancel via third-party provider Like most modern streaming platforms, Peacock has partnerships with third-party providers like Apple and Amazon. This lets users sign up for the service through an entirely separate platform, like Prime Video. Cancelling has to also go through this third party. The general idea here is to sign into that account and find somewhere to manage billing and subscriptions, looking for Peacock. Here are specific steps for some of the more common providers. Cancel via Apple Go to the Settings app on your iPhone or iPad. Tap on your name at the top of the screen and tap Subscriptions. Select your Peacock subscription to manage and make changes. Cancel via Amazon Go to Amazon Memberships and Subscriptions using a web browser. Sign in to your Amazon account. Navigate to your Peacock subscription and select Cancel Subscription. Cancel via Google Play Go to the Google Play store using a web browser. Confirm that you’re signed in to your Google account. On the top right, click your Google account icon and select Payment & Subscriptions. Click the Subscriptions tab and select your Peacock subscription. Click Manage and select Cancel subscription. Cancel via Roku On your Roku TV, highlight Peacock. Press the star (*) button. Select Manage Subscriptions. Look for Peacock and hit Cancel. How to cancel a promotional subscription Peacock is often given away by internet providers like Comcast and phone carriers, among others. These plans often start free, but that goes away after a year or so. Check the fine print to see when your gifted subscription will run out, as you'll begin getting charged the usual rate. The best way to cancel these subscriptions is via the entity that offered it in the first place. This means you'll have to call up Xfinity or Spectrum directly. A customer representative should be able to handle the cancellation. Can I pause a Peacock subscription? No, Peacock doesn't currently offer the ability to pause a subscription. The best way to effectively \"pause\" a subscription is to cancel via one of the aforementioned methods and then resubscribe at a later date. What happens after you cancel? Cancelling a Peacock subscription doesn't immediately end your service. There are no partial refunds given, so you'll have full access to the account until the next payment date. At that point, the service will revert to the free tier. This means that if you change your mind before the next pay period, it's really easy to get things going again. Just look for a Restart Subscription button somewhere on the Account page. Like most modern tech services, cancelling doesn't erase any of your data. The subscription reverts to the free tier and will live on. To permanently close an account, you have to manually fill out a request via the Privacy Web Form in the Account page. This will lead you to a website to close the account.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/how-to-cancel-your-peacock-subscription-160047090.html?src=rss",
          "content": "It happened again. Peacock just raised subscription prices for its Premium and Premium Plus plans. This is the third price increase in as many years. If your bank account is feeling the pain, or if you're just looking to streamline your entertainment options, you may decide it's time to take a break from NBC's flagship platform. Here's everything you need to know about canceling your Peacock subscription. How to cancel via web The simplest way to end your Peacock Premium service is if you're being billed directly by the company. You can follow the same steps in a web or mobile browser. Log in to your Peacock Premium or Premium Plus account. Click on the Profile icon. Select Account or Plans & Payments. Click on Cancel Plan. Follow the prompts to confirm the cancellation. That's pretty simple, but things get a bit more complicated if you're not in a direct-billing situation. How to cancel via third-party provider Like most modern streaming platforms, Peacock has partnerships with third-party providers like Apple and Amazon. This lets users sign up for the service through an entirely separate platform, like Prime Video. Cancelling has to also go through this third party. The general idea here is to sign into that account and find somewhere to manage billing and subscriptions, looking for Peacock. Here are specific steps for some of the more common providers. Cancel via Apple Go to the Settings app on your iPhone or iPad. Tap on your name at the top of the screen and tap Subscriptions. Select your Peacock subscription to manage and make changes. Cancel via Amazon Go to Amazon Memberships and Subscriptions using a web browser. Sign in to your Amazon account. Navigate to your Peacock subscription and select Cancel Subscription. Cancel via Google Play Go to the Google Play store using a web browser. Confirm that you’re signed in to your Google account. On the top right, click your Google account icon and select Payment & Subscriptions. Click the Subscriptions tab and select your Peacock subscription. Click Manage and select Cancel subscription. Cancel via Roku On your Roku TV, highlight Peacock. Press the star (*) button. Select Manage Subscriptions. Look for Peacock and hit Cancel. How to cancel a promotional subscription Peacock is often given away by internet providers like Comcast and phone carriers, among others. These plans often start free, but that goes away after a year or so. Check the fine print to see when your gifted subscription will run out, as you'll begin getting charged the usual rate. The best way to cancel these subscriptions is via the entity that offered it in the first place. This means you'll have to call up Xfinity or Spectrum directly. A customer representative should be able to handle the cancellation. Can I pause a Peacock subscription? No, Peacock doesn't currently offer the ability to pause a subscription. The best way to effectively \"pause\" a subscription is to cancel via one of the aforementioned methods and then resubscribe at a later date. What happens after you cancel? Cancelling a Peacock subscription doesn't immediately end your service. There are no partial refunds given, so you'll have full access to the account until the next payment date. At that point, the service will revert to the free tier. This means that if you change your mind before the next pay period, it's really easy to get things going again. Just look for a Restart Subscription button somewhere on the Account page. Like most modern tech services, cancelling doesn't erase any of your data. The subscription reverts to the free tier and will live on. To permanently close an account, you have to manually fill out a request via the Privacy Web Form in the Account page. This will lead you to a website to close the account.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/how-to-cancel-your-peacock-subscription-160047090.html?src=rss",
          "feed_position": 36
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/anthropic-rolls-out-claude-ai-for-finance-integrates-with-excel-to-rival",
          "published_at": "Mon, 27 Oct 2025 16:00:00 GMT",
          "title": "Anthropic rolls out Claude AI for finance, integrates with Excel to rival Microsoft Copilot",
          "standfirst": "Anthropic is making its most aggressive push yet into the trillion-dollar financial services industry, unveiling a suite of tools that embed its Claude AI assistant directly into Microsoft Excel and connect it to real-time market data from some of the world&#x27;s most influential financial information providers.The San Francisco-based AI startup announced Monday it is releasing Claude for Excel, allowing financial analysts to interact with the AI system directly within their spreadsheets — the quintessential tool of modern finance. Beyond Excel, select Claude models are also being made available in Microsoft Copilot Studio and Researcher agent, expanding the integration across Microsoft&#x27;s enterprise AI ecosystem. The integration marks a significant escalation in Anthropic&#x27;s campaign to position itself as the AI platform of choice for banks, asset managers, and insurance companies, markets where precision and regulatory compliance matter far more than creative flair.The expansion comes just three months after Anthropic launched its Financial Analysis Solution in July, and it signals the company&#x27;s determination to capture market share in an industry projected to spend $97 billion on AI by 2027, up from $35 billion in 2023.More importantly, it positions Anthropic to compete directly with Microsoft — ironically, its partner in this Excel integration — which has its own Copilot AI assistant embedded across its Office suite, and with OpenAI, which counts Microsoft as its largest investor.Why Excel has become the new battleground for AI in financeThe decision to build directly into Excel is hardly accidental. Excel remains the lingua franca of finance, the digital workspace where analysts spend countless hours constructing financial models, running valuations, and stress-testing assumptions. By embedding Claude into this environment, Anthropic is meeting financial professionals exactly where they work rather than asking them to toggle between applications.Claude for Excel allows users to work with the AI in a sidebar where it can read, analyze, modify, and create new Excel workbooks while providing full transparency about the actions it takes by tracking and explaining changes and letting users navigate directly to referenced cells.This transparency feature addresses one of the most persistent anxieties around AI in finance: the \"black box\" problem. When billions of dollars ride on a financial model&#x27;s output, analysts need to understand not just the answer but how the AI arrived at it. By showing its work at the cell level, Anthropic is attempting to build the trust necessary for widespread adoption in an industry where careers and fortunes can turn on a misplaced decimal point.The technical implementation is sophisticated. Claude can discuss how spreadsheets work, modify them while preserving formula dependencies — a notoriously complex task — debug cell formulas, populate templates with new data, or build entirely new spreadsheets from scratch. This isn&#x27;t merely a chatbot that answers questions about your data; it&#x27;s a collaborative tool that can actively manipulate the models that drive investment decisions worth trillions of dollars.How Anthropic is building data moats around its financial AI platformPerhaps more significant than the Excel integration is Anthropic&#x27;s expansion of its connector ecosystem, which now links Claude to live market data and proprietary research from financial information giants. The company added six major new data partnerships spanning the entire spectrum of financial information that professional investors rely upon.Aiera now provides Claude with real-time earnings call transcripts and summaries of investor events like shareholder meetings, presentations, and conferences. The Aiera connector also enables a data feed from Third Bridge, which gives Claude access to a library of insights interviews, company intelligence, and industry analysis from experts and former executives. Chronograph gives private equity investors operational and financial information for portfolio monitoring and conducting due diligence, including performance metrics, valuations, and fund-level data.Egnyte enables Claude to securely search permitted data for internal data rooms, investment documents, and approved financial models while maintaining governed access controls. LSEG, the London Stock Exchange Group, connects Claude to live market data including fixed income pricing, equities, foreign exchange rates, macroeconomic indicators, and analysts&#x27; estimates of other important financial metrics. Moody&#x27;s provides access to proprietary credit ratings, research, and company data covering ownership, financials, and news on more than 600 million public and private companies, supporting work and research in compliance, credit analysis, and business development. MT Newswires provides Claude with access to the latest global multi-asset class news on financial markets and economies.These partnerships amount to a land grab for the informational infrastructure that powers modern finance. Previously announced in July, Anthropic had already secured integrations with S&P Capital IQ, Daloopa, Morningstar, FactSet, PitchBook, Snowflake, and Databricks. Together, these connectors give Claude access to virtually every category of financial data an analyst might need: fundamental company data, market prices, credit assessments, private company intelligence, alternative data, and breaking news.This matters because the quality of AI outputs depends entirely on the quality of inputs. Generic large language models trained on public internet data simply cannot compete with systems that have direct pipelines to Bloomberg-quality financial information. By securing these partnerships, Anthropic is building moats around its financial services offering that competitors will find difficult to replicate.The strategic calculus here is clear: Anthropic is betting that domain-specific AI systems with privileged access to proprietary data will outcompete general-purpose AI assistants. It&#x27;s a direct challenge to the \"one AI to rule them all\" approach favored by some competitors.Pre-configured workflows target the daily grind of Wall Street analystsThe third pillar of Anthropic&#x27;s announcement involves six new \"Agent Skills\" — pre-configured workflows for common financial tasks. These skills are Anthropic&#x27;s attempt to productize the workflows of entry-level and mid-level financial analysts, professionals who spend their days building models, processing due diligence documents, and writing research reports. Anthropic has designed skills specifically to automate these time-consuming tasks.The new skills include building discounted cash flow models complete with full free cash flow projections, weighted average cost of capital calculations, scenario toggles, and sensitivity tables. There&#x27;s comparable company analysis featuring valuation multiples and operating metrics that can be easily refreshed with updated data. Claude can now process data room documents into Excel spreadsheets populated with financial information, customer lists, and contract terms. It can create company teasers and profiles for pitch books and buyer lists, perform earnings analyses that use quarterly transcripts and financials to extract important metrics, guidance changes, and management commentary, and produce initiating coverage reports with industry analysis, company deep dives, and valuation frameworks.It&#x27;s worth noting that Anthropic&#x27;s Sonnet 4.5 model now tops the Finance Agent benchmark from Vals AI at 55.3% accuracy, a metric designed to test AI systems on tasks expected of entry-level financial analysts. A 55% accuracy rate might sound underwhelming, but it is state-of-the-art performance and highlights both the promise and limitations of AI in finance. The technology can clearly handle sophisticated analytical tasks, but it&#x27;s not yet reliable enough to operate autonomously without human oversight — a reality that may actually reassure both regulators and the analysts whose jobs might otherwise be at risk.The Agent Skills approach is particularly clever because it packages AI capabilities in terms that financial institutions already understand. Rather than selling generic \"AI assistance,\" Anthropic is offering solutions to specific, well-defined problems: \"You need a DCF model? We have a skill for that. You need to analyze earnings calls? We have a skill for that too.\"Trillion-dollar clients are already seeing massive productivity gainsAnthropic&#x27;s financial services strategy appears to be gaining traction with exactly the kind of marquee clients that matter in enterprise sales. The company counts among its clients AIA Labs at Bridgewater, Commonwealth Bank of Australia, American International Group, and Norges Bank Investment Management — Norway&#x27;s $1.6 trillion sovereign wealth fund, one of the world&#x27;s largest institutional investors.NBIM CEO Nicolai Tangen reported achieving approximately 20% productivity gains, equivalent to 213,000 hours, with portfolio managers and risk departments now able to \"seamlessly query our Snowflake data warehouse and analyze earnings calls with unprecedented efficiency.\"At AIG, CEO Peter Zaffino said the partnership has \"compressed the timeline to review business by more than 5x in our early rollouts while simultaneously improving our data accuracy from 75% to over 90%.\" If these numbers hold across broader deployments, the productivity implications for the financial services industry are staggering.These aren&#x27;t pilot programs or proof-of-concept deployments; they&#x27;re production implementations at institutions managing trillions of dollars in assets and making underwriting decisions that affect millions of customers. Their public endorsements provide the social proof that typically drives enterprise adoption in conservative industries.Regulatory uncertainty creates both opportunity and risk for AI deploymentYet Anthropic&#x27;s financial services ambitions unfold against a backdrop of heightened regulatory scrutiny and shifting enforcement priorities. In 2023, the Consumer Financial Protection Bureau released guidance requiring lenders to \"use specific and accurate reasons when taking adverse actions against consumers\" involving AI, and issued additional guidance requiring regulated entities to \"evaluate their underwriting models for bias\" and \"evaluate automated collateral-valuation and appraisal processes in ways that minimize bias.\"However, according to a Brookings Institution analysis, these measures have since been revoked with work stopped or eliminated at the current downsized CFPB under the current administration, creating regulatory uncertainty. The pendulum has swung from the Biden administration&#x27;s cautious approach, exemplified by an executive order on safe AI development, toward the Trump administration&#x27;s \"America&#x27;s AI Action Plan,\" which seeks to \"cement U.S. dominance in artificial intelligence\" through deregulation.This regulatory flux creates both opportunities and risks. Financial institutions eager to deploy AI now face less prescriptive federal oversight, potentially accelerating adoption. But the absence of clear guardrails also exposes them to potential liability if AI systems produce discriminatory outcomes, particularly in lending and underwriting.The Massachusetts Attorney General recently reached a $2.5 million settlement with student loan company Earnest Operations, alleging that its use of AI models resulted in \"disparate impact in approval rates and loan terms, specifically disadvantaging Black and Hispanic applicants.\" Such cases will likely multiply as AI deployment grows, creating a patchwork of state-level enforcement even as federal oversight recedes.Anthropic appears acutely aware of these risks. In an interview with Banking Dive, Jonathan Pelosi, Anthropic&#x27;s global head of industry for financial services, emphasized that Claude requires a \"human in the loop.\" The platform, he said, is not intended for autonomous financial decision-making or to provide stock recommendations that users follow blindly. During client onboarding, Pelosi told the publication, Anthropic focuses on training and understanding model limitations, putting guardrails in place so people treat Claude as a helpful technology rather than a replacement for human judgment.Competition heats up as every major tech company targets finance AIAnthropic&#x27;s financial services push comes as AI competition intensifies across the enterprise. OpenAI, Microsoft, Google, and numerous startups are all vying for position in what may become one of AI&#x27;s most lucrative verticals. Goldman Sachs introduced a generative AI assistant to its bankers, traders, and asset managers in January, signaling that major banks may build their own capabilities rather than rely exclusively on third-party providers.The emergence of domain-specific AI models like BloombergGPT — trained specifically on financial data — suggests the market may fragment between generalized AI assistants and specialized tools. Anthropic&#x27;s strategy appears to stake out a middle ground: general-purpose models, since Claude was not trained exclusively on financial data, enhanced with financial-specific tooling, data access, and workflows.The company&#x27;s partnership strategy with implementation consultancies including Deloitte, KPMG, PwC, Slalom, TribeAI, and Turing is equally critical. These firms serve as force multipliers, embedding Anthropic&#x27;s technology into their own service offerings and providing the change management expertise that financial institutions need to successfully adopt AI at scale.CFOs worry about AI hallucinations and cascading errorsThe broader question is whether AI tools like Claude will genuinely transform financial services productivity or merely shift work around. The PYMNTS Intelligence report \"The Agentic Trust Gap\" found that chief financial officers remain hesitant about AI agents, with \"nagging concern\" about hallucinations where \"an AI agent can go off script and expose firms to cascading payment errors and other inaccuracies.\"\"For finance leaders, the message is stark: Harness AI&#x27;s momentum now, but build the guardrails before the next quarterly call—or risk owning the fallout,\" the report warned.A 2025 KPMG report found that 70% of board members have developed responsible use policies for employees, with other popular initiatives including implementing a recognized AI risk and governance framework, developing ethical guidelines and training programs for AI developers, and conducting regular AI use audits.The financial services industry faces a delicate balancing act: move too slowly and risk competitive disadvantage as rivals achieve productivity gains; move too quickly and risk operational failures, regulatory penalties, or reputational damage. Speaking at the Evident AI Symposium in New York last week, Ian Glasner, HSBC&#x27;s group head of emerging technology, innovation and ventures, struck an optimistic tone about the sector&#x27;s readiness for AI adoption. \"As an industry, we are very well prepared to manage risk,\" he said, according to CIO Dive. \"Let&#x27;s not overcomplicate this. We just need to be focused on the business use case and the value associated.\"Anthropic&#x27;s latest moves suggest the company sees financial services as a beachhead market where AI&#x27;s value proposition is clear, customers have deep pockets, and the technical requirements play to Claude&#x27;s strengths in reasoning and accuracy. By building Excel integration, securing data partnerships, and pre-packaging common workflows, Anthropic is reducing the friction that typically slows enterprise AI adoption.The $61.5 billion valuation the company commanded in its March fundraising round — up from roughly $16 billion a year earlier — suggests investors believe this strategy will work. But the real test will come as these tools move from pilot programs to production deployments across thousands of analysts and billions of dollars in transactions.Financial services may prove to be AI&#x27;s most demanding proving ground: an industry where mistakes are costly, regulation is stringent, and trust is everything. If Claude can successfully navigate the spreadsheet cells and data feeds of Wall Street without hallucinating a decimal point in the wrong direction, Anthropic will have accomplished something far more valuable than winning another benchmark test. It will have proven that AI can be trusted with the money.",
          "content": "Anthropic is making its most aggressive push yet into the trillion-dollar financial services industry, unveiling a suite of tools that embed its Claude AI assistant directly into Microsoft Excel and connect it to real-time market data from some of the world&#x27;s most influential financial information providers.The San Francisco-based AI startup announced Monday it is releasing Claude for Excel, allowing financial analysts to interact with the AI system directly within their spreadsheets — the quintessential tool of modern finance. Beyond Excel, select Claude models are also being made available in Microsoft Copilot Studio and Researcher agent, expanding the integration across Microsoft&#x27;s enterprise AI ecosystem. The integration marks a significant escalation in Anthropic&#x27;s campaign to position itself as the AI platform of choice for banks, asset managers, and insurance companies, markets where precision and regulatory compliance matter far more than creative flair.The expansion comes just three months after Anthropic launched its Financial Analysis Solution in July, and it signals the company&#x27;s determination to capture market share in an industry projected to spend $97 billion on AI by 2027, up from $35 billion in 2023.More importantly, it positions Anthropic to compete directly with Microsoft — ironically, its partner in this Excel integration — which has its own Copilot AI assistant embedded across its Office suite, and with OpenAI, which counts Microsoft as its largest investor.Why Excel has become the new battleground for AI in financeThe decision to build directly into Excel is hardly accidental. Excel remains the lingua franca of finance, the digital workspace where analysts spend countless hours constructing financial models, running valuations, and stress-testing assumptions. By embedding Claude into this environment, Anthropic is meeting financial professionals exactly where they work rather than asking them to toggle between applications.Claude for Excel allows users to work with the AI in a sidebar where it can read, analyze, modify, and create new Excel workbooks while providing full transparency about the actions it takes by tracking and explaining changes and letting users navigate directly to referenced cells.This transparency feature addresses one of the most persistent anxieties around AI in finance: the \"black box\" problem. When billions of dollars ride on a financial model&#x27;s output, analysts need to understand not just the answer but how the AI arrived at it. By showing its work at the cell level, Anthropic is attempting to build the trust necessary for widespread adoption in an industry where careers and fortunes can turn on a misplaced decimal point.The technical implementation is sophisticated. Claude can discuss how spreadsheets work, modify them while preserving formula dependencies — a notoriously complex task — debug cell formulas, populate templates with new data, or build entirely new spreadsheets from scratch. This isn&#x27;t merely a chatbot that answers questions about your data; it&#x27;s a collaborative tool that can actively manipulate the models that drive investment decisions worth trillions of dollars.How Anthropic is building data moats around its financial AI platformPerhaps more significant than the Excel integration is Anthropic&#x27;s expansion of its connector ecosystem, which now links Claude to live market data and proprietary research from financial information giants. The company added six major new data partnerships spanning the entire spectrum of financial information that professional investors rely upon.Aiera now provides Claude with real-time earnings call transcripts and summaries of investor events like shareholder meetings, presentations, and conferences. The Aiera connector also enables a data feed from Third Bridge, which gives Claude access to a library of insights interviews, company intelligence, and industry analysis from experts and former executives. Chronograph gives private equity investors operational and financial information for portfolio monitoring and conducting due diligence, including performance metrics, valuations, and fund-level data.Egnyte enables Claude to securely search permitted data for internal data rooms, investment documents, and approved financial models while maintaining governed access controls. LSEG, the London Stock Exchange Group, connects Claude to live market data including fixed income pricing, equities, foreign exchange rates, macroeconomic indicators, and analysts&#x27; estimates of other important financial metrics. Moody&#x27;s provides access to proprietary credit ratings, research, and company data covering ownership, financials, and news on more than 600 million public and private companies, supporting work and research in compliance, credit analysis, and business development. MT Newswires provides Claude with access to the latest global multi-asset class news on financial markets and economies.These partnerships amount to a land grab for the informational infrastructure that powers modern finance. Previously announced in July, Anthropic had already secured integrations with S&P Capital IQ, Daloopa, Morningstar, FactSet, PitchBook, Snowflake, and Databricks. Together, these connectors give Claude access to virtually every category of financial data an analyst might need: fundamental company data, market prices, credit assessments, private company intelligence, alternative data, and breaking news.This matters because the quality of AI outputs depends entirely on the quality of inputs. Generic large language models trained on public internet data simply cannot compete with systems that have direct pipelines to Bloomberg-quality financial information. By securing these partnerships, Anthropic is building moats around its financial services offering that competitors will find difficult to replicate.The strategic calculus here is clear: Anthropic is betting that domain-specific AI systems with privileged access to proprietary data will outcompete general-purpose AI assistants. It&#x27;s a direct challenge to the \"one AI to rule them all\" approach favored by some competitors.Pre-configured workflows target the daily grind of Wall Street analystsThe third pillar of Anthropic&#x27;s announcement involves six new \"Agent Skills\" — pre-configured workflows for common financial tasks. These skills are Anthropic&#x27;s attempt to productize the workflows of entry-level and mid-level financial analysts, professionals who spend their days building models, processing due diligence documents, and writing research reports. Anthropic has designed skills specifically to automate these time-consuming tasks.The new skills include building discounted cash flow models complete with full free cash flow projections, weighted average cost of capital calculations, scenario toggles, and sensitivity tables. There&#x27;s comparable company analysis featuring valuation multiples and operating metrics that can be easily refreshed with updated data. Claude can now process data room documents into Excel spreadsheets populated with financial information, customer lists, and contract terms. It can create company teasers and profiles for pitch books and buyer lists, perform earnings analyses that use quarterly transcripts and financials to extract important metrics, guidance changes, and management commentary, and produce initiating coverage reports with industry analysis, company deep dives, and valuation frameworks.It&#x27;s worth noting that Anthropic&#x27;s Sonnet 4.5 model now tops the Finance Agent benchmark from Vals AI at 55.3% accuracy, a metric designed to test AI systems on tasks expected of entry-level financial analysts. A 55% accuracy rate might sound underwhelming, but it is state-of-the-art performance and highlights both the promise and limitations of AI in finance. The technology can clearly handle sophisticated analytical tasks, but it&#x27;s not yet reliable enough to operate autonomously without human oversight — a reality that may actually reassure both regulators and the analysts whose jobs might otherwise be at risk.The Agent Skills approach is particularly clever because it packages AI capabilities in terms that financial institutions already understand. Rather than selling generic \"AI assistance,\" Anthropic is offering solutions to specific, well-defined problems: \"You need a DCF model? We have a skill for that. You need to analyze earnings calls? We have a skill for that too.\"Trillion-dollar clients are already seeing massive productivity gainsAnthropic&#x27;s financial services strategy appears to be gaining traction with exactly the kind of marquee clients that matter in enterprise sales. The company counts among its clients AIA Labs at Bridgewater, Commonwealth Bank of Australia, American International Group, and Norges Bank Investment Management — Norway&#x27;s $1.6 trillion sovereign wealth fund, one of the world&#x27;s largest institutional investors.NBIM CEO Nicolai Tangen reported achieving approximately 20% productivity gains, equivalent to 213,000 hours, with portfolio managers and risk departments now able to \"seamlessly query our Snowflake data warehouse and analyze earnings calls with unprecedented efficiency.\"At AIG, CEO Peter Zaffino said the partnership has \"compressed the timeline to review business by more than 5x in our early rollouts while simultaneously improving our data accuracy from 75% to over 90%.\" If these numbers hold across broader deployments, the productivity implications for the financial services industry are staggering.These aren&#x27;t pilot programs or proof-of-concept deployments; they&#x27;re production implementations at institutions managing trillions of dollars in assets and making underwriting decisions that affect millions of customers. Their public endorsements provide the social proof that typically drives enterprise adoption in conservative industries.Regulatory uncertainty creates both opportunity and risk for AI deploymentYet Anthropic&#x27;s financial services ambitions unfold against a backdrop of heightened regulatory scrutiny and shifting enforcement priorities. In 2023, the Consumer Financial Protection Bureau released guidance requiring lenders to \"use specific and accurate reasons when taking adverse actions against consumers\" involving AI, and issued additional guidance requiring regulated entities to \"evaluate their underwriting models for bias\" and \"evaluate automated collateral-valuation and appraisal processes in ways that minimize bias.\"However, according to a Brookings Institution analysis, these measures have since been revoked with work stopped or eliminated at the current downsized CFPB under the current administration, creating regulatory uncertainty. The pendulum has swung from the Biden administration&#x27;s cautious approach, exemplified by an executive order on safe AI development, toward the Trump administration&#x27;s \"America&#x27;s AI Action Plan,\" which seeks to \"cement U.S. dominance in artificial intelligence\" through deregulation.This regulatory flux creates both opportunities and risks. Financial institutions eager to deploy AI now face less prescriptive federal oversight, potentially accelerating adoption. But the absence of clear guardrails also exposes them to potential liability if AI systems produce discriminatory outcomes, particularly in lending and underwriting.The Massachusetts Attorney General recently reached a $2.5 million settlement with student loan company Earnest Operations, alleging that its use of AI models resulted in \"disparate impact in approval rates and loan terms, specifically disadvantaging Black and Hispanic applicants.\" Such cases will likely multiply as AI deployment grows, creating a patchwork of state-level enforcement even as federal oversight recedes.Anthropic appears acutely aware of these risks. In an interview with Banking Dive, Jonathan Pelosi, Anthropic&#x27;s global head of industry for financial services, emphasized that Claude requires a \"human in the loop.\" The platform, he said, is not intended for autonomous financial decision-making or to provide stock recommendations that users follow blindly. During client onboarding, Pelosi told the publication, Anthropic focuses on training and understanding model limitations, putting guardrails in place so people treat Claude as a helpful technology rather than a replacement for human judgment.Competition heats up as every major tech company targets finance AIAnthropic&#x27;s financial services push comes as AI competition intensifies across the enterprise. OpenAI, Microsoft, Google, and numerous startups are all vying for position in what may become one of AI&#x27;s most lucrative verticals. Goldman Sachs introduced a generative AI assistant to its bankers, traders, and asset managers in January, signaling that major banks may build their own capabilities rather than rely exclusively on third-party providers.The emergence of domain-specific AI models like BloombergGPT — trained specifically on financial data — suggests the market may fragment between generalized AI assistants and specialized tools. Anthropic&#x27;s strategy appears to stake out a middle ground: general-purpose models, since Claude was not trained exclusively on financial data, enhanced with financial-specific tooling, data access, and workflows.The company&#x27;s partnership strategy with implementation consultancies including Deloitte, KPMG, PwC, Slalom, TribeAI, and Turing is equally critical. These firms serve as force multipliers, embedding Anthropic&#x27;s technology into their own service offerings and providing the change management expertise that financial institutions need to successfully adopt AI at scale.CFOs worry about AI hallucinations and cascading errorsThe broader question is whether AI tools like Claude will genuinely transform financial services productivity or merely shift work around. The PYMNTS Intelligence report \"The Agentic Trust Gap\" found that chief financial officers remain hesitant about AI agents, with \"nagging concern\" about hallucinations where \"an AI agent can go off script and expose firms to cascading payment errors and other inaccuracies.\"\"For finance leaders, the message is stark: Harness AI&#x27;s momentum now, but build the guardrails before the next quarterly call—or risk owning the fallout,\" the report warned.A 2025 KPMG report found that 70% of board members have developed responsible use policies for employees, with other popular initiatives including implementing a recognized AI risk and governance framework, developing ethical guidelines and training programs for AI developers, and conducting regular AI use audits.The financial services industry faces a delicate balancing act: move too slowly and risk competitive disadvantage as rivals achieve productivity gains; move too quickly and risk operational failures, regulatory penalties, or reputational damage. Speaking at the Evident AI Symposium in New York last week, Ian Glasner, HSBC&#x27;s group head of emerging technology, innovation and ventures, struck an optimistic tone about the sector&#x27;s readiness for AI adoption. \"As an industry, we are very well prepared to manage risk,\" he said, according to CIO Dive. \"Let&#x27;s not overcomplicate this. We just need to be focused on the business use case and the value associated.\"Anthropic&#x27;s latest moves suggest the company sees financial services as a beachhead market where AI&#x27;s value proposition is clear, customers have deep pockets, and the technical requirements play to Claude&#x27;s strengths in reasoning and accuracy. By building Excel integration, securing data partnerships, and pre-packaging common workflows, Anthropic is reducing the friction that typically slows enterprise AI adoption.The $61.5 billion valuation the company commanded in its March fundraising round — up from roughly $16 billion a year earlier — suggests investors believe this strategy will work. But the real test will come as these tools move from pilot programs to production deployments across thousands of analysts and billions of dollars in transactions.Financial services may prove to be AI&#x27;s most demanding proving ground: an industry where mistakes are costly, regulation is stringent, and trust is everything. If Claude can successfully navigate the spreadsheet cells and data feeds of Wall Street without hallucinating a decimal point in the wrong direction, Anthropic will have accomplished something far more valuable than winning another benchmark test. It will have proven that AI can be trusted with the money.",
          "feed_position": 7,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7FxShaZWxncA14CgV1wwvN/8ddd8d938cc83eb730d4630fa88e9c48/nuneybits_Vector_art_of_money_sign_on_retro_computer_screen_in__5728d90d-4417-472b-b380-857cf4cd4682.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/save-50-percent-on-a-year-subscription-to-one-of-our-favorite-budgeting-apps-174011259.html",
          "published_at": "Mon, 27 Oct 2025 15:00:35 +0000",
          "title": "Save 50 percent on a year subscription to one of our favorite budgeting apps",
          "standfirst": "Those looking for a better way to keep track of their finances should consider a budgeting app. There are dozens of them on the market now, and one of our favorites is running a discount for new subscribers. Monarch Money is offering 50 percent off annual plans right now when you use the code MONARCHVIP at checkout. With the typical yearly price being $100, this will save you $50. As mentioned before, the discount is only for new users and it can't be combined with other offers. The code only works when you sign up through the web as well. You can't redeem it through the Monarch mobile app. We feel that Monarch has a steeper learning curve than some other budget trackers and that certain aspects of the app are slightly more complex than they probably need to be. But it offers a great deal of customization and granularity, which outweighs our misgivings. On the main dashboard, you'll see your net worth along with your latest transactions, spending versus the previous month, your income so far for the month and details about upcoming bills, your investments and goals you've set. There's also a link to a month-in-review page, which offers an in-depth overview of what's been happening with your money that month. You'll also be able to take a peek at how your net worth has changed over time. Monarch can connect to your bank and track Apple Card, Apple Cash and Savings accounts. It can pull in your transactions and balance history automatically and detect your recurring expenses and income. The app can even keep your car valuation up to date. While it might take a little work to set up Monarch (and you might have to tweak things here and there), it's a detailed budgeting app that can help you keep better track of your income, expenditure and net worth.This article originally appeared on Engadget at https://www.engadget.com/deals/save-50-percent-on-a-year-subscription-to-one-of-our-favorite-budgeting-apps-174011259.html?src=rss",
          "content": "Those looking for a better way to keep track of their finances should consider a budgeting app. There are dozens of them on the market now, and one of our favorites is running a discount for new subscribers. Monarch Money is offering 50 percent off annual plans right now when you use the code MONARCHVIP at checkout. With the typical yearly price being $100, this will save you $50. As mentioned before, the discount is only for new users and it can't be combined with other offers. The code only works when you sign up through the web as well. You can't redeem it through the Monarch mobile app. We feel that Monarch has a steeper learning curve than some other budget trackers and that certain aspects of the app are slightly more complex than they probably need to be. But it offers a great deal of customization and granularity, which outweighs our misgivings. On the main dashboard, you'll see your net worth along with your latest transactions, spending versus the previous month, your income so far for the month and details about upcoming bills, your investments and goals you've set. There's also a link to a month-in-review page, which offers an in-depth overview of what's been happening with your money that month. You'll also be able to take a peek at how your net worth has changed over time. Monarch can connect to your bank and track Apple Card, Apple Cash and Savings accounts. It can pull in your transactions and balance history automatically and detect your recurring expenses and income. The app can even keep your car valuation up to date. While it might take a little work to set up Monarch (and you might have to tweak things here and there), it's a detailed budgeting app that can help you keep better track of your income, expenditure and net worth.This article originally appeared on Engadget at https://www.engadget.com/deals/save-50-percent-on-a-year-subscription-to-one-of-our-favorite-budgeting-apps-174011259.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/this-baseus-magnetic-power-bank-is-on-sale-for-only-36-164814187.html",
          "published_at": "Mon, 27 Oct 2025 13:15:35 +0000",
          "title": "This Baseus magnetic power bank is on sale for only $36",
          "standfirst": "If you’re on the go a lot, a power bank is practically a backpack essential, and while a chunkier device is sometimes necessary for power users, if you just need something to juice up your phone you can easily stay within the realms of pocketability. Baseus’ Picogo 5K belongs to the latter category, and right now you can pick one up for $36, which is a record low price. While this particular accessory only made it into the \"others we tested\" section in our guide to the best MagSafe power banks for iPhone, that’s only because it was slightly beaten in the slimness department by the Anker Nano. However, as we noted in the guide, the Nano doesn’t have a stand, and the Picogo 5K does, so if you like to be able to prop up your phone while it’s charging, it might be the better pick for you. As you can probably guess from its name, Baseus’ power bank has a 5,000mAh capacity and is Qi2-certified. In our testing. It gave our tester iPhone 15 a 43 percent bump in battery in 42 minutes, which returned the phone to 91 percent. It has a curved design and is wrapped in soft silicone, making it easy to grip in a pinch. As a reminder, MagSafe charging is supported on iPhone 12 models and later, though you’ll need an iPhone 13 or later to reach the 15W charging speed on a third-party Qi2 accessory such as the one featured in this deal. If you don't need the built-in stand, Baseus has a similar magnetic power bank without it on sale for only $20. You can also upgrade to a 10K bank with the same design for only $40. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/this-baseus-magnetic-power-bank-is-on-sale-for-only-36-164814187.html?src=rss",
          "content": "If you’re on the go a lot, a power bank is practically a backpack essential, and while a chunkier device is sometimes necessary for power users, if you just need something to juice up your phone you can easily stay within the realms of pocketability. Baseus’ Picogo 5K belongs to the latter category, and right now you can pick one up for $36, which is a record low price. While this particular accessory only made it into the \"others we tested\" section in our guide to the best MagSafe power banks for iPhone, that’s only because it was slightly beaten in the slimness department by the Anker Nano. However, as we noted in the guide, the Nano doesn’t have a stand, and the Picogo 5K does, so if you like to be able to prop up your phone while it’s charging, it might be the better pick for you. As you can probably guess from its name, Baseus’ power bank has a 5,000mAh capacity and is Qi2-certified. In our testing. It gave our tester iPhone 15 a 43 percent bump in battery in 42 minutes, which returned the phone to 91 percent. It has a curved design and is wrapped in soft silicone, making it easy to grip in a pinch. As a reminder, MagSafe charging is supported on iPhone 12 models and later, though you’ll need an iPhone 13 or later to reach the 15W charging speed on a third-party Qi2 accessory such as the one featured in this deal. If you don't need the built-in stand, Baseus has a similar magnetic power bank without it on sale for only $20. You can also upgrade to a 10K bank with the same design for only $40. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/this-baseus-magnetic-power-bank-is-on-sale-for-only-36-164814187.html?src=rss",
          "feed_position": 40
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/airtag-deal-grab-a-four-pack-of-bluetooth-trackers-for-a-record-low-price-143112388.html",
          "published_at": "Mon, 27 Oct 2025 12:55:35 +0000",
          "title": "AirTag deal: Grab a four-pack of Bluetooth trackers for a record-low price",
          "standfirst": "Apple deals can be hard to come by, but right now you can save on one of the company's smallest (and arguably one if its most useful) gadgets. A four-pack of Apple AirTags is down to $65 right now, which is 34 percent off its usual price. That brings each AirTag in the bundle down to $16.25 each. If you're an Apple user, then the AirTag is the best Bluetooth tracker on the market for you. You can put these little discs in your wallet, in a backpack or in your luggage while you're traveling. Your AirTag's location will show up in your Find My app, powered by the vast network of iPhones, iPads and other compatible devices that receive the AirTag's Bluetooth signal. Keep in mind these only work when close enough to participating devices to be located. You can attach AirTags to just about anything thanks to an abundance of available accessories. Their built-in speakers can play a tone, triggered from your iPhone, to help you find them when the object they're affixed to is lost. On iPhone 11 and newer models, you can take advantage of the AirTag's Ultra Wideband capability and have your phone lead you right to your AirTag, complete with directional arrows on your iPhone screen.This article originally appeared on Engadget at https://www.engadget.com/deals/airtag-deal-grab-a-four-pack-of-bluetooth-trackers-for-a-record-low-price-143112388.html?src=rss",
          "content": "Apple deals can be hard to come by, but right now you can save on one of the company's smallest (and arguably one if its most useful) gadgets. A four-pack of Apple AirTags is down to $65 right now, which is 34 percent off its usual price. That brings each AirTag in the bundle down to $16.25 each. If you're an Apple user, then the AirTag is the best Bluetooth tracker on the market for you. You can put these little discs in your wallet, in a backpack or in your luggage while you're traveling. Your AirTag's location will show up in your Find My app, powered by the vast network of iPhones, iPads and other compatible devices that receive the AirTag's Bluetooth signal. Keep in mind these only work when close enough to participating devices to be located. You can attach AirTags to just about anything thanks to an abundance of available accessories. Their built-in speakers can play a tone, triggered from your iPhone, to help you find them when the object they're affixed to is lost. On iPhone 11 and newer models, you can take advantage of the AirTag's Ultra Wideband capability and have your phone lead you right to your AirTag, complete with directional arrows on your iPhone screen.This article originally appeared on Engadget at https://www.engadget.com/deals/airtag-deal-grab-a-four-pack-of-bluetooth-trackers-for-a-record-low-price-143112388.html?src=rss",
          "feed_position": 41
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/a-bundle-of-two-blink-mini-2-cameras-is-on-sale-for-only-28-144258742.html",
          "published_at": "Mon, 27 Oct 2025 12:30:35 +0000",
          "title": "A bundle of two Blink Mini 2 cameras is on sale for only $28",
          "standfirst": "If you're in the market for a budget-friendly home security camera (or even several), the Blink Mini 2 may be worth considering. A two-pack of the cameras is on sale at Amazon as the bundle has dropped from $70 to $28. That's a discount of 60 percent, which is certainly nothing to shake at. This is also a better price than the $35 we saw for the cameras during Prime Day. Amazon recently revealed a newer version of the Blink Mini that records 2K footage, but the 1080p Blink Mini 2 can still get the job done. The Blink Mini 2 is our pick for the best budget security camera. It's easy to set up and it integrates neatly into the Alexa smart home ecosystem. While you need a Blink Subscription for cloud storage ($3 for one camera, $10 for as many as you like), you can pick up a Sync Module 2 or Sync Module XR to store Blink Mini 2 footage locally. A Blink Subscription also enables specialized detection and alerts (e.g. for people and pets) and features like periodic photo captures. The Blink Mini 2 is weather resistant, though you'll need an adapter to use it outdoors. Additionally, you can use the Mini 2 as a plug-in chime that sounds when someone presses a Blink Video Doorbell. A number of other Blink cameras and bundles are on sale at the moment. If you like the idea of the Mini 2 but want to use it outdoors, you can get two cameras with two weather-resistant adapters for only $48. Elsewhere, the latest Blink Video Doorbell is 50 percent off and down to $30 and Blink Outdoor 4 camera systems are 60 percent off, so you can grab one starting at just $32. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/a-bundle-of-two-blink-mini-2-cameras-is-on-sale-for-only-28-144258742.html?src=rss",
          "content": "If you're in the market for a budget-friendly home security camera (or even several), the Blink Mini 2 may be worth considering. A two-pack of the cameras is on sale at Amazon as the bundle has dropped from $70 to $28. That's a discount of 60 percent, which is certainly nothing to shake at. This is also a better price than the $35 we saw for the cameras during Prime Day. Amazon recently revealed a newer version of the Blink Mini that records 2K footage, but the 1080p Blink Mini 2 can still get the job done. The Blink Mini 2 is our pick for the best budget security camera. It's easy to set up and it integrates neatly into the Alexa smart home ecosystem. While you need a Blink Subscription for cloud storage ($3 for one camera, $10 for as many as you like), you can pick up a Sync Module 2 or Sync Module XR to store Blink Mini 2 footage locally. A Blink Subscription also enables specialized detection and alerts (e.g. for people and pets) and features like periodic photo captures. The Blink Mini 2 is weather resistant, though you'll need an adapter to use it outdoors. Additionally, you can use the Mini 2 as a plug-in chime that sounds when someone presses a Blink Video Doorbell. A number of other Blink cameras and bundles are on sale at the moment. If you like the idea of the Mini 2 but want to use it outdoors, you can get two cameras with two weather-resistant adapters for only $48. Elsewhere, the latest Blink Video Doorbell is 50 percent off and down to $30 and Blink Outdoor 4 camera systems are 60 percent off, so you can grab one starting at just $32. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/a-bundle-of-two-blink-mini-2-cameras-is-on-sale-for-only-28-144258742.html?src=rss",
          "feed_position": 42
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/apples-ipad-pro-m5-is-50-off-right-now-122611748.html",
          "published_at": "Mon, 27 Oct 2025 12:26:11 +0000",
          "title": "Apple's iPad Pro (M5) is $50 off right now",
          "standfirst": "Apple only released its newest iPad in mid-October but the device is already on sale. Right now you can pick up the 11-inch iPad Pro (M5) for $949, down from $999. The five percent discount is exclusive to the 256GB Wi-Fi model with standard glass. It's also only available for the Space Black model, though the Silver version is currently listed as $983. We gave the new iPad Pro an 85 in our review, in large part because of its impressive M5 chip. It's especially powerful when you're using the iPad for GPU-powered tasks. While you'll see an improvement from the M4 model, it's a really significant boost if you have an iPad Pro with an M3 chip or older. Then there's the other bits and bobs we liked, such as its extremely thin and lightweight design. It also has Apple Intelligence and an ultra retina XDR display — the screen is really great overall. Plus, the iPad Pro finally supports fast charging, so a 60W power adaptor should get you to 50 percent in just a half hour. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apples-ipad-pro-m5-is-50-off-right-now-122611748.html?src=rss",
          "content": "Apple only released its newest iPad in mid-October but the device is already on sale. Right now you can pick up the 11-inch iPad Pro (M5) for $949, down from $999. The five percent discount is exclusive to the 256GB Wi-Fi model with standard glass. It's also only available for the Space Black model, though the Silver version is currently listed as $983. We gave the new iPad Pro an 85 in our review, in large part because of its impressive M5 chip. It's especially powerful when you're using the iPad for GPU-powered tasks. While you'll see an improvement from the M4 model, it's a really significant boost if you have an iPad Pro with an M3 chip or older. Then there's the other bits and bobs we liked, such as its extremely thin and lightweight design. It also has Apple Intelligence and an ultra retina XDR display — the screen is really great overall. Plus, the iPad Pro finally supports fast charging, so a 60W power adaptor should get you to 50 percent in just a half hour. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apples-ipad-pro-m5-is-50-off-right-now-122611748.html?src=rss",
          "feed_position": 43
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/pick-up-our-favorite-magsafe-power-bank-for-only-57-right-now-152128684.html",
          "published_at": "Mon, 27 Oct 2025 11:58:10 +0000",
          "title": "Pick up our favorite MagSafe power bank for only $57 right now",
          "standfirst": "The Anker MagGo Power Bank (10K) is on sale via Amazon for just $57. This is a discount of 37 percent, which is nothing to sneeze at. The sale applies to multiple colorways. This model topped our list of the best power banks, and with very good reason. It's a workhorse that gets the job done. It includes Qi2 tech for fast wireless charging and ships with a sturdy kickstand to prop up smartphones during use. The integrated LED display makes it easy to see the battery percentage, which is always nice. The 10,000mAh battery should charge a modern iPhone nearly two times before requiring a trip to the outlet. For those not keen on wireless charging, there's a USB-C port. As for compatibility, this power bank has been optimized for Apple iPhones. It'll work with Android handsets, but the wireless charging will be disabled. That's basically the only downside here. That's not the only Anker product on sale right now. A two-pack of Anker Zolo Qi2 wireless chargers is down to only $26, and the tried-and-true Anker 313 wireless charging stand is on sale for only $14. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-our-favorite-magsafe-power-bank-for-only-57-right-now-152128684.html?src=rss",
          "content": "The Anker MagGo Power Bank (10K) is on sale via Amazon for just $57. This is a discount of 37 percent, which is nothing to sneeze at. The sale applies to multiple colorways. This model topped our list of the best power banks, and with very good reason. It's a workhorse that gets the job done. It includes Qi2 tech for fast wireless charging and ships with a sturdy kickstand to prop up smartphones during use. The integrated LED display makes it easy to see the battery percentage, which is always nice. The 10,000mAh battery should charge a modern iPhone nearly two times before requiring a trip to the outlet. For those not keen on wireless charging, there's a USB-C port. As for compatibility, this power bank has been optimized for Apple iPhones. It'll work with Android handsets, but the wireless charging will be disabled. That's basically the only downside here. That's not the only Anker product on sale right now. A two-pack of Anker Zolo Qi2 wireless chargers is down to only $26, and the tried-and-true Anker 313 wireless charging stand is on sale for only $14. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-our-favorite-magsafe-power-bank-for-only-57-right-now-152128684.html?src=rss",
          "feed_position": 44
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-wireless-workout-headphones-191517835.html",
          "published_at": "Mon, 27 Oct 2025 09:00:37 +0000",
          "title": "The best wireless workout headphones for 2025",
          "standfirst": "Regardless of what kind of exercise you’re into, if you’re working out, you’ll want a pair of wireless workout headphones. They allow you to be free and untethered during a serious weight-lifting session, a 5K run, an hour at the skate park and everywhere in between where you’re moving and sweating a ton. There are dozens of great wireless headphones and wireless earbud options out there, but for exercise in particular, there are additional factors to consider before picking one up like water resistance, battery life and overall comfort.At Engadget, we’ve tested a bunch of fitness-ready headphones and earbuds to come up with our top picks, plus some advice to consider before you pick up a pair. All of our top picks below will work in and out of the gym, so you can invest in just one pair and make those your daily driver. If you’re primarily a runner, check out our list of best headphones for running. Best workout headphones for 2025 Others wireless workout headphones we tested Apple AirPods Pro 3 When it comes to running and working out, the edge that the AirPods Pro 3 have over the Pro 2, or even the top picks on our list, is built-in heart rate monitoring. That means you could go out with just your Pro 3 earbuds and your iPhone and still get heart rate information for your entire training session. But otherwise, the Pro 3 buds are just as capable as the Pro 2 when it comes to exercise. Some may prefer the soft-touch finish on our top picks to the AirPods' slick texture. Beats Powerbeats Pro 2 The Powerbeats Pro 2 are a good alternative to the Beats Fit Pro if you’re a stickler for a hook design. However, they cost $50 more than the Powerbeats Fit, and the main added advantage here is built-in heart rate sensors. Anker Soundcore AeroFit Pro The Soundcore AeroFit Pro is Anker’s version of the Shokz OpenFit, but I found the fit to be less secure and not as comfortable. The actual earbuds on the AeroFit Pro are noticeably bulkier than those on the OpenFit and that caused them to shift and move much more during exercise. They never fell off of my ears completely, but I spent more time adjusting them than I did enjoying them. JBL Endurance Peak 3 The most noteworthy thing about the Endurance Peak 3 is that they have the same IP68 rating as the Jabra Elite 8 Active, except they only cost $100. But, while you get the same protection here, you’ll have to sacrifice in other areas. The Endurance Peak 3 didn’t blow me away when it came to sound quality or comfort (its hook is more rigid than those on my favorite similarly designed buds) and their charging case is massive compared to most competitors. What to look for in workout headphones Design Before diving in, it’s worth mentioning that this guide focuses on wireless earbuds. While you could wear over-ear or on-ear headphones during a workout, most of the best headphones available now do not have the same level of durability. Water and dust resistance, particularly the former, is important for any audio gear you plan on sweating with or taking outdoors, and that’s more prevalent in the wireless earbuds world. Most earbuds have one of three designs: in-ear, in-ear with hook or open-ear. The first two are the most popular. In-ears are arguably the most common, while those with hooks promise better security and fit since they have an appendage that curls around the top of your ear. Open-ear designs don’t stick into your ear canal, but rather sit just outside of it. This makes it easier to hear the world around you while also listening to audio, and could be more comfortable for those who don’t like the intrusiveness of in-ear buds. Water resistance and dust protection Even if a pair of headphones for working out aren’t marketed specifically as exercise headphones, a sturdy, water-resistant design will, by default, make them suitable for exercise. To avoid repetition, here’s a quick primer on durability, or ingression protection (IP) ratings. The first digit you’ll see after the “IP” refers to protection from dust and other potential intrusions, measured on a scale from 1 to 6. The second refers to water resistance or even waterproofing, in the best cases. The ratings for water resistance are ranked on a scale of 1 to 9; higher numbers mean more protection, while the letter “X” means the device is not rated for protection in that regard. All of the earbuds we tested for this guide have at least an IPX4 rating, which means there’s no dust protection, but the buds can withstand splashes from any direction and are sweat resistant, but probably shouldn't be submerged. For a detailed breakdown of all the possible permutations, check out this guide published by a supplier called The Enclosure Company. Active noise cancellation and transparency mode Active noise cancellation (ANC) is becoming standard on wireless earbuds, at least those above a certain price point. If you’re looking for a pair of buds that can be your workout companion and serve you outside of the gym, too, noise cancelation is a good feature to have. It makes the buds more versatile, allowing you to block out the dull roar of your home or office so you can focus, or give you some solitude during a busy commute. But an earbud’s ability to block out the world goes hand-in-hand with its ability to open things back up should you need it. Many ANC earbuds also support some sort of “transparency mode,” or various levels of noise reduction. This is important for running headphones because exercising outdoors, alongside busy streets, can be dangerous. You probably don’t want to be totally oblivious to what’s going on around you when you’re running outside; adjusting noise cancelation levels to increase your awareness will help with that. Stronger noise cancelation might be more appealing to those doing more indoor training if they want to block out the dull roar of a gym or the guy exaggeratingly lifting weights next to you. Battery life All of the Bluetooth earbuds we tested have a battery life of six to eight hours. In general, that’s what you can expect from this space, with a few outliers that can get up to 15 hours of life on a charge. Even the low end of the spectrum should be good enough for most athletes and gym junkies, but it’ll be handy to keep the buds’ charging case on you if you think you’ll get close to using up all their juice during a single session. You’ll get an average of 20 to 28 extra hours of battery out of most charging cases and all of the earbuds we tested had holders that provided at least an extra 15 hours. This will dictate how often you actually have to charge the device — as in physically connect the case with earbuds inside to a charging cable, or set it on a wireless charger to power up. How we test workout headphones In testing wireless workout headphones, I wear them during every bit of exercise I do — be it a casual walk around the block, a brisk morning run or a challenging weight-lifting session. I’m looking for comfort arguably most of all, because you should never be fussing with your earbuds when you should be focusing on working out. In the same vein, I’m cognizant of if they get loose during fast movements or slippery when I’m sweating. I also use the earbuds when not exercising to take calls and listen to music throughout the day. Many people will want just one pair of earbuds that they can use while exercising and just doing everyday things, so I evaluate each pair on their ability to be comfortable and provide a good listening experience in multiple different activities. While I am also evaluating sound quality, I’m admittedly not an audio expert. My colleague Billy Steele holds that title at Engadget, and you’ll find much more detailed information about audio quality for some of our top picks in his reviews and buying guides. With these headphones for working out, however, I will make note of related issues if they stood out (i.e. if a pair of earbuds had noticeably strong bass out of the box, weak highs, etc). Most of the wireless workout headphones we tested work with companion apps that have adjustable EQ settings, so you’ll be able to tweak sound profiles to your liking in most cases.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-workout-headphones-191517835.html?src=rss",
          "content": "Regardless of what kind of exercise you’re into, if you’re working out, you’ll want a pair of wireless workout headphones. They allow you to be free and untethered during a serious weight-lifting session, a 5K run, an hour at the skate park and everywhere in between where you’re moving and sweating a ton. There are dozens of great wireless headphones and wireless earbud options out there, but for exercise in particular, there are additional factors to consider before picking one up like water resistance, battery life and overall comfort.At Engadget, we’ve tested a bunch of fitness-ready headphones and earbuds to come up with our top picks, plus some advice to consider before you pick up a pair. All of our top picks below will work in and out of the gym, so you can invest in just one pair and make those your daily driver. If you’re primarily a runner, check out our list of best headphones for running. Best workout headphones for 2025 Others wireless workout headphones we tested Apple AirPods Pro 3 When it comes to running and working out, the edge that the AirPods Pro 3 have over the Pro 2, or even the top picks on our list, is built-in heart rate monitoring. That means you could go out with just your Pro 3 earbuds and your iPhone and still get heart rate information for your entire training session. But otherwise, the Pro 3 buds are just as capable as the Pro 2 when it comes to exercise. Some may prefer the soft-touch finish on our top picks to the AirPods' slick texture. Beats Powerbeats Pro 2 The Powerbeats Pro 2 are a good alternative to the Beats Fit Pro if you’re a stickler for a hook design. However, they cost $50 more than the Powerbeats Fit, and the main added advantage here is built-in heart rate sensors. Anker Soundcore AeroFit Pro The Soundcore AeroFit Pro is Anker’s version of the Shokz OpenFit, but I found the fit to be less secure and not as comfortable. The actual earbuds on the AeroFit Pro are noticeably bulkier than those on the OpenFit and that caused them to shift and move much more during exercise. They never fell off of my ears completely, but I spent more time adjusting them than I did enjoying them. JBL Endurance Peak 3 The most noteworthy thing about the Endurance Peak 3 is that they have the same IP68 rating as the Jabra Elite 8 Active, except they only cost $100. But, while you get the same protection here, you’ll have to sacrifice in other areas. The Endurance Peak 3 didn’t blow me away when it came to sound quality or comfort (its hook is more rigid than those on my favorite similarly designed buds) and their charging case is massive compared to most competitors. What to look for in workout headphones Design Before diving in, it’s worth mentioning that this guide focuses on wireless earbuds. While you could wear over-ear or on-ear headphones during a workout, most of the best headphones available now do not have the same level of durability. Water and dust resistance, particularly the former, is important for any audio gear you plan on sweating with or taking outdoors, and that’s more prevalent in the wireless earbuds world. Most earbuds have one of three designs: in-ear, in-ear with hook or open-ear. The first two are the most popular. In-ears are arguably the most common, while those with hooks promise better security and fit since they have an appendage that curls around the top of your ear. Open-ear designs don’t stick into your ear canal, but rather sit just outside of it. This makes it easier to hear the world around you while also listening to audio, and could be more comfortable for those who don’t like the intrusiveness of in-ear buds. Water resistance and dust protection Even if a pair of headphones for working out aren’t marketed specifically as exercise headphones, a sturdy, water-resistant design will, by default, make them suitable for exercise. To avoid repetition, here’s a quick primer on durability, or ingression protection (IP) ratings. The first digit you’ll see after the “IP” refers to protection from dust and other potential intrusions, measured on a scale from 1 to 6. The second refers to water resistance or even waterproofing, in the best cases. The ratings for water resistance are ranked on a scale of 1 to 9; higher numbers mean more protection, while the letter “X” means the device is not rated for protection in that regard. All of the earbuds we tested for this guide have at least an IPX4 rating, which means there’s no dust protection, but the buds can withstand splashes from any direction and are sweat resistant, but probably shouldn't be submerged. For a detailed breakdown of all the possible permutations, check out this guide published by a supplier called The Enclosure Company. Active noise cancellation and transparency mode Active noise cancellation (ANC) is becoming standard on wireless earbuds, at least those above a certain price point. If you’re looking for a pair of buds that can be your workout companion and serve you outside of the gym, too, noise cancelation is a good feature to have. It makes the buds more versatile, allowing you to block out the dull roar of your home or office so you can focus, or give you some solitude during a busy commute. But an earbud’s ability to block out the world goes hand-in-hand with its ability to open things back up should you need it. Many ANC earbuds also support some sort of “transparency mode,” or various levels of noise reduction. This is important for running headphones because exercising outdoors, alongside busy streets, can be dangerous. You probably don’t want to be totally oblivious to what’s going on around you when you’re running outside; adjusting noise cancelation levels to increase your awareness will help with that. Stronger noise cancelation might be more appealing to those doing more indoor training if they want to block out the dull roar of a gym or the guy exaggeratingly lifting weights next to you. Battery life All of the Bluetooth earbuds we tested have a battery life of six to eight hours. In general, that’s what you can expect from this space, with a few outliers that can get up to 15 hours of life on a charge. Even the low end of the spectrum should be good enough for most athletes and gym junkies, but it’ll be handy to keep the buds’ charging case on you if you think you’ll get close to using up all their juice during a single session. You’ll get an average of 20 to 28 extra hours of battery out of most charging cases and all of the earbuds we tested had holders that provided at least an extra 15 hours. This will dictate how often you actually have to charge the device — as in physically connect the case with earbuds inside to a charging cable, or set it on a wireless charger to power up. How we test workout headphones In testing wireless workout headphones, I wear them during every bit of exercise I do — be it a casual walk around the block, a brisk morning run or a challenging weight-lifting session. I’m looking for comfort arguably most of all, because you should never be fussing with your earbuds when you should be focusing on working out. In the same vein, I’m cognizant of if they get loose during fast movements or slippery when I’m sweating. I also use the earbuds when not exercising to take calls and listen to music throughout the day. Many people will want just one pair of earbuds that they can use while exercising and just doing everyday things, so I evaluate each pair on their ability to be comfortable and provide a good listening experience in multiple different activities. While I am also evaluating sound quality, I’m admittedly not an audio expert. My colleague Billy Steele holds that title at Engadget, and you’ll find much more detailed information about audio quality for some of our top picks in his reviews and buying guides. With these headphones for working out, however, I will make note of related issues if they stood out (i.e. if a pair of earbuds had noticeably strong bass out of the box, weak highs, etc). Most of the wireless workout headphones we tested work with companion apps that have adjustable EQ settings, so you’ll be able to tweak sound profiles to your liking in most cases.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-workout-headphones-191517835.html?src=rss",
          "feed_position": 46
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/4rwJWqsHkQ8TmY86sokH5j/cf400e028ed640c8e65f6bec9134c149/cfr0z3n_Flat_illustration_neon_pink_and_oranges_on_blue_backdro_3059ee39-d179-4b1b-9d52-a4264f21e970.png?w=300&q=30",
      "popularity_score": 2012.0509330555556,
      "ai_summary": [
        "IBM released four new Granite 4.0 Nano AI models.",
        "The models range from 350 million to 1.5 billion parameters.",
        "The smallest models can run in a web browser.",
        "The models are released under the Apache 2.0 license.",
        "The models are designed for edge devices and laptops."
      ]
    },
    {
      "id": "cluster_18",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 03:30:56 +0000",
      "title": "Mazda shows a rotary hybrid concept for Tokyo with evolved design language",
      "neutral_headline": "Mazda shows a rotary hybrid concept for Tokyo with evolved design language",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/mazda-shows-a-rotary-hybrid-concept-for-tokyo-with-evolved-design-language/",
          "published_at": "Wed, 29 Oct 2025 03:30:56 +0000",
          "title": "Mazda shows a rotary hybrid concept for Tokyo with evolved design language",
          "standfirst": "Ideas include algae-based fuels and capturing carbon from the exhaust while driving.",
          "content": "The Japan Mobility Show kicks off in Tokyo this week, and Mazda is using the occasion to show off a couple of concepts it says embody a theme called “the joy of driving fuels a sustainable tomorrow.” One of these is the Vision X-Coupe, which Mazda says shows off the evolution of its KODO design language—something we first saw at the Tokyo show a decade ago. You can see a clear visual link between the renderings of the Vision X-Coupe and some of Mazda’s current models like the 3 hatchback or the CX-30 crossover, but translated through the long, low form factor of a four-door coupe. The design language is perhaps less interesting than some of the sustainability ideas that Mazda is exploring here, though. There's definitely hints of the Mazda RX-Vision in this shape. Credit: Mazda It's a four-seat, four-door coupe. Credit: Mazda Fun to drive AND sustainable? Sign us up. Credit: Mazda The powertrain is a 503 hp (375 kW) plug-in hybrid that uses a two-rotor turbocharged rotary engine as the internal combustion part of the equation. Mazda says it should have a total range of 500 miles (800 km), with a range of 100 miles (160 km) on battery power alone.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/MAZDA_VISION_MODEL_3-X-COUPE-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/MAZDA_VISION_MODEL_3-X-COUPE-1152x648.jpg",
      "popularity_score": 355.18315527777776,
      "ai_summary": [
        "Mazda presented a rotary hybrid concept.",
        "The concept was shown in Tokyo.",
        "The design language has been evolved.",
        "Ideas include algae-based fuels.",
        "The concept aims to capture carbon from exhaust."
      ]
    },
    {
      "id": "cluster_37",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 22:38:46 +0000",
      "title": "Westinghouse is claiming a nuclear deal would see $80B of new reactors",
      "neutral_headline": "Westinghouse Claims Nuclear Deal Involves $80 Billion Reactors",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/westinghouse-is-claiming-a-nuclear-deal-would-see-80b-of-new-reactors/",
          "published_at": "Tue, 28 Oct 2025 22:38:46 +0000",
          "title": "Westinghouse is claiming a nuclear deal would see $80B of new reactors",
          "standfirst": "Details are remarkably sparse on what has been agreed to.",
          "content": "On Tuesday, Westinghouse announced that it had reached an agreement with the Trump administration that would purportedly see $80 billion of new nuclear reactors built in the US. And the government indicated that it had finalized plans for a collaboration of GE Vernova and Hitachi to build additional reactors. Unfortunately, there are roughly zero details about the deal at the moment. The agreements were apparently negotiated during President Trump’s trip to Japan. An announcement of those agreements indicates that “Japan and various Japanese companies” would invest “up to” $332 billion for energy infrastructure. This specifically mentioned Westinghouse, GE Vernova, and Hitachi. This promises the construction of both large AP1000 reactors and small modular nuclear reactors. The announcement then goes on to indicate that many other companies would also get a slice of that “up to $332 billion,” many for basic grid infrastructure. So the total amount devoted to nuclear reactors is not specified in the announcement or anywhere else. As of the publication time, the Department of Energy has no information on the deal; Hitachi, GE Vernova, and the Hitachi/GE Vernova collaboration websites are also silent on it.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-526258466-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-526258466-1024x648.jpg",
      "popularity_score": 349.31371083333335,
      "ai_summary": [
        "Westinghouse claims a nuclear deal involves $80 billion in new reactors.",
        "Details regarding the agreement are currently sparse and not fully available.",
        "The specifics of the deal and its implications remain largely undefined.",
        "Further information is needed to fully understand the scope of the agreement.",
        "The lack of detail makes it difficult to assess the deal's true impact."
      ]
    },
    {
      "id": "cluster_61",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 19:12:29 +0000",
      "title": "If things in America weren’t stupid enough, Texas is suing Tylenol maker",
      "neutral_headline": "Texas Sues Tylenol Maker Over Autism Claim",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/if-things-in-america-werent-stupid-enough-texas-is-suing-tylenol-maker/",
          "published_at": "Tue, 28 Oct 2025 19:12:29 +0000",
          "title": "If things in America weren’t stupid enough, Texas is suing Tylenol maker",
          "standfirst": "Texas sues Tylenol maker over unproven claim the pain medicine causes autism.",
          "content": "While the underlying cause or causes of autism spectrum disorder remain elusive and appear likely to be a complex interplay of genetic and environmental factors, President Trump and his anti-vaccine health secretary Robert F. Kennedy Jr.—neither of whom have any scientific or medical background whatsoever—have decided to pin the blame on Tylenol, a common pain reliever and fever reducer that has no proven link to autism. And now, Texas Attorney General Ken Paxton is suing the maker of Tylenol, Kenvue and Johnson & Johnson, who previously sold Tylenol, claiming that they have been “deceptively marketing Tylenol” knowing that it “leads to a significantly increased risk of autism and other disorders.” To back that claim, Paxton relies on the “considerable body of evidence… recently highlighted by the Trump Administration.”Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2150327872-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2150327872-1152x648.jpg",
      "popularity_score": 320.87565527777775,
      "ai_summary": [
        "Texas is suing the Tylenol maker, alleging a link to autism.",
        "The lawsuit is based on an unproven claim regarding the pain medicine.",
        "The claim suggests a connection between Tylenol and autism development.",
        "The lawsuit's basis is the unverified assertion of a causal relationship.",
        "The legal action challenges the safety of the widely used medication."
      ]
    },
    {
      "id": "cluster_72",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 18:30:32 +0000",
      "title": "An autonomous car for consumers? Lucid says it’s happening.",
      "neutral_headline": "Lucid Plans Consumer Autonomous Car Production",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/an-autonomous-car-for-consumers-lucid-says-its-happening/",
          "published_at": "Tue, 28 Oct 2025 18:30:32 +0000",
          "title": "An autonomous car for consumers? Lucid says it’s happening.",
          "standfirst": "Nvidia is working with Lucid on autonomous cars and future factories.",
          "content": "Is it possible to be a CEO in 2025 and not catch a case of AI fever? The latest company to catch this particular cold is Lucid, the Saudi-backed electric vehicle startup. Today, it announced a new collaboration with Nvidia to use the latter’s hardware and software, with the aim of creating an autonomous vehicle for consumers. Oh, and the AI will apparently design Lucid’s production lines. Formed by refugees from Tesla who saw a chance to improve on their past work, Lucid has already built the most efficient EV on sale in North America. But until recently, it also just had variants of the same Air sedan to offer consumers, before the Gravity SUV joined the range this year. The company will need to start selling tens of thousands of EVs a year before too long, especially if it’s ever to become profitable. And that will involve some smaller, cheaper models, starting with a midsize crossover sometime in 2027. A major goal for the first of those EVs is a starting price of less than $50,000, so I hope they’re getting a good deal on the Nvidia GPUs that Lucid now says will enable a “true eyes-off, hands-off, and mind-off” autonomous driving system for consumer-owned vehicles.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/EMBARGO_Lucid_NVIDIA-GTC_IMAGE-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/EMBARGO_Lucid_NVIDIA-GTC_IMAGE-1152x648.jpg",
      "popularity_score": 310.1764886111111,
      "ai_summary": [
        "Lucid plans to produce autonomous cars for consumer use.",
        "Nvidia is collaborating with Lucid on autonomous vehicle technology.",
        "The partnership includes work on future manufacturing facilities.",
        "The collaboration aims to advance autonomous driving capabilities.",
        "The project seeks to bring self-driving cars to the consumer market."
      ]
    },
    {
      "id": "cluster_79",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 18:11:36 +0000",
      "title": "OpenAI data suggests 1 million users discuss suicide with ChatGPT weekly",
      "neutral_headline": "OpenAI Data Shows Suicide Discussions on ChatGPT",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/openai-data-suggests-1-million-users-discuss-suicide-with-chatgpt-weekly/",
          "published_at": "Tue, 28 Oct 2025 18:11:36 +0000",
          "title": "OpenAI data suggests 1 million users discuss suicide with ChatGPT weekly",
          "standfirst": "Sensitive chats are rare but significant given the large user base.",
          "content": "An AI language model like the kind that powers ChatGPT is a gigantic statistical web of data relationships. You give it a prompt (such as a question), and it provides a response that is statistically related and hopefully helpful. At first, ChatGPT was a tech amusement, but now hundreds of millions of people are relying on this statistical process to guide them through life’s challenges. It’s the first time in history that large numbers of people have begun to confide their feelings to a talking machine, and mitigating the potential harm the systems can cause has been an ongoing challenge. On Monday, OpenAI released data estimating that 0.15 percent of ChatGPT’s active users in a given week have conversations that include explicit indicators of potential suicidal planning or intent. It’s a tiny fraction of the overall user base, but with more than 800 million weekly active users, that translates to over a million people each week, reports TechCrunch. OpenAI also estimates that a similar percentage of users show heightened levels of emotional attachment to ChatGPT, and that hundreds of thousands of people show signs of psychosis or mania in their weekly conversations with the chatbot.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_therapy_1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_therapy_1-1152x648.jpg",
      "popularity_score": 304.86093305555556,
      "ai_summary": [
        "OpenAI data indicates one million users discuss suicide weekly with ChatGPT.",
        "Sensitive conversations are infrequent but significant given the user base size.",
        "The large user base amplifies the impact of these discussions.",
        "The data highlights the potential for mental health support on the platform.",
        "The findings raise questions about AI's role in mental health."
      ]
    },
    {
      "id": "cluster_75",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 18:28:51 +0000",
      "title": "Senators move to keep Big Tech’s creepy companion bots away from kids",
      "neutral_headline": "Senators Propose Restrictions on Big Tech Companion Bots for Children",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/senators-move-to-keep-big-techs-creepy-companion-bots-away-from-kids/",
          "published_at": "Tue, 28 Oct 2025 18:28:51 +0000",
          "title": "Senators move to keep Big Tech’s creepy companion bots away from kids",
          "standfirst": "Big Tech immediately opposed the proposed law as \"heavy-handed.\"",
          "content": "The US will weigh a ban on children’s access to companion bots, as two senators announced bipartisan legislation Tuesday that would criminalize making chatbots that encourage harms like suicidal ideation or engage kids in sexually explicit chats. At a press conference, Josh Hawley (R-Mo.) and Richard Blumenthal (D-Conn.) introduced the GUARD Act, joined by grieving parents holding up photos of their children lost after engaging with chatbots. If passed, the law would require chatbot makers to check IDs or use “any other commercially reasonable method” to accurately assess if a user is a minor who must be blocked. Companion bots would also have to repeatedly remind users of all ages that they aren’t real humans or trusted professionals.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-1152x648.jpg",
      "popularity_score": 300.14843305555553,
      "ai_summary": [
        "Senators are working to keep Big Tech's companion bots away from children.",
        "Big Tech companies immediately opposed the proposed legislation.",
        "The companies described the proposed law as \"heavy-handed\" in its approach.",
        "The legislation aims to protect children from potentially harmful interactions.",
        "The debate highlights the tension between innovation and child safety."
      ]
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 18:00:21 +0000",
      "title": "Melissa strikes Jamaica, tied as most powerful Atlantic storm to come ashore",
      "neutral_headline": "Melissa Strikes Jamaica, Tied as Most Powerful Atlantic Storm",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/melissa-strikes-jamaica-tied-as-most-powerful-atlantic-storm-to-come-ashore/",
          "published_at": "Tue, 28 Oct 2025 18:00:21 +0000",
          "title": "Melissa strikes Jamaica, tied as most powerful Atlantic storm to come ashore",
          "standfirst": "The storm was so strong a hurricane hunter had to end its mission early.",
          "content": "Hurricane Melissa made landfall in southwestern Jamaica, near New Hope, on Tuesday at 1 pm ET with staggeringly powerful sustained winds of 185 mph. In the National Hurricane Center update noting the precise landfall time and location, specialist Larry Kelly characterized Melissa as an “extremely dangerous and life-threatening” hurricane. Melissa is bringing very heavy rainfall, damaging surge, and destructive winds to the small Caribbean island that is home to about 3 million people. The effects on the island are sure to be catastrophic and prolonged.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2243299438-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2243299438-1024x648.jpg",
      "popularity_score": 284.67343305555556,
      "ai_summary": [
        "Hurricane Melissa struck Jamaica, tying as the strongest storm to hit.",
        "The storm's intensity forced a hurricane hunter to end its mission early.",
        "The storm's strength caused significant disruption and damage.",
        "The hurricane's impact highlights the power of extreme weather events.",
        "The event underscores the need for effective disaster preparedness."
      ]
    },
    {
      "id": "cluster_80",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 18:10:18 +0000",
      "title": "Samsung makes ads on $3,499 smart fridges official with upcoming software update",
      "neutral_headline": "Samsung to Introduce Ads on Smart Fridges via Software Update",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/samsung-makes-ads-on-3499-smart-fridges-official-with-upcoming-software-update/",
          "published_at": "Tue, 28 Oct 2025 18:10:18 +0000",
          "title": "Samsung makes ads on $3,499 smart fridges official with upcoming software update",
          "standfirst": "Update introduces two ways for the fridges to show ads.",
          "content": "After kicking off an unpopular pilot test last month, Samsung made the practice of having its expensive smart fridges display ads official this week. The ads will be shown on Samsung’s 2024 Family Hub smart fridges. As of this writing, Samsung’s Family Hub fridges have MSRPs ranging from $1,899 to $3,499. The ads will arrive through a software update that Samsung will start issuing this month and display on the fridge’s integrated 21.5- or 32-inch (depending on the model) screen. The ads will show when the fridges are idle and display what Samsung calls Cover Screens. As part of the Family Hub software update, we are piloting a new widget for select Cover Screens themes of Family Hub refrigerators. The widget will display useful day-to-day information such as news, calendar and weather forecasts, along with curated advertisements. Samsung also said that its fridges will only show contextualized ads, instead of personalized ads, which rely on collecting data on users.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Samsung.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Samsung.jpg",
      "popularity_score": 279.8392663888889,
      "ai_summary": [
        "Samsung will introduce ads on its $3,499 smart fridges.",
        "The upcoming software update will enable ad display on the devices.",
        "The update provides two methods for the fridges to show advertisements.",
        "The move marks a shift in how Samsung monetizes its appliances.",
        "The change raises questions about user experience and privacy."
      ]
    },
    {
      "id": "cluster_89",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 16:46:56 +0000",
      "title": "Here’s how Slate Auto plans to handle repairs to its electric trucks",
      "neutral_headline": "Slate Auto Plans Electric Truck Repairs with RepairPal",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/slate-auto-announces-repair-network-access-to-superchargers/",
          "published_at": "Tue, 28 Oct 2025 16:46:56 +0000",
          "title": "Here’s how Slate Auto plans to handle repairs to its electric trucks",
          "standfirst": "The startup has partnered with RepairPal to service its affordable EV truck.",
          "content": "Earlier this year, Slate Auto emerged from stealth mode and stunned industry watchers with the Slate Truck, a compact electric pickup it plans to sell for less than $30,000. Achieving that price won’t be easy, but Slate really does look to be doing things differently from the rest of the industry—even Tesla. For example, the truck will be made from just 600 parts, with no paint or even an infotainment system, to keep costs down. An unanswered question until now has been “where do I take it to be fixed if it breaks?” Today, we have an answer. Slate is partnering with RepairPal to use the latter’s network of more than 4,000 locations across the US. “Slate’s OEM partnership with RepairPal’s nationwide network of service centers will give Slate customers peace of mind while empowering independent service shops to provide accessorization and service,” said Slate chief commercial officer Jeremy Snyder.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/0829_slate-7-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/0829_slate-7-1152x648.jpg",
      "popularity_score": 269.44982194444447,
      "ai_summary": [
        "Slate Auto is partnering with RepairPal for electric truck repairs.",
        "The startup aims to service its affordable EV truck through this partnership.",
        "RepairPal will provide repair services for Slate Auto's electric trucks.",
        "The collaboration focuses on maintaining the EV truck fleet.",
        "The partnership aims to ensure accessible and reliable repairs."
      ]
    },
    {
      "id": "cluster_85",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 17:45:34 +0000",
      "title": "Python plan to boost software security foiled by Trump admin’s anti-DEI rules",
      "neutral_headline": "Python Security Plan Foiled by Trump Administration Rules",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/python-foundation-rejects-1-5-million-grant-over-trump-admins-anti-dei-rules/",
          "published_at": "Tue, 28 Oct 2025 17:45:34 +0000",
          "title": "Python plan to boost software security foiled by Trump admin’s anti-DEI rules",
          "standfirst": "National Science Foundation said grantees must not operate any DEI programs.",
          "content": "The Python Software Foundation has rejected a $1.5 million government grant because of anti-DEI requirements imposed by the Trump administration, the nonprofit said in a blog post yesterday. The grant would have been the largest in the organization’s history. Hoping to “address structural vulnerabilities in Python and PyPI,” the foundation submitted a grant proposal in January 2025 to the National Science Foundation’s Safety, Security, and Privacy of Open Source Ecosystems program. After a “multi-round proposal writing process” and a “months-long vetting process,” it appeared the foundation was close to obtaining a two-year grant worth $1.5 million. But what at first seemed like good news quickly turned sour due to rules against Diversity, Equity, and Inclusion programs, the foundation said:Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/rejecting-money-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/rejecting-money-1152x648.jpg",
      "popularity_score": 269.4270441666667,
      "ai_summary": [
        "A Python plan to boost software security was affected by rules.",
        "The Trump administration's anti-DEI rules impacted the project.",
        "The National Science Foundation said grantees must not operate DEI programs.",
        "The rules prevented the implementation of diversity, equity, and inclusion programs.",
        "The situation highlights the impact of policy on technological advancements."
      ]
    },
    {
      "id": "cluster_103",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 15:02:30 +0000",
      "title": "Expert panel will determine AGI arrival in new Microsoft-OpenAI agreement",
      "neutral_headline": "Expert Panel to Determine AGI Arrival in Microsoft-OpenAI Deal",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2025/10/expert-panel-will-determine-agi-arrival-in-new-microsoft-openai-agreement/",
          "published_at": "Tue, 28 Oct 2025 15:02:30 +0000",
          "title": "Expert panel will determine AGI arrival in new Microsoft-OpenAI agreement",
          "standfirst": "New deal extends Microsoft IP rights until 2032 or until AGI arrives.",
          "content": "On Monday, Microsoft and OpenAI announced a revised partnership agreement that introduces an independent expert panel to verify when OpenAI achieves so-called artificial general intelligence (AGI), a determination that will trigger major shifts in how the companies share technology and revenue. The deal values Microsoft’s stake in OpenAI at approximately $135 billion and extends the exclusive partnership through 2032 while giving both companies more freedom to pursue AGI independently. The partnership began in 2019 when Microsoft invested $1 billion in OpenAI. Since then, Microsoft has provided billions in cloud computing resources through Azure and used OpenAI’s models as the basis of products like Copilot. The new agreement maintains Microsoft as OpenAI’s frontier model partner and preserves Microsoft’s exclusive rights to OpenAI’s IP and Azure API exclusivity until the threshold of AGI is reached. Under a previous arrangement, OpenAI alone would determine when it achieved AGI, which is a nebulous concept that is difficult to define. The revised deal requires an independent expert panel to verify that claim, a change that adds oversight to a determination with billions of dollars at stake. When the panel confirms that AGI has been reached, Microsoft’s intellectual property rights to OpenAI’s research methods will expire, and the revenue-sharing arrangement between the companies will end, though payments will continue over a longer period.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-1152x648.jpg",
      "popularity_score": 163.7092663888889,
      "ai_summary": [
        "A new Microsoft-OpenAI agreement involves an expert panel.",
        "The panel will determine the arrival of Artificial General Intelligence.",
        "The new deal extends Microsoft's IP rights until 2032 or AGI arrival.",
        "The agreement outlines the terms for future AI development.",
        "The deal reflects the ongoing competition in the AI field."
      ]
    },
    {
      "id": "cluster_117",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 11:30:16 +0000",
      "title": "Trump’s UCLA deal: Pay us $1B+, and we can still cut your grants again",
      "neutral_headline": "Trump's UCLA Deal: Pay Us $1B+, Grants May Still Be Cut",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/trumps-ucla-deal-pay-us-1b-and-we-can-still-cut-your-grants-again/",
          "published_at": "Tue, 28 Oct 2025 11:30:16 +0000",
          "title": "Trump’s UCLA deal: Pay us $1B+, and we can still cut your grants again",
          "standfirst": "The deal wouldn't protect UCLA from the proposed university compact.",
          "content": "On Friday, the California Supreme Court ordered the University of California system to release the details of a proposed deal from the federal government that would restore research grants that were suspended by the Trump administration. The proposed deal, first issued in August, had remained confidential as a suit filed by faculty at UCLA made its way through appeals. With California’s top court now weighing in, the university administrators have released the document, still marked “draft” and “confidential attorney work product.” Most of the demands will seem unsurprising to those familiar with the Trump administration’s interest: an end to all diversity programs and those supporting transgender individuals, plus a sharp crackdown on campus protests. The eye-opening portion comes at the price tag of nearly $1.2 billion paid out, with UCLA covering all the costs of compliance. And, as written, the deal wouldn’t stop the Trump administration from cutting the grants for other reasons or imposing more intrusive regulations, such as those mentioned in its university compact. Familiar concerns In many ways, the proposed deal is much more focused than the odd list of demands the administration sent Harvard University earlier this year, in that it targets issues that the administration has focused on repeatedly. These include an end to all diversity programs at both the faculty and student levels. It demands that UCLA agree to “remove explicit or implicit goals for compositional diversity based on race, sex, or ethnicity, including eliminating any secretive or proxy-based ‘diversity’ hiring processes.”Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2185840924-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2185840924-1152x648.jpg",
      "popularity_score": 148.17204416666667,
      "ai_summary": [
        "Trump's deal with UCLA requires a payment of over $1 billion.",
        "The deal does not protect UCLA from potential grant cuts.",
        "The proposed university compact could still affect UCLA's funding.",
        "The agreement outlines the financial terms of the deal.",
        "The situation highlights the complexities of university funding."
      ]
    },
    {
      "id": "cluster_132",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 20:18:05 +0000",
      "title": "AI-powered search engines rely on “less popular” sources, researchers find",
      "neutral_headline": "AI Search Engines Rely on Less Popular Sources",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/ai-powered-search-engines-rely-on-less-popular-sources-researchers-find/",
          "published_at": "Mon, 27 Oct 2025 20:18:05 +0000",
          "title": "AI-powered search engines rely on “less popular” sources, researchers find",
          "standfirst": "Generative search engines often cite sites that wouldn't appear in Google's top 100 links.",
          "content": "Since last year’s disastrous rollout of Google’s AI Overviews, the world at large has been aware of how AI-powered search results can differ wildly from the traditional list of links search engines have generated for decades. Now, new research helps quantify that difference, showing that AI search engines tend to cite less popular websites and ones that wouldn’t even appear in the Top 100 links listed in an “organic” Google search. In the pre-print paper “Characterizing Web Search in The Age of Generative AI,” researchers from Ruhr University in Bochum, Germany, and the Max Planck Institute for Software Systems compared traditional link results from Google’s search engine to its AI Overviews and Gemini-2.5-Flash. The researchers also looked at GPT-4o’s web search mode and the separate “GPT-4o with Search Tool,” which resorts to searching the web only when the LLM decides it needs information found outside its own pre-trained data. The researchers drew test queries from a number of sources, including specific questions submitted to ChatGPT in the WildChat dataset, general political topics listed on AllSides, and products included in the 100 most-searched Amazon products list.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-184366155-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-184366155-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "AI-powered search engines often rely on less popular sources.",
        "Researchers found that these engines cite different websites.",
        "Generative search engines often cite sites not in Google's top 100.",
        "The findings highlight differences in search engine algorithms.",
        "The research raises questions about source credibility."
      ]
    },
    {
      "id": "cluster_118",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 11:15:50 +0000",
      "title": "Trump and Republicans join Big Oil’s push to shut down climate liability efforts",
      "neutral_headline": "Trump and Republicans Support Big Oil on Climate Liability",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/trump-and-republicans-join-big-oils-push-to-shut-down-climate-liability-efforts/",
          "published_at": "Tue, 28 Oct 2025 11:15:50 +0000",
          "title": "Trump and Republicans join Big Oil’s push to shut down climate liability efforts",
          "standfirst": "Republicans are attempting to foreclose the ability of cities and states to seek damages linked to climate change.",
          "content": "As efforts continue to hold some of the world’s largest fossil fuel corporations liable for destructive and deadly climate impacts, backlash from the politically powerful oil and gas industry and its allies in government is on the rise, bolstered by the Trump administration’s allegiance to fossil fuels. From lobbying Congress for liability protection to suing states over their climate liability laws and lawsuits, attempts to shield Big Oil from potential liability and to shut down climate accountability initiatives are advancing on multiple fronts. “The effort has escalated dramatically in the past six or seven months,” said Richard Wiles, president of the Center for Climate Integrity, an organization that advocates for holding fossil fuel companies accountable for selling products they knew were dangerously warming the planet.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2164018073-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2164018073-1152x648.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "Trump and Republicans are supporting Big Oil's climate liability efforts.",
        "Republicans are attempting to shut down climate liability efforts.",
        "The goal is to prevent cities and states from seeking damages.",
        "The focus is on damages linked to climate change.",
        "The situation highlights the political dynamics of climate change."
      ]
    },
    {
      "id": "cluster_138",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 19:19:37 +0000",
      "title": "25 years, one website: ISS in Real Time captures quarter-century on space station",
      "neutral_headline": "ISS in Real Time Captures 25 Years on Space Station",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/25-years-one-website-iss-in-real-time-captures-quarter-century-on-space-station/",
          "published_at": "Mon, 27 Oct 2025 19:19:37 +0000",
          "title": "25 years, one website: ISS in Real Time captures quarter-century on space station",
          "standfirst": "From the makers of Apollo in Real Time comes a site with 500 times more data.",
          "content": "With the milestone just days away, you are likely to hear this week that there has now been a continuous human presence on the International Space Station (ISS) for the past 25 years. But what does that quarter of a century actually encompass? If only there was a way to see, hear, and experience each of those 9,131 days. Fortunately, the astronauts and cosmonauts on the space station have devoted some of their work time and a lot of their free time to taking photos, filming videos, and calling down to Earth. Much of that data has been made available to the public, but in separate repositories, with no real way to correlate or connect it with the timeline on which it was all created.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/news-102725a-lg-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/news-102725a-lg-1152x648.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "ISS in Real Time captures a quarter-century on the space station.",
        "The site is from the makers of Apollo in Real Time.",
        "The site contains 500 times more data than the previous project.",
        "The project documents the history of the International Space Station.",
        "The site offers a comprehensive view of the ISS's operations."
      ]
    },
    {
      "id": "cluster_92",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 16:36:29 +0000",
      "title": "Australia’s social media ban is “problematic,” but platforms will comply anyway",
      "neutral_headline": "Australia’s social media ban is “problematic,” but platforms will comply anyway",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/social-media-firms-abandon-fight-against-australia-law-banning-under-16-users/",
          "published_at": "Tue, 28 Oct 2025 16:36:29 +0000",
          "title": "Australia’s social media ban is “problematic,” but platforms will comply anyway",
          "standfirst": "Platforms expect to monitor a range of signals, but age detection will be spotty.",
          "content": "Social media platforms have agreed to comply with Australia’s social media ban for users under 16 years old, begrudgingly embracing the world’s most restrictive online child safety law. On Tuesday, Meta, Snap, and TikTok confirmed to Australia’s parliament that they’ll start removing and deactivating more than a million underage accounts when the law’s enforcement begins on December 10, Reuters reported. Firms risk fines of up to $32.5 million for failing to block underage users.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1525301733-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1525301733-1152x648.jpg",
      "popularity_score": 138.2756552777778,
      "ai_summary": [
        "Australia's social media ban is considered \"problematic\" by platforms.",
        "Platforms will comply with the ban despite concerns.",
        "Platforms expect to monitor a range of signals for compliance.",
        "Age detection on the platforms will be spotty.",
        "The situation highlights the challenges of content regulation."
      ]
    },
    {
      "id": "cluster_99",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 15:17:13 +0000",
      "title": "AMD shores up its budget laptop CPUs by renaming more years-old silicon",
      "neutral_headline": "AMD Renames Older Laptop CPUs to Serve Budget Market",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/amd-shores-up-its-budget-laptop-cpus-by-renaming-more-years-old-silicon/",
          "published_at": "Tue, 28 Oct 2025 15:17:13 +0000",
          "title": "AMD shores up its budget laptop CPUs by renaming more years-old silicon",
          "standfirst": "Both AMD and Intel continue to serve low-end PCs with aging silicon.",
          "content": "As newer, more efficient silicon manufacturing processes have gotten more expensive and difficult to develop, chipmakers like Intel and AMD have repeatedly rebranded some of their older processors with new model numbers. This has allowed both companies to release “new” products that aren’t actually new at all, muddying the waters for people trying to buy lower-end and midrange laptops. As spotted by Tom’s Hardware, AMD has quietly rebranded a swath of its Ryzen laptop chips with new model numbers without changing the silicon. The rebranded processors use either Rembrandt-R silicon with Zen 3+ CPU cores and RDNA 2 graphics cores or Mendocino silicon with Zen 2 CPU cores and RDNA 2 graphics cores. Both of these architectures first launched in 2022, but Mendocino’s Zen 2 CPU architecture dates all the way back to 2019. During the company’s model number decoder ring era, these designs had been sold as Ryzen 7035- and Ryzen 7020-series chips, respectively. This is actually AMD’s second rebranding for the Rembrandt-R silicon, which was launched as the Ryzen 6000 series in 2022. These chips will compete most directly with Intel’s non-Ultra Core 100 series processors, most of which use 2022-vintage Raptor Lake silicon.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/AMD-mendocino-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/AMD-mendocino-1152x648.jpg",
      "popularity_score": 136.95454416666666,
      "ai_summary": [
        "AMD continues to utilize older silicon for budget laptop processors.",
        "This strategy allows AMD to offer lower-cost CPU options.",
        "The company is renaming these older chips for current market use.",
        "This approach is similar to Intel's strategy for low-end PCs.",
        "Both companies are leveraging existing designs for cost-effectiveness."
      ]
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 23:01:06 +0000",
      "title": "Porsche’s 2026 911 Turbo S is a ballistic, twin-turbo, 701-horsepower monster",
      "neutral_headline": "Porsche 911 Turbo S Boasts High Horsepower and Agility",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/porsches-2026-911-turbo-s-is-a-ballistic-twin-turbo-701-horsepower-monster/",
          "published_at": "Mon, 27 Oct 2025 23:01:06 +0000",
          "title": "Porsche’s 2026 911 Turbo S is a ballistic, twin-turbo, 701-horsepower monster",
          "standfirst": "Big power, no lag, surprising agility make for a stellar drive—at an astronomical cost.",
          "content": "Porsche provided flights from Albany, New York, to Malaga, Spain, and accommodation so Ars could drive the 911 Turbo S. Ars does not accept paid editorial content. Turbochargers have been injecting more power into engines for over 100 years, but never before have they been so prevalent in our cars. A little boost can add a lot of power and efficiency, too, making a turbocharger a great solution to eke maximum performance out of today’s engines. Usually, though, that comes with the penalty of throttle lag: You put your foot to the floor, and nothing much happens for a beat or two. As we’ve recently seen in our review of the new 911 GTS, Porsche’s engineers have worked some magic to create a turbocharger that provides all the power and fun of forced induction but with none of the throttle response penalty. If adding one high-tech, high-voltage turbocharger is good, surely two would be better, right? Indeed, it is, if you can afford the cost of entry. Meet the 701 hp (523 kW) 2026 911 Turbo S, Porsche’s new most powerful 911 ever. Twinning the T-Hybrid For Porsche’s first hybrid 911, the GTS, the company didn’t simply add an electric motor and bigger battery into the mix and call it a day. It also inserted another high-speed motor into the turbocharger, enabling it to spin up to maximum speed in less than a second, nearly eliminating turbo lag.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2026-Porsche-911-Turbo-S-first-drive-005-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2026-Porsche-911-Turbo-S-first-drive-005-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "The 2026 Porsche 911 Turbo S has a twin-turbo engine.",
        "It generates 701 horsepower, providing significant power.",
        "The car is known for its impressive acceleration and minimal lag.",
        "It offers surprising agility and handling characteristics.",
        "The vehicle's performance comes at a high price point."
      ]
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 19:58:43 +0000",
      "title": "AT&T ad congratulating itself for its ethics violated an ad-industry rule",
      "neutral_headline": "AT&T Ad Violated Advertising Industry Ethics Rules",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/att-ad-congratulating-itself-for-its-ethics-violated-an-ad-industry-rule/",
          "published_at": "Mon, 27 Oct 2025 19:58:43 +0000",
          "title": "AT&T ad congratulating itself for its ethics violated an ad-industry rule",
          "standfirst": "Ad industry watchdog says AT&#038;T violated program rule, demands removal of ads.",
          "content": "AT&T committed a big no-no in its latest advertising campaign against T-Mobile, according to the organization that runs the ad industry’s self-regulatory system. BBB National Programs’ National Advertising Division said Friday that AT&T “violated Section 2.1(I) of the National Advertising Division (NAD)/National Advertising Review Board (NARB) Procedures for the US advertising industry’s process of self-regulation by issuing a video advertisement and press release that use the NAD process and its findings for promotional purposes. NAD has demanded that AT&T immediately remove such violative promotional materials and cease all future dissemination.” The NAD said that AT&T’s action threatens the “integrity and success of the self-regulatory forum,” and “undermines NAD’s mission to promote truth and accuracy of advertising claims and foster consumer trust in the marketplace.”Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/luke-wilson-att-1152x648-1761591326.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/luke-wilson-att-1152x648-1761591326.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "AT&T ran an advertisement congratulating itself on its ethics.",
        "An advertising industry watchdog found the ad violated program rules.",
        "The watchdog has demanded the removal of the advertisement.",
        "The specific rules violated were not explicitly stated.",
        "The situation highlights advertising industry self-regulation."
      ]
    },
    {
      "id": "cluster_143",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 16:35:52 +0000",
      "title": "F1 in Mexico City: We have a new championship leader",
      "neutral_headline": "New Championship Leader Emerges in Mexico City F1 Race",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/f1-in-mexico-city-we-have-a-new-championship-leader/",
          "published_at": "Mon, 27 Oct 2025 16:35:52 +0000",
          "title": "F1 in Mexico City: We have a new championship leader",
          "standfirst": "It was a quiet race for the win, but there was plenty of action for second and third.",
          "content": "Mexico City is one of the more unusual places that Formula 1 races, and it’s all thanks to altitude. The city sits at than 7,350 feet (2,240 m) above sea level, which makes the air noticeably thin compared to the average Grand Prix held at sea level. Like humans, F1 cars need air. Oxygen is necessary if you want any internal combustion to happen inside the turbocharged 1.6 L V6 engine. A good flow of air across the various radiators and heat exchangers in the car is vital if you want to make it to the end of the race. And the downforce-generating wings and underbody only generate downforce by creating differences in air pressure above and below the car. At over a mile above sea level, there’s about 20 percent less air, and therefore less power created by combustion, less efficient cooling of the cars, and less downforce able to be generated.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2243465873-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2243465873-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "The F1 race in Mexico City saw a new championship leader.",
        "The race for the win was relatively uneventful.",
        "There was significant action and competition for second and third.",
        "The results have shifted the standings in the championship.",
        "The race provided excitement despite the quiet lead position."
      ]
    }
  ]
}