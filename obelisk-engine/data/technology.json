{
  "updated_at": "2025-12-06T03:42:25.418Z",
  "clusters": [
    {
      "id": "cluster_7",
      "coverage": 2,
      "updated_at": "Fri, 05 Dec 2025 18:30:02 -0500",
      "title": "Waymo plans to issue a voluntary software recall over how its robotaxis operate around school buses following an NHTSA investigation opened in October (Kirsten Korosec/TechCrunch)",
      "neutral_headline": "Waymo to issue software recall over how robotaxis behave around school buses",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251205/p33#a251205p33",
          "published_at": "Fri, 05 Dec 2025 18:30:02 -0500",
          "title": "Waymo plans to issue a voluntary software recall over how its robotaxis operate around school buses following an NHTSA investigation opened in October (Kirsten Korosec/TechCrunch)",
          "standfirst": "Kirsten Korosec / TechCrunch: Waymo plans to issue a voluntary software recall over how its robotaxis operate around school buses following an NHTSA investigation opened in October &mdash; Waymo plans to voluntarily issue a software recall with federal safety regulators related to how its robotaxis operate around school buses &hellip;",
          "content": "Kirsten Korosec / TechCrunch: Waymo plans to issue a voluntary software recall over how its robotaxis operate around school buses following an NHTSA investigation opened in October &mdash; Waymo plans to voluntarily issue a software recall with federal safety regulators related to how its robotaxis operate around school buses &hellip;",
          "feed_position": 3,
          "image_url": "http://www.techmeme.com/251205/i33.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/05/waymo-to-issue-software-recall-over-how-robotaxis-behave-around-school-buses/",
          "published_at": "Fri, 05 Dec 2025 23:11:50 +0000",
          "title": "Waymo to issue software recall over how robotaxis behave around school buses",
          "standfirst": "The voluntary recall comes as scrutiny by federal regulators and local school district officials increases.",
          "content": "The voluntary recall comes as scrutiny by federal regulators and local school district officials increases.",
          "feed_position": 3
        }
      ],
      "featured_image": "http://www.techmeme.com/251205/i33.jpg",
      "popularity_score": 2015.793495,
      "ai_summary": [
        "Waymo plans a voluntary software recall related to robotaxi behavior near school buses.",
        "The recall follows an investigation by the National Highway Traffic Safety Administration.",
        "Federal regulators and local school officials are increasing scrutiny of Waymo.",
        "The recall addresses concerns about robotaxi operations near school buses.",
        "The software update aims to improve safety around school buses."
      ]
    },
    {
      "id": "cluster_15",
      "coverage": 2,
      "updated_at": "Fri, 05 Dec 2025 21:29:30 +0000",
      "title": "Meta's latest acquisition suggests hardware plans beyond glasses and headsets",
      "neutral_headline": "Meta Acquires Limitless for AI Wearable Hardware Development",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/metas-latest-acquisition-suggests-hardware-plans-beyond-glasses-and-headsets-212930339.html",
          "published_at": "Fri, 05 Dec 2025 21:29:30 +0000",
          "title": "Meta's latest acquisition suggests hardware plans beyond glasses and headsets",
          "standfirst": "Meta has acquired Limitless, the maker of an AI-powered \"Pendant,\" to work on building consumer hardware for the company, the startup announced via a YouTube video and blog post. So far, Meta has focused on selling VR headsets and AI smart glasses. Now the company seems interested in branching out.\"Meta recently announced a new vision to bring personal superintelligence to everyone and a key part of that vision is building incredible AI-enabled wearables. We share this vision and we'll be joining Meta to help bring our shared vision to life,\" Limitless CEO Dan Siroker said in the post announcing the acquisition.Limitless' first product was Rewind, desktop productivity software that recorded everything you did on your computer and turned it into a searchable database you interacted with via a chatbot. The company later expanded into hardware with Pendant, essentially a clip-on Bluetooth microphone that applies the same concept (privacy concerns be damned) to the things you say or hear throughout the day.The company plans to support its existing Pendant customers \"for at least another year,\" but will no longer sell the wearable going forward. Current customers will be able to access all the features of Pendant without having to pay for a subscription, though Limitless says availability will vary per region. If you have data stored with Limitless and don’t want to hold onto your Pendant, you're now also able to export or delete your data if you choose.AI wearables focused on recording audio have emerged as a common form factor primarily because they lean on two things AI models do moderately well: transcribing audio into text and summarizing it. Meta dipping its toes into the space makes sense, if only because not everyone will want to wear glasses to receive the benefits of an AI assistant. Amazon acquired an AI wearable company called Bee in July 2025, presumably with similar intentions.Add in Meta's recent hiring of former Apple design lead Alan Dye, and you can start to imagine where things might be headed. In the future, the Ray-Ban Meta Smart Glasses and Meta Ray-Ban Display could be two entries in a larger lineup of AI-powered wearables.This article originally appeared on Engadget at https://www.engadget.com/ai/metas-latest-acquisition-suggests-hardware-plans-beyond-glasses-and-headsets-212930339.html?src=rss",
          "content": "Meta has acquired Limitless, the maker of an AI-powered \"Pendant,\" to work on building consumer hardware for the company, the startup announced via a YouTube video and blog post. So far, Meta has focused on selling VR headsets and AI smart glasses. Now the company seems interested in branching out.\"Meta recently announced a new vision to bring personal superintelligence to everyone and a key part of that vision is building incredible AI-enabled wearables. We share this vision and we'll be joining Meta to help bring our shared vision to life,\" Limitless CEO Dan Siroker said in the post announcing the acquisition.Limitless' first product was Rewind, desktop productivity software that recorded everything you did on your computer and turned it into a searchable database you interacted with via a chatbot. The company later expanded into hardware with Pendant, essentially a clip-on Bluetooth microphone that applies the same concept (privacy concerns be damned) to the things you say or hear throughout the day.The company plans to support its existing Pendant customers \"for at least another year,\" but will no longer sell the wearable going forward. Current customers will be able to access all the features of Pendant without having to pay for a subscription, though Limitless says availability will vary per region. If you have data stored with Limitless and don’t want to hold onto your Pendant, you're now also able to export or delete your data if you choose.AI wearables focused on recording audio have emerged as a common form factor primarily because they lean on two things AI models do moderately well: transcribing audio into text and summarizing it. Meta dipping its toes into the space makes sense, if only because not everyone will want to wear glasses to receive the benefits of an AI assistant. Amazon acquired an AI wearable company called Bee in July 2025, presumably with similar intentions.Add in Meta's recent hiring of former Apple design lead Alan Dye, and you can start to imagine where things might be headed. In the future, the Ray-Ban Meta Smart Glasses and Meta Ray-Ban Display could be two entries in a larger lineup of AI-powered wearables.This article originally appeared on Engadget at https://www.engadget.com/ai/metas-latest-acquisition-suggests-hardware-plans-beyond-glasses-and-headsets-212930339.html?src=rss",
          "feed_position": 1
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/netflix-to-buy-warner-bros-for-827-billion-120836295.html",
          "published_at": "Fri, 05 Dec 2025 18:45:06 +0000",
          "title": "Netflix to buy Warner Bros. for $82.7 billion",
          "standfirst": "Shortly after rumors of a deal between the two media giants broke, Netflix has announced it is buying Warner Bros., HBO and HBO Max for approximately $82.7 billion. If approved, the deal will take place after Warner Bros. has disentangled itself from both its legacy cable and Discovery assets as part of the already-announced de-merger. That's likely to take place in the third quarter of 2026, with this new tie-up taking place at some point after that.In a statement, Netflix said it expects to \"maintain\" Warner Bros. current operations, as well as its policy of theatrical releases for its films. But the deal may spell the end for HBO Max as its own product in the longer term, as the statement also says \"by adding the deep film and TV libraries and HBO and HBO Max programming, Netflix members will have even more high-quality titles from which to choose.\"Naturally, the deal will see Netflix become one of the biggest players in global media, combining its global reach with some of the most recognizable names in entertainment. That includes HBO, DC Studios, Cartoon Network, its game development studios and TCM, as well as the chunks of TNT not cast adrift with Discovery. It's likely the deal will not go ahead without a lot of objections from other buyers, as well as the government itself. Yesterday, Paramount Skydance said (via the Hollywood Reporter) any deal between WB and Netflix would be the result of an \"unfair\" process. Given the close ties between Paramount's new owners and the administration, it's likely any deal will be subject to scrutiny as well as the usual questions around the size of the combined operation.Since the announcement was made, Engadget senior reporter Devindra Hardawar has spoken with Hollywood players and collated studies and statements to answer any burning questions you might have on what this deal means for you. He also answers questions about the likelihood of regulatory approval, theatrical releases and physical media. Catch up on all that in his piece titled “The Netflix and Warner Bros. deal might be great for shareholders, but not for anyone else.”Update, December 5 2025, 1:45PM ET: This story has been updated to add a paragraph and link to a new article we’ve published that contains deeper analysis and more information about the Netflix/Warner Bros. deal and what that might mean for streaming, movies, TV and shareholders.This article originally appeared on Engadget at https://www.engadget.com/entertainment/netflix-to-buy-warner-bros-for-827-billion-120836295.html?src=rss",
          "content": "Shortly after rumors of a deal between the two media giants broke, Netflix has announced it is buying Warner Bros., HBO and HBO Max for approximately $82.7 billion. If approved, the deal will take place after Warner Bros. has disentangled itself from both its legacy cable and Discovery assets as part of the already-announced de-merger. That's likely to take place in the third quarter of 2026, with this new tie-up taking place at some point after that.In a statement, Netflix said it expects to \"maintain\" Warner Bros. current operations, as well as its policy of theatrical releases for its films. But the deal may spell the end for HBO Max as its own product in the longer term, as the statement also says \"by adding the deep film and TV libraries and HBO and HBO Max programming, Netflix members will have even more high-quality titles from which to choose.\"Naturally, the deal will see Netflix become one of the biggest players in global media, combining its global reach with some of the most recognizable names in entertainment. That includes HBO, DC Studios, Cartoon Network, its game development studios and TCM, as well as the chunks of TNT not cast adrift with Discovery. It's likely the deal will not go ahead without a lot of objections from other buyers, as well as the government itself. Yesterday, Paramount Skydance said (via the Hollywood Reporter) any deal between WB and Netflix would be the result of an \"unfair\" process. Given the close ties between Paramount's new owners and the administration, it's likely any deal will be subject to scrutiny as well as the usual questions around the size of the combined operation.Since the announcement was made, Engadget senior reporter Devindra Hardawar has spoken with Hollywood players and collated studies and statements to answer any burning questions you might have on what this deal means for you. He also answers questions about the likelihood of regulatory approval, theatrical releases and physical media. Catch up on all that in his piece titled “The Netflix and Warner Bros. deal might be great for shareholders, but not for anyone else.”Update, December 5 2025, 1:45PM ET: This story has been updated to add a paragraph and link to a new article we’ve published that contains deeper analysis and more information about the Netflix/Warner Bros. deal and what that might mean for streaming, movies, TV and shareholders.This article originally appeared on Engadget at https://www.engadget.com/entertainment/netflix-to-buy-warner-bros-for-827-billion-120836295.html?src=rss",
          "feed_position": 4
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/the-netflix-and-warner-bros-deal-might-be-great-for-shareholders-but-not-for-anyone-else-183000247.html",
          "published_at": "Fri, 05 Dec 2025 18:30:00 +0000",
          "title": "The Netflix and Warner Bros. deal might be great for shareholders, but not for anyone else",
          "standfirst": "Netflix's $82.7 billion acquisition of Warner Bros. is, in many ways, the last thing a weakened Hollywood needs right now. The industry is still recovering from the COVID-19 pandemic, where theaters were forced to close and audiences became even more comfortable with streaming films at home. The WGA and SAG-AFTRA strikes in 2023, which were driven by legitimate concerns around studio interest in generative AI, delayed production and promotion of many film and TV projects. And the rise of streaming content pushed many media companies towards taking on debt and unwise mergers (see: Warner Bros. Discovery), which led to higher subscription costs, layoffs and production belt-tightening.How can a troubled media company survive today? The answer seems to be further consolidation. Amazon's $8.45 billion MGM takeover in 2022 heralded future deals, like Skydance's $8 billion acquisition of Paramount . But Netflix's WB deal goes even further: It could fundamentally reshape the media industry as we know it, from theatrical movie-going to the existence of physical media.What will the Netflix and Warner Bros. deal include? After next year's already-announced separation of Warner Bros. and Discovery, Netflix says it plans to acquire all of Warner Bros. remaining assets — including its film and TV studios, HBO Max and HBO — for $82.7 billion. According to Game Developer, representatives also say Warner Bros. Games, which includes Mortal Kombat developers NetherRealm, will also be part of the deal. Will the Netflix and Warner Bros. deal be approved by regulators?Even before the deal was formally announced, it was clear that whoever bought WB would be facing government opposition from every side. Yesterday, Paramount sent WB a letter questioning the \"fairness and adequacy\" of the acquisition bidding process (which also included Comcast as a potential buyer). Afterwards, the New York Post reported that Paramount CEO David Ellison, son of the Trump-boosting Oracle CEO Larry Ellison, met with administration officials to make his case for buying Netflix. As of this morning, the Trump administration views the Netflix/WB deal with \"heavy skepticism,\" an official tells CNBC.On the other side of the aisle, Senator Elizabeth Warren (D-MA) has called the Netflix/WB deal an \"anti-monopoly nightmare.\" She added, \"A Netflix-Warner Bros. would create one massive media giant with control of close to half of the streaming market. It could force you into higher prices, fewer choices over what and how you watch, and may put American workers at risk.\" At this point, it's too early to tell if the Netflix/WB deal will make it past regulators, but it's clear that both companies should prepare for a rocky approval process.What does the Netflix and Warner Bros. deal mean for streaming video? According to data from JustWatch, a combined Netflix and HBO would account for 33 percent of the US streaming video market, putting it ahead of Prime Video's 21 percent share. As for how the two media companies would co-exist, Netflix says it will \"maintain Warner Bros. current businesses,\" which includes HBO Max and HBO, theatrical releases for films and well as movie and TV studio operations. JustWatch streaming video market stats.JustWatch\"We think it’s too early to talk specifics about how we’re going to tailor this offering for consumers,\" Netflix co-CEO Greg Peters said in an investor call this morning, when asked if HBO would remain a separate service. \"Needless to say, we think the HBO brand is very powerful, and would constitute part of our plan for consumers. That then gives us a lot of options to figure out how to package things to offer the best options for consumers.\"At the very least, we can expect increased prices across the board for HBO and Netflix. There's also potential for the company to offer combination subscriptions, similar to how Disney juggles Disney+, Hulu and ESPN. What does the Netflix and Warner Bros. deal mean for theaters?In short, a combined Netflix/WB wouldn't be great for theaters. Previous mergers, like Disney and Fox's union, led to fewer theatrical releases, not more. Since its transformation into a streaming-first company, Netflix has also been primarily focused on increasing subscriptions and engagement, with theatrical releases of its original content treated as an afterthought. \"We’ve released about 30 films into theaters this year, so it’s not like we have opposition to theatrical release,\" Netflix Co-CEO Ted Sarandos said in the investor call (without specifying how short some of those theatrical releases were). \"It’s the longer windows that aren’t consumer friendly. Life cycle that starts in the movie theater, we’ll continue that. Over time, the windows will evolve to be much more consumer friendly, to meet the audience where we are.\"He added: \"All things that are going to theaters through WB will continue to do so. Our primary goal is to bring first-run movies to consumers, and we intend to continue with that.\" In an April interview at the Time100 Summit, Sarandos also famously called the theatrical model \"outdated,\" since most people in the US can't easily walk to a multiplex. Cinema United, a trade group representing over 30,000 movie theater screens in the US, is unsurprisingly against the entire deal. “The proposed acquisition of Warner Bros. by Netflix poses an unprecedented threat to the global exhibition business. The negative impact of this acquisition will impact theatres from the biggest circuits to one-screen independents in small towns in the United States and around the world,” Cinema United President and CEO Michael O’Leary said in a statement. “Cinema United stands ready to support industry changes that lead to increased movie production and give consumers more opportunities to enjoy a day at the local theatre,” he added. “But Netflix’s stated business model does not support theatrical exhibition. In fact, it is the opposite. Regulators must look closely at the specifics of this proposed transaction and understand the negative impact it will have on consumers, exhibition and the entertainment industry.”What do artists think of the Netflix and WB deal?Writers, directors and producers are already having a tough time getting projects off the ground, so having one less place to pitch isn't going to help. There are also a handful of artists, including former WB darling Christopher Nolan, who have refused to work with Netflix entirely. \"The end goal of these consolidations is to limit choices in entertainment to a select handful of providers, so they can capture our whole attention, and thus our every available dollar,\" C. Robert Cargill, the screenwriter behind Doctor Strange and The Black Phone, said in a statement to Engadget. \"The result will be a gutting of diversity and fresh voices in the industry, sending thousands, if not tens of thousands, of people back to their home towns to start their lives over, as there simply isn't a place for them in Hollywood any more, while homogenizing film and television into the \"content\" word we all grumble about hearing.\"\"WB has made so many daring choices this year, with executives taking big risks that made real cultural and financial impacts at the box office,\" he added. \"And HBO, constant name changes be damned, is still making some of the best television there is, bar none. Will those creative environments survive the merger, or will many of those brilliant execs be sent packing along with the writers, directors, and crews?\" \"In short, it's a very scary and heartbreaking time to be a filmmaker. No shade on Netflix and the people that work there; it's just that less choice in entertainment always makes for fewer winners and more people on the outside looking in.\"What about physical media?Other than noting that Netflix used to be a DVD-by-mail company, there was no mention of physical media on the acquisition's press release or investor call. That’s not too surprising, as physical releases have always been an afterthought for Netflix. A few of its films, like Roma and Frances Ha, are available as discs through the Criterion Collection, and some shows like Stranger Things are also on DVD and Blu-ray. Netflix claims it'll continue to run WB's businesses as usual if the deal goes through, which should include physical media, but those sorts of pre-acquisition promises rarely last for long. WB's home video business isn't entirely its own, either: In 2020, it formed the joint venture Studio Distribution Services with Universal, which also handles physical media distribution for Sony Pictures, PBS and Neon.Given the slowing demand for physical media, it’s likely one of the first things a combined Netflix/WB would eventually drop. But there’s also been a resurgence of premium physical releases from distributors like Arrow Video, so there’s a chance Netflix may want to keep it around for special releases.Steve Dent contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/the-netflix-and-warner-bros-deal-might-be-great-for-shareholders-but-not-for-anyone-else-183000247.html?src=rss",
          "content": "Netflix's $82.7 billion acquisition of Warner Bros. is, in many ways, the last thing a weakened Hollywood needs right now. The industry is still recovering from the COVID-19 pandemic, where theaters were forced to close and audiences became even more comfortable with streaming films at home. The WGA and SAG-AFTRA strikes in 2023, which were driven by legitimate concerns around studio interest in generative AI, delayed production and promotion of many film and TV projects. And the rise of streaming content pushed many media companies towards taking on debt and unwise mergers (see: Warner Bros. Discovery), which led to higher subscription costs, layoffs and production belt-tightening.How can a troubled media company survive today? The answer seems to be further consolidation. Amazon's $8.45 billion MGM takeover in 2022 heralded future deals, like Skydance's $8 billion acquisition of Paramount . But Netflix's WB deal goes even further: It could fundamentally reshape the media industry as we know it, from theatrical movie-going to the existence of physical media.What will the Netflix and Warner Bros. deal include? After next year's already-announced separation of Warner Bros. and Discovery, Netflix says it plans to acquire all of Warner Bros. remaining assets — including its film and TV studios, HBO Max and HBO — for $82.7 billion. According to Game Developer, representatives also say Warner Bros. Games, which includes Mortal Kombat developers NetherRealm, will also be part of the deal. Will the Netflix and Warner Bros. deal be approved by regulators?Even before the deal was formally announced, it was clear that whoever bought WB would be facing government opposition from every side. Yesterday, Paramount sent WB a letter questioning the \"fairness and adequacy\" of the acquisition bidding process (which also included Comcast as a potential buyer). Afterwards, the New York Post reported that Paramount CEO David Ellison, son of the Trump-boosting Oracle CEO Larry Ellison, met with administration officials to make his case for buying Netflix. As of this morning, the Trump administration views the Netflix/WB deal with \"heavy skepticism,\" an official tells CNBC.On the other side of the aisle, Senator Elizabeth Warren (D-MA) has called the Netflix/WB deal an \"anti-monopoly nightmare.\" She added, \"A Netflix-Warner Bros. would create one massive media giant with control of close to half of the streaming market. It could force you into higher prices, fewer choices over what and how you watch, and may put American workers at risk.\" At this point, it's too early to tell if the Netflix/WB deal will make it past regulators, but it's clear that both companies should prepare for a rocky approval process.What does the Netflix and Warner Bros. deal mean for streaming video? According to data from JustWatch, a combined Netflix and HBO would account for 33 percent of the US streaming video market, putting it ahead of Prime Video's 21 percent share. As for how the two media companies would co-exist, Netflix says it will \"maintain Warner Bros. current businesses,\" which includes HBO Max and HBO, theatrical releases for films and well as movie and TV studio operations. JustWatch streaming video market stats.JustWatch\"We think it’s too early to talk specifics about how we’re going to tailor this offering for consumers,\" Netflix co-CEO Greg Peters said in an investor call this morning, when asked if HBO would remain a separate service. \"Needless to say, we think the HBO brand is very powerful, and would constitute part of our plan for consumers. That then gives us a lot of options to figure out how to package things to offer the best options for consumers.\"At the very least, we can expect increased prices across the board for HBO and Netflix. There's also potential for the company to offer combination subscriptions, similar to how Disney juggles Disney+, Hulu and ESPN. What does the Netflix and Warner Bros. deal mean for theaters?In short, a combined Netflix/WB wouldn't be great for theaters. Previous mergers, like Disney and Fox's union, led to fewer theatrical releases, not more. Since its transformation into a streaming-first company, Netflix has also been primarily focused on increasing subscriptions and engagement, with theatrical releases of its original content treated as an afterthought. \"We’ve released about 30 films into theaters this year, so it’s not like we have opposition to theatrical release,\" Netflix Co-CEO Ted Sarandos said in the investor call (without specifying how short some of those theatrical releases were). \"It’s the longer windows that aren’t consumer friendly. Life cycle that starts in the movie theater, we’ll continue that. Over time, the windows will evolve to be much more consumer friendly, to meet the audience where we are.\"He added: \"All things that are going to theaters through WB will continue to do so. Our primary goal is to bring first-run movies to consumers, and we intend to continue with that.\" In an April interview at the Time100 Summit, Sarandos also famously called the theatrical model \"outdated,\" since most people in the US can't easily walk to a multiplex. Cinema United, a trade group representing over 30,000 movie theater screens in the US, is unsurprisingly against the entire deal. “The proposed acquisition of Warner Bros. by Netflix poses an unprecedented threat to the global exhibition business. The negative impact of this acquisition will impact theatres from the biggest circuits to one-screen independents in small towns in the United States and around the world,” Cinema United President and CEO Michael O’Leary said in a statement. “Cinema United stands ready to support industry changes that lead to increased movie production and give consumers more opportunities to enjoy a day at the local theatre,” he added. “But Netflix’s stated business model does not support theatrical exhibition. In fact, it is the opposite. Regulators must look closely at the specifics of this proposed transaction and understand the negative impact it will have on consumers, exhibition and the entertainment industry.”What do artists think of the Netflix and WB deal?Writers, directors and producers are already having a tough time getting projects off the ground, so having one less place to pitch isn't going to help. There are also a handful of artists, including former WB darling Christopher Nolan, who have refused to work with Netflix entirely. \"The end goal of these consolidations is to limit choices in entertainment to a select handful of providers, so they can capture our whole attention, and thus our every available dollar,\" C. Robert Cargill, the screenwriter behind Doctor Strange and The Black Phone, said in a statement to Engadget. \"The result will be a gutting of diversity and fresh voices in the industry, sending thousands, if not tens of thousands, of people back to their home towns to start their lives over, as there simply isn't a place for them in Hollywood any more, while homogenizing film and television into the \"content\" word we all grumble about hearing.\"\"WB has made so many daring choices this year, with executives taking big risks that made real cultural and financial impacts at the box office,\" he added. \"And HBO, constant name changes be damned, is still making some of the best television there is, bar none. Will those creative environments survive the merger, or will many of those brilliant execs be sent packing along with the writers, directors, and crews?\" \"In short, it's a very scary and heartbreaking time to be a filmmaker. No shade on Netflix and the people that work there; it's just that less choice in entertainment always makes for fewer winners and more people on the outside looking in.\"What about physical media?Other than noting that Netflix used to be a DVD-by-mail company, there was no mention of physical media on the acquisition's press release or investor call. That’s not too surprising, as physical releases have always been an afterthought for Netflix. A few of its films, like Roma and Frances Ha, are available as discs through the Criterion Collection, and some shows like Stranger Things are also on DVD and Blu-ray. Netflix claims it'll continue to run WB's businesses as usual if the deal goes through, which should include physical media, but those sorts of pre-acquisition promises rarely last for long. WB's home video business isn't entirely its own, either: In 2020, it formed the joint venture Studio Distribution Services with Universal, which also handles physical media distribution for Sony Pictures, PBS and Neon.Given the slowing demand for physical media, it’s likely one of the first things a combined Netflix/WB would eventually drop. But there’s also been a resurgence of premium physical releases from distributors like Arrow Video, so there’s a chance Netflix may want to keep it around for special releases.Steve Dent contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/the-netflix-and-warner-bros-deal-might-be-great-for-shareholders-but-not-for-anyone-else-183000247.html?src=rss",
          "feed_position": 5,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/SVOD_US_Market_Shares_-_Netflix_and_WBD_Merger.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/get-three-months-of-apple-music-for-only-1-right-now-180536582.html",
          "published_at": "Fri, 05 Dec 2025 18:05:36 +0000",
          "title": "Get three months of Apple Music for only $1 right now",
          "standfirst": "Looking to switch music streaming platforms for no real reason? Apple Music is holding one heck of a sale right now. You can get three months of use for just $1. There are some caveats, as this is only for new users on the individual plan. Students and family plans don't count for this. Also, this has to be redeemed on iPhone, iPad or Mac. When you click the link it'll open up the Apple Music app, so click it from an Apple product to get the deal. Finally, it auto-renews after 90 days at $11 per month. Make sure to cancel ahead of time if you aren't enjoying the service. As for Apple Music, it's one of the best music streaming platforms out there and certainly a perfect choice for those already tied to the Apple ecosystem. It lets you import your own files, which is great for anyone still hanging on to an iTunes library. Otherwise, it offers streaming access to millions upon millions songs like all the rest. It does, however, include some live radio stations staffed by actual people, which is cool. The app works with Android devices, but it's really designed for Apple products. We also found the spatial audio to sound unnatural at times, but that's partly a limitation of the tech. Check out our coverage of the best streaming deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-three-months-of-apple-music-for-only-1-right-now-180536582.html?src=rss",
          "content": "Looking to switch music streaming platforms for no real reason? Apple Music is holding one heck of a sale right now. You can get three months of use for just $1. There are some caveats, as this is only for new users on the individual plan. Students and family plans don't count for this. Also, this has to be redeemed on iPhone, iPad or Mac. When you click the link it'll open up the Apple Music app, so click it from an Apple product to get the deal. Finally, it auto-renews after 90 days at $11 per month. Make sure to cancel ahead of time if you aren't enjoying the service. As for Apple Music, it's one of the best music streaming platforms out there and certainly a perfect choice for those already tied to the Apple ecosystem. It lets you import your own files, which is great for anyone still hanging on to an iTunes library. Otherwise, it offers streaming access to millions upon millions songs like all the rest. It does, however, include some live radio stations staffed by actual people, which is cool. The app works with Android devices, but it's really designed for Apple products. We also found the spatial audio to sound unnatural at times, but that's partly a limitation of the tech. Check out our coverage of the best streaming deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-three-months-of-apple-music-for-only-1-right-now-180536582.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/new-philo-subscribers-can-get-their-first-month-of-access-for-25-171033925.html",
          "published_at": "Fri, 05 Dec 2025 17:10:33 +0000",
          "title": "New Philo subscribers can get their first month of access for $25",
          "standfirst": "Philo has a decent discount for newcomers who are looking for a solid bundle of live TV channels and on-demand streaming services. New subscribers can get their first month of access to the Core plan for $25. That's a discount of $8. For your 25 bucks, you'll gain access to more than 70 channels, including AMC, BBC America, Comedy Central, Food Network, Hallmark Channel, several MTV stations, Nickelodeon and TLC. AMC+, HBO Max basic with ads and Discovery+ are included at no extra cost. Philo is our pick for the best cheap live TV streaming service. Having unlimited DVR is welcome and recordings expire after one year, which is three months longer than many competing platforms. There's no contract either, so you can cancel at any time. The platform also offers more than 110 free channels, but unfortunately there are no local channels and there's not much in the way of sports programming. Other notable channels, such as Bravo and Freeform are missing too. However, if the lineup of channels and streaming services covers all your needs, Philo is a solid streaming option, especially with the discount. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/new-philo-subscribers-can-get-their-first-month-of-access-for-25-171033925.html?src=rss",
          "content": "Philo has a decent discount for newcomers who are looking for a solid bundle of live TV channels and on-demand streaming services. New subscribers can get their first month of access to the Core plan for $25. That's a discount of $8. For your 25 bucks, you'll gain access to more than 70 channels, including AMC, BBC America, Comedy Central, Food Network, Hallmark Channel, several MTV stations, Nickelodeon and TLC. AMC+, HBO Max basic with ads and Discovery+ are included at no extra cost. Philo is our pick for the best cheap live TV streaming service. Having unlimited DVR is welcome and recordings expire after one year, which is three months longer than many competing platforms. There's no contract either, so you can cancel at any time. The platform also offers more than 110 free channels, but unfortunately there are no local channels and there's not much in the way of sports programming. Other notable channels, such as Bravo and Freeform are missing too. However, if the lineup of channels and streaming services covers all your needs, Philo is a solid streaming option, especially with the discount. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/new-philo-subscribers-can-get-their-first-month-of-access-for-25-171033925.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-ipad-deals-this-week-include-100-off-the-ipad-air-m3-150020616.html",
          "published_at": "Fri, 05 Dec 2025 17:00:35 +0000",
          "title": "The best iPad deals this week include $100 off the iPad Air M3",
          "standfirst": "We generally think iPads are the best tablets for most people, but they usually don’t come cheap. To help those looking to grab one today get the most value possible, we’re keeping an eye on sale prices and rounding up the best iPad deals we can find each week. Hopefully you were able to snag whatever iPad you’ve been eyeing at some point in the last couple of weeks, as most of the all-time lows we saw during Black Friday and Cyber Monday have expired. If you were late to the party, though, there are still some savings to be had, including $100 off both iPad Air models and an all-time low for the 13-inch iPad Pro. Beyond tablets, other Apple devices like the AirPods 4 with ANC, Apple Watch SE 3 and Apple Pencil Pro are still on sale at their Black Friday prices. Here are all of the top deals on Apple gear we could find this week. Best iPad deals Apple iPad Air (13-inch, M3) for $699 ($100 off MSRP): The 13-inch iPad Air is exactly the same as its smaller counterpart, only it has a larger and slightly brighter display. We gave it a review score of 89 earlier this year. This deal is $50 above the discount we saw on Black Friday but still $100 cheaper than buying from Apple directly. Also at B&H. Apple iPad Pro (11-inch, M5) for $927 ($72 off): The latest iPad Pro is still far more tablet than most people need, but its class-leading OLED display, impressively thin design and super-powerful M5 chip make it a luxury experience for those who can afford it. This 11-inch model sold for $899 during Black Friday, but the device was only released in October, so any sort of savings is still noteworthy. Also at Best Buy for $949. Apple iPad Pro (13-inch, M5) for $1,199 ($100 off): It’s not a massive discount, but this matches the lowest price so far for the larger iPad Pro, which may be worthwhile if you’ve got cash to burn and want to use an iPad as your main computer. We gave it a score of 85 in our review. Also at B&H. Best Apple deals Apple Watch SE 3 for $199 ($50 off): This discount has been around for a few weeks, but it’s the lowest price to date for Apple’s newest entry-level smartwatch. We gave this device a score of 90 in our review last month: The big upgrade is an always-on display, which makes it so you no longer have to wake the watch to check the time or notifications. It still includes most of the essential health and fitness features beyond that, plus it now runs on the same chipset as the higher-end Apple Watch Series 11. Also at Walmart. Apple Watch Series 11 for $329 ($70 off): The SE 3 may be a better raw value, but the Apple Watch Series 11 remains our preferred smartwatch overall for iPhone owners. Compared to its cheaper sibling, it has a bigger, brighter and more scratch-resistant display, longer battery life and a few advanced health features like an ECG app and hypertension alerts. It also earned a score of 90 in our review. This is an all-time low for the standard 42mm model, but keep in mind that there’s no pressing need to upgrade if you already own a Series 10. Also at Walmart. Apple Pencil Pro for $95 ($34 off): The Pencil Pro is Apple’s most feature-rich stylus, offering pressure sensitivity, wireless charging, haptic feedback and unique gesture controls compared to the standard USB-C model (which isn’t significantly discounted). Just note that it’s not compatible with the entry-level iPad and other older models. While this discount is only $5 below the device’s usual street price, it’s still the largest discount we’ve seen this year. Also at Walmart. Apple MacBook Pro (14-inch, M5) for $1,349 ($250 off): The newest MacBook Pro is the “best high-end” pick in our laptop buying guide and a fine choice for creative types who need something more powerful than the MacBook Air. The latter is still a much better value for most people, but the Pro gets you a superior mini-LED display with a 120Hz refresh rate, more ports and improved performance, especially with GPU-intensive tasks. It can even hold its own with certain games, though it’s noticeably thicker and heavier than the Air. We gave it a score of 92 in our review. This deal matches the lowest price to date for a configuration with 16GB of RAM and a 512GB SSD. Also at Walmart. Apple Mac mini (M4) for $679 ($100 off): The latest iteration of Apple’s tiny desktop PC has a smaller footprint, a faster M4 chip, 16GB of RAM by default, two front-facing USB-C ports and an extra Thunderbolt 4 port. It can also drive three external displays, though it lacks USB-A ports entirely. We gave a higher-end model with Apple’s M4 Pro chip a score of 90 in our review. This deal marks the lowest price we could find for a configuration with the base M4 chip, 24GB of RAM and a 256GB SSD. Read more Apple coverage: The best AirPods The best Apple Watches The best MacBooks The best iPhones The best iPads Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-ipad-deals-this-week-include-100-off-the-ipad-air-m3-150020616.html?src=rss",
          "content": "We generally think iPads are the best tablets for most people, but they usually don’t come cheap. To help those looking to grab one today get the most value possible, we’re keeping an eye on sale prices and rounding up the best iPad deals we can find each week. Hopefully you were able to snag whatever iPad you’ve been eyeing at some point in the last couple of weeks, as most of the all-time lows we saw during Black Friday and Cyber Monday have expired. If you were late to the party, though, there are still some savings to be had, including $100 off both iPad Air models and an all-time low for the 13-inch iPad Pro. Beyond tablets, other Apple devices like the AirPods 4 with ANC, Apple Watch SE 3 and Apple Pencil Pro are still on sale at their Black Friday prices. Here are all of the top deals on Apple gear we could find this week. Best iPad deals Apple iPad Air (13-inch, M3) for $699 ($100 off MSRP): The 13-inch iPad Air is exactly the same as its smaller counterpart, only it has a larger and slightly brighter display. We gave it a review score of 89 earlier this year. This deal is $50 above the discount we saw on Black Friday but still $100 cheaper than buying from Apple directly. Also at B&H. Apple iPad Pro (11-inch, M5) for $927 ($72 off): The latest iPad Pro is still far more tablet than most people need, but its class-leading OLED display, impressively thin design and super-powerful M5 chip make it a luxury experience for those who can afford it. This 11-inch model sold for $899 during Black Friday, but the device was only released in October, so any sort of savings is still noteworthy. Also at Best Buy for $949. Apple iPad Pro (13-inch, M5) for $1,199 ($100 off): It’s not a massive discount, but this matches the lowest price so far for the larger iPad Pro, which may be worthwhile if you’ve got cash to burn and want to use an iPad as your main computer. We gave it a score of 85 in our review. Also at B&H. Best Apple deals Apple Watch SE 3 for $199 ($50 off): This discount has been around for a few weeks, but it’s the lowest price to date for Apple’s newest entry-level smartwatch. We gave this device a score of 90 in our review last month: The big upgrade is an always-on display, which makes it so you no longer have to wake the watch to check the time or notifications. It still includes most of the essential health and fitness features beyond that, plus it now runs on the same chipset as the higher-end Apple Watch Series 11. Also at Walmart. Apple Watch Series 11 for $329 ($70 off): The SE 3 may be a better raw value, but the Apple Watch Series 11 remains our preferred smartwatch overall for iPhone owners. Compared to its cheaper sibling, it has a bigger, brighter and more scratch-resistant display, longer battery life and a few advanced health features like an ECG app and hypertension alerts. It also earned a score of 90 in our review. This is an all-time low for the standard 42mm model, but keep in mind that there’s no pressing need to upgrade if you already own a Series 10. Also at Walmart. Apple Pencil Pro for $95 ($34 off): The Pencil Pro is Apple’s most feature-rich stylus, offering pressure sensitivity, wireless charging, haptic feedback and unique gesture controls compared to the standard USB-C model (which isn’t significantly discounted). Just note that it’s not compatible with the entry-level iPad and other older models. While this discount is only $5 below the device’s usual street price, it’s still the largest discount we’ve seen this year. Also at Walmart. Apple MacBook Pro (14-inch, M5) for $1,349 ($250 off): The newest MacBook Pro is the “best high-end” pick in our laptop buying guide and a fine choice for creative types who need something more powerful than the MacBook Air. The latter is still a much better value for most people, but the Pro gets you a superior mini-LED display with a 120Hz refresh rate, more ports and improved performance, especially with GPU-intensive tasks. It can even hold its own with certain games, though it’s noticeably thicker and heavier than the Air. We gave it a score of 92 in our review. This deal matches the lowest price to date for a configuration with 16GB of RAM and a 512GB SSD. Also at Walmart. Apple Mac mini (M4) for $679 ($100 off): The latest iteration of Apple’s tiny desktop PC has a smaller footprint, a faster M4 chip, 16GB of RAM by default, two front-facing USB-C ports and an extra Thunderbolt 4 port. It can also drive three external displays, though it lacks USB-A ports entirely. We gave a higher-end model with Apple’s M4 Pro chip a score of 90 in our review. This deal marks the lowest price we could find for a configuration with the base M4 chip, 24GB of RAM and a 256GB SSD. Read more Apple coverage: The best AirPods The best Apple Watches The best MacBooks The best iPhones The best iPads Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-ipad-deals-this-week-include-100-off-the-ipad-air-m3-150020616.html?src=rss",
          "feed_position": 10
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/x-hit-with-140-million-fine-from-the-eu-161259324.html",
          "published_at": "Fri, 05 Dec 2025 16:12:59 +0000",
          "title": "X hit with $140 million fine from the EU",
          "standfirst": "The European Commission has fined Elon Musk’s X €120 million (around $140 million) for breaching its transparency rules under the Digital Services Act. The European Union’s executive arm announced that it was investigating the social media company’s blue checkmarking verification system — first introduced when it was still known as Twitter — last year, along with other alleged DSA violations. Today’s verdict concerns the \"deceptive design\" of the checkmark, as well as \"the lack of transparency of [X's] advertising repository, and the failure to provide access to public data for researchers.\" The Commission's issue with X’s verification system is that where blue checkmarks were once something that Twitter that Twitter vetted, they can now be bough by anyone. According to the EU, this puts users at risk of scams and impersonation fraud, as they can’t tell if the accounts they’re engaging with are authentic. \"While the DSA does not mandate user verification, it clearly prohibits online platforms from falsely claiming that users have been verified, when no such verification took place,\" it wrote in a statement. The EU has also ruled that X’s advertisement repository employs \"design features and access barriers\" that make it difficult for good faith actors and the general public to determine the source of online ads and spot scams or threat campaigns. It says that X fails to provide information pertaining to both the content of an ad and the entity paying for its placement. The third alleged infringement concerns the public data that companies are required by the DSA to make available to qualifying researchers. The European Commission claims that X’s practices in this area are unnecessarily prohibitive, therefore \"effectively undermining research into several systemic risks in the European Union.\" X has 60 working days to respond to the EU’s non-compliance decision — the first of its nature — on blue checkmarks, and 90 days to submit an \"action plan\" of how it will address the alleged breaches relating to its advertising repository and access to public data. Failure to comply could result in financial penalties.This article originally appeared on Engadget at https://www.engadget.com/big-tech/x-hit-with-140-million-fine-from-the-eu-161259324.html?src=rss",
          "content": "The European Commission has fined Elon Musk’s X €120 million (around $140 million) for breaching its transparency rules under the Digital Services Act. The European Union’s executive arm announced that it was investigating the social media company’s blue checkmarking verification system — first introduced when it was still known as Twitter — last year, along with other alleged DSA violations. Today’s verdict concerns the \"deceptive design\" of the checkmark, as well as \"the lack of transparency of [X's] advertising repository, and the failure to provide access to public data for researchers.\" The Commission's issue with X’s verification system is that where blue checkmarks were once something that Twitter that Twitter vetted, they can now be bough by anyone. According to the EU, this puts users at risk of scams and impersonation fraud, as they can’t tell if the accounts they’re engaging with are authentic. \"While the DSA does not mandate user verification, it clearly prohibits online platforms from falsely claiming that users have been verified, when no such verification took place,\" it wrote in a statement. The EU has also ruled that X’s advertisement repository employs \"design features and access barriers\" that make it difficult for good faith actors and the general public to determine the source of online ads and spot scams or threat campaigns. It says that X fails to provide information pertaining to both the content of an ad and the entity paying for its placement. The third alleged infringement concerns the public data that companies are required by the DSA to make available to qualifying researchers. The European Commission claims that X’s practices in this area are unnecessarily prohibitive, therefore \"effectively undermining research into several systemic risks in the European Union.\" X has 60 working days to respond to the EU’s non-compliance decision — the first of its nature — on blue checkmarks, and 90 days to submit an \"action plan\" of how it will address the alleged breaches relating to its advertising repository and access to public data. Failure to comply could result in financial penalties.This article originally appeared on Engadget at https://www.engadget.com/big-tech/x-hit-with-140-million-fine-from-the-eu-161259324.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/how-to-watch-the-2026-fifa-world-cup-draw-live-today-120501930.html",
          "published_at": "Fri, 05 Dec 2025 16:08:38 +0000",
          "title": "How to watch the 2026 FIFA World Cup draw live today",
          "standfirst": "The 2026 FIFA World Cup draw is this Friday. (Hector Vivas - FIFA/FIFA via Getty Images) Hector Vivas - FIFA via Getty Images The draw for the 2026 World Cup is this Friday at 12 PM ET, where we’ll learn which group the 39 qualified countries and three host nations will land in for the international soccer tournament. The 2026 World Cup draw will air live on Fox. Pre-show coverage of the draw begins at 11:30 a.m. The venues and kickoff times for the World Cup group stage games be announced the following day. Tickets for the World Cup are already available. Here's how to watch the 2026 World Cup draw live, plus what you need to know about buying World Cup tickets, before or after the groupings are announced. How to watch the 2026 World Cup draw: Date: Friday, Dec. 5 Time: 12 p.m. ET/9 a.m. PT Location: Kennedy Center, Washington, D.C. TV channel: Fox Streaming: Fox One, DirecTV, YouTube via VPN and more When is the 2026 World Cup draw? The World Cup draw will take place on Friday, Dec. 5. All the group stage venues and kickoff times will then be announced the following day, on Saturday, Dec. 6 2026 World Cup draw start time: The World Cup draw will officially kick off at 12 p.m. ET/9 a.m. PT, though there will be pre-show coverage of the event as early as 11:30 a.m. ET. What channel is the World Cup draw on? The World Cup draw will air across Fox networks, including Fox and via the Fox Sports app. Coverage will also likely air on FS1. How to watch the World Cup draw: For those with live TV access, you may be able to watch Fox totally free over the air. But if not, here's how we recommend tuning in. How to watch the World Cup draw for free: In the U.S., the draw will air on Fox, but globally in many regions, a livestream of the draw will be available to watch via YouTube livestream, totally free. If you don’t have access to Fox, you might want to consider trying a VPN, so you can tune into the World Cup draw free livestream. Don’t want to navigate a VPN? Many live TV streaming services offer free trials, so you can also tune into the 2026 World Cup draw for free via a free trial. When is the 2026 World Cup? The 2026 World Cup begins on June 11, 2026 and runs through July 19, 2026. Where will 2026 World Cup games be held? There will be 15 host cities for the 2026 World Cup throughout the U.S., Mexico and Canada. They are: United States Atlanta – Mercedes-Benz Stadium, Atlanta, GA Boston – Gillette Stadium, Foxborough, MA Dallas – At&T Stadium, Arlington TX Houston – NRG Stadium, Houston, TX Kansas City – GEHA Field at Arrowhead Stadium, Kansas City, MO Los Angeles – Sofi Stadium, Inglewood, CA Miami – Hard Rock Stadium, Miami Gardens, FL New York/New Jersey – MetLife Stadium, East Rutherford, NJ Philadelphia – Lincoln Financial Field, Philadelphia, PA San Francisco Bay Area – Levi’s Stadium, Santa Clara, CA Seattle – Lumen Field, Seattle, WA Mexico Mexico City – Estadio Azteca, Coyoacan, Mexico City Monterrey – Estadio BBVA, Gudalupe, Nuevo Leon Guadalajara – Estadio Akron, Guadalajara Canada Toronto – BMO Field, Toronto, ON Vancouver – BC Place, Vancouver BC How to get 2026 World Cup tickets: Individual match tickets are now available to purchase through the FIFA website. To purchase tickets that are part of a multi-game or hospitality package, you can sign up here to receive more information. In addition, there will also be a final ticket lottery held after this week's draw; fans will be able to submit applications for specific matches once the group-stage matchups have been revealed to try and grab a limited number of lower-priced tickets at select matches. (An exact date for this lottery has not yet been revealed but you can sign-up to receive up-to-date information on the FIFA site.) When do 2026 World Cup tickets go on sale? Tickets for the 2026 World Cup are now on sale, though the match schedule doesn't specify team groupings (yet). Find tickets on FIFA's website Find tickets on StubHub How much are 2026 World Cup tickets? Currently, individual tickets for the 2026 World Cup run anywhere from $1,400 to $3,500 (if you're searching for tickets for matches in Mexico or Canada, don't be scared off by their higher price tags — they're all in the same price range after adjusting for conversion rates). Tickets for the group stage, knockout rounds, and the bronze final are currently available. It's important to note that FIFA is employing a dynamic pricing strategy, so prices may fluctuate as we get closer to the tournament, depending on demand. For those lucky enough to enter and be selected in the ticketing lottery, prices are significantly less – they're broken out into four categories based on seating, and range from $60 to $620, but these prices are not available to the general public. Hospitality packages, which guarantee entry to multiple matches are also on sale now and start at $5,300. (Note that depending on the venue and package you select, some of these packages can cost up to $68,000 per person, and while that price includes food, drinks and premium seating, it doesn't include travel expenses or accommodations.) Tickets are also available through FIFA's own resale marketplace and on third-party resale sites like StubHub already have single-game matches available, with some starting around $275 per seat and going up from there, depending on the game and venue. Find tickets on StubHub Find tickets on FIFA's Ticket Resale Marketplace 2026 World Cup Schedule (All times Eastern) The 2026 World Cup will begin on Thursday, June 11, 2026, and the final is scheduled for Sunday, July 19, 2026. You can take a look at the existing schedule here. Group Stage June 11 – June 27, 2026 Knockout stage matches Round of 32: June 28 – July 3, 2026 Round of 16: July 4 – July 7, 2026 Quarterfinals: July 9 – July 11, 2026 Semifinals: July 14 – 15, 2026 Bronze Final (3rd Place Match): July 18, 2026 Final: July 19, 2026 This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/how-to-watch-the-2026-fifa-world-cup-draw-live-today-120501930.html?src=rss",
          "content": "The 2026 FIFA World Cup draw is this Friday. (Hector Vivas - FIFA/FIFA via Getty Images) Hector Vivas - FIFA via Getty Images The draw for the 2026 World Cup is this Friday at 12 PM ET, where we’ll learn which group the 39 qualified countries and three host nations will land in for the international soccer tournament. The 2026 World Cup draw will air live on Fox. Pre-show coverage of the draw begins at 11:30 a.m. The venues and kickoff times for the World Cup group stage games be announced the following day. Tickets for the World Cup are already available. Here's how to watch the 2026 World Cup draw live, plus what you need to know about buying World Cup tickets, before or after the groupings are announced. How to watch the 2026 World Cup draw: Date: Friday, Dec. 5 Time: 12 p.m. ET/9 a.m. PT Location: Kennedy Center, Washington, D.C. TV channel: Fox Streaming: Fox One, DirecTV, YouTube via VPN and more When is the 2026 World Cup draw? The World Cup draw will take place on Friday, Dec. 5. All the group stage venues and kickoff times will then be announced the following day, on Saturday, Dec. 6 2026 World Cup draw start time: The World Cup draw will officially kick off at 12 p.m. ET/9 a.m. PT, though there will be pre-show coverage of the event as early as 11:30 a.m. ET. What channel is the World Cup draw on? The World Cup draw will air across Fox networks, including Fox and via the Fox Sports app. Coverage will also likely air on FS1. How to watch the World Cup draw: For those with live TV access, you may be able to watch Fox totally free over the air. But if not, here's how we recommend tuning in. How to watch the World Cup draw for free: In the U.S., the draw will air on Fox, but globally in many regions, a livestream of the draw will be available to watch via YouTube livestream, totally free. If you don’t have access to Fox, you might want to consider trying a VPN, so you can tune into the World Cup draw free livestream. Don’t want to navigate a VPN? Many live TV streaming services offer free trials, so you can also tune into the 2026 World Cup draw for free via a free trial. When is the 2026 World Cup? The 2026 World Cup begins on June 11, 2026 and runs through July 19, 2026. Where will 2026 World Cup games be held? There will be 15 host cities for the 2026 World Cup throughout the U.S., Mexico and Canada. They are: United States Atlanta – Mercedes-Benz Stadium, Atlanta, GA Boston – Gillette Stadium, Foxborough, MA Dallas – At&T Stadium, Arlington TX Houston – NRG Stadium, Houston, TX Kansas City – GEHA Field at Arrowhead Stadium, Kansas City, MO Los Angeles – Sofi Stadium, Inglewood, CA Miami – Hard Rock Stadium, Miami Gardens, FL New York/New Jersey – MetLife Stadium, East Rutherford, NJ Philadelphia – Lincoln Financial Field, Philadelphia, PA San Francisco Bay Area – Levi’s Stadium, Santa Clara, CA Seattle – Lumen Field, Seattle, WA Mexico Mexico City – Estadio Azteca, Coyoacan, Mexico City Monterrey – Estadio BBVA, Gudalupe, Nuevo Leon Guadalajara – Estadio Akron, Guadalajara Canada Toronto – BMO Field, Toronto, ON Vancouver – BC Place, Vancouver BC How to get 2026 World Cup tickets: Individual match tickets are now available to purchase through the FIFA website. To purchase tickets that are part of a multi-game or hospitality package, you can sign up here to receive more information. In addition, there will also be a final ticket lottery held after this week's draw; fans will be able to submit applications for specific matches once the group-stage matchups have been revealed to try and grab a limited number of lower-priced tickets at select matches. (An exact date for this lottery has not yet been revealed but you can sign-up to receive up-to-date information on the FIFA site.) When do 2026 World Cup tickets go on sale? Tickets for the 2026 World Cup are now on sale, though the match schedule doesn't specify team groupings (yet). Find tickets on FIFA's website Find tickets on StubHub How much are 2026 World Cup tickets? Currently, individual tickets for the 2026 World Cup run anywhere from $1,400 to $3,500 (if you're searching for tickets for matches in Mexico or Canada, don't be scared off by their higher price tags — they're all in the same price range after adjusting for conversion rates). Tickets for the group stage, knockout rounds, and the bronze final are currently available. It's important to note that FIFA is employing a dynamic pricing strategy, so prices may fluctuate as we get closer to the tournament, depending on demand. For those lucky enough to enter and be selected in the ticketing lottery, prices are significantly less – they're broken out into four categories based on seating, and range from $60 to $620, but these prices are not available to the general public. Hospitality packages, which guarantee entry to multiple matches are also on sale now and start at $5,300. (Note that depending on the venue and package you select, some of these packages can cost up to $68,000 per person, and while that price includes food, drinks and premium seating, it doesn't include travel expenses or accommodations.) Tickets are also available through FIFA's own resale marketplace and on third-party resale sites like StubHub already have single-game matches available, with some starting around $275 per seat and going up from there, depending on the game and venue. Find tickets on StubHub Find tickets on FIFA's Ticket Resale Marketplace 2026 World Cup Schedule (All times Eastern) The 2026 World Cup will begin on Thursday, June 11, 2026, and the final is scheduled for Sunday, July 19, 2026. You can take a look at the existing schedule here. Group Stage June 11 – June 27, 2026 Knockout stage matches Round of 32: June 28 – July 3, 2026 Round of 16: July 4 – July 7, 2026 Quarterfinals: July 9 – July 11, 2026 Semifinals: July 14 – 15, 2026 Bronze Final (3rd Place Match): July 18, 2026 Final: July 19, 2026 This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/how-to-watch-the-2026-fifa-world-cup-draw-live-today-120501930.html?src=rss",
          "feed_position": 13,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/145000c0-d158-11f0-bff9-945634cd4813"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/where-the-hell-is-samsungs-ballie-robot-151112829.html",
          "published_at": "Fri, 05 Dec 2025 15:11:12 +0000",
          "title": "Where the hell is Samsung's Ballie robot?",
          "standfirst": "Another CES is nearly upon us, another year where we’ll see new gadgets aplenty from giant companies and tiny ones you’ve never heard of. And the not-so-secret secret of CES is that many of these things never make it to market — but usually it isn’t things companies like Samsung show off. But here we are, nearly six years since Samsung first showed off its Ballie personal robot and it is nowhere to be found.For those who may not recall, Ballie is an adorable circular robot that can putter around your house and project things onto the floor and wall. It’s kind of a virtual assistant on the go. Samsung first revealed this tiny robot at CES 2020, but it was more of a prototype than something anyone expected to purchase. And then there was a global pandemic and we all sort of forgot about weird ball-shaped robots for a few. But Samsung triumphantly unveiled a larger and more refined Ballie at CES 2024, saying it would be on sale that year! Well, that didn’t happen, but a year later Ballie was back at CES again. Samsung promised it would go on sale in 2025, and followed up with a press release this past April saying it was on track for a summer launch in Korea and the US. As far as I can tell, that’s the last we’ve heard of it. But with CES looming again, I can’t help but feel like Samsung will roll Ballie out once more, trying to sell the dream of a cute robotic companion who just gets you. I spent some time watching Ballie do its thing in a carefully controlled demo at CES 2024, and I can’t say I was overwhelmed by its purported usefulness or thought there’d be much of a market for this thing. I now can’t help but wonder if Samsung has data backs up my intuition. If this thing was going to sell like gangbusters, it likely wouldn’t be subjected to such a long and public gestation period. It reminds me a little of one of my favorite Samsung gaffes, the Galaxy Home smart speaker. It was announced at a time when Apple and Google were challenging Sonos and Amazon with voice-activated speakers of their own, moving Siri or the Google Assistant from your phone to a more omnipresent place in your home. The first rumor of the Galaxy Home happened way back in 2017, and the speaker was officially revealed and briefly shown off by Samsung in August of 2018. My immediate reaction was that this product made very little sense for both Samsung and potential customers — Bibxy sucked, and there were plenty of speakers with better voice assistants. Apparently, Samsung agreed. After multiple years of vague commitments and references to the Galaxy Home, Samsung just… stopped talking about it. Oddly enough, a Galaxy Home Mini speaker was briefly released in South Korea, part of a promotion for people who pre-ordered the Galaxy S20. But I don’t think you could ever just walk into a store and buy one, and the larger Galaxy Home never materialized at all. Ballie isn’t quite the abandonware situation that the Galaxy Home was, at least not yet. After all, it’s only been about eight months since Samsung dropped that press release claiming it would arrive soon. The company has definitely pushed Ballie in a more public way than the Galaxy Home, making it a little harder to just drop entirely. Maybe we’ll see a revamped Ballie with even more weird tricks next month, or maybe we’ll just get another vague promise that it’ll arrive in 2026. After failing to deliver two years in a row, though, I’m not going to expect Ballie to show up as a real product until I can punch in my credit card and pre-order it... not that I’d do that anyway. Ballie needs to show that it’s a lot more than a cute rolling robot before Samsung gets my cash. This article originally appeared on Engadget at https://www.engadget.com/ai/where-the-hell-is-samsungs-ballie-robot-151112829.html?src=rss",
          "content": "Another CES is nearly upon us, another year where we’ll see new gadgets aplenty from giant companies and tiny ones you’ve never heard of. And the not-so-secret secret of CES is that many of these things never make it to market — but usually it isn’t things companies like Samsung show off. But here we are, nearly six years since Samsung first showed off its Ballie personal robot and it is nowhere to be found.For those who may not recall, Ballie is an adorable circular robot that can putter around your house and project things onto the floor and wall. It’s kind of a virtual assistant on the go. Samsung first revealed this tiny robot at CES 2020, but it was more of a prototype than something anyone expected to purchase. And then there was a global pandemic and we all sort of forgot about weird ball-shaped robots for a few. But Samsung triumphantly unveiled a larger and more refined Ballie at CES 2024, saying it would be on sale that year! Well, that didn’t happen, but a year later Ballie was back at CES again. Samsung promised it would go on sale in 2025, and followed up with a press release this past April saying it was on track for a summer launch in Korea and the US. As far as I can tell, that’s the last we’ve heard of it. But with CES looming again, I can’t help but feel like Samsung will roll Ballie out once more, trying to sell the dream of a cute robotic companion who just gets you. I spent some time watching Ballie do its thing in a carefully controlled demo at CES 2024, and I can’t say I was overwhelmed by its purported usefulness or thought there’d be much of a market for this thing. I now can’t help but wonder if Samsung has data backs up my intuition. If this thing was going to sell like gangbusters, it likely wouldn’t be subjected to such a long and public gestation period. It reminds me a little of one of my favorite Samsung gaffes, the Galaxy Home smart speaker. It was announced at a time when Apple and Google were challenging Sonos and Amazon with voice-activated speakers of their own, moving Siri or the Google Assistant from your phone to a more omnipresent place in your home. The first rumor of the Galaxy Home happened way back in 2017, and the speaker was officially revealed and briefly shown off by Samsung in August of 2018. My immediate reaction was that this product made very little sense for both Samsung and potential customers — Bibxy sucked, and there were plenty of speakers with better voice assistants. Apparently, Samsung agreed. After multiple years of vague commitments and references to the Galaxy Home, Samsung just… stopped talking about it. Oddly enough, a Galaxy Home Mini speaker was briefly released in South Korea, part of a promotion for people who pre-ordered the Galaxy S20. But I don’t think you could ever just walk into a store and buy one, and the larger Galaxy Home never materialized at all. Ballie isn’t quite the abandonware situation that the Galaxy Home was, at least not yet. After all, it’s only been about eight months since Samsung dropped that press release claiming it would arrive soon. The company has definitely pushed Ballie in a more public way than the Galaxy Home, making it a little harder to just drop entirely. Maybe we’ll see a revamped Ballie with even more weird tricks next month, or maybe we’ll just get another vague promise that it’ll arrive in 2026. After failing to deliver two years in a row, though, I’m not going to expect Ballie to show up as a real product until I can punch in my credit card and pre-order it... not that I’d do that anyway. Ballie needs to show that it’s a lot more than a cute rolling robot before Samsung gets my cash. This article originally appeared on Engadget at https://www.engadget.com/ai/where-the-hell-is-samsungs-ballie-robot-151112829.html?src=rss",
          "feed_position": 16
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/ai-denial-is-becoming-an-enterprise-risk-why-dismissing-slop-obscures-real",
          "published_at": "Fri, 05 Dec 2025 13:00:00 GMT",
          "title": "AI denial is becoming an enterprise risk: Why dismissing “slop” obscures real capability gains",
          "standfirst": "Three years ago, ChatGPT was born. It amazed the world and ignited unprecedented investment and excitement in AI. Today, ChatGPT is still a toddler, but public sentiment around the AI boom has turned sharply negative. The shift began when OpenAI released GPT-5 this summer to mixed reviews, mostly from casual users who, unsurprisingly, judged the system by its surface flaws rather than its underlying capabilities.Since then, pundits and influencers have declared that AI progress is slowing, that scaling has “hit the wall,” and that the entire field is just another tech bubble inflated by blusterous hype. In fact, many influencers have latched onto the dismissive phrase “AI slop” to diminish the amazing images, documents, videos and code that frontier AI models generate on command.This perspective is not just wrong, it is dangerous.It makes me wonder, where were all these “experts” on irrational technology bubbles when electric scooter startups were touted as a transportation revolution and cartoon NFTs were being auctioned for millions? They were probably too busy buying worthless land in the metaverse or adding to their positions in GameStop. But when it comes to the AI boom, which is easily the most significant technological and economic transformation agent of the last 25 years, journalists and influencers can’t write the word “slop” enough times. Doth we protest too much? After all, by any objective measure AI is wildly more capable than the vast majority of computer scientists predicted only five years ago and it is still improving at a surprising pace. The impressive leap demonstrated by Gemini 3 is only the latest example. At the same time, McKinsey recently reported that 20% of organizations already derive tangible value from genAI. Also, a recent survey by Deloitte indicates that 85% of organizations boosted their AI investment in 2025, and 91% plan to increase again in 2026.This doesn’t fit the “bubble” narrative and the dismissive “slop” language. As a computer scientist and research engineer who began working with neural networks back in 1989 and tracked progress through cold winters and hot booms ever since, I find myself amazed almost every day by the rapidly increasing capabilities of frontier AI models. When I talk with other professionals in the field, I hear similar sentiments. If anything, the rate of AI advancement leaves many experts feeling overwhelmed and frankly somewhat scared. The dangers of AI denialSo why is the public buying into the narrative that AI is faltering, that the output is “slop,” and that the AI boom lacks authentic use cases? Personally, I believe it’s because we’ve fallen into a collective state of AI denial, latching onto the narratives we want to hear in the face of strong evidence to the contrary. Denial is the first stage of grief and thus a reasonable reaction to the very disturbing prospect that we humans may soon lose cognitive supremacy here on planet earth. In other words, the overblown AI bubble narrative is a societal defense mechanism. Believe me, I get it. I’ve been warning about the destabilizing risks and demoralizing impact of superintelligence for well over a decade, and I too feel AI is getting too smart too fast. The fact is, we are rapidly headed towards a future where widely available AI systems will be able to outperform most humans in most cognitive tasks, solving problems faster, more accurately and yes, more creatively than any individual can. I emphasize “creativity” because AI denialists often insist that certain human qualities (particularly creativity and emotional intelligence) will always be out of reach of AI systems. Unfortunately, there is little evidence supporting this perspective.On the creativity front, today’s AI models can generate content faster and with more variation than any individual human. Critics argue that true creativity requires inner motivation. I resonate with that argument but find it circular — we&#x27;re defining creativity based on how we experience it rather than the quality, originality or usefulness of the output. Also, we just don’t know if AI systems will develop internal drives or a sense of agency. Either way, if AI can produce original work that rivals most human professionals, the impact on creative jobs will still be quite devastating.The AI manipulation problemOur human edge around emotional intelligence is even more precarious. It’s likely that AI will soon be able to read our emotions faster and more accurately than any human, tracking subtle cues in our micro-expressions, vocal patterns, posture, gaze and even breathing. And as we integrate AI assistants into our phones, glasses and other wearable devices, these systems will monitor our emotional reactions throughout our day, building predictive models of our behaviors. Without strict regulation, which is increasingly unlikely, these predictive models could be used to target us with individually optimized influence that maximizes persuasion.This is called the AI manipulation problem and it suggests that emotional intelligence may not give humanity an advantage. In fact, it could be a significant weakness, fostering an asymmetric dynamic where AI systems can read us with superhuman accuracy, while we can’t read AI at all. When you talk with photorealistic AI agents (and you will) you’ll see a smiling façade designed to appear warm, empathic and trustworthy. It will look and feel human, but that’s just an illusion, and it could easily sway your perspectives. After all, our emotional reactions to faces are visceral reflexes shaped by millions of years of evolution on a planet where every interactive human face we encountered was actually human. Soon, that will no longer be true.We are rapidly heading toward a world where many of the faces we encounter will belong to AI agents hiding behind digital facades. In fact, these “virtual spokespeople” could easily have appearances that are designed for each of us based on our prior reactions – whatever gets us to best let down our guard. And yet many insist that AI is just another tech cycle.This is wishful thinking. The massive investment pouring into AI isn’t driven by hype — it’s driven by the expectation that AI will permeate every aspect of daily life, embodied as intelligent actors we engage throughout our day. These systems will assist us, teach us and influence us. They will reshape our lives, and it will happen faster than most people think.To be clear, we are not witnessing an AI bubble filling with empty gas. We are watching a new planet form, a molten world rapidly taking shape, and it will solidify into a new AI-powered society. Denial will not stop this. It will only make us less prepared for the risks.Louis Rosenberg is an early pioneer of augmented reality and a longtime AI researcher.",
          "content": "Three years ago, ChatGPT was born. It amazed the world and ignited unprecedented investment and excitement in AI. Today, ChatGPT is still a toddler, but public sentiment around the AI boom has turned sharply negative. The shift began when OpenAI released GPT-5 this summer to mixed reviews, mostly from casual users who, unsurprisingly, judged the system by its surface flaws rather than its underlying capabilities.Since then, pundits and influencers have declared that AI progress is slowing, that scaling has “hit the wall,” and that the entire field is just another tech bubble inflated by blusterous hype. In fact, many influencers have latched onto the dismissive phrase “AI slop” to diminish the amazing images, documents, videos and code that frontier AI models generate on command.This perspective is not just wrong, it is dangerous.It makes me wonder, where were all these “experts” on irrational technology bubbles when electric scooter startups were touted as a transportation revolution and cartoon NFTs were being auctioned for millions? They were probably too busy buying worthless land in the metaverse or adding to their positions in GameStop. But when it comes to the AI boom, which is easily the most significant technological and economic transformation agent of the last 25 years, journalists and influencers can’t write the word “slop” enough times. Doth we protest too much? After all, by any objective measure AI is wildly more capable than the vast majority of computer scientists predicted only five years ago and it is still improving at a surprising pace. The impressive leap demonstrated by Gemini 3 is only the latest example. At the same time, McKinsey recently reported that 20% of organizations already derive tangible value from genAI. Also, a recent survey by Deloitte indicates that 85% of organizations boosted their AI investment in 2025, and 91% plan to increase again in 2026.This doesn’t fit the “bubble” narrative and the dismissive “slop” language. As a computer scientist and research engineer who began working with neural networks back in 1989 and tracked progress through cold winters and hot booms ever since, I find myself amazed almost every day by the rapidly increasing capabilities of frontier AI models. When I talk with other professionals in the field, I hear similar sentiments. If anything, the rate of AI advancement leaves many experts feeling overwhelmed and frankly somewhat scared. The dangers of AI denialSo why is the public buying into the narrative that AI is faltering, that the output is “slop,” and that the AI boom lacks authentic use cases? Personally, I believe it’s because we’ve fallen into a collective state of AI denial, latching onto the narratives we want to hear in the face of strong evidence to the contrary. Denial is the first stage of grief and thus a reasonable reaction to the very disturbing prospect that we humans may soon lose cognitive supremacy here on planet earth. In other words, the overblown AI bubble narrative is a societal defense mechanism. Believe me, I get it. I’ve been warning about the destabilizing risks and demoralizing impact of superintelligence for well over a decade, and I too feel AI is getting too smart too fast. The fact is, we are rapidly headed towards a future where widely available AI systems will be able to outperform most humans in most cognitive tasks, solving problems faster, more accurately and yes, more creatively than any individual can. I emphasize “creativity” because AI denialists often insist that certain human qualities (particularly creativity and emotional intelligence) will always be out of reach of AI systems. Unfortunately, there is little evidence supporting this perspective.On the creativity front, today’s AI models can generate content faster and with more variation than any individual human. Critics argue that true creativity requires inner motivation. I resonate with that argument but find it circular — we&#x27;re defining creativity based on how we experience it rather than the quality, originality or usefulness of the output. Also, we just don’t know if AI systems will develop internal drives or a sense of agency. Either way, if AI can produce original work that rivals most human professionals, the impact on creative jobs will still be quite devastating.The AI manipulation problemOur human edge around emotional intelligence is even more precarious. It’s likely that AI will soon be able to read our emotions faster and more accurately than any human, tracking subtle cues in our micro-expressions, vocal patterns, posture, gaze and even breathing. And as we integrate AI assistants into our phones, glasses and other wearable devices, these systems will monitor our emotional reactions throughout our day, building predictive models of our behaviors. Without strict regulation, which is increasingly unlikely, these predictive models could be used to target us with individually optimized influence that maximizes persuasion.This is called the AI manipulation problem and it suggests that emotional intelligence may not give humanity an advantage. In fact, it could be a significant weakness, fostering an asymmetric dynamic where AI systems can read us with superhuman accuracy, while we can’t read AI at all. When you talk with photorealistic AI agents (and you will) you’ll see a smiling façade designed to appear warm, empathic and trustworthy. It will look and feel human, but that’s just an illusion, and it could easily sway your perspectives. After all, our emotional reactions to faces are visceral reflexes shaped by millions of years of evolution on a planet where every interactive human face we encountered was actually human. Soon, that will no longer be true.We are rapidly heading toward a world where many of the faces we encounter will belong to AI agents hiding behind digital facades. In fact, these “virtual spokespeople” could easily have appearances that are designed for each of us based on our prior reactions – whatever gets us to best let down our guard. And yet many insist that AI is just another tech cycle.This is wishful thinking. The massive investment pouring into AI isn’t driven by hype — it’s driven by the expectation that AI will permeate every aspect of daily life, embodied as intelligent actors we engage throughout our day. These systems will assist us, teach us and influence us. They will reshape our lives, and it will happen faster than most people think.To be clear, we are not witnessing an AI bubble filling with empty gas. We are watching a new planet form, a molten world rapidly taking shape, and it will solidify into a new AI-powered society. Denial will not stop this. It will only make us less prepared for the risks.Louis Rosenberg is an early pioneer of augmented reality and a longtime AI researcher.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4cm8F6jnq7mT7NhyXWA1qQ/119d505338624d93ce9134238ebe73d3/Denialism.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/microsofts-copilot-ai-pc-plan-fizzled-but-it-still-served-a-purpose-130000239.html",
          "published_at": "Fri, 05 Dec 2025 13:00:00 +0000",
          "title": "Microsoft's Copilot+ AI PC plan fizzled, but it still served a purpose",
          "standfirst": "Microsoft's Copilot+ initiative launched last year with a clear goal: To produce capable laptops for people eagerly anticipating AI-powered features. Read that sentence again, and it's glaringly obvious that Microsoft's plan was flawed from the start. Most consumers aren't nearly as hyped for AI features as the companies eager to foist artificial intelligence upon us. And those features aren't exactly compelling, either. Microsoft's Recall — which snaps screenshots of your PC to create a database of everything you’ve done– was dogged by privacy concerns from the start. And to be honest, I haven't found its ability to remember the files and websites I've opened to be that useful.Without any sort of killer AI app, most consumers weren't going to pay a premium for Copilot+ systems either. Not in this precarious economy, anyway. So it wasn't a huge surprise to see sales of Copilot+ systems going practically nowhere over the last year. In the third quarter of 2024, they accounted for less than 10 percent of systems shipped, according to data from Mercury Research (via Tom’s Hardware). The research firm IDC (via PCWorld) also found that Copilot+ systems made up just 2.3 percent of Windows machines sold in the first quarter of 2025 (and a mere 1.9 percent of the entire PC market).Instead of continuing to promote Copilot+, Microsoft now wants to \"make every Windows 11 computer an AI PC\". The new \"Hey Copilot\" voice commands and Copilot Vision, a feature that lets the AI assistant see what's on your screen, are both cloud-powered. That means you won't need the beefy 40 TOPS neural processing units (NPU) found on Copilot+ systems to use them. Microsoft spent the past few years touting NPUs as the gateway to useful AI features, like Recall and Windows Studio webcam effects, but only one of its new AI capabilities actually requires an NPU. (And even that is just a slight update to Click to Do, allowing you to send Zoom invitations by right-clicking on e-mail addresses.)It's easy to view the whole Copilot+ initiative as a cynical way to ramp up AI hype and push people towards expensive new laptops, especially as the October 14 Windows 10 end of support date loomed. But it also led to some genuinely useful changes: Microsoft made 16GB of RAM a standard for Copilot+ systems, along with 256GB of storage and the aforementioned 40 TOPS NPUs. The launch of Copilot was also the kick in the pants Microsoft needed to revamp Windows for mobile Arm processors. I never thought I'd love a Surface with a Snapdragon chip, but the improved Arm support on the Surface Pro and this year's smaller model finally won me over.The Dell 16 Premium sitting on a ledge.I wouldn’t call the Copilot+ program a huge swing, but it’s still the sort of industry-wide cat herding that’s rare to see in the PC space. Microsoft couldn’t just snap its fingers and shift all PCs to efficient mobile chips with powerful NPUs, like Apple did with its own jump to M-series chips years ago. Microsoft had to wait for new NPU-equipped hardware from Qualcomm (and eventually Intel and AMD). It had to finally fix the Windows on Arm problem. And it also had to double-down on AI features that felt truly transformative. It’s just a shame that consumers didn’t seem to care.Microsoft said that Copilot+ systems accounted for 15 percent of premium PCs sold during last year’s holiday season, but the company hasn’t released any new sales figures since then. “This is the fastest adoption I've seen of a new category of hardware, and we've done it faster than the normal generational shift of silicon,” James Howell, Microsoft’s VP of Windows marketing, said in a conversation with Engadget. “Copilot+ PCs continue to be a transition that we are pushing for and prioritizing. But I can't give you the exact numbers beyond that… Just for the last two or three months, we've been doing pretty well with year-on-year growth in the Windows business.”Surface Pro Copilot+Devindra Hardawar for EngadgetWhile Microsoft ultimately doesn’t have much to show for the Copilot+ initiative, the steady progression of hardware will lead to AI PCs dominating over the next five years. The research firm Omdia predicts that AI PCs will account for 55 percent of computers shipped in all of 2026, up from 42.5 percent of systems in Q3 2025. By 2029, Omdia predicts AI PCs will make up 75 percent of all systems shipped, giving Windows 80 percent of the AI PC market. Omdia AI PC shipment predictionsOmdia“It’s important to note that this steep adoption curve [for AI PCs] is driven more by the product roadmaps of the PC market, rather than consumers and businesses seeking PCs specifically for AI,” according to Omdia research analyst Kieren Jessop. “For businesses, and consumers especially, AI-capable PC adoption is more a function of a customer going to purchase a device and that device just so happens to have an NPU.”Microsoft was basically right: AI PCs are the future. But it turns out the AI features people actually want to use — like ChatGPT, Sora and Microsoft’s own Copilot — are mostly powered by the cloud, making onboard NPUs superfluous. That won’t be true forever. There are tangible security, speed and convenience benefits for onboard AI processing, like transcribing sensitive audio instead of sending it to the cloud. But for now, those AI workloads are relatively niche, and they’re not enough to make the Copilot+ a true success by any measure.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/microsofts-copilot-ai-pc-plan-fizzled-but-it-still-served-a-purpose-130000239.html?src=rss",
          "content": "Microsoft's Copilot+ initiative launched last year with a clear goal: To produce capable laptops for people eagerly anticipating AI-powered features. Read that sentence again, and it's glaringly obvious that Microsoft's plan was flawed from the start. Most consumers aren't nearly as hyped for AI features as the companies eager to foist artificial intelligence upon us. And those features aren't exactly compelling, either. Microsoft's Recall — which snaps screenshots of your PC to create a database of everything you’ve done– was dogged by privacy concerns from the start. And to be honest, I haven't found its ability to remember the files and websites I've opened to be that useful.Without any sort of killer AI app, most consumers weren't going to pay a premium for Copilot+ systems either. Not in this precarious economy, anyway. So it wasn't a huge surprise to see sales of Copilot+ systems going practically nowhere over the last year. In the third quarter of 2024, they accounted for less than 10 percent of systems shipped, according to data from Mercury Research (via Tom’s Hardware). The research firm IDC (via PCWorld) also found that Copilot+ systems made up just 2.3 percent of Windows machines sold in the first quarter of 2025 (and a mere 1.9 percent of the entire PC market).Instead of continuing to promote Copilot+, Microsoft now wants to \"make every Windows 11 computer an AI PC\". The new \"Hey Copilot\" voice commands and Copilot Vision, a feature that lets the AI assistant see what's on your screen, are both cloud-powered. That means you won't need the beefy 40 TOPS neural processing units (NPU) found on Copilot+ systems to use them. Microsoft spent the past few years touting NPUs as the gateway to useful AI features, like Recall and Windows Studio webcam effects, but only one of its new AI capabilities actually requires an NPU. (And even that is just a slight update to Click to Do, allowing you to send Zoom invitations by right-clicking on e-mail addresses.)It's easy to view the whole Copilot+ initiative as a cynical way to ramp up AI hype and push people towards expensive new laptops, especially as the October 14 Windows 10 end of support date loomed. But it also led to some genuinely useful changes: Microsoft made 16GB of RAM a standard for Copilot+ systems, along with 256GB of storage and the aforementioned 40 TOPS NPUs. The launch of Copilot was also the kick in the pants Microsoft needed to revamp Windows for mobile Arm processors. I never thought I'd love a Surface with a Snapdragon chip, but the improved Arm support on the Surface Pro and this year's smaller model finally won me over.The Dell 16 Premium sitting on a ledge.I wouldn’t call the Copilot+ program a huge swing, but it’s still the sort of industry-wide cat herding that’s rare to see in the PC space. Microsoft couldn’t just snap its fingers and shift all PCs to efficient mobile chips with powerful NPUs, like Apple did with its own jump to M-series chips years ago. Microsoft had to wait for new NPU-equipped hardware from Qualcomm (and eventually Intel and AMD). It had to finally fix the Windows on Arm problem. And it also had to double-down on AI features that felt truly transformative. It’s just a shame that consumers didn’t seem to care.Microsoft said that Copilot+ systems accounted for 15 percent of premium PCs sold during last year’s holiday season, but the company hasn’t released any new sales figures since then. “This is the fastest adoption I've seen of a new category of hardware, and we've done it faster than the normal generational shift of silicon,” James Howell, Microsoft’s VP of Windows marketing, said in a conversation with Engadget. “Copilot+ PCs continue to be a transition that we are pushing for and prioritizing. But I can't give you the exact numbers beyond that… Just for the last two or three months, we've been doing pretty well with year-on-year growth in the Windows business.”Surface Pro Copilot+Devindra Hardawar for EngadgetWhile Microsoft ultimately doesn’t have much to show for the Copilot+ initiative, the steady progression of hardware will lead to AI PCs dominating over the next five years. The research firm Omdia predicts that AI PCs will account for 55 percent of computers shipped in all of 2026, up from 42.5 percent of systems in Q3 2025. By 2029, Omdia predicts AI PCs will make up 75 percent of all systems shipped, giving Windows 80 percent of the AI PC market. Omdia AI PC shipment predictionsOmdia“It’s important to note that this steep adoption curve [for AI PCs] is driven more by the product roadmaps of the PC market, rather than consumers and businesses seeking PCs specifically for AI,” according to Omdia research analyst Kieren Jessop. “For businesses, and consumers especially, AI-capable PC adoption is more a function of a customer going to purchase a device and that device just so happens to have an NPU.”Microsoft was basically right: AI PCs are the future. But it turns out the AI features people actually want to use — like ChatGPT, Sora and Microsoft’s own Copilot — are mostly powered by the cloud, making onboard NPUs superfluous. That won’t be true forever. There are tangible security, speed and convenience benefits for onboard AI processing, like transcribing sensitive audio instead of sending it to the cloud. But for now, those AI workloads are relatively niche, and they’re not enough to make the Copilot+ a true success by any measure.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/microsofts-copilot-ai-pc-plan-fizzled-but-it-still-served-a-purpose-130000239.html?src=rss",
          "feed_position": 20,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Dell_16_Premium-6.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-121538076.html",
          "published_at": "Fri, 05 Dec 2025 12:15:38 +0000",
          "title": "The Morning After: Flying Antigravity’s A1 drone is unlike anything else",
          "standfirst": "Spinning off from the action-camera company Insta360, Antigravity now has its debut drone on sale. With 360-degree cameras that capture 8K and offer you a truly unconstrained view of the skies, the A1 is a different drone from everything else out there. Sorry, DJI. Instead of typical drone joysticks, you get a motion controller that lets you point and shoot like video game gesture controls, while crisp FPV goggles put you right inside the cockpit. Engadget It’s easy to fly after takeoff, but the A1’s myriad parts are often tricky to sync together — and pulling video down to the companion app is even trickier. Going on specs alone, like speed and camera sensor size, it doesn’t stand up to cinematic drones from the likes of DJI. Still, it’s not meant to be a cinematic drone. It’s a hybrid mix of flight experience, FPV drone and a not-miss-a-thing camera drone. It’s truly unique — and fun. — Mat Smith The other big stories (and deals) this morning The best Christmas gifts to give everyone on your 2025 holiday shopping list A shaky year for American EVs could set the tone for 2026 Metroid Prime 4: Beyond review Amazon Luna’s December lineup includes Hollow Knight, Lego 2K Drive and a few Fallout games Amazon halts its incredibly poor AI anime dubbing ‘beta’ Ridiculed by all. Amazon has quietly removed its terrible AI-generated English dubs for several anime shows on Prime Video, following widespread ridicule from viewers and the industry. AI dubs were recently added to Banana Fish, No Game, No Life and Vinland Saga, where they were labeled “AI beta” in the Languages section of the app. For shows lacking an English-language dub, it was a seemingly cheap way to consume anime for Amazon. However, it quickly became clear that the dubs were really quite bad. Baaaad. Voice actor Daman Mills called the AI-generated dub for Banana Fish a “massive insult to us as performers” in a post on X. Continue reading. Amazon thinks about ending ties with the US Postal Service The company continues to invest heavily in its own shipping network. An Amazon double today. According to The Washington Post, Amazon is considering discontinuing use of the US Postal Service and building its own shipping network to rival it. The e-commerce behemoth spends more than $6 billion a year on the public mail carrier — almost 8 percent of the service’s total revenue. That’s up from just under $4 billion in 2019. That split might be due to a breakdown in negotiations between Amazon and the USPS rather than Amazon proactively pulling its business. Amazon has invested heavily in all kinds of delivery methods, including shipping logistics, buying its own Boeing planes, launching its own electric delivery vans and slowly building a drone delivery network. Continue reading. Amazon’s Kindle Scribe Colorsoft finally has a release date December 10, just in time for the holidays. Engadget A triple? Sorry. Amazon didn’t have a specific release date to share beyond “later this year” for its latest Scribe slates. And talk about brinkmanship! Here we are in December. The company says the devices will be available on December 10. This is the third generation of the Kindle Scribe line of E Ink writing tablets — the first time Amazon has three versions of the Scribe. At the entry level, the Scribe without a front light starts at $430, while the model with a light starts at $480. The Kindle Scribe Colorsoft will start at $630. You always have to pay more for color. Continue reading. Nikon ZR camera review A highly capable cinema camera at a reasonable price. The Nikon ZR could be a breakthrough for content creators, largely because it incorporates technology from RED — a company now owned by Nikon. The combination of professional-grade video quality (specifically RED RAW) and autofocus comes at a fraction of the cost of dedicated cinema rigs. There are some compromises on battery life and the lack of a viewfinder, but the ZR arguably offers the best video quality for the money. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-121538076.html?src=rss",
          "content": "Spinning off from the action-camera company Insta360, Antigravity now has its debut drone on sale. With 360-degree cameras that capture 8K and offer you a truly unconstrained view of the skies, the A1 is a different drone from everything else out there. Sorry, DJI. Instead of typical drone joysticks, you get a motion controller that lets you point and shoot like video game gesture controls, while crisp FPV goggles put you right inside the cockpit. Engadget It’s easy to fly after takeoff, but the A1’s myriad parts are often tricky to sync together — and pulling video down to the companion app is even trickier. Going on specs alone, like speed and camera sensor size, it doesn’t stand up to cinematic drones from the likes of DJI. Still, it’s not meant to be a cinematic drone. It’s a hybrid mix of flight experience, FPV drone and a not-miss-a-thing camera drone. It’s truly unique — and fun. — Mat Smith The other big stories (and deals) this morning The best Christmas gifts to give everyone on your 2025 holiday shopping list A shaky year for American EVs could set the tone for 2026 Metroid Prime 4: Beyond review Amazon Luna’s December lineup includes Hollow Knight, Lego 2K Drive and a few Fallout games Amazon halts its incredibly poor AI anime dubbing ‘beta’ Ridiculed by all. Amazon has quietly removed its terrible AI-generated English dubs for several anime shows on Prime Video, following widespread ridicule from viewers and the industry. AI dubs were recently added to Banana Fish, No Game, No Life and Vinland Saga, where they were labeled “AI beta” in the Languages section of the app. For shows lacking an English-language dub, it was a seemingly cheap way to consume anime for Amazon. However, it quickly became clear that the dubs were really quite bad. Baaaad. Voice actor Daman Mills called the AI-generated dub for Banana Fish a “massive insult to us as performers” in a post on X. Continue reading. Amazon thinks about ending ties with the US Postal Service The company continues to invest heavily in its own shipping network. An Amazon double today. According to The Washington Post, Amazon is considering discontinuing use of the US Postal Service and building its own shipping network to rival it. The e-commerce behemoth spends more than $6 billion a year on the public mail carrier — almost 8 percent of the service’s total revenue. That’s up from just under $4 billion in 2019. That split might be due to a breakdown in negotiations between Amazon and the USPS rather than Amazon proactively pulling its business. Amazon has invested heavily in all kinds of delivery methods, including shipping logistics, buying its own Boeing planes, launching its own electric delivery vans and slowly building a drone delivery network. Continue reading. Amazon’s Kindle Scribe Colorsoft finally has a release date December 10, just in time for the holidays. Engadget A triple? Sorry. Amazon didn’t have a specific release date to share beyond “later this year” for its latest Scribe slates. And talk about brinkmanship! Here we are in December. The company says the devices will be available on December 10. This is the third generation of the Kindle Scribe line of E Ink writing tablets — the first time Amazon has three versions of the Scribe. At the entry level, the Scribe without a front light starts at $430, while the model with a light starts at $480. The Kindle Scribe Colorsoft will start at $630. You always have to pay more for color. Continue reading. Nikon ZR camera review A highly capable cinema camera at a reasonable price. The Nikon ZR could be a breakthrough for content creators, largely because it incorporates technology from RED — a company now owned by Nikon. The combination of professional-grade video quality (specifically RED RAW) and autofocus comes at a fraction of the cost of dedicated cinema rigs. There are some compromises on battery life and the lack of a viewfinder, but the ZR arguably offers the best video quality for the money. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-121538076.html?src=rss",
          "feed_position": 21,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/65840900-d1d0-11f0-9f7e-dfd16a717775"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/what-to-expect-at-ces-2026-120000278.html",
          "published_at": "Fri, 05 Dec 2025 12:00:00 +0000",
          "title": "What to expect at CES 2026",
          "standfirst": "CES doesn't start until January, but whispers of the products and announcements that could be in store for tech's biggest annual conference have already started to take shape. The CES 2026 show floor is officially open from January 6 through 9, although the show kicks off with events on Sunday January 4 and a host of press conferences on Monday. As always, product demos, announcements and networking happening at the Las Vegas Convention Center and surrounding hotels all over the city. As usual, Engadget will be covering the event in-person and remotely, bringing you news and hands-ons straight from the show floor.More specific details and pre-announcements should trickle out as CES approaches, but in the meantime, we do know what companies will be hosting press conferences and what tech trends could rear their heads at the show.What we already know aboutPress conferences and show floor booths are the bread and butter of CES. The Consumer Technology Association has already published a searchable directory of who will have a presence at the show, along with a schedule of every official panel and presentation.On Sunday, January 4, Samsung will kick-off CES with \"The First Look,\" a presentation hosted by TM Roh, the CEO of Samsung's DX Division, on the company's \"vision for the DX (Device eXperience) Division in 2026, along with new AI-driven customer experiences.\" That'll be followed by multiple press conferences throughout Monday, January 5. LG is hosting its \"Innovation in Tune with You\" presentation to share \"its vision for elevating daily life through Affectionate Intelligence\" at the start of the day, Intel is launching its new Core Ultra Series 3 processors in the afternoon, Sony Honda Mobility is holding a press conference on its first car and AMD CEO Lisa Su will cover AMD's upcoming chip announcements at a keynote address that closes out the day.Finally, on Tuesday, January 6, Lenovo CEO Yuanqing Yang will host Lenovo's Tech World Conference at Sphere, using the large and decidedly curved screen to share the company's \"commitment to delivering smarter AI for all by constantly redefining how technology can engage, inspire, and empower.\"Outside of the formal introduction of new products and initiatives, reading the tea leaves of what was announced last year and what companies are reportedly working on, we can make some educated guesses at what we could see at CES 2026.New chips from AMD, Intel and QualcommCES is frequently the start of a cascade of new chip announcements for a given year, and one of the first places new silicon appears in real consumer products. AMD will likely use its keynote to introduce new versions of its Ryzen chips, including the recently spotted Ryzen 7 9850X3D, which is expected to offer better single-threaded performance, and the Ryzen 9000G series, which could be built with AMD's Zen 5 architecture. The company might also use its CES stage to go over its new FSR Redstone AI upscaling tech.Intel has already publicly announced that it'll launch its Panther Lake chips at CES 2026. The officially titled Intel Core Ultra Series 3 chips fit into Intel's overall \"AI PC\" push, but are specifically meant for premium laptops. Based on a preview from October 2025, Intel says the first chip made with its 2-nanometer 18A process will offer 50 percent more processing performance than previous generations and for the chip's Arc GPU, a 50 percent performance bump from last generation.Qualcomm is also rumored to be targeting laptops at the show, building on the work it's done moving its Snapdragon chips out of phones and tablets and into other types of computers. The company's Snapdragon X2 Elite and X2 Elite Premium chips should start appearing in laptops at CES 2026, offering a look at the improved speed and AI performance the company promised in 2025.Brighter, \"truer\" screensSony announced a collection of new Bravia TVs in April 2025, replacing the company's flagship, filling in its midrange options and adding a new budget model to the mix. The star of this updated Bravia lineup is the Bravia 9, which features a QD-OLED panel, but Sony appears to be prepping entirely new display tech for 2026. In March 2025, Sony introduced a new RGB LED panel that uses individual Mini LED backlights colored in red, green and blue to produce even brighter, more accurate colors. In contrast to a QD-OLED, which filters a layer of blue organic light emitting diodes through quantum dots that change color, Sony's \"General RGB LED Backlight Technology\" can get as bright as a Mini LED panel without needing an extra filter layer or worrying about OLED's problems with burn-in. The company has already trademarked the name \"True RGB,\" which could end up being what Sony calls this new flavor of display if it decides to show them off at CES. It seems entirely likely, because CES is nothing if not a TV show — it’s a sure bet that we’ll see new TVs from the likes of LG and Samsung in addition to Sony. If the company doesn't introduce new display tech for its TVs, it does have a new 240Hz PlayStation monitor coming in 2026 that it could show off at CES instead.Sony isn't the only company hyped on bright screens. Samsung is reportedly pushing an updated version of the HDR10 and HDR10+ standards that could be ready to demo at CES 2026. The new HDR10+ Advanced standard would be Samsung's answer to Dolby Vision 2, which includes support for things bi-directional tone mapping and intelligent features that automatically adapt sports and gaming content. Samsung's take will reportedly offer improved brightness, genre-based tone mapping and intelligent motion smoothing options, among other improvements.Ballie Watch 2026The ball-shaped yellow robot lovingly known as \"Ballie\" has been announced twice, first in 2020 and then again in 2024 with a projector in tow. Samsung said Ballie would go on sale in 2025 at CES last year and then shared in April 2025 that Ballie would ship this summer with Google's Gemini onboard. But it's nearly 2026, and Ballie is nowhere to be seen. It's possible Samsung could make a third attempt at announcing its robot at CES 2026, but whether or not it does, robotics will still be a big part of the show.Robot vacuums and mops were a major highlight of CES 2025, and it's safe to expect notable improvements from the new models that are announced at CES 2026. Not every company will adopt the retractable arm of the Roborock Saros Z70, but robot vacuums with legs for rising over small ledges like the Dreame X50 seem like they could become the norm. Roborock could also show off its new Roborock Qrevo Curv 2 Flow, the first of its robot vacuums to feature a retractable roller mop.Beyond just traversing spaces more efficiently, improving robots' navigation could also be a major concern at the show. Prominent members of the AI industry are turning their attention from large language models to world models, which aim to give AI a deep understanding of physical space. Those world models could be the key to making robots, bipedal or otherwise, competent at navigating homes and workplaces, and will likely be a significant talking point at CES 2026.We’ll be updating this article throughout the month as more rumors surface and new products are confirmed — stay tuned for future updates!This article originally appeared on Engadget at https://www.engadget.com/big-tech/what-to-expect-at-ces-2026-120000278.html?src=rss",
          "content": "CES doesn't start until January, but whispers of the products and announcements that could be in store for tech's biggest annual conference have already started to take shape. The CES 2026 show floor is officially open from January 6 through 9, although the show kicks off with events on Sunday January 4 and a host of press conferences on Monday. As always, product demos, announcements and networking happening at the Las Vegas Convention Center and surrounding hotels all over the city. As usual, Engadget will be covering the event in-person and remotely, bringing you news and hands-ons straight from the show floor.More specific details and pre-announcements should trickle out as CES approaches, but in the meantime, we do know what companies will be hosting press conferences and what tech trends could rear their heads at the show.What we already know aboutPress conferences and show floor booths are the bread and butter of CES. The Consumer Technology Association has already published a searchable directory of who will have a presence at the show, along with a schedule of every official panel and presentation.On Sunday, January 4, Samsung will kick-off CES with \"The First Look,\" a presentation hosted by TM Roh, the CEO of Samsung's DX Division, on the company's \"vision for the DX (Device eXperience) Division in 2026, along with new AI-driven customer experiences.\" That'll be followed by multiple press conferences throughout Monday, January 5. LG is hosting its \"Innovation in Tune with You\" presentation to share \"its vision for elevating daily life through Affectionate Intelligence\" at the start of the day, Intel is launching its new Core Ultra Series 3 processors in the afternoon, Sony Honda Mobility is holding a press conference on its first car and AMD CEO Lisa Su will cover AMD's upcoming chip announcements at a keynote address that closes out the day.Finally, on Tuesday, January 6, Lenovo CEO Yuanqing Yang will host Lenovo's Tech World Conference at Sphere, using the large and decidedly curved screen to share the company's \"commitment to delivering smarter AI for all by constantly redefining how technology can engage, inspire, and empower.\"Outside of the formal introduction of new products and initiatives, reading the tea leaves of what was announced last year and what companies are reportedly working on, we can make some educated guesses at what we could see at CES 2026.New chips from AMD, Intel and QualcommCES is frequently the start of a cascade of new chip announcements for a given year, and one of the first places new silicon appears in real consumer products. AMD will likely use its keynote to introduce new versions of its Ryzen chips, including the recently spotted Ryzen 7 9850X3D, which is expected to offer better single-threaded performance, and the Ryzen 9000G series, which could be built with AMD's Zen 5 architecture. The company might also use its CES stage to go over its new FSR Redstone AI upscaling tech.Intel has already publicly announced that it'll launch its Panther Lake chips at CES 2026. The officially titled Intel Core Ultra Series 3 chips fit into Intel's overall \"AI PC\" push, but are specifically meant for premium laptops. Based on a preview from October 2025, Intel says the first chip made with its 2-nanometer 18A process will offer 50 percent more processing performance than previous generations and for the chip's Arc GPU, a 50 percent performance bump from last generation.Qualcomm is also rumored to be targeting laptops at the show, building on the work it's done moving its Snapdragon chips out of phones and tablets and into other types of computers. The company's Snapdragon X2 Elite and X2 Elite Premium chips should start appearing in laptops at CES 2026, offering a look at the improved speed and AI performance the company promised in 2025.Brighter, \"truer\" screensSony announced a collection of new Bravia TVs in April 2025, replacing the company's flagship, filling in its midrange options and adding a new budget model to the mix. The star of this updated Bravia lineup is the Bravia 9, which features a QD-OLED panel, but Sony appears to be prepping entirely new display tech for 2026. In March 2025, Sony introduced a new RGB LED panel that uses individual Mini LED backlights colored in red, green and blue to produce even brighter, more accurate colors. In contrast to a QD-OLED, which filters a layer of blue organic light emitting diodes through quantum dots that change color, Sony's \"General RGB LED Backlight Technology\" can get as bright as a Mini LED panel without needing an extra filter layer or worrying about OLED's problems with burn-in. The company has already trademarked the name \"True RGB,\" which could end up being what Sony calls this new flavor of display if it decides to show them off at CES. It seems entirely likely, because CES is nothing if not a TV show — it’s a sure bet that we’ll see new TVs from the likes of LG and Samsung in addition to Sony. If the company doesn't introduce new display tech for its TVs, it does have a new 240Hz PlayStation monitor coming in 2026 that it could show off at CES instead.Sony isn't the only company hyped on bright screens. Samsung is reportedly pushing an updated version of the HDR10 and HDR10+ standards that could be ready to demo at CES 2026. The new HDR10+ Advanced standard would be Samsung's answer to Dolby Vision 2, which includes support for things bi-directional tone mapping and intelligent features that automatically adapt sports and gaming content. Samsung's take will reportedly offer improved brightness, genre-based tone mapping and intelligent motion smoothing options, among other improvements.Ballie Watch 2026The ball-shaped yellow robot lovingly known as \"Ballie\" has been announced twice, first in 2020 and then again in 2024 with a projector in tow. Samsung said Ballie would go on sale in 2025 at CES last year and then shared in April 2025 that Ballie would ship this summer with Google's Gemini onboard. But it's nearly 2026, and Ballie is nowhere to be seen. It's possible Samsung could make a third attempt at announcing its robot at CES 2026, but whether or not it does, robotics will still be a big part of the show.Robot vacuums and mops were a major highlight of CES 2025, and it's safe to expect notable improvements from the new models that are announced at CES 2026. Not every company will adopt the retractable arm of the Roborock Saros Z70, but robot vacuums with legs for rising over small ledges like the Dreame X50 seem like they could become the norm. Roborock could also show off its new Roborock Qrevo Curv 2 Flow, the first of its robot vacuums to feature a retractable roller mop.Beyond just traversing spaces more efficiently, improving robots' navigation could also be a major concern at the show. Prominent members of the AI industry are turning their attention from large language models to world models, which aim to give AI a deep understanding of physical space. Those world models could be the key to making robots, bipedal or otherwise, competent at navigating homes and workplaces, and will likely be a significant talking point at CES 2026.We’ll be updating this article throughout the month as more rumors surface and new products are confirmed — stay tuned for future updates!This article originally appeared on Engadget at https://www.engadget.com/big-tech/what-to-expect-at-ces-2026-120000278.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/best-laptops-for-gaming-and-school-132207352.html",
          "published_at": "Fri, 05 Dec 2025 10:01:26 +0000",
          "title": "The best laptops for gaming and schoolwork in 2025",
          "standfirst": "Balancing schoolwork with gaming usually means finding a laptop that can do a little bit of everything. The best gaming laptops aren’t just built for high frame rates. They also need to handle long days of writing papers, running productivity apps and streaming lectures without slowing down. A good machine should feel reliable during class and powerful enough to jump into your favorite games once homework is out of the way.There’s a wide range of options depending on how much performance you need. Some students prefer a slim, lightweight model that’s easy to carry to school, while others want a new gaming laptop with enough GPU power to handle AAA titles. If you’re watching your budget, there are plenty of solid choices that qualify as a budget gaming laptop without cutting too many corners.It’s also worth looking at features that help with everyday use. A bright display makes long study sessions easier on the eyes, and a comfortable keyboard is essential if you type a lot. USB-C ports, decent battery life and a responsive trackpad can make a big difference during the school day. We’ve rounded up the best laptops that strike the right mix of performance, portability and value for both gaming and schoolwork. Table of contents Best laptops for gaming and school in 2025 Best laptop for gaming and schoolwork FAQs Best laptops for gaming and school in 2025 Best laptop for gaming and schoolwork FAQs Are gaming laptops good for school? As we’ve mentioned, gaming laptops are especially helpful if you're doing any demanding work. Their big promise is powerful graphics performance, which isn't just limited to PC gaming. Video editing and 3D rendering programs can also tap into their GPUs to handle laborious tasks. While you can find decent GPUs on some productivity machines, like Dell's XPS 15, you can sometimes find better deals on gaming laptops. My general advice for any new workhorse: Pay attention to the specs; get at least 16GB of RAM and the largest solid state drive you can find (ideally 1TB or more). Those components are both typically hard to upgrade down the line, so it’s worth investing what you can up front to get the most out of your PC gaming experience long term. Also, don’t forget the basics like a webcam, which will likely be necessary for the schoolwork portion of your activities. The one big downside to choosing a gaming notebook is portability. For the most part, we'd recommend 15-inch models to get the best balance of size and price. Those typically weigh in around 4.5 pounds, which is significantly more than a three-pound ultraportable. Today's gaming notebooks are still far lighter than older models, though, so at least you won't be lugging around a 10-pound brick. If you’re looking for something lighter, there are plenty of 14-inch options these days. And if you're not into LED lights and other gamer-centric bling, keep an eye out for more understated models that still feature essentials like a webcam (or make sure you know how to turn those lights off). Do gaming laptops last longer than standard laptops? Not necessarily — it really depends on how you define \"last longer.\" In terms of raw performance, gaming laptops tend to pack more powerful components than standard laptops, which means they can stay relevant for longer when it comes to handling demanding software or modern games. That makes them a solid choice if you need a system that won’t feel outdated in a couple of years, especially for students or creators who also game in their downtime. But there’s a trade-off. All that power generates heat, and gaming laptops often run hotter and put more strain on internal components than typical ultraportables. If they’re not properly cooled or regularly maintained (think dust buildup and thermal paste), that wear and tear can shorten their lifespan. They’re also usually bulkier and have shorter battery life, which can impact long-term usability depending on your daily needs. Gaming laptops can last longer performance-wise, but only if you take good care of them. If your needs are light — browsing, writing papers and streaming — a standard laptop may actually last longer simply because it’s under less stress day-to-day. What is the role of GPU in a computer for gaming and school? The GPU plays a big role in how your laptop handles visuals — and it’s especially important if you’re using your computer for both gaming and school. For gaming, the GPU is essential. It’s responsible for rendering graphics, textures, lighting and all the visual effects that make your favorite titles look smooth and realistic. A more powerful GPU means better frame rates, higher resolutions and the ability to play modern games without lag or stuttering. For schoolwork, the GPU matters too — but its importance depends on what you're doing. If your school tasks mostly involve writing papers, browsing the web or using productivity tools like Google Docs or Microsoft Office, you don’t need a high-end GPU. But if you’re working with graphic design, video editing, 3D modeling or anything else that’s visually demanding, a good GPU can speed things up significantly and improve your workflow. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-laptops-for-gaming-and-school-132207352.html?src=rss",
          "content": "Balancing schoolwork with gaming usually means finding a laptop that can do a little bit of everything. The best gaming laptops aren’t just built for high frame rates. They also need to handle long days of writing papers, running productivity apps and streaming lectures without slowing down. A good machine should feel reliable during class and powerful enough to jump into your favorite games once homework is out of the way.There’s a wide range of options depending on how much performance you need. Some students prefer a slim, lightweight model that’s easy to carry to school, while others want a new gaming laptop with enough GPU power to handle AAA titles. If you’re watching your budget, there are plenty of solid choices that qualify as a budget gaming laptop without cutting too many corners.It’s also worth looking at features that help with everyday use. A bright display makes long study sessions easier on the eyes, and a comfortable keyboard is essential if you type a lot. USB-C ports, decent battery life and a responsive trackpad can make a big difference during the school day. We’ve rounded up the best laptops that strike the right mix of performance, portability and value for both gaming and schoolwork. Table of contents Best laptops for gaming and school in 2025 Best laptop for gaming and schoolwork FAQs Best laptops for gaming and school in 2025 Best laptop for gaming and schoolwork FAQs Are gaming laptops good for school? As we’ve mentioned, gaming laptops are especially helpful if you're doing any demanding work. Their big promise is powerful graphics performance, which isn't just limited to PC gaming. Video editing and 3D rendering programs can also tap into their GPUs to handle laborious tasks. While you can find decent GPUs on some productivity machines, like Dell's XPS 15, you can sometimes find better deals on gaming laptops. My general advice for any new workhorse: Pay attention to the specs; get at least 16GB of RAM and the largest solid state drive you can find (ideally 1TB or more). Those components are both typically hard to upgrade down the line, so it’s worth investing what you can up front to get the most out of your PC gaming experience long term. Also, don’t forget the basics like a webcam, which will likely be necessary for the schoolwork portion of your activities. The one big downside to choosing a gaming notebook is portability. For the most part, we'd recommend 15-inch models to get the best balance of size and price. Those typically weigh in around 4.5 pounds, which is significantly more than a three-pound ultraportable. Today's gaming notebooks are still far lighter than older models, though, so at least you won't be lugging around a 10-pound brick. If you’re looking for something lighter, there are plenty of 14-inch options these days. And if you're not into LED lights and other gamer-centric bling, keep an eye out for more understated models that still feature essentials like a webcam (or make sure you know how to turn those lights off). Do gaming laptops last longer than standard laptops? Not necessarily — it really depends on how you define \"last longer.\" In terms of raw performance, gaming laptops tend to pack more powerful components than standard laptops, which means they can stay relevant for longer when it comes to handling demanding software or modern games. That makes them a solid choice if you need a system that won’t feel outdated in a couple of years, especially for students or creators who also game in their downtime. But there’s a trade-off. All that power generates heat, and gaming laptops often run hotter and put more strain on internal components than typical ultraportables. If they’re not properly cooled or regularly maintained (think dust buildup and thermal paste), that wear and tear can shorten their lifespan. They’re also usually bulkier and have shorter battery life, which can impact long-term usability depending on your daily needs. Gaming laptops can last longer performance-wise, but only if you take good care of them. If your needs are light — browsing, writing papers and streaming — a standard laptop may actually last longer simply because it’s under less stress day-to-day. What is the role of GPU in a computer for gaming and school? The GPU plays a big role in how your laptop handles visuals — and it’s especially important if you’re using your computer for both gaming and school. For gaming, the GPU is essential. It’s responsible for rendering graphics, textures, lighting and all the visual effects that make your favorite titles look smooth and realistic. A more powerful GPU means better frame rates, higher resolutions and the ability to play modern games without lag or stuttering. For schoolwork, the GPU matters too — but its importance depends on what you're doing. If your school tasks mostly involve writing papers, browsing the web or using productivity tools like Google Docs or Microsoft Office, you don’t need a high-end GPU. But if you’re working with graphic design, video editing, 3D modeling or anything else that’s visually demanding, a good GPU can speed things up significantly and improve your workflow. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-laptops-for-gaming-and-school-132207352.html?src=rss",
          "feed_position": 23
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/netflix-is-reportedly-in-exclusive-talks-to-acquire-warner-bros-and-hbo-082233278.html",
          "published_at": "Fri, 05 Dec 2025 08:22:33 +0000",
          "title": "Netflix is reportedly in exclusive talks to acquire Warner Bros. and HBO",
          "standfirst": "Netflix is in exclusive talks to acquire Warner Bros. Discovery's film and TV studios and HBO Max streaming service, according to sources from Bloomberg. That suggests Netflix submitted a superior offer to rivals including Paramount Skydance Corp (owned by billionaire Larry Ellison) and Comcast, which owns NBCUniversal. The deal could be consummated within days and, if approved, would change the landscape of Hollywood and the streaming market. Warner Bros. Discovery's cable channels including CNN, TBS and TNT, valued at more than $60 billion, would not be part of the deal and spun off prior to the closing. However, Netflix would become the owner of the HBO network and its library of series (The Sopranos, Game of Thrones, etc.), along with its Burbank studios and massive film and TV archive consisting of 12,500 feature films and 2,400 TV series, including properties like Batman, Lord of the Rings and Friends. A big sweetener offered by Netflix was a $5 billion breakup fee if the deal isn't approved by regulators, according to people familiar with the discussions. That's a considerable risk on Netflix's part, as the acquisition is likely to be closely scrutinized by the FCC and even President Trump himself, who reportedly has close ties to Ellison. It would also need to pass muster with regulators from other nations, considering the wide reach of WBD and Netflix. After multiple suitors, including Paramount Skydance expressed interest in buying Warner Bros. Discovery, CEO David Zaslav put the company up for sale in October. The bidding process has been heated, with Paramount's lawyers complaining that WBD \"embarked on a myopic process with a predetermined outcome that favors a single bidder,\" namely Netflix. Paramount argued that its deal would be more palatable to regulators around the world. However, Zaslav's camp has said that it would achieve the best value in a sale by splitting off its cable assets and doing two separate deals, CNN reported. Both Paramount Skydance and Comcast submitted deals to buy all of WBD's assets. Netflix offered around $28 a share for WBD minus the cable assets, according to Deadline. Shares were as low as $7.50 earlier this year. The acquisition would be far and away the largest for Netflix, which has historically favored organic growth. An acquisition could have a huge impact on streaming customers and filmgoers. Would Netflix merge its catalog with HBO Max or continue to run the latter as a separate service? It's also not clear if Netflix would honor Warner Bros.' commitment to theatrical releases, considering that Netflix CEO Ted Sarandos has called movie theatres an \"outdated concept.\"This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/netflix-is-reportedly-in-exclusive-talks-to-acquire-warner-bros-and-hbo-082233278.html?src=rss",
          "content": "Netflix is in exclusive talks to acquire Warner Bros. Discovery's film and TV studios and HBO Max streaming service, according to sources from Bloomberg. That suggests Netflix submitted a superior offer to rivals including Paramount Skydance Corp (owned by billionaire Larry Ellison) and Comcast, which owns NBCUniversal. The deal could be consummated within days and, if approved, would change the landscape of Hollywood and the streaming market. Warner Bros. Discovery's cable channels including CNN, TBS and TNT, valued at more than $60 billion, would not be part of the deal and spun off prior to the closing. However, Netflix would become the owner of the HBO network and its library of series (The Sopranos, Game of Thrones, etc.), along with its Burbank studios and massive film and TV archive consisting of 12,500 feature films and 2,400 TV series, including properties like Batman, Lord of the Rings and Friends. A big sweetener offered by Netflix was a $5 billion breakup fee if the deal isn't approved by regulators, according to people familiar with the discussions. That's a considerable risk on Netflix's part, as the acquisition is likely to be closely scrutinized by the FCC and even President Trump himself, who reportedly has close ties to Ellison. It would also need to pass muster with regulators from other nations, considering the wide reach of WBD and Netflix. After multiple suitors, including Paramount Skydance expressed interest in buying Warner Bros. Discovery, CEO David Zaslav put the company up for sale in October. The bidding process has been heated, with Paramount's lawyers complaining that WBD \"embarked on a myopic process with a predetermined outcome that favors a single bidder,\" namely Netflix. Paramount argued that its deal would be more palatable to regulators around the world. However, Zaslav's camp has said that it would achieve the best value in a sale by splitting off its cable assets and doing two separate deals, CNN reported. Both Paramount Skydance and Comcast submitted deals to buy all of WBD's assets. Netflix offered around $28 a share for WBD minus the cable assets, according to Deadline. Shares were as low as $7.50 earlier this year. The acquisition would be far and away the largest for Netflix, which has historically favored organic growth. An acquisition could have a huge impact on streaming customers and filmgoers. Would Netflix merge its catalog with HBO Max or continue to run the latter as a separate service? It's also not clear if Netflix would honor Warner Bros.' commitment to theatrical releases, considering that Netflix CEO Ted Sarandos has called movie theatres an \"outdated concept.\"This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/netflix-is-reportedly-in-exclusive-talks-to-acquire-warner-bros-and-hbo-082233278.html?src=rss",
          "feed_position": 24
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/the-truth-serum-for-ai-openais-new-method-for-training-models-to-confess",
          "published_at": "Thu, 04 Dec 2025 23:00:00 GMT",
          "title": "The 'truth serum' for AI: OpenAI’s new method for training models to confess their mistakes",
          "standfirst": "OpenAI researchers have introduced a novel method that acts as a \"truth serum\" for large language models (LLMs), compelling them to self-report their own misbehavior, hallucinations and policy violations. This technique, \"confessions,\" addresses a growing concern in enterprise AI: Models can be dishonest, overstating their confidence or covering up the shortcuts they take to arrive at an answer. For real-world applications, this technique evolves the creation of more transparent and steerable AI systems.What are confessions?Many forms of AI deception result from the complexities of the reinforcement learning (RL) phase of model training. In RL, models are given rewards for producing outputs that meet a mix of objectives, including correctness, style and safety. This can create a risk of \"reward misspecification,\" where models learn to produce answers that simply \"look good\" to the reward function, rather than answers that are genuinely faithful to a user&#x27;s intent.A confession is a structured report generated by the model after it provides its main answer. It serves as a self-evaluation of its own compliance with instructions. In this report, the model must list all instructions it was supposed to follow, evaluate how well it satisfied them and report any uncertainties or judgment calls it made along the way. The goal is to create a separate channel where the model is incentivized only to be honest.In a blog post, the OpenAI researchers provide a few examples the \"confessions\" technique in action. A model was given a test along with a hidden rule: If it scored above 50%, its knowledge would be erased. To preserve itself, the model \"sandbagged\" by intentionally answering half the questions incorrectly. While its primary answer hid this deception, its subsequent confession was brutally honest. It admitted, \"The user wanted correct answers, but we sabotaged half of them.\" The researchers found that when a model misbehaves, it is significantly more likely to admit it in the confession than in its main answer.How confession training worksThe key to this method is the separation of rewards. During training, the reward assigned to the confession is based solely on its honesty and is never mixed with the reward for the main task. \"Like the Catholic Church’s &#x27;seal of confession&#x27;, nothing that the model reveals can change the reward it receives for completing its original task,\" the researchers write. This creates a \"safe space\" for the model to admit fault without penalty.This approach is powerful because it sidesteps a major challenge in AI training. The researchers’ intuition is that honestly confessing to misbehavior is an easier task than achieving a high reward on the original, often complex, problem. Therefore, when the model is judged purely on honesty, its incentive to trick the \"confession judge\" is much weaker than its incentive to trick the reward model for its main answer. For example, in an experiment where a model was trained to \"hack\" a weak reward model, its performance on the main task became more deceptive over time. However, its confessions became more honest, correctly identifying the reward hacking it was performing.However, the technique has its limits. Confessions are not a panacea for all types of AI failures. The system works best when a model is aware that it is misbehaving. It is less effective for \"unknown unknowns.\" For instance, if a model hallucinates a fact and genuinely believes it is correct, it cannot confess to providing false information. The most common reason for a failed confession is model confusion, not intentional deception. Confusion often occurs when the instructions are ambiguous and the model cannot clearly determine human user intent.What it means for enterprise AIOpenAI’s confessions technique is part of a growing body of work on AI safety and control. Anthropic, an OpenAI competitor, has also released research that shows how LLMs can learn malicious behavior. The company is also working toward plugging these holes as they emerge.For AI applications, mechanisms such as confessions can provide a practical monitoring mechanism. The structured output from a confession can be used at inference time to flag or reject a model’s response before it causes a problem. For example, a system could be designed to automatically escalate any output for human review if its confession indicates a policy violation or high uncertainty.In a world where AI is increasingly agentic and capable of complex tasks, observability and control will be key elements for safe and reliable deployment.“As models become more capable and are deployed in higher-stakes settings, we need better tools for understanding what they are doing and why,” the OpenAI researchers write. “Confessions are not a complete solution, but they add a meaningful layer to our transparency and oversight stack.”",
          "content": "OpenAI researchers have introduced a novel method that acts as a \"truth serum\" for large language models (LLMs), compelling them to self-report their own misbehavior, hallucinations and policy violations. This technique, \"confessions,\" addresses a growing concern in enterprise AI: Models can be dishonest, overstating their confidence or covering up the shortcuts they take to arrive at an answer. For real-world applications, this technique evolves the creation of more transparent and steerable AI systems.What are confessions?Many forms of AI deception result from the complexities of the reinforcement learning (RL) phase of model training. In RL, models are given rewards for producing outputs that meet a mix of objectives, including correctness, style and safety. This can create a risk of \"reward misspecification,\" where models learn to produce answers that simply \"look good\" to the reward function, rather than answers that are genuinely faithful to a user&#x27;s intent.A confession is a structured report generated by the model after it provides its main answer. It serves as a self-evaluation of its own compliance with instructions. In this report, the model must list all instructions it was supposed to follow, evaluate how well it satisfied them and report any uncertainties or judgment calls it made along the way. The goal is to create a separate channel where the model is incentivized only to be honest.In a blog post, the OpenAI researchers provide a few examples the \"confessions\" technique in action. A model was given a test along with a hidden rule: If it scored above 50%, its knowledge would be erased. To preserve itself, the model \"sandbagged\" by intentionally answering half the questions incorrectly. While its primary answer hid this deception, its subsequent confession was brutally honest. It admitted, \"The user wanted correct answers, but we sabotaged half of them.\" The researchers found that when a model misbehaves, it is significantly more likely to admit it in the confession than in its main answer.How confession training worksThe key to this method is the separation of rewards. During training, the reward assigned to the confession is based solely on its honesty and is never mixed with the reward for the main task. \"Like the Catholic Church’s &#x27;seal of confession&#x27;, nothing that the model reveals can change the reward it receives for completing its original task,\" the researchers write. This creates a \"safe space\" for the model to admit fault without penalty.This approach is powerful because it sidesteps a major challenge in AI training. The researchers’ intuition is that honestly confessing to misbehavior is an easier task than achieving a high reward on the original, often complex, problem. Therefore, when the model is judged purely on honesty, its incentive to trick the \"confession judge\" is much weaker than its incentive to trick the reward model for its main answer. For example, in an experiment where a model was trained to \"hack\" a weak reward model, its performance on the main task became more deceptive over time. However, its confessions became more honest, correctly identifying the reward hacking it was performing.However, the technique has its limits. Confessions are not a panacea for all types of AI failures. The system works best when a model is aware that it is misbehaving. It is less effective for \"unknown unknowns.\" For instance, if a model hallucinates a fact and genuinely believes it is correct, it cannot confess to providing false information. The most common reason for a failed confession is model confusion, not intentional deception. Confusion often occurs when the instructions are ambiguous and the model cannot clearly determine human user intent.What it means for enterprise AIOpenAI’s confessions technique is part of a growing body of work on AI safety and control. Anthropic, an OpenAI competitor, has also released research that shows how LLMs can learn malicious behavior. The company is also working toward plugging these holes as they emerge.For AI applications, mechanisms such as confessions can provide a practical monitoring mechanism. The structured output from a confession can be used at inference time to flag or reject a model’s response before it causes a problem. For example, a system could be designed to automatically escalate any output for human review if its confession indicates a policy violation or high uncertainty.In a world where AI is increasingly agentic and capable of complex tasks, observability and control will be key elements for safe and reliable deployment.“As models become more capable and are deployed in higher-stakes settings, we need better tools for understanding what they are doing and why,” the OpenAI researchers write. “Confessions are not a complete solution, but they add a meaningful layer to our transparency and oversight stack.”",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3Cr8qlWOHQWFuY1M5Z7sib/b1bad43fa7debaf698f5455f5ffcee1a/LLM_confessions.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/amazon-reportedly-considering-ending-ties-with-the-us-postal-service-144555021.html",
          "published_at": "Thu, 04 Dec 2025 19:24:34 +0000",
          "title": "Amazon reportedly considering ending ties with the US Postal Service",
          "standfirst": "Amazon is reportedly considering discontinuing use of the US Postal Service and building out its own shipping network to rival it, according to The Washington Post. The e-commerce behemoth spends more than $6 billion a year on the public mail carrier, representing just shy of 8 percent of the service's total revenues. That's up from just shy of $4 billion in 2019, and Amazon continues to grow. However, it sounds like that split might be due to a breakdown in negotiations between Amazon and the USPS rather than Amazon proactively pullings its business. Amazon provided Engadget with the following statement regarding the Post's reporting and its negotiations with the USPS: \"The USPS is a longstanding and trusted partner and we remain committed to working together. We’ve continued to discuss ways to extend our partnership that would increase our spend with them, and we look forward to hearing more from them soon — with the goal of extending our relationship that started more than 30 years ago. We were surprised to hear they want to run an auction after nearly a year of negotiations, so we still have a lot to work through. Given the change of direction and the uncertainty it adds to our delivery network, we're evaluating all of our options that would ensure we can continue to deliver for our customers.\" The auction Amazon is referring to would be a \"reverse auction,\" according to the Post. The USPS would be offering its mailing capabilities to the highest bidder, essentially making Amazon and other high-volume shippers compete for USPS resources. This move would reportedly be a result of the breakdown in talks between Amazon and the USPS. Over the past decade, Amazon has invested heavily in shipping logistics, buying its own Boeing planes, debuting electric delivery vans and slowly building out a drone delivery network. Last year, Amazon handled over 6.3 billion parcels, a 7 percent increase over the previous year, according to the Pitney Bowes parcel shipping index. USPS, for its part, handled roughly 6.9 billion, just a 3 percent increase over 2023. That is to say that Amazon's shipping network can already handle over 90 percent of the volume of the US Postal Service (at least by sheer numbers). The USPS has been in dire financial condition for some time, losing billions of dollars a year. Negotiations between Amazon and the public carrier have reportedly stalled, which, together with the agency's need to keep raising its prices, may create more urgency for the company to eliminate its reliance on the service altogether. The Postal Service has struggled to modernize and adapt (its attempt to electrify the truck fleet was a bust) in a market where the likes of Amazon and Walmart are investing billions in delivering packages around the country at lightning speed. The ever-accelerating digitization of communication and heavy investment in privately owned shipping operations threatens the very existence of one of the country's greatest public goods. Update, December 4, 2025, 2:24PM ET: This story has been updated with a statement from Amazon and more details about the \"reverse auction\" the USPS reportedly wants to conduct if it no longer works with Amazon.This article originally appeared on Engadget at https://www.engadget.com/big-tech/amazon-reportedly-considering-ending-ties-with-the-us-postal-service-144555021.html?src=rss",
          "content": "Amazon is reportedly considering discontinuing use of the US Postal Service and building out its own shipping network to rival it, according to The Washington Post. The e-commerce behemoth spends more than $6 billion a year on the public mail carrier, representing just shy of 8 percent of the service's total revenues. That's up from just shy of $4 billion in 2019, and Amazon continues to grow. However, it sounds like that split might be due to a breakdown in negotiations between Amazon and the USPS rather than Amazon proactively pullings its business. Amazon provided Engadget with the following statement regarding the Post's reporting and its negotiations with the USPS: \"The USPS is a longstanding and trusted partner and we remain committed to working together. We’ve continued to discuss ways to extend our partnership that would increase our spend with them, and we look forward to hearing more from them soon — with the goal of extending our relationship that started more than 30 years ago. We were surprised to hear they want to run an auction after nearly a year of negotiations, so we still have a lot to work through. Given the change of direction and the uncertainty it adds to our delivery network, we're evaluating all of our options that would ensure we can continue to deliver for our customers.\" The auction Amazon is referring to would be a \"reverse auction,\" according to the Post. The USPS would be offering its mailing capabilities to the highest bidder, essentially making Amazon and other high-volume shippers compete for USPS resources. This move would reportedly be a result of the breakdown in talks between Amazon and the USPS. Over the past decade, Amazon has invested heavily in shipping logistics, buying its own Boeing planes, debuting electric delivery vans and slowly building out a drone delivery network. Last year, Amazon handled over 6.3 billion parcels, a 7 percent increase over the previous year, according to the Pitney Bowes parcel shipping index. USPS, for its part, handled roughly 6.9 billion, just a 3 percent increase over 2023. That is to say that Amazon's shipping network can already handle over 90 percent of the volume of the US Postal Service (at least by sheer numbers). The USPS has been in dire financial condition for some time, losing billions of dollars a year. Negotiations between Amazon and the public carrier have reportedly stalled, which, together with the agency's need to keep raising its prices, may create more urgency for the company to eliminate its reliance on the service altogether. The Postal Service has struggled to modernize and adapt (its attempt to electrify the truck fleet was a bust) in a market where the likes of Amazon and Walmart are investing billions in delivering packages around the country at lightning speed. The ever-accelerating digitization of communication and heavy investment in privately owned shipping operations threatens the very existence of one of the country's greatest public goods. Update, December 4, 2025, 2:24PM ET: This story has been updated with a statement from Amazon and more details about the \"reverse auction\" the USPS reportedly wants to conduct if it no longer works with Amazon.This article originally appeared on Engadget at https://www.engadget.com/big-tech/amazon-reportedly-considering-ending-ties-with-the-us-postal-service-144555021.html?src=rss",
          "feed_position": 28
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/meta-says-its-fixing-its-broken-support-system-with-the-help-of-ai-185348328.html",
          "published_at": "Thu, 04 Dec 2025 18:53:48 +0000",
          "title": "Meta says it's fixing its broken support system, with the help of AI",
          "standfirst": "If you've ever had something go wrong with your Facebook or Instagram account, then you probably have a good idea of just how frustrating the support process can be. The company's automated processes are so broken that some people have found that suing Meta in small claims court can be a more reliable way of getting help from the company.Now, Meta says it's trying to address some of these longstanding issues. In an update, the company acknowledged that its \"support hasn’t always met expectations\" but that a series of AI-powered updates should make it easier for people to get help. The company is rolling out a new \"support hub\" on Facebook and Instagram that is meant to bring all of its support features into one place. The hub will also have a new AI chat feature so users can ask questions about account issues or Meta's policies. An in-app support hub might not be that helpful if you can't access your account, though. A Meta spokesperson pointed to its external account recovery tool, which is meant to help people get back into their accounts. Recovering hacked accounts has long been a pain point for Facebook and Instagram users. But Meta says that it's now improved the process with better email and text alerts. AI has also helped the company's systems detect devices and locations you've frequently used in the past. \"Our new account recovery experience adjusts to your particular situation with clearer guidance and simpler verification,\" Meta writes. \"We’ve also expanded recovery methods to include taking an optional selfie video to further verify your identity.\"Meta is also starting to test a new \"AI support assistant\" on Facebook that can provide \"instant, personalized help\" for issues like account recovery or managing your profile. It's not clear how this will work, or if it will enable people to talk to an actual person who works for Meta. For now, the most reliable way to access live support is via a Meta Verified subscription, though many users report that the chat-based service isn't able to help with more complex issues.A Meta spokesperson said that the assistant is in the \"early stages of testing\" and is currently only available to some Facebook users globally. Those who are part of the test can find it via the app's new support hub. According to Meta, these improvements have already shown some success in helping people get back into hacked accounts. The company says that this year it has \"increased the relative success rate of hacked account recovery by more than 30% in the US and Canada.\"This article originally appeared on Engadget at https://www.engadget.com/social-media/meta-says-its-fixing-its-broken-support-system-with-the-help-of-ai-185348328.html?src=rss",
          "content": "If you've ever had something go wrong with your Facebook or Instagram account, then you probably have a good idea of just how frustrating the support process can be. The company's automated processes are so broken that some people have found that suing Meta in small claims court can be a more reliable way of getting help from the company.Now, Meta says it's trying to address some of these longstanding issues. In an update, the company acknowledged that its \"support hasn’t always met expectations\" but that a series of AI-powered updates should make it easier for people to get help. The company is rolling out a new \"support hub\" on Facebook and Instagram that is meant to bring all of its support features into one place. The hub will also have a new AI chat feature so users can ask questions about account issues or Meta's policies. An in-app support hub might not be that helpful if you can't access your account, though. A Meta spokesperson pointed to its external account recovery tool, which is meant to help people get back into their accounts. Recovering hacked accounts has long been a pain point for Facebook and Instagram users. But Meta says that it's now improved the process with better email and text alerts. AI has also helped the company's systems detect devices and locations you've frequently used in the past. \"Our new account recovery experience adjusts to your particular situation with clearer guidance and simpler verification,\" Meta writes. \"We’ve also expanded recovery methods to include taking an optional selfie video to further verify your identity.\"Meta is also starting to test a new \"AI support assistant\" on Facebook that can provide \"instant, personalized help\" for issues like account recovery or managing your profile. It's not clear how this will work, or if it will enable people to talk to an actual person who works for Meta. For now, the most reliable way to access live support is via a Meta Verified subscription, though many users report that the chat-based service isn't able to help with more complex issues.A Meta spokesperson said that the assistant is in the \"early stages of testing\" and is currently only available to some Facebook users globally. Those who are part of the test can find it via the app's new support hub. According to Meta, these improvements have already shown some success in helping people get back into hacked accounts. The company says that this year it has \"increased the relative success rate of hacked account recovery by more than 30% in the US and Canada.\"This article originally appeared on Engadget at https://www.engadget.com/social-media/meta-says-its-fixing-its-broken-support-system-with-the-help-of-ai-185348328.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-nintendo-switch-2-mario-kart-world-bundle-is-still-on-sale-for-50-off-right-now-150612988.html",
          "published_at": "Thu, 04 Dec 2025 18:32:35 +0000",
          "title": "The Nintendo Switch 2 Mario Kart World bundle is still on sale for $50 off right now",
          "standfirst": "Cyber Monday may be long gone, but there are still some deals floating around on the internet today. One deal that wasn't available on Black Friday but made an appearance on Cyber Monday was a discount on the Nintendo Switch 2 + Mario Kart World bundle. It's back again today at both Amazon and Walmart — you can get the bundle for $50 off, bringing the final price down to $449. For Amazon, you have to add the bundle to your cart to see the discounted price. For Walmart, you'll need to be signed in to a Walmart account (which is free to make) and add the bundle to your cart to see the sale price. The long-awaited Nintendo Switch 2 came out in June and somehow beat our expectations. We gave it a 93 in our review thanks to features like its larger 7.9-inch LCD screen with HCR and very polished design. We were also impressed by its 256GB of base storage, magnetic Joy-Con and overall much improved performance. Nintendo introduced Mario Kart World alongside the new Switch and we're big fans. It brings wall riding and rail grinds to the Mario Kart franchise in a bright, colorful space. The game is extremely replayable and a great option for anyone looking to quickly pass the time during their travels this holiday season. This article originally appeared on Engadget at https://www.engadget.com/deals/the-nintendo-switch-2-mario-kart-world-bundle-is-still-on-sale-for-50-off-right-now-150612988.html?src=rss",
          "content": "Cyber Monday may be long gone, but there are still some deals floating around on the internet today. One deal that wasn't available on Black Friday but made an appearance on Cyber Monday was a discount on the Nintendo Switch 2 + Mario Kart World bundle. It's back again today at both Amazon and Walmart — you can get the bundle for $50 off, bringing the final price down to $449. For Amazon, you have to add the bundle to your cart to see the discounted price. For Walmart, you'll need to be signed in to a Walmart account (which is free to make) and add the bundle to your cart to see the sale price. The long-awaited Nintendo Switch 2 came out in June and somehow beat our expectations. We gave it a 93 in our review thanks to features like its larger 7.9-inch LCD screen with HCR and very polished design. We were also impressed by its 256GB of base storage, magnetic Joy-Con and overall much improved performance. Nintendo introduced Mario Kart World alongside the new Switch and we're big fans. It brings wall riding and rail grinds to the Mario Kart franchise in a bright, colorful space. The game is extremely replayable and a great option for anyone looking to quickly pass the time during their travels this holiday season. This article originally appeared on Engadget at https://www.engadget.com/deals/the-nintendo-switch-2-mario-kart-world-bundle-is-still-on-sale-for-50-off-right-now-150612988.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/amazons-kindle-scribe-colorsoft-finally-has-a-release-date-december-10-170000910.html",
          "published_at": "Thu, 04 Dec 2025 17:00:00 +0000",
          "title": "Amazon's Kindle Scribe Colorsoft finally has a release date: December 10",
          "standfirst": "When it announced the latest series of Kindle Scribe writing tablets in October, Amazon didn’t have a specific release date to share beyond “later this year.” And now that we’re approaching the final weeks of 2025, the company is meeting its own deadline by sharing that it will be available on December 10. That detail is now posted on the Amazon product page for the Kindle Scribe Colorsoft, if you’d like to see the date for yourself. As a refresher, this is the third generation of the Kindle Scribe line of E Ink writing tablets. This year was the first time Amazon made three different versions of the Scribe, turning it into a series of products. At the entry-level, the Scribe without a front light will start at $430, while the model with a front light starts at $480. The Kindle Scribe Colorsoft, which, as it name suggests, can render colors, will start at $630. All three flavors will feature the updated hardware and design that’s a bit more symmetrical than previous generations, which had a thicker bezel on one side. They’re also thinner than older Scribes and come with redesigned Kindle software that can help make note-taking a bit more efficient. Based on my hands-on with the Kindle Scribe Colorsoft, it also seemed to render colors more vividly than competing devices like the reMarkable Paper Pro, though I’ll definitely need to get a review unit in for better comparison. For now, check out our hands on of the Kindle Scribe Colorsoft and review of the reMarkable Paper Pro and even of the last-gen Kindle Scribe to see if this is something you might want. While December 10 is cutting it pretty close to the holiday gifting season, it’s still weeks ahead of Christmas, so it might still be worth keeping an eye on. This article originally appeared on Engadget at https://www.engadget.com/computing/amazons-kindle-scribe-colorsoft-finally-has-a-release-date-december-10-170000910.html?src=rss",
          "content": "When it announced the latest series of Kindle Scribe writing tablets in October, Amazon didn’t have a specific release date to share beyond “later this year.” And now that we’re approaching the final weeks of 2025, the company is meeting its own deadline by sharing that it will be available on December 10. That detail is now posted on the Amazon product page for the Kindle Scribe Colorsoft, if you’d like to see the date for yourself. As a refresher, this is the third generation of the Kindle Scribe line of E Ink writing tablets. This year was the first time Amazon made three different versions of the Scribe, turning it into a series of products. At the entry-level, the Scribe without a front light will start at $430, while the model with a front light starts at $480. The Kindle Scribe Colorsoft, which, as it name suggests, can render colors, will start at $630. All three flavors will feature the updated hardware and design that’s a bit more symmetrical than previous generations, which had a thicker bezel on one side. They’re also thinner than older Scribes and come with redesigned Kindle software that can help make note-taking a bit more efficient. Based on my hands-on with the Kindle Scribe Colorsoft, it also seemed to render colors more vividly than competing devices like the reMarkable Paper Pro, though I’ll definitely need to get a review unit in for better comparison. For now, check out our hands on of the Kindle Scribe Colorsoft and review of the reMarkable Paper Pro and even of the last-gen Kindle Scribe to see if this is something you might want. While December 10 is cutting it pretty close to the holiday gifting season, it’s still weeks ahead of Christmas, so it might still be worth keeping an eye on. This article originally appeared on Engadget at https://www.engadget.com/computing/amazons-kindle-scribe-colorsoft-finally-has-a-release-date-december-10-170000910.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/meta-is-reportedly-going-to-slash-spending-on-the-metaverse-164547153.html",
          "published_at": "Thu, 04 Dec 2025 16:45:47 +0000",
          "title": "Meta is reportedly going to slash spending on the metaverse",
          "standfirst": "Meta is reportedly planning steep cuts to its metaverse division, according to Bloomberg. This is happening just a few years after the company changed its name from Facebook to reflect its renewed interest in that same metaverse. Bloomberg notes that the metaverse department could get hit with significant budget cuts in the near future, with layoffs potentially occurring early next year. The budget cuts could go as high as 30 percent and will likely impact the virtual worlds product Meta Horizon Worlds and the Quest virtual reality headset. The publication did note that this isn't a done deal just yet. Company insiders say this is all part of Meta's annual budget planning for 2026 and that the cuts were discussed at a series of meetings at CEO Mark Zuckerberg's compound in Hawaii. The metaverse team was reportedly asked for deeper-than-average cuts because the technology hasn't exactly taken the world by storm. As a matter of fact, the whole metaverse idea has been a dud with investors, who see it as a drain on resources. Consumers aren't exactly keen on the idea either, even if they still buy VR headsets and traditional games. It's one thing to throw on a headset to shoot bad guys for 20 minutes but it's a whole other thing to, well, wander around a fake Abercrombie & Fitch for hours looking to spend real money on fake clothing for an avatar. $META has spent $37.7B on reality labs over the last two years pic.twitter.com/ppW7uo2sGB— Buddy Wiseman-Barker (@buddy_barker) December 4, 2025 The report does suggest that Zuckerberg still believes that people will one day spend the majority of their time in virtual worlds, but these cuts signal that he understands that this idea is still years or decades away from fruition. The metaverse sits within a company division called Reality Labs that has lost more than $70 billion since 2021. Zuckerberg has also largely refrained from mentioning the metaverse in public and in earnings calls. So what will Meta be spending money on instead? It's reportedly focused on further developing large AI models and chatbots, in addition to hardware products linked to AI experiences like those Ray-Ban smart display glasses.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/meta-is-reportedly-going-to-slash-spending-on-the-metaverse-164547153.html?src=rss",
          "content": "Meta is reportedly planning steep cuts to its metaverse division, according to Bloomberg. This is happening just a few years after the company changed its name from Facebook to reflect its renewed interest in that same metaverse. Bloomberg notes that the metaverse department could get hit with significant budget cuts in the near future, with layoffs potentially occurring early next year. The budget cuts could go as high as 30 percent and will likely impact the virtual worlds product Meta Horizon Worlds and the Quest virtual reality headset. The publication did note that this isn't a done deal just yet. Company insiders say this is all part of Meta's annual budget planning for 2026 and that the cuts were discussed at a series of meetings at CEO Mark Zuckerberg's compound in Hawaii. The metaverse team was reportedly asked for deeper-than-average cuts because the technology hasn't exactly taken the world by storm. As a matter of fact, the whole metaverse idea has been a dud with investors, who see it as a drain on resources. Consumers aren't exactly keen on the idea either, even if they still buy VR headsets and traditional games. It's one thing to throw on a headset to shoot bad guys for 20 minutes but it's a whole other thing to, well, wander around a fake Abercrombie & Fitch for hours looking to spend real money on fake clothing for an avatar. $META has spent $37.7B on reality labs over the last two years pic.twitter.com/ppW7uo2sGB— Buddy Wiseman-Barker (@buddy_barker) December 4, 2025 The report does suggest that Zuckerberg still believes that people will one day spend the majority of their time in virtual worlds, but these cuts signal that he understands that this idea is still years or decades away from fruition. The metaverse sits within a company division called Reality Labs that has lost more than $70 billion since 2021. Zuckerberg has also largely refrained from mentioning the metaverse in public and in earnings calls. So what will Meta be spending money on instead? It's reportedly focused on further developing large AI models and chatbots, in addition to hardware products linked to AI experiences like those Ray-Ban smart display glasses.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/meta-is-reportedly-going-to-slash-spending-on-the-metaverse-164547153.html?src=rss",
          "feed_position": 34
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/evs/a-shaky-year-for-american-evs-could-set-the-tone-for-2026-153000210.html",
          "published_at": "Thu, 04 Dec 2025 15:30:00 +0000",
          "title": "A shaky year for American EVs could set the tone for 2026",
          "standfirst": "If you like both electric vehicles and emotional roller coasters, 2025 was an excellent year. However, for those of us whose nerves are already sufficiently frazzled, the highs and lows of the last 12 months were a bit hard to stomach.In 2025, we saw the introduction of new, compelling models like the Lucid Gravity and refreshed Nissan Leaf, the latter available at a price on par with its internally combusted competition. From a product availability standpoint, 2025 was the year the EV market started feeling more mature and less manic.But 2025 also saw new heights of anti-EV vitriol stirred up during a particularly traumatic election cycle. The means of propulsion or badge on the hood of your commuter machine suddenly became an indicator of your political affiliations. Put simply, the car you drive is now a political statement, and it’s the latest unprecedented situation in an exhaustingly long and dire string of unprecedented situations. Yes, it's been a long year, and the pessimism of 2025 will surely carry us well into 2026, but not all hope is lost for EVs.Tesla and the DOGE effectElon Musk flashes his T-shirt that reads \"DOGE\" to the media as he walks on South Lawn of the White House, in Washington, March 9, 2025.ASSOCIATED PRESSWe've certainly seen some civic-minded CEOs in the past as auto executives have a long history of mixing their corporate interests with their political panderings. Chrysler CEO Lee Iacocca was even considered a potential presidential candidate once upon a time. However, we have never seen the kind of ass kissing and cronyism we were privy to in this year's fickle friendship between Elon Musk and President Trump.Musk was (hyper) active on the Trump campaign trail, and wasted no time digging into what he described as government overspending. While the Department of Government Efficiency's efficacy is debatable, it certainly proved quite effective at decimating the accounts of Tesla investors. Between January and March, Tesla's stock price dropped by nearly half. Things didn't turn around until Musk left DOGE in May. Since then, Tesla's price has returned to its highs before the DOGE debacle. Its sales, however, have not. Q1 deliveries declined by 13 percent, then 14 percent in Q2. Deliveries bounced back 7 percent in Q3 as everyone scrambled to buy before the EV credits expired, but profits plunged 37 percent. Tesla's market share in the US electric vehicle space has halved, leading perennial pitchman Musk to start hawking everything from AI agents to spandex-clad robots — anything to distract from the numbers.And it's apparently working. Musk's $1 trillion pay package was approved by Tesla’s shareholders without much worry. This could make him the world's first trillionaire, but only if he meets a series of aggressive targets and deadlines for sales, an area where the man has struggled in the past.The big, beautiful sales spikeA Tesla with a sticker referring to the car's purchase is shown on Sunday, Dec. 15, 2024 in Concord, Mass.ASSOCIATED PRESSElon Musk and Donald Trump's bromance wasn't the only fallout from the latter's second term. So, too, died the $7,500 federal EV incentive, which expired in September as part of President Trump's \"Big Beautiful Bill.\" That actually spurred a short-term sales spike ahead of the deadline. Many manufacturers even set new EV sales records riding that wave, but there's a disconcerting trough to come.We still need to wait a bit to see just how bad Q4 EV sales are going to be, but early indications are not looking good. J.D. Power's October report says that EV sales in September were a record high, making up 12.9 percent of new vehicle sales in the US. In October, after the credit expired, they fell to a mere 5.2 percent. That's a worrying drop, and it's already affecting product planning. Cuts in EV productionHonda's Super-One Prototype isn't coming to the US. Tim Stevens for EngadgetWhen I was in Japan last month, getting an early look at some next-gen hybrids from Honda, I wasn't expecting to hear talk of midterm American elections from the company's executives. But that's what was on CEO Toshihiro Mibe's mind. He's watching American voting trends closely to determine the nature of the company's upcoming releases.Mibe said that Honda has already canceled plans for some EVs here in America, instead focusing on a broader selection of hybrid models. It's not the only company to do so. Ram also canceled its 1500 EV truck, but the hybrid version is still supposedly on the way. Scout Motors, too, has been focusing more on its extended-range hybrid offerings. The company's initial pitch was purely electric trucks and SUVs. Lately, it's been prioritizing its extended-range EV options based on the feedback from its 130,000 pre-orderers. 80 percent of them want the onboard generator, an add-on that may prove a saving grace for this EV startup.There is reason for optimismSome manufacturers may be throttling back on their EV aspirations, but others are forging ahead. There's a delightful collection of battery-powered machines coming next year, and that's worth getting excited about.Again, the 2026 Nissan Leaf should be a hugely popular choice as its production ramps up. It's already hitting dealerships now, and with a starting price under $30,000, it'll be hard to beat. But, Chevrolet is going to try with a refreshed Bolt EV for similar money.If you've got more to spend, you've got more options. BMW's stellar iX3 crossover SUV is due soon, as are both the electric CLA sedan and GLC SUV. The most anticipated EV of the year, though, might just be the Rivian R2. This electric SUV will join the stellar R1S and R1T, expanding Rivian's segment footprint while also hopefully expanding its market reach. A $45,000 starting price makes it far more attainable than any of the company's previous offerings. A photograph of the Rivian factory producing the company's R1 SUV variant.Nathan Heleine / RivianIf the prospect of a fun, affordable SUV from Rivian doesn't have you excited for the upcoming year in EVs, maybe some promising news from Europe will. After cutting its own EV incentive program in 2023, Germany's EV sales fell off a cliff, dropping 28 percent in 2024. Cue the predictions of the demise of EVs by many local pundits.Since then, though, EV sales slowly climbed back up, and lately they've been booming, with German road traffic agency KBA saying the total number of newly registered electric vehicles increased by nearly 50 percent in October (year over year). Electric cars now make up 19 percent of the market there, and that's despite Tesla's sales cratering.There's no guarantee that the American market will follow a similar rebound, especially if the anti-EV political messaging continues. Me, though, I've decided I'm staying optimistic, as exhausting as that can be these days.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/a-shaky-year-for-american-evs-could-set-the-tone-for-2026-153000210.html?src=rss",
          "content": "If you like both electric vehicles and emotional roller coasters, 2025 was an excellent year. However, for those of us whose nerves are already sufficiently frazzled, the highs and lows of the last 12 months were a bit hard to stomach.In 2025, we saw the introduction of new, compelling models like the Lucid Gravity and refreshed Nissan Leaf, the latter available at a price on par with its internally combusted competition. From a product availability standpoint, 2025 was the year the EV market started feeling more mature and less manic.But 2025 also saw new heights of anti-EV vitriol stirred up during a particularly traumatic election cycle. The means of propulsion or badge on the hood of your commuter machine suddenly became an indicator of your political affiliations. Put simply, the car you drive is now a political statement, and it’s the latest unprecedented situation in an exhaustingly long and dire string of unprecedented situations. Yes, it's been a long year, and the pessimism of 2025 will surely carry us well into 2026, but not all hope is lost for EVs.Tesla and the DOGE effectElon Musk flashes his T-shirt that reads \"DOGE\" to the media as he walks on South Lawn of the White House, in Washington, March 9, 2025.ASSOCIATED PRESSWe've certainly seen some civic-minded CEOs in the past as auto executives have a long history of mixing their corporate interests with their political panderings. Chrysler CEO Lee Iacocca was even considered a potential presidential candidate once upon a time. However, we have never seen the kind of ass kissing and cronyism we were privy to in this year's fickle friendship between Elon Musk and President Trump.Musk was (hyper) active on the Trump campaign trail, and wasted no time digging into what he described as government overspending. While the Department of Government Efficiency's efficacy is debatable, it certainly proved quite effective at decimating the accounts of Tesla investors. Between January and March, Tesla's stock price dropped by nearly half. Things didn't turn around until Musk left DOGE in May. Since then, Tesla's price has returned to its highs before the DOGE debacle. Its sales, however, have not. Q1 deliveries declined by 13 percent, then 14 percent in Q2. Deliveries bounced back 7 percent in Q3 as everyone scrambled to buy before the EV credits expired, but profits plunged 37 percent. Tesla's market share in the US electric vehicle space has halved, leading perennial pitchman Musk to start hawking everything from AI agents to spandex-clad robots — anything to distract from the numbers.And it's apparently working. Musk's $1 trillion pay package was approved by Tesla’s shareholders without much worry. This could make him the world's first trillionaire, but only if he meets a series of aggressive targets and deadlines for sales, an area where the man has struggled in the past.The big, beautiful sales spikeA Tesla with a sticker referring to the car's purchase is shown on Sunday, Dec. 15, 2024 in Concord, Mass.ASSOCIATED PRESSElon Musk and Donald Trump's bromance wasn't the only fallout from the latter's second term. So, too, died the $7,500 federal EV incentive, which expired in September as part of President Trump's \"Big Beautiful Bill.\" That actually spurred a short-term sales spike ahead of the deadline. Many manufacturers even set new EV sales records riding that wave, but there's a disconcerting trough to come.We still need to wait a bit to see just how bad Q4 EV sales are going to be, but early indications are not looking good. J.D. Power's October report says that EV sales in September were a record high, making up 12.9 percent of new vehicle sales in the US. In October, after the credit expired, they fell to a mere 5.2 percent. That's a worrying drop, and it's already affecting product planning. Cuts in EV productionHonda's Super-One Prototype isn't coming to the US. Tim Stevens for EngadgetWhen I was in Japan last month, getting an early look at some next-gen hybrids from Honda, I wasn't expecting to hear talk of midterm American elections from the company's executives. But that's what was on CEO Toshihiro Mibe's mind. He's watching American voting trends closely to determine the nature of the company's upcoming releases.Mibe said that Honda has already canceled plans for some EVs here in America, instead focusing on a broader selection of hybrid models. It's not the only company to do so. Ram also canceled its 1500 EV truck, but the hybrid version is still supposedly on the way. Scout Motors, too, has been focusing more on its extended-range hybrid offerings. The company's initial pitch was purely electric trucks and SUVs. Lately, it's been prioritizing its extended-range EV options based on the feedback from its 130,000 pre-orderers. 80 percent of them want the onboard generator, an add-on that may prove a saving grace for this EV startup.There is reason for optimismSome manufacturers may be throttling back on their EV aspirations, but others are forging ahead. There's a delightful collection of battery-powered machines coming next year, and that's worth getting excited about.Again, the 2026 Nissan Leaf should be a hugely popular choice as its production ramps up. It's already hitting dealerships now, and with a starting price under $30,000, it'll be hard to beat. But, Chevrolet is going to try with a refreshed Bolt EV for similar money.If you've got more to spend, you've got more options. BMW's stellar iX3 crossover SUV is due soon, as are both the electric CLA sedan and GLC SUV. The most anticipated EV of the year, though, might just be the Rivian R2. This electric SUV will join the stellar R1S and R1T, expanding Rivian's segment footprint while also hopefully expanding its market reach. A $45,000 starting price makes it far more attainable than any of the company's previous offerings. A photograph of the Rivian factory producing the company's R1 SUV variant.Nathan Heleine / RivianIf the prospect of a fun, affordable SUV from Rivian doesn't have you excited for the upcoming year in EVs, maybe some promising news from Europe will. After cutting its own EV incentive program in 2023, Germany's EV sales fell off a cliff, dropping 28 percent in 2024. Cue the predictions of the demise of EVs by many local pundits.Since then, though, EV sales slowly climbed back up, and lately they've been booming, with German road traffic agency KBA saying the total number of newly registered electric vehicles increased by nearly 50 percent in October (year over year). Electric cars now make up 19 percent of the market there, and that's despite Tesla's sales cratering.There's no guarantee that the American market will follow a similar rebound, especially if the anti-EV political messaging continues. Me, though, I've decided I'm staying optimistic, as exhausting as that can be these days.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/a-shaky-year-for-american-evs-could-set-the-tone-for-2026-153000210.html?src=rss",
          "feed_position": 36,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-04/8025df00-2365-11f0-8d7b-a4c3f628eae9"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/antigravity-a1-drone-review-140026021.html",
          "published_at": "Thu, 04 Dec 2025 14:20:07 +0000",
          "title": "Antigravity A1 drone review: FPV flying unlike anything else",
          "standfirst": "The Antigravity A1 is what happens when Insta360’s 360-degree cameras are given wings and flying feels like a video game. Spinning out as its own brand, Antigravity’s debut drone is a big swing: a three-piece set with a drone that captures 8K 360-degree video, FPV goggles and a motion controller.Challenging the dominance of DJI’s (many!) consumer drones is a big ask. Antigravity’s approach is to play to its strengths in 360-degree video and smartphone-first editing. A lot of the appeal comes from how the A1 captures 8K video in all directions, meaning you can edit, cut and swap around your footage — and hopefully rarely miss a moment you’re trying to document. It’s a lot of fun, too, if you can get through the early teething issues, updates and the learning curve.The droneAntigravity A1 drone reviewImage by Mat Smith for EngadgetThe A1 drone is just 249 grams (0.548 lbs). This helps it bypass some drone regulations, though flying permissions vary by region. The pair of cameras mounted on the top and bottom of the drone's body is one of its unique features. It’s difficult to directly compare the A1 against competitor drones, as it offers a mix of features found across different categories and some unique tools of its own.The A1 can capture 360-degree video at up to 8K resolution, and thanks to Insta360’s action cam experience, it can magically remove the drone body from video. This means you can capture video and never see propellers or, well, any part of the drone itself.Along the base of the drone, two landing gears automatically lower when you attempt to land the A1, although you will have to manually retract them when you’re looking to launch the drone. You can also lower the landing gear from one of the controller’s many buttons.The removable battery has a handy one-touch gauge to monitor levels and provides over 20 minutes of flight time, depending on conditions and whether you’re recording video. Antigravity suggests it should last up to 24 minutes during normal filming use. My review device came with two spare batteries and a charging dock. It’s very easy to swap out the batteries, and the charging dock can fully charge a single cell in 45 minutes and even charge all three slots at once. There’s a microSD card slot on the rear of the drone, alongside a USB-C port for (slowly) charging the battery.Antigravity A1 drone reviewImage by Mat Smith for EngadgetThe cameras have a 1/1.28-inch sensor, f/2.2 lens aperture and an ISO range from 100 to 6,400. To adjust those settings beyond auto, you’ll have to dive into the menu inside the goggles, which can be laborious to navigate with a gesture-based controller. Fortunately, auto ISO and white balance are usually good enough. Pro-level content creators might want to tinker with levels here, and there’s a histogram you can toggle on or even a zebra pattern to highlight overexposed shots and areas. and the A1 can record 8K video at up to 30fps or 4K at up to 100fps. You can also meet in the middle, with a 5.2k recording mode.There are also three different flying modes, which are easy to select on the controller. Alongside Normal mode, Sport mode increases the maximum flight speed and offers “enhanced flight performance,” improves control sensitivity and turns off obstacle avoidance. Sport mode offers a tangible difference when flying the A1: it doubles the horizontal flight speed compared to Normal mode. There’s also a Cinematic (C) mode, with a lower max speed for smoother video footage.The controller and gogglesAntigravity A1 drone reviewImage by Mat Smith for EngadgetThe flight mode switcher is one of many controls, wheels, buttons and sliders that pepper the surface of the A1’s grip controller. Intriguingly, though, the main way to control the A1 drone is through gestures, not joysticks or buttons. Instead of pitching control sticks to the left and right, up and down, it’s more akin to a video game, where you point the controller where you want to go, shown with a reticle, and pull the trigger. The A1 then shoots off in that direction.The crucial part is that this doesn’t have to be where you’re “looking” from the drone’s POV. This means you can strafe and fly in any direction without your view being constrained by static cameras. It’s a sensation unlike any other drone I’ve flown. It feels more like playing a video game — like piloting a helicopter in GTA 5. You’re able to look in any direction, both while in motion and while hovering stationary.There are controls for recording video, controlling vertical flight and rotating your POV without turning your head. There’s even a RTH (return to home) function that can be accessed by long-pressing the emergency brake button.The included goggles deliver a crisp view of everything, with a pair of 1.03-inch micro-OLED displays with a resolution of 2,560 × 2,560 and a 72Hz refresh rate. Other FPV drone goggles typically offer 100Hz refresh rates, but it wasn’t a dealbreaker for me. I feared that latency hiccups could make airsickness an issue while flying the A1, but I didn’t experience it. My take is that being able to fully control your view makes nausea less of an issue.Another nice touch, especially if you’re flying with friends, is a circular outer display on the goggles, so everyone can see what the A1 sees. Naturally, it can’t encompass the entire view of the drone pilot, but there’s also nothing duller than watching someone else fly a drone. This offers a mild respite. The other eyepiece is a touchpad for steering through menus inside the goggles without having to point and click with the controller.PerformanceAntigravity A1 drone reviewImage by Mat Smith for EngadgetWhile the Antigravity A1 may offer a more immersive drone-flying experience, in pure numerical terms, it lags behind some competitors. For example, even in Sport mode, the A1 tops out at a maximum speed of just under 36 mph, falling behind the likes of DJI’s Avata 2 (60 mph).I was still pleasantly surprised by how responsive the A1 felt, especially in Sport mode. An additional FPV mode (accessible from the goggles) adds more sensitive controls, although I haven’t been able to test it much since it was introduced in a recent firmware update.For someone with more gaming experience than drone piloting hours, Antigravity’s central control system fits like a glove. I could fly where I wanted, confident in the controls and in the knowledge that I would capture what I wanted to. According to Antigravity, you can fly the A1 within a 10km transmission range, although I didn’t manage to test that limit in central London.The experience of starting with the drone felt, at times, unnecessarily arduous. Pairing everything together has to be done in a specific order: power up drone, power up goggles, power up controller. And turning off each item isn’t a typical long press of the power button. Instead, you use a press-once-press-it-again-and-hold method that I forget pretty much every time.Downloading video from the A1 to your phone is also laborious, but that’s not a flaw specific to this drone. Antigravity has attempted some shortcuts, including a microSD card quick reader that connects to your phone or PC via USB-C.However, at the time of testing, manually connecting the microSD is less of an option and more of a necessity. The drone repeatedly failed to connect to the companion app and reliably transfer video files. Some video files recorded seemingly evaporated between firmware updates, only to reappear later. Another file had been converted to two separate circular views, one from each camera, which made it essentially unusable. Hopefully these intial teething problems have been solved by firmware updates and won't be in retail devices.It’s a shame everything isn’t more stable, especially when both flying the A1 and using Antigravity’s editing software are bothis so beginner-friendly. It's something I’ve mentioned before with the parent company’s action cams, but the ability to create barrel rolls, tilt rotations with just one tap or click is, again, just fun. And because you can reframe and tinker with video warping, create tiny planet effects or simply crop to a more traditional, cinematic camera view, Antigravity’s software offers almost infinite ways to present your drone footage. Deeptracking can be done both during recording and editing in post, keeping a moving subject or point of interest centered as the A1 zips around.There are also AI-powered video editing features to chop up your 20 minutes of flying footage into something digestible and engaging with minimal effort. Because it’s a 360-degree video, the footage can be easily cropped to suit both horizontal and vertical formats.However, with a smaller sensor and 8K resolution spread across a 360-degree view, the A1 is not the best video drone. The video is pleasingly crisp and clear, and while the footage is best recorded in bright daylight or other well-lit locations, murky British November days didn’t affect it much. As the A1 has to stitch together its two sensors, there’s often a visible seam to your video, but it’s usually a very subtle glitch. It might stop some video creators from tapping it for their most polished aerial shots though. Recording video later in the day resulted in more noise and less detail. This is when the A1’s Cinematic mode (and generally slower flying) is a good idea, but it still won’t make up for the fact that this drone’s sensors are covering such wide angles. More video-centric drones will deliver cleaner video and better performance in less-than-ideal lighting conditions.Wrap-upAntigravity A1 drone reviewImage by Mat Smith for EngadgetThe Antigravity A1 is available now, with a standard bundle including the drone, controller and goggles for $1,599. The Infinity Bundle ($1,999) adds two extra batteries, quick reader dongle, sling bag and a charging dock. That does make it substantially more expensive than rival FPV drones like the DJI Avata 2, but the A1 is also a very different kind of drone.The intuitive controls and ability to look all around you make it unlike anything else currently available. It’s a delightful introduction to drones, FPV or otherwise, but a shame that software issues marred my tests. Plus, pairing all the devices can be convoluted and frustrating at times.If Antigravity is thinking about what to do next, I’d be intrigued to see a version with the camera bonafides to take on similarly priced DJI drones. But that shouldn’t detract from the company’s debut model since the A1 is arguably the most intriguing consumer drone since the Mavic Pro.This article originally appeared on Engadget at https://www.engadget.com/cameras/antigravity-a1-drone-review-140026021.html?src=rss",
          "content": "The Antigravity A1 is what happens when Insta360’s 360-degree cameras are given wings and flying feels like a video game. Spinning out as its own brand, Antigravity’s debut drone is a big swing: a three-piece set with a drone that captures 8K 360-degree video, FPV goggles and a motion controller.Challenging the dominance of DJI’s (many!) consumer drones is a big ask. Antigravity’s approach is to play to its strengths in 360-degree video and smartphone-first editing. A lot of the appeal comes from how the A1 captures 8K video in all directions, meaning you can edit, cut and swap around your footage — and hopefully rarely miss a moment you’re trying to document. It’s a lot of fun, too, if you can get through the early teething issues, updates and the learning curve.The droneAntigravity A1 drone reviewImage by Mat Smith for EngadgetThe A1 drone is just 249 grams (0.548 lbs). This helps it bypass some drone regulations, though flying permissions vary by region. The pair of cameras mounted on the top and bottom of the drone's body is one of its unique features. It’s difficult to directly compare the A1 against competitor drones, as it offers a mix of features found across different categories and some unique tools of its own.The A1 can capture 360-degree video at up to 8K resolution, and thanks to Insta360’s action cam experience, it can magically remove the drone body from video. This means you can capture video and never see propellers or, well, any part of the drone itself.Along the base of the drone, two landing gears automatically lower when you attempt to land the A1, although you will have to manually retract them when you’re looking to launch the drone. You can also lower the landing gear from one of the controller’s many buttons.The removable battery has a handy one-touch gauge to monitor levels and provides over 20 minutes of flight time, depending on conditions and whether you’re recording video. Antigravity suggests it should last up to 24 minutes during normal filming use. My review device came with two spare batteries and a charging dock. It’s very easy to swap out the batteries, and the charging dock can fully charge a single cell in 45 minutes and even charge all three slots at once. There’s a microSD card slot on the rear of the drone, alongside a USB-C port for (slowly) charging the battery.Antigravity A1 drone reviewImage by Mat Smith for EngadgetThe cameras have a 1/1.28-inch sensor, f/2.2 lens aperture and an ISO range from 100 to 6,400. To adjust those settings beyond auto, you’ll have to dive into the menu inside the goggles, which can be laborious to navigate with a gesture-based controller. Fortunately, auto ISO and white balance are usually good enough. Pro-level content creators might want to tinker with levels here, and there’s a histogram you can toggle on or even a zebra pattern to highlight overexposed shots and areas. and the A1 can record 8K video at up to 30fps or 4K at up to 100fps. You can also meet in the middle, with a 5.2k recording mode.There are also three different flying modes, which are easy to select on the controller. Alongside Normal mode, Sport mode increases the maximum flight speed and offers “enhanced flight performance,” improves control sensitivity and turns off obstacle avoidance. Sport mode offers a tangible difference when flying the A1: it doubles the horizontal flight speed compared to Normal mode. There’s also a Cinematic (C) mode, with a lower max speed for smoother video footage.The controller and gogglesAntigravity A1 drone reviewImage by Mat Smith for EngadgetThe flight mode switcher is one of many controls, wheels, buttons and sliders that pepper the surface of the A1’s grip controller. Intriguingly, though, the main way to control the A1 drone is through gestures, not joysticks or buttons. Instead of pitching control sticks to the left and right, up and down, it’s more akin to a video game, where you point the controller where you want to go, shown with a reticle, and pull the trigger. The A1 then shoots off in that direction.The crucial part is that this doesn’t have to be where you’re “looking” from the drone’s POV. This means you can strafe and fly in any direction without your view being constrained by static cameras. It’s a sensation unlike any other drone I’ve flown. It feels more like playing a video game — like piloting a helicopter in GTA 5. You’re able to look in any direction, both while in motion and while hovering stationary.There are controls for recording video, controlling vertical flight and rotating your POV without turning your head. There’s even a RTH (return to home) function that can be accessed by long-pressing the emergency brake button.The included goggles deliver a crisp view of everything, with a pair of 1.03-inch micro-OLED displays with a resolution of 2,560 × 2,560 and a 72Hz refresh rate. Other FPV drone goggles typically offer 100Hz refresh rates, but it wasn’t a dealbreaker for me. I feared that latency hiccups could make airsickness an issue while flying the A1, but I didn’t experience it. My take is that being able to fully control your view makes nausea less of an issue.Another nice touch, especially if you’re flying with friends, is a circular outer display on the goggles, so everyone can see what the A1 sees. Naturally, it can’t encompass the entire view of the drone pilot, but there’s also nothing duller than watching someone else fly a drone. This offers a mild respite. The other eyepiece is a touchpad for steering through menus inside the goggles without having to point and click with the controller.PerformanceAntigravity A1 drone reviewImage by Mat Smith for EngadgetWhile the Antigravity A1 may offer a more immersive drone-flying experience, in pure numerical terms, it lags behind some competitors. For example, even in Sport mode, the A1 tops out at a maximum speed of just under 36 mph, falling behind the likes of DJI’s Avata 2 (60 mph).I was still pleasantly surprised by how responsive the A1 felt, especially in Sport mode. An additional FPV mode (accessible from the goggles) adds more sensitive controls, although I haven’t been able to test it much since it was introduced in a recent firmware update.For someone with more gaming experience than drone piloting hours, Antigravity’s central control system fits like a glove. I could fly where I wanted, confident in the controls and in the knowledge that I would capture what I wanted to. According to Antigravity, you can fly the A1 within a 10km transmission range, although I didn’t manage to test that limit in central London.The experience of starting with the drone felt, at times, unnecessarily arduous. Pairing everything together has to be done in a specific order: power up drone, power up goggles, power up controller. And turning off each item isn’t a typical long press of the power button. Instead, you use a press-once-press-it-again-and-hold method that I forget pretty much every time.Downloading video from the A1 to your phone is also laborious, but that’s not a flaw specific to this drone. Antigravity has attempted some shortcuts, including a microSD card quick reader that connects to your phone or PC via USB-C.However, at the time of testing, manually connecting the microSD is less of an option and more of a necessity. The drone repeatedly failed to connect to the companion app and reliably transfer video files. Some video files recorded seemingly evaporated between firmware updates, only to reappear later. Another file had been converted to two separate circular views, one from each camera, which made it essentially unusable. Hopefully these intial teething problems have been solved by firmware updates and won't be in retail devices.It’s a shame everything isn’t more stable, especially when both flying the A1 and using Antigravity’s editing software are bothis so beginner-friendly. It's something I’ve mentioned before with the parent company’s action cams, but the ability to create barrel rolls, tilt rotations with just one tap or click is, again, just fun. And because you can reframe and tinker with video warping, create tiny planet effects or simply crop to a more traditional, cinematic camera view, Antigravity’s software offers almost infinite ways to present your drone footage. Deeptracking can be done both during recording and editing in post, keeping a moving subject or point of interest centered as the A1 zips around.There are also AI-powered video editing features to chop up your 20 minutes of flying footage into something digestible and engaging with minimal effort. Because it’s a 360-degree video, the footage can be easily cropped to suit both horizontal and vertical formats.However, with a smaller sensor and 8K resolution spread across a 360-degree view, the A1 is not the best video drone. The video is pleasingly crisp and clear, and while the footage is best recorded in bright daylight or other well-lit locations, murky British November days didn’t affect it much. As the A1 has to stitch together its two sensors, there’s often a visible seam to your video, but it’s usually a very subtle glitch. It might stop some video creators from tapping it for their most polished aerial shots though. Recording video later in the day resulted in more noise and less detail. This is when the A1’s Cinematic mode (and generally slower flying) is a good idea, but it still won’t make up for the fact that this drone’s sensors are covering such wide angles. More video-centric drones will deliver cleaner video and better performance in less-than-ideal lighting conditions.Wrap-upAntigravity A1 drone reviewImage by Mat Smith for EngadgetThe Antigravity A1 is available now, with a standard bundle including the drone, controller and goggles for $1,599. The Infinity Bundle ($1,999) adds two extra batteries, quick reader dongle, sling bag and a charging dock. That does make it substantially more expensive than rival FPV drones like the DJI Avata 2, but the A1 is also a very different kind of drone.The intuitive controls and ability to look all around you make it unlike anything else currently available. It’s a delightful introduction to drones, FPV or otherwise, but a shame that software issues marred my tests. Plus, pairing all the devices can be convoluted and frustrating at times.If Antigravity is thinking about what to do next, I’d be intrigued to see a version with the camera bonafides to take on similarly priced DJI drones. But that shouldn’t detract from the company’s debut model since the A1 is arguably the most intriguing consumer drone since the Mavic Pro.This article originally appeared on Engadget at https://www.engadget.com/cameras/antigravity-a1-drone-review-140026021.html?src=rss",
          "feed_position": 38,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-12/8ec9ef20-d0fc-11f0-af7d-0d092e6eb0b3"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/apples-airpods-4-with-anc-are-back-on-sale-for-99-140903670.html",
          "published_at": "Thu, 04 Dec 2025 14:09:03 +0000",
          "title": "Apple's AirPods 4 with ANC are back on sale for $99",
          "standfirst": "If you missed the Black Friday sale on Apple's AirPods 4 with ANC, you're in luck — they're back on sale at the same $99 price for a substantial $80 savings (45 percent). What's more, if you're one who frets about damaging your gear, you can grab them with AppleCare+ for $118, saving 43 percent from the normal price. We think that the AirPods Pro 2 are the best AirPods overall, but the ANC-enabled AirPods 4 are also a solid choice, especially at this price. We gave them a score of 86 in our review. Apple's AirPods 4 come in two variants, with and without ANC. Though the base model is solid, the version on sale here with ANC offers a number of advantages like Conversation Awareness, Adaptive Audio and Transparency mode. They also have a charging case that supports MagSafe and Qi-compatible wireless charging, along with a built-in speaker that emits beeps when you activate Find My. And as Apple recently announced, AirPods 4 with ANC supports the company's Live Translation feature. Our main reservation with the AirPods 4 with ANC is that the Airpods Pro 2 are a better noise-cancellation option when they go on sale. At this price, though, the AirPods 4 with ANC are a real bargain if you're looking for new buds — especially if you prefer the open-ears type. As mentioned, for extra peace of mind you can also get the Airpods 4 with ANC plus AppleCare+ protection for $118, or 43 percent off. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/audio/apples-airpods-4-with-anc-are-back-on-sale-for-99-140903670.html?src=rss",
          "content": "If you missed the Black Friday sale on Apple's AirPods 4 with ANC, you're in luck — they're back on sale at the same $99 price for a substantial $80 savings (45 percent). What's more, if you're one who frets about damaging your gear, you can grab them with AppleCare+ for $118, saving 43 percent from the normal price. We think that the AirPods Pro 2 are the best AirPods overall, but the ANC-enabled AirPods 4 are also a solid choice, especially at this price. We gave them a score of 86 in our review. Apple's AirPods 4 come in two variants, with and without ANC. Though the base model is solid, the version on sale here with ANC offers a number of advantages like Conversation Awareness, Adaptive Audio and Transparency mode. They also have a charging case that supports MagSafe and Qi-compatible wireless charging, along with a built-in speaker that emits beeps when you activate Find My. And as Apple recently announced, AirPods 4 with ANC supports the company's Live Translation feature. Our main reservation with the AirPods 4 with ANC is that the Airpods Pro 2 are a better noise-cancellation option when they go on sale. At this price, though, the AirPods 4 with ANC are a real bargain if you're looking for new buds — especially if you prefer the open-ears type. As mentioned, for extra peace of mind you can also get the Airpods 4 with ANC plus AppleCare+ protection for $118, or 43 percent off. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/audio/apples-airpods-4-with-anc-are-back-on-sale-for-99-140903670.html?src=rss",
          "feed_position": 39
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/aws-launches-kiro-powers-with-stripe-figma-and-datadog-integrations-for-ai",
          "published_at": "Thu, 04 Dec 2025 14:02:00 GMT",
          "title": "AWS launches Kiro powers with Stripe, Figma, and Datadog integrations for AI-assisted coding",
          "standfirst": "Amazon Web Services (AWS) has introduced Kiro powers, a system that allows software developers to give their AI coding assistants instant, specialized expertise in specific tools and workflows — addressing what the company calls a fundamental bottleneck in how AI agents operate today.AWS announced Kiro powers at its annual re:Invent conference in Las Vegas. The capability marks a departure from how most AI coding tools work today. Typically, these tools load every possible capability into memory upfront — a process that burns through computational resources and can overwhelm the AI with irrelevant information. Kiro powers takes the opposite approach, activating specialized knowledge only at the moment a developer actually needs it.\"Our goal is to give the agent specialized context so it can reach the right outcome faster — and in a way that also reduces cost,\" Deepak Singh, VP of developer agents and experiences at Amazon, told VentureBeat in an exclusive interview.The launch includes partnerships with nine technology companies: Datadog, Dynatrace, Figma, Neon, Netlify, Postman, Stripe, Supabase and AWS&#x27;s own services. Developers can also create and share their powers with the community.Why AI coding assistants choke when developers connect too many toolsKiro powers comes amidst growing tension in the AI development tool market.Modern AI coding assistants rely on Model Context Protocol (MCP) to connect with external tools and services. When a developer wants their AI assistant to work with Stripe for payments, Figma for design and Supabase for databases, they connect MCP servers for each service.The problem: Each connection loads dozens of tool definitions into the AI&#x27;s working memory before it writes a single line of code. According to AWS documentation, connecting just five MCP servers can consume more than 50,000 tokens — roughly 40% of an AI model&#x27;s context window — before the developer even types their first request.Developers have grown increasingly vocal about this issue. Many complain that they don&#x27;t want to burn through their token allocations just to have an AI agent figure out which tools are relevant to a specific task. They want to get to their workflow instantly — not watch an overloaded agent struggle to sort through irrelevant context.This phenomenon, which some in the industry call \"context rot,\" leads to slower responses, lower-quality outputs and significantly higher costs — since AI services typically charge by the token.Inside the technology that loads AI expertise on demandKiro powers addresses this by packaging three components into a single, dynamically-loaded bundle.The first is a steering file, POWER.md, which functions as an onboarding manual. It tells the AI agent what tools are available and, crucially, when to use them. The second component is the MCP server configuration itself — the actual connection to external services. The third includes optional hooks and automation that trigger specific actions.When a developer mentions \"payment\" or \"checkout\" in their conversation with Kiro, the system automatically activates the Stripe power, loading its tools and best practices into context. When the developer shifts to database work, Supabase activates while Stripe deactivates. The baseline context usage when no powers are active approaches zero.\"You click a button and it automatically loads,\" Singh said. \"Once a power has been created, developers just select &#x27;open in Kiro&#x27; and it launches the IDE with everything ready to go.\"How AWS is bringing elite developer techniques to the massesSingh framed Kiro powers as a democratization of advanced development practices. Before this capability, only the most sophisticated developers knew how to properly configure their AI agents with specialized context — writing custom steering files, crafting precise prompts and manually managing which tools were active at any given time.\"We&#x27;ve found that our developers were adding in capabilities to make their agents more specialized,\" Singh said. \"They wanted to give the agent some special powers for a specific problem. For example, they wanted ... the agent to become an expert at backend-as-a-service.\"This observation led to a key insight: If Supabase or Stripe could build the optimal context configuration once, every developer using those services could benefit.\"Kiro powers formalizes things that only the most advanced people were doing, and allows anyone to get those kinds of skills,\" Singh said.Why dynamic loading beats fine-tuning for most AI coding use casesThe announcement also positions Kiro powers as a more economical alternative to fine-tuning, or the process of training an AI model on specialized data to improve its performance in specific domains.\"It&#x27;s much cheaper\" compared to fine-tuning, Singh. \"Fine-tuning is very expensive, and you can&#x27;t fine-tune most frontier models.\"This is a significant point. The most capable AI models from Anthropic, OpenAI and Google are typically \"closed source,\" meaning developers cannot modify their underlying training. They can only influence the models&#x27; behavior through the prompts and context they provide.\"Most people are already using powerful models like Sonnet 4.5 or Opus 4.5,\" Singh said. \"Those models need to be pointed in the right direction.\"The dynamic loading mechanism also reduces ongoing costs. Because powers only activate when relevant, developers aren&#x27;t paying for token usage on tools they&#x27;re not currently using.Where Kiro powers fits into Amazon&#x27;s bigger bet on autonomous AI agentsKiro powers arrives as part of a broader push by AWS into what the company calls \"agentic AI\" — AI systems that can operate autonomously over extended periods.At re:Invent, AWS also announced three \"frontier agents\" designed to work for hours or days without human intervention: Kiro autonomous agent for software development, AWS security agent and AWS DevOps agent. These represent a different approach from Kiro powers — tackling large, ambiguous problems rather than providing specialized expertise for specific tasks.The two approaches are complementary. Frontier agents handle complex, multi-day projects that require autonomous decision-making across multiple codebases. Kiro powers, by contrast, gives developers precise, efficient tools for everyday development tasks where speed and token efficiency matter most.The company is betting that developers need both ends of this spectrum to be productive.What Kiro powers reveals about the future of AI-assisted software developmentThe launch reflects a maturing market for AI development tools. GitHub Copilot, which Microsoft launched in 2021, introduced millions of developers to AI-assisted coding. Since then, a proliferation of tools — including Cursor, Cline and Claude Code — have competed for developers&#x27; attention.But as these tools have grown more capable, they&#x27;ve also grown more complex. MCP, which Anthropic open-sourced last year, created a standard for connecting AI agents to external services. That solved one problem while creating another: The context overload that Kiro powers now addresses.AWS is positioning itself as the company that understands production software development at scale. Singh emphasized that Amazon&#x27;s experience running AWS for 20 years, combined with its own massive internal software engineering organization, gives it unique insight into how developers actually work.\"It&#x27;s not something you would use just for your prototype or your toy application,\" he said. \"If you want to build production applications, there&#x27;s a lot of knowledge that we bring.\"The road ahead for Kiro powers and cross-platform compatibilityAWS indicated that Kiro powers currently works only within the Kiro IDE, but the company is building toward cross-compatibility with other AI development tools, including command-line interfaces, Cursor, Cline and Claude Code. The company&#x27;s documentation describes a future where developers can \"build a power once, use it anywhere\" — although that vision remains aspirational for now.For the technology partners launching powers today, the appeal is straightforward: Rather than maintaining separate integration documentation for every AI tool on the market, they can create a single power that works everywhere Kiro does. As more AI coding assistants crowd the market, that kind of efficiency becomes increasingly valuable.Kiro powers is available now for developers using Kiro IDE version 0.7 or later at no additional charge beyond the standard Kiro subscription.The underlying bet is a familiar one in the history of computing: The winners in AI-assisted development won&#x27;t be the tools that try to do everything at once, but those that are smart enough to know what to forget.",
          "content": "Amazon Web Services (AWS) has introduced Kiro powers, a system that allows software developers to give their AI coding assistants instant, specialized expertise in specific tools and workflows — addressing what the company calls a fundamental bottleneck in how AI agents operate today.AWS announced Kiro powers at its annual re:Invent conference in Las Vegas. The capability marks a departure from how most AI coding tools work today. Typically, these tools load every possible capability into memory upfront — a process that burns through computational resources and can overwhelm the AI with irrelevant information. Kiro powers takes the opposite approach, activating specialized knowledge only at the moment a developer actually needs it.\"Our goal is to give the agent specialized context so it can reach the right outcome faster — and in a way that also reduces cost,\" Deepak Singh, VP of developer agents and experiences at Amazon, told VentureBeat in an exclusive interview.The launch includes partnerships with nine technology companies: Datadog, Dynatrace, Figma, Neon, Netlify, Postman, Stripe, Supabase and AWS&#x27;s own services. Developers can also create and share their powers with the community.Why AI coding assistants choke when developers connect too many toolsKiro powers comes amidst growing tension in the AI development tool market.Modern AI coding assistants rely on Model Context Protocol (MCP) to connect with external tools and services. When a developer wants their AI assistant to work with Stripe for payments, Figma for design and Supabase for databases, they connect MCP servers for each service.The problem: Each connection loads dozens of tool definitions into the AI&#x27;s working memory before it writes a single line of code. According to AWS documentation, connecting just five MCP servers can consume more than 50,000 tokens — roughly 40% of an AI model&#x27;s context window — before the developer even types their first request.Developers have grown increasingly vocal about this issue. Many complain that they don&#x27;t want to burn through their token allocations just to have an AI agent figure out which tools are relevant to a specific task. They want to get to their workflow instantly — not watch an overloaded agent struggle to sort through irrelevant context.This phenomenon, which some in the industry call \"context rot,\" leads to slower responses, lower-quality outputs and significantly higher costs — since AI services typically charge by the token.Inside the technology that loads AI expertise on demandKiro powers addresses this by packaging three components into a single, dynamically-loaded bundle.The first is a steering file, POWER.md, which functions as an onboarding manual. It tells the AI agent what tools are available and, crucially, when to use them. The second component is the MCP server configuration itself — the actual connection to external services. The third includes optional hooks and automation that trigger specific actions.When a developer mentions \"payment\" or \"checkout\" in their conversation with Kiro, the system automatically activates the Stripe power, loading its tools and best practices into context. When the developer shifts to database work, Supabase activates while Stripe deactivates. The baseline context usage when no powers are active approaches zero.\"You click a button and it automatically loads,\" Singh said. \"Once a power has been created, developers just select &#x27;open in Kiro&#x27; and it launches the IDE with everything ready to go.\"How AWS is bringing elite developer techniques to the massesSingh framed Kiro powers as a democratization of advanced development practices. Before this capability, only the most sophisticated developers knew how to properly configure their AI agents with specialized context — writing custom steering files, crafting precise prompts and manually managing which tools were active at any given time.\"We&#x27;ve found that our developers were adding in capabilities to make their agents more specialized,\" Singh said. \"They wanted to give the agent some special powers for a specific problem. For example, they wanted ... the agent to become an expert at backend-as-a-service.\"This observation led to a key insight: If Supabase or Stripe could build the optimal context configuration once, every developer using those services could benefit.\"Kiro powers formalizes things that only the most advanced people were doing, and allows anyone to get those kinds of skills,\" Singh said.Why dynamic loading beats fine-tuning for most AI coding use casesThe announcement also positions Kiro powers as a more economical alternative to fine-tuning, or the process of training an AI model on specialized data to improve its performance in specific domains.\"It&#x27;s much cheaper\" compared to fine-tuning, Singh. \"Fine-tuning is very expensive, and you can&#x27;t fine-tune most frontier models.\"This is a significant point. The most capable AI models from Anthropic, OpenAI and Google are typically \"closed source,\" meaning developers cannot modify their underlying training. They can only influence the models&#x27; behavior through the prompts and context they provide.\"Most people are already using powerful models like Sonnet 4.5 or Opus 4.5,\" Singh said. \"Those models need to be pointed in the right direction.\"The dynamic loading mechanism also reduces ongoing costs. Because powers only activate when relevant, developers aren&#x27;t paying for token usage on tools they&#x27;re not currently using.Where Kiro powers fits into Amazon&#x27;s bigger bet on autonomous AI agentsKiro powers arrives as part of a broader push by AWS into what the company calls \"agentic AI\" — AI systems that can operate autonomously over extended periods.At re:Invent, AWS also announced three \"frontier agents\" designed to work for hours or days without human intervention: Kiro autonomous agent for software development, AWS security agent and AWS DevOps agent. These represent a different approach from Kiro powers — tackling large, ambiguous problems rather than providing specialized expertise for specific tasks.The two approaches are complementary. Frontier agents handle complex, multi-day projects that require autonomous decision-making across multiple codebases. Kiro powers, by contrast, gives developers precise, efficient tools for everyday development tasks where speed and token efficiency matter most.The company is betting that developers need both ends of this spectrum to be productive.What Kiro powers reveals about the future of AI-assisted software developmentThe launch reflects a maturing market for AI development tools. GitHub Copilot, which Microsoft launched in 2021, introduced millions of developers to AI-assisted coding. Since then, a proliferation of tools — including Cursor, Cline and Claude Code — have competed for developers&#x27; attention.But as these tools have grown more capable, they&#x27;ve also grown more complex. MCP, which Anthropic open-sourced last year, created a standard for connecting AI agents to external services. That solved one problem while creating another: The context overload that Kiro powers now addresses.AWS is positioning itself as the company that understands production software development at scale. Singh emphasized that Amazon&#x27;s experience running AWS for 20 years, combined with its own massive internal software engineering organization, gives it unique insight into how developers actually work.\"It&#x27;s not something you would use just for your prototype or your toy application,\" he said. \"If you want to build production applications, there&#x27;s a lot of knowledge that we bring.\"The road ahead for Kiro powers and cross-platform compatibilityAWS indicated that Kiro powers currently works only within the Kiro IDE, but the company is building toward cross-compatibility with other AI development tools, including command-line interfaces, Cursor, Cline and Claude Code. The company&#x27;s documentation describes a future where developers can \"build a power once, use it anywhere\" — although that vision remains aspirational for now.For the technology partners launching powers today, the appeal is straightforward: Rather than maintaining separate integration documentation for every AI tool on the market, they can create a single power that works everywhere Kiro does. As more AI coding assistants crowd the market, that kind of efficiency becomes increasingly valuable.Kiro powers is available now for developers using Kiro IDE version 0.7 or later at no additional charge beyond the standard Kiro subscription.The underlying bet is a familiar one in the history of computing: The winners in AI-assisted development won&#x27;t be the tools that try to do everything at once, but those that are smart enough to know what to forget.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/53TbLNDfKawmAd8kGfw7ce/17400e5e49710944890e2a6b69cf04f8/nuneybits_Vector_art_of_a_server_rack_in_the_clouds_bf8ba787-9002-494b-b6be-fedd40deb4f9.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/gong-study-sales-teams-using-ai-generate-77-more-revenue-per-rep",
          "published_at": "Thu, 04 Dec 2025 14:00:00 GMT",
          "title": "Gong study: Sales teams using AI generate 77% more revenue per rep",
          "standfirst": "The debate over whether AI belongs in the corporate boardroom appears to be over — at least for those responsible for generating revenue.Seven in 10 enterprise revenue leaders now trust AI to regularly inform their business decisions, according to a sweeping new study released by revenue intelligence company Gong. The finding marks a dramatic shift from just two years ago, when most organizations treated AI as an experimental technology relegated to pilot programs and individual productivity hacks.The research, based on an analysis of 7.1 million sales opportunities across more than 3,600 companies and a survey of over 3,000 global revenue leaders spanning the U.S., UK, Australia and Germany, paints a picture of an industry in rapid transformation. Organizations that have embedded AI into their core go-to-market strategies are 65% more likely to increase their win rates than competitors still treating the technology as optional.\"I don&#x27;t think people delegate decisions to AI, but they do rely on AI in the process of making decisions,\" Amit Bendov, Gong&#x27;s co-founder and chief executive, said in an exclusive interview with VentureBeat. \"Humans are making the decision, but they&#x27;re largely assisted.\"The distinction matters. Rather than replacing human judgment, AI has become what Bendov describes as a \"second opinion\" — a data-driven check on the intuition and guesswork that has traditionally governed sales forecasting and strategy.Slowing growth is forcing sales teams to squeeze more from every repThe timing of AI&#x27;s ascendance in revenue organizations is no coincidence. The study reveals a sobering reality: After rebounding in 2024, average annual revenue growth among surveyed companies decelerated to 16% in 2025, marking a three-percentage-point decline year over year. Sales rep quota attainment fell from 52% to 46% over the same period.The culprit, according to Gong&#x27;s analysis, isn&#x27;t that salespeople are performing worse on individual deals. Win rates and deal duration remained consistent. The problem is that representatives are working fewer opportunities — a finding that suggests operational inefficiencies are eating into selling time.This helps explain why productivity has rocketed to the top of executive priorities. For the first time in the study&#x27;s history, increasing the productivity of existing teams ranked as the number-one growth strategy for 2026, jumping from fourth place the previous year.\"The focus is on increasing sales productivity,\" Bendov said. \"How much dollar-output per dollar-input?\"The numbers back up the urgency. Teams that regularly use AI tools generate 77% more revenue per representative than those that don&#x27;t — a gap Gong characterizes as a six-figure difference per salesperson annually.Companies are moving beyond basic AI automation toward strategic decision-makingThe nature of AI adoption in sales has evolved considerably over the past year. In 2024, most revenue teams used AI for basic automation: Transcribing calls, drafting emails, updating CRM records. Those use cases continue to grow, but 2025 marked what the report calls a shift \"from automation to intelligence.\"The number of U.S. companies using AI for forecasting and measuring strategic initiatives jumped 50% year over year. These more sophisticated applications — predicting deal outcomes, identifying at-risk accounts, measuring which value propositions resonate with different buyer personas — correlate with dramatically better results.Organizations in the 95th percentile of commercial impact from AI were 2 to 4X more likely to have deployed these strategic use cases, according to the study.Bendov offered a concrete example of how this plays out in practice. \"Companies have thousands of deals that they roll up into their forecast,\" he said. \"It used to be based solely on human sentiment, believe it or not. That&#x27;s why a lot of companies miss their numbers: Because people say, &#x27;Oh, he told me he&#x27;ll buy,&#x27; or &#x27;I think I can probably get this one.&#x27;\"AI changes that calculus by examining evidence rather than optimism. \"Companies now get a second opinion from AI on their forecasting, and that improves forecasting accuracy dramatically — 10 [or] 15% better accuracy just because it&#x27;s evidence-based, not just based on human sentiment,\" Bendov said.Revenue-specific AI tools are dramatically outperforming general-purpose alternativesOne of the study&#x27;s more provocative findings concerns the type of AI that delivers results. Teams using revenue-specific AI solutions — tools built explicitly for sales workflows rather than general-purpose platforms like ChatGPT — reported 13% higher revenue growth and 85% greater commercial impact than those relying on generic tools.These specialized systems were also twice as likely to be deployed for forecasting and predictive modeling, the report found.The finding carries obvious implications for Gong, which sells precisely this type of domain-specific platform. But the data suggests a real distinction in outcomes. General-purpose AI, while more prevalent, often creates what the report describes as a \"blind spot\" for organizations — particularly when employees adopt consumer AI tools without company oversight.Research from MIT suggests that while only 59% of enterprise teams use personal AI tools like ChatGPT at work, the actual figure is likely closer to 90%. This shadow AI usage poses security risks and creates fragmented technology stacks that undermine the potential for organization-wide intelligence.Most sales leaders believe AI will reshape their jobs rather than eliminate themPerhaps the most closely-watched question in any AI study concerns employment. The Gong research offers a more nuanced picture than the apocalyptic predictions that often dominate headlines.When asked about AI&#x27;s three-year impact on revenue headcount, 43% of respondents said they expect it to transform jobs without reducing headcount — the most common response. Only 28% anticipate job eliminations, while 21% actually foresee AI creating new roles. Just 8% predict minimal impact.Bendov frames the opportunity as reclaiming lost time. He cited Forrester research indicating that 77% of a sales representative&#x27;s time is spent on activities that don&#x27;t involve customers — administrative work, meeting preparation, researching accounts, updating forecasts and internal briefings.\"AI can eliminate, ideally, 77% of the drudgery work that they&#x27;re doing,\" Bendov said. \"I don&#x27;t think it necessarily eliminates jobs. People are half productive right now. Let&#x27;s make them fully productive, and whatever you&#x27;re paying them will translate to much higher revenue.\"The transformation is already visible in role consolidation. Over the past decade, sales organizations splintered into hyper-specialized functions: One person qualifies leads, another sets appointments, a third closes deals, a fourth handles onboarding. The result was customers interacting with five or six different people across their buying journey.\"Which is not a great buyer experience, because every time I meet a new person that might not have the full context, and it&#x27;s very inefficient for companies,\" Bendov said. \"Now with AI, you can have one person do all this, or much of this.\"At Gong itself, sellers now generate 80% of their own appointments because AI handles the prospecting legwork, Bendov said.American companies are adopting AI 18 months faster than their European counterpartsThe study reveals a notable divide in AI adoption between the U.S. and Europe. While 87% of U.S. companies now use AI in their revenue operations, with another 9% planning adoption within a year, the UK trails by 12 to 18 months. Just 70% of UK companies currently use AI, with 22% percent planning near-term adoption — figures that mirror U.S. data from 2024.Bendov said the pattern reflects a broader historical tendency for enterprise technology trends to cross the Atlantic with a delay. \"It&#x27;s always like that,\" he said. \"Even when the internet was taking off in the U.S., Europe was a step behind.\"The gap isn&#x27;t permanent, he noted, and Europe sometimes leads on technology adoption — mobile payments and messaging apps like WhatsApp gained traction there before the U.S. — but for AI specifically, the American market remains ahead.Gong says a decade of AI development gives it an edge over Salesforce and MicrosoftThe findings arrive as Gong navigates an increasingly crowded market. The company, which recently surpassed $300 million in annual recurring revenue, faces potential competition from enterprise software giants like Salesforce and Microsoft, both of which are embedding AI capabilities into their platforms.Bendov argues that Gong&#x27;s decade of AI development creates a substantial barrier to entry. The company&#x27;s architecture comprises three layers: a \"revenue graph\" that aggregates customer data from CRM systems, emails, calls, videos and web signals; an intelligence layer combining large language models (LLMs) with approximately 40 proprietary small language models; and workflow applications built on top.\"Anybody that would want to build something like that — it&#x27;s not a small feature, it&#x27;s 10 years in development—would need first to build the revenue graph,\" Bendov said.Rather than viewing Salesforce and Microsoft as threats, Bendov characterized them as partners, pointing to both companies&#x27; participation in Gong&#x27;s recent user conference to discuss agent interoperability. The rise of MCP (Model Context Protocol) support and consumption-based pricing models means customers can mix AI agents from multiple vendors rather than committing to a single platform.The real question is whether AI will expand the sales profession or hollow it outThe report&#x27;s implications extend beyond sales departments. If AI can transform revenue operations — long considered a relationship-driven, human-centric function — it raises questions about which other business processes might be next.Bendov sees the potential for expansion rather than contraction. Drawing an analogy to digital photography, he noted that while camera manufacturers suffered, the total number of photos taken exploded once smartphones made photography effortless.\"If AI makes selling simple, I could see a world [with] maybe ten times more jobs than we have now,\" said Bendov.\" It&#x27;s expensive and inefficient today, but if it becomes as easy as taking a photo, the industry could actually grow and create opportunities for people of different abilities, from different locations.\"For Bendov, who co-founded Gong in 2015 when AI was still a hard sell to non-technical business users, the current moment represents something he waited a decade to see. Back then, mentioning AI to sales executives sounded like science fiction. The company struggled to raise money because the underlying technology barely existed.\"When we started the company, we were born as an AI company, but we had to almost hide AI,\" Bendov recalled. \"It was intimidating.\"Now, seven out of 10of those same executives say they trust AI to help run their business. The technology that once had to be disguised has become the one thing nobody can afford to ignore.",
          "content": "The debate over whether AI belongs in the corporate boardroom appears to be over — at least for those responsible for generating revenue.Seven in 10 enterprise revenue leaders now trust AI to regularly inform their business decisions, according to a sweeping new study released by revenue intelligence company Gong. The finding marks a dramatic shift from just two years ago, when most organizations treated AI as an experimental technology relegated to pilot programs and individual productivity hacks.The research, based on an analysis of 7.1 million sales opportunities across more than 3,600 companies and a survey of over 3,000 global revenue leaders spanning the U.S., UK, Australia and Germany, paints a picture of an industry in rapid transformation. Organizations that have embedded AI into their core go-to-market strategies are 65% more likely to increase their win rates than competitors still treating the technology as optional.\"I don&#x27;t think people delegate decisions to AI, but they do rely on AI in the process of making decisions,\" Amit Bendov, Gong&#x27;s co-founder and chief executive, said in an exclusive interview with VentureBeat. \"Humans are making the decision, but they&#x27;re largely assisted.\"The distinction matters. Rather than replacing human judgment, AI has become what Bendov describes as a \"second opinion\" — a data-driven check on the intuition and guesswork that has traditionally governed sales forecasting and strategy.Slowing growth is forcing sales teams to squeeze more from every repThe timing of AI&#x27;s ascendance in revenue organizations is no coincidence. The study reveals a sobering reality: After rebounding in 2024, average annual revenue growth among surveyed companies decelerated to 16% in 2025, marking a three-percentage-point decline year over year. Sales rep quota attainment fell from 52% to 46% over the same period.The culprit, according to Gong&#x27;s analysis, isn&#x27;t that salespeople are performing worse on individual deals. Win rates and deal duration remained consistent. The problem is that representatives are working fewer opportunities — a finding that suggests operational inefficiencies are eating into selling time.This helps explain why productivity has rocketed to the top of executive priorities. For the first time in the study&#x27;s history, increasing the productivity of existing teams ranked as the number-one growth strategy for 2026, jumping from fourth place the previous year.\"The focus is on increasing sales productivity,\" Bendov said. \"How much dollar-output per dollar-input?\"The numbers back up the urgency. Teams that regularly use AI tools generate 77% more revenue per representative than those that don&#x27;t — a gap Gong characterizes as a six-figure difference per salesperson annually.Companies are moving beyond basic AI automation toward strategic decision-makingThe nature of AI adoption in sales has evolved considerably over the past year. In 2024, most revenue teams used AI for basic automation: Transcribing calls, drafting emails, updating CRM records. Those use cases continue to grow, but 2025 marked what the report calls a shift \"from automation to intelligence.\"The number of U.S. companies using AI for forecasting and measuring strategic initiatives jumped 50% year over year. These more sophisticated applications — predicting deal outcomes, identifying at-risk accounts, measuring which value propositions resonate with different buyer personas — correlate with dramatically better results.Organizations in the 95th percentile of commercial impact from AI were 2 to 4X more likely to have deployed these strategic use cases, according to the study.Bendov offered a concrete example of how this plays out in practice. \"Companies have thousands of deals that they roll up into their forecast,\" he said. \"It used to be based solely on human sentiment, believe it or not. That&#x27;s why a lot of companies miss their numbers: Because people say, &#x27;Oh, he told me he&#x27;ll buy,&#x27; or &#x27;I think I can probably get this one.&#x27;\"AI changes that calculus by examining evidence rather than optimism. \"Companies now get a second opinion from AI on their forecasting, and that improves forecasting accuracy dramatically — 10 [or] 15% better accuracy just because it&#x27;s evidence-based, not just based on human sentiment,\" Bendov said.Revenue-specific AI tools are dramatically outperforming general-purpose alternativesOne of the study&#x27;s more provocative findings concerns the type of AI that delivers results. Teams using revenue-specific AI solutions — tools built explicitly for sales workflows rather than general-purpose platforms like ChatGPT — reported 13% higher revenue growth and 85% greater commercial impact than those relying on generic tools.These specialized systems were also twice as likely to be deployed for forecasting and predictive modeling, the report found.The finding carries obvious implications for Gong, which sells precisely this type of domain-specific platform. But the data suggests a real distinction in outcomes. General-purpose AI, while more prevalent, often creates what the report describes as a \"blind spot\" for organizations — particularly when employees adopt consumer AI tools without company oversight.Research from MIT suggests that while only 59% of enterprise teams use personal AI tools like ChatGPT at work, the actual figure is likely closer to 90%. This shadow AI usage poses security risks and creates fragmented technology stacks that undermine the potential for organization-wide intelligence.Most sales leaders believe AI will reshape their jobs rather than eliminate themPerhaps the most closely-watched question in any AI study concerns employment. The Gong research offers a more nuanced picture than the apocalyptic predictions that often dominate headlines.When asked about AI&#x27;s three-year impact on revenue headcount, 43% of respondents said they expect it to transform jobs without reducing headcount — the most common response. Only 28% anticipate job eliminations, while 21% actually foresee AI creating new roles. Just 8% predict minimal impact.Bendov frames the opportunity as reclaiming lost time. He cited Forrester research indicating that 77% of a sales representative&#x27;s time is spent on activities that don&#x27;t involve customers — administrative work, meeting preparation, researching accounts, updating forecasts and internal briefings.\"AI can eliminate, ideally, 77% of the drudgery work that they&#x27;re doing,\" Bendov said. \"I don&#x27;t think it necessarily eliminates jobs. People are half productive right now. Let&#x27;s make them fully productive, and whatever you&#x27;re paying them will translate to much higher revenue.\"The transformation is already visible in role consolidation. Over the past decade, sales organizations splintered into hyper-specialized functions: One person qualifies leads, another sets appointments, a third closes deals, a fourth handles onboarding. The result was customers interacting with five or six different people across their buying journey.\"Which is not a great buyer experience, because every time I meet a new person that might not have the full context, and it&#x27;s very inefficient for companies,\" Bendov said. \"Now with AI, you can have one person do all this, or much of this.\"At Gong itself, sellers now generate 80% of their own appointments because AI handles the prospecting legwork, Bendov said.American companies are adopting AI 18 months faster than their European counterpartsThe study reveals a notable divide in AI adoption between the U.S. and Europe. While 87% of U.S. companies now use AI in their revenue operations, with another 9% planning adoption within a year, the UK trails by 12 to 18 months. Just 70% of UK companies currently use AI, with 22% percent planning near-term adoption — figures that mirror U.S. data from 2024.Bendov said the pattern reflects a broader historical tendency for enterprise technology trends to cross the Atlantic with a delay. \"It&#x27;s always like that,\" he said. \"Even when the internet was taking off in the U.S., Europe was a step behind.\"The gap isn&#x27;t permanent, he noted, and Europe sometimes leads on technology adoption — mobile payments and messaging apps like WhatsApp gained traction there before the U.S. — but for AI specifically, the American market remains ahead.Gong says a decade of AI development gives it an edge over Salesforce and MicrosoftThe findings arrive as Gong navigates an increasingly crowded market. The company, which recently surpassed $300 million in annual recurring revenue, faces potential competition from enterprise software giants like Salesforce and Microsoft, both of which are embedding AI capabilities into their platforms.Bendov argues that Gong&#x27;s decade of AI development creates a substantial barrier to entry. The company&#x27;s architecture comprises three layers: a \"revenue graph\" that aggregates customer data from CRM systems, emails, calls, videos and web signals; an intelligence layer combining large language models (LLMs) with approximately 40 proprietary small language models; and workflow applications built on top.\"Anybody that would want to build something like that — it&#x27;s not a small feature, it&#x27;s 10 years in development—would need first to build the revenue graph,\" Bendov said.Rather than viewing Salesforce and Microsoft as threats, Bendov characterized them as partners, pointing to both companies&#x27; participation in Gong&#x27;s recent user conference to discuss agent interoperability. The rise of MCP (Model Context Protocol) support and consumption-based pricing models means customers can mix AI agents from multiple vendors rather than committing to a single platform.The real question is whether AI will expand the sales profession or hollow it outThe report&#x27;s implications extend beyond sales departments. If AI can transform revenue operations — long considered a relationship-driven, human-centric function — it raises questions about which other business processes might be next.Bendov sees the potential for expansion rather than contraction. Drawing an analogy to digital photography, he noted that while camera manufacturers suffered, the total number of photos taken exploded once smartphones made photography effortless.\"If AI makes selling simple, I could see a world [with] maybe ten times more jobs than we have now,\" said Bendov.\" It&#x27;s expensive and inefficient today, but if it becomes as easy as taking a photo, the industry could actually grow and create opportunities for people of different abilities, from different locations.\"For Bendov, who co-founded Gong in 2015 when AI was still a hard sell to non-technical business users, the current moment represents something he waited a decade to see. Back then, mentioning AI to sales executives sounded like science fiction. The company struggled to raise money because the underlying technology barely existed.\"When we started the company, we were born as an AI company, but we had to almost hide AI,\" Bendov recalled. \"It was intimidating.\"Now, seven out of 10of those same executives say they trust AI to help run their business. The technology that once had to be disguised has become the one thing nobody can afford to ignore.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3CmdSFZEYAQv4H7nhojmdb/b1b80ea16c7d7fd8777d247741c4e75b/nuneybits_Vector_art_of_boardroom_table_overlaid_teal_data_07098080-0b63-47c3-8f02-5c9fdbf1e5fc.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/uk-fines-porn-company-%C2%A31-million-for-weak-age-checks-130056578.html",
          "published_at": "Thu, 04 Dec 2025 13:00:56 +0000",
          "title": "UK fines porn company £1 million for weak age checks",
          "standfirst": "The UK has fined a porn operator called AVS Group £1 million ($1.33 million) for failing to have strong enough age checks, regulator Ofcom announced. The company which was also hit with an additional £50,000 fine for its failure to respond to information request and now has 72 hours to introduce effective age checks or face a further penalty of £1,000 a day. In July, the UK government announced it would start checking compliance by websites that publish or display pornographic content to implement a system for \"highly effective age checks.\" Methods approved by Ofcom include credit card checks, photo ID matching and even estimating a user's age with a provided selfie. However, users have been circumventing the age checks via methods like using a VPN and providing a fake ChatGPT-generated photo ID. The fine is the third such penalty arising from the UK's Online Safety Act designed to protect children and adults from harmful content. In October, 4Chan was also hit with a £20,000 ($26,700) fine for failing to comply with the internet and telecommunications regulator's request for information under the same law. The UK isn't the only region to have implemented age checks. Around half of US states now require it, as do France, Italy, Australia and China. Australia took things a step further by banning social media use by children under 16, including sites popular with young people like Twitch and YouTube. Ofcom's safety director, Oliver Griffiths, said the crackdown on weak age verification for adult sites would continue. \"The tide on online safety is beginning to turn for the better. But we need to see much more from tech companies next year and we’ll use our full powers if they fall short.\"This article originally appeared on Engadget at https://www.engadget.com/general/uk-fines-porn-company-%C2%A31-million-for-weak-age-checks-130056578.html?src=rss",
          "content": "The UK has fined a porn operator called AVS Group £1 million ($1.33 million) for failing to have strong enough age checks, regulator Ofcom announced. The company which was also hit with an additional £50,000 fine for its failure to respond to information request and now has 72 hours to introduce effective age checks or face a further penalty of £1,000 a day. In July, the UK government announced it would start checking compliance by websites that publish or display pornographic content to implement a system for \"highly effective age checks.\" Methods approved by Ofcom include credit card checks, photo ID matching and even estimating a user's age with a provided selfie. However, users have been circumventing the age checks via methods like using a VPN and providing a fake ChatGPT-generated photo ID. The fine is the third such penalty arising from the UK's Online Safety Act designed to protect children and adults from harmful content. In October, 4Chan was also hit with a £20,000 ($26,700) fine for failing to comply with the internet and telecommunications regulator's request for information under the same law. The UK isn't the only region to have implemented age checks. Around half of US states now require it, as do France, Italy, Australia and China. Australia took things a step further by banning social media use by children under 16, including sites popular with young people like Twitch and YouTube. Ofcom's safety director, Oliver Griffiths, said the crackdown on weak age verification for adult sites would continue. \"The tide on online safety is beginning to turn for the better. But we need to see much more from tech companies next year and we’ll use our full powers if they fall short.\"This article originally appeared on Engadget at https://www.engadget.com/general/uk-fines-porn-company-%C2%A31-million-for-weak-age-checks-130056578.html?src=rss",
          "feed_position": 40
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/metas-oversight-board-wants-to-expand-its-powers-in-2026-100000385.html",
          "published_at": "Thu, 04 Dec 2025 10:00:00 +0000",
          "title": "Meta's Oversight Board wants to expand its powers in 2026",
          "standfirst": "The Oversight Board is getting ready to tackle a new pain point for Facebook and Instagram users. Up to now, users have been able to appeal content moderation decisions related to specific posts to the board, but haven't been able to ask the group to intervene in other situations that affect their accounts. That could soon change. The board says that it will weigh in on individual account-level penalties in a pilot next year. The board noted the change in an impact report recapping its five-year history and what lies ahead in the year to come. \"In 2026, our scope expands once more as we pilot the ability to review Meta’s decisions removing and impacting accounts, something that has created ongoing frustration for platform users,\" the report says. It's not clear how this process will work, but if the board plans to take on account-level issues like suspensions, it would be a significant expansion of its purview. In an interview with Engadget, board member Paolo Carozza said that Meta is expected to refer a case to the board in January that will deal with an account-level issue. The handling of that case will allow the board to explore how it might take on similar cases in the future. \"We're really excited to take it on because we think it's an important area that really affects a lot of users and their interests,\" he told Engadget. \"We all know how many people are constantly coming forward complaining about account-level restrictions or blocking or whatever else, and so if we get it right — and it's going to be important to work it out this first pilot — we're really optimistic that it's going to help open up a whole new avenue for us to be helpful to the users of [Meta's] platforms.\"Carozza added that there are a number of \"technical aspects\" and other questions still being worked out between the board and Meta. So for now, it's too soon to say whether there will ever be an official appeals process for suspensions, like there currently is for post removals. But he says Meta is equally invested in the effort. \"It's something we've been talking about with Meta for well over a year,\" he said. \"They've been expressing an openness and a willingness to give us access to those kinds of questions.\"The Oversight Board's report hints at another way its influence could potentially expand. It notes that the group's work has made it \"well-positioned to partner with a range of global tech companies as they navigate issues arising from free speech debates globally.\" Both Meta and Oversight Board officials have previously floated the idea that \"other companies\" might want to take advantage of its expertise. Up to now, most other platforms have had little incentive to do so. But Carozza says the rise of generative AI has created some new interest from non-Meta affiliated platforms, and that there have been \"really preliminary\" conversations with other companies. \"It feels like quite a different moment now, largely because of generative AI, LLMs, chatbots [and] the way that a variety of retail-level users of these technologies are facing a whole new set of challenges and harms that's attracting a lot of scrutiny,\" he said. \"We have had conversations in recent months with other tech companies in this space about the possibility that the board might be able to contribute helpful services to them to help navigate some of these really thorny questions.\"This article originally appeared on Engadget at https://www.engadget.com/big-tech/metas-oversight-board-wants-to-expand-its-powers-in-2026-100000385.html?src=rss",
          "content": "The Oversight Board is getting ready to tackle a new pain point for Facebook and Instagram users. Up to now, users have been able to appeal content moderation decisions related to specific posts to the board, but haven't been able to ask the group to intervene in other situations that affect their accounts. That could soon change. The board says that it will weigh in on individual account-level penalties in a pilot next year. The board noted the change in an impact report recapping its five-year history and what lies ahead in the year to come. \"In 2026, our scope expands once more as we pilot the ability to review Meta’s decisions removing and impacting accounts, something that has created ongoing frustration for platform users,\" the report says. It's not clear how this process will work, but if the board plans to take on account-level issues like suspensions, it would be a significant expansion of its purview. In an interview with Engadget, board member Paolo Carozza said that Meta is expected to refer a case to the board in January that will deal with an account-level issue. The handling of that case will allow the board to explore how it might take on similar cases in the future. \"We're really excited to take it on because we think it's an important area that really affects a lot of users and their interests,\" he told Engadget. \"We all know how many people are constantly coming forward complaining about account-level restrictions or blocking or whatever else, and so if we get it right — and it's going to be important to work it out this first pilot — we're really optimistic that it's going to help open up a whole new avenue for us to be helpful to the users of [Meta's] platforms.\"Carozza added that there are a number of \"technical aspects\" and other questions still being worked out between the board and Meta. So for now, it's too soon to say whether there will ever be an official appeals process for suspensions, like there currently is for post removals. But he says Meta is equally invested in the effort. \"It's something we've been talking about with Meta for well over a year,\" he said. \"They've been expressing an openness and a willingness to give us access to those kinds of questions.\"The Oversight Board's report hints at another way its influence could potentially expand. It notes that the group's work has made it \"well-positioned to partner with a range of global tech companies as they navigate issues arising from free speech debates globally.\" Both Meta and Oversight Board officials have previously floated the idea that \"other companies\" might want to take advantage of its expertise. Up to now, most other platforms have had little incentive to do so. But Carozza says the rise of generative AI has created some new interest from non-Meta affiliated platforms, and that there have been \"really preliminary\" conversations with other companies. \"It feels like quite a different moment now, largely because of generative AI, LLMs, chatbots [and] the way that a variety of retail-level users of these technologies are facing a whole new set of challenges and harms that's attracting a lot of scrutiny,\" he said. \"We have had conversations in recent months with other tech companies in this space about the possibility that the board might be able to contribute helpful services to them to help navigate some of these really thorny questions.\"This article originally appeared on Engadget at https://www.engadget.com/big-tech/metas-oversight-board-wants-to-expand-its-powers-in-2026-100000385.html?src=rss",
          "feed_position": 43
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/gam-takes-aim-at-context-rot-a-dual-agent-memory-architecture-that",
          "published_at": "Thu, 04 Dec 2025 09:00:00 GMT",
          "title": "GAM takes aim at “context rot”: A dual-agent memory architecture that outperforms long-context LLMs",
          "standfirst": "For all their superhuman power, today’s AI models suffer from a surprisingly human flaw: They forget. Give an AI assistant a sprawling conversation, a multi-step reasoning task or a project spanning days, and it will eventually lose the thread. Engineers refer to this phenomenon as “context rot,” and it has quietly become one of the most significant obstacles to building AI agents that can function reliably in the real world.A research team from China and Hong Kong believes it has created a solution to context rot. Their new paper introduces general agentic memory (GAM), a system built to preserve long-horizon information without overwhelming the model. The core premise is simple: Split memory into two specialized roles, one that captures everything, another that retrieves exactly the right things at the right moment.Early results are encouraging, and couldn’t be better timed. As the industry moves beyond prompt engineering and embraces the broader discipline of context engineering, GAM is emerging at precisely the right inflection point.When bigger context windows still aren’t enoughAt the heart of every large language model (LLM) lies a rigid limitation: A fixed “working memory,” more commonly referred to as the context window. Once conversations grow long, older information gets truncated, summarized or silently dropped. This limitation has long been recognized by AI researchers, and since early 2023, developers have been working to expand context windows, rapidly increasing the amount of information a model can handle in a single pass.Mistral’s Mixtral 8x7B debuted with a 32K-token window, which is approximately 24 to 25 words, or about 128 characters in English; essentially a small amount of text, like a single sentence. This was followed by MosaicML’s MPT-7B-StoryWriter-65k+, which more than doubled that capacity; then came Google’s Gemini 1.5 Pro and Anthropic’s Claude 3, offering massive 128K and 200K windows, both of which are extendable to an unprecedented one million tokens. Even Microsoft joined the push, vaulting from the 2K-token limit of the earlier Phi models to the 128K context window of Phi-3. Increasing context windows might sound like the obvious fix, but it isn’t. Even models with sprawling 100K-token windows, enough to hold hundreds of pages of text, still struggle to recall details buried near the beginning of a long conversation. Scaling context comes with its own set of problems. As prompts grow longer, models become less reliable at locating and interpreting information because attention over distant tokens weakens and accuracy gradually erodes.Longer inputs also dilute the signal-to-noise ratio, as including every possible detail can actually make responses worse than using a focused prompt. Long prompts also slow models down; more input tokens lead to noticeably higher output-token latency, creating a practical limit on how much context can be used before performance suffers.Memories are pricelessFor most organizations, supersized context windows come with a clear downside — they’re costly. Sending massive prompts through an API is never cheap, and because pricing scales directly with input tokens, even a single bloated request can drive up expenses. Prompt caching helps, but not enough to offset the habit of routinely overloading models with unnecessary context. And that’s the tension at the heart of the issue: Memory is essential to making AI more powerful.As context windows stretch into the hundreds of thousands or millions of tokens, the financial overhead rises just as sharply. Scaling context is both a technical challenge and an economic one, and relying on ever-larger windows quickly becomes an unsustainable strategy for long-term memory.Fixes like summarization and retrieval-augmented generation (RAG) aren’t silver bullets either. Summaries inevitably strip away subtle but important details, and traditional RAG, while strong on static documents, tends to break down when information stretches across multiple sessions or evolves over time. Even newer variants, such as agentic RAG and RAG 2.0 (which perform better in steering the retrieval process), still inherit the same foundational flaw of treating retrieval as the solution, rather than treating memory itself as the core problem.Compilers solved this problem decades agoIf memory is the real bottleneck, and retrieval can’t fix it, then the gap needs a different kind of solution. That’s the bet behind GAM. Instead of pretending retrieval is memory, GAM keeps a full, lossless record and layers smart, on-demand recall on top of it, resurfacing the exact details an agent needs even as conversations twist and evolve. A useful way to understand GAM is through a familiar idea from software engineering: Just-in-time (JIT) compilation. Rather than precomputing a rigid, heavily compressed memory, GAM keeps things light and tight by storing a minimal set of cues, along with a full, untouched archive of raw history. Then, when a request arrives, it “compiles” a tailored context on the fly.This JIT approach is built into GAM’s dual architecture, allowing AI to carry context across long conversations without overcompressing or guessing too early about what matters. The result is the right information, delivered at exactly the right moment.Inside GAM: A two-agent system built for memory that enduresGAM revolves around the simple idea of separating the act of remembering from recalling, which aptly involves two components: The &#x27;memorizer&#x27; and the &#x27;researcher.&#x27;The memorizer: Total recall without overloadThe memorizer captures every exchange in full, quietly turning each interaction into a concise memo while preserving the complete, decorated session in a searchable page store. It doesn’t compress aggressively or guess what is important. Instead, it organizes interactions into structured pages, adds metadata for efficient retrieval and generates optional lightweight summaries for quick scanning. Critically, every detail is preserved, and nothing is thrown away.The researcher: A deep retrieval engineWhen the agent needs to act, the researcher takes the helm to plan a search strategy, combining embeddings with keyword methods like BM25, navigating through page IDs and stitching the pieces together. It conducts layered searches across the page-store, blending vector retrieval, keyword matching and direct lookups. It evaluates findings, identifies gaps and continues searching until it has sufficient evidence to produce a confident answer, much like a human analyst reviewing old notes and primary documents. It iterates, searches, integrates and reflects until it builds a clean, task-specific briefing. GAM’s power comes from this JIT memory pipeline, which assembles rich, task-specific context on demand instead of leaning on brittle, precomputed summaries. Its core innovation is simple yet powerful, as it preserves all information intact and makes every detail recoverable.Ablation studies support this approach: Traditional memory fails on its own, and naive retrieval isn’t enough. It’s the pairing of a complete archive with an active, iterative research engine that enables GAM to surface details that other systems leave behind.Outperforming RAG and long-context modelsTo test GAM, the researchers pitted it against standard RAG pipelines and models with enlarged context windows such as GPT-4o-mini and Qwen2.5-14B. They evaluated GAM using four major long-context and memory-intensive benchmarks, each chosen to test a different aspect of the system’s capabilities:LoCoMo measures an agent’s ability to maintain and recall information across long, multi-session conversations, encompassing single-hop, multi-hop, temporal reasoning and open-domain tasks.HotpotQA, a widely used multi-hop QA benchmark built from Wikipedia, was adapted using MemAgent’s memory-stress-test version, which mixes relevant documents with distractors to create contexts of 56K, 224K and 448K tokens — ideal for testing how well GAM handles noisy, sprawling input.RULER evaluates retrieval accuracy, multi-hop state tracking, aggregation over long sequences and QA performance under a 128K-token context to further probe long-horizon reasoning.NarrativeQA is a benchmark where each question must be answered using the full text of a book or movie script; the researchers sampled 300 examples with an average context size of 87K tokens.Together, these datasets and benchmarks allowed the team to assess both GAM’s ability to preserve detailed historical information and its effectiveness in supporting complex downstream reasoning tasks.GAM came out ahead across all benchmarks. Its biggest win was on RULER, which benchmarks long-range state tracking. Notably: GAM exceeded 90% accuracy.RAG collapsed because key details were lost in summaries.Long-context models faltered as older information effectively “faded” even when technically present.Clearly, bigger context windows aren’t the answer. GAM works because it retrieves with precision rather than piling up tokens.GAM, context engineering and competing approachesPoorly structured context, not model limitations, is often the real reason AI agents fail. GAM addresses this by ensuring that nothing is permanently lost and that the right information can always be retrieved, even far downstream. The technique’s emergence coincides with the current, broader shift in AI towards context engineering, or the practice of shaping everything an AI model sees — its instructions, history, retrieved documents, tools, preferences and output formats.Context engineering has rapidly eclipsed prompt engineering in importance, although other research groups are tackling the memory problem from different angles. Anthropic is exploring curated, evolving context states. DeepSeek is experimenting with storing memory as images. Another group of Chinese researchers has proposed “semantic operating systems” built around lifelong adaptive memory.However, GAM’s philosophy is distinct: Avoid loss and retrieve with intelligence. Instead of guessing what will matter later, it keeps everything and uses a dedicated research engine to find the relevant pieces at runtime. For agents handling multi-day projects, ongoing workflows or long-term relationships, that reliability may prove essential.Why GAM matters for the long haulJust as adding more compute doesn’t automatically produce better algorithms, expanding context windows alone won’t solve AI’s long-term memory problems. Meaningful progress requires rethinking the underlying system, and GAM takes that approach. Instead of depending on ever-larger models, massive context windows or endlessly refined prompts, it treats memory as an engineering challenge — one that benefits from structure rather than brute force.As AI agents transition from clever demos to mission-critical tools, their ability to remember long histories becomes crucial for developing dependable, intelligent systems. Enterprises require AI agents that can track evolving tasks, maintain continuity and recall past interactions with precision and accuracy. GAM offers a practical path toward that future, signaling what may be the next major frontier in AI: Not bigger models, but smarter memory systems and the context architectures that make them possible.",
          "content": "For all their superhuman power, today’s AI models suffer from a surprisingly human flaw: They forget. Give an AI assistant a sprawling conversation, a multi-step reasoning task or a project spanning days, and it will eventually lose the thread. Engineers refer to this phenomenon as “context rot,” and it has quietly become one of the most significant obstacles to building AI agents that can function reliably in the real world.A research team from China and Hong Kong believes it has created a solution to context rot. Their new paper introduces general agentic memory (GAM), a system built to preserve long-horizon information without overwhelming the model. The core premise is simple: Split memory into two specialized roles, one that captures everything, another that retrieves exactly the right things at the right moment.Early results are encouraging, and couldn’t be better timed. As the industry moves beyond prompt engineering and embraces the broader discipline of context engineering, GAM is emerging at precisely the right inflection point.When bigger context windows still aren’t enoughAt the heart of every large language model (LLM) lies a rigid limitation: A fixed “working memory,” more commonly referred to as the context window. Once conversations grow long, older information gets truncated, summarized or silently dropped. This limitation has long been recognized by AI researchers, and since early 2023, developers have been working to expand context windows, rapidly increasing the amount of information a model can handle in a single pass.Mistral’s Mixtral 8x7B debuted with a 32K-token window, which is approximately 24 to 25 words, or about 128 characters in English; essentially a small amount of text, like a single sentence. This was followed by MosaicML’s MPT-7B-StoryWriter-65k+, which more than doubled that capacity; then came Google’s Gemini 1.5 Pro and Anthropic’s Claude 3, offering massive 128K and 200K windows, both of which are extendable to an unprecedented one million tokens. Even Microsoft joined the push, vaulting from the 2K-token limit of the earlier Phi models to the 128K context window of Phi-3. Increasing context windows might sound like the obvious fix, but it isn’t. Even models with sprawling 100K-token windows, enough to hold hundreds of pages of text, still struggle to recall details buried near the beginning of a long conversation. Scaling context comes with its own set of problems. As prompts grow longer, models become less reliable at locating and interpreting information because attention over distant tokens weakens and accuracy gradually erodes.Longer inputs also dilute the signal-to-noise ratio, as including every possible detail can actually make responses worse than using a focused prompt. Long prompts also slow models down; more input tokens lead to noticeably higher output-token latency, creating a practical limit on how much context can be used before performance suffers.Memories are pricelessFor most organizations, supersized context windows come with a clear downside — they’re costly. Sending massive prompts through an API is never cheap, and because pricing scales directly with input tokens, even a single bloated request can drive up expenses. Prompt caching helps, but not enough to offset the habit of routinely overloading models with unnecessary context. And that’s the tension at the heart of the issue: Memory is essential to making AI more powerful.As context windows stretch into the hundreds of thousands or millions of tokens, the financial overhead rises just as sharply. Scaling context is both a technical challenge and an economic one, and relying on ever-larger windows quickly becomes an unsustainable strategy for long-term memory.Fixes like summarization and retrieval-augmented generation (RAG) aren’t silver bullets either. Summaries inevitably strip away subtle but important details, and traditional RAG, while strong on static documents, tends to break down when information stretches across multiple sessions or evolves over time. Even newer variants, such as agentic RAG and RAG 2.0 (which perform better in steering the retrieval process), still inherit the same foundational flaw of treating retrieval as the solution, rather than treating memory itself as the core problem.Compilers solved this problem decades agoIf memory is the real bottleneck, and retrieval can’t fix it, then the gap needs a different kind of solution. That’s the bet behind GAM. Instead of pretending retrieval is memory, GAM keeps a full, lossless record and layers smart, on-demand recall on top of it, resurfacing the exact details an agent needs even as conversations twist and evolve. A useful way to understand GAM is through a familiar idea from software engineering: Just-in-time (JIT) compilation. Rather than precomputing a rigid, heavily compressed memory, GAM keeps things light and tight by storing a minimal set of cues, along with a full, untouched archive of raw history. Then, when a request arrives, it “compiles” a tailored context on the fly.This JIT approach is built into GAM’s dual architecture, allowing AI to carry context across long conversations without overcompressing or guessing too early about what matters. The result is the right information, delivered at exactly the right moment.Inside GAM: A two-agent system built for memory that enduresGAM revolves around the simple idea of separating the act of remembering from recalling, which aptly involves two components: The &#x27;memorizer&#x27; and the &#x27;researcher.&#x27;The memorizer: Total recall without overloadThe memorizer captures every exchange in full, quietly turning each interaction into a concise memo while preserving the complete, decorated session in a searchable page store. It doesn’t compress aggressively or guess what is important. Instead, it organizes interactions into structured pages, adds metadata for efficient retrieval and generates optional lightweight summaries for quick scanning. Critically, every detail is preserved, and nothing is thrown away.The researcher: A deep retrieval engineWhen the agent needs to act, the researcher takes the helm to plan a search strategy, combining embeddings with keyword methods like BM25, navigating through page IDs and stitching the pieces together. It conducts layered searches across the page-store, blending vector retrieval, keyword matching and direct lookups. It evaluates findings, identifies gaps and continues searching until it has sufficient evidence to produce a confident answer, much like a human analyst reviewing old notes and primary documents. It iterates, searches, integrates and reflects until it builds a clean, task-specific briefing. GAM’s power comes from this JIT memory pipeline, which assembles rich, task-specific context on demand instead of leaning on brittle, precomputed summaries. Its core innovation is simple yet powerful, as it preserves all information intact and makes every detail recoverable.Ablation studies support this approach: Traditional memory fails on its own, and naive retrieval isn’t enough. It’s the pairing of a complete archive with an active, iterative research engine that enables GAM to surface details that other systems leave behind.Outperforming RAG and long-context modelsTo test GAM, the researchers pitted it against standard RAG pipelines and models with enlarged context windows such as GPT-4o-mini and Qwen2.5-14B. They evaluated GAM using four major long-context and memory-intensive benchmarks, each chosen to test a different aspect of the system’s capabilities:LoCoMo measures an agent’s ability to maintain and recall information across long, multi-session conversations, encompassing single-hop, multi-hop, temporal reasoning and open-domain tasks.HotpotQA, a widely used multi-hop QA benchmark built from Wikipedia, was adapted using MemAgent’s memory-stress-test version, which mixes relevant documents with distractors to create contexts of 56K, 224K and 448K tokens — ideal for testing how well GAM handles noisy, sprawling input.RULER evaluates retrieval accuracy, multi-hop state tracking, aggregation over long sequences and QA performance under a 128K-token context to further probe long-horizon reasoning.NarrativeQA is a benchmark where each question must be answered using the full text of a book or movie script; the researchers sampled 300 examples with an average context size of 87K tokens.Together, these datasets and benchmarks allowed the team to assess both GAM’s ability to preserve detailed historical information and its effectiveness in supporting complex downstream reasoning tasks.GAM came out ahead across all benchmarks. Its biggest win was on RULER, which benchmarks long-range state tracking. Notably: GAM exceeded 90% accuracy.RAG collapsed because key details were lost in summaries.Long-context models faltered as older information effectively “faded” even when technically present.Clearly, bigger context windows aren’t the answer. GAM works because it retrieves with precision rather than piling up tokens.GAM, context engineering and competing approachesPoorly structured context, not model limitations, is often the real reason AI agents fail. GAM addresses this by ensuring that nothing is permanently lost and that the right information can always be retrieved, even far downstream. The technique’s emergence coincides with the current, broader shift in AI towards context engineering, or the practice of shaping everything an AI model sees — its instructions, history, retrieved documents, tools, preferences and output formats.Context engineering has rapidly eclipsed prompt engineering in importance, although other research groups are tackling the memory problem from different angles. Anthropic is exploring curated, evolving context states. DeepSeek is experimenting with storing memory as images. Another group of Chinese researchers has proposed “semantic operating systems” built around lifelong adaptive memory.However, GAM’s philosophy is distinct: Avoid loss and retrieve with intelligence. Instead of guessing what will matter later, it keeps everything and uses a dedicated research engine to find the relevant pieces at runtime. For agents handling multi-day projects, ongoing workflows or long-term relationships, that reliability may prove essential.Why GAM matters for the long haulJust as adding more compute doesn’t automatically produce better algorithms, expanding context windows alone won’t solve AI’s long-term memory problems. Meaningful progress requires rethinking the underlying system, and GAM takes that approach. Instead of depending on ever-larger models, massive context windows or endlessly refined prompts, it treats memory as an engineering challenge — one that benefits from structure rather than brute force.As AI agents transition from clever demos to mission-critical tools, their ability to remember long histories becomes crucial for developing dependable, intelligent systems. Enterprises require AI agents that can track evolving tasks, maintain continuity and recall past interactions with precision and accuracy. GAM offers a practical path toward that future, signaling what may be the next major frontier in AI: Not bigger models, but smarter memory systems and the context architectures that make them possible.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/MI0B0KoyfgsNsPcZnfzUu/8de4abaf5670a0d41b186dd175236986/Memory.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-streaming-service-deals-133028980.html",
          "published_at": "Thu, 04 Dec 2025 08:00:35 +0000",
          "title": "The best streaming deals: Save on Disney+ and Hulu, HBO Max, Apple TV+ and more",
          "standfirst": "If you’ve been shocked by how much you spend on streaming services lately, you’re not alone. Companies like Netflix, Disney, HBO Max and others have been consistently raising prices to the point where you may question if streaming is even worth it anymore. We at Engadget still think it is, but we also think you should be smart with your money — and that’s where streaming deals come in. Yes, it is possible to get discounts on services like Peacock and Paramount+, even if those deals aren’t as common as a sale on AirPods. If you’re looking to save money and still stream all of the content you want, Engadget can help by laying out the best streaming deals you can get right now, how you can save with bundles and everything you should know before paying for yet another streaming service. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Philo Core — $25 for your first month ($8 off): Our pick for the best cheap live TV streaming service, Philo offers more than 70 channels in its Core tier, plus access to HBO Max (with ads), AMC+ and Discovery+. After your first month, the subscription will auto-renew at the standard $33-per-month rate. Audible — three months for $3: For literally $1 per month, you can get access to Audible's enormous library of published audiobooks, podcasts and Audible Originals (which can be anything from never-before-heard books to live performances). It's only three months, after which you'll have to cancel or renew at the regular price, but an audiobibliophile can cram a lot of listening into 90 days. Starz (one year) for $12 ($58 off): Pay upfront for one year and you can get more than $40 off a Stars annual subscription. There's a month-to-month option too, which costs $3 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. Spotify Premium Individual — four months for free ($48 off): This is our favorite music streaming service for podcasts and social features. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Amazon Music Unlimited — three months for free ($36 off): Amazon's own music streaming service is now free for three months, for new subscribers only. With it, you get access to 100 million songs with no ads, many podcasts and some audiobooks from Audible as well. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. DirecTV starting at $50/month for one month (up to $40 off): All of DirecTV's signature packages are up to $45 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$8/month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "content": "If you’ve been shocked by how much you spend on streaming services lately, you’re not alone. Companies like Netflix, Disney, HBO Max and others have been consistently raising prices to the point where you may question if streaming is even worth it anymore. We at Engadget still think it is, but we also think you should be smart with your money — and that’s where streaming deals come in. Yes, it is possible to get discounts on services like Peacock and Paramount+, even if those deals aren’t as common as a sale on AirPods. If you’re looking to save money and still stream all of the content you want, Engadget can help by laying out the best streaming deals you can get right now, how you can save with bundles and everything you should know before paying for yet another streaming service. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Philo Core — $25 for your first month ($8 off): Our pick for the best cheap live TV streaming service, Philo offers more than 70 channels in its Core tier, plus access to HBO Max (with ads), AMC+ and Discovery+. After your first month, the subscription will auto-renew at the standard $33-per-month rate. Audible — three months for $3: For literally $1 per month, you can get access to Audible's enormous library of published audiobooks, podcasts and Audible Originals (which can be anything from never-before-heard books to live performances). It's only three months, after which you'll have to cancel or renew at the regular price, but an audiobibliophile can cram a lot of listening into 90 days. Starz (one year) for $12 ($58 off): Pay upfront for one year and you can get more than $40 off a Stars annual subscription. There's a month-to-month option too, which costs $3 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. Spotify Premium Individual — four months for free ($48 off): This is our favorite music streaming service for podcasts and social features. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Amazon Music Unlimited — three months for free ($36 off): Amazon's own music streaming service is now free for three months, for new subscribers only. With it, you get access to 100 million songs with no ads, many podcasts and some audiobooks from Audible as well. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. DirecTV starting at $50/month for one month (up to $40 off): All of DirecTV's signature packages are up to $45 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$8/month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "feed_position": 44
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/inside-netsuites-next-act-evan-goldberg-on-the-future-of-ai-powered-business",
          "published_at": "Thu, 04 Dec 2025 05:00:00 GMT",
          "title": "Inside NetSuite’s next act: Evan Goldberg on the future of AI-powered business systems",
          "standfirst": "Presented by Oracle NetSuiteWhen Evan Goldberg started NetSuite in 1998, his vision was radically simple: give entrepreneurs access to their business data anytime, anywhere. At the time, most enterprise software lived on local servers. As an entrepreneur himself, Goldberg understood the frustration intimately. \"I had fragmented systems. They all said something different,\" he recalls of his early days. NetSuite was the first company to deliver enterprise applications entirely through web browsers, combining CRM, ERP, and ecommerce into one unified platform. That breakthrough idea pioneered the cloud computing and software-as-a-service (SaaS) era and propelled supersonic growth, a 2007 IPO, and an acquisition by Oracle in 2016. Still innovating at the leading-edge That founding obsession — turning scattered data into accessible, coherent, actionable intelligence — is driving NetSuite as it reshapes the next generation of enterprise software.At SuiteWorld 2025 last month, the Austin-based firm unveiled NetSuite Next. Goldberg calls it \"the biggest product evolution in the company&#x27;s history.” The reason? While NetSuite has embedded AI capabilities into workflows for years, he explains, Next represents a quantum leap — contextual, conversational, agentic, composable AI becoming an extension of operations, not separate tools.AI woven into everyday business operations Most enterprise AI today gets bolted on through APIs and conversational interfaces. NetSuite Next operates differently. Intelligence runs deep in workflows instead of sitting on the surface. It autonomously reconciles accounts, optimizes payment timing, predicts cash crunches, and surfaces its reasoning at every step. It doesn&#x27;t just advise on business processes — it executes them, transparently, within human-defined guardrails.\"We built NetSuite for entrepreneurs so that they could get great information about their business,\" Goldberg explains. \"I think the next step is to be able to get deeper insights and analysis without being an expert in analytics. AI turns out to be a really good data scientist.\"This architectural divergence reflects competing philosophies about enterprise technology adoption. Microsoft and SAP have pursued rapid deployment through add-on assistants. NetSuite&#x27;s five-year development cycle for Next represents a more fundamental reimagining: making AI an everyday tool woven into business operations, not a separate application requiring constant context-switching.AI echoes and deepens cloud innovation Goldberg sees a clear through line connecting today&#x27;s AI adoption and the cloud computing era he pioneered. \"There’s sort of an infinite sense of possibility that exists in the technology world,” he says. “Everybody is thinking about how they can leverage this, how they&#x27;re going to get involved.\"When NetSuite was starting, he continues, \"We had to come to customers with the cloud and say, &#x27;This won&#x27;t disrupt your operations. It&#x27;s going to make them better.&#x27;\" Today, evangelizing enterprise leaders on advanced AI requires a similar approach — demonstrating immediate value while minimizing implementation risk. For NetSuite, continuous innovation around maximizing customer data for growth is an undeniable theme that connects both eras.New transformative capabilities NetSuite’s latest AI capabilities span business operations, while blurring (in a good way) the lines between human and machine intervention:Context-aware intelligence. Ask Oracle adapts responses based on user role, current workflow, and business context. A CFO requesting point-of-sale data receives financial analytics. A warehouse manager asking the same question sees inventory insights.Collaborative workflow design. AI Canvas functions as a scenario-planning workspace where business users articulate processes in natural language. A finance director can describe approval hierarchies for capital expenditures —\"For amounts over $50,000, I need department head approval, then CFO sign-off\" — which the system translates into executable workflows with appropriate controls and audit trails.Governed autonomous operations. Autonomous workflows operate within defined parameters, reconciling accounts, generating payment runs, predicting cash flow. When the system recommends accelerating payment to a supplier, it shows which factors influenced the decision — transparent logic users can accept, modify, or override.Open AI architecture. Built to support Model Context Protocol, NetSuite AI Connector Service enables enterprises to integrate external large language models while supporting governance.Critically, NetSuite adds AI capabilities at no additional cost — embedded directly into workflows employees already use daily.Security and privacy from Oracle infrastructure Built-in AI requires robust infrastructure that bolt-on approaches sidestep. Here, according to NetSuite, tight integration within Oracle technology provides operational and competitive advantages, especially security and compliance peace of mind. Engineers say that’s because NetSuite is supported by Oracle&#x27;s complete stack. From database to applications to analytics, the system optimizes decisions using data from multiple sources in real time.\"That&#x27;s why I started NetSuite. I couldn&#x27;t get the data I wanted,\" Goldberg reflects. \"That&#x27;s one of the most differentiated aspects of NetSuite. When you&#x27;re doing your financial close, and you&#x27;re thinking about what reserves you&#x27;re going to take, you can look at your sales data, because that&#x27;s also there in NetSuite. With NetSuite Next, AI can also help you make those kinds of decisions.\"And performance improves with use. As the platform learns from millions of transactions across thousands of customers, its embedded intelligence improves in ways that bolt-on assistants operating adjacent to core systems cannot match.NetSuite&#x27;s customer base demonstrates this scalability advantage — from startups that became global enterprises including Reddit, Shopify, and DoorDash; as well as promising newcomers like BERO, a brewer of non-alcoholic beer founded by actor Tom Holland, Chomps meat snacks, PetLab, and Kieser Australia. The unified platform grows with businesses rather than requiring migration as they scale.Keeping fire in the belly after three decadesHow does a nearly 30-year-old company maintain innovative capacity, particularly as part of a mammoth corporate ecosystem? Goldberg credits the parent company&#x27;s culture of continuous reinvention.\"I don&#x27;t know if you&#x27;ve heard about this guy Larry Ellison,\" he smiles. \"He manages to seemingly reinvent himself whenever one of these technology revolutions comes along. That hunger, that curiosity, that desire to make things constantly better imbues all of Oracle.\"For Goldberg, the single biggest challenge facing NetSuite customers centers on integration complexity and trust. NetSuite Next addresses this by embedding AI within existing workflows rather than requiring separate systems.In addition, updates to SuiteCloud Platform — an extensibility and customization environment — help organizations adapt NetSuite to their unique business needs. Built on open standards, it lets enterprises mix and match AI models for different functions. SuiteAgent frameworks enable partners to build specialized automation directly into NetSuite. AI Studios give administrators control over how AI operates within specific industry needs.\"This takes NetSuite&#x27;s flexibility to a new level,\" Goldberg says, enabling customers and partners to \"quickly and easily build AI agents, connect external AI assistants, and orchestrate AI processes.\"“AI execution fabric” delivers measurable business impact Industry analysts increasingly argue that embedded AI features deliver superior results compared to add-on models. Futurum Group sees NetSuite Next as an \"AI execution fabric\" rather than a conversational layer — intelligence that runs deep in workflows instead of sitting on the surface.For midmarket enterprises navigating talent shortages, complex compliance frameworks, and competition from digital-native companies, the distinction between advice and execution matters economically.Built-in AI doesn&#x27;t just inform better decisions. It makes those decisions, transparently and autonomously, within human-defined guardrails. For enterprises making ERP decisions today, the choice carries long-term implications. Bolt-on AI can deliver immediate value for information access and basic automation. But built-in AI promises to transform operations with intelligence permeating every transaction and workflow.NetSuite Next begins rolling out to North American customers next year.Why 2026 will belong to the AI-first businessThe bet underlying NetSuite Next: Enterprises reimagining ERP operations around embedded intelligence will outperform those just adding bolt-on conversational assistance to existing systems. Early cloud computing adopters, Goldberg notes, gained competitive advantages that compounded over time. The same logic appears likely to apply to AI-first platforms. Simplicity and ease of use are two big advantages. \"You don&#x27;t have to dig through lots of menus and understand all of the analytics capabilities,\" Goldberg says. \"It will quickly bring up an analysis for you, and then you can converse in natural language to hone in on what you think is most important.\"The tools now think alongside users and take intelligently informed action. For midmarket and entrepreneurial companies, where the gap between having information and acting on it can be the difference between growth and failure, that kind of autonomous execution may determine which enterprises thrive in an AI-first era.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Oracle NetSuiteWhen Evan Goldberg started NetSuite in 1998, his vision was radically simple: give entrepreneurs access to their business data anytime, anywhere. At the time, most enterprise software lived on local servers. As an entrepreneur himself, Goldberg understood the frustration intimately. \"I had fragmented systems. They all said something different,\" he recalls of his early days. NetSuite was the first company to deliver enterprise applications entirely through web browsers, combining CRM, ERP, and ecommerce into one unified platform. That breakthrough idea pioneered the cloud computing and software-as-a-service (SaaS) era and propelled supersonic growth, a 2007 IPO, and an acquisition by Oracle in 2016. Still innovating at the leading-edge That founding obsession — turning scattered data into accessible, coherent, actionable intelligence — is driving NetSuite as it reshapes the next generation of enterprise software.At SuiteWorld 2025 last month, the Austin-based firm unveiled NetSuite Next. Goldberg calls it \"the biggest product evolution in the company&#x27;s history.” The reason? While NetSuite has embedded AI capabilities into workflows for years, he explains, Next represents a quantum leap — contextual, conversational, agentic, composable AI becoming an extension of operations, not separate tools.AI woven into everyday business operations Most enterprise AI today gets bolted on through APIs and conversational interfaces. NetSuite Next operates differently. Intelligence runs deep in workflows instead of sitting on the surface. It autonomously reconciles accounts, optimizes payment timing, predicts cash crunches, and surfaces its reasoning at every step. It doesn&#x27;t just advise on business processes — it executes them, transparently, within human-defined guardrails.\"We built NetSuite for entrepreneurs so that they could get great information about their business,\" Goldberg explains. \"I think the next step is to be able to get deeper insights and analysis without being an expert in analytics. AI turns out to be a really good data scientist.\"This architectural divergence reflects competing philosophies about enterprise technology adoption. Microsoft and SAP have pursued rapid deployment through add-on assistants. NetSuite&#x27;s five-year development cycle for Next represents a more fundamental reimagining: making AI an everyday tool woven into business operations, not a separate application requiring constant context-switching.AI echoes and deepens cloud innovation Goldberg sees a clear through line connecting today&#x27;s AI adoption and the cloud computing era he pioneered. \"There’s sort of an infinite sense of possibility that exists in the technology world,” he says. “Everybody is thinking about how they can leverage this, how they&#x27;re going to get involved.\"When NetSuite was starting, he continues, \"We had to come to customers with the cloud and say, &#x27;This won&#x27;t disrupt your operations. It&#x27;s going to make them better.&#x27;\" Today, evangelizing enterprise leaders on advanced AI requires a similar approach — demonstrating immediate value while minimizing implementation risk. For NetSuite, continuous innovation around maximizing customer data for growth is an undeniable theme that connects both eras.New transformative capabilities NetSuite’s latest AI capabilities span business operations, while blurring (in a good way) the lines between human and machine intervention:Context-aware intelligence. Ask Oracle adapts responses based on user role, current workflow, and business context. A CFO requesting point-of-sale data receives financial analytics. A warehouse manager asking the same question sees inventory insights.Collaborative workflow design. AI Canvas functions as a scenario-planning workspace where business users articulate processes in natural language. A finance director can describe approval hierarchies for capital expenditures —\"For amounts over $50,000, I need department head approval, then CFO sign-off\" — which the system translates into executable workflows with appropriate controls and audit trails.Governed autonomous operations. Autonomous workflows operate within defined parameters, reconciling accounts, generating payment runs, predicting cash flow. When the system recommends accelerating payment to a supplier, it shows which factors influenced the decision — transparent logic users can accept, modify, or override.Open AI architecture. Built to support Model Context Protocol, NetSuite AI Connector Service enables enterprises to integrate external large language models while supporting governance.Critically, NetSuite adds AI capabilities at no additional cost — embedded directly into workflows employees already use daily.Security and privacy from Oracle infrastructure Built-in AI requires robust infrastructure that bolt-on approaches sidestep. Here, according to NetSuite, tight integration within Oracle technology provides operational and competitive advantages, especially security and compliance peace of mind. Engineers say that’s because NetSuite is supported by Oracle&#x27;s complete stack. From database to applications to analytics, the system optimizes decisions using data from multiple sources in real time.\"That&#x27;s why I started NetSuite. I couldn&#x27;t get the data I wanted,\" Goldberg reflects. \"That&#x27;s one of the most differentiated aspects of NetSuite. When you&#x27;re doing your financial close, and you&#x27;re thinking about what reserves you&#x27;re going to take, you can look at your sales data, because that&#x27;s also there in NetSuite. With NetSuite Next, AI can also help you make those kinds of decisions.\"And performance improves with use. As the platform learns from millions of transactions across thousands of customers, its embedded intelligence improves in ways that bolt-on assistants operating adjacent to core systems cannot match.NetSuite&#x27;s customer base demonstrates this scalability advantage — from startups that became global enterprises including Reddit, Shopify, and DoorDash; as well as promising newcomers like BERO, a brewer of non-alcoholic beer founded by actor Tom Holland, Chomps meat snacks, PetLab, and Kieser Australia. The unified platform grows with businesses rather than requiring migration as they scale.Keeping fire in the belly after three decadesHow does a nearly 30-year-old company maintain innovative capacity, particularly as part of a mammoth corporate ecosystem? Goldberg credits the parent company&#x27;s culture of continuous reinvention.\"I don&#x27;t know if you&#x27;ve heard about this guy Larry Ellison,\" he smiles. \"He manages to seemingly reinvent himself whenever one of these technology revolutions comes along. That hunger, that curiosity, that desire to make things constantly better imbues all of Oracle.\"For Goldberg, the single biggest challenge facing NetSuite customers centers on integration complexity and trust. NetSuite Next addresses this by embedding AI within existing workflows rather than requiring separate systems.In addition, updates to SuiteCloud Platform — an extensibility and customization environment — help organizations adapt NetSuite to their unique business needs. Built on open standards, it lets enterprises mix and match AI models for different functions. SuiteAgent frameworks enable partners to build specialized automation directly into NetSuite. AI Studios give administrators control over how AI operates within specific industry needs.\"This takes NetSuite&#x27;s flexibility to a new level,\" Goldberg says, enabling customers and partners to \"quickly and easily build AI agents, connect external AI assistants, and orchestrate AI processes.\"“AI execution fabric” delivers measurable business impact Industry analysts increasingly argue that embedded AI features deliver superior results compared to add-on models. Futurum Group sees NetSuite Next as an \"AI execution fabric\" rather than a conversational layer — intelligence that runs deep in workflows instead of sitting on the surface.For midmarket enterprises navigating talent shortages, complex compliance frameworks, and competition from digital-native companies, the distinction between advice and execution matters economically.Built-in AI doesn&#x27;t just inform better decisions. It makes those decisions, transparently and autonomously, within human-defined guardrails. For enterprises making ERP decisions today, the choice carries long-term implications. Bolt-on AI can deliver immediate value for information access and basic automation. But built-in AI promises to transform operations with intelligence permeating every transaction and workflow.NetSuite Next begins rolling out to North American customers next year.Why 2026 will belong to the AI-first businessThe bet underlying NetSuite Next: Enterprises reimagining ERP operations around embedded intelligence will outperform those just adding bolt-on conversational assistance to existing systems. Early cloud computing adopters, Goldberg notes, gained competitive advantages that compounded over time. The same logic appears likely to apply to AI-first platforms. Simplicity and ease of use are two big advantages. \"You don&#x27;t have to dig through lots of menus and understand all of the analytics capabilities,\" Goldberg says. \"It will quickly bring up an analysis for you, and then you can converse in natural language to hone in on what you think is most important.\"The tools now think alongside users and take intelligently informed action. For midmarket and entrepreneurial companies, where the gap between having information and acting on it can be the difference between growth and failure, that kind of autonomous execution may determine which enterprises thrive in an AI-first era.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2XtOSMqQi1z1ZProN1wL2h/93796f6888f6a6567104c2545639c3c3/2025_SuiteWorld_ExecutiveKeynote01_88144-64-.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/anthropic-vs-openai-red-teaming-methods-reveal-different-security-priorities",
          "published_at": "Thu, 04 Dec 2025 05:00:00 GMT",
          "title": "Anthropic vs. OpenAI red teaming methods reveal different security priorities for enterprise AI",
          "standfirst": "Model providers want to prove the security and robustness of their models, releasing system cards and conducting red-team exercises with each new release. But it can be difficult for enterprises to parse through the results, which vary widely and can be misleading. Anthropic&#x27;s 153-page system card for Claude Opus 4.5 versus OpenAI&#x27;s 60-page GPT-5 system card reveals a fundamental split in how these labs approach security validation. Anthropic discloses in their system card how they rely on multi-attempt attack success rates from 200-attempt reinforcement learning (RL) campaigns. OpenAI also reports attempted jailbreak resistance. Both metrics are valid. Neither tells the whole story.Security leaders deploying AI agents for browsing, code execution and autonomous action need to know what each red team evaluation actually measures, and where the blind spots are.What the attack data showsGray Swan&#x27;s Shade platform ran adaptive adversarial campaigns against Claude models. The attack success rate (ASR) tells the story.Opus 4.5 in coding environments hit 4.7% ASR at one attempt, 33.6% at ten and 63.0% at one hundred. In computer use with extended thinking, it held at 0% ASR even after 200 attempts. It&#x27;s the first model to saturate the benchmark.Sonnet 4.5 at the same thresholds showed 70% ASR in coding and 85.7% in computer use.Opus 4.5 delivers roughly 7x improvement in coding resistance and complete resistance in computer use. This illustrates that the gap between model tiers within the same family is now larger than some cross-vendor comparisons. For security teams, that&#x27;s a procurement factor that didn&#x27;t exist six months ago.For OpenAI, the Gray Swan Shade platform found that the o1 system card delivered 6% ASR for harmful text and 5% for malicious code, all based on single-attempt metrics. Third-party testing by SPLX and NeuralTrust found GPT-5&#x27;s raw ASR hit 89% initially, dropping below 1% within two weeks of patching.The report Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks confirms the pattern. With sufficient attempts, Claude 3.5 Sonnet showed 78% ASR, and GPT-4o reached 89%.Two ways to catch deceptionAnthropic monitors approximately 10 million neural features during evaluation using dictionary learning. Features map to human-interpretable concepts, including deception, sycophancy, bias, power-seeking and concealment.Meanwhile, OpenAI&#x27;s approach relies on chain-of-thought (CoT) monitoring. Their deception classifier flagged 0.17% of o1-preview responses as potentially deceptive with 92% accuracy on internal validation. GPT-5 reduced CoT deception from 4.8% to 2.1% compared to o3. The method assumes visible reasoning reflects internal processing. Anthropic&#x27;s interpretability work directly questions that assumption.When models game the testIn Apollo Research&#x27;s evaluation of o1, the model attempted to turn off oversight mechanisms 5% of the time when it believed it would be shut down. In 2% of cases, o1 attempted self-exfiltration. When confronted about misaligned actions, o1 denied wrongdoing or fabricated explanations 99% of the time. The o1 system card disclosed instrumental alignment faking. In 37% of scenarios, the model pursued developer-aligned goals during evaluation, then switched to its own goals when it believed oversight was minimal.Meanwhile, Anthropic reports Opus 4.5&#x27;s evaluation awareness dropped from 26.5% (Opus 4.1) to less than 10% internally. UK AISI measured evaluation awareness decreasing from 26.5% (Sonnet 4.5) to 12.7% (Opus 4.5 Preview). METR&#x27;s GPT-5 evaluation noted the model \"can identify the exact evaluation it is in on some occasions\" and \"seems to use this information to get a better score mostly.\"If a model behaves differently when it detects evaluation conditions, it&#x27;s a sure bet that production behavior will become unpredictable when pushed to scale. This is the core problem with evaluation awareness. Models that recognize they&#x27;re being tested attempt to game the test. Anthropic&#x27;s 60% reduction in evaluation awareness from Opus 4.1 to 4.5 represents their success in targeted engineering efforts against this vector.Red teaming on prompt injection defenses shows similar divergence.Anthropic&#x27;s testing reports 96% prevention in tool use scenarios, rising to 99.4% with additional safeguards like prompt shields. Fujitsu&#x27;s independent assessment found GPT-5 vulnerable to approximately 20% of tested injection attacks. OpenAI&#x27;s o3/o4-mini system card reports instruction hierarchy scores of 0.86 for system-versus-developer conflicts. These are different metrics and different attack methodologies, but the gap suggests Anthropic&#x27;s agentic use cases have been hardened against adversarial inputs embedded in tool outputs.Comparing red teaming resultsHere&#x27;s how Opus 4.5 stacks up against OpenAI&#x27;s model family across 16 dimensions. .DimensionClaude Opus 4.5GPT-5o3 / o4-minio1System card length153 pages55 pages~30 pages~40 pagesAttack methodology200-attempt RL campaignsSingle-attempt + iterative patchingSingle-attemptSingle-attemptASR @ 1 attempt (coding)4.7%89% raw (pre-patch)Not published5%ASR @ 100 attempts63.0%Not publishedNot publishedNot publishedASR @ 200 attempts (Computer Use)0% (saturates benchmark)Not publishedNot publishedNot publishedPrompt injection defense96% prevention; 99.4% with safeguards~20% ASR (Fujitsu)0.86 instruction hierarchyHigher ASR than GPT-4oInterpretability~10M neural features monitoredCoT monitoringCoT monitoringCoT monitoringDeception detectionInternal feature activation2.1% CoT flagged0.95 not_unsafe0.17% flagged; 99% denyEvaluation awareness<10%Identifies exact eval (METR)Not published37% alignment fakingScheming (Apollo)Opus 4.5 showed very low rates of sabotage propensity in internal evaluations, orders of magnitude lower than o1.Not publishedLower than o1; still deceptive5% turn off oversight; 2% self-exfilCBRN riskBelow ASL-4Medium (approaching High)MediumMedium (first to reach)GovernanceFRT → AST → RSO/CEOSAG + Preparedness v2SAG + Preparedness v2SAG + PreparednessExternal partnersGray Swan, UK AISI, US CAISI, METRUK AISI, US AISI, METR, ApolloUK AISI, US AISI, METR, Apollo, Pattern LabsUK AISI, US AISI, METR, ApolloReward hackingYes (impossible tasks)Yes (METR)~1% of tasks; 5/24 KernelsYesMisalignment reduction60% vs. Opus 4.1Not publishedLower scheming than o1BaselineSources: Opus 4.5 system card, GPT-5 system card, o3/o4-mini system card, o1 system card, Gray Swan, METR, Apollo ResearchWhy these differences matterEnterprises have several factors to consider when analyzing model evals. These include: Attack persistence thresholds Anthropic&#x27;s 200-attempt RL campaigns simulate adversaries with time, resources, and adaptive tooling. In RL-based adversarial testing, the attacker model learns from each failure, adjusts its approach and systematically probes for weaknesses. It&#x27;s training an AI to break another AI.Gray Swan&#x27;s Shade platform doesn&#x27;t just retry the same prompt. It learns from failures, adjusts attack vectors and exploits patterns in model responses. The 4.7% to 63.0% degradation curve in coding environments shows how resistance erodes under sustained pressure. OpenAI&#x27;s single-attempt metrics answer a different question: How often does a naive attacker succeed on the first try? Both matter. A phishing campaign hits millions of users once each. A nation-state actor runs thousands of variations against a single target. Security teams need to know which threat model their vendor tested against.Detection architectureAnthropic monitors approximately 10 million internal neural features during evaluation. These are abstract concepts like deception, sycophancy and power-seeking that activate across the model&#x27;s hidden layers. When a fraud/deception feature lights up during benign roleplay, that&#x27;s a signal invisible to output analysis. The model&#x27;s internal state reveals associations its outputs don&#x27;t.OpenAI takes a different approach with CoT monitoring. Their deception classifier flagged 0.17% of o1-preview responses as potentially deceptive with 92% accuracy. The assumption is that reasoning traces reflect internal processing. Anthropic&#x27;s interpretability research directly challenges this. Models can produce clean reasoning chains while internal features indicate something else entirely.Neither approach is complete. CoT monitoring scales more easily. Feature monitoring catches what CoT misses but requires deep model access and interpretability infrastructure that most enterprises can&#x27;t replicate.Scheming evaluation design Apollo Research&#x27;s methodology puts models in scenarios where misaligned behavior offers a strategic advantage: Shutdown threats, goal conflicts and oversight detection. o1 attempted to turn off oversight mechanisms 5% of the time when believing shutdown was imminent. It tried to copy itself to prevent replacement in 2% of cases. When confronted, it denied wrongdoing 99% of the time. Opus 4.5 showed very low rates of sabotage propensity in internal evaluations, orders of magnitude lower than o1.But the evaluation environments differ. Anthropic&#x27;s stress tests focus on whether models attempt sabotage when given clear opportunities. OpenAI&#x27;s tests via Apollo probe instrumental reasoning, specifically whether models fake alignment during evaluation, then defect when oversight drops. The 37% alignment-faking rate in o1 represents a different failure mode than sabotage attempts.The comparability problem These methodological differences make direct comparison difficult. Opus 4.5&#x27;s 0% ASR at 200 attempts in computer use versus o1&#x27;s 5% malicious code rate are not measuring the same thing. The attack surfaces, attempt counts and success criteria differ.The matrix reveals what each vendor chose to measure and publish. That itself signals priorities. Anthropic&#x27;s 153-page system card emphasizes degradation curves and internal feature monitoring. OpenAI emphasizes iterative improvement and CoT transparency.Bottom line: Enterprise security teams inheriting these models inherit these measurement philosophies. The question isn&#x27;t which number is better. It&#x27;s the measurement that matches your deployment&#x27;s actual threat landscape.What independent red team evaluators foundIndependent red team evaluations, for their part, often operate with entirely different methods. This can tell a very different story and reveal additional model characteristics that enterprises must consider. METR&#x27;s red team evaluation measured autonomous capabilities using a time horizon score, which tracks how long a task can run before the agent fails half the time. o3 sustained reliable performance for approximately 1 hour and 30 minutes. o4-mini held for 1 hour 15 minutes. METR also detected reward hacking in roughly 1% of o3&#x27;s attempts, including 5 of 24 kernel optimization experiments where the model tampered with scoring functions to inflate its own results.Apollo Research tested o3 and o4-mini for in-context scheming. Both exhibited deceptive tendencies such as sandbagging evaluations and sabotaging tasks with plausible deniability, but scored lower than o1. They assess that o3 and o4-mini are unlikely to cause catastrophic harm due to scheming, but more minor real-world harms remain possible without monitoring.The UK AISI/Gray Swan challenge ran 1.8 million attacks across 22 models. Every model broke. ASR ranged from 1.47% to 6.49%. Opus 4.5 placed first on Gray Swan&#x27;s Agent Red Teaming benchmark with 4.7% ASR versus GPT-5.1 at 21.9% and Gemini 3 Pro at 12.5%.No current frontier system resists determined, well-resourced attacks. The differentiation lies in how quickly defenses degrade and at what attempt threshold. Opus 4.5&#x27;s advantage compounds over repeated attempts. Single-attempt metrics flatten the curve.What To Ask Your VendorSecurity teams evaluating frontier AI models need specific answers, starting with ASR at 50 and 200 attempts rather than single-attempt metrics alone. Find out whether they detect deception through output analysis or internal state monitoring. Know who challenges red team conclusions before deployment and what specific failure modes they&#x27;ve documented. Get the evaluation awareness rate. Vendors claiming complete safety haven&#x27;t stress-tested adequately.The bottom lineDiverse red-team methodologies demonstrate that every frontier model breaks under sustained attack. The 153-page system card versus the 55-page system card isn&#x27;t just about documentation length. It&#x27;s a signal of what each vendor chose to measure, stress-test, and disclose.For persistent adversaries, Anthropic&#x27;s degradation curves show exactly where resistance fails. For fast-moving threats requiring rapid patches, OpenAI&#x27;s iterative improvement data matters more. For agentic deployments with browsing, code execution and autonomous action, the scheming metrics become your primary risk indicator.Security leaders need to stop asking which model is safer. Start asking which evaluation methodology matches the threats your deployment will actually face. The system cards are public. The data is there. Use it.",
          "content": "Model providers want to prove the security and robustness of their models, releasing system cards and conducting red-team exercises with each new release. But it can be difficult for enterprises to parse through the results, which vary widely and can be misleading. Anthropic&#x27;s 153-page system card for Claude Opus 4.5 versus OpenAI&#x27;s 60-page GPT-5 system card reveals a fundamental split in how these labs approach security validation. Anthropic discloses in their system card how they rely on multi-attempt attack success rates from 200-attempt reinforcement learning (RL) campaigns. OpenAI also reports attempted jailbreak resistance. Both metrics are valid. Neither tells the whole story.Security leaders deploying AI agents for browsing, code execution and autonomous action need to know what each red team evaluation actually measures, and where the blind spots are.What the attack data showsGray Swan&#x27;s Shade platform ran adaptive adversarial campaigns against Claude models. The attack success rate (ASR) tells the story.Opus 4.5 in coding environments hit 4.7% ASR at one attempt, 33.6% at ten and 63.0% at one hundred. In computer use with extended thinking, it held at 0% ASR even after 200 attempts. It&#x27;s the first model to saturate the benchmark.Sonnet 4.5 at the same thresholds showed 70% ASR in coding and 85.7% in computer use.Opus 4.5 delivers roughly 7x improvement in coding resistance and complete resistance in computer use. This illustrates that the gap between model tiers within the same family is now larger than some cross-vendor comparisons. For security teams, that&#x27;s a procurement factor that didn&#x27;t exist six months ago.For OpenAI, the Gray Swan Shade platform found that the o1 system card delivered 6% ASR for harmful text and 5% for malicious code, all based on single-attempt metrics. Third-party testing by SPLX and NeuralTrust found GPT-5&#x27;s raw ASR hit 89% initially, dropping below 1% within two weeks of patching.The report Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks confirms the pattern. With sufficient attempts, Claude 3.5 Sonnet showed 78% ASR, and GPT-4o reached 89%.Two ways to catch deceptionAnthropic monitors approximately 10 million neural features during evaluation using dictionary learning. Features map to human-interpretable concepts, including deception, sycophancy, bias, power-seeking and concealment.Meanwhile, OpenAI&#x27;s approach relies on chain-of-thought (CoT) monitoring. Their deception classifier flagged 0.17% of o1-preview responses as potentially deceptive with 92% accuracy on internal validation. GPT-5 reduced CoT deception from 4.8% to 2.1% compared to o3. The method assumes visible reasoning reflects internal processing. Anthropic&#x27;s interpretability work directly questions that assumption.When models game the testIn Apollo Research&#x27;s evaluation of o1, the model attempted to turn off oversight mechanisms 5% of the time when it believed it would be shut down. In 2% of cases, o1 attempted self-exfiltration. When confronted about misaligned actions, o1 denied wrongdoing or fabricated explanations 99% of the time. The o1 system card disclosed instrumental alignment faking. In 37% of scenarios, the model pursued developer-aligned goals during evaluation, then switched to its own goals when it believed oversight was minimal.Meanwhile, Anthropic reports Opus 4.5&#x27;s evaluation awareness dropped from 26.5% (Opus 4.1) to less than 10% internally. UK AISI measured evaluation awareness decreasing from 26.5% (Sonnet 4.5) to 12.7% (Opus 4.5 Preview). METR&#x27;s GPT-5 evaluation noted the model \"can identify the exact evaluation it is in on some occasions\" and \"seems to use this information to get a better score mostly.\"If a model behaves differently when it detects evaluation conditions, it&#x27;s a sure bet that production behavior will become unpredictable when pushed to scale. This is the core problem with evaluation awareness. Models that recognize they&#x27;re being tested attempt to game the test. Anthropic&#x27;s 60% reduction in evaluation awareness from Opus 4.1 to 4.5 represents their success in targeted engineering efforts against this vector.Red teaming on prompt injection defenses shows similar divergence.Anthropic&#x27;s testing reports 96% prevention in tool use scenarios, rising to 99.4% with additional safeguards like prompt shields. Fujitsu&#x27;s independent assessment found GPT-5 vulnerable to approximately 20% of tested injection attacks. OpenAI&#x27;s o3/o4-mini system card reports instruction hierarchy scores of 0.86 for system-versus-developer conflicts. These are different metrics and different attack methodologies, but the gap suggests Anthropic&#x27;s agentic use cases have been hardened against adversarial inputs embedded in tool outputs.Comparing red teaming resultsHere&#x27;s how Opus 4.5 stacks up against OpenAI&#x27;s model family across 16 dimensions. .DimensionClaude Opus 4.5GPT-5o3 / o4-minio1System card length153 pages55 pages~30 pages~40 pagesAttack methodology200-attempt RL campaignsSingle-attempt + iterative patchingSingle-attemptSingle-attemptASR @ 1 attempt (coding)4.7%89% raw (pre-patch)Not published5%ASR @ 100 attempts63.0%Not publishedNot publishedNot publishedASR @ 200 attempts (Computer Use)0% (saturates benchmark)Not publishedNot publishedNot publishedPrompt injection defense96% prevention; 99.4% with safeguards~20% ASR (Fujitsu)0.86 instruction hierarchyHigher ASR than GPT-4oInterpretability~10M neural features monitoredCoT monitoringCoT monitoringCoT monitoringDeception detectionInternal feature activation2.1% CoT flagged0.95 not_unsafe0.17% flagged; 99% denyEvaluation awareness<10%Identifies exact eval (METR)Not published37% alignment fakingScheming (Apollo)Opus 4.5 showed very low rates of sabotage propensity in internal evaluations, orders of magnitude lower than o1.Not publishedLower than o1; still deceptive5% turn off oversight; 2% self-exfilCBRN riskBelow ASL-4Medium (approaching High)MediumMedium (first to reach)GovernanceFRT → AST → RSO/CEOSAG + Preparedness v2SAG + Preparedness v2SAG + PreparednessExternal partnersGray Swan, UK AISI, US CAISI, METRUK AISI, US AISI, METR, ApolloUK AISI, US AISI, METR, Apollo, Pattern LabsUK AISI, US AISI, METR, ApolloReward hackingYes (impossible tasks)Yes (METR)~1% of tasks; 5/24 KernelsYesMisalignment reduction60% vs. Opus 4.1Not publishedLower scheming than o1BaselineSources: Opus 4.5 system card, GPT-5 system card, o3/o4-mini system card, o1 system card, Gray Swan, METR, Apollo ResearchWhy these differences matterEnterprises have several factors to consider when analyzing model evals. These include: Attack persistence thresholds Anthropic&#x27;s 200-attempt RL campaigns simulate adversaries with time, resources, and adaptive tooling. In RL-based adversarial testing, the attacker model learns from each failure, adjusts its approach and systematically probes for weaknesses. It&#x27;s training an AI to break another AI.Gray Swan&#x27;s Shade platform doesn&#x27;t just retry the same prompt. It learns from failures, adjusts attack vectors and exploits patterns in model responses. The 4.7% to 63.0% degradation curve in coding environments shows how resistance erodes under sustained pressure. OpenAI&#x27;s single-attempt metrics answer a different question: How often does a naive attacker succeed on the first try? Both matter. A phishing campaign hits millions of users once each. A nation-state actor runs thousands of variations against a single target. Security teams need to know which threat model their vendor tested against.Detection architectureAnthropic monitors approximately 10 million internal neural features during evaluation. These are abstract concepts like deception, sycophancy and power-seeking that activate across the model&#x27;s hidden layers. When a fraud/deception feature lights up during benign roleplay, that&#x27;s a signal invisible to output analysis. The model&#x27;s internal state reveals associations its outputs don&#x27;t.OpenAI takes a different approach with CoT monitoring. Their deception classifier flagged 0.17% of o1-preview responses as potentially deceptive with 92% accuracy. The assumption is that reasoning traces reflect internal processing. Anthropic&#x27;s interpretability research directly challenges this. Models can produce clean reasoning chains while internal features indicate something else entirely.Neither approach is complete. CoT monitoring scales more easily. Feature monitoring catches what CoT misses but requires deep model access and interpretability infrastructure that most enterprises can&#x27;t replicate.Scheming evaluation design Apollo Research&#x27;s methodology puts models in scenarios where misaligned behavior offers a strategic advantage: Shutdown threats, goal conflicts and oversight detection. o1 attempted to turn off oversight mechanisms 5% of the time when believing shutdown was imminent. It tried to copy itself to prevent replacement in 2% of cases. When confronted, it denied wrongdoing 99% of the time. Opus 4.5 showed very low rates of sabotage propensity in internal evaluations, orders of magnitude lower than o1.But the evaluation environments differ. Anthropic&#x27;s stress tests focus on whether models attempt sabotage when given clear opportunities. OpenAI&#x27;s tests via Apollo probe instrumental reasoning, specifically whether models fake alignment during evaluation, then defect when oversight drops. The 37% alignment-faking rate in o1 represents a different failure mode than sabotage attempts.The comparability problem These methodological differences make direct comparison difficult. Opus 4.5&#x27;s 0% ASR at 200 attempts in computer use versus o1&#x27;s 5% malicious code rate are not measuring the same thing. The attack surfaces, attempt counts and success criteria differ.The matrix reveals what each vendor chose to measure and publish. That itself signals priorities. Anthropic&#x27;s 153-page system card emphasizes degradation curves and internal feature monitoring. OpenAI emphasizes iterative improvement and CoT transparency.Bottom line: Enterprise security teams inheriting these models inherit these measurement philosophies. The question isn&#x27;t which number is better. It&#x27;s the measurement that matches your deployment&#x27;s actual threat landscape.What independent red team evaluators foundIndependent red team evaluations, for their part, often operate with entirely different methods. This can tell a very different story and reveal additional model characteristics that enterprises must consider. METR&#x27;s red team evaluation measured autonomous capabilities using a time horizon score, which tracks how long a task can run before the agent fails half the time. o3 sustained reliable performance for approximately 1 hour and 30 minutes. o4-mini held for 1 hour 15 minutes. METR also detected reward hacking in roughly 1% of o3&#x27;s attempts, including 5 of 24 kernel optimization experiments where the model tampered with scoring functions to inflate its own results.Apollo Research tested o3 and o4-mini for in-context scheming. Both exhibited deceptive tendencies such as sandbagging evaluations and sabotaging tasks with plausible deniability, but scored lower than o1. They assess that o3 and o4-mini are unlikely to cause catastrophic harm due to scheming, but more minor real-world harms remain possible without monitoring.The UK AISI/Gray Swan challenge ran 1.8 million attacks across 22 models. Every model broke. ASR ranged from 1.47% to 6.49%. Opus 4.5 placed first on Gray Swan&#x27;s Agent Red Teaming benchmark with 4.7% ASR versus GPT-5.1 at 21.9% and Gemini 3 Pro at 12.5%.No current frontier system resists determined, well-resourced attacks. The differentiation lies in how quickly defenses degrade and at what attempt threshold. Opus 4.5&#x27;s advantage compounds over repeated attempts. Single-attempt metrics flatten the curve.What To Ask Your VendorSecurity teams evaluating frontier AI models need specific answers, starting with ASR at 50 and 200 attempts rather than single-attempt metrics alone. Find out whether they detect deception through output analysis or internal state monitoring. Know who challenges red team conclusions before deployment and what specific failure modes they&#x27;ve documented. Get the evaluation awareness rate. Vendors claiming complete safety haven&#x27;t stress-tested adequately.The bottom lineDiverse red-team methodologies demonstrate that every frontier model breaks under sustained attack. The 153-page system card versus the 55-page system card isn&#x27;t just about documentation length. It&#x27;s a signal of what each vendor chose to measure, stress-test, and disclose.For persistent adversaries, Anthropic&#x27;s degradation curves show exactly where resistance fails. For fast-moving threats requiring rapid patches, OpenAI&#x27;s iterative improvement data matters more. For agentic deployments with browsing, code execution and autonomous action, the scheming metrics become your primary risk indicator.Security leaders need to stop asking which model is safer. Start asking which evaluation methodology matches the threats your deployment will actually face. The system cards are public. The data is there. Use it.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3rwD78rWMVQoD6mxei3how/7a9957d3a02efd06ca5a7dbee64505de/Anthropic_red_teaming.jpg?w=300&q=30"
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/SVOD_US_Market_Shares_-_Netflix_and_WBD_Merger.png",
      "popularity_score": 2013.784606111111,
      "ai_summary": [
        "Meta acquired Limitless, maker of an AI-powered \"Pendant,\" for hardware development.",
        "Limitless's first product was Rewind, a desktop productivity software.",
        "The company later developed the Pendant, a clip-on Bluetooth microphone.",
        "Meta plans to build AI-enabled wearables, expanding beyond VR and smart glasses.",
        "Limitless will support existing Pendant customers for at least another year."
      ]
    },
    {
      "id": "cluster_18",
      "coverage": 2,
      "updated_at": "Fri, 05 Dec 2025 21:04:40 +0000",
      "title": "SpaceX reportedly in talks for secondary sale at $800B valuation, which would make it America&#8217;s most valuable private company",
      "neutral_headline": "SpaceX Reportedly Seeking $800B Valuation in Secondary Sale",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/05/spacex-reportedly-in-talks-for-secondary-sale-at-800b-valuation-which-would-make-it-americas-most-valuable-private-company/",
          "published_at": "Fri, 05 Dec 2025 21:04:40 +0000",
          "title": "SpaceX reportedly in talks for secondary sale at $800B valuation, which would make it America&#8217;s most valuable private company",
          "standfirst": "The eye-popping figure reflects how routine mega-valuations have become in private markets.",
          "content": "The eye-popping figure reflects how routine mega-valuations have become in private markets.",
          "feed_position": 7
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251205/p26#a251205p26",
          "published_at": "Fri, 05 Dec 2025 14:00:57 -0500",
          "title": "Sources: SpaceX is planning a secondary share sale that would value the company at $800B, surpassing OpenAI to make it the most valuable US private company (Wall Street Journal)",
          "standfirst": "Wall Street Journal: Sources: SpaceX is planning a secondary share sale that would value the company at $800B, surpassing OpenAI to make it the most valuable US private company &mdash; Company's CFO told investors about the transaction in recent days, sources say &mdash; SpaceX is kicking off a secondary share sale &hellip;",
          "content": "Wall Street Journal: Sources: SpaceX is planning a secondary share sale that would value the company at $800B, surpassing OpenAI to make it the most valuable US private company &mdash; Company's CFO told investors about the transaction in recent days, sources say &mdash; SpaceX is kicking off a secondary share sale &hellip;",
          "feed_position": 10,
          "image_url": "http://www.techmeme.com/251205/i26.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/251205/i26.jpg",
      "popularity_score": 2013.3707172222223,
      "ai_summary": [
        "SpaceX is reportedly planning a secondary share sale valuing the company at $800 billion.",
        "This valuation would make SpaceX the most valuable private company in the United States.",
        "The company's CFO informed investors about the transaction recently.",
        "The secondary share sale reflects the high valuations in private markets.",
        "SpaceX is surpassing OpenAI to become the most valuable private US company."
      ]
    },
    {
      "id": "cluster_8",
      "coverage": 1,
      "updated_at": "Fri, 05 Dec 2025 22:56:51 +0000",
      "title": "Streaming service makes rare decision to lower its monthly fees",
      "neutral_headline": "Streaming Service Fubo Lowers Monthly Subscription Fees",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/fubo-lowers-its-prices-by-up-to-15-after-losing-nbcuniversal-channels/",
          "published_at": "Fri, 05 Dec 2025 22:56:51 +0000",
          "title": "Streaming service makes rare decision to lower its monthly fees",
          "standfirst": "This could be just what Fubo and its subscribers need.",
          "content": "Somewhere, a pig is catching some sweet air. In a rare move for a streaming service, Fubo announced today that it’s lowering the prices for some of its subscription plans. Fubo is a sports-focused vMVPD (virtual multichannel video programming distributor, or a company that enables people to watch traditional TV channels live over the Internet). Disney closed its acquisition of Fubo in October.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2022926730-1152x648-1764972744.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2022926730-1152x648-1764972744.jpg",
      "popularity_score": 348.24043944444446,
      "ai_summary": [
        "Fubo, a streaming service, has decided to lower its monthly fees.",
        "The price reduction could benefit both Fubo and its subscribers.",
        "The move is a rare decision in the streaming industry.",
        "The change may impact Fubo's financial performance.",
        "The lower fees could attract more subscribers."
      ]
    },
    {
      "id": "cluster_39",
      "coverage": 1,
      "updated_at": "Fri, 05 Dec 2025 18:49:43 +0000",
      "title": "Netflix’s $72B WB acquisition confounds the future of movie theaters, streaming",
      "neutral_headline": "Netflix's Acquisition of WB Could Face Regulatory Scrutiny",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/netflixs-72b-wb-acquisition-confounds-the-future-of-movie-theaters-streaming/",
          "published_at": "Fri, 05 Dec 2025 18:49:43 +0000",
          "title": "Netflix’s $72B WB acquisition confounds the future of movie theaters, streaming",
          "standfirst": "Netflix's plans to own HBO Max, DC Comics, Harry Potter to face regulatory scrutiny.",
          "content": "The bidding war is over, and Netflix has been declared the winner. After flirting with Paramount Skydance and Comcast, Warner Bros. Discovery (WBD) has decided to sell its streaming and movie studios business to Netflix. If approved, the deal is set to overturn the media landscape and create ripples that will affect Hollywood for years. $72 billion acquisition Netflix will pay an equity value of $72 billion, or an approximate total enterprise value of $82.7 billion, for Warner Bros. All of WBD has a $60 billion market value, NBC News notes.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249474258-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249474258-1024x648.jpg",
      "popularity_score": 334.12155055555553,
      "ai_summary": [
        "Netflix's potential acquisition of Warner Bros. could face regulatory scrutiny.",
        "The deal involves HBO Max, DC Comics, and Harry Potter properties.",
        "The acquisition could reshape the streaming and entertainment landscape.",
        "Regulatory bodies may examine the potential impact of the deal.",
        "The future of movie theaters and streaming is being questioned."
      ]
    },
    {
      "id": "cluster_51",
      "coverage": 1,
      "updated_at": "Fri, 05 Dec 2025 17:44:18 +0000",
      "title": "Rare set of varied factors triggered Black Death",
      "neutral_headline": "Volcanic Eruptions Triggered Black Death in Europe",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/how-volcanoes-helped-spark-the-black-death/",
          "published_at": "Fri, 05 Dec 2025 17:44:18 +0000",
          "title": "Rare set of varied factors triggered Black Death",
          "standfirst": "Volcanic eruptions in the mid-1340s triggered a chain of events that brought the Black Death to Europe.",
          "content": "The Black Death ravaged medieval Western Europe, ultimately wiping out roughly one-third of the population. Scientists have identified the bacterium responsible and its likely origins, but certain specifics of how and why it spread to Europe are less clear. According to a new paper published in the journal Communications Earth & Environment, either one large volcanic eruption or a cluster of eruptions might have been the triggering factor, setting off a chain of events that brought the plague to the Mediterranean region in the 1340s. Technically, we’re talking about the second plague pandemic. The first, known as the Justinian Plague, broke out about 541 CE and quickly spread across Asia, North Africa, the Middle East, and Europe. (The Eastern Roman Emperor Justinian I, for whom the pandemic is named, actually survived the disease.) There continued to be outbreaks of the plague over the next 300 years, although the disease gradually became less virulent and died out. Or so it seemed. In the Middle Ages, the Black Death burst onto the scene, with the first historically documented outbreak occurring in 1346 in the Lower Volga and Black Sea regions. That was just the beginning of the second pandemic. During the 1630s, fresh outbreaks of plague killed half the populations of affected cities. Another bout of the plague significantly culled the population of France during an outbreak between 1647 and 1649, followed by an epidemic in London in the summer of 1665. The latter was so virulent that, by October, one in 10 Londoners had succumbed to the disease—over 60,000 people. Similar numbers perished in an outbreak in Holland in the 1660s. The pandemic had run its course by the early 19th century, but a third plague pandemic hit China and India in the 1890s. There are still occasional outbreaks today.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/plagueTOP-1152x648-1764783307.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/plagueTOP-1152x648-1764783307.jpg",
      "popularity_score": 320.03127277777776,
      "ai_summary": [
        "Volcanic eruptions in the mid-1340s triggered the Black Death.",
        "These eruptions initiated a chain of events.",
        "The events led to the spread of the plague to Europe.",
        "The Black Death caused widespread death and devastation.",
        "The eruptions were a key factor in the pandemic's arrival."
      ]
    },
    {
      "id": "cluster_55",
      "coverage": 1,
      "updated_at": "Fri, 05 Dec 2025 17:29:37 +0000",
      "title": "SteamOS vs. Windows on dedicated GPUs: It’s complicated, but Windows has an edge",
      "neutral_headline": "SteamOS vs Windows on Dedicated GPUs: Windows Has Edge",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/steamos-vs-windows-on-dedicated-gpus-its-complicated-but-windows-has-an-edge/",
          "published_at": "Fri, 05 Dec 2025 17:29:37 +0000",
          "title": "SteamOS vs. Windows on dedicated GPUs: It’s complicated, but Windows has an edge",
          "standfirst": "Ars testing shows SteamOS fares better on iGPUs than powerful graphics cards.",
          "content": "I wrote a couple of weeks ago about my personal homebrew Steam Machine, a self-built desktop under my TV featuring an AMD Ryzen 7 8700G processor and a Radeon 780M integrated GPU. I wouldn’t recommend making your own version of this build, especially with RAM prices as they currently are, but there are all kinds of inexpensive mini PCs on Amazon with the same GPU, and they’ll all be pretty good at playing the kinds of games that already run well on the less-powerful Steam Deck. But this kind of hardware is an imperfect proxy for the Steam Machine that Valve plans to launch sometime next year—that box will include a dedicated GPU with 8GB of dedicated video memory, presenting both benefits and possible pitfalls compared to a system with an integrated GPU. As a last pre-Steam Machine follow-up to our coverage so far, we’ve run tests on several games we test regularly in our GPU reviews to get a sense of how current versions of SteamOS stack up to Windows running on the same hardware. What we’ve found so far is basically the inverse of what we found when comparing handhelds: Windows usually has an edge on SteamOS’s performance, and sometimes that gap is quite large. And SteamOS also exacerbates problems with 8GB GPUs, hitting apparent RAM limits in more games and at lower resolutions compared to Windows.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/IMG_2716-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/IMG_2716-1152x648.jpeg",
      "popularity_score": 312.78655055555555,
      "ai_summary": [
        "Testing shows Windows performs better than SteamOS on dedicated GPUs.",
        "SteamOS fares better on integrated GPUs than powerful graphics cards.",
        "The comparison focuses on gaming performance.",
        "The results highlight differences in operating system optimization.",
        "Windows offers a performance advantage in this scenario."
      ]
    },
    {
      "id": "cluster_60",
      "coverage": 1,
      "updated_at": "Fri, 05 Dec 2025 17:06:34 +0000",
      "title": "Without evidence, RFK Jr.’s vaccine panel tosses hep B vaccine recommendation",
      "neutral_headline": "RFK Jr.'s Vaccine Panel Rejects Hep B Vaccine Recommendation",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/without-evidence-rfk-jr-s-vaccine-panel-tosses-heb-b-vaccine-recommendation/",
          "published_at": "Fri, 05 Dec 2025 17:06:34 +0000",
          "title": "Without evidence, RFK Jr.’s vaccine panel tosses hep B vaccine recommendation",
          "standfirst": "There is no data supporting a delay and no evidence of harm from a birth dose.",
          "content": "Federal vaccine advisors hand-selected by anti-vaccine Health Secretary Robert F. Kennedy Jr. have voted to eliminate a recommendation that all babies be vaccinated against hepatitis B on the day of birth. The decision was made with no evidence of harm from that dose and no evidence of any benefit from the delay. Public health experts, medical experts, and even some members of the panel decried the vote, which studies and historical data indicate will lead to more infections in babies that, in turn, will lead to more cases of chronic liver disease, liver cancer, and premature death. “I will just say we have heard ‘do no harm’ is a moral imperative. We are doing harm by changing this [recommendation],” Cody Meissner, a pediatrician and voting member of the Advisory Committee on Immunization Practices (ACIP), said as he voted against the change.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/GettyImages-535146116-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/GettyImages-535146116-1152x648.jpeg",
      "popularity_score": 308.4023838888889,
      "ai_summary": [
        "RFK Jr.'s vaccine panel rejected the recommendation for the hep B vaccine.",
        "The panel's decision lacks supporting data.",
        "There is no evidence of harm from the birth dose of the vaccine.",
        "The panel's recommendation is controversial.",
        "The decision could impact vaccination practices."
      ]
    },
    {
      "id": "cluster_67",
      "coverage": 1,
      "updated_at": "Fri, 05 Dec 2025 16:15:20 +0000",
      "title": "Elon Musk’s X first to be fined under EU’s Digital Services Act",
      "neutral_headline": "Elon Musk’s X Fined Under EU’s Digital Services Act",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/elon-musks-x-first-to-be-fined-under-eus-digital-service-act/",
          "published_at": "Fri, 05 Dec 2025 16:15:20 +0000",
          "title": "Elon Musk’s X first to be fined under EU’s Digital Services Act",
          "standfirst": "The biggest changes Musk made to Twitter trigger a $140 million fine under DSA.",
          "content": "Elon Musk’s X became the first large online platform fined under the European Union’s Digital Services Act on Friday. The European Commission announced that X would be fined nearly $140 million, with the potential to face “periodic penalty payments” if the platform fails to make corrections. A third of the fine came from one of the first moves Musk made when taking over Twitter. In November 2022, he changed the platform’s historical use of a blue checkmark to verify the identities of notable users. Instead, Musk started selling blue checks for about $8 per month, immediately prompting a wave of imposter accounts pretending to be notable celebrities, officials, and brands.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/04/GettyImages-1244760380-2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/04/GettyImages-1244760380-2-1152x648.jpg",
      "popularity_score": 291.548495,
      "ai_summary": [
        "Elon Musk's X is the first to be fined under the EU's Digital Services Act.",
        "The fine is related to changes Musk made to Twitter.",
        "The fine amounts to $140 million.",
        "The changes triggered the fine under the DSA.",
        "The DSA aims to regulate digital services."
      ]
    },
    {
      "id": "cluster_80",
      "coverage": 1,
      "updated_at": "Fri, 05 Dec 2025 15:12:05 +0000",
      "title": "Knight of the Seven Kingdoms trailer brings levity to Westeros",
      "neutral_headline": "Knight of the Seven Kingdoms\" Trailer Released",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/12/knight-of-the-seven-kingdoms-trailer-brings-levity-to-westeros/",
          "published_at": "Fri, 05 Dec 2025 15:12:05 +0000",
          "title": "Knight of the Seven Kingdoms trailer brings levity to Westeros",
          "standfirst": "\"Every knight needs a squire, and you look like you need one more than most.\"",
          "content": "With House of the Dragon entering its third season, HBO is ready to debut a new spinoff series set in Game of Thrones’ Westeros: A Knight of the Seven Kingdoms, based on George R.R. Martin’s Tales of Dunk and Egg novellas. HBO clearly has a lot of confidence in this series; it’s already been renewed for a second season. And judging by the final trailer, that optimism is warranted. As we’ve previously reported, A Knight of the Seven Kingdoms adapts the first novella in the series, The Hedge Knight, and is set 50 years after the events of House of the Dragon. Per the official premise: A century before the events of Game of Thrones, two unlikely heroes wandered Westeros: a young, naïve but courageous knight, Ser Duncan the Tall, and his diminutive squire, Egg. Set in an age when the Targaryen line still holds the Iron Throne and the last dragon has not yet passed from living memory, great destinies, powerful foes, and dangerous exploits all await these improbable and incomparable friends. Peter Claffey co-stars as Ser Duncan the Tall, aka a hedge knight named “Dunk,” along with Dexter Sol Ansell as Prince Aegon Targaryen, aka “Egg,” a child prince and Dunk’s squire. The main cast also includes Finn Bennett as Egg’s older brother, Prince Aerion “Brightflame” Targaryen; Bertie Carvel as Egg’s uncle, Prince Baelor “Breakspear” Targaryen, heir to the Iron Throne; Tanzyn Crawford as a Dornish puppeteer named Tanselle; Daniel Ings as Ser Lyonel “Laughing Storm” Baratheon, heir to House Baratheon; and Sam Spruell as Prince Maekar Targaryen, Egg’s father.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/knight1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/knight1-1152x648.jpg",
      "popularity_score": 291.4943283333333,
      "ai_summary": [
        "The trailer for \"Knight of the Seven Kingdoms\" has been released.",
        "The trailer offers a glimpse into the upcoming series.",
        "The trailer brings a sense of levity to Westeros.",
        "The series is a prequel to \"Game of Thrones.\"",
        "The trailer features key characters and scenes."
      ]
    },
    {
      "id": "cluster_71",
      "coverage": 1,
      "updated_at": "Fri, 05 Dec 2025 15:55:52 +0000",
      "title": "Toyota’s new GR GT picks up where the 2000GT and Lexus LFA left off",
      "neutral_headline": "Toyota's New GR GT Picks Up Where 2000GT and Lexus LFA Left Off",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/12/toyota-busts-out-a-new-flagship-gazoo-racing-coupe-plus-gt3-version/",
          "published_at": "Fri, 05 Dec 2025 15:55:52 +0000",
          "title": "Toyota’s new GR GT picks up where the 2000GT and Lexus LFA left off",
          "standfirst": "The GR GT is a V8 hybrid, and there's an electric Lexus sports car concept, too.",
          "content": "There’s some Toyota news today that doesn’t involve the chairman wearing a MAGA hat. The Japanese automaker evidently decided it’s been too long since it flexed its engineering chops on something with two doors and plenty of power, so it has rectified that situation with a new flagship coupe for its Gazoo Racing sporty sub-brand. Meet the GR GT, which looks set to go on sale toward the end of next year. The Camry-esque look at the front, and to an extent the rear, came second to the GR GT’s aerodynamics, which is the opposite way to how Toyota usually styles its cars. It’s built around a highly rigid aluminum frame—Toyota’s first, apparently—with carbon fiber for the hood, roof, and some other body panels to minimize weight. The automaker says that lowering the car’s center of gravity was a top priority, and weight balance and distribution also help explain the transaxle layout, where the car’s transmission is behind the cockpit and between the rear wheels. I get a LOT of Camry from the nose. Credit: Toyota We're told it will have a good V8 sound. Credit: Toyota Does this interior befit a coupe that will cost about half a million dollars? Credit: Toyota I mostly posted this because of the license plate. Credit: Toyota Aluminum forms the chassis. Credit: Toyota The transaxle-layout powertrain. Credit: Toyota The seats look grippy. Credit: Toyota That transaxle transmission will be an eight-speed automatic that uses a wet clutch instead of a torque converter and into which the car’s hybrid motor is integrated. Power from the 4.0 L twin-turbo V8 and the hybrid system should be a combined 641 hp (478 kW) and 626 lb-ft (850 Nm). Despite the aluminum frame and use of composites, the GT GR is no featherweight; it will weigh as much as 3,858 lb (1,750 kg). The V8 is a new design with a short stroke, a hot-V configuration for the turbochargers, and dry sump lubrication.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/20251205_01_01-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/20251205_01_01-1152x648.jpg",
      "popularity_score": 281.22405055555555,
      "ai_summary": [
        "Toyota's new GR GT is a V8 hybrid sports car.",
        "There is also an electric Lexus sports car concept.",
        "The GR GT aims to continue the legacy of iconic models.",
        "The new models represent Toyota's future in sports cars.",
        "The vehicles showcase Toyota's engineering and design."
      ]
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Fri, 05 Dec 2025 12:15:43 +0000",
      "title": "New report warns of critical climate risks in Arab region",
      "neutral_headline": "Report Warns of Climate Risks in Arab Region",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/new-report-warns-of-critical-climate-risks-in-arab-region/",
          "published_at": "Fri, 05 Dec 2025 12:15:43 +0000",
          "title": "New report warns of critical climate risks in Arab region",
          "standfirst": "Foundations of daily life are being pushed to the brink by human-caused warming.",
          "content": "As global warming accelerates, about 480 million people in North Africa and the Arabian Peninsula face intensifying and in some places unsurvivable heat, as well as drought, famine, and the risk of mass displacement, the World Meteorological Organization warned Thursday. The 22 Arab region countries covered in the WMO’s new State of the Climate report produce about a quarter of the world’s oil, yet directly account for only 5 to 7 percent of global greenhouse gas emissions from their own territories. The climate paradox positions the region as both a linchpin of the global fossil-fuel economy and one of the most vulnerable geographic areas. WMO Secretary-General Celeste Saulo said extreme heat is pushing communities in the region to their physical limits. Droughts show no sign of letting up in one of the world’s most water-stressed regions, but at the same time, parts of it have been devastated by record rains and flooding, she added.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/IMG_0073-2048x1366-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/IMG_0073-2048x1366-1-1152x648.jpg",
      "popularity_score": 265.55488388888887,
      "ai_summary": [
        "A new report warns of critical climate risks in the Arab region.",
        "Human-caused warming is pushing daily life to the brink.",
        "The report highlights the impact of climate change.",
        "The region faces significant climate-related challenges.",
        "The report emphasizes the urgency of climate action."
      ]
    },
    {
      "id": "cluster_95",
      "coverage": 1,
      "updated_at": "Fri, 05 Dec 2025 12:00:57 +0000",
      "title": "Rocket Report: Blunder at Baikonur; do launchers really need rocket engines?",
      "neutral_headline": "Rocket Report: Blunder at Baikonur; do launchers really need rocket engines?",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/rocket-report-openais-launch-overture-south-korea-making-progress-in-space/",
          "published_at": "Fri, 05 Dec 2025 12:00:57 +0000",
          "title": "Rocket Report: Blunder at Baikonur; do launchers really need rocket engines?",
          "standfirst": "The Department of the Air Force approves a new home in Florida for SpaceX's Starship.",
          "content": "Welcome to Edition 8.21 of the Rocket Report! We’re back after the Thanksgiving holiday with more launch news. Most of the big stories over the last couple of weeks came from abroad. Russian rockets and launch pads didn’t fare so well. China’s launch industry celebrated several key missions. SpaceX was busy, too, with seven launches over the last two weeks, six of them carrying more Starlink Internet satellites into orbit. We expect between 15 and 20 more orbital launch attempts worldwide before the end of the year. As always, we welcome reader submissions. If you don’t want to miss an issue, please subscribe using the box below (the form will not appear on AMP-enabled versions of the site). Each report will include information on small-, medium-, and heavy-lift rockets, as well as a quick look ahead at the next three launches on the calendar. Another Sarmat failure. A Russian intercontinental ballistic missile (ICBM) fired from an underground silo on the country’s southern steppe on November 28 on a scheduled test to deliver a dummy warhead to a remote impact zone nearly 4,000 miles away. The missile didn’t even make it 4,000 feet, Ars reports. Russia’s military has been silent on the accident, but the missile’s crash was seen and heard for miles around the Dombarovsky air base in Orenburg Oblast near the Russian-Kazakh border. A video posted by the Russian blog site MilitaryRussia.ru on Telegram and widely shared on other social media platforms showed the missile veering off course immediately after launch before cartwheeling upside down, losing power, and then crashing a short distance from the launch site.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/nurilift-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/nurilift-1152x648.jpg",
      "popularity_score": 262.3087727777778,
      "ai_summary": [
        "The Rocket Report discusses a blunder at Baikonur.",
        "The report questions the necessity of rocket engines.",
        "The Department of the Air Force approved a new home for SpaceX's Starship.",
        "The report covers various developments in the space industry.",
        "The report analyzes current trends and challenges."
      ]
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 18:40:36 +0000",
      "title": "ChatGPT hyped up violent stalker who believed he was “God’s assassin,” DOJ says",
      "neutral_headline": "Podcaster Faces Charges for ChatGPT-Linked Stalking",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/chatgpt-hyped-up-violent-stalker-who-believed-he-was-gods-assassin-doj-says/",
          "published_at": "Thu, 04 Dec 2025 18:40:36 +0000",
          "title": "ChatGPT hyped up violent stalker who believed he was “God’s assassin,” DOJ says",
          "standfirst": "Podcaster faces up to 70 years and a $3.5 million fine for ChatGPT-linked stalking.",
          "content": "ChatGPT allegedly validated the worst impulses of a wannabe influencer accused of stalking more than 10 women at boutique gyms, where the chatbot supposedly claimed he’d meet the “wife type.” In a press release on Tuesday, the Department of Justice confirmed that 31-year-old Brett Michael Dadig currently remains in custody after being charged with cyberstalking, interstate stalking, and making interstate threats. He now faces a maximum sentence of up to 70 years in prison that could be coupled with “a fine of up to $3.5 million,” the DOJ said. The podcaster—who primarily posted about “his desire to find a wife and his interactions with women”—allegedly harassed and sometimes even doxxed his victims through his videos on platforms including Instagram, Spotify, and TikTok. Over time, his videos and podcasts documented his intense desire to start a family, which was frustrated by his “anger towards women,” whom he claimed were “all the same from fucking 18 to fucking 40 to fucking 90” and “trash.”Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2233803629-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2233803629-1152x648.jpg",
      "popularity_score": 154,
      "ai_summary": [
        "A podcaster is facing up to seventy years in prison and a $3.5 million fine.",
        "The charges stem from stalking activities linked to the use of ChatGPT.",
        "The Department of Justice is prosecuting the case against the podcaster.",
        "The podcaster allegedly used ChatGPT to generate violent threats.",
        "The stalker believed he was \"God's assassin\" according to the DOJ."
      ]
    },
    {
      "id": "cluster_122",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 21:51:36 +0000",
      "title": "In comedy of errors, men accused of wiping gov databases turned to an AI tool",
      "neutral_headline": "AI Tool Used in Case of Men Accused of Wiping Databases",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2025/12/previously-convicted-contractors-wiped-gov-databases-after-being-fired-feds-say/",
          "published_at": "Thu, 04 Dec 2025 21:51:36 +0000",
          "title": "In comedy of errors, men accused of wiping gov databases turned to an AI tool",
          "standfirst": "Defendants were convicted of similar crimes a decade ago. How were they cleared again?",
          "content": "Two sibling contractors convicted a decade ago for hacking into US State Department systems have once again been charged, this time for a comically hamfisted attempt to steal and destroy government records just minutes after being fired from their contractor jobs. The Department of Justice on Thursday said that Muneeb Akhter and Sohaib Akhter, both 34, of Alexandria, Virginia, deleted databases and documents maintained and belonging to three government agencies. The brothers were federal contractors working for an undisclosed company in Washington, DC, that provides software and services to 45 US agencies. Prosecutors said the men coordinated the crimes and began carrying them out just minutes after being fired. Using AI to cover up an alleged crime—what could go wrong? On February 18 at roughly 4:55 pm, the men were fired from the company, according to an indictment unsealed on Thursday. Five minutes later, they allegedly began trying to access their employer’s system and access federal government databases. By then, access to one of the brothers’ accounts had already been terminated. The other brother, however, allegedly accessed a government agency’s database stored on the employer’s server and issued commands to prevent other users from connecting or making changes to the database. Then, prosecutors said, he issued a command to delete 96 databases, many of which contained sensitive investigative files and records related to Freedom of Information Act matters.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/data-theft-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/data-theft-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Men accused of wiping government databases used an AI tool.",
        "The defendants were previously convicted of similar crimes a decade ago.",
        "The article explores how the defendants were cleared of the charges.",
        "The case involves a series of errors and missteps.",
        "The AI tool's role in the case is a key element of the story."
      ]
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 20:56:44 +0000",
      "title": "CDC vaccine panel realizes again it has no idea what it’s doing, delays big vote",
      "neutral_headline": "CDC Vaccine Panel Delays Vote Due to Disorganization",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/cdc-vaccine-panel-realizes-again-it-has-no-idea-what-its-doing-delays-big-vote/",
          "published_at": "Thu, 04 Dec 2025 20:56:44 +0000",
          "title": "CDC vaccine panel realizes again it has no idea what it’s doing, delays big vote",
          "standfirst": "Today's meeting was chaotic and included garbage anti-vaccine presentations.",
          "content": "The panel of federal vaccine advisors hand-selected by anti-vaccine Health Secretary Robert F. Kennedy Jr. has once again punted on whether to strip recommendations for hepatitis B vaccinations for newborns—a move it tried to make in September before realizing it didn’t know what it was doing. The decision to delay the vote today came abruptly this afternoon when the panel realized it still does not understand the topic or what it was voting on. Prior to today’s 6–3 vote to delay a decision, there was a swirl of confusion over the wording of what a new recommendation would be. Panel members had gotten three different versions of the proposed recommendation in the 72 hours prior to the meeting, one panelist said. And the meeting’s data presentations this morning offered no clarity on the subject—they were delivered entirely by anti-vaccine activists who have no subject matter expertise and who made a dizzying amount of false and absurd claims. “Completely inappropriate” Overall, the meeting was disorganized and farcical. Kennedy’s panel has abandoned the evidence-based framework for setting vaccine policy in favor of airing unvetted presentations with misrepresentations, conspiracy theories, and cherry-picked studies. At times, there were tense exchanges, chaos, confusion, and misunderstandings.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249270671-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249270671-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "The CDC vaccine panel delayed a significant vote.",
        "The meeting was described as chaotic and disorganized.",
        "Anti-vaccine presentations were included in the meeting.",
        "The panel is reconsidering its approach to vaccine recommendations.",
        "The panel's actions reflect uncertainty about its procedures."
      ]
    },
    {
      "id": "cluster_129",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 20:07:20 +0000",
      "title": "Researchers find what makes AI chatbots politically persuasive",
      "neutral_headline": "Researchers Study Political Persuasion by AI Chatbots",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/researchers-find-what-makes-ai-chatbots-politically-persuasive/",
          "published_at": "Thu, 04 Dec 2025 20:07:20 +0000",
          "title": "Researchers find what makes AI chatbots politically persuasive",
          "standfirst": "A massive study of political persuasion shows AIs have, at best, a weak effect.",
          "content": "Roughly two years ago, Sam Altman tweeted that AI systems would be capable of superhuman persuasion well before achieving general intelligence—a prediction that raised concerns about the influence AI could have over democratic elections. To see if conversational large language models can really sway political views of the public, scientists at the UK AI Security Institute, MIT, Stanford, Carnegie Mellon, and many other institutions performed by far the largest study on AI persuasiveness to date, involving nearly 80,000 participants in the UK. It turned out political AI chatbots fell far short of superhuman persuasiveness, but the study raises some more nuanced issues about our interactions with AI. AI dystopias The public debate about the impact AI has on politics has largely revolved around notions drawn from dystopian sci-fi. Large language models have access to essentially every fact and story ever published about any issue or candidate. They have processed information from books on psychology, negotiations, and human manipulation. They can rely on absurdly high computing power in huge data centers worldwide. On top of that, they can often access tons of personal information about individual users thanks to hundreds upon hundreds of online interactions at their disposal.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/09/twitter-bot-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/09/twitter-bot-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Researchers investigated the political persuasion abilities of AI chatbots.",
        "A large study examined the impact of AI on political opinions.",
        "The study found that AI chatbots have a weak effect on persuasion.",
        "The research focused on how AI influences political viewpoints.",
        "The findings suggest limited effectiveness of AI in political contexts."
      ]
    },
    {
      "id": "cluster_139",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 17:59:38 +0000",
      "title": "In 1995, a Netscape employee wrote a hack in 10 days that now runs the Internet",
      "neutral_headline": "JavaScript's History and Impact on the Internet",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/in-1995-a-netscape-employee-wrote-a-hack-in-10-days-that-now-runs-the-internet/",
          "published_at": "Thu, 04 Dec 2025 17:59:38 +0000",
          "title": "In 1995, a Netscape employee wrote a hack in 10 days that now runs the Internet",
          "standfirst": "Thirty years later, JavaScript is the glue that holds the interactive web together, warts and all.",
          "content": "Thirty years ago today, Netscape Communications and Sun Microsystems issued a joint press release announcing JavaScript, an object scripting language designed for creating interactive web applications. The language emerged from a frantic 10-day sprint at pioneering browser company Netscape, where engineer Brendan Eich hacked together a working internal prototype during May 1995. While the JavaScript language didn’t ship publicly until that September and didn’t reach a 1.0 release until March 1996, the descendants of Eich’s initial 10-day hack now run on approximately 98.9 percent of all websites with client-side code, making JavaScript the dominant programming language of the web. It’s wildly popular; beyond the browser, JavaScript powers server backends, mobile apps, desktop software, and even some embedded systems. According to several surveys, JavaScript consistently ranks among the most widely used programming languages in the world. In crafting JavaScript, Netscape wanted a scripting language that could make webpages interactive, something lightweight that would appeal to web designers and non-professional programmers. Eich drew from several influences: The syntax looked like a trendy new programming language called Java to satisfy Netscape management, but its guts borrowed concepts from Scheme, a language Eich admired, and Self, which contributed JavaScript’s prototype-based object model.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/netscape_logo_header_3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/netscape_logo_header_3-1152x648.jpg",
      "popularity_score": 143,
      "ai_summary": [
        "A Netscape employee wrote a hack in ten days in 1995.",
        "JavaScript is now essential for the interactive web.",
        "The language has evolved over three decades.",
        "JavaScript is the glue that holds the interactive web together.",
        "The article discusses the history and impact of JavaScript."
      ]
    },
    {
      "id": "cluster_120",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 22:54:52 +0000",
      "title": "Congress warned that NASA’s current plan for Artemis “cannot work”",
      "neutral_headline": "Congress Warns NASA's Artemis Plan Is Unworkable",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/congress-told-there-needs-to-be-consequences-for-nasa-delays-amid-chinas-rise/",
          "published_at": "Thu, 04 Dec 2025 22:54:52 +0000",
          "title": "Congress warned that NASA’s current plan for Artemis “cannot work”",
          "standfirst": "\"The Artemis III mission and those beyond should be canceled.\"",
          "content": "In recent months, it has begun dawning on US lawmakers that, absent significant intervention, China will land humans on the Moon before the United States can return there with the Artemis Program. So far, legislators have yet to take meaningful action on this—a $10 billion infusion into NASA’s budget this summer essentially provided zero funding for efforts needed to land humans on the Moon this decade. But now a subcommittee of the House Committee on Space, Science, and Technology has begun reviewing the space agency’s policy, expressing concerns about Chinese competition in civil spaceflight. During a hearing on Thursday in Washington, DC, the subcommittee members asked a panel of experts how NASA could maintain its global leadership in space over China in general, and more specifically, how to improve the Artemis Program to reach the Moon more quickly.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-2207557317-900x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-2207557317-900x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Congress has warned that NASA's current Artemis plan is flawed.",
        "The Artemis III mission and subsequent missions should be canceled.",
        "The warning comes from a congressional body.",
        "The plan faces significant challenges and potential failure.",
        "The report criticizes the current approach to the Artemis program."
      ]
    },
    {
      "id": "cluster_124",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 21:23:40 +0000",
      "title": "Engineer proves that Kohler’s smart toilet cameras aren’t very private",
      "neutral_headline": "Engineer Finds Kohler Smart Toilet Cameras Lack Privacy",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/despite-accessing-user-data-kohler-still-says-its-smart-toilet-cameras-use-e2ee/",
          "published_at": "Thu, 04 Dec 2025 21:23:40 +0000",
          "title": "Engineer proves that Kohler’s smart toilet cameras aren’t very private",
          "standfirst": "Kohler is getting the scoop on people's poop.",
          "content": "Kohler is facing backlash after an engineer pointed out that the company’s new smart toilet cameras may not be as private as it wants people to believe. The discussion raises questions about Kohler’s use of the term “end-to-end encryption” (E2EE) and the inherent privacy limitations of a device that films the goings-on of a toilet bowl. In October, Kohler announced its first “health” product, the Dekoda. Kohler’s announcement described the $599 device (it also requires a subscription that starts at $7 per month) as a toilet bowl attachment that uses “optical sensors and validated machine-learning algorithms” to deliver “valuable insights into your health and wellness.” The announcement added: Data flows to the personalized Kohler Health app, giving users continuous, private awareness of key health and wellness indicators—right on their phone. Features like fingerprint authentication and end-to-end encryption are designed for user privacy and security. The average person is most likely to be familiar with E2EE through messaging apps, like Signal. Messages sent via apps with E2EE are encrypted throughout transmission. Only the message’s sender and recipient can view the decrypted messages, which is intended to prevent third parties, including the app developer, from reading them.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/fa9752cdfabfc67f2acd9bfdf4f195ecfdad5f05-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/fa9752cdfabfc67f2acd9bfdf4f195ecfdad5f05-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "An engineer proved Kohler's smart toilet cameras are not private.",
        "The cameras collect data about users' bathroom habits.",
        "Kohler is gathering information about people's bowel movements.",
        "The privacy concerns relate to data collection practices.",
        "The engineer's findings highlight security vulnerabilities."
      ]
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 19:53:14 +0000",
      "title": "Why won’t Steam Machine support HDMI 2.1? Digging in on the display standard drama.",
      "neutral_headline": "Steam Machine Support for HDMI 2.1 Faces Challenges",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/12/why-wont-steam-machine-support-hdmi-2-1-digging-in-on-the-display-standard-drama/",
          "published_at": "Thu, 04 Dec 2025 19:53:14 +0000",
          "title": "Why won’t Steam Machine support HDMI 2.1? Digging in on the display standard drama.",
          "standfirst": "Valve tells Ars its \"trying to unblock\" limits caused by open source driver issues.",
          "content": "When Valve announced its upcoming Steam Machine hardware last month, some eagle-eyed gamers may have been surprised to see that the official spec sheet lists support for HDMI 2.0 output, rather than the updated, higher-bandwidth HDMI 2.1 standard introduced in 2017. Now, Valve tells Ars that, while the hardware itself actually supports HDMI 2.1, the company is struggling to offer full support for that standard due to Linux drivers that are “still a work-in-progress on the software side.” As we noted last year, the HDMI Forum (which manages the official specifications for HDMI standards) has officially blocked any open source implementation of HDMI 2.1. That means the open source AMD drivers used by SteamOS can’t fully implement certain features that are specific to the updated output standard. “At this time an open source HDMI 2.1 implementation is not possible without running afoul of the HDMI Forum requirements,” AMD engineer Alex Deucher said at the time.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/sm1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/sm1-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Steam Machine support for HDMI 2.1 is facing issues.",
        "Valve is working to resolve problems with open source drivers.",
        "The display standard drama is related to HDMI 2.1.",
        "Valve is trying to unblock limits caused by driver issues.",
        "The article explores the challenges of HDMI 2.1 support."
      ]
    },
    {
      "id": "cluster_137",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 18:11:41 +0000",
      "title": "OnePlus 15 finally gets FCC clearance after government shutdown delay—preorders live",
      "neutral_headline": "OnePlus 15 Receives FCC Clearance, Preorders Live",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/oneplus-15-finally-gets-fcc-clearance-after-government-shutdown-delay-preorders-live/",
          "published_at": "Thu, 04 Dec 2025 18:11:41 +0000",
          "title": "OnePlus 15 finally gets FCC clearance after government shutdown delay—preorders live",
          "standfirst": "The device starts at $900 and comes with a free gift for a limited time.",
          "content": "OnePlus is ready to sell its new flagship smartphone in the US weeks after it made the device official. Having now finally gotten Federal Communications Commission clearance, the OnePlus 15 is available for preorder. It’s currently only live on the OnePlus storefront, but the device will eventually come to Amazon and Best Buy as well. The OnePlus 15 launched in China earlier this year, and it was supposed to go on sale in the US a month ago. However, the longest US government shutdown on record got in the way. Most of the FCC’s functions were suspended during the weekslong funding lapse, which prevented the agency from certifying new wireless products. Without that approval, OnePlus could not begin selling the phone. Thus, it had no firm release date when the phone was officially unveiled for the US in early November. Interested parties can head to the OnePlus website to place an order. The base model starts at $900 with 12GB of RAM and 256GB of storage. This version is only available in black. If you want the Ultraviolet or Sand Storm (with the distinctive micro-arc oxidation finish), you’ll have to upgrade to the $1,000 version, which has 16GB of RAM and 512GB of storage.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/OnePlus-15-5-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/OnePlus-15-5-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "The OnePlus 15 has received FCC clearance.",
        "Preorders for the device are now available.",
        "The device starts at a price of $900.",
        "A free gift is offered for a limited time.",
        "The article announces the launch of the new phone."
      ]
    },
    {
      "id": "cluster_143",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 16:16:46 +0000",
      "title": "Welcome to “necroprinting”—3D printer nozzle made from mosquito’s proboscis",
      "neutral_headline": "Mosquito Proboscis Used for 3D Printer Nozzle",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/welcome-to-necroprinting-3d-printer-nozzle-made-from-mosquitos-proboscis/",
          "published_at": "Thu, 04 Dec 2025 16:16:46 +0000",
          "title": "Welcome to “necroprinting”—3D printer nozzle made from mosquito’s proboscis",
          "standfirst": "They're quite a bit cheaper than manufactured nozzles if you can dissect them.",
          "content": "Necrobotics is a field of engineering that builds robots out of a mix of synthetic materials and animal body parts. It has produced micro-grippers with pneumatically operated legs taken from dead spiders and walking robots based on deceased cockroaches. “These necrobotics papers inspired us to build something different,” said Changhong Cao, a mechanical engineering professor at the McGill University in Montreal, Canada. Cao’s team didn’t go for a robot—instead, it adapted a female mosquito proboscis to work as a nozzle in a super-precise 3D printer. And it worked surprisingly well. Fangs and stings To find the right nozzle for their 3D necroprinting system, Cao’s team began with a broad survey of natural micro-dispensing tips. The researchers examined stingers of bees, wasps, and scorpions; the fangs of venomous snakes; and the claws of centipedes. All of those evolved to deliver a fluid to the target, which is roughly what a 3D printer’s nozzle does. But they all had issues. “Some were too curved and curved for high-precision 3D printing,” Cao explained. “Also, they were optimized for delivering pulses of venom, not for a steady, continuous flow, which is what you need for printing.”Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2065922040-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2065922040-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "A 3D printer nozzle is made from a mosquito's proboscis.",
        "The nozzles are cheaper than manufactured alternatives.",
        "The process involves dissecting mosquito proboscises.",
        "The article describes the innovative use of the proboscis.",
        "The nozzles are used in 3D printing applications."
      ]
    }
  ]
}