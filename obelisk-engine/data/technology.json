{
  "updated_at": "2025-10-24T07:19:12.204Z",
  "clusters": [
    {
      "id": "cluster_0",
      "coverage": 2,
      "updated_at": "Fri, 24 Oct 2025 07:00:37 +0000",
      "title": "The best iPad for 2025: How to pick the best Apple tablet for you",
      "neutral_headline": "Choosing the Best iPad for 2025",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/best-ipads-how-to-pick-the-best-apple-tablet-for-you-150054066.html",
          "published_at": "Fri, 24 Oct 2025 07:00:37 +0000",
          "title": "The best iPad for 2025: How to pick the best Apple tablet for you",
          "standfirst": "We’ve long considered Apple’s iPads to be the best tablets on the market, but determining exactly which model you should buy isn’t always straightforward. Do you just want a big screen for streaming and web browsing? Do you want to use it like a pseudo-laptop? Do you care about Apple Intelligence at all? If you’re not sure, allow us to help. We’ve tested every iPad available today and broken down which ones should best fit your needs below. Table of contents The best iPads for 2025 How we test the best iPads iPad FAQs Recent updates The best iPads for 2025 How we test the best iPads The top edge of the iPad mini. Photo by Nathan Ingraham / Engadget Much like we do for our guide to the best tablets overall, we spend several days with each iPad to see how they feel and perform with different tasks: watching videos, web browsing, playing both casual and graphically intense games, editing 4K photos and video, running multiple apps side-by-side, making FaceTime calls and the like. To better measure performance specifically, we use benchmarking tests like Geekbench 6, 3DMark and GFXBench Metal, plus we measure how long it takes for each tablet to boot up and open various apps. We also check how well each tablet holds up long-term, whether it’s with a review unit provided by Apple or an iPad model that’s owned by a member of the Engadget staff. To help compare the color performance and brightness of the displays, we play the same videos on different iPads, side-by-side, at equal brightness levels. We use each tablet in direct sunlight outdoors to see how well they hold up to glare, and we play a handful of the same musical tracks to evaluate speaker performance. For battery life, we keep track of how long each tablet generally lasts before it needs a recharge, but we also play a 1080p movie on a loop at roughly 70 percent brightness with power-sapping background processes off. We also test each device with an Apple Pencil and note how responsive the stylus feels. Finally, we carefully pore over spec sheets and software updates to keep track of which features are available on certain iPads but not others. iPad FAQs The iPad (A16) on top of an 13-inch iPad Air. Jeff Dunn for Engadget What are some new features coming to iPadOS 26? Apple released the latest update to its iPad operating system, iPadOS 26, in September. The update is a fairly significant overhaul, one that brings iPadOS closer to macOS than ever before. New features include the ability to open more windows simultaneously and resize or tile them more freely; a Mac-style Menu bar; a dedicated Preview app; an upgraded Files app; an improved ability to export or download large files in the background; an Exposé view that shows all open windows; a pointier cursor and the option to add folders to the Dock. It also uses the new “liquid glass” design language that Apple is rolling out across all of its platforms in 2025. That said, it completely removed the “slide over” and “split view” modes found in previous versions of iPadOS, which can make quickly viewing multiple apps at once a little more cumbersome. (Though the former will now return in an upcoming update.) Notably, most of these features are available across Apple’s tablet lineup, from the iPad Pro to the entry-level iPad. You can find the full list of compatible devices at the bottom of Apple’s overview page. How long do iPads typically last? If history is any indication, expect Apple to update your iPad to the latest version of iPadOS for at least five years, if not longer. The current iPadOS 26 update, for example, is available on iPad Pro models dating back to 2018 and other iPads dating back to 2019. How long your iPad’s hardware will last depends on which model you buy and how well you maintain it. (If you’re particularly clumsy, consider an iPad case.) A more powerful iPad Pro will feel fast for a longer time than an entry-level iPad, but each model should remain at least serviceable until Apple stops updating it, at minimum. What’s the difference between the iPad and the iPad Air? Compared to the standard iPad, the iPad Air runs on a stronger M3 chip (instead of the A16 Bionic) and has 2GB more RAM (8GB total). Both come with 128GB of storage by default. The Air is also available in two sizes, 11 and 13 inches, whereas the 11th-gen iPad doesn't offer the larger screen option. The M-series SoC gives the Air better long-term performance prospects, plus access to certain iPadOS features such as Apple Intelligence. Its display supports a wider P3 color gamut, has an antireflective coating and is fully laminated. The latter means there’s no “air gap” between the display and the glass covering it, so it feels more like you’re directly touching what’s on screen instead of interacting with an image below the glass. The Air also works with the newer Pencil Pro stylus and more comfortable Magic Keyboards, and its USB-C port supports faster data transfer speeds. It technically supports faster Wi-Fi 6E, too, while the lower-cost iPad uses Wi-Fi 6. Starting at $349, the 11th-gen iPad is $250 less expensive than the iPad Air. It has a similarly elegant design with flat edges, thin bezels, USB-C port, and a Touch ID reader. Battery life is rated at the same 10 hours, and both devices have their front-facing camera on their long edge, which is a more natural position for video calls. The cheaper iPad works with the first-gen and USB-C Apple Pencils – which are more convoluted to charge – and a unique keyboard accessory called the Magic Keyboard Folio. Jeff Dunn for Engadget What’s the difference between iPads and Android tablets? The operating system, duh. But to give a few more specifics: Android devices are available from more manufacturers and cover a wider price range. You won’t see an $80 iPad anytime soon. Android is also more malleable in that you can easily sideload apps from places beyond Google’s official app store and more extensively customize the look of the OS (though the former may no longer be an option in the coming months). Several Android tablets still have features like a headphone jack or a microSD slot for adding storage, too, though those are getting rarer. But we tend to recommend Apple tablets to those who have no allegiance either way. iPad apps are still a bit more likely to be designed specifically for larger screens, rather than looking like blown-up phone software, and Apple is just about peerless when it comes to long-term software support. Every new iPad hits a certain baseline of hardware quality and performance — none of them feel cheap, and all of them are fast enough for most needs. Plus, you’ll get the most out of an iPad if you use other Apple devices. Can an iPad replace a laptop? This is a loaded question, since laptop workflows differ from person to person. If you mostly use a notebook for browsing the web, watching videos or writing emails and word docs, then sure, you can get along just fine with an iPad and the right iPad accessories. It’ll be easier to carry around, the battery life is great and having the touchscreen and stylus support is handy (though many Windows users have that regardless). Even beyond the basics, plenty of media editors, graphic designers and digital artists have shown they can get things done on an iPad. Broadly speaking, though, a laptop OS tends to be more flexible when it comes to file management, multitasking, coding or other “heavy” tasks. The recent iPadOS 26 update does close the gap a bit, though it’s still not quite as fluid. Safari on the iPad isn’t fully on par with desktop browsers either. So the answer really depends on you. How do I take a screenshot on an iPad? As we note in our screenshot how-to guide, you can take a screenshot on your iPad by pressing the top button and either volume button at the same time. If you have an older iPad with a Home button, simultaneously press the top button and the Home button instead. Recent updates Late October 2025: The new M5-based iPad Pro replaces the previous-generation iPad Pro as our top pick for power users. Early October 2025: We’ve made a few edits to reflect the full release of iPadOS 26 and made sure our recommendations are still accurate. August 2025: We've taken another sweep to ensure our picks are still accurate and added a few more notes to our FAQ section. June 2025: We’ve made a few minor edits to reflect the announcement of Apple’s latest iPadOS update, which we detail above. May 2025: We’ve lightly edited this guide to ensure all details and links are still correct. We’re also keeping an eye on how the Trump administration’s tariff policy affects the pricing and stock of the iPad lineup (and every other tech category). All of our picks are still available at normal prices today, but we’ll update this guide if that changes. March 2025: We've reviewed the iPad (A16) and named it our new budget pick, removing the discontinued 10th-gen iPad in the process. March 2025: The recently-launched iPad Air M3 has replaced its predecessor as our top overall recommendation. We’ve also made a note regarding the new iPad (A16), which we plan to test in the near future and expect to become our new budget pick. We’ve made a handful of edits elsewhere in the guide to reflect Apple’s latest hardware. January 2025: We’ve lightly edited this guide for clarity. Our recommendations remain the same. October 2024: We've updated our guide to include the new iPad mini 7. June 2024: We’ve touched up this guide to reflect some of the new iPadOS features Apple announced at WWDC, though our picks remain the same. Nathan Ingraham contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-ipads-how-to-pick-the-best-apple-tablet-for-you-150054066.html?src=rss",
          "content": "We’ve long considered Apple’s iPads to be the best tablets on the market, but determining exactly which model you should buy isn’t always straightforward. Do you just want a big screen for streaming and web browsing? Do you want to use it like a pseudo-laptop? Do you care about Apple Intelligence at all? If you’re not sure, allow us to help. We’ve tested every iPad available today and broken down which ones should best fit your needs below. Table of contents The best iPads for 2025 How we test the best iPads iPad FAQs Recent updates The best iPads for 2025 How we test the best iPads The top edge of the iPad mini. Photo by Nathan Ingraham / Engadget Much like we do for our guide to the best tablets overall, we spend several days with each iPad to see how they feel and perform with different tasks: watching videos, web browsing, playing both casual and graphically intense games, editing 4K photos and video, running multiple apps side-by-side, making FaceTime calls and the like. To better measure performance specifically, we use benchmarking tests like Geekbench 6, 3DMark and GFXBench Metal, plus we measure how long it takes for each tablet to boot up and open various apps. We also check how well each tablet holds up long-term, whether it’s with a review unit provided by Apple or an iPad model that’s owned by a member of the Engadget staff. To help compare the color performance and brightness of the displays, we play the same videos on different iPads, side-by-side, at equal brightness levels. We use each tablet in direct sunlight outdoors to see how well they hold up to glare, and we play a handful of the same musical tracks to evaluate speaker performance. For battery life, we keep track of how long each tablet generally lasts before it needs a recharge, but we also play a 1080p movie on a loop at roughly 70 percent brightness with power-sapping background processes off. We also test each device with an Apple Pencil and note how responsive the stylus feels. Finally, we carefully pore over spec sheets and software updates to keep track of which features are available on certain iPads but not others. iPad FAQs The iPad (A16) on top of an 13-inch iPad Air. Jeff Dunn for Engadget What are some new features coming to iPadOS 26? Apple released the latest update to its iPad operating system, iPadOS 26, in September. The update is a fairly significant overhaul, one that brings iPadOS closer to macOS than ever before. New features include the ability to open more windows simultaneously and resize or tile them more freely; a Mac-style Menu bar; a dedicated Preview app; an upgraded Files app; an improved ability to export or download large files in the background; an Exposé view that shows all open windows; a pointier cursor and the option to add folders to the Dock. It also uses the new “liquid glass” design language that Apple is rolling out across all of its platforms in 2025. That said, it completely removed the “slide over” and “split view” modes found in previous versions of iPadOS, which can make quickly viewing multiple apps at once a little more cumbersome. (Though the former will now return in an upcoming update.) Notably, most of these features are available across Apple’s tablet lineup, from the iPad Pro to the entry-level iPad. You can find the full list of compatible devices at the bottom of Apple’s overview page. How long do iPads typically last? If history is any indication, expect Apple to update your iPad to the latest version of iPadOS for at least five years, if not longer. The current iPadOS 26 update, for example, is available on iPad Pro models dating back to 2018 and other iPads dating back to 2019. How long your iPad’s hardware will last depends on which model you buy and how well you maintain it. (If you’re particularly clumsy, consider an iPad case.) A more powerful iPad Pro will feel fast for a longer time than an entry-level iPad, but each model should remain at least serviceable until Apple stops updating it, at minimum. What’s the difference between the iPad and the iPad Air? Compared to the standard iPad, the iPad Air runs on a stronger M3 chip (instead of the A16 Bionic) and has 2GB more RAM (8GB total). Both come with 128GB of storage by default. The Air is also available in two sizes, 11 and 13 inches, whereas the 11th-gen iPad doesn't offer the larger screen option. The M-series SoC gives the Air better long-term performance prospects, plus access to certain iPadOS features such as Apple Intelligence. Its display supports a wider P3 color gamut, has an antireflective coating and is fully laminated. The latter means there’s no “air gap” between the display and the glass covering it, so it feels more like you’re directly touching what’s on screen instead of interacting with an image below the glass. The Air also works with the newer Pencil Pro stylus and more comfortable Magic Keyboards, and its USB-C port supports faster data transfer speeds. It technically supports faster Wi-Fi 6E, too, while the lower-cost iPad uses Wi-Fi 6. Starting at $349, the 11th-gen iPad is $250 less expensive than the iPad Air. It has a similarly elegant design with flat edges, thin bezels, USB-C port, and a Touch ID reader. Battery life is rated at the same 10 hours, and both devices have their front-facing camera on their long edge, which is a more natural position for video calls. The cheaper iPad works with the first-gen and USB-C Apple Pencils – which are more convoluted to charge – and a unique keyboard accessory called the Magic Keyboard Folio. Jeff Dunn for Engadget What’s the difference between iPads and Android tablets? The operating system, duh. But to give a few more specifics: Android devices are available from more manufacturers and cover a wider price range. You won’t see an $80 iPad anytime soon. Android is also more malleable in that you can easily sideload apps from places beyond Google’s official app store and more extensively customize the look of the OS (though the former may no longer be an option in the coming months). Several Android tablets still have features like a headphone jack or a microSD slot for adding storage, too, though those are getting rarer. But we tend to recommend Apple tablets to those who have no allegiance either way. iPad apps are still a bit more likely to be designed specifically for larger screens, rather than looking like blown-up phone software, and Apple is just about peerless when it comes to long-term software support. Every new iPad hits a certain baseline of hardware quality and performance — none of them feel cheap, and all of them are fast enough for most needs. Plus, you’ll get the most out of an iPad if you use other Apple devices. Can an iPad replace a laptop? This is a loaded question, since laptop workflows differ from person to person. If you mostly use a notebook for browsing the web, watching videos or writing emails and word docs, then sure, you can get along just fine with an iPad and the right iPad accessories. It’ll be easier to carry around, the battery life is great and having the touchscreen and stylus support is handy (though many Windows users have that regardless). Even beyond the basics, plenty of media editors, graphic designers and digital artists have shown they can get things done on an iPad. Broadly speaking, though, a laptop OS tends to be more flexible when it comes to file management, multitasking, coding or other “heavy” tasks. The recent iPadOS 26 update does close the gap a bit, though it’s still not quite as fluid. Safari on the iPad isn’t fully on par with desktop browsers either. So the answer really depends on you. How do I take a screenshot on an iPad? As we note in our screenshot how-to guide, you can take a screenshot on your iPad by pressing the top button and either volume button at the same time. If you have an older iPad with a Home button, simultaneously press the top button and the Home button instead. Recent updates Late October 2025: The new M5-based iPad Pro replaces the previous-generation iPad Pro as our top pick for power users. Early October 2025: We’ve made a few edits to reflect the full release of iPadOS 26 and made sure our recommendations are still accurate. August 2025: We've taken another sweep to ensure our picks are still accurate and added a few more notes to our FAQ section. June 2025: We’ve made a few minor edits to reflect the announcement of Apple’s latest iPadOS update, which we detail above. May 2025: We’ve lightly edited this guide to ensure all details and links are still correct. We’re also keeping an eye on how the Trump administration’s tariff policy affects the pricing and stock of the iPad lineup (and every other tech category). All of our picks are still available at normal prices today, but we’ll update this guide if that changes. March 2025: We've reviewed the iPad (A16) and named it our new budget pick, removing the discontinued 10th-gen iPad in the process. March 2025: The recently-launched iPad Air M3 has replaced its predecessor as our top overall recommendation. We’ve also made a note regarding the new iPad (A16), which we plan to test in the near future and expect to become our new budget pick. We’ve made a handful of edits elsewhere in the guide to reflect Apple’s latest hardware. January 2025: We’ve lightly edited this guide for clarity. Our recommendations remain the same. October 2024: We've updated our guide to include the new iPad mini 7. June 2024: We’ve touched up this guide to reflect some of the new iPadOS features Apple announced at WWDC, though our picks remain the same. Nathan Ingraham contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-ipads-how-to-pick-the-best-apple-tablet-for-you-150054066.html?src=rss",
          "feed_position": 0,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2024-10/ded6eb30-8fee-11ef-bfcf-f1599e27e076"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html",
          "published_at": "Fri, 24 Oct 2025 00:00:35 +0000",
          "title": "The best VPN service for 2025",
          "standfirst": "As frustrating as it is that governments and businesses are running roughshod over our online freedoms, at least we have plenty of good VPNs to choose from to keep us protected online. There are so many fast, intelligently designed, full-featured and affordable services on the market that the biggest problem is picking one. For any use case, you can bet at least two providers will be neck-and-neck for first place.On the other hand, the VPN world is still the Wild West in some ways. It's easy enough to slap a cheap VPN together that the market is flooded with low-quality apps that put more money into advertising than infrastructure. They may look good, but it's all styrofoam under the hood.I built this list of the best VPNs after intensive testing to help you reorient your focus on the providers that actually deserve your time and money. Which one truly fits your needs is dependent on who you are and what you do online, but if you pick any of my seven recommendations, you can't go too far wrong.For each VPN on this list, I've shared which platforms it works on, how much it cuts into your download speed, where it offers servers, what other features are included and how much the best available deal costs. At the end, I'll list some honorable and dishonorable mentions, then answer some of the most common questions I hear about VPNs.Editor's note: This list has been completely overhauled and rewritten as of September 2025. We intend to revisit this list every three months at a minimum, at which time our picks may be adjusted based on changes in pricing, features, testing results and other factors. Table of contents Best VPNs for 2025 Other VPNs we tested What to look for in a VPN VPN FAQs Best VPNs for 2025 Other VPNs we tested The VPNs in this section didn't crack our top list above, but we're summarizing them here so you can see their positives and negatives as of the time of our evaluation. Windscribe Windscribe is another well-known free VPN supported by paid subscriptions. In many ways, it takes the best from both Mullvad and Proton VPN, with the former's no-nonsense privacy and the latter's healthy free plan. Without paying, you can connect to 10 of Windscribe's server locations on an unlimited number of devices at once. Unfortunately, Windscribe didn't copy the most important part of Proton VPN's free plan — the unlimited data. You're only allowed to use 10GB per month, which isn't enough for regular streaming. It's also committed to a cramped and headache-inducing user interface that stands out from the crowd in all the worst ways. Private Internet Access Private Internet Access (PIA VPN) has a deeply annoying name — I assume whoever invented it also likes to hop in their Toyota Forward Motion to grab a gallon of Sustaining Cow Extract from the grocery store — but it's a worthwhile VPN whose pricing provides incredible value. Its monthly and yearly plans are good enough, but its three-year plan is the clincher. Not only is it longer than average, but you can continue to renew at the three-year level, so you won't see an unpleasant price jump the first time you re-up. PIA's apps have a dark UI reminiscent of Proton VPN, which is always a good thing. It also supports port forwarding, custom DNS and the use of a SOCKS5 or Shadowsocks proxy as a second step in the VPN connection. You can even set the maximum data packet size to help out a struggling connection, as I cover in my full PIA VPN review. The downside is that your connection will struggle a lot. While well-designed, PIA's apps have a tendency to lag. In my most recent battery of tests, it dragged oddly on my internet in ways that weren't directly reflected in the speed tests. It's also not always capable of unblocking streaming services in other countries, and while its server network offers 152 IP address options in 84 countries, it's heavily bulked out by virtual locations. TunnelBear TunnelBear has a decent interface, which its target audience of VPN beginners will find very easy to use. Its speeds are perfectly good too, and I appreciate the depth and breadth of its transparency reports. But it's far too limited overall, with few extra features, less than 50 server locations and a free plan that caps data at 2GB per month. VyprVPN VyprVPN often flies under the radar, but it has some of the best apps in the business and a very good security record (there was a breach in 2023, but it didn't crack the VPN encryption itself). It's also got a verified privacy policy, a solid jurisdiction and runs every connection through an in-house DNS to prevent leaks. Despite all that, it didn't make the top seven because its connection speeds aren't up to scratch — you'll likely notice a bigger slowdown than average. It also has a troubling history of wild, seemingly experimental swings in its pricing and simultaneous connection limits. Norton VPN Norton VPN is part of the Norton 360 package that includes the well-known antivirus software and other security apps. It's a nice bonus if you use Norton already, but as a standalone VPN, it falls short. My tests repeatedly showed it dropping encryption and revealing my IP address whenever I switched servers, and not all of its locations managed to unblock Netflix. This isn't to say Norton VPN is terrible. It has a fairly large server network, user-friendly apps and some cool features like an IP rotator. It also recently revamped its OpenVPN infrastructure to improve speeds on Windows. But you probably won't find those things sufficient to balance out significant speed drops on other platforms or poorly written FAQs. I especially advise against Norton VPN for Apple users, as its Mac and iPhone apps are much more limited than their Windows and Android counterparts. What to look for in a VPN Choosing a VPN can quickly get you mired in analysis paralysis. We're here to help, but since only you know your particular needs, you should know the major red and green flags so you can make the final call yourself. Every reputable VPN provider offers a free trial or refund guarantee you can use to run the tests below. Compatibility: First, make sure your VPN works on all the platforms you plan to use it on. Most VPNs have apps for Windows, Mac, Android and iOS, but those apps aren't always created equal — check that the app for your chosen OS is user-friendly and has all the features you need. Speed: Use a speed testing app to see how fast your internet is before and after connecting to the VPN (I use Ookla's speedtest.net). To check security, look up your IP address while connected to a VPN server and see if it's actually changed your virtual location. Be sure it's using expert-vetted protocols like OpenVPN, WireGuard and IKEv2. Try connecting to streaming services and seeing whether the VPN changes the available content. Background: Do some outside research into the VPN's origins, especially its parent company, privacy policy and any past incidents. It's a dealbreaker if you can't figure out where the VPN is headquartered (which indicates a lax approach to transparency) or if it seems to have never passed a real third-party audit. Server network: Look at the server network to make sure the VPN has locations near you and in any countries where you'll want an IP address — e.g. if you need a VPN to unblock Canadian Netflix, look for multiple server locations in Canada. Customer Service: I also advise testing the customer support options by looking for the answer to a straightforward question. If phone support (versus email and chat) is important to you, make sure to prioritize that — and make sure it's available at convenient times in your timezone. Pricing: Finally, check prices. See if the VPN is affordable and decide whether you're comfortable taking a long-term subscription for better savings. If you do get a multi-year plan, check what price it will renew at, since many of the cheapest subscriptions are only introductory deals. VPN FAQs To wrap up, let's answer some of the most common questions we get about VPNs. Feel free to get in touch if you have a query I don't cover here. What is a VPN? VPN stands for virtual private network. There are a few different types of VPNs, but for this list, we're talking about commercial services that let individual users access the internet with an assumed identity. Whenever you get online, you're assigned an IP address — a digital nametag that tells websites where to send the information you request. For an IP address to work, it needs to be unique, which means it's possible to create a record of what an individual does online. When you use a VPN, all the data you send to the internet goes through one of the VPN's servers before heading to its final destination. The VPN encrypts the connection between your computer and its server so the data won't trace back to you. Any website, ISP or third party that cares to look will only see the VPN's IP address, not yours. What are some things VPNs are used for? The three main use cases for a commercial VPN are security, privacy and entertainment. Using a VPN conceals your real IP address from anyone who might want to use it for nefarious purposes like cyberstalking, DDoS attacks or deducing your real location. It also keeps your ISP from profiling you for ads based on where you live or what you do online. One side effect of borrowing a VPN's IP address is that you can make it appear as though your connection is coming from another country. You can use this to access streaming content and platforms that are only available in certain regions due to copyright. Changing your location can even get you better prices when shopping online. Location spoofing can also be used to get online in countries that censor internet access, like China and Russia, as well as certain US states or countries — like the UK — that are adding barriers like age-gating to previously unfettered online access. All you have to do is connect to a neighboring country (or locality) where the internet isn't blocked. If you plan to do this while traveling, make sure you have the VPN downloaded before you go, as some nations prevent you from even loading a VPN's homepage. Make sure you check with local laws regarding the legality of VPN use as well — just because your VPN traffic is encrypted doesn't mean that authorities can't detect that it's being used in a given location. Are VPNs worth it? Whether a VPN is worth the price depends on how much you value those three use cases above. It's no secret that your personal information is profitable for a lot of people, from illicit hackers to corporations to law enforcement. A VPN will not make you completely anonymous, nor is it a license to commit crimes (see the next question) but it will give you a lot more control over what you transmit to the world. With entertainment, the value is even clearer. You can use a VPN to fight back against streaming balkanization by getting more shows and movies out of a single platform — for example, a lot of shows that have been kicked off American Netflix are still on Netflix in other countries. What information does a VPN hide? A VPN does not make it impossible for you to be unmasked or taken advantage of online. It prevents you from passively leaking information, keeps your IP address undiscoverable on public wi-fi networks and gets you around online censorship. However, if you share personal information of your own volition, there's nothing the VPN can do. If you reveal your password in a social media post or click a link in a phishing email, that information bypasses the VPN. Likewise, if you do anything sensitive while logged into an account, the account holder will have that information even if you're using a VPN. A VPN is a critical part of your online security, but it can't do the whole job by itself. Healthy passwords, malware scanners, private search engines and common sense all have roles to play. Never forget, too, that using a VPN means trusting the VPN provider with access to information that's concealed from everyone else — make sure you trust the privacy policy before signing up. Are VPNs safe? As far as we can determine, all the VPNs recommended in this story are safe to use. As with anything you subscribe to online, due diligence is important, but there's very little inherent risk; generally, the worst thing a bad VPN will do is fail to work, leaving you no worse off than before. There are some VPNs (usually offered for free) that transmit malware, so always make sure to look up any complaints or warnings about a service before you download it. Can you get a VPN on your phone? Absolutely — almost every VPN has apps for both desktop and mobile devices. A good VPN will redesign its app to be mobile-friendly without dropping too many features. Both iOS and Android natively support VPN connections, so you're free to choose whichever provider you like. What about Google's One VPN? Google One VPN was, as you might expect, a VPN provided by Google. It was launched in 2020 for Google One subscribers and discontinued in 2024 due to lack of use. If you really want a Google VPN, you can still get one if you have certain Pixel models or if you're a Google Fi subscriber. That said, I don't recommend using a VPN from Google even if you do still have access to one. Google is one of the worst big tech companies at protecting user privacy. While its VPN might not leak, I wouldn't trust it to guard your sensitive information.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html?src=rss",
          "content": "As frustrating as it is that governments and businesses are running roughshod over our online freedoms, at least we have plenty of good VPNs to choose from to keep us protected online. There are so many fast, intelligently designed, full-featured and affordable services on the market that the biggest problem is picking one. For any use case, you can bet at least two providers will be neck-and-neck for first place.On the other hand, the VPN world is still the Wild West in some ways. It's easy enough to slap a cheap VPN together that the market is flooded with low-quality apps that put more money into advertising than infrastructure. They may look good, but it's all styrofoam under the hood.I built this list of the best VPNs after intensive testing to help you reorient your focus on the providers that actually deserve your time and money. Which one truly fits your needs is dependent on who you are and what you do online, but if you pick any of my seven recommendations, you can't go too far wrong.For each VPN on this list, I've shared which platforms it works on, how much it cuts into your download speed, where it offers servers, what other features are included and how much the best available deal costs. At the end, I'll list some honorable and dishonorable mentions, then answer some of the most common questions I hear about VPNs.Editor's note: This list has been completely overhauled and rewritten as of September 2025. We intend to revisit this list every three months at a minimum, at which time our picks may be adjusted based on changes in pricing, features, testing results and other factors. Table of contents Best VPNs for 2025 Other VPNs we tested What to look for in a VPN VPN FAQs Best VPNs for 2025 Other VPNs we tested The VPNs in this section didn't crack our top list above, but we're summarizing them here so you can see their positives and negatives as of the time of our evaluation. Windscribe Windscribe is another well-known free VPN supported by paid subscriptions. In many ways, it takes the best from both Mullvad and Proton VPN, with the former's no-nonsense privacy and the latter's healthy free plan. Without paying, you can connect to 10 of Windscribe's server locations on an unlimited number of devices at once. Unfortunately, Windscribe didn't copy the most important part of Proton VPN's free plan — the unlimited data. You're only allowed to use 10GB per month, which isn't enough for regular streaming. It's also committed to a cramped and headache-inducing user interface that stands out from the crowd in all the worst ways. Private Internet Access Private Internet Access (PIA VPN) has a deeply annoying name — I assume whoever invented it also likes to hop in their Toyota Forward Motion to grab a gallon of Sustaining Cow Extract from the grocery store — but it's a worthwhile VPN whose pricing provides incredible value. Its monthly and yearly plans are good enough, but its three-year plan is the clincher. Not only is it longer than average, but you can continue to renew at the three-year level, so you won't see an unpleasant price jump the first time you re-up. PIA's apps have a dark UI reminiscent of Proton VPN, which is always a good thing. It also supports port forwarding, custom DNS and the use of a SOCKS5 or Shadowsocks proxy as a second step in the VPN connection. You can even set the maximum data packet size to help out a struggling connection, as I cover in my full PIA VPN review. The downside is that your connection will struggle a lot. While well-designed, PIA's apps have a tendency to lag. In my most recent battery of tests, it dragged oddly on my internet in ways that weren't directly reflected in the speed tests. It's also not always capable of unblocking streaming services in other countries, and while its server network offers 152 IP address options in 84 countries, it's heavily bulked out by virtual locations. TunnelBear TunnelBear has a decent interface, which its target audience of VPN beginners will find very easy to use. Its speeds are perfectly good too, and I appreciate the depth and breadth of its transparency reports. But it's far too limited overall, with few extra features, less than 50 server locations and a free plan that caps data at 2GB per month. VyprVPN VyprVPN often flies under the radar, but it has some of the best apps in the business and a very good security record (there was a breach in 2023, but it didn't crack the VPN encryption itself). It's also got a verified privacy policy, a solid jurisdiction and runs every connection through an in-house DNS to prevent leaks. Despite all that, it didn't make the top seven because its connection speeds aren't up to scratch — you'll likely notice a bigger slowdown than average. It also has a troubling history of wild, seemingly experimental swings in its pricing and simultaneous connection limits. Norton VPN Norton VPN is part of the Norton 360 package that includes the well-known antivirus software and other security apps. It's a nice bonus if you use Norton already, but as a standalone VPN, it falls short. My tests repeatedly showed it dropping encryption and revealing my IP address whenever I switched servers, and not all of its locations managed to unblock Netflix. This isn't to say Norton VPN is terrible. It has a fairly large server network, user-friendly apps and some cool features like an IP rotator. It also recently revamped its OpenVPN infrastructure to improve speeds on Windows. But you probably won't find those things sufficient to balance out significant speed drops on other platforms or poorly written FAQs. I especially advise against Norton VPN for Apple users, as its Mac and iPhone apps are much more limited than their Windows and Android counterparts. What to look for in a VPN Choosing a VPN can quickly get you mired in analysis paralysis. We're here to help, but since only you know your particular needs, you should know the major red and green flags so you can make the final call yourself. Every reputable VPN provider offers a free trial or refund guarantee you can use to run the tests below. Compatibility: First, make sure your VPN works on all the platforms you plan to use it on. Most VPNs have apps for Windows, Mac, Android and iOS, but those apps aren't always created equal — check that the app for your chosen OS is user-friendly and has all the features you need. Speed: Use a speed testing app to see how fast your internet is before and after connecting to the VPN (I use Ookla's speedtest.net). To check security, look up your IP address while connected to a VPN server and see if it's actually changed your virtual location. Be sure it's using expert-vetted protocols like OpenVPN, WireGuard and IKEv2. Try connecting to streaming services and seeing whether the VPN changes the available content. Background: Do some outside research into the VPN's origins, especially its parent company, privacy policy and any past incidents. It's a dealbreaker if you can't figure out where the VPN is headquartered (which indicates a lax approach to transparency) or if it seems to have never passed a real third-party audit. Server network: Look at the server network to make sure the VPN has locations near you and in any countries where you'll want an IP address — e.g. if you need a VPN to unblock Canadian Netflix, look for multiple server locations in Canada. Customer Service: I also advise testing the customer support options by looking for the answer to a straightforward question. If phone support (versus email and chat) is important to you, make sure to prioritize that — and make sure it's available at convenient times in your timezone. Pricing: Finally, check prices. See if the VPN is affordable and decide whether you're comfortable taking a long-term subscription for better savings. If you do get a multi-year plan, check what price it will renew at, since many of the cheapest subscriptions are only introductory deals. VPN FAQs To wrap up, let's answer some of the most common questions we get about VPNs. Feel free to get in touch if you have a query I don't cover here. What is a VPN? VPN stands for virtual private network. There are a few different types of VPNs, but for this list, we're talking about commercial services that let individual users access the internet with an assumed identity. Whenever you get online, you're assigned an IP address — a digital nametag that tells websites where to send the information you request. For an IP address to work, it needs to be unique, which means it's possible to create a record of what an individual does online. When you use a VPN, all the data you send to the internet goes through one of the VPN's servers before heading to its final destination. The VPN encrypts the connection between your computer and its server so the data won't trace back to you. Any website, ISP or third party that cares to look will only see the VPN's IP address, not yours. What are some things VPNs are used for? The three main use cases for a commercial VPN are security, privacy and entertainment. Using a VPN conceals your real IP address from anyone who might want to use it for nefarious purposes like cyberstalking, DDoS attacks or deducing your real location. It also keeps your ISP from profiling you for ads based on where you live or what you do online. One side effect of borrowing a VPN's IP address is that you can make it appear as though your connection is coming from another country. You can use this to access streaming content and platforms that are only available in certain regions due to copyright. Changing your location can even get you better prices when shopping online. Location spoofing can also be used to get online in countries that censor internet access, like China and Russia, as well as certain US states or countries — like the UK — that are adding barriers like age-gating to previously unfettered online access. All you have to do is connect to a neighboring country (or locality) where the internet isn't blocked. If you plan to do this while traveling, make sure you have the VPN downloaded before you go, as some nations prevent you from even loading a VPN's homepage. Make sure you check with local laws regarding the legality of VPN use as well — just because your VPN traffic is encrypted doesn't mean that authorities can't detect that it's being used in a given location. Are VPNs worth it? Whether a VPN is worth the price depends on how much you value those three use cases above. It's no secret that your personal information is profitable for a lot of people, from illicit hackers to corporations to law enforcement. A VPN will not make you completely anonymous, nor is it a license to commit crimes (see the next question) but it will give you a lot more control over what you transmit to the world. With entertainment, the value is even clearer. You can use a VPN to fight back against streaming balkanization by getting more shows and movies out of a single platform — for example, a lot of shows that have been kicked off American Netflix are still on Netflix in other countries. What information does a VPN hide? A VPN does not make it impossible for you to be unmasked or taken advantage of online. It prevents you from passively leaking information, keeps your IP address undiscoverable on public wi-fi networks and gets you around online censorship. However, if you share personal information of your own volition, there's nothing the VPN can do. If you reveal your password in a social media post or click a link in a phishing email, that information bypasses the VPN. Likewise, if you do anything sensitive while logged into an account, the account holder will have that information even if you're using a VPN. A VPN is a critical part of your online security, but it can't do the whole job by itself. Healthy passwords, malware scanners, private search engines and common sense all have roles to play. Never forget, too, that using a VPN means trusting the VPN provider with access to information that's concealed from everyone else — make sure you trust the privacy policy before signing up. Are VPNs safe? As far as we can determine, all the VPNs recommended in this story are safe to use. As with anything you subscribe to online, due diligence is important, but there's very little inherent risk; generally, the worst thing a bad VPN will do is fail to work, leaving you no worse off than before. There are some VPNs (usually offered for free) that transmit malware, so always make sure to look up any complaints or warnings about a service before you download it. Can you get a VPN on your phone? Absolutely — almost every VPN has apps for both desktop and mobile devices. A good VPN will redesign its app to be mobile-friendly without dropping too many features. Both iOS and Android natively support VPN connections, so you're free to choose whichever provider you like. What about Google's One VPN? Google One VPN was, as you might expect, a VPN provided by Google. It was launched in 2020 for Google One subscribers and discontinued in 2024 due to lack of use. If you really want a Google VPN, you can still get one if you have certain Pixel models or if you're a Google Fi subscriber. That said, I don't recommend using a VPN from Google even if you do still have access to one. Google is one of the worst big tech companies at protecting user privacy. While its VPN might not leak, I wouldn't trust it to guard your sensitive information.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html?src=rss",
          "feed_position": 2
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/ea-partners-with-the-company-behind-stable-diffusion-to-make-games-with-ai-222253069.html",
          "published_at": "Thu, 23 Oct 2025 22:22:53 +0000",
          "title": "EA partners with the company behind Stable Diffusion to make games with AI",
          "standfirst": "Electronic Arts has announced a new partnership with Stability AI, the creator of AI image generation tool Stable Diffusion. The company will \"co-develop transformative AI models, tools, and workflows\" for the game developer, with the hopes of speeding up development while maintaining quality.\"I use the term smarter paintbrushes,” Steve Kestell, Head of Technical Art for EA SPORTS said in the announcement. \"We are giving our creatives the tools to express what they want.\" To start, the \"smarter paintbrushes\" EA and Stability AI are building are concentrated on generating textures and in-game assets. EA hopes to create \"Physically Based Rendering materials\" with new tools \"that generate 2D textures that maintain exact color and light accuracy across any environment.\" The company also describes using AI to \"pre-visualize entire 3D environments from a series of intentional prompts, allowing artists to creatively direct the generation of game content.\" Stability AI is most famous for its powerful Stable Diffusion image generator, but the company maintains multiple tools for generating 3D models, too, so the partnership is by no means out of place.It helps that AI is on the tip of most video game executives' tongues. Strauss Zelnick, the head of Grand Theft Auto publisher Take-Two, recently shared that generative AI \"will not reduce employment, it will increase employment,\" because \"technology always increases productivity, which in turn increases GDP, which in turn increases employment.\" Krafton, the publisher of PUBG: Battlegrounds, made its commitment to AI even more clear, announcing plans on Thursday to become an AI-first company. Companies with a direct stake in the success of the AI industry, like Microsoft, have also created gaming-focused tools and developed models for prototyping. The motivations for EA might be even simpler, though. The company is in the midst of being taken private, and will soon be saddled with billions in debt. Theoretically cutting costs with AI might be one way the company hopes to survive the transition.This article originally appeared on Engadget at https://www.engadget.com/gaming/ea-partners-with-the-company-behind-stable-diffusion-to-make-games-with-ai-222253069.html?src=rss",
          "content": "Electronic Arts has announced a new partnership with Stability AI, the creator of AI image generation tool Stable Diffusion. The company will \"co-develop transformative AI models, tools, and workflows\" for the game developer, with the hopes of speeding up development while maintaining quality.\"I use the term smarter paintbrushes,” Steve Kestell, Head of Technical Art for EA SPORTS said in the announcement. \"We are giving our creatives the tools to express what they want.\" To start, the \"smarter paintbrushes\" EA and Stability AI are building are concentrated on generating textures and in-game assets. EA hopes to create \"Physically Based Rendering materials\" with new tools \"that generate 2D textures that maintain exact color and light accuracy across any environment.\" The company also describes using AI to \"pre-visualize entire 3D environments from a series of intentional prompts, allowing artists to creatively direct the generation of game content.\" Stability AI is most famous for its powerful Stable Diffusion image generator, but the company maintains multiple tools for generating 3D models, too, so the partnership is by no means out of place.It helps that AI is on the tip of most video game executives' tongues. Strauss Zelnick, the head of Grand Theft Auto publisher Take-Two, recently shared that generative AI \"will not reduce employment, it will increase employment,\" because \"technology always increases productivity, which in turn increases GDP, which in turn increases employment.\" Krafton, the publisher of PUBG: Battlegrounds, made its commitment to AI even more clear, announcing plans on Thursday to become an AI-first company. Companies with a direct stake in the success of the AI industry, like Microsoft, have also created gaming-focused tools and developed models for prototyping. The motivations for EA might be even simpler, though. The company is in the midst of being taken private, and will soon be saddled with billions in debt. Theoretically cutting costs with AI might be one way the company hopes to survive the transition.This article originally appeared on Engadget at https://www.engadget.com/gaming/ea-partners-with-the-company-behind-stable-diffusion-to-make-games-with-ai-222253069.html?src=rss",
          "feed_position": 3
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/openai-launches-company-knowledge-in-chatgpt-letting-you-access-your-firms",
          "published_at": "Thu, 23 Oct 2025 22:19:00 GMT",
          "title": "OpenAI launches company knowledge in ChatGPT, letting you access your firm's data from Google Drive, Slack, GitHub",
          "standfirst": "Is the Google Search for internal enterprise knowledge finally here...but from OpenAI? It certainly seems that way. Today, OpenAI has launched company knowledge in ChatGPT, a major new capability for subscribers to ChatGPT&#x27;s paid Business, Enterprise, and Edu plans that lets them call up their company&#x27;s data directly from third-party workplace apps including Slack, SharePoint, Google Drive, Gmail, GitHub, HubSpot and combine it in ChatGPT outputs to them. As OpenAI&#x27;s CEO of Applications Fidji Simo put it in a post on the social network X: \"it brings all the context from your apps (Slack, Google Drive, GitHub, etc) together in ChatGPT so you can get answers that are specific to your business.\"Intriguingly, OpenAI&#x27;s blog post on the feature states that is \"powered by a version of GPT‑5 that’s trained to look across multiple sources to give more comprehensive and accurate answers,\" which sounds to me like a new fine-tuned version of the model family the company released back in August, though there are no additional details on how it was trained. Nonetheless, company knowledge in ChatGPT is rolling out globally and is designed to make ChatGPT a central point of access for verified organizational information, supported by secure integrations and enterprise-grade compliance controls, and give employees way faster access to their company&#x27;s information while working.Now, instead of toggling over to Slack to find the assignment you were given and instructions, or tabbing over to Google Drive and opening up specific files to find the names and numbers you need to call, ChatGPT can deliver all that type of information directly into your chat session — if your company enables the proper connections.As OpenAI Chief Operating Officer Brad Lightcap wrote in a post on the social network X: \"company knowledge has changed how i use chatgpt at work more than anything we have built so far - let us know what you think!\"It builds upon the third-party app connectors unveiled back in August 2025, though those were only for individual users on the ChatGPT Plus plans.Connecting ChatGPT to Workplace SystemsEnterprise teams often face the challenge of fragmented data across various internal tools—email, chat, file storage, project management, and customer platforms. Company knowledge bridges those silos by enabling ChatGPT to connect to approved systems like, and other supported apps through enterprise-managed connectors.Each response generated with company knowledge includes citations and direct links to the original sources, allowing teams to verify where specific details originated. This transparency helps organizations maintain data trustworthiness while increasing productivity.OpenAI confirms that company knowledge uses a version of GPT-5 optimized for multi-source reasoning and cross-system synthesis, providing detailed, contextually accurate results even across disparate sources.Built for Enterprise Control and SecurityCompany knowledge was designed from the ground up for enterprise governance and compliance. It respects existing permissions within connected apps — ChatGPT can only access what a user is already authorized to view— and never trains on company data by default.Security features include industry-standard encryption, support for SSO and SCIM for account provisioning, and IP allowlisting to restrict access to approved corporate networks. Enterprise administrators can also define role-based access control (RBAC) policies and manage permissions at a group or department level.OpenAI’s Enterprise Compliance API provides a full audit trail, allowing administrators to review conversation logs for reporting and regulatory purposes. This capability helps enterprises meet internal governance standards and industry-specific requirements such as SOC 2 and ISO 27001 compliance.Admin Configuration and Connector ManagementFor enterprise deployment, administrators must enable company knowledge and its connectors within the ChatGPT workspace. Once connectors are active, users can authenticate their own accounts for each work app they need to access.In Enterprise and Edu plans, connectors are off by default and require explicit admin approval before employees can use them. Admins can selectively enable connectors, manage access by role, and require SSO-based authentication for enhanced control.Business plan users, by contrast, have connectors enabled automatically if available in their workspace. Admins can still oversee which connectors are approved, ensuring alignment with internal IT and data policies.Company knowledge becomes available to any user with at least one active connector, and admins can configure group-level permissions for different teams — such as restricting GitHub access to engineering while enabling Google Drive or HubSpot for marketing and sales.How Company Knowledge Works in PracticeActivating company knowledge is straightforward. Users can start a new or existing conversation in ChatGPT and select “Company knowledge” under the message composer or from the tools menu. After authenticating their connected apps, they can ask questions as usual—such as “Summarize this account’s latest feedback and risks” or “Compile a Q4 performance summary from project trackers.”ChatGPT searches across the connected tools, retrieves relevant context, and produces an answer with full citations and source links. The system can combine data across apps — for instance, blending Slack updates, Google Docs notes, and HubSpot CRM records — to create an integrated view of a project, client, or initiative.When company knowledge is not selected, ChatGPT may still use connectors in a limited capacity as part of the default experience, but responses will not include detailed citations or multi-source synthesis.Advanced Use Cases for Enterprise TeamsFor development and operations leaders, company knowledge can act as a centralized intelligence layer that surfaces real-time updates and dependencies across complex workflows. ChatGPT can, for example, summarize open GitHub pull requests, highlight unresolved Linear tickets, and cross-reference Slack engineering discussions—all in a single output.Technical teams can also use it for incident retrospectives or release planning by pulling relevant information from issue trackers, logs, and meeting notes. Procurement or finance leaders can use it to consolidate purchase requests or budget updates across shared drives and internal communications.Because the model can reference structured and unstructured data simultaneously, it supports wide-ranging scenarios—from compliance documentation reviews to cross-departmental performance summaries.Privacy, Data Residency, and ComplianceEnterprise data protection is a central design element of company knowledge. ChatGPT processes data in line with OpenAI’s enterprise-grade security model, ensuring that no connected app data leaves the secure boundary of the organization’s authorized environment.Data residency policies vary by connector. Certain integrations, such as Slack, support region-specific data storage, while others—like Google Drive and SharePoint—are available for U.S.-based customers with or without at-rest data residency. Organizations with regional compliance obligations can review connector-specific security documentation for details.No geo restrictions apply to company knowledge, making it suitable for multinational organizations operating across multiple jurisdictions.Limitations and Future EnhancementsAt present, users must manually enable company knowledge in each new ChatGPT conversation. OpenAI is developing a unified interface that will automatically integrate company knowledge with other ChatGPT tools—such as browsing and chart generation—so that users won’t need to toggle between modes.When enabled, company knowledge temporarily disables web browsing and visual output generation, though users can switch modes within the same conversation to re-enable those features.OpenAI also continues to expand the network of supported tools. Recent updates have added connectors for Asana, GitLab Issues, and ClickUp, and OpenAI plans to support future MCP (Model Context Protocol) connectors to enable custom, developer-built integrations.Several important details about company knowledge remain unclear based on OpenAI’s published materials. It’s not yet known whether the system can detect and exclude information labeled as confidential, whether organizations can opt in or out of data training separately for this feature, or if users will eventually be able to select which model powers it. OpenAI has also not said whether this version of GPT-5 is new or specific to the feature, or what service-level guarantees exist to ensure accuracy and prevent hallucinations in company-specific responses. VentureBeat has emailed OpenAI spokespeople with these and related questions and is awaiting a response, which we will publish if and when we receive it.Availability and Getting StartedCompany knowledge is now available to all ChatGPT Business, Enterprise, and Edu users. Organizations can begin by enabling the feature under the ChatGPT message composer and connecting approved work apps.For enterprise rollouts, OpenAI recommends a phased deployment: first enabling core connectors (such as Google Drive and Slack), configuring RBAC and SSO, then expanding to specialized systems once data access policies are verified.Procurement and security leaders evaluating the feature should note that company knowledge is covered under existing ChatGPT Enterprise terms and uses the same encryption, compliance, and service-level guarantees.With company knowledge, OpenAI aims to make ChatGPT not just a conversational assistant but an intelligent interface to enterprise data—delivering secure, context-aware insights that help technical and business leaders act with confidence.",
          "content": "Is the Google Search for internal enterprise knowledge finally here...but from OpenAI? It certainly seems that way. Today, OpenAI has launched company knowledge in ChatGPT, a major new capability for subscribers to ChatGPT&#x27;s paid Business, Enterprise, and Edu plans that lets them call up their company&#x27;s data directly from third-party workplace apps including Slack, SharePoint, Google Drive, Gmail, GitHub, HubSpot and combine it in ChatGPT outputs to them. As OpenAI&#x27;s CEO of Applications Fidji Simo put it in a post on the social network X: \"it brings all the context from your apps (Slack, Google Drive, GitHub, etc) together in ChatGPT so you can get answers that are specific to your business.\"Intriguingly, OpenAI&#x27;s blog post on the feature states that is \"powered by a version of GPT‑5 that’s trained to look across multiple sources to give more comprehensive and accurate answers,\" which sounds to me like a new fine-tuned version of the model family the company released back in August, though there are no additional details on how it was trained. Nonetheless, company knowledge in ChatGPT is rolling out globally and is designed to make ChatGPT a central point of access for verified organizational information, supported by secure integrations and enterprise-grade compliance controls, and give employees way faster access to their company&#x27;s information while working.Now, instead of toggling over to Slack to find the assignment you were given and instructions, or tabbing over to Google Drive and opening up specific files to find the names and numbers you need to call, ChatGPT can deliver all that type of information directly into your chat session — if your company enables the proper connections.As OpenAI Chief Operating Officer Brad Lightcap wrote in a post on the social network X: \"company knowledge has changed how i use chatgpt at work more than anything we have built so far - let us know what you think!\"It builds upon the third-party app connectors unveiled back in August 2025, though those were only for individual users on the ChatGPT Plus plans.Connecting ChatGPT to Workplace SystemsEnterprise teams often face the challenge of fragmented data across various internal tools—email, chat, file storage, project management, and customer platforms. Company knowledge bridges those silos by enabling ChatGPT to connect to approved systems like, and other supported apps through enterprise-managed connectors.Each response generated with company knowledge includes citations and direct links to the original sources, allowing teams to verify where specific details originated. This transparency helps organizations maintain data trustworthiness while increasing productivity.OpenAI confirms that company knowledge uses a version of GPT-5 optimized for multi-source reasoning and cross-system synthesis, providing detailed, contextually accurate results even across disparate sources.Built for Enterprise Control and SecurityCompany knowledge was designed from the ground up for enterprise governance and compliance. It respects existing permissions within connected apps — ChatGPT can only access what a user is already authorized to view— and never trains on company data by default.Security features include industry-standard encryption, support for SSO and SCIM for account provisioning, and IP allowlisting to restrict access to approved corporate networks. Enterprise administrators can also define role-based access control (RBAC) policies and manage permissions at a group or department level.OpenAI’s Enterprise Compliance API provides a full audit trail, allowing administrators to review conversation logs for reporting and regulatory purposes. This capability helps enterprises meet internal governance standards and industry-specific requirements such as SOC 2 and ISO 27001 compliance.Admin Configuration and Connector ManagementFor enterprise deployment, administrators must enable company knowledge and its connectors within the ChatGPT workspace. Once connectors are active, users can authenticate their own accounts for each work app they need to access.In Enterprise and Edu plans, connectors are off by default and require explicit admin approval before employees can use them. Admins can selectively enable connectors, manage access by role, and require SSO-based authentication for enhanced control.Business plan users, by contrast, have connectors enabled automatically if available in their workspace. Admins can still oversee which connectors are approved, ensuring alignment with internal IT and data policies.Company knowledge becomes available to any user with at least one active connector, and admins can configure group-level permissions for different teams — such as restricting GitHub access to engineering while enabling Google Drive or HubSpot for marketing and sales.How Company Knowledge Works in PracticeActivating company knowledge is straightforward. Users can start a new or existing conversation in ChatGPT and select “Company knowledge” under the message composer or from the tools menu. After authenticating their connected apps, they can ask questions as usual—such as “Summarize this account’s latest feedback and risks” or “Compile a Q4 performance summary from project trackers.”ChatGPT searches across the connected tools, retrieves relevant context, and produces an answer with full citations and source links. The system can combine data across apps — for instance, blending Slack updates, Google Docs notes, and HubSpot CRM records — to create an integrated view of a project, client, or initiative.When company knowledge is not selected, ChatGPT may still use connectors in a limited capacity as part of the default experience, but responses will not include detailed citations or multi-source synthesis.Advanced Use Cases for Enterprise TeamsFor development and operations leaders, company knowledge can act as a centralized intelligence layer that surfaces real-time updates and dependencies across complex workflows. ChatGPT can, for example, summarize open GitHub pull requests, highlight unresolved Linear tickets, and cross-reference Slack engineering discussions—all in a single output.Technical teams can also use it for incident retrospectives or release planning by pulling relevant information from issue trackers, logs, and meeting notes. Procurement or finance leaders can use it to consolidate purchase requests or budget updates across shared drives and internal communications.Because the model can reference structured and unstructured data simultaneously, it supports wide-ranging scenarios—from compliance documentation reviews to cross-departmental performance summaries.Privacy, Data Residency, and ComplianceEnterprise data protection is a central design element of company knowledge. ChatGPT processes data in line with OpenAI’s enterprise-grade security model, ensuring that no connected app data leaves the secure boundary of the organization’s authorized environment.Data residency policies vary by connector. Certain integrations, such as Slack, support region-specific data storage, while others—like Google Drive and SharePoint—are available for U.S.-based customers with or without at-rest data residency. Organizations with regional compliance obligations can review connector-specific security documentation for details.No geo restrictions apply to company knowledge, making it suitable for multinational organizations operating across multiple jurisdictions.Limitations and Future EnhancementsAt present, users must manually enable company knowledge in each new ChatGPT conversation. OpenAI is developing a unified interface that will automatically integrate company knowledge with other ChatGPT tools—such as browsing and chart generation—so that users won’t need to toggle between modes.When enabled, company knowledge temporarily disables web browsing and visual output generation, though users can switch modes within the same conversation to re-enable those features.OpenAI also continues to expand the network of supported tools. Recent updates have added connectors for Asana, GitLab Issues, and ClickUp, and OpenAI plans to support future MCP (Model Context Protocol) connectors to enable custom, developer-built integrations.Several important details about company knowledge remain unclear based on OpenAI’s published materials. It’s not yet known whether the system can detect and exclude information labeled as confidential, whether organizations can opt in or out of data training separately for this feature, or if users will eventually be able to select which model powers it. OpenAI has also not said whether this version of GPT-5 is new or specific to the feature, or what service-level guarantees exist to ensure accuracy and prevent hallucinations in company-specific responses. VentureBeat has emailed OpenAI spokespeople with these and related questions and is awaiting a response, which we will publish if and when we receive it.Availability and Getting StartedCompany knowledge is now available to all ChatGPT Business, Enterprise, and Edu users. Organizations can begin by enabling the feature under the ChatGPT message composer and connecting approved work apps.For enterprise rollouts, OpenAI recommends a phased deployment: first enabling core connectors (such as Google Drive and Slack), configuring RBAC and SSO, then expanding to specialized systems once data access policies are verified.Procurement and security leaders evaluating the feature should note that company knowledge is covered under existing ChatGPT Enterprise terms and uses the same encryption, compliance, and service-level guarantees.With company knowledge, OpenAI aims to make ChatGPT not just a conversational assistant but an intelligent interface to enterprise data—delivering secure, context-aware insights that help technical and business leaders act with confidence.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/77MUUhh1PM8EeHOJyHjmwX/2f1b317b8af31339017a06f84d871d58/cfr0z3n_third-person_view_of_woman_seated_at_desk_in_a_home_off_d68bd7db-ac86-44be-8e05-2cdb878c7190.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/nike-pitches-robotic-sneakers-and-mind-altering-mules-212716340.html",
          "published_at": "Thu, 23 Oct 2025 21:27:16 +0000",
          "title": "Nike pitches robotic sneakers and mind-altering mules",
          "standfirst": "Nike is no stranger to a unique footwear concept, be it self-lacing shoes or a \"Hyperboot\" that can speed up recovery. The company claims its Project Amplify and new \"neuroscience-based\" footwear take things a bit further, though, by actively augmenting your body and mind while you're wearing them. Developed with robotics startup Dephy, Project Amplify acts as \"a second set of calf muscles\" for \"everyday athletes\" who want to walk or run more. Nike says the first-generation model consists of a running shoe with a carbon fiber plate, a calf-mounted rechargeable battery, a motor and a drive belt. While it has the neon colors and cushioned finish of a normal pair of running shoes, the basic design of Project Amplify seems like a more polished version of the robotic Sidekick shoes Dephy is already pitching on its website. Project Amplify doesn't replace your legs' ability to walk or run, but rather makes going further and faster easier. Nike compares the experience to an e-bike, which typically don't eliminate the need for pedaling, and instead augment your pedals with power from an electric motor. Nike says Project Amplify \"makes walking or running uphill feel like moving on flat ground,\" and in the case of some people who tested it, turned a 12-minute mile into a 10-minute mile. Dephy and the Nike Sport Research Lab (NSRL) worked with more than 400 different athletes to test various versions of robotic shoes, covering \"over 2.4 million steps, the equivalent of roughly 12,000 laps around the NSRL’s 200-meter track.\" The companies' approach, melding an existing fashion brand with robotics, is similar to Arc'teryx's MO/GO pants from 2024, robotic trousers developed in partnership with Skip that help hikers with balance and endurance. Project Amplify is smaller (and hopefully less expensive), but robot-assisted gadgets increasingly seem like a way robotics research could make its way into consumer products, beyond things like vacuums.The Nike Mind 001 mules and Nike Mind 002 sneakers on a white background.NikeNike's Mind 001 and Mind 002 shoes are based on the company's neuroscience research, and are strange in a different way. Created by the Nike Mind Science Department, the foam nodes in both shoes — a pair of mules and sneakers, respectively — imparts the texture of the ground underneath the wearer's feet. This process \"heightens sensory awareness, which can help clear away distractions and enhance concentration,\" Nike says.The Nike Mind 001 and Mind 002 will go on sale in January 2026 as the first shoes in the Nike Mind line. Nike says Project Amplify, meanwhile, will receive \"a broad consumer launch in the coming years.\"This article originally appeared on Engadget at https://www.engadget.com/wearables/nike-pitches-robotic-sneakers-and-mind-altering-mules-212716340.html?src=rss",
          "content": "Nike is no stranger to a unique footwear concept, be it self-lacing shoes or a \"Hyperboot\" that can speed up recovery. The company claims its Project Amplify and new \"neuroscience-based\" footwear take things a bit further, though, by actively augmenting your body and mind while you're wearing them. Developed with robotics startup Dephy, Project Amplify acts as \"a second set of calf muscles\" for \"everyday athletes\" who want to walk or run more. Nike says the first-generation model consists of a running shoe with a carbon fiber plate, a calf-mounted rechargeable battery, a motor and a drive belt. While it has the neon colors and cushioned finish of a normal pair of running shoes, the basic design of Project Amplify seems like a more polished version of the robotic Sidekick shoes Dephy is already pitching on its website. Project Amplify doesn't replace your legs' ability to walk or run, but rather makes going further and faster easier. Nike compares the experience to an e-bike, which typically don't eliminate the need for pedaling, and instead augment your pedals with power from an electric motor. Nike says Project Amplify \"makes walking or running uphill feel like moving on flat ground,\" and in the case of some people who tested it, turned a 12-minute mile into a 10-minute mile. Dephy and the Nike Sport Research Lab (NSRL) worked with more than 400 different athletes to test various versions of robotic shoes, covering \"over 2.4 million steps, the equivalent of roughly 12,000 laps around the NSRL’s 200-meter track.\" The companies' approach, melding an existing fashion brand with robotics, is similar to Arc'teryx's MO/GO pants from 2024, robotic trousers developed in partnership with Skip that help hikers with balance and endurance. Project Amplify is smaller (and hopefully less expensive), but robot-assisted gadgets increasingly seem like a way robotics research could make its way into consumer products, beyond things like vacuums.The Nike Mind 001 mules and Nike Mind 002 sneakers on a white background.NikeNike's Mind 001 and Mind 002 shoes are based on the company's neuroscience research, and are strange in a different way. Created by the Nike Mind Science Department, the foam nodes in both shoes — a pair of mules and sneakers, respectively — imparts the texture of the ground underneath the wearer's feet. This process \"heightens sensory awareness, which can help clear away distractions and enhance concentration,\" Nike says.The Nike Mind 001 and Mind 002 will go on sale in January 2026 as the first shoes in the Nike Mind line. Nike says Project Amplify, meanwhile, will receive \"a broad consumer launch in the coming years.\"This article originally appeared on Engadget at https://www.engadget.com/wearables/nike-pitches-robotic-sneakers-and-mind-altering-mules-212716340.html?src=rss",
          "feed_position": 6,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/nike-mind-1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/leicas-latest-m-camera-drops-the-rangefinder-in-favor-of-an-electronic-viewfinder-190547479.html",
          "published_at": "Thu, 23 Oct 2025 19:05:47 +0000",
          "title": "Leica's latest M camera drops the rangefinder in favor of an electronic viewfinder",
          "standfirst": "When you're trying to keep Leica's digital camera lineups straight, the M-System was always the one with optical rangefinder display (and high price tag). However. the company just upended that precedent with the M EV1, a 60MP mirrorless camera with a classic M design but an electronic viewfinder (EVF) in place of the rangefinder. It may upset purists, but it's a move that makes sense from a sales point of view. Leica's old-school film cameras used its M mount lens system and, in order to keep the bodies compact, didn't have reflex mirrors like SLRs. Instead, they used an optical rangefinder, which provides a weird, offset and inaccurate view of the scene. Leica kept the rangefinders when it launched its digital M cameras, even though it could have switched to an EVF. Leica In 2014, Leica launched a more modern mirrorless camera lineup with the new SL mount that did use electronic viewfinders. However, they have always lacked the cachet, compact size and gorgeous looks of the M-System, so don't appeal as much to well-heeled buyers that want the full Leica experience. Enter the M EV1, which looks exactly like you want a Leica to look but boots the rangefinder in favor of an EVF. \"Designed for both devoted Leica enthusiasts and those new to the M System, it makes capturing beautiful, intentional photographs easier than ever,\" the company wrote. Leica probably noticed buyers who wanted a pretty camera were drawn to the M series, but then put off by the wonky rangefinders. Handmade in Germany, the M EV1 is definitely beautiful, with the classic rounded rectangular M shape and a new diamond-patterned leatherette to give it a distinctive look compared to the rangefinder models. Leica also eliminated the dedicated ISO dial (the setting is now done via another control), which helped make it 1.62 ounces lighter than the M11-P. It has a new custom function lever that lets you activate focusing aids and digital zoom options while looking through the viewfinder. Leica That viewfinder is definitely a good one, with 5.76 million dots of resolution for a sharp view. The rear screen has a sharp 2.32-million-dot display, but is fixed in place and doesn't tilt. Otherwise, the M EV1 has similar specs to the M11-P. It has a high resolution 60MP sensor with support for 14-bit RAW images processed using Leica's excellent color science and burst speeds up to 4.5 fps. You can shoot with the mechanical shutter at up to 1/4000th and 1/16,000th in silent mode (flash sync is 1/180th). Focusing is strictly manual, with magnification and focus peaking assist functions. Naturally, it uses Leica's famous and tremendously expensive compact M mount lenses. There's no support for video. Though some features are old school, the M EV1 lets you connect to Leica's Fotos app via Bluetooth, Wi-Fi or a cable for quick sharing on social media and elsewhere. It also supports Leica's Content Credentials system that enables the origin and history of an image to be clearly traced to avoid copyright theft or AI spoofing. Other features include 64GB of built-in storage along with UHS-II SD card support, and a meager 237 shots on a battery charge when using the EVF. Seeing the price is always a fun experience with a new Leica camera, and the M EV1 doesn't disappoint. It's now on pre-order for $8,995 (black, body only) with shipping set for later this year. This article originally appeared on Engadget at https://www.engadget.com/cameras/leicas-latest-m-camera-drops-the-rangefinder-in-favor-of-an-electronic-viewfinder-190547479.html?src=rss",
          "content": "When you're trying to keep Leica's digital camera lineups straight, the M-System was always the one with optical rangefinder display (and high price tag). However. the company just upended that precedent with the M EV1, a 60MP mirrorless camera with a classic M design but an electronic viewfinder (EVF) in place of the rangefinder. It may upset purists, but it's a move that makes sense from a sales point of view. Leica's old-school film cameras used its M mount lens system and, in order to keep the bodies compact, didn't have reflex mirrors like SLRs. Instead, they used an optical rangefinder, which provides a weird, offset and inaccurate view of the scene. Leica kept the rangefinders when it launched its digital M cameras, even though it could have switched to an EVF. Leica In 2014, Leica launched a more modern mirrorless camera lineup with the new SL mount that did use electronic viewfinders. However, they have always lacked the cachet, compact size and gorgeous looks of the M-System, so don't appeal as much to well-heeled buyers that want the full Leica experience. Enter the M EV1, which looks exactly like you want a Leica to look but boots the rangefinder in favor of an EVF. \"Designed for both devoted Leica enthusiasts and those new to the M System, it makes capturing beautiful, intentional photographs easier than ever,\" the company wrote. Leica probably noticed buyers who wanted a pretty camera were drawn to the M series, but then put off by the wonky rangefinders. Handmade in Germany, the M EV1 is definitely beautiful, with the classic rounded rectangular M shape and a new diamond-patterned leatherette to give it a distinctive look compared to the rangefinder models. Leica also eliminated the dedicated ISO dial (the setting is now done via another control), which helped make it 1.62 ounces lighter than the M11-P. It has a new custom function lever that lets you activate focusing aids and digital zoom options while looking through the viewfinder. Leica That viewfinder is definitely a good one, with 5.76 million dots of resolution for a sharp view. The rear screen has a sharp 2.32-million-dot display, but is fixed in place and doesn't tilt. Otherwise, the M EV1 has similar specs to the M11-P. It has a high resolution 60MP sensor with support for 14-bit RAW images processed using Leica's excellent color science and burst speeds up to 4.5 fps. You can shoot with the mechanical shutter at up to 1/4000th and 1/16,000th in silent mode (flash sync is 1/180th). Focusing is strictly manual, with magnification and focus peaking assist functions. Naturally, it uses Leica's famous and tremendously expensive compact M mount lenses. There's no support for video. Though some features are old school, the M EV1 lets you connect to Leica's Fotos app via Bluetooth, Wi-Fi or a cable for quick sharing on social media and elsewhere. It also supports Leica's Content Credentials system that enables the origin and history of an image to be clearly traced to avoid copyright theft or AI spoofing. Other features include 64GB of built-in storage along with UHS-II SD card support, and a meager 237 shots on a battery charge when using the EVF. Seeing the price is always a fun experience with a new Leica camera, and the M EV1 doesn't disappoint. It's now on pre-order for $8,995 (black, body only) with shipping set for later this year. This article originally appeared on Engadget at https://www.engadget.com/cameras/leicas-latest-m-camera-drops-the-rangefinder-in-favor-of-an-electronic-viewfinder-190547479.html?src=rss",
          "feed_position": 10,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/ee8e2060-b041-11f0-bfd8-56b8b6c7bea8"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/best-macbook-140032524.html",
          "published_at": "Thu, 23 Oct 2025 19:01:26 +0000",
          "title": "The best MacBook for 2025: Which Apple laptop should you buy?",
          "standfirst": "Picking the best MacBook may seem like an easy decision. After all, Apple just makes two models: the MacBook Air and the MacBook Pro. But the available variations within those categories — screen size, chip type, capacity and more — deserve some consideration. You also may wonder what the real-world differences are between models and who they’re best for. To make things even more interesting, Apple keeps announcing new chips. The latest, the M5 came out October 15, and is now found in the base model, 14-inch MacBook Pro (as well as the iPad Pro and the Vision Pro). This guide breaks down Apple’s terminology, as well as all which upgrades make the most sense so you can get the best MacBook for what you want to do. Table of contents Best MacBooks for 2025 What about budget MacBooks? Factors to consider when buying a MacBook MacBooks specs comparison chart Best MacBook FAQs Best MacBooks for 2025 What about budget MacBooks? Historically, Apple kept the previous year’s MacBook Air in its lineup as a sort of budget option. But the company took a different approach with the release of the M4 MacBook Air. Instead of continuing to sell the older model, Apple discontinued the M3 Air and gave its newest computer a $100 price cut. Now, if you can even find a brand new M3 MacBook Air (typically from retailers like Amazon or B&H), it’s often more expensive than the M4 version. During sales like Amazon Prime Day, we’ve seen the newest M4 Air go for as little as $799. That effectively makes our overall pick a budget pick as well. Of course, $800 isn’t exactly a small investment either for college students or others on a budget. Especially when you can find some decent PCs for under $500. If you’re looking to save even more on a MacBook, we recommend checking out refurbished options directly from Apple, or even third party sellers like BackMarket. There are a few guidelines to keep in mind, which we go over in our refurbished guide, but mainly, you’ll want to shop from a reputable source that has a stated process and offers at least a year-long warranty. Using your old gear as a trade-in will bring down your final cost as well. Factors to consider when buying a MacBook Compared to PCs, Apple computers tend to have more streamlined specifications. The company has long been known for this simplicity, and the M-series “system-on-a-chip” condenses things even further. Prior to the M1 chip, Apple used Intel chips in its laptop and desktop computers. The M2 and M3 generations followed that first chip and currently, MacBooks come equipped with M4 and M5-series chips. You’ll find the standard M4 processor in the Air. The base-model 14-inch Pro now comes with either the latest M5 chip. Other Pro configurations have the M4 Max or the M4 Pro (currently there is no M4 Ultra chip, as there was with the M3 series in the Mac Studio). All M-series chips combine, among other technologies, the CPU, graphics card and unified memory (RAM). Apple’s Neural Engine is included too, which is a specialized group of processor cores that handles machine learning tasks such as image analysis and voice recognition. While a unified chip means you have fewer decisions to make when picking a MacBook, there are still a few factors to consider, including specs like the number of CPU cores, amount of RAM, storage capacity, screen size, and, obviously, price. The finish color may be a minor consideration, but it's worth pointing out that the Pro comes in just two colors (Silver or Space Black) but the Air comes in four hues (Midnight, Starlight, Sky Blue and Silver). CPU cores The lowest-specced chip in a current-lineup MacBook is the standard M4 chip, which is found in all models of the MacBook Air. That chip houses a 10-core CPU and either an 8- or 10-core GPU. The base-model MacBook Pro uses the latest M5 chip, but only on the 14-inch model. The upgraded versions of that laptop use the M4 Pro or M4 Max chips (which are a step up from their predecessors, the M3, M3 Pro and M3 Max chips). The M4 Max is the burliest chip and built with either a 14- or 16-core CPU and a 32- or 40-core GPU. Cores are, in essence, smaller processing units that can handle different tasks simultaneously. Having more of them translates to the computer being able to run multiple programs and applications at once, while also smoothly processing demanding tasks like video and photo editing and high-level gaming. In short, more cores allow for more advanced computing and better performance. But if your processing power needs fall below professional-level gaming and cinematic video and audio editing, getting the highest number of cores is likely overkill — and after all, more cores equals higher cost and more power usage. Photo by Devindra Hardawar/Engadget RAM Your options for RAM (or unified memory) varies, but when Apple switched to the M4 chip for the MacBook Air, the lowest amount of RAM you can get was bumped to 16GB. That’s a necessary jump to accommodate the tech world’s favorite feature of the moment: AI or, in this case, Apple Intelligence (still AI, but Cupertino’s version). The M4 Pro chip has 24 or 48GB memory options, while the M4 Max chip supports 48, 64 or a whopping 128GB of RAM. The M5 chip in the base-model MacBook Pro comes with a minimum of 16GB and can be configured to a maximum of 32GB of RAM.. You’ve likely heard the analogy comparing memory to the amount of workspace available on a literal desktop surface, whereas storage is the amount of drawers you have to store projects to work on later. The larger the worktop surface, the more projects you can work on at once. The bigger the drawers, the more you can save for later. In addition to supporting Apple Intelligence, more RAM is ideal for people who plan to work in multiple apps at once. And the more demanding each program is, the more RAM will be required. Extra memory can also come in handy if you’re the type who likes to have infinite numbers of tabs open on your browser. If your daily workflow doesn’t involve simultaneously using a vast number of memory-intensive programs, you can save yourself money and buy the RAM configuration that you’re most likely to actually use. For a long time, Apple continued to offer MacBooks with just 8GB of RAM, and we recommended upgrading to at least 16GB of RAM. With this being the standard today, grabbing a base model should be fine for most non-pro-level users. One thing to note is that, unlike most PCs, the RAM in a MacBook is not user-upgradable since it’s tied into the system-on-a-chip. If you think you might end up needing more memory, you should go for the spec upgrade up front. Storage capacity (SSD) Storage options range from 256GB of SSD for the base-model MacBook Air and 8TB of storage for the MacBook Pros with the M4 Max chip. If you want to rotate between a long roster of game titles or keep lots of high-res videos on hand, you’ll want more storage. If you’re mostly working with browser- and cloud-based applications, you can get away with a smaller-capacity configuration. That said, we recommend springing for 512GB of storage or more, if it’s within your budget. You’ll quickly feel the limits of a 256GB machine as it ages since the operating system alone takes up a good portion of that space. Having 1TB will feel even roomier and allow for more data storage over the life of your laptop. When Apple announced the iPhone 15, the company also announced new iCloud+ storage storage plans, with subscriptions that allow up to 12TB of storage shared among your iOS and MacOS devices. You could also transfer files to an external storage device. But if you don’t want to pay for a monthly subscription and prefer the convenience of having immediate access to your files, it’s best to get the highest amount of storage space your budget allows for at the outset. Screen size The MacBook Air comes in 13- or 15-inch sizes. Pro models have either 14- or 16-inch screens. A two-inch delta may not seem like much but, as Engadget’s Nathan Ingraham noted when he reviewed the then-new 15-inch M2-powered MacBook Air, a larger screen \"makes a surprising difference.” That’s especially true if you plan to use your laptop as an all-day productivity machine and won’t be using an external monitor. More space means you can more clearly view side-by-side windows and have a more immersive experience when watching shows or gaming. But screen size is one of the main factors influencing weight. The 13-inch MacBook Air M4 weighs 2.7 pounds, whereas the top-end 16-inch MacBook Pro with the Max chip weighs 4.7 pounds. If you plan to travel a lot or swap your work locations regularly, a smaller screen will make life easier in the long run. All MacBooks feature IPS LCD panels (in-plane switching, liquid crystal display), which Apple markets as Retina displays. The MacBook Air M4 has a Liquid Retina display and the Pro models have Liquid Retina XDR displays. “Liquid” refers to the way the lighted portion of the display “flows” within the contours of the screen, filling the rounded corners and curving around the camera notch. “XDR” is what Apple calls HDR (high dynamic range). You also get the option of a standard or nano-texture display on the MacBook Pro. The glass, which reduces glare and is also available on the Studio Display, iMac and iPad Pro, comes with a $150 price increase, but if you really don’t like reflections on your screen, it could be worth it. Compared to most other laptops, MacBook displays are notably bright, sharp and lush. But one feature worth pointing out is another Apple marketing term: ProMotion. It’s the company’s term to describe a screen with a higher, 120Hz refresh rate, which results in smoother scrolling and more fluid-looking graphics. Only MacBook Pros offer ProMotion; the Air maxes out at 60Hz, which is perfectly fine for everyday browsing and typical workdays. But if you want buttery-smooth motion from your display, you’ll have to shell out more money for an upgrade. Operating systems Software considerations won’t make much of a difference when deciding between MacBook models — all come with macOS installed. But if you’re switching from, say, a Windows PC, the operating system may be something to factor into your decision — though it’s probably less of an issue than it once was. Now that so much of the work we do on our computers is browser- and cloud-based, the learning curve between the two platforms isn’t as steep. Apps and programs like Gmail perform similarly regardless of what computer you’re using. Apple machines have historically had more limited support of AAA gaming titles, but even that is changing with more AAA games and better graphics coming to Macs. As for macOS, it’s getting better too. With macOS Tahoe 26, the Spotlight function is more advanced, making it easier to find apps and perform tasks straight from your keyboard. The software also implements Apple's unifying Liquid Glass design for a modern look that looks consistent across iOS and iPad devices. New enhanced iPhone continuity features also make MacBooks and the handset work better together. A revamped Shortcuts app is more powerful as well, giving users custom automations that leverage Apple Intelligence (the company’s own AI). Price When Apple announced the MacBook Air M4, it also delivered a bit of refreshing news: The latest model now starts $100 cheaper than the previous generation. So now, the least expensive MacBook is the 13-inch, M4-powered Air with 16GB of RAM and 256GB of storage for $999. Alternatively, you can spend up to $7,349 for the 16-inch MacBook Pro M4 Max with the nano-texture glass, 128GB of RAM and 8TB of storage. Chip type, screen size, memory and storage capacity all influence the final price, which is why guides like this can help you determine just what you need (and what you don’t) so you can get the most cost-effective machine for you. AppleCare is another cost to consider. The extended warranty plan from Apple covers repairs from accidents and offers free battery replacement and starts at $3.50 per month or $35 per year for MacBooks. We recommend the MacBook Air M4 for most people, and thanks to that $100 price cut, it’s also a good budget option. If you want something even cheaper, we recommend looking at refurbished M-series models from Apple. We think the 14-inch M5 or 16-inch M4 MacBook Pros are best for professionals. If you have extra money to spare once you’ve picked your machine, we recommend upgrading to at least 512GB of storage and 32GB of RAM to make your machine as future-proof as possible. Of course, if you're just after Apple’s silicon and want the cheapest route to get it, you might consider the M4 Mac mini, which starts at $599 (though you'll have to supply the screen, mouse and keyboard). Best MacBooks spec comparison chart Product Superlative Tested configuration Tested battery life Rated battery life Apple MacBook Air M4 (13-inch) Best MacBook overall Apple M4, 16GB RAM, 256GB SSD 18.25 hours Up to 18 hours Apple MacBook Pro M5 (14-inch) Best MacBook for creatives Apple M5, 32GB RAM, 512GB SSD 34.5 hours Up to 24 hours Best MacBook FAQs What's the difference between MacBook Air and Pro? The MacBook Air comes with the M4 chip. The 14-inch, base-model Pro comes with the M5 chip. MacBook Pro models have the option of more powerful M4 Pro or M4 Max chips. The Pro models have higher resolution screens with a higher peak brightness that supports up to 120Hz adaptive refresh rates and XDR (extreme dynamic range). The battery life on most Pro models is longer than on the Air models as well. Pro models also have more ports and more speakers. In short, the MacBook Air is aimed at everyday users looking for good productivity and entertainment capabilities, while Pro models are aimed at professionals who need a high-performance computer. What's the difference between macOS and Windows? MacOS is the operating system developed by Apple and used in all of its desktop and laptop computers. It can only be found in hardware made by Apple including MacBooks and iMacs. Microsoft’s Windows operating system can be found in the company’s own Surface laptops as well as computers made by a wide array of manufacturers, like Acer, Asus, Dell and Razer.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-macbook-140032524.html?src=rss",
          "content": "Picking the best MacBook may seem like an easy decision. After all, Apple just makes two models: the MacBook Air and the MacBook Pro. But the available variations within those categories — screen size, chip type, capacity and more — deserve some consideration. You also may wonder what the real-world differences are between models and who they’re best for. To make things even more interesting, Apple keeps announcing new chips. The latest, the M5 came out October 15, and is now found in the base model, 14-inch MacBook Pro (as well as the iPad Pro and the Vision Pro). This guide breaks down Apple’s terminology, as well as all which upgrades make the most sense so you can get the best MacBook for what you want to do. Table of contents Best MacBooks for 2025 What about budget MacBooks? Factors to consider when buying a MacBook MacBooks specs comparison chart Best MacBook FAQs Best MacBooks for 2025 What about budget MacBooks? Historically, Apple kept the previous year’s MacBook Air in its lineup as a sort of budget option. But the company took a different approach with the release of the M4 MacBook Air. Instead of continuing to sell the older model, Apple discontinued the M3 Air and gave its newest computer a $100 price cut. Now, if you can even find a brand new M3 MacBook Air (typically from retailers like Amazon or B&H), it’s often more expensive than the M4 version. During sales like Amazon Prime Day, we’ve seen the newest M4 Air go for as little as $799. That effectively makes our overall pick a budget pick as well. Of course, $800 isn’t exactly a small investment either for college students or others on a budget. Especially when you can find some decent PCs for under $500. If you’re looking to save even more on a MacBook, we recommend checking out refurbished options directly from Apple, or even third party sellers like BackMarket. There are a few guidelines to keep in mind, which we go over in our refurbished guide, but mainly, you’ll want to shop from a reputable source that has a stated process and offers at least a year-long warranty. Using your old gear as a trade-in will bring down your final cost as well. Factors to consider when buying a MacBook Compared to PCs, Apple computers tend to have more streamlined specifications. The company has long been known for this simplicity, and the M-series “system-on-a-chip” condenses things even further. Prior to the M1 chip, Apple used Intel chips in its laptop and desktop computers. The M2 and M3 generations followed that first chip and currently, MacBooks come equipped with M4 and M5-series chips. You’ll find the standard M4 processor in the Air. The base-model 14-inch Pro now comes with either the latest M5 chip. Other Pro configurations have the M4 Max or the M4 Pro (currently there is no M4 Ultra chip, as there was with the M3 series in the Mac Studio). All M-series chips combine, among other technologies, the CPU, graphics card and unified memory (RAM). Apple’s Neural Engine is included too, which is a specialized group of processor cores that handles machine learning tasks such as image analysis and voice recognition. While a unified chip means you have fewer decisions to make when picking a MacBook, there are still a few factors to consider, including specs like the number of CPU cores, amount of RAM, storage capacity, screen size, and, obviously, price. The finish color may be a minor consideration, but it's worth pointing out that the Pro comes in just two colors (Silver or Space Black) but the Air comes in four hues (Midnight, Starlight, Sky Blue and Silver). CPU cores The lowest-specced chip in a current-lineup MacBook is the standard M4 chip, which is found in all models of the MacBook Air. That chip houses a 10-core CPU and either an 8- or 10-core GPU. The base-model MacBook Pro uses the latest M5 chip, but only on the 14-inch model. The upgraded versions of that laptop use the M4 Pro or M4 Max chips (which are a step up from their predecessors, the M3, M3 Pro and M3 Max chips). The M4 Max is the burliest chip and built with either a 14- or 16-core CPU and a 32- or 40-core GPU. Cores are, in essence, smaller processing units that can handle different tasks simultaneously. Having more of them translates to the computer being able to run multiple programs and applications at once, while also smoothly processing demanding tasks like video and photo editing and high-level gaming. In short, more cores allow for more advanced computing and better performance. But if your processing power needs fall below professional-level gaming and cinematic video and audio editing, getting the highest number of cores is likely overkill — and after all, more cores equals higher cost and more power usage. Photo by Devindra Hardawar/Engadget RAM Your options for RAM (or unified memory) varies, but when Apple switched to the M4 chip for the MacBook Air, the lowest amount of RAM you can get was bumped to 16GB. That’s a necessary jump to accommodate the tech world’s favorite feature of the moment: AI or, in this case, Apple Intelligence (still AI, but Cupertino’s version). The M4 Pro chip has 24 or 48GB memory options, while the M4 Max chip supports 48, 64 or a whopping 128GB of RAM. The M5 chip in the base-model MacBook Pro comes with a minimum of 16GB and can be configured to a maximum of 32GB of RAM.. You’ve likely heard the analogy comparing memory to the amount of workspace available on a literal desktop surface, whereas storage is the amount of drawers you have to store projects to work on later. The larger the worktop surface, the more projects you can work on at once. The bigger the drawers, the more you can save for later. In addition to supporting Apple Intelligence, more RAM is ideal for people who plan to work in multiple apps at once. And the more demanding each program is, the more RAM will be required. Extra memory can also come in handy if you’re the type who likes to have infinite numbers of tabs open on your browser. If your daily workflow doesn’t involve simultaneously using a vast number of memory-intensive programs, you can save yourself money and buy the RAM configuration that you’re most likely to actually use. For a long time, Apple continued to offer MacBooks with just 8GB of RAM, and we recommended upgrading to at least 16GB of RAM. With this being the standard today, grabbing a base model should be fine for most non-pro-level users. One thing to note is that, unlike most PCs, the RAM in a MacBook is not user-upgradable since it’s tied into the system-on-a-chip. If you think you might end up needing more memory, you should go for the spec upgrade up front. Storage capacity (SSD) Storage options range from 256GB of SSD for the base-model MacBook Air and 8TB of storage for the MacBook Pros with the M4 Max chip. If you want to rotate between a long roster of game titles or keep lots of high-res videos on hand, you’ll want more storage. If you’re mostly working with browser- and cloud-based applications, you can get away with a smaller-capacity configuration. That said, we recommend springing for 512GB of storage or more, if it’s within your budget. You’ll quickly feel the limits of a 256GB machine as it ages since the operating system alone takes up a good portion of that space. Having 1TB will feel even roomier and allow for more data storage over the life of your laptop. When Apple announced the iPhone 15, the company also announced new iCloud+ storage storage plans, with subscriptions that allow up to 12TB of storage shared among your iOS and MacOS devices. You could also transfer files to an external storage device. But if you don’t want to pay for a monthly subscription and prefer the convenience of having immediate access to your files, it’s best to get the highest amount of storage space your budget allows for at the outset. Screen size The MacBook Air comes in 13- or 15-inch sizes. Pro models have either 14- or 16-inch screens. A two-inch delta may not seem like much but, as Engadget’s Nathan Ingraham noted when he reviewed the then-new 15-inch M2-powered MacBook Air, a larger screen \"makes a surprising difference.” That’s especially true if you plan to use your laptop as an all-day productivity machine and won’t be using an external monitor. More space means you can more clearly view side-by-side windows and have a more immersive experience when watching shows or gaming. But screen size is one of the main factors influencing weight. The 13-inch MacBook Air M4 weighs 2.7 pounds, whereas the top-end 16-inch MacBook Pro with the Max chip weighs 4.7 pounds. If you plan to travel a lot or swap your work locations regularly, a smaller screen will make life easier in the long run. All MacBooks feature IPS LCD panels (in-plane switching, liquid crystal display), which Apple markets as Retina displays. The MacBook Air M4 has a Liquid Retina display and the Pro models have Liquid Retina XDR displays. “Liquid” refers to the way the lighted portion of the display “flows” within the contours of the screen, filling the rounded corners and curving around the camera notch. “XDR” is what Apple calls HDR (high dynamic range). You also get the option of a standard or nano-texture display on the MacBook Pro. The glass, which reduces glare and is also available on the Studio Display, iMac and iPad Pro, comes with a $150 price increase, but if you really don’t like reflections on your screen, it could be worth it. Compared to most other laptops, MacBook displays are notably bright, sharp and lush. But one feature worth pointing out is another Apple marketing term: ProMotion. It’s the company’s term to describe a screen with a higher, 120Hz refresh rate, which results in smoother scrolling and more fluid-looking graphics. Only MacBook Pros offer ProMotion; the Air maxes out at 60Hz, which is perfectly fine for everyday browsing and typical workdays. But if you want buttery-smooth motion from your display, you’ll have to shell out more money for an upgrade. Operating systems Software considerations won’t make much of a difference when deciding between MacBook models — all come with macOS installed. But if you’re switching from, say, a Windows PC, the operating system may be something to factor into your decision — though it’s probably less of an issue than it once was. Now that so much of the work we do on our computers is browser- and cloud-based, the learning curve between the two platforms isn’t as steep. Apps and programs like Gmail perform similarly regardless of what computer you’re using. Apple machines have historically had more limited support of AAA gaming titles, but even that is changing with more AAA games and better graphics coming to Macs. As for macOS, it’s getting better too. With macOS Tahoe 26, the Spotlight function is more advanced, making it easier to find apps and perform tasks straight from your keyboard. The software also implements Apple's unifying Liquid Glass design for a modern look that looks consistent across iOS and iPad devices. New enhanced iPhone continuity features also make MacBooks and the handset work better together. A revamped Shortcuts app is more powerful as well, giving users custom automations that leverage Apple Intelligence (the company’s own AI). Price When Apple announced the MacBook Air M4, it also delivered a bit of refreshing news: The latest model now starts $100 cheaper than the previous generation. So now, the least expensive MacBook is the 13-inch, M4-powered Air with 16GB of RAM and 256GB of storage for $999. Alternatively, you can spend up to $7,349 for the 16-inch MacBook Pro M4 Max with the nano-texture glass, 128GB of RAM and 8TB of storage. Chip type, screen size, memory and storage capacity all influence the final price, which is why guides like this can help you determine just what you need (and what you don’t) so you can get the most cost-effective machine for you. AppleCare is another cost to consider. The extended warranty plan from Apple covers repairs from accidents and offers free battery replacement and starts at $3.50 per month or $35 per year for MacBooks. We recommend the MacBook Air M4 for most people, and thanks to that $100 price cut, it’s also a good budget option. If you want something even cheaper, we recommend looking at refurbished M-series models from Apple. We think the 14-inch M5 or 16-inch M4 MacBook Pros are best for professionals. If you have extra money to spare once you’ve picked your machine, we recommend upgrading to at least 512GB of storage and 32GB of RAM to make your machine as future-proof as possible. Of course, if you're just after Apple’s silicon and want the cheapest route to get it, you might consider the M4 Mac mini, which starts at $599 (though you'll have to supply the screen, mouse and keyboard). Best MacBooks spec comparison chart Product Superlative Tested configuration Tested battery life Rated battery life Apple MacBook Air M4 (13-inch) Best MacBook overall Apple M4, 16GB RAM, 256GB SSD 18.25 hours Up to 18 hours Apple MacBook Pro M5 (14-inch) Best MacBook for creatives Apple M5, 32GB RAM, 512GB SSD 34.5 hours Up to 24 hours Best MacBook FAQs What's the difference between MacBook Air and Pro? The MacBook Air comes with the M4 chip. The 14-inch, base-model Pro comes with the M5 chip. MacBook Pro models have the option of more powerful M4 Pro or M4 Max chips. The Pro models have higher resolution screens with a higher peak brightness that supports up to 120Hz adaptive refresh rates and XDR (extreme dynamic range). The battery life on most Pro models is longer than on the Air models as well. Pro models also have more ports and more speakers. In short, the MacBook Air is aimed at everyday users looking for good productivity and entertainment capabilities, while Pro models are aimed at professionals who need a high-performance computer. What's the difference between macOS and Windows? MacOS is the operating system developed by Apple and used in all of its desktop and laptop computers. It can only be found in hardware made by Apple including MacBooks and iMacs. Microsoft’s Windows operating system can be found in the company’s own Surface laptops as well as computers made by a wide array of manufacturers, like Acer, Asus, Dell and Razer.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-macbook-140032524.html?src=rss",
          "feed_position": 11,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-11/e536a1d0-7c1e-11ee-9e77-9ea8e142b078"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/microsoft-copilot-gets-12-big-updates-for-fall-including-new-ai-assistant",
          "published_at": "Thu, 23 Oct 2025 19:01:00 GMT",
          "title": "Microsoft Copilot gets 12 big updates for fall, including new AI assistant character Mico",
          "standfirst": "Microsoft today held a live announcement event online for its Copilot AI digital assistant, with Mustafa Suleyman, CEO of Microsoft&#x27;s AI division, and other presenters unveiling a new generation of features that deepen integration across Windows, Edge, and Microsoft 365, positioning the platform as a practical assistant for people during work and off-time, while allowing them to preserve control and safety of their data.The new Copilot 2025 Fall Update features also up the ante in terms of capabilities and the accessibility of generative AI assistance from Microsoft to users, so businesses relying on Microsoft products, and those who seek to offer complimentary or competing products, would do well to review them.Suleyman emphasized that the updates reflect a shift from hype to usefulness. “Technology should work in service of people, not the other way around,” he said. “Copilot is not just a product—it’s a promise that AI can be helpful, supportive, and deeply personal.”Intriguingly, the announcement also sought to shine a greater spotlight on Microsoft&#x27;s own homegrown AI models, as opposed to those of its partner and investment OpenAI, which previously powered the entire Copilot experience. Instead, Suleyman wrote today in a blog post: “At the foundation of it all is our strategy to put the best models to work for you – both those we build and those we don’t. Over the past few months, we have released in-house models like MAI-Voice-1, MAI-1-Preview and MAI-Vision-1, and are rapidly iterating.”12 Features That Redefine CopilotThe Fall Release consolidates Copilot’s identity around twelve key capabilities—each with potential to streamline organizational knowledge work, development, or support operations.Groups – Shared Copilot sessions where up to 32 participants can brainstorm, co-author, or plan simultaneously. For distributed teams, it effectively merges a meeting chat, task board, and generative workspace. Copilot maintains context, summarizes decisions, and tracks open actions. Imagine – A collaborative hub for creating and remixing AI-generated content. In an enterprise setting, Imagine enables rapid prototyping of visuals, marketing drafts, or training materials.Mico – A new character identity for Copilot that introduces expressive feedback and emotional expression in the form of a cute, amorphous blob. Echoing Microsoft’s historic character interfaces like Clippy (Office 97) or Cortana (2014), Mico serves as a unifying UX layer across modalities.Real Talk – A conversational mode that adapts to a user’s communication style and offers calibrated pushback — ending the sycophancy that some users have complained about with other AI models such as prior versions of OpenAI&#x27;s ChatGPT. For professionals, it allows Socratic problem-solving rather than passive answer generation, making Copilot more credible in technical collaboration.Memory & Personalization – Long-term contextual memory that lets Copilot recall key details—training plans, dates, goals—at the user’s direction.Connectors – Integration with OneDrive, Outlook, Gmail, Google Drive, and Google Calendar for natural-language search across accounts.Proactive Actions (Preview) – Context-based prompts and next-step suggestions derived from recent activity.Copilot for Health – Health information grounded in credible medical sources such as Harvard Health, with tools allowing users to locate and compare doctors.Learn Live – A Socratic, voice-driven tutoring experience using questions, visuals, and whiteboards.Copilot Mode in Edge – Converts Microsoft Edge into an “AI browser” that summarizes, compares, and executes web actions by voice.Copilot on Windows – Deep integration across Windows 11 PCs with “Hey Copilot” activation, Copilot Vision guidance, and quick access to files and apps.Copilot Pages and Copilot Search – A collaborative file canvas plus a unified search experience combining AI-generated, cited answers with standard web results.The Fall Release is immediately available in the United States, with rollout to the UK, Canada, and other markets in progress. Some functions—such as Groups, Journeys, and Copilot for Health—remain U.S.-only for now. Proactive Actions requires a Microsoft 365 Personal, Family, or Premium subscription.Together these updates illustrate Microsoft’s pivot from static productivity suites to contextual AI infrastructure, with the Copilot brand acting as the connective tissue across user roles.From Clippy to Mico: The Return of a Guided InterfaceOne of the most notable introductions is Mico, a small animated companion that is available within Copilot’s voice-enabled experiences, including the Copilot app on Windows, iOS, and Android, as well as in Study Mode and other conversational contexts. It serves as an optional visual companion that appears during interactive or voice-based sessions, rather than across all Copilot interfaces.Mico listens, reacts with expressions, and changes color to reflect tone and emotion — bringing a visual warmth to an AI assistant experience that has traditionally been text-heavy.Mico’s design recalls earlier eras of Microsoft’s history with character-based assistants. In the mid-1990s, Microsoft experimented with Microsoft Bob (1995), a software interface that used cartoon characters like a dog named Rover to guide users through everyday computing tasks. While innovative for its time, Bob was discontinued after a year due to performance and usability issues.A few years later came Clippy, the Office Assistant introduced in Microsoft Office 97. Officially known as “Clippit,” the animated paperclip would pop up to offer help and tips within Word and other Office applications. Clippy became widely recognized—sometimes humorously so—for interrupting users with unsolicited advice. Microsoft retired Clippy from Office in 2001, though the character remains a nostalgic symbol of early AI-driven assistance.More recently, Cortana, launched in 2014 as Microsoft’s digital voice assistant for Windows and mobile devices, aimed to provide natural-language interaction similar to Apple’s Siri or Amazon’s Alexa. Despite positive early reception, Cortana’s role diminished as Microsoft refocused on enterprise productivity and AI integration. The service was officially discontinued on Windows in 2023.Mico, by contrast, represents a modern reimagining of that tradition—combining the personality of early assistants with the intelligence and adaptability of contemporary AI models. Where Clippy offered canned responses, Mico listens, learns, and reflects a user’s mood in real time. The goal, as Suleyman framed it, is to create an AI that feels “helpful, supportive, and deeply personal.”Groups Are Microsoft&#x27;s Version of Claude and ChatGPT ProjectsDuring Microsoft’s launch video, product researcher Wendy described Groups as a transformative shift: “You can finally bring in other people directly to the conversation that you’re having with Copilot,” she said. “It’s the only place you can do this.”Up to 32 users can join a shared Copilot session, brainstorming, editing, or planning together while the AI manages logistics such as summarizing discussion threads, tallying votes, and splitting tasks. Participants can enter or exit sessions using a link, maintaining full visibility into ongoing work.Instead of a single user prompting an AI and later sharing results, Groups lets teams prompt and iterate together in one unified conversation. In some ways, it&#x27;s an answer to Anthropic’s Claude Projects and OpenAI’s ChatGPT Projects, both launched within the last year as tools to centralize team workspaces and shared AI context. Where Claude and ChatGPT Projects allow users to aggregate files, prompts, and conversations into a single container, Groups extends that model into real-time, multi-participant collaboration. Unlike Anthropic’s and OpenAI’s implementations, Groups is deeply embedded within Microsoft’s productivity environment. Like other Copilot experiences connected to Outlook and OneDrive, Groups operates within Microsoft’s enterprise identity framework, governed by Microsoft 365 and Entra ID (formerly Azure Active Directory) authentication and consent modelsThis means conversations, shared artifacts, and generated summaries are governed under the same compliance policies that already protect Outlook, Teams, and SharePoint data.Hours after the unveiling, OpenAI hit back against its own investor in the escalating AI competition between the \"frenemies\" by expanding its Shared Projects feature beyond its current Enterprise, Team, and Edu subscriber availability to users of its free, Plus, and Pro subscription tiers. Operational Impact for AI and Data TeamsMemory & Personalization and Connectors effectively extend a lightweight orchestration layer across Microsoft’s ecosystem. Instead of building separate context-stores or retrieval APIs, teams can leverage Copilot’s secure integration with OneDrive or SharePoint as a governed data backbone. A presenter explained that Copilot’s memory “naturally picks up on important details and remembers them long after you’ve had the conversation,” yet remains editable. For data engineers, Copilot Search and Connectors reduce friction in data discovery across multiple systems. Natural-language retrieval from internal and cloud repositories may lower the cost of knowledge management initiatives by consolidating search endpoints.For security directors, Copilot’s explicit consent requirements and on/off toggles in Edge and Windows help maintain data residency standards. The company reiterated during the livestream that Copilot “acts only with user permission and within organizational privacy controls.”Copilot Mode in Edge: The AI Browser for Research and AutomationCopilot Mode in Edge stands out for offering AI-assisted information workflows. The browser can now parse open tabs, summarize differences, and perform transactional steps.“Historically, browsers have been static—just endless clicking and tab-hopping,” said a presenter during Microsoft’s livestream. “We asked not how browsers should work, but how people work.”In practice, an analyst could prompt Edge to compare supplier documentation, extract structured data, and auto-fill procurement forms—all with consistent citation. Voice-only navigation enables accessibility and multitasking, while Journeys, a companion feature, organizes browsing sessions into storylines for later review.Copilot on Windows: The Operating System as an AI SurfaceIn Windows 11, Copilot now functions as an embedded assistant. With the wake-word “Hey Copilot,” users can initiate context-aware commands without leaving the desktop—drafting documentation, troubleshooting configuration issues, or summarizing system logs.A presenter described it as a “super assistant plugged into all your files and applications.” For enterprises standardizing on Windows 11, this positions Copilot as a native productivity layer rather than an add-on, reducing training friction and promoting secure, on-device reasoning.Copilot Vision, now in early deployment, adds visual comprehension. IT staff can capture a screen region and ask Copilot to interpret error messages, explain configuration options, or generate support tickets automatically.Combined with Copilot Pages, which supports up to twenty concurrent file uploads, this enables more efficient cross-document analysis for audits, RFPs, or code reviews.Leveraging MAI Models for Multimodal WorkflowsAt the foundation of these capabilities are Microsoft’s proprietary MAI-Voice-1, MAI-1 Preview, and MAI-Vision-1 models—trained in-house to handle text, voice, and visual inputs cohesively.For engineering teams managing LLM orchestration, this architecture introduces several potential efficiencies:Unified multimodal reasoning – Reduces the need for separate ASR (speech-to-text) and image-parsing services.Fine-tuning continuity – Because Microsoft owns the model stack, updates propagate across Copilot experiences without re-integration.Predictable latency and governance – In-house hosting under Azure compliance frameworks simplifies security certification for regulated industries.A presenter described the new stack as “the foundation for immersive, creative, and dynamic experiences that still respect enterprise boundaries.”A Strategic Pivot Toward Contextual AIFor years, Microsoft positioned Copilot primarily as a productivity companion. With the Fall 2025 release, it crosses into operational AI infrastructure—a set of extensible services for reasoning over data and processes.Suleyman described this evolution succinctly: “Judge an AI by how much it elevates human potential, not just by its own smarts.” For CIOs and technical leads, the elevation comes from efficiency and interoperability.Copilot now acts as:A connective interface linking files, communications, and cloud data.A reasoning agent capable of understanding context across sessions and modalities.A secure orchestration layer compatible with Microsoft’s compliance and identity framework.Suleyman’s insistence that “technology should work in service of people” now extends to organizations as well: technology that serves teams, not workloads; systems that adapt to enterprise context rather than demand it.",
          "content": "Microsoft today held a live announcement event online for its Copilot AI digital assistant, with Mustafa Suleyman, CEO of Microsoft&#x27;s AI division, and other presenters unveiling a new generation of features that deepen integration across Windows, Edge, and Microsoft 365, positioning the platform as a practical assistant for people during work and off-time, while allowing them to preserve control and safety of their data.The new Copilot 2025 Fall Update features also up the ante in terms of capabilities and the accessibility of generative AI assistance from Microsoft to users, so businesses relying on Microsoft products, and those who seek to offer complimentary or competing products, would do well to review them.Suleyman emphasized that the updates reflect a shift from hype to usefulness. “Technology should work in service of people, not the other way around,” he said. “Copilot is not just a product—it’s a promise that AI can be helpful, supportive, and deeply personal.”Intriguingly, the announcement also sought to shine a greater spotlight on Microsoft&#x27;s own homegrown AI models, as opposed to those of its partner and investment OpenAI, which previously powered the entire Copilot experience. Instead, Suleyman wrote today in a blog post: “At the foundation of it all is our strategy to put the best models to work for you – both those we build and those we don’t. Over the past few months, we have released in-house models like MAI-Voice-1, MAI-1-Preview and MAI-Vision-1, and are rapidly iterating.”12 Features That Redefine CopilotThe Fall Release consolidates Copilot’s identity around twelve key capabilities—each with potential to streamline organizational knowledge work, development, or support operations.Groups – Shared Copilot sessions where up to 32 participants can brainstorm, co-author, or plan simultaneously. For distributed teams, it effectively merges a meeting chat, task board, and generative workspace. Copilot maintains context, summarizes decisions, and tracks open actions. Imagine – A collaborative hub for creating and remixing AI-generated content. In an enterprise setting, Imagine enables rapid prototyping of visuals, marketing drafts, or training materials.Mico – A new character identity for Copilot that introduces expressive feedback and emotional expression in the form of a cute, amorphous blob. Echoing Microsoft’s historic character interfaces like Clippy (Office 97) or Cortana (2014), Mico serves as a unifying UX layer across modalities.Real Talk – A conversational mode that adapts to a user’s communication style and offers calibrated pushback — ending the sycophancy that some users have complained about with other AI models such as prior versions of OpenAI&#x27;s ChatGPT. For professionals, it allows Socratic problem-solving rather than passive answer generation, making Copilot more credible in technical collaboration.Memory & Personalization – Long-term contextual memory that lets Copilot recall key details—training plans, dates, goals—at the user’s direction.Connectors – Integration with OneDrive, Outlook, Gmail, Google Drive, and Google Calendar for natural-language search across accounts.Proactive Actions (Preview) – Context-based prompts and next-step suggestions derived from recent activity.Copilot for Health – Health information grounded in credible medical sources such as Harvard Health, with tools allowing users to locate and compare doctors.Learn Live – A Socratic, voice-driven tutoring experience using questions, visuals, and whiteboards.Copilot Mode in Edge – Converts Microsoft Edge into an “AI browser” that summarizes, compares, and executes web actions by voice.Copilot on Windows – Deep integration across Windows 11 PCs with “Hey Copilot” activation, Copilot Vision guidance, and quick access to files and apps.Copilot Pages and Copilot Search – A collaborative file canvas plus a unified search experience combining AI-generated, cited answers with standard web results.The Fall Release is immediately available in the United States, with rollout to the UK, Canada, and other markets in progress. Some functions—such as Groups, Journeys, and Copilot for Health—remain U.S.-only for now. Proactive Actions requires a Microsoft 365 Personal, Family, or Premium subscription.Together these updates illustrate Microsoft’s pivot from static productivity suites to contextual AI infrastructure, with the Copilot brand acting as the connective tissue across user roles.From Clippy to Mico: The Return of a Guided InterfaceOne of the most notable introductions is Mico, a small animated companion that is available within Copilot’s voice-enabled experiences, including the Copilot app on Windows, iOS, and Android, as well as in Study Mode and other conversational contexts. It serves as an optional visual companion that appears during interactive or voice-based sessions, rather than across all Copilot interfaces.Mico listens, reacts with expressions, and changes color to reflect tone and emotion — bringing a visual warmth to an AI assistant experience that has traditionally been text-heavy.Mico’s design recalls earlier eras of Microsoft’s history with character-based assistants. In the mid-1990s, Microsoft experimented with Microsoft Bob (1995), a software interface that used cartoon characters like a dog named Rover to guide users through everyday computing tasks. While innovative for its time, Bob was discontinued after a year due to performance and usability issues.A few years later came Clippy, the Office Assistant introduced in Microsoft Office 97. Officially known as “Clippit,” the animated paperclip would pop up to offer help and tips within Word and other Office applications. Clippy became widely recognized—sometimes humorously so—for interrupting users with unsolicited advice. Microsoft retired Clippy from Office in 2001, though the character remains a nostalgic symbol of early AI-driven assistance.More recently, Cortana, launched in 2014 as Microsoft’s digital voice assistant for Windows and mobile devices, aimed to provide natural-language interaction similar to Apple’s Siri or Amazon’s Alexa. Despite positive early reception, Cortana’s role diminished as Microsoft refocused on enterprise productivity and AI integration. The service was officially discontinued on Windows in 2023.Mico, by contrast, represents a modern reimagining of that tradition—combining the personality of early assistants with the intelligence and adaptability of contemporary AI models. Where Clippy offered canned responses, Mico listens, learns, and reflects a user’s mood in real time. The goal, as Suleyman framed it, is to create an AI that feels “helpful, supportive, and deeply personal.”Groups Are Microsoft&#x27;s Version of Claude and ChatGPT ProjectsDuring Microsoft’s launch video, product researcher Wendy described Groups as a transformative shift: “You can finally bring in other people directly to the conversation that you’re having with Copilot,” she said. “It’s the only place you can do this.”Up to 32 users can join a shared Copilot session, brainstorming, editing, or planning together while the AI manages logistics such as summarizing discussion threads, tallying votes, and splitting tasks. Participants can enter or exit sessions using a link, maintaining full visibility into ongoing work.Instead of a single user prompting an AI and later sharing results, Groups lets teams prompt and iterate together in one unified conversation. In some ways, it&#x27;s an answer to Anthropic’s Claude Projects and OpenAI’s ChatGPT Projects, both launched within the last year as tools to centralize team workspaces and shared AI context. Where Claude and ChatGPT Projects allow users to aggregate files, prompts, and conversations into a single container, Groups extends that model into real-time, multi-participant collaboration. Unlike Anthropic’s and OpenAI’s implementations, Groups is deeply embedded within Microsoft’s productivity environment. Like other Copilot experiences connected to Outlook and OneDrive, Groups operates within Microsoft’s enterprise identity framework, governed by Microsoft 365 and Entra ID (formerly Azure Active Directory) authentication and consent modelsThis means conversations, shared artifacts, and generated summaries are governed under the same compliance policies that already protect Outlook, Teams, and SharePoint data.Hours after the unveiling, OpenAI hit back against its own investor in the escalating AI competition between the \"frenemies\" by expanding its Shared Projects feature beyond its current Enterprise, Team, and Edu subscriber availability to users of its free, Plus, and Pro subscription tiers. Operational Impact for AI and Data TeamsMemory & Personalization and Connectors effectively extend a lightweight orchestration layer across Microsoft’s ecosystem. Instead of building separate context-stores or retrieval APIs, teams can leverage Copilot’s secure integration with OneDrive or SharePoint as a governed data backbone. A presenter explained that Copilot’s memory “naturally picks up on important details and remembers them long after you’ve had the conversation,” yet remains editable. For data engineers, Copilot Search and Connectors reduce friction in data discovery across multiple systems. Natural-language retrieval from internal and cloud repositories may lower the cost of knowledge management initiatives by consolidating search endpoints.For security directors, Copilot’s explicit consent requirements and on/off toggles in Edge and Windows help maintain data residency standards. The company reiterated during the livestream that Copilot “acts only with user permission and within organizational privacy controls.”Copilot Mode in Edge: The AI Browser for Research and AutomationCopilot Mode in Edge stands out for offering AI-assisted information workflows. The browser can now parse open tabs, summarize differences, and perform transactional steps.“Historically, browsers have been static—just endless clicking and tab-hopping,” said a presenter during Microsoft’s livestream. “We asked not how browsers should work, but how people work.”In practice, an analyst could prompt Edge to compare supplier documentation, extract structured data, and auto-fill procurement forms—all with consistent citation. Voice-only navigation enables accessibility and multitasking, while Journeys, a companion feature, organizes browsing sessions into storylines for later review.Copilot on Windows: The Operating System as an AI SurfaceIn Windows 11, Copilot now functions as an embedded assistant. With the wake-word “Hey Copilot,” users can initiate context-aware commands without leaving the desktop—drafting documentation, troubleshooting configuration issues, or summarizing system logs.A presenter described it as a “super assistant plugged into all your files and applications.” For enterprises standardizing on Windows 11, this positions Copilot as a native productivity layer rather than an add-on, reducing training friction and promoting secure, on-device reasoning.Copilot Vision, now in early deployment, adds visual comprehension. IT staff can capture a screen region and ask Copilot to interpret error messages, explain configuration options, or generate support tickets automatically.Combined with Copilot Pages, which supports up to twenty concurrent file uploads, this enables more efficient cross-document analysis for audits, RFPs, or code reviews.Leveraging MAI Models for Multimodal WorkflowsAt the foundation of these capabilities are Microsoft’s proprietary MAI-Voice-1, MAI-1 Preview, and MAI-Vision-1 models—trained in-house to handle text, voice, and visual inputs cohesively.For engineering teams managing LLM orchestration, this architecture introduces several potential efficiencies:Unified multimodal reasoning – Reduces the need for separate ASR (speech-to-text) and image-parsing services.Fine-tuning continuity – Because Microsoft owns the model stack, updates propagate across Copilot experiences without re-integration.Predictable latency and governance – In-house hosting under Azure compliance frameworks simplifies security certification for regulated industries.A presenter described the new stack as “the foundation for immersive, creative, and dynamic experiences that still respect enterprise boundaries.”A Strategic Pivot Toward Contextual AIFor years, Microsoft positioned Copilot primarily as a productivity companion. With the Fall 2025 release, it crosses into operational AI infrastructure—a set of extensible services for reasoning over data and processes.Suleyman described this evolution succinctly: “Judge an AI by how much it elevates human potential, not just by its own smarts.” For CIOs and technical leads, the elevation comes from efficiency and interoperability.Copilot now acts as:A connective interface linking files, communications, and cloud data.A reasoning agent capable of understanding context across sessions and modalities.A secure orchestration layer compatible with Microsoft’s compliance and identity framework.Suleyman’s insistence that “technology should work in service of people” now extends to organizations as well: technology that serves teams, not workloads; systems that adapt to enterprise context rather than demand it.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1Y044YCqXidwgzt8iDL4XH/2a45ab0dfe64db4d9371db86b1d0e5d2/cfr0z3n_flat_2D_illustration_mod_colorful_playful_whimsical_sty_715bb078-8762-43bc-93ec-ce95bb5d570d.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/mico-is-microsofts-clippy-for-the-ai-age-174524597.html",
          "published_at": "Thu, 23 Oct 2025 17:45:24 +0000",
          "title": "Mico is Microsoft's Clippy for the AI age",
          "standfirst": "What if Clippy were powered by AI? That seems to be the pitch behind Microsoft's new \"expressive, customizable and warm\" face of Copilot's voice mode. The friendly blob listens, reacts and changes color in response to user interactions. Microsoft sees Mico as an answer to what an \"AI companion\" looks like. The \"optional visual presence\" aims to listen and support without kissing ass. \"It will push back on you sometimes, but always respectfully,\" Microsoft AI CEO Mustafa Suleyman wrote in a blog post. But don't take my word for it. Get ready for the most exciting 39 seconds of your day, as you watch Mico silently spin and shift hues. Clippy — I mean, Mico — is also part of a new Copilot feature called Learn Live. The student-focused voice mode will have Mico act as a Socratic tutor that \"guides you through concepts instead of just giving answers.\" Its tools will include questions, visual cues and interactive whiteboards. The Verge reports that Mico is only available in the US, UK and Canada at launch. The character is now being enabled by default for Copilot's voice mode. But you can turn it off if talking to fictional characters isn't your thing.This article originally appeared on Engadget at https://www.engadget.com/ai/mico-is-microsofts-clippy-for-the-ai-age-174524597.html?src=rss",
          "content": "What if Clippy were powered by AI? That seems to be the pitch behind Microsoft's new \"expressive, customizable and warm\" face of Copilot's voice mode. The friendly blob listens, reacts and changes color in response to user interactions. Microsoft sees Mico as an answer to what an \"AI companion\" looks like. The \"optional visual presence\" aims to listen and support without kissing ass. \"It will push back on you sometimes, but always respectfully,\" Microsoft AI CEO Mustafa Suleyman wrote in a blog post. But don't take my word for it. Get ready for the most exciting 39 seconds of your day, as you watch Mico silently spin and shift hues. Clippy — I mean, Mico — is also part of a new Copilot feature called Learn Live. The student-focused voice mode will have Mico act as a Socratic tutor that \"guides you through concepts instead of just giving answers.\" Its tools will include questions, visual cues and interactive whiteboards. The Verge reports that Mico is only available in the US, UK and Canada at launch. The character is now being enabled by default for Copilot's voice mode. But you can turn it off if talking to fictional characters isn't your thing.This article originally appeared on Engadget at https://www.engadget.com/ai/mico-is-microsofts-clippy-for-the-ai-age-174524597.html?src=rss",
          "feed_position": 17
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/claude-can-now-compartmentalize-as-part-of-a-major-memory-upgrade-170000194.html",
          "published_at": "Thu, 23 Oct 2025 17:00:00 +0000",
          "title": "Claude can now compartmentalize as part of a major memory upgrade",
          "standfirst": "Back in August, Anthropic made Claude capable of remembering past conversations. With the update, people could reference specific chats, so that they wouldn't need to repeat themselves when revisiting a topic. Today, the company has begun out a new, enhanced memory feature set, with the included improvements coming to all paying users. Plenty of chatbots, including ChatGPT and Gemini, can remember past conversations, but Anthropic believes its implementation has a few legs up on the competition. For one, Claude will learn your preferences and work patterns over time, which Anthropic says will translate to the chatbot getting better at understanding how you work. Additionally, the company claims Claude is \"fully transparent\" about its memory, meaning users will see an \"actual synthesis\" of what it has recorded over time, instead of \"vague summaries.\" If you want to edit its memory, you can do so through conversation. At the same, Anthropic has made it easy to compartmentalize the data Claude collects. When using the Projects feature to group conversations together, the chatbot will create a distinct memory space for each grouping. In this way, information Claude has saved from your work conversations won't bleed over to your personal chats, for example. If you're coming from ChatGPT or Gemini, Anthropic has made it possible to import saved memories from those chatbots to Claude. You can also export any tidbits of context Claude saves to other AI platforms. Ahead of today's announcement, Anthropic notes it conducted extensive testing to determine if Claude's new capabilities would lead to greater sycophancy and more harmful conversations. \"Though this testing, we identified areas where Claude’s responses needed refinement and made targeted adjustments to how memory functions,\" the company said. \"These iterations helped us build and improve the memory feature in a way that allows Claude to provide helpful and safe responses to users.\" Max subscribers can enable Claude new memory capabilities starting today, with availability for Pro users to follow in the coming days. The feature is fully optional, and won't be turned on unless you toggle it through the settings menu.This article originally appeared on Engadget at https://www.engadget.com/ai/claude-can-now-compartmentalize-as-part-of-a-major-memory-upgrade-170000194.html?src=rss",
          "content": "Back in August, Anthropic made Claude capable of remembering past conversations. With the update, people could reference specific chats, so that they wouldn't need to repeat themselves when revisiting a topic. Today, the company has begun out a new, enhanced memory feature set, with the included improvements coming to all paying users. Plenty of chatbots, including ChatGPT and Gemini, can remember past conversations, but Anthropic believes its implementation has a few legs up on the competition. For one, Claude will learn your preferences and work patterns over time, which Anthropic says will translate to the chatbot getting better at understanding how you work. Additionally, the company claims Claude is \"fully transparent\" about its memory, meaning users will see an \"actual synthesis\" of what it has recorded over time, instead of \"vague summaries.\" If you want to edit its memory, you can do so through conversation. At the same, Anthropic has made it easy to compartmentalize the data Claude collects. When using the Projects feature to group conversations together, the chatbot will create a distinct memory space for each grouping. In this way, information Claude has saved from your work conversations won't bleed over to your personal chats, for example. If you're coming from ChatGPT or Gemini, Anthropic has made it possible to import saved memories from those chatbots to Claude. You can also export any tidbits of context Claude saves to other AI platforms. Ahead of today's announcement, Anthropic notes it conducted extensive testing to determine if Claude's new capabilities would lead to greater sycophancy and more harmful conversations. \"Though this testing, we identified areas where Claude’s responses needed refinement and made targeted adjustments to how memory functions,\" the company said. \"These iterations helped us build and improve the memory feature in a way that allows Claude to provide helpful and safe responses to users.\" Max subscribers can enable Claude new memory capabilities starting today, with availability for Pro users to follow in the coming days. The feature is fully optional, and won't be turned on unless you toggle it through the settings menu.This article originally appeared on Engadget at https://www.engadget.com/ai/claude-can-now-compartmentalize-as-part-of-a-major-memory-upgrade-170000194.html?src=rss",
          "feed_position": 20
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/amazon-calls-on-ai-once-again-with-its-new-help-me-decide-shopping-tool-164516673.html",
          "published_at": "Thu, 23 Oct 2025 16:45:16 +0000",
          "title": "Amazon calls on AI once again with its new ‘Help Me Decide’ shopping tool",
          "standfirst": "People are evidently never buying quite enough stuff from Amazon to keep the company entirely happy, and it's calling on AI once again to push indecisive shoppers into locking down the purchase they’ve been eyeing up. The new tool, which Amazon calls Help Me Decide, gives shoppers in the US personalized recommendations of products they should buy by analyzing their browsing history, searches and preferences. It’s designed to \"help\" customers who have been looking at a number of products in a particular category, such as wireless headphones, to decide which one best suits their needs. The Help Me Decide button will pop up on a product detail page when it detects that you’ve been browsing for a while without making a final choice. If you choose to tap for AI assistance, it will pull together all the information it can find on your relevant shopping history and recommend the product it deems the right choice for you. It also recommends an alternative upgrade pick and a similar product for those on a budget. Help Me Decide can also group together related searches. Amazon uses the example of the tool recommending an all-season tent for four people based on you previously looking for adult and kids’ sleeping bags that keep you warm, camping accessories and children’s hiking boots. The recommendation it chooses includes an explanation of why it’s the best pick for you based on its features and your previous purchases, and pulls in customer reviews to back it up. This suggests that how useful the recommendations are will ultimately come down to how much you take notice of customer reviews. When searching for products to recommend to you, Help Me Decide leverages Amazon's Bedrock and SageMaker machine learning platforms, as well as its OpenSearch tool, to marry up all the different factors it takes into consideration. It follows the introduction of the Interests tool earlier this year, which uses AI to generate shopping results based on your natural language prompts. Back In May, the company also started experimenting with AI-generated hosts that can summarise products for you before you buy them, again relying heavily on customer reviews for its information. Help Me Decide is live in the US now and can be found in the Amazon app (iOS and Android) and mobile browser. If you tap “Keep shopping for” it should show up, and will do the same on a product detail page after you’ve looked at a number of products in a related category.This article originally appeared on Engadget at https://www.engadget.com/ai/amazon-calls-on-ai-once-again-with-its-new-help-me-decide-shopping-tool-164516673.html?src=rss",
          "content": "People are evidently never buying quite enough stuff from Amazon to keep the company entirely happy, and it's calling on AI once again to push indecisive shoppers into locking down the purchase they’ve been eyeing up. The new tool, which Amazon calls Help Me Decide, gives shoppers in the US personalized recommendations of products they should buy by analyzing their browsing history, searches and preferences. It’s designed to \"help\" customers who have been looking at a number of products in a particular category, such as wireless headphones, to decide which one best suits their needs. The Help Me Decide button will pop up on a product detail page when it detects that you’ve been browsing for a while without making a final choice. If you choose to tap for AI assistance, it will pull together all the information it can find on your relevant shopping history and recommend the product it deems the right choice for you. It also recommends an alternative upgrade pick and a similar product for those on a budget. Help Me Decide can also group together related searches. Amazon uses the example of the tool recommending an all-season tent for four people based on you previously looking for adult and kids’ sleeping bags that keep you warm, camping accessories and children’s hiking boots. The recommendation it chooses includes an explanation of why it’s the best pick for you based on its features and your previous purchases, and pulls in customer reviews to back it up. This suggests that how useful the recommendations are will ultimately come down to how much you take notice of customer reviews. When searching for products to recommend to you, Help Me Decide leverages Amazon's Bedrock and SageMaker machine learning platforms, as well as its OpenSearch tool, to marry up all the different factors it takes into consideration. It follows the introduction of the Interests tool earlier this year, which uses AI to generate shopping results based on your natural language prompts. Back In May, the company also started experimenting with AI-generated hosts that can summarise products for you before you buy them, again relying heavily on customer reviews for its information. Help Me Decide is live in the US now and can be found in the Amazon app (iOS and Android) and mobile browser. If you tap “Keep shopping for” it should show up, and will do the same on a product detail page after you’ve looked at a number of products in a related category.This article originally appeared on Engadget at https://www.engadget.com/ai/amazon-calls-on-ai-once-again-with-its-new-help-me-decide-shopping-tool-164516673.html?src=rss",
          "feed_position": 21
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/microsoft-makes-edges-copilot-mode-a-bit-smarter-160031147.html",
          "published_at": "Thu, 23 Oct 2025 16:00:31 +0000",
          "title": "Microsoft makes Edge's Copilot Mode a bit smarter",
          "standfirst": "Apparently, web browsers are cool again. Two days after OpenAI launched its AI browser, Microsoft has some updates for its Edge's AI mode. (Fancy that!) Copilot Mode, introduced in July, now has several features that were teased at launch. First up: Copilot Actions, which is Microsoft's branding for AI-assisted, multi-step tasks. This feature is already available in the standard version of Copilot, but it's now being previewed for Edge's Copilot Mode. Microsoft's examples of Copilot Actions in Edge include unsubscribing from email newsletters or making a restaurant reservation. Another new (but previously announced) feature is Journeys. These are saved projects you can return to anytime. \"Remember that project you started a while back, but life got in the way?\" Microsoft's blog post asks. \"No need to bookmark all those tabs.\" For example, if you're researching starting a business, Copilot can recap articles you've read, suggest next steps and resurface a tutorial video you watched. Here's a video from when Microsoft teased Journeys in July. Along similar lines, another new Copilot Mode feature is the option to let the assistant access your browsing history. One example Microsoft gives is chatting with Copilot about a clothing item you checked out last week. Or, ask it for movie recommendations based on content you previously liked. Copilot requires explicit permission to access your private data for these new features. Microsoft's blog post stresses that your browser data is protected under the company's privacy statement and that Copilot \"only collects what's needed to improve your experience.\" The company also notes that you'll see clear visual cues so you know when Copilot is active. Still, these features require loads of private information to be useful. Don't grant those permissions without first giving it some serious thought. The new Copilot features are currently free in a US-only \"limited preview.\"This article originally appeared on Engadget at https://www.engadget.com/ai/microsoft-makes-edges-copilot-mode-a-bit-smarter-160031147.html?src=rss",
          "content": "Apparently, web browsers are cool again. Two days after OpenAI launched its AI browser, Microsoft has some updates for its Edge's AI mode. (Fancy that!) Copilot Mode, introduced in July, now has several features that were teased at launch. First up: Copilot Actions, which is Microsoft's branding for AI-assisted, multi-step tasks. This feature is already available in the standard version of Copilot, but it's now being previewed for Edge's Copilot Mode. Microsoft's examples of Copilot Actions in Edge include unsubscribing from email newsletters or making a restaurant reservation. Another new (but previously announced) feature is Journeys. These are saved projects you can return to anytime. \"Remember that project you started a while back, but life got in the way?\" Microsoft's blog post asks. \"No need to bookmark all those tabs.\" For example, if you're researching starting a business, Copilot can recap articles you've read, suggest next steps and resurface a tutorial video you watched. Here's a video from when Microsoft teased Journeys in July. Along similar lines, another new Copilot Mode feature is the option to let the assistant access your browsing history. One example Microsoft gives is chatting with Copilot about a clothing item you checked out last week. Or, ask it for movie recommendations based on content you previously liked. Copilot requires explicit permission to access your private data for these new features. Microsoft's blog post stresses that your browser data is protected under the company's privacy statement and that Copilot \"only collects what's needed to improve your experience.\" The company also notes that you'll see clear visual cues so you know when Copilot is active. Still, these features require loads of private information to be useful. Don't grant those permissions without first giving it some serious thought. The new Copilot features are currently free in a US-only \"limited preview.\"This article originally appeared on Engadget at https://www.engadget.com/ai/microsoft-makes-edges-copilot-mode-a-bit-smarter-160031147.html?src=rss",
          "feed_position": 23
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/baby-steps-isnt-done-with-maxi-boch-140000613.html",
          "published_at": "Thu, 23 Oct 2025 14:00:00 +0000",
          "title": "Baby Steps isn't done with Maxi Boch",
          "standfirst": "Maxi Boch isn’t done with Baby Steps. Boch has enjoyed a productive career in game development and she knows how it feels to be creatively finished with a project. She experienced it at various points with Rock Band, Dance Central, Fantasia: Music Evolved and Ape Out, but on Baby Steps’ launch day, done was not the vibe. “I've been in the industry for a long time; I shipped broken strumbars for Rock Band,” Boch told Engadget. “I know that things change over time in this world, and it's not to say that Baby Steps is not done. It's done. But whether I'm done with Baby Steps, this is a different story.” To make a long one short: Boch’s collaborators, Bennett Foddy and Gabe Cuzzillo, were ready and excited to ship the game before she was, and so they did. Baby Steps hit PC and PlayStation 5 on September 23, 2025 (following one strategic delay to avoid the Hollow Knight: Silksong release window). From the player’s side, Baby Steps feels like a finely honed experience. It’s a walking simulator that follows Nate, a manchild in a gray onesie, as he attempts to scale a mountain and symbolically escape his parents’ basement. The player controls Nate’s legs individually, lifting each knee and carefully placing one foot in front of the other, learning how to walk in the very literal sense. Baby Steps succeeds because of its mechanical precision, but it excels because of its irreverent tone, magically surreal setting and AAA levels of polish. The mountain is a mix of childhood memories and adult anxieties represented by giant chess pieces, rude graffiti, and a crew of drinking, smoking, anthropomorphic donkeys who wander the cliffs with their dicks swinging free. Improvised dialogue between Nate and the NPCs turns each cutscene into a comedy sketch, but his journey also includes shocking revelations of existential numbness. In Baby Steps, falling is just as much of a mechanic as walking. You will fall — dramatically, drastically, down crevasses that took hours to climb — and Nate will bounce and slide and eventually just lay there, mumbling to himself while his onesie fills with mud. And then you’ll pick him back up and start walking again. You’ll settle his steps into a soothing cadence. You’ll marvel at the way his sweat slowly saturates the material at the base of his spine, just above his bulbous butt. You’ll try to skip a cutscene and realize that in order to do so, you need to play a minigame with the X prompt. You’ll learn how to run. And somewhere along the way, you’ll remember what it feels like to just enjoy play. Baby StepsDevolver Digital As a former marching band member, I appreciate the sense of rhythm that’s built into Baby Steps, spurred by the animal sounds and natural-world musical cues that are tied to Nate’s footfall in specific areas. This is Boch’s area of expertise, and also the main reason she doesn’t feel finished with the game. Boch and her collaborators ended up using a slapdash mosaic of audio middleware and low-level software for Baby Steps, and a series of late-stage issues infused all of the songs in the game with incorrect samples. On launch day, the music and audio cues weren’t reacting as intended when Nate stepped, stumbled and fell. On September 23, the day that Baby Steps came out, Boch and I talked for an hour about its development process. Our conversation gently circled the topic of perseverance, the game’s core theme, but we only directly acknowledged it at minute 59. It’s not something you need to scream or repeat — tenacity is the obvious message in a game about climbing a mountain on wobbly feet — but it was fascinating to learn why Boch in particular was inspired to build a game about endurance. Making Baby Steps Boch, Foddy and Cuzzillo started working on Baby Steps right after they released Ape Out and cemented their names in the annals of frenetic, bloody and slightly silly indie history. Foddy was already known as the creator of QWOP, GIRP and Getting Over It, and Boch as the rhythmic and hardware mastermind behind the largest AAA music games of the mid-2000s. The trio worked out of Boch and Foddy’s shared office at the NYU Game Center, where they were instructors and Cuzzillo was finishing up a graduate degree with Ape Out as his final project. They began prototyping Baby Steps around March 2019. “At that point, I also started manifesting more symptoms of my chronic illness, and so I was in the midst of a period of an attempt at really intense reconditioning, which ultimately failed,” Boch said. “But when that period was over, I joined up with the crew again.” Boch lives with a trifecta of chronic illnesses: Ehlers-Danlos Syndrome, Postural Orthostatic Tachycardia Syndrome and Mast Cell Activation Syndrome. EDS is a connective tissue disorder that affects the entire body, and it can cause hypermobility, fatigue, vision issues, fragile skin and an increased risk of vascular ruptures. People with POTS experience an abnormally large increase in heart rate when changing posture, and MCAS is a disorder that releases excessive amounts of histamine and similar chemicals in the body, causing random and potentially life-threatening allergic reactions. It’s common for people with one of these diagnoses to also receive the others. “It’s been an incredible challenge,” Boch said. “I think, easily, the hardest thing I've had to deal with in my life. I think there's something very singular about each one of us, the three core members of this crew, and part of that is our ability to work fluidly across disciplines and the like. But another part of it is just a level of stick-to-it-iveness that my body has handily rejected, and so I'm in a fight with it all the time.” Baby StepsDevolver Digital Boch has an arsenal of specialized tools to help her create games, including ergonomic (and very expensive) keyboards and a pair of glasses that act as a mouse. “I have found that most of what game development is about and is oriented around is kind of hostile to those of us with poor fine-motor skills, and it's an odd thing to be experiencing alongside the making of a thing that is stridently difficult,” Boch said. “There's odd moments in it, where I have been going through physical therapy processes to retrain my actual walking, alongside working on this thing that is deconstructing walking. A very odd subset of feelings.” Boch said the hardest thing for her to contend with is the moment-to-moment unpredictability of her health. But by the fall of 2019, she was back in the office with Cuzzillo and Foddy, iterating on the ideas that would eventually become Baby Steps. Cuzzillo and Foddy were feeling slightly discouraged at this point: They were four or five ideas deep, messing around with a competitive, real-time strategy game or a SimCity type of experience, but nothing was quite right. Boch encouraged them to return to their ridiculous, mechanically-driven roots. “I think it started to become a lot clearer in everyone's mind when it started to take on aspects of Bennett’s work,” Boch said. “The first handful of years of Baby Steps’ development, we were all playing various sorts of roles. The work of VO direction, recording and narrative development was something we were all working on together. Some of the foundational narrative premise things are concepts that I brought to the table as ways to try and prop up some world around this character. Lots of tools building and infrastructural work and all of the foundational stuff that makes it possible for a team that's so tiny to make a thing that's so strong.” The Baby Steps crew shared a house in upstate New York during the first winter of the pandemic in 2020. They hiked together and worked on the game at one big folding table, enjoying the mountain air with their partners and each other. There were no strict roles on the game development side, with Boch, Cuzzillo and Foddy contributing to all aspects at once, including voice work. “Over time, there are aspects of the narrative development that became increasingly more personal to my collaborators,” Boch said. “And they started to feel more comfortable in a director-less environment in terms of coaxing naturalistic performances out of themselves, and so that work became more disjointed.” By the time they were recording voices and finding characters through improvisation in the sound booth, Boch happened to be in the early stages of transitioning. Vocal training and voice acting are a tricky mix, it turns out. “I kind of recognized what it was going to take to be doing voiceover performance myself in the midst of my early transition, and I made the call that it was not the right activity for me,” Boch said. “So my characters were cut — it was like one or two — and I endeavored to strike up some novel collaborations on the audio side.” For the past year and half in particular, Boch has been focused on all things audio in Baby Steps, as well as overseeing big-picture production tasks. She brought on a collaborator from the world of hardcore techno music, Jack Schlesinger, and he primarily handled system architecture details while Boch dealt with creative aspects. DJ Ashe Kilbourne and harpist Emily Hopkins rounded out the list of audio contributors. When she was able, Boch took an improvised sound kit into the wild and collected nature noises, and the team stitched together a reactive audio system using middleware and leftover bits of software from the Harmonix days. When Baby Steps’ dynamic audio kicks in, and the boops, chirps and thunks start layering on top of one another as Nate waddles along, it adds a delicious sense of hypnosis to the game. Unfortunately, the audio systems fell apart in the final weeks before launch. The VO was fine, but many of the sounds and beats weren’t populating in the right places at the proper times, and Boch’s vision wasn’t being clearly communicated day-one. “The foundations of game audio tooling are terrible,” Boch said. She continued, “The world of game audio, from my perspective, is a bunch of people who are sitting on top of a bunch of work they've done to write drivers to talk to consoles, and a bunch of work they've done to forge relationships with console manufacturers so that their audio technology will be licensed by the two major engines. But they're both trash. I will not endorse either one, and I will not say that either one is capable of doing the kind of work that I need done.” Since launch, the Baby Steps audio team has released patches addressing the sampling issues and adjusting dynamic audio cues across the game. An imminent update will introduce animals singing along with the songs, outdoor and indoor reverb simulations across all sounds, and other fixes. Boch has additional updates and surprises planned, including a Baby Steps Fi Beats livestream to showcase the game’s music on YouTube. By November, the audio team will be focused on composing. Baby Steps is only going to get more immersive as the audio improvements roll out. And if you listen closely, you’ll be able to hear Boch voicing a few small roles throughout the game. “I play, like, a baby and a hypothetical gay partner for Nate and a bunch of other random characters,” Boch said. “There's some cosmic sadness on my part, that the timing worked out in exactly the ways that it did. But I don't know, it's the cards you're dealt. It's important to do the thing that's true to you.” One glaring truth that shook out during the Baby Steps development process was the supremely close and infectious bond between Cuzzillo and Foddy. The game’s dialogue and cutscenes are composed of off-the-cuff conversations and rambling inside jokes between Cuzzillo and Foddy, and each of these moments is delightful in a chaotic kind of way. Like a classic comedy duo, these developers share an undeniable resonance. They’re even born on the same day and they have older brothers with the same birthday, two facts that Boch finds adorable. “I'm not a horoscope person at all, but they have a kind of cosmic level of synchronicity that they both acknowledge, but also are a little bit like, ‘What, this?’” Boch said. “They have plenty that they disagree about and plenty that they bicker about, but there's something about their orientations toward the world that's perplexing and generative. They are immensely talented folks.” Taking Baby Steps In the end, Cuzzillo and Foddy felt finished with Baby Steps before Boch. She didn’t want to hold their joy hostage, so the audio team made it work and they shipped the game on September 23, 2025, published by Devolver Digital. “That kind of dream-deferred shit is emotional torture, and so I had no interest in putting them through that, they had no interest in going through that,” Boch said. “It makes sense to me to be landing in the place that we are.” Baby StepsDevolver Digital I caught up with Boch three weeks after Baby Steps’ release date to see if she was feeling more done, now that the launch-day dust had settled. She said it was a hard question. “There is so much more that I am interested in exploring, and so much more that I have set up in terms of pins to knock down,” she said. “I think this is a struggle that highlights the inherent tension of trying to make art at this boundary between a fine art practice and a commercial art practice. I think that for the sake of the work, and for the sake of me and my team as artists, the tech I have built deserves to continue to be refined in a different context, one wherein sound is more paramount. That's where we're headed.” This is a tease of what’s next for Boch, even though she’s still finishing up Baby Steps. She’s planning on leaving NYU, spurred by the unpredictability of her health, but she’s not done making games. Her next one will be more personal. “It's important to me to share what I'm doing with people,” Boch said in September. “I think that there is not enough in the world of games that puts audio at its very center. I think that my personal ambitions and future ambitions are definitely leaning more in that direction by the day. I had a long time of needing to get some space from interactive audio as The Thing. Where my winds are blowing is in that direction.” Baby Steps exists in its current form because Boch and her teammates were able to adapt and endure. They were honest about what was working, what wasn’t and what could, and they leaned into the aspects that felt the most natural to them. Boch in particular set aside her ego, listened to her body, and took things day by day. You know, baby steps. “The process of transition is one that involves an enormous amount of self-reflection and a growing sense of self knowledge,” Boch said. “Ultimately, that process for me was kind of orthogonal to the storytelling of Baby Steps. There's a lot that comes from lived experience, and from commiserating and sharing that lived experience between Bennett and Gabe, and you can see that very clearly in the work. There's also just ways in which that process was illuminating to me in terms of inherent differences. There's an aspect of it that came alongside the necessity of slowing down, and then the subsequent necessity of staying inside that hit with my chronic illness and then Covid. There was a way in which I was more with myself at that moment than I’ve ever been.”This article originally appeared on Engadget at https://www.engadget.com/gaming/baby-steps-isnt-done-with-maxi-boch-140000613.html?src=rss",
          "content": "Maxi Boch isn’t done with Baby Steps. Boch has enjoyed a productive career in game development and she knows how it feels to be creatively finished with a project. She experienced it at various points with Rock Band, Dance Central, Fantasia: Music Evolved and Ape Out, but on Baby Steps’ launch day, done was not the vibe. “I've been in the industry for a long time; I shipped broken strumbars for Rock Band,” Boch told Engadget. “I know that things change over time in this world, and it's not to say that Baby Steps is not done. It's done. But whether I'm done with Baby Steps, this is a different story.” To make a long one short: Boch’s collaborators, Bennett Foddy and Gabe Cuzzillo, were ready and excited to ship the game before she was, and so they did. Baby Steps hit PC and PlayStation 5 on September 23, 2025 (following one strategic delay to avoid the Hollow Knight: Silksong release window). From the player’s side, Baby Steps feels like a finely honed experience. It’s a walking simulator that follows Nate, a manchild in a gray onesie, as he attempts to scale a mountain and symbolically escape his parents’ basement. The player controls Nate’s legs individually, lifting each knee and carefully placing one foot in front of the other, learning how to walk in the very literal sense. Baby Steps succeeds because of its mechanical precision, but it excels because of its irreverent tone, magically surreal setting and AAA levels of polish. The mountain is a mix of childhood memories and adult anxieties represented by giant chess pieces, rude graffiti, and a crew of drinking, smoking, anthropomorphic donkeys who wander the cliffs with their dicks swinging free. Improvised dialogue between Nate and the NPCs turns each cutscene into a comedy sketch, but his journey also includes shocking revelations of existential numbness. In Baby Steps, falling is just as much of a mechanic as walking. You will fall — dramatically, drastically, down crevasses that took hours to climb — and Nate will bounce and slide and eventually just lay there, mumbling to himself while his onesie fills with mud. And then you’ll pick him back up and start walking again. You’ll settle his steps into a soothing cadence. You’ll marvel at the way his sweat slowly saturates the material at the base of his spine, just above his bulbous butt. You’ll try to skip a cutscene and realize that in order to do so, you need to play a minigame with the X prompt. You’ll learn how to run. And somewhere along the way, you’ll remember what it feels like to just enjoy play. Baby StepsDevolver Digital As a former marching band member, I appreciate the sense of rhythm that’s built into Baby Steps, spurred by the animal sounds and natural-world musical cues that are tied to Nate’s footfall in specific areas. This is Boch’s area of expertise, and also the main reason she doesn’t feel finished with the game. Boch and her collaborators ended up using a slapdash mosaic of audio middleware and low-level software for Baby Steps, and a series of late-stage issues infused all of the songs in the game with incorrect samples. On launch day, the music and audio cues weren’t reacting as intended when Nate stepped, stumbled and fell. On September 23, the day that Baby Steps came out, Boch and I talked for an hour about its development process. Our conversation gently circled the topic of perseverance, the game’s core theme, but we only directly acknowledged it at minute 59. It’s not something you need to scream or repeat — tenacity is the obvious message in a game about climbing a mountain on wobbly feet — but it was fascinating to learn why Boch in particular was inspired to build a game about endurance. Making Baby Steps Boch, Foddy and Cuzzillo started working on Baby Steps right after they released Ape Out and cemented their names in the annals of frenetic, bloody and slightly silly indie history. Foddy was already known as the creator of QWOP, GIRP and Getting Over It, and Boch as the rhythmic and hardware mastermind behind the largest AAA music games of the mid-2000s. The trio worked out of Boch and Foddy’s shared office at the NYU Game Center, where they were instructors and Cuzzillo was finishing up a graduate degree with Ape Out as his final project. They began prototyping Baby Steps around March 2019. “At that point, I also started manifesting more symptoms of my chronic illness, and so I was in the midst of a period of an attempt at really intense reconditioning, which ultimately failed,” Boch said. “But when that period was over, I joined up with the crew again.” Boch lives with a trifecta of chronic illnesses: Ehlers-Danlos Syndrome, Postural Orthostatic Tachycardia Syndrome and Mast Cell Activation Syndrome. EDS is a connective tissue disorder that affects the entire body, and it can cause hypermobility, fatigue, vision issues, fragile skin and an increased risk of vascular ruptures. People with POTS experience an abnormally large increase in heart rate when changing posture, and MCAS is a disorder that releases excessive amounts of histamine and similar chemicals in the body, causing random and potentially life-threatening allergic reactions. It’s common for people with one of these diagnoses to also receive the others. “It’s been an incredible challenge,” Boch said. “I think, easily, the hardest thing I've had to deal with in my life. I think there's something very singular about each one of us, the three core members of this crew, and part of that is our ability to work fluidly across disciplines and the like. But another part of it is just a level of stick-to-it-iveness that my body has handily rejected, and so I'm in a fight with it all the time.” Baby StepsDevolver Digital Boch has an arsenal of specialized tools to help her create games, including ergonomic (and very expensive) keyboards and a pair of glasses that act as a mouse. “I have found that most of what game development is about and is oriented around is kind of hostile to those of us with poor fine-motor skills, and it's an odd thing to be experiencing alongside the making of a thing that is stridently difficult,” Boch said. “There's odd moments in it, where I have been going through physical therapy processes to retrain my actual walking, alongside working on this thing that is deconstructing walking. A very odd subset of feelings.” Boch said the hardest thing for her to contend with is the moment-to-moment unpredictability of her health. But by the fall of 2019, she was back in the office with Cuzzillo and Foddy, iterating on the ideas that would eventually become Baby Steps. Cuzzillo and Foddy were feeling slightly discouraged at this point: They were four or five ideas deep, messing around with a competitive, real-time strategy game or a SimCity type of experience, but nothing was quite right. Boch encouraged them to return to their ridiculous, mechanically-driven roots. “I think it started to become a lot clearer in everyone's mind when it started to take on aspects of Bennett’s work,” Boch said. “The first handful of years of Baby Steps’ development, we were all playing various sorts of roles. The work of VO direction, recording and narrative development was something we were all working on together. Some of the foundational narrative premise things are concepts that I brought to the table as ways to try and prop up some world around this character. Lots of tools building and infrastructural work and all of the foundational stuff that makes it possible for a team that's so tiny to make a thing that's so strong.” The Baby Steps crew shared a house in upstate New York during the first winter of the pandemic in 2020. They hiked together and worked on the game at one big folding table, enjoying the mountain air with their partners and each other. There were no strict roles on the game development side, with Boch, Cuzzillo and Foddy contributing to all aspects at once, including voice work. “Over time, there are aspects of the narrative development that became increasingly more personal to my collaborators,” Boch said. “And they started to feel more comfortable in a director-less environment in terms of coaxing naturalistic performances out of themselves, and so that work became more disjointed.” By the time they were recording voices and finding characters through improvisation in the sound booth, Boch happened to be in the early stages of transitioning. Vocal training and voice acting are a tricky mix, it turns out. “I kind of recognized what it was going to take to be doing voiceover performance myself in the midst of my early transition, and I made the call that it was not the right activity for me,” Boch said. “So my characters were cut — it was like one or two — and I endeavored to strike up some novel collaborations on the audio side.” For the past year and half in particular, Boch has been focused on all things audio in Baby Steps, as well as overseeing big-picture production tasks. She brought on a collaborator from the world of hardcore techno music, Jack Schlesinger, and he primarily handled system architecture details while Boch dealt with creative aspects. DJ Ashe Kilbourne and harpist Emily Hopkins rounded out the list of audio contributors. When she was able, Boch took an improvised sound kit into the wild and collected nature noises, and the team stitched together a reactive audio system using middleware and leftover bits of software from the Harmonix days. When Baby Steps’ dynamic audio kicks in, and the boops, chirps and thunks start layering on top of one another as Nate waddles along, it adds a delicious sense of hypnosis to the game. Unfortunately, the audio systems fell apart in the final weeks before launch. The VO was fine, but many of the sounds and beats weren’t populating in the right places at the proper times, and Boch’s vision wasn’t being clearly communicated day-one. “The foundations of game audio tooling are terrible,” Boch said. She continued, “The world of game audio, from my perspective, is a bunch of people who are sitting on top of a bunch of work they've done to write drivers to talk to consoles, and a bunch of work they've done to forge relationships with console manufacturers so that their audio technology will be licensed by the two major engines. But they're both trash. I will not endorse either one, and I will not say that either one is capable of doing the kind of work that I need done.” Since launch, the Baby Steps audio team has released patches addressing the sampling issues and adjusting dynamic audio cues across the game. An imminent update will introduce animals singing along with the songs, outdoor and indoor reverb simulations across all sounds, and other fixes. Boch has additional updates and surprises planned, including a Baby Steps Fi Beats livestream to showcase the game’s music on YouTube. By November, the audio team will be focused on composing. Baby Steps is only going to get more immersive as the audio improvements roll out. And if you listen closely, you’ll be able to hear Boch voicing a few small roles throughout the game. “I play, like, a baby and a hypothetical gay partner for Nate and a bunch of other random characters,” Boch said. “There's some cosmic sadness on my part, that the timing worked out in exactly the ways that it did. But I don't know, it's the cards you're dealt. It's important to do the thing that's true to you.” One glaring truth that shook out during the Baby Steps development process was the supremely close and infectious bond between Cuzzillo and Foddy. The game’s dialogue and cutscenes are composed of off-the-cuff conversations and rambling inside jokes between Cuzzillo and Foddy, and each of these moments is delightful in a chaotic kind of way. Like a classic comedy duo, these developers share an undeniable resonance. They’re even born on the same day and they have older brothers with the same birthday, two facts that Boch finds adorable. “I'm not a horoscope person at all, but they have a kind of cosmic level of synchronicity that they both acknowledge, but also are a little bit like, ‘What, this?’” Boch said. “They have plenty that they disagree about and plenty that they bicker about, but there's something about their orientations toward the world that's perplexing and generative. They are immensely talented folks.” Taking Baby Steps In the end, Cuzzillo and Foddy felt finished with Baby Steps before Boch. She didn’t want to hold their joy hostage, so the audio team made it work and they shipped the game on September 23, 2025, published by Devolver Digital. “That kind of dream-deferred shit is emotional torture, and so I had no interest in putting them through that, they had no interest in going through that,” Boch said. “It makes sense to me to be landing in the place that we are.” Baby StepsDevolver Digital I caught up with Boch three weeks after Baby Steps’ release date to see if she was feeling more done, now that the launch-day dust had settled. She said it was a hard question. “There is so much more that I am interested in exploring, and so much more that I have set up in terms of pins to knock down,” she said. “I think this is a struggle that highlights the inherent tension of trying to make art at this boundary between a fine art practice and a commercial art practice. I think that for the sake of the work, and for the sake of me and my team as artists, the tech I have built deserves to continue to be refined in a different context, one wherein sound is more paramount. That's where we're headed.” This is a tease of what’s next for Boch, even though she’s still finishing up Baby Steps. She’s planning on leaving NYU, spurred by the unpredictability of her health, but she’s not done making games. Her next one will be more personal. “It's important to me to share what I'm doing with people,” Boch said in September. “I think that there is not enough in the world of games that puts audio at its very center. I think that my personal ambitions and future ambitions are definitely leaning more in that direction by the day. I had a long time of needing to get some space from interactive audio as The Thing. Where my winds are blowing is in that direction.” Baby Steps exists in its current form because Boch and her teammates were able to adapt and endure. They were honest about what was working, what wasn’t and what could, and they leaned into the aspects that felt the most natural to them. Boch in particular set aside her ego, listened to her body, and took things day by day. You know, baby steps. “The process of transition is one that involves an enormous amount of self-reflection and a growing sense of self knowledge,” Boch said. “Ultimately, that process for me was kind of orthogonal to the storytelling of Baby Steps. There's a lot that comes from lived experience, and from commiserating and sharing that lived experience between Bennett and Gabe, and you can see that very clearly in the work. There's also just ways in which that process was illuminating to me in terms of inherent differences. There's an aspect of it that came alongside the necessity of slowing down, and then the subsequent necessity of staying inside that hit with my chronic illness and then Covid. There was a way in which I was more with myself at that moment than I’ve ever been.”This article originally appeared on Engadget at https://www.engadget.com/gaming/baby-steps-isnt-done-with-maxi-boch-140000613.html?src=rss",
          "feed_position": 28,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/ss_1e34e8a5237d66b978f5389924cfdfecdde60df0.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/ai-is-tearing-companies-apart-writer-ai-ceo-slams-fortune-500-leaders-for",
          "published_at": "Thu, 23 Oct 2025 13:02:00 GMT",
          "title": "‘AI is tearing companies apart’: Writer AI CEO slams Fortune 500 leaders for mismanaging tech",
          "standfirst": "May Habib, co-founder and CEO of Writer AI, delivered one of the bluntest assessments of corporate AI failures at the TED AI conference on Tuesday, revealing that nearly half of Fortune 500 executives believe artificial intelligence is actively damaging their organizations — and placing the blame squarely on leadership&#x27;s shoulders.The problem, according to Habib, isn&#x27;t the technology. It&#x27;s that business leaders are making a category error, treating AI transformation like previous technology rollouts and delegating it to IT departments. This approach, she warned, has led to \"billions of dollars spent on AI initiatives that are going nowhere.\"\"Earlier this year, we did a survey of 800 Fortune 500 C-suite executives,\" Habib told the audience of Silicon Valley executives and investors. \"42% of them said AI is tearing their company apart.\"The diagnosis challenges conventional wisdom about how enterprises should approach AI adoption. While most major companies have stood up AI task forces, appointed chief AI officers, or expanded IT budgets, Habib argues these moves reflect a fundamental misunderstanding of what AI represents: not another software tool, but a wholesale reorganization of how work gets done.\"There is something leaders are missing when they compare AI to just another tech tool,\" Habib said. \"This is not like giving accountants calculators or bankers Excel or designers Photoshop.\"Why the &#x27;old playbook&#x27; of delegating to IT departments is failing companiesHabib, whose company has spent five years building AI systems for Fortune 500 companies and logged two million miles visiting customer sites, said the pattern is consistent: \"When generative AI started showing up, we turned to the old playbook. We turned to IT and said, &#x27;Go figure this out.&#x27;\"That approach fails, she argued, because AI fundamentally changes the economics and organization of work itself. \"For 100 years, enterprises have been built around the idea that execution is expensive and hard,\" Habib said. \"The enterprise built complex org charts, complex processes, all to manage people doing stuff.\"AI inverts that model. \"Execution is going from scarce and expensive to programmatic, on-demand and abundant,\" she said. In this new paradigm, the bottleneck shifts from execution capacity to strategic design — a shift that requires business leaders, not IT departments, to drive transformation.\"With AI technology, it can no longer be centralized. It&#x27;s in every workflow, every business,\" Habib said. \"It is now the most important part of a business leader&#x27;s job. It cannot be delegated.\"The statement represents a direct challenge to how most large organizations have structured their AI initiatives, with centralized centers of excellence, dedicated AI teams, or IT-led implementations that business units are expected to adopt.A generational power shift is happening based on who understands AI workflow designHabib framed the shift in dramatic terms: \"A generational transfer of power is happening right now. It&#x27;s not about your age or how long you&#x27;ve been at a company. The generational transfer of power is about the nature of leadership itself.\"Traditional leadership, she argued, has been defined by the ability to manage complexity — big teams, big budgets, intricate processes. \"The identity of leaders at these companies, people like us, has been tied to old school power structures: control, hierarchy, how big our teams are, how big our budgets are. Our value is measured by the sheer amount of complexity we could manage,\" Habib said. \"Today we reward leaders for this. We promote leaders for this.\"AI makes that model obsolete. \"When I am able to 10x the output of my team or do things that could never be possible, work is no longer about the 1x,\" she said. \"Leadership is no longer about managing complex human execution.\"Instead, Habib outlined three fundamental shifts that define what she calls \"AI-first leaders\" — executives her company has worked with who have successfully deployed AI agents solving \"$100 million plus problems.\"The first shift: Taking a machete to enterprise complexityThe new leadership mandate, according to Habib, is \"taking a machete to the complexity that has calcified so many organizations.\" She pointed to the layers of friction that have accumulated in enterprises: \"Brilliant ideas dying in memos, the endless cycles of approvals, the death by 1,000 clicks, meetings about meetings — a death, by the way, that&#x27;s happening in 17 different browser tabs each for software that promises to be a single source of truth.\"Rather than accepting this complexity as inevitable, AI-first leaders redesign workflows from first principles. \"There are very few legacy systems that can&#x27;t be replaced in your organization, that won&#x27;t be replaced,\" Habib said. \"But they&#x27;re not going to be replaced by another monolithic piece of software. They can only be replaced by a business leader articulating business logic and getting that into an agentic system.\"She offered a concrete example: \"We have customers where it used to take them seven months to get a creative campaign — not even a product, a campaign. Now they can go from TikTok trend to digital shelf in 30 days. That is radical simplicity.\"The catch, she emphasized, is that CIOs can&#x27;t drive this transformation alone. \"Your CIO can&#x27;t help flatten your org chart. Only a business leader can look at workflows and say, &#x27;This part is necessary genius, this part is bureaucratic scar tissue that has to go.&#x27;\"The second shift: Managing the fear as career ladders disappearWhen AI handles execution, \"your humans are liberated to do what they&#x27;re amazing at: judgment, strategy, creativity,\" Habib explained. \"The old leadership playbook was about managing headcount. We managed people against revenue: one business development rep for every three account executives, one marketer for every five salespeople.\"But this liberation carries profound challenges that leaders must address directly. Habib acknowledged the elephant in the room that many executives avoid discussing: \"These changes are still frightening for people, even when it&#x27;s become unholy to talk about it.\" She&#x27;s witnessed the fear firsthand. \"It shows up as tears in an AI workshop when someone feels like their old skill set isn&#x27;t translated to the new.\"She introduced a term for a common form of resistance: \"productivity anchoring\" — when employees \"cling to the hard way of doing things because they feel productive, because their self-worth is tied to them, even when empirically AI can be better.\"The solution isn&#x27;t to look away. \"We have to design new pathways to impact, to show your people their value is not in executing a task. Their value is in orchestrating systems of execution, to ask the next great question,\" Habib said. She advocates replacing career \"ladders\" with \"lattices\" where \"people need to grow laterally, to expand sideways.\"She was candid about the disruption: \"The first rungs on our career ladders are indeed going away. I know because my company is automating them.\" But she insisted this creates opportunity for work that is \"more creative, more strategic, more driven by curiosity and impact — and I believe a lot more human than the jobs that they&#x27;re replacing.\"The third shift: When execution becomes free, ambition becomes the only bottleneckThe final shift is from optimization to creation. \"Before AI, we used to call it transformation when we took 12 steps and made them nine,\" Habib said. \"That&#x27;s optimizing the world as it is. We can now create a new world. That is the greenfield mindset.\"She challenged executives to identify assumptions their industries are built on that AI now disrupts. Writer&#x27;s customers, she said, are already seeing new categories of growth: treating every customer like their only customer, democratizing premium services to broader markets, and entering new markets at unprecedented speed because \"AI strips away the friction to access new channels.\"\"When execution is abundant, the only bottleneck is the scope of your own ambition,\" Habib declared.What this means for CIOs: Building the stadium while business leaders design the playsHabib didn&#x27;t leave IT leaders without a role — she redefined it. \"If tech is everyone&#x27;s job, you might be asking, what is mine?\" she addressed CIOs. \"Yours is to provide the mission critical infrastructure that makes this revolution possible.\"As tens or hundreds of thousands of AI agents operate at various levels of autonomy within organizations, \"governance becomes existential,\" she explained. \"The business leader&#x27;s job is to design the play, but you have to build the stadium, you have to write the rule book, and you have to make sure these plays can win at championship scale.\"The formulation suggests a partnership model: business leaders drive workflow redesign and strategic implementation while IT provides the infrastructure, governance frameworks, and security guardrails that make mass AI deployment safe and scalable. \"One can&#x27;t succeed without the other,\" Habib said.For CIOs and technical leaders, this represents a fundamental shift from gatekeeper to enabler. When business units deploy agents autonomously, IT faces governance challenges unlike anything in enterprise software history. Success requires genuine partnership between business and IT — neither can succeed alone, forcing cultural changes in how these functions collaborate.A real example: From multi-day scrambles to instant answers during a market crisisTo ground her arguments in concrete business impact, Habib described working with the chief client officer of a Fortune 500 wealth advisory firm during recent market volatility following tariff announcements.\"Their phone was ringing off the hook with customers trying to figure out their market exposure,\" she recounted. \"Every request kicked off a multi-day, multi-person scramble: a portfolio manager ran the show, an analyst pulled charts, a relationship manager built the PowerPoint, a compliance officer had to review everything for disclosures. And the leader in all this — she was forwarding emails and chasing updates. This is the top job: managing complexity.\"With an agentic AI system, the same work happens programmatically. \"A system of agents is able to assemble the answer faster than any number of people could have. No more midnight deck reviews. No more days on end\" of coordination, Habib said.This isn&#x27;t about marginal productivity gains — it&#x27;s about fundamentally different operating models where senior executives shift from managing coordination to designing intelligent systems.Why so many AI initiatives are failing despite massive investmentHabib&#x27;s arguments arrive as many enterprises face AI disillusionment. After initial excitement about generative AI, many companies have struggled to move beyond pilots and demonstrations to production deployments generating tangible business value.Her diagnosis — that leaders are delegating rather than driving transformation — aligns with growing evidence that organizational factors, not technical limitations, explain most failures. Companies often lack clarity on use cases, struggle with data preparation, or face internal resistance to workflow changes that AI requires.Perhaps the most striking aspect of Habib&#x27;s presentation was her willingness to acknowledge the human cost of AI transformation — and insist leaders address it rather than avoid it. \"Your job as a leader is to not look away from this fear. Your job is to face it with a plan,\" she told the audience.She described \"productivity anchoring\" as a form of \"self-sabotage\" where employees resist AI adoption because their identity and self-worth are tied to execution tasks AI can now perform. The phenomenon suggests that successful AI transformation requires not just technical and strategic changes but psychological and cultural work that many leaders may be unprepared for.Two challenges: Get your hands dirty, then reimagine everythingHabib closed by throwing down two gauntlets to her executive audience.\"First, a small one: get your hands dirty with agentic AI. Don&#x27;t delegate. Choose a process that you oversee and automate it. See the difference from managing a complex process to redesigning it for yourself.\"The second was more ambitious: \"Go back to your team and ask, what could we achieve if execution were free? What would work feel like, be like, look like if you&#x27;re unbound from the friction and process that slows us down today?\"She concluded: \"The tools for creation are in your hands. The mandate for leadership is on your shoulders. What will you build?\"For enterprise leaders accustomed to viewing AI as an IT initiative, Habib&#x27;s message is clear: that approach isn&#x27;t working, won&#x27;t work, and reflects a fundamental misunderstanding of what AI represents. Whether executives embrace her call to personally drive transformation — or continue delegating to IT departments — may determine which organizations thrive and which become cautionary tales.The statistic she opened with lingers uncomfortably: 42% of Fortune 500 C-suite executives say AI is tearing their companies apart. Habib&#x27;s diagnosis suggests they&#x27;re tearing themselves apart by clinging to organizational models designed for an era when execution was scarce. The cure she prescribes requires leaders to do something most find uncomfortable: stop managing complexity and start dismantling it.",
          "content": "May Habib, co-founder and CEO of Writer AI, delivered one of the bluntest assessments of corporate AI failures at the TED AI conference on Tuesday, revealing that nearly half of Fortune 500 executives believe artificial intelligence is actively damaging their organizations — and placing the blame squarely on leadership&#x27;s shoulders.The problem, according to Habib, isn&#x27;t the technology. It&#x27;s that business leaders are making a category error, treating AI transformation like previous technology rollouts and delegating it to IT departments. This approach, she warned, has led to \"billions of dollars spent on AI initiatives that are going nowhere.\"\"Earlier this year, we did a survey of 800 Fortune 500 C-suite executives,\" Habib told the audience of Silicon Valley executives and investors. \"42% of them said AI is tearing their company apart.\"The diagnosis challenges conventional wisdom about how enterprises should approach AI adoption. While most major companies have stood up AI task forces, appointed chief AI officers, or expanded IT budgets, Habib argues these moves reflect a fundamental misunderstanding of what AI represents: not another software tool, but a wholesale reorganization of how work gets done.\"There is something leaders are missing when they compare AI to just another tech tool,\" Habib said. \"This is not like giving accountants calculators or bankers Excel or designers Photoshop.\"Why the &#x27;old playbook&#x27; of delegating to IT departments is failing companiesHabib, whose company has spent five years building AI systems for Fortune 500 companies and logged two million miles visiting customer sites, said the pattern is consistent: \"When generative AI started showing up, we turned to the old playbook. We turned to IT and said, &#x27;Go figure this out.&#x27;\"That approach fails, she argued, because AI fundamentally changes the economics and organization of work itself. \"For 100 years, enterprises have been built around the idea that execution is expensive and hard,\" Habib said. \"The enterprise built complex org charts, complex processes, all to manage people doing stuff.\"AI inverts that model. \"Execution is going from scarce and expensive to programmatic, on-demand and abundant,\" she said. In this new paradigm, the bottleneck shifts from execution capacity to strategic design — a shift that requires business leaders, not IT departments, to drive transformation.\"With AI technology, it can no longer be centralized. It&#x27;s in every workflow, every business,\" Habib said. \"It is now the most important part of a business leader&#x27;s job. It cannot be delegated.\"The statement represents a direct challenge to how most large organizations have structured their AI initiatives, with centralized centers of excellence, dedicated AI teams, or IT-led implementations that business units are expected to adopt.A generational power shift is happening based on who understands AI workflow designHabib framed the shift in dramatic terms: \"A generational transfer of power is happening right now. It&#x27;s not about your age or how long you&#x27;ve been at a company. The generational transfer of power is about the nature of leadership itself.\"Traditional leadership, she argued, has been defined by the ability to manage complexity — big teams, big budgets, intricate processes. \"The identity of leaders at these companies, people like us, has been tied to old school power structures: control, hierarchy, how big our teams are, how big our budgets are. Our value is measured by the sheer amount of complexity we could manage,\" Habib said. \"Today we reward leaders for this. We promote leaders for this.\"AI makes that model obsolete. \"When I am able to 10x the output of my team or do things that could never be possible, work is no longer about the 1x,\" she said. \"Leadership is no longer about managing complex human execution.\"Instead, Habib outlined three fundamental shifts that define what she calls \"AI-first leaders\" — executives her company has worked with who have successfully deployed AI agents solving \"$100 million plus problems.\"The first shift: Taking a machete to enterprise complexityThe new leadership mandate, according to Habib, is \"taking a machete to the complexity that has calcified so many organizations.\" She pointed to the layers of friction that have accumulated in enterprises: \"Brilliant ideas dying in memos, the endless cycles of approvals, the death by 1,000 clicks, meetings about meetings — a death, by the way, that&#x27;s happening in 17 different browser tabs each for software that promises to be a single source of truth.\"Rather than accepting this complexity as inevitable, AI-first leaders redesign workflows from first principles. \"There are very few legacy systems that can&#x27;t be replaced in your organization, that won&#x27;t be replaced,\" Habib said. \"But they&#x27;re not going to be replaced by another monolithic piece of software. They can only be replaced by a business leader articulating business logic and getting that into an agentic system.\"She offered a concrete example: \"We have customers where it used to take them seven months to get a creative campaign — not even a product, a campaign. Now they can go from TikTok trend to digital shelf in 30 days. That is radical simplicity.\"The catch, she emphasized, is that CIOs can&#x27;t drive this transformation alone. \"Your CIO can&#x27;t help flatten your org chart. Only a business leader can look at workflows and say, &#x27;This part is necessary genius, this part is bureaucratic scar tissue that has to go.&#x27;\"The second shift: Managing the fear as career ladders disappearWhen AI handles execution, \"your humans are liberated to do what they&#x27;re amazing at: judgment, strategy, creativity,\" Habib explained. \"The old leadership playbook was about managing headcount. We managed people against revenue: one business development rep for every three account executives, one marketer for every five salespeople.\"But this liberation carries profound challenges that leaders must address directly. Habib acknowledged the elephant in the room that many executives avoid discussing: \"These changes are still frightening for people, even when it&#x27;s become unholy to talk about it.\" She&#x27;s witnessed the fear firsthand. \"It shows up as tears in an AI workshop when someone feels like their old skill set isn&#x27;t translated to the new.\"She introduced a term for a common form of resistance: \"productivity anchoring\" — when employees \"cling to the hard way of doing things because they feel productive, because their self-worth is tied to them, even when empirically AI can be better.\"The solution isn&#x27;t to look away. \"We have to design new pathways to impact, to show your people their value is not in executing a task. Their value is in orchestrating systems of execution, to ask the next great question,\" Habib said. She advocates replacing career \"ladders\" with \"lattices\" where \"people need to grow laterally, to expand sideways.\"She was candid about the disruption: \"The first rungs on our career ladders are indeed going away. I know because my company is automating them.\" But she insisted this creates opportunity for work that is \"more creative, more strategic, more driven by curiosity and impact — and I believe a lot more human than the jobs that they&#x27;re replacing.\"The third shift: When execution becomes free, ambition becomes the only bottleneckThe final shift is from optimization to creation. \"Before AI, we used to call it transformation when we took 12 steps and made them nine,\" Habib said. \"That&#x27;s optimizing the world as it is. We can now create a new world. That is the greenfield mindset.\"She challenged executives to identify assumptions their industries are built on that AI now disrupts. Writer&#x27;s customers, she said, are already seeing new categories of growth: treating every customer like their only customer, democratizing premium services to broader markets, and entering new markets at unprecedented speed because \"AI strips away the friction to access new channels.\"\"When execution is abundant, the only bottleneck is the scope of your own ambition,\" Habib declared.What this means for CIOs: Building the stadium while business leaders design the playsHabib didn&#x27;t leave IT leaders without a role — she redefined it. \"If tech is everyone&#x27;s job, you might be asking, what is mine?\" she addressed CIOs. \"Yours is to provide the mission critical infrastructure that makes this revolution possible.\"As tens or hundreds of thousands of AI agents operate at various levels of autonomy within organizations, \"governance becomes existential,\" she explained. \"The business leader&#x27;s job is to design the play, but you have to build the stadium, you have to write the rule book, and you have to make sure these plays can win at championship scale.\"The formulation suggests a partnership model: business leaders drive workflow redesign and strategic implementation while IT provides the infrastructure, governance frameworks, and security guardrails that make mass AI deployment safe and scalable. \"One can&#x27;t succeed without the other,\" Habib said.For CIOs and technical leaders, this represents a fundamental shift from gatekeeper to enabler. When business units deploy agents autonomously, IT faces governance challenges unlike anything in enterprise software history. Success requires genuine partnership between business and IT — neither can succeed alone, forcing cultural changes in how these functions collaborate.A real example: From multi-day scrambles to instant answers during a market crisisTo ground her arguments in concrete business impact, Habib described working with the chief client officer of a Fortune 500 wealth advisory firm during recent market volatility following tariff announcements.\"Their phone was ringing off the hook with customers trying to figure out their market exposure,\" she recounted. \"Every request kicked off a multi-day, multi-person scramble: a portfolio manager ran the show, an analyst pulled charts, a relationship manager built the PowerPoint, a compliance officer had to review everything for disclosures. And the leader in all this — she was forwarding emails and chasing updates. This is the top job: managing complexity.\"With an agentic AI system, the same work happens programmatically. \"A system of agents is able to assemble the answer faster than any number of people could have. No more midnight deck reviews. No more days on end\" of coordination, Habib said.This isn&#x27;t about marginal productivity gains — it&#x27;s about fundamentally different operating models where senior executives shift from managing coordination to designing intelligent systems.Why so many AI initiatives are failing despite massive investmentHabib&#x27;s arguments arrive as many enterprises face AI disillusionment. After initial excitement about generative AI, many companies have struggled to move beyond pilots and demonstrations to production deployments generating tangible business value.Her diagnosis — that leaders are delegating rather than driving transformation — aligns with growing evidence that organizational factors, not technical limitations, explain most failures. Companies often lack clarity on use cases, struggle with data preparation, or face internal resistance to workflow changes that AI requires.Perhaps the most striking aspect of Habib&#x27;s presentation was her willingness to acknowledge the human cost of AI transformation — and insist leaders address it rather than avoid it. \"Your job as a leader is to not look away from this fear. Your job is to face it with a plan,\" she told the audience.She described \"productivity anchoring\" as a form of \"self-sabotage\" where employees resist AI adoption because their identity and self-worth are tied to execution tasks AI can now perform. The phenomenon suggests that successful AI transformation requires not just technical and strategic changes but psychological and cultural work that many leaders may be unprepared for.Two challenges: Get your hands dirty, then reimagine everythingHabib closed by throwing down two gauntlets to her executive audience.\"First, a small one: get your hands dirty with agentic AI. Don&#x27;t delegate. Choose a process that you oversee and automate it. See the difference from managing a complex process to redesigning it for yourself.\"The second was more ambitious: \"Go back to your team and ask, what could we achieve if execution were free? What would work feel like, be like, look like if you&#x27;re unbound from the friction and process that slows us down today?\"She concluded: \"The tools for creation are in your hands. The mandate for leadership is on your shoulders. What will you build?\"For enterprise leaders accustomed to viewing AI as an IT initiative, Habib&#x27;s message is clear: that approach isn&#x27;t working, won&#x27;t work, and reflects a fundamental misunderstanding of what AI represents. Whether executives embrace her call to personally drive transformation — or continue delegating to IT departments — may determine which organizations thrive and which become cautionary tales.The statistic she opened with lingers uncomfortably: 42% of Fortune 500 C-suite executives say AI is tearing their companies apart. Habib&#x27;s diagnosis suggests they&#x27;re tearing themselves apart by clinging to organizational models designed for an era when execution was scarce. The cure she prescribes requires leaders to do something most find uncomfortable: stop managing complexity and start dismantling it.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4aHBNxyB2pkPhCFjBLoMOH/b09ae06e86fe5534666c4574c5de2bdb/nuneybits_Vector_art_of_company_fracturing_apart_433a69a5-4c41-4199-bf6a-51d8cd076379.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/sakana-ais-cto-says-hes-absolutely-sick-of-transformers-the-tech-that-powers",
          "published_at": "Thu, 23 Oct 2025 13:00:00 GMT",
          "title": "Sakana AI's CTO says he's 'absolutely sick' of transformers, the tech that powers every major AI model",
          "standfirst": "In a striking act of self-critique, one of the architects of the transformer technology that powers ChatGPT, Claude, and virtually every major AI system told an audience of industry leaders this week that artificial intelligence research has become dangerously narrow — and that he&#x27;s moving on from his own creation.Llion Jones, who co-authored the seminal 2017 paper \"Attention Is All You Need\" and even coined the name \"transformer,\" delivered an unusually candid assessment at the TED AI conference in San Francisco on Tuesday: Despite unprecedented investment and talent flooding into AI, the field has calcified around a single architectural approach, potentially blinding researchers to the next major breakthrough.\"Despite the fact that there&#x27;s never been so much interest and resources and money and talent, this has somehow caused the narrowing of the research that we&#x27;re doing,\" Jones told the audience. The culprit, he argued, is the \"immense amount of pressure\" from investors demanding returns and researchers scrambling to stand out in an overcrowded field.The warning carries particular weight given Jones&#x27;s role in AI history. The transformer architecture he helped develop at Google has become the foundation of the generative AI boom, enabling systems that can write essays, generate images, and engage in human-like conversation. His paper has been cited more than 100,000 times, making it one of the most influential computer science publications of the century.Now, as CTO and co-founder of Tokyo-based Sakana AI, Jones is explicitly abandoning his own creation. \"I personally made a decision in the beginning of this year that I&#x27;m going to drastically reduce the amount of time that I spend on transformers,\" he said. \"I&#x27;m explicitly now exploring and looking for the next big thing.\"Why more AI funding has led to less creative research, according to a transformer pioneerJones painted a picture of an AI research community suffering from what he called a paradox: More resources have led to less creativity. He described researchers constantly checking whether they&#x27;ve been \"scooped\" by competitors working on identical ideas, and academics choosing safe, publishable projects over risky, potentially transformative ones.\"If you&#x27;re doing standard AI research right now, you kind of have to assume that there&#x27;s maybe three or four other groups doing something very similar, or maybe exactly the same,\" Jones said, describing an environment where \"unfortunately, this pressure damages the science, because people are rushing their papers, and it&#x27;s reducing the amount of creativity.\"He drew an analogy from AI itself — the \"exploration versus exploitation\" trade-off that governs how algorithms search for solutions. When a system exploits too much and explores too little, it finds mediocre local solutions while missing superior alternatives. \"We are almost certainly in that situation right now in the AI industry,\" Jones argued.The implications are sobering. Jones recalled the period just before transformers emerged, when researchers were endlessly tweaking recurrent neural networks — the previous dominant architecture — for incremental gains. Once transformers arrived, all that work suddenly seemed irrelevant. \"How much time do you think those researchers would have spent trying to improve the recurrent neural network if they knew something like transformers was around the corner?\" he asked.He worries the field is repeating that pattern. \"I&#x27;m worried that we&#x27;re in that situation right now where we&#x27;re just concentrating on one architecture and just permuting it and trying different things, where there might be a breakthrough just around the corner.\"How the &#x27;Attention is all you need&#x27; paper was born from freedom, not pressureTo underscore his point, Jones described the conditions that allowed transformers to emerge in the first place — a stark contrast to today&#x27;s environment. The project, he said, was \"very organic, bottom up,\" born from \"talking over lunch or scrawling randomly on the whiteboard in the office.\"Critically, \"we didn&#x27;t actually have a good idea, we had the freedom to actually spend time and go and work on it, and even more importantly, we didn&#x27;t have any pressure that was coming down from management,\" Jones recounted. \"No pressure to work on any particular project, publish a number of papers to push a certain metric up.\"That freedom, Jones suggested, is largely absent today. Even researchers recruited for astronomical salaries — \"literally a million dollars a year, in some cases\" — may not feel empowered to take risks. \"Do you think that when they start their new position they feel empowered to try their wild ideas and more speculative ideas, or do they feel immense pressure to prove their worth and once again, go for the low hanging fruit?\" he asked.Why one AI lab is betting that research freedom beats million-dollar salariesJones&#x27;s proposed solution is deliberately provocative: Turn up the \"explore dial\" and openly share findings, even at competitive cost. He acknowledged the irony of his position. \"It may sound a little controversial to hear one of the Transformers authors stand on stage and tell you that he&#x27;s absolutely sick of them, but it&#x27;s kind of fair enough, right? I&#x27;ve been working on them longer than anyone, with the possible exception of seven people.\"At Sakana AI, Jones said he&#x27;s attempting to recreate that pre-transformer environment, with nature-inspired research and minimal pressure to chase publications or compete directly with rivals. He offered researchers a mantra from engineer Brian Cheung: \"You should only do the research that wouldn&#x27;t happen if you weren&#x27;t doing it.\"One example is Sakana&#x27;s \"continuous thought machine,\" which incorporates brain-like synchronization into neural networks. An employee who pitched the idea told Jones he would have faced skepticism and pressure not to waste time at previous employers or academic positions. At Sakana, Jones gave him a week to explore. The project became successful enough to be spotlighted at NeurIPS, a major AI conference.Jones even suggested that freedom beats compensation in recruiting. \"It&#x27;s a really, really good way of getting talent,\" he said of the exploratory environment. \"Think about it, talented, intelligent people, ambitious people, will naturally seek out this kind of environment.\"The transformer&#x27;s success may be blocking AI&#x27;s next breakthroughPerhaps most provocatively, Jones suggested transformers may be victims of their own success. \"The fact that the current technology is so powerful and flexible... stopped us from looking for better,\" he said. \"It makes sense that if the current technology was worse, more people would be looking for better.\"He was careful to clarify that he&#x27;s not dismissing ongoing transformer research. \"There&#x27;s still plenty of very important work to be done on current technology and bringing a lot of value in the coming years,\" he said. \"I&#x27;m just saying that given the amount of talent and resources that we have currently, we can afford to do a lot more.\"His ultimate message was one of collaboration over competition. \"Genuinely, from my perspective, this is not a competition,\" Jones concluded. \"We all have the same goal. We all want to see this technology progress so that we can all benefit from it. So if we can all collectively turn up the explore dial and then openly share what we find, we can get to our goal much faster.\"The high stakes of AI&#x27;s exploration problemThe remarks arrive at a pivotal moment for artificial intelligence. The industry grapples with mounting evidence that simply building larger transformer models may be approaching diminishing returns. Leading researchers have begun openly discussing whether the current paradigm has fundamental limitations, with some suggesting that architectural innovations — not just scale — will be needed for continued progress toward more capable AI systems.Jones&#x27;s warning suggests that finding those innovations may require dismantling the very incentive structures that have driven AI&#x27;s recent boom. With tens of billions of dollars flowing into AI development annually and fierce competition among labs driving secrecy and rapid publication cycles, the exploratory research environment he described seems increasingly distant.Yet his insider perspective carries unusual weight. As someone who helped create the technology now dominating the field, Jones understands both what it takes to achieve breakthrough innovation and what the industry risks by abandoning that approach. His decision to walk away from transformers — the architecture that made his reputation — adds credibility to a message that might otherwise sound like contrarian positioning.Whether AI&#x27;s power players will heed the call remains uncertain. But Jones offered a pointed reminder of what&#x27;s at stake: The next transformer-scale breakthrough could be just around the corner, pursued by researchers with the freedom to explore. Or it could be languishing unexplored while thousands of researchers race to publish incremental improvements on architecture that, in Jones&#x27;s words, one of its creators is \"absolutely sick of.\"After all, he&#x27;s been working on transformers longer than almost anyone. He would know when it&#x27;s time to move on.",
          "content": "In a striking act of self-critique, one of the architects of the transformer technology that powers ChatGPT, Claude, and virtually every major AI system told an audience of industry leaders this week that artificial intelligence research has become dangerously narrow — and that he&#x27;s moving on from his own creation.Llion Jones, who co-authored the seminal 2017 paper \"Attention Is All You Need\" and even coined the name \"transformer,\" delivered an unusually candid assessment at the TED AI conference in San Francisco on Tuesday: Despite unprecedented investment and talent flooding into AI, the field has calcified around a single architectural approach, potentially blinding researchers to the next major breakthrough.\"Despite the fact that there&#x27;s never been so much interest and resources and money and talent, this has somehow caused the narrowing of the research that we&#x27;re doing,\" Jones told the audience. The culprit, he argued, is the \"immense amount of pressure\" from investors demanding returns and researchers scrambling to stand out in an overcrowded field.The warning carries particular weight given Jones&#x27;s role in AI history. The transformer architecture he helped develop at Google has become the foundation of the generative AI boom, enabling systems that can write essays, generate images, and engage in human-like conversation. His paper has been cited more than 100,000 times, making it one of the most influential computer science publications of the century.Now, as CTO and co-founder of Tokyo-based Sakana AI, Jones is explicitly abandoning his own creation. \"I personally made a decision in the beginning of this year that I&#x27;m going to drastically reduce the amount of time that I spend on transformers,\" he said. \"I&#x27;m explicitly now exploring and looking for the next big thing.\"Why more AI funding has led to less creative research, according to a transformer pioneerJones painted a picture of an AI research community suffering from what he called a paradox: More resources have led to less creativity. He described researchers constantly checking whether they&#x27;ve been \"scooped\" by competitors working on identical ideas, and academics choosing safe, publishable projects over risky, potentially transformative ones.\"If you&#x27;re doing standard AI research right now, you kind of have to assume that there&#x27;s maybe three or four other groups doing something very similar, or maybe exactly the same,\" Jones said, describing an environment where \"unfortunately, this pressure damages the science, because people are rushing their papers, and it&#x27;s reducing the amount of creativity.\"He drew an analogy from AI itself — the \"exploration versus exploitation\" trade-off that governs how algorithms search for solutions. When a system exploits too much and explores too little, it finds mediocre local solutions while missing superior alternatives. \"We are almost certainly in that situation right now in the AI industry,\" Jones argued.The implications are sobering. Jones recalled the period just before transformers emerged, when researchers were endlessly tweaking recurrent neural networks — the previous dominant architecture — for incremental gains. Once transformers arrived, all that work suddenly seemed irrelevant. \"How much time do you think those researchers would have spent trying to improve the recurrent neural network if they knew something like transformers was around the corner?\" he asked.He worries the field is repeating that pattern. \"I&#x27;m worried that we&#x27;re in that situation right now where we&#x27;re just concentrating on one architecture and just permuting it and trying different things, where there might be a breakthrough just around the corner.\"How the &#x27;Attention is all you need&#x27; paper was born from freedom, not pressureTo underscore his point, Jones described the conditions that allowed transformers to emerge in the first place — a stark contrast to today&#x27;s environment. The project, he said, was \"very organic, bottom up,\" born from \"talking over lunch or scrawling randomly on the whiteboard in the office.\"Critically, \"we didn&#x27;t actually have a good idea, we had the freedom to actually spend time and go and work on it, and even more importantly, we didn&#x27;t have any pressure that was coming down from management,\" Jones recounted. \"No pressure to work on any particular project, publish a number of papers to push a certain metric up.\"That freedom, Jones suggested, is largely absent today. Even researchers recruited for astronomical salaries — \"literally a million dollars a year, in some cases\" — may not feel empowered to take risks. \"Do you think that when they start their new position they feel empowered to try their wild ideas and more speculative ideas, or do they feel immense pressure to prove their worth and once again, go for the low hanging fruit?\" he asked.Why one AI lab is betting that research freedom beats million-dollar salariesJones&#x27;s proposed solution is deliberately provocative: Turn up the \"explore dial\" and openly share findings, even at competitive cost. He acknowledged the irony of his position. \"It may sound a little controversial to hear one of the Transformers authors stand on stage and tell you that he&#x27;s absolutely sick of them, but it&#x27;s kind of fair enough, right? I&#x27;ve been working on them longer than anyone, with the possible exception of seven people.\"At Sakana AI, Jones said he&#x27;s attempting to recreate that pre-transformer environment, with nature-inspired research and minimal pressure to chase publications or compete directly with rivals. He offered researchers a mantra from engineer Brian Cheung: \"You should only do the research that wouldn&#x27;t happen if you weren&#x27;t doing it.\"One example is Sakana&#x27;s \"continuous thought machine,\" which incorporates brain-like synchronization into neural networks. An employee who pitched the idea told Jones he would have faced skepticism and pressure not to waste time at previous employers or academic positions. At Sakana, Jones gave him a week to explore. The project became successful enough to be spotlighted at NeurIPS, a major AI conference.Jones even suggested that freedom beats compensation in recruiting. \"It&#x27;s a really, really good way of getting talent,\" he said of the exploratory environment. \"Think about it, talented, intelligent people, ambitious people, will naturally seek out this kind of environment.\"The transformer&#x27;s success may be blocking AI&#x27;s next breakthroughPerhaps most provocatively, Jones suggested transformers may be victims of their own success. \"The fact that the current technology is so powerful and flexible... stopped us from looking for better,\" he said. \"It makes sense that if the current technology was worse, more people would be looking for better.\"He was careful to clarify that he&#x27;s not dismissing ongoing transformer research. \"There&#x27;s still plenty of very important work to be done on current technology and bringing a lot of value in the coming years,\" he said. \"I&#x27;m just saying that given the amount of talent and resources that we have currently, we can afford to do a lot more.\"His ultimate message was one of collaboration over competition. \"Genuinely, from my perspective, this is not a competition,\" Jones concluded. \"We all have the same goal. We all want to see this technology progress so that we can all benefit from it. So if we can all collectively turn up the explore dial and then openly share what we find, we can get to our goal much faster.\"The high stakes of AI&#x27;s exploration problemThe remarks arrive at a pivotal moment for artificial intelligence. The industry grapples with mounting evidence that simply building larger transformer models may be approaching diminishing returns. Leading researchers have begun openly discussing whether the current paradigm has fundamental limitations, with some suggesting that architectural innovations — not just scale — will be needed for continued progress toward more capable AI systems.Jones&#x27;s warning suggests that finding those innovations may require dismantling the very incentive structures that have driven AI&#x27;s recent boom. With tens of billions of dollars flowing into AI development annually and fierce competition among labs driving secrecy and rapid publication cycles, the exploratory research environment he described seems increasingly distant.Yet his insider perspective carries unusual weight. As someone who helped create the technology now dominating the field, Jones understands both what it takes to achieve breakthrough innovation and what the industry risks by abandoning that approach. His decision to walk away from transformers — the architecture that made his reputation — adds credibility to a message that might otherwise sound like contrarian positioning.Whether AI&#x27;s power players will heed the call remains uncertain. But Jones offered a pointed reminder of what&#x27;s at stake: The next transformer-scale breakthrough could be just around the corner, pursued by researchers with the freedom to explore. Or it could be languishing unexplored while thousands of researchers race to publish incremental improvements on architecture that, in Jones&#x27;s words, one of its creators is \"absolutely sick of.\"After all, he&#x27;s been working on transformers longer than almost anyone. He would know when it&#x27;s time to move on.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/WSXBhFReMwh2HPn3P3k9E/f6352f008c9afddcbf6a4ff6148d7c96/nuneybits_Vector_art_of_a_koi_fish_with_scales_formed_from_algo_8e356867-71b0-4e3b-b5b1-87ac3e4c8013.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data-infrastructure/research-finds-that-77-of-data-engineers-have-heavier-workloads-despite-ai",
          "published_at": "Thu, 23 Oct 2025 13:00:00 GMT",
          "title": "Research finds that 77% of data engineers have heavier workloads despite AI tools: Here's why and what to do about it",
          "standfirst": "Data engineers should be working faster than ever. AI-powered tools promise to automate pipeline optimization, accelerate data integration and handle the repetitive grunt work that has defined the profession for decades.Yet, according to a new survey of 400 senior technology executives by MIT Technology Review Insights in partnership with Snowflake, 77% say their data engineering teams&#x27; workloads are getting heavier, not lighter.The culprit? The very AI tools meant to help are creating a new set of problems.While 83% of organizations have already deployed AI-based data engineering tools, 45% cite integration complexity as a top challenge. Another 38% are struggling with tool sprawl and fragmentation.\"Many data engineers are using one tool to collect data, one tool to process data and another to run analytics on that data,\" Chris Child, VP of product for data engineering at Snowflake, told VentureBeat. \"Using several tools along this data lifecycle introduces complexity, risk and increased infrastructure management, which data engineers can&#x27;t afford to take on.\"The result is a productivity paradox. AI tools are making individual tasks faster, but the proliferation of disconnected tools is making the overall system more complex to manage. For enterprises racing to deploy AI at scale, this fragmentation represents a critical bottleneck.From SQL queries to LLM pipelines: The daily workflow shiftThe survey found that data engineers spent an average of 19% of their time on AI projects two years ago. Today, that figure has jumped to 37%. Respondents expect it to hit 61% within two years.But what does that shift actually look like in practice?Child offered a concrete example. Previously, if the CFO of a company needed to make forecast predictions, they would tap the data engineering team to help build a system that correlates unstructured data like vendor contracts with structured data like revenue numbers into a static dashboard. Connecting these two worlds of different data types was extremely time-consuming and expensive, requiring lawyers to manually read through each document for key contract terms and upload that information into a database.Today, that same workflow looks radically different.\"Data engineers can use a tool like Snowflake Openflow to seamlessly bring the unstructured PDF contracts living in a source like Box, together with the structured financial figures into a single platform like Snowflake, making the data accessible to LLMs,\" Child said. \"What used to take hours of manual work is now near instantaneous.\"The shift isn&#x27;t just about speed. It&#x27;s about the nature of the work itself.Two years ago, a typical data engineer&#x27;s day consisted of tuning clusters, writing SQL transformations and ensuring data readiness for human analysts. Today, that same engineer is more likely to be debugging LLM-powered transformation pipelines and setting up governance rules for AI model workflows.\"Data engineers&#x27; core skill isn&#x27;t just coding,\" Child said. \"It&#x27;s orchestrating the data foundation and ensuring trust, context and governance so AI outputs are reliable.\"The tool stack problem: When help becomes hindranceHere&#x27;s where enterprises are getting stuck.The promise of AI-powered data tools is compelling: automate pipeline optimization, accelerate debugging, streamline integration. But in practice, many organizations are discovering that each new AI tool they add creates its own integration headaches.The survey data bears this out. While AI has led to improvements in output quantity (74% report increases) and quality (77% report improvements), those gains are being offset by the operational overhead of managing disconnected tools.\"The other problem we&#x27;re seeing is that AI tools often make it easy to build a prototype by stitching together several data sources with an out-of-the-box LLM,\" Child said. \"But then when you want to take that into production, you realize that you don&#x27;t have the data accessible and you don&#x27;t know what governance you need, so it becomes difficult to roll the tool out to your users.\"For technical decision-makers evaluating their data engineering stack right now, Child offered a clear framework. \"Teams should prioritize AI tools that accelerate productivity, while at the same time eliminate infrastructure and operational complexity,\" he said. \"This allows engineers to move their focus away from managing the &#x27;glue work&#x27; of data engineering and closer to business outcomes.\"The agentic AI deployment window: 12 months to get it rightThe survey revealed that 54% of organizations plan to deploy agentic AI within the next 12 months. Agentic AI refers to autonomous agents that can make decisions and take actions without human intervention. Another 20% have already begun doing so.For data engineering teams, agentic AI represents both an enormous opportunity and a significant risk. Done right, autonomous agents can handle repetitive tasks like detecting schema drift or debugging transformation errors. Done wrong, they can corrupt datasets or expose sensitive information.\"Data engineers must prioritize pipeline optimization and monitoring in order to truly deploy agentic AI at scale,\" Child said. \"It&#x27;s a low-risk, high-return starting point that allows agentic AI to safely automate repetitive tasks like detecting schema drift or debugging transformation errors when done correctly.\"But Child was emphatic about the guardrails that must be in place first.\"Before organizations let agents near production data, two safeguards must be in place: strong governance and lineage tracking, and active human oversight,\" he said. \"Agents must inherit fine-grained permissions and operate within an established governance framework.\"The risks of skipping those steps are real. \"Without proper lineage or access governance, an agent could unintentionally corrupt datasets or expose sensitive information,\" Child warned.The perception gap that&#x27;s costing enterprises AI successPerhaps the most striking finding in the survey is a disconnect at the C-suite level.While 80% of chief data officers and 82% of chief AI officers consider data engineers integral to business success, only 55% of CIOs share that view.\"This shows that the data-forward leaders are seeing data engineering&#x27;s strategic value, but we need to do more work to help the rest of the C-suite recognize that investing in a unified, scalable data foundation and the people helping drive this is an investment in AI success, not just IT operations,\" Child said.That perception gap has real consequences.Data engineers in the surveyed organizations are already influential in decisions about AI use-case feasibility (53% of respondents) and business units&#x27; use of AI models (56%). But if CIOs don&#x27;t recognize data engineers as strategic partners, they&#x27;re unlikely to give those teams the resources, authority or seat at the table they need to prevent the kinds of tool sprawl and integration problems the survey identified.The gap appears to correlate with visibility. Chief data officers and chief AI officers work directly with data engineering teams daily and understand the complexity of what they&#x27;re managing. CIOs, focused more broadly on infrastructure and operations, may not see the strategic architecture work that data engineers are increasingly doing.This disconnect also shows up in how different executives rate the challenges facing data engineering teams. Chief AI officers are significantly more likely than CIOs to agree that data engineers&#x27; workloads are becoming increasingly heavy (93% vs. 75%). They&#x27;re also more likely to recognize data engineers&#x27; influence on overall AI strategy.What data engineers need to learn nowThe survey identified three critical skills data engineers need to develop: AI expertise, business acumen and communication abilities.For an enterprise with a 20-person data engineering team, that presents a practical challenge. Do you hire for these skills, train existing engineers or restructure the team? Child&#x27;s answer suggested the priority should be business understanding.\"The most important skill right now is for data engineers to understand what is critical to their end business users and prioritize how they can make those questions easier and faster to answer,\" he said.The lesson for enterprises: Business context matters more than adding technical certifications. Child stressed that understanding the business impact of &#x27;why&#x27; data engineers are performing certain tasks will allow them to anticipate the needs of customers better, delivering value more immediately to the business. \"The organizations with data engineering teams that prioritize this business understanding will set themselves apart from competition.\"For enterprises looking to lead in AI, the solution to the data engineering productivity crisis isn&#x27;t more AI tools. The organizations that will move fastest are consolidating their tool stacks now, deploying governance infrastructure before agents go into production and elevating data engineers from support staff to strategic architects. The window is narrow. With 54% planning agentic AI deployment within 12 months and data engineers expected to spend 61% of their time on AI projects within two years, teams that haven&#x27;t addressed tool sprawl and governance gaps will find their AI initiatives stuck in permanent pilot mode.",
          "content": "Data engineers should be working faster than ever. AI-powered tools promise to automate pipeline optimization, accelerate data integration and handle the repetitive grunt work that has defined the profession for decades.Yet, according to a new survey of 400 senior technology executives by MIT Technology Review Insights in partnership with Snowflake, 77% say their data engineering teams&#x27; workloads are getting heavier, not lighter.The culprit? The very AI tools meant to help are creating a new set of problems.While 83% of organizations have already deployed AI-based data engineering tools, 45% cite integration complexity as a top challenge. Another 38% are struggling with tool sprawl and fragmentation.\"Many data engineers are using one tool to collect data, one tool to process data and another to run analytics on that data,\" Chris Child, VP of product for data engineering at Snowflake, told VentureBeat. \"Using several tools along this data lifecycle introduces complexity, risk and increased infrastructure management, which data engineers can&#x27;t afford to take on.\"The result is a productivity paradox. AI tools are making individual tasks faster, but the proliferation of disconnected tools is making the overall system more complex to manage. For enterprises racing to deploy AI at scale, this fragmentation represents a critical bottleneck.From SQL queries to LLM pipelines: The daily workflow shiftThe survey found that data engineers spent an average of 19% of their time on AI projects two years ago. Today, that figure has jumped to 37%. Respondents expect it to hit 61% within two years.But what does that shift actually look like in practice?Child offered a concrete example. Previously, if the CFO of a company needed to make forecast predictions, they would tap the data engineering team to help build a system that correlates unstructured data like vendor contracts with structured data like revenue numbers into a static dashboard. Connecting these two worlds of different data types was extremely time-consuming and expensive, requiring lawyers to manually read through each document for key contract terms and upload that information into a database.Today, that same workflow looks radically different.\"Data engineers can use a tool like Snowflake Openflow to seamlessly bring the unstructured PDF contracts living in a source like Box, together with the structured financial figures into a single platform like Snowflake, making the data accessible to LLMs,\" Child said. \"What used to take hours of manual work is now near instantaneous.\"The shift isn&#x27;t just about speed. It&#x27;s about the nature of the work itself.Two years ago, a typical data engineer&#x27;s day consisted of tuning clusters, writing SQL transformations and ensuring data readiness for human analysts. Today, that same engineer is more likely to be debugging LLM-powered transformation pipelines and setting up governance rules for AI model workflows.\"Data engineers&#x27; core skill isn&#x27;t just coding,\" Child said. \"It&#x27;s orchestrating the data foundation and ensuring trust, context and governance so AI outputs are reliable.\"The tool stack problem: When help becomes hindranceHere&#x27;s where enterprises are getting stuck.The promise of AI-powered data tools is compelling: automate pipeline optimization, accelerate debugging, streamline integration. But in practice, many organizations are discovering that each new AI tool they add creates its own integration headaches.The survey data bears this out. While AI has led to improvements in output quantity (74% report increases) and quality (77% report improvements), those gains are being offset by the operational overhead of managing disconnected tools.\"The other problem we&#x27;re seeing is that AI tools often make it easy to build a prototype by stitching together several data sources with an out-of-the-box LLM,\" Child said. \"But then when you want to take that into production, you realize that you don&#x27;t have the data accessible and you don&#x27;t know what governance you need, so it becomes difficult to roll the tool out to your users.\"For technical decision-makers evaluating their data engineering stack right now, Child offered a clear framework. \"Teams should prioritize AI tools that accelerate productivity, while at the same time eliminate infrastructure and operational complexity,\" he said. \"This allows engineers to move their focus away from managing the &#x27;glue work&#x27; of data engineering and closer to business outcomes.\"The agentic AI deployment window: 12 months to get it rightThe survey revealed that 54% of organizations plan to deploy agentic AI within the next 12 months. Agentic AI refers to autonomous agents that can make decisions and take actions without human intervention. Another 20% have already begun doing so.For data engineering teams, agentic AI represents both an enormous opportunity and a significant risk. Done right, autonomous agents can handle repetitive tasks like detecting schema drift or debugging transformation errors. Done wrong, they can corrupt datasets or expose sensitive information.\"Data engineers must prioritize pipeline optimization and monitoring in order to truly deploy agentic AI at scale,\" Child said. \"It&#x27;s a low-risk, high-return starting point that allows agentic AI to safely automate repetitive tasks like detecting schema drift or debugging transformation errors when done correctly.\"But Child was emphatic about the guardrails that must be in place first.\"Before organizations let agents near production data, two safeguards must be in place: strong governance and lineage tracking, and active human oversight,\" he said. \"Agents must inherit fine-grained permissions and operate within an established governance framework.\"The risks of skipping those steps are real. \"Without proper lineage or access governance, an agent could unintentionally corrupt datasets or expose sensitive information,\" Child warned.The perception gap that&#x27;s costing enterprises AI successPerhaps the most striking finding in the survey is a disconnect at the C-suite level.While 80% of chief data officers and 82% of chief AI officers consider data engineers integral to business success, only 55% of CIOs share that view.\"This shows that the data-forward leaders are seeing data engineering&#x27;s strategic value, but we need to do more work to help the rest of the C-suite recognize that investing in a unified, scalable data foundation and the people helping drive this is an investment in AI success, not just IT operations,\" Child said.That perception gap has real consequences.Data engineers in the surveyed organizations are already influential in decisions about AI use-case feasibility (53% of respondents) and business units&#x27; use of AI models (56%). But if CIOs don&#x27;t recognize data engineers as strategic partners, they&#x27;re unlikely to give those teams the resources, authority or seat at the table they need to prevent the kinds of tool sprawl and integration problems the survey identified.The gap appears to correlate with visibility. Chief data officers and chief AI officers work directly with data engineering teams daily and understand the complexity of what they&#x27;re managing. CIOs, focused more broadly on infrastructure and operations, may not see the strategic architecture work that data engineers are increasingly doing.This disconnect also shows up in how different executives rate the challenges facing data engineering teams. Chief AI officers are significantly more likely than CIOs to agree that data engineers&#x27; workloads are becoming increasingly heavy (93% vs. 75%). They&#x27;re also more likely to recognize data engineers&#x27; influence on overall AI strategy.What data engineers need to learn nowThe survey identified three critical skills data engineers need to develop: AI expertise, business acumen and communication abilities.For an enterprise with a 20-person data engineering team, that presents a practical challenge. Do you hire for these skills, train existing engineers or restructure the team? Child&#x27;s answer suggested the priority should be business understanding.\"The most important skill right now is for data engineers to understand what is critical to their end business users and prioritize how they can make those questions easier and faster to answer,\" he said.The lesson for enterprises: Business context matters more than adding technical certifications. Child stressed that understanding the business impact of &#x27;why&#x27; data engineers are performing certain tasks will allow them to anticipate the needs of customers better, delivering value more immediately to the business. \"The organizations with data engineering teams that prioritize this business understanding will set themselves apart from competition.\"For enterprises looking to lead in AI, the solution to the data engineering productivity crisis isn&#x27;t more AI tools. The organizations that will move fastest are consolidating their tool stacks now, deploying governance infrastructure before agents go into production and elevating data engineers from support staff to strategic architects. The window is narrow. With 54% planning agentic AI deployment within 12 months and data engineers expected to spend 61% of their time on AI projects within two years, teams that haven&#x27;t addressed tool sprawl and governance gaps will find their AI initiatives stuck in permanent pilot mode.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6c6tA8fZ29MNNDGLsHQgK9/78cecaac03eddd1b3bd5489771bd2e57/modern-data-engineer-smk.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-streaming-service-deals-133028980.html",
          "published_at": "Thu, 23 Oct 2025 12:01:26 +0000",
          "title": "The best streaming deals: Save on Hulu + Live TV, Audible, Starz and more",
          "standfirst": "If you’ve been shocked by how much you spend on streaming services lately, you’re not alone. Companies like Netflix, Disney, Max and others have been consistently raising prices to the point where you may question if streaming is even worth it anymore. We at Engadget still think it is, but we also think you should be smart with your money — and that’s where streaming deals come in. Yes, it is possible to get discounts on services like Peacock and Paramount+, even if those deals aren’t as common as a sale on AirPods. If you’re looking to save money and still stream all of the content you want, Engadget can help by laying out the best streaming deals you can get right now, how you can save with bundles and everything you should know before paying for yet another streaming service. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Audible subscription (three months) for $3 ($42 off): From now through mid-December, you can get Amazon’s audiobook subscription for just a dollar a month for three months. Note that it will auto-renew at $15 per month after that, but you can cancel at any point. Starz (one year) for $30 ($40 off): Pay upfront for one year and you can get $40 off a Stars annual subscription. There's a month-to-month option too, which costs $5 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. DirecTV starting at $50/month for one month ($35 off): All of DirecTV's signature packages are $35 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Spotify Premium Individual (3 month) for $0 ($36 off): This is our favorite music streaming service for podcasts and social features. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing as of October 21, 2025, accounting for the latest price hike. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$/8month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "content": "If you’ve been shocked by how much you spend on streaming services lately, you’re not alone. Companies like Netflix, Disney, Max and others have been consistently raising prices to the point where you may question if streaming is even worth it anymore. We at Engadget still think it is, but we also think you should be smart with your money — and that’s where streaming deals come in. Yes, it is possible to get discounts on services like Peacock and Paramount+, even if those deals aren’t as common as a sale on AirPods. If you’re looking to save money and still stream all of the content you want, Engadget can help by laying out the best streaming deals you can get right now, how you can save with bundles and everything you should know before paying for yet another streaming service. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Audible subscription (three months) for $3 ($42 off): From now through mid-December, you can get Amazon’s audiobook subscription for just a dollar a month for three months. Note that it will auto-renew at $15 per month after that, but you can cancel at any point. Starz (one year) for $30 ($40 off): Pay upfront for one year and you can get $40 off a Stars annual subscription. There's a month-to-month option too, which costs $5 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. DirecTV starting at $50/month for one month ($35 off): All of DirecTV's signature packages are $35 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Spotify Premium Individual (3 month) for $0 ($36 off): This is our favorite music streaming service for podcasts and social features. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing as of October 21, 2025, accounting for the latest price hike. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$/8month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "feed_position": 35
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/samsungs-galaxy-xr-doesnt-give-me-much-hope-for-android-xr-110000129.html",
          "published_at": "Thu, 23 Oct 2025 11:00:00 +0000",
          "title": "Samsung's Galaxy XR doesn't give me much hope for Android XR",
          "standfirst": "So Samsung made a \"Vision Pro Lite.\" That was my immediate takeaway after this week's debut of the Galaxy XR, the first Android XR device to hit the market. While Samsung deserves credit for offering something close to the Vision Pro for nearly half the price, an $1,800 headset still won't get mainstream consumers rushing out the door to experience the wonders of mixed reality. And with the limited amount of content in Android XR at the moment, the Galaxy XR is in the same position as the Vision Pro: It's just a well-polished developer kit. The only logical reason to buy a Galaxy XR would be to test out apps for Android XR. If you just want to experience VR and dabble in a bit of augmented reality, you're better off spending that money on a gaming laptop and the excellent $500 Meta Quest 3. (The Meta Quest Pro, the company’s first high-end mixed reality device, was unceremoniously killed after launching at an eye-watering $1,500.) But even for developers, the Galaxy XR feels like it's lacking, well, vision. Samsung has done an admirable job of copying almost every aspect of the Vision Pro: The sleek ski goggle design, dual micro-OLED displays and hand gesture interaction powered by a slew of cameras and sensors. But while Apple positioned the Vision Pro as its first stab at spatial computing, an exciting new platform where we can use interactive apps in virtual space, Samsung and Google are basically just gunning to put Android on your face. There aren't many custom-built XR apps, aside from Google's offerings like Maps and Photos. (Something that also reminds me of the dearth of real tablet apps on Android.) And the ability to view 360-degree videos on YouTube has been a staple of every VR headset for the last decade — it's not exactly notable on something that costs $1,800. Samsung and Google also haven't said much about how they plan to elevate XR content. At least Apple is attempting to push the industry forward with its 8K Immersive Videos, which look sharper and more realistic than low-res 360-degree content.For the most part, it seems as if Google is treating Android XR as another way to force its Gemini AI on users. In its press release for the Galaxy XR, Samsung notes that it's \"introducing a new category of AI-native devices designed to deliver immersive experiences in a form factor optimized for multimodal AI.\" …What? In addition to being a crime against the English language, what the company is actually pitching is fairly simple: It's just launching a headset that can access AI features via camera and voice inputs. Who knows, maybe Gemini will make Android XR devices more capable down the line. But at the moment, all I'm seeing in the Galaxy XR is another Samsung device that's shamelessly aping Apple, from the virtual avatars to specific pinch gestures. And Google's history in VR and interactive content doesn't inspire much hope about Android XR. Don't forget how it completely abandoned Google Cardboard, the short-lived Daydream project and its hyped up Stadia cloud service. Stadia's death was particularly galling, since Google initially pitched it as a way to revolutionize the very world of gaming, only to let it fall on its face.There’s no doubt that Samsung, Apple and Meta have a ton of work left ahead in the world of XR. Samsung is at least closer to delivering something under $1,000, and Meta also recently launched the $800 Ray-Ban Display. But price is only one part of the problem. Purpose is another issue entirely. After living with the Vision Pro since its debut, I can tell that Apple is at least thinking a bit more deeply about what it’s like to wear a computer on your face. Just look at the upgrades its made around ultra-wide Mac mirroring, or the way Spatial Personas make it feel as if you’re working alongside other people. With Android XR, Google seems to just be making a more open Vision Pro.Honestly, it’s unclear if normal users will ever want to use any sort of XR headset regularly, no matter how cheap they get. The experience making these headsets could help Google, Apple and Meta develop future AR glasses, or eyewear that offer some sort of XR experience (Samsung already has something in the works with Warby Parker and Gentle Monster). But while Apple and Meta have broken new ground in XR, Google and Samsung just seem to be following in their footsteps.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsungs-galaxy-xr-doesnt-give-me-much-hope-for-android-xr-110000129.html?src=rss",
          "content": "So Samsung made a \"Vision Pro Lite.\" That was my immediate takeaway after this week's debut of the Galaxy XR, the first Android XR device to hit the market. While Samsung deserves credit for offering something close to the Vision Pro for nearly half the price, an $1,800 headset still won't get mainstream consumers rushing out the door to experience the wonders of mixed reality. And with the limited amount of content in Android XR at the moment, the Galaxy XR is in the same position as the Vision Pro: It's just a well-polished developer kit. The only logical reason to buy a Galaxy XR would be to test out apps for Android XR. If you just want to experience VR and dabble in a bit of augmented reality, you're better off spending that money on a gaming laptop and the excellent $500 Meta Quest 3. (The Meta Quest Pro, the company’s first high-end mixed reality device, was unceremoniously killed after launching at an eye-watering $1,500.) But even for developers, the Galaxy XR feels like it's lacking, well, vision. Samsung has done an admirable job of copying almost every aspect of the Vision Pro: The sleek ski goggle design, dual micro-OLED displays and hand gesture interaction powered by a slew of cameras and sensors. But while Apple positioned the Vision Pro as its first stab at spatial computing, an exciting new platform where we can use interactive apps in virtual space, Samsung and Google are basically just gunning to put Android on your face. There aren't many custom-built XR apps, aside from Google's offerings like Maps and Photos. (Something that also reminds me of the dearth of real tablet apps on Android.) And the ability to view 360-degree videos on YouTube has been a staple of every VR headset for the last decade — it's not exactly notable on something that costs $1,800. Samsung and Google also haven't said much about how they plan to elevate XR content. At least Apple is attempting to push the industry forward with its 8K Immersive Videos, which look sharper and more realistic than low-res 360-degree content.For the most part, it seems as if Google is treating Android XR as another way to force its Gemini AI on users. In its press release for the Galaxy XR, Samsung notes that it's \"introducing a new category of AI-native devices designed to deliver immersive experiences in a form factor optimized for multimodal AI.\" …What? In addition to being a crime against the English language, what the company is actually pitching is fairly simple: It's just launching a headset that can access AI features via camera and voice inputs. Who knows, maybe Gemini will make Android XR devices more capable down the line. But at the moment, all I'm seeing in the Galaxy XR is another Samsung device that's shamelessly aping Apple, from the virtual avatars to specific pinch gestures. And Google's history in VR and interactive content doesn't inspire much hope about Android XR. Don't forget how it completely abandoned Google Cardboard, the short-lived Daydream project and its hyped up Stadia cloud service. Stadia's death was particularly galling, since Google initially pitched it as a way to revolutionize the very world of gaming, only to let it fall on its face.There’s no doubt that Samsung, Apple and Meta have a ton of work left ahead in the world of XR. Samsung is at least closer to delivering something under $1,000, and Meta also recently launched the $800 Ray-Ban Display. But price is only one part of the problem. Purpose is another issue entirely. After living with the Vision Pro since its debut, I can tell that Apple is at least thinking a bit more deeply about what it’s like to wear a computer on your face. Just look at the upgrades its made around ultra-wide Mac mirroring, or the way Spatial Personas make it feel as if you’re working alongside other people. With Android XR, Google seems to just be making a more open Vision Pro.Honestly, it’s unclear if normal users will ever want to use any sort of XR headset regularly, no matter how cheap they get. The experience making these headsets could help Google, Apple and Meta develop future AR glasses, or eyewear that offer some sort of XR experience (Samsung already has something in the works with Warby Parker and Gentle Monster). But while Apple and Meta have broken new ground in XR, Google and Samsung just seem to be following in their footsteps.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsungs-galaxy-xr-doesnt-give-me-much-hope-for-android-xr-110000129.html?src=rss",
          "feed_position": 37
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-noise-canceling-headphones-130029881.html",
          "published_at": "Thu, 23 Oct 2025 09:00:35 +0000",
          "title": "The best noise-canceling headphones for 2025",
          "standfirst": "Whether you're working in a noisy office, commuting on a packed train or just trying to focus at home, a good pair of noise-canceling headphones can make all the difference. The best noise-canceling headphones block out distractions and let you enjoy your music, podcasts or calls in peace — all while delivering great sound quality and all-day comfort. From models with plush cushions to wireless cans with loads of extra features, there’s something here for every style and budget. Table of contents Best noise-canceling headphones for 2025 How to choose the best noise-canceling headphones for you How we test noise-canceling headphones Other noise-canceling headphones we tested Noise-canceling headphones FAQs Best noise-canceling headphones of 2025 How to choose the best noise-canceling headphones for you Design When you’re shopping for the best wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of this guide, I focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear, active noise-canceling headphones are much more effective at blocking outside sounds since your ears are completely covered. For gamers, there are also gaming headsets that feature noise cancellation — some even have detachable microphones, so they can double as over-ear headphones. However, for the purpose of this article, we’re only going to be focusing on noise-canceling headphones rather than headsets. Look for models with a comfortable headband and memory foam ear cups to ensure you can wear them for long periods without discomfort. Many headphones also come with a range of color options, so if aesthetics matter to you, you’ll find plenty of choices beyond just black or white. Whether you’re looking for something neutral or a bold pop of color, brands now offer a variety of styles to match your personal taste. Finally, if you’re planning to wear your headphones for long periods of time, it’s important to pick a model with a comfortable fit. Memory foam ear cups, an adjustable headband, and lightweight materials can make all the difference during extended listening sessions. After all, great sound is only part of the equation; comfort matters just as much. Type of noise cancellation Next, you’ll want to look at the type of ANC a set of headphones offers. You’ll come across terms like “hybrid active noise cancellation” or “hybrid adaptive active noise cancellation,” and there are key differences between the two. A hybrid ANC setup uses microphones on the inside and on the outside of the device to detect outside noise and cancel it out. By analyzing input from both mics, a hybrid system can combat more sounds than “regular” ANC, but it does so at a constant level that doesn’t change. Adaptive ANC takes the hybrid configuration a step further by continuously adjusting the noise cancellation for changes in your environment and any leakage around the padding of the ear cups. Adaptive noise-canceling also does a better job with wind noise, which can really kill your vibe while using headphones outdoors. Some high-end headphones also support Dolby Atmos, which enhances spatial audio and makes everything from music to movies sound more immersive. For the purposes of this best headphones list, I’m only considering products with hybrid ANC or adaptive ANC setups because those are the most effective at blocking noise and improving your overall listening experience. Customization You’ll also want to check to see if the ANC system on a prospective set of headphones offers adjustable levels of noise cancellation or presets. These can help you dial in the amount of ANC you need for various environments, but it can also help you save battery life. Master & Dynamic, for example, has ANC presets that provide both maximum noise blocking and more efficient cancellation that is more energy efficient. Other companies may include a slider in their companion apps that let you adjust the ANC level to your liking. Some high-end models even allow you to fine-tune the ANC for specific types of environments. How we test noise-canceling headphones The primary way we test headphones is to wear them as much as possible. I prefer to do this over a one-to-two-week period, but sometimes deadlines don’t allow it. During this time, I listen to a mix of music and podcasts, while also using the headphones to take both voice and video calls. Since battery life for headphones can be 30 hours or more, I drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, I’ll typically power the headphones off several times and leave them that way during a review. This simulates real-world use and keeps me from having to constantly monitor the process for over 24 straight hours. To test ANC performance specifically, I use headphones in a variety of environments, from noisy coffee shops to quiet home offices. When my schedule allows, I use them during air travel since plane noise is a massive distraction to both work and relaxation. Even if I can’t hop on a flight, I’ll simulate a constant roar with white noise machines, bathroom fans, vacuums and more. I also make note of how well each device blocks human voices, which are a key stumbling block for a lot of ANC headphones. ANC-related features are something else to consider. Here, I do a thorough review of companion apps, testing each feature as I work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones I’m testing are an updated version of a previous model, I’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that I review. Other noise-canceling headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancellation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor, which is actually handy. All told, that’s not a lot for a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 is more expensive and not nearly as comfortable as the Px7 S3. Noble Audio FoKus Apollo While this is my top pick for overall sound quality in our main guide to the best wireless headphones, the ANC performance is less impressive than the Px7 S3. Bowers & Wilkins gets the nod here for its improved noise cancellation over the Px7 S2 and Px7 S2e, and its overall excellent audio quality. Noise-canceling headphones FAQs Does noise cancellation block all noise? Noise cancellation doesn’t block out all noise, though it does drastically reduce the volume of most external sounds. Is there a difference between wired vs wireless noise-canceling headphones? In terms of sound quality, if you have two headphones — one wired and one wireless — with similar specs, the difference is going to be very minimal. However, wireless headphones offer more convenience, allowing you to move around more freely with your headphones on, which is why they often feature noise cancellation to minimize external sounds. Does noise cancellation impact sound quality? ANC does bear some weight on sound quality, but the impact of this often doesn’t outweigh the benefits. Noise cancellation reduces ambient noise, allowing a greater focus on audio detail. For audiophiles, however, there may be a small difference in sound fidelity when ANC is turned on.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-noise-canceling-headphones-130029881.html?src=rss",
          "content": "Whether you're working in a noisy office, commuting on a packed train or just trying to focus at home, a good pair of noise-canceling headphones can make all the difference. The best noise-canceling headphones block out distractions and let you enjoy your music, podcasts or calls in peace — all while delivering great sound quality and all-day comfort. From models with plush cushions to wireless cans with loads of extra features, there’s something here for every style and budget. Table of contents Best noise-canceling headphones for 2025 How to choose the best noise-canceling headphones for you How we test noise-canceling headphones Other noise-canceling headphones we tested Noise-canceling headphones FAQs Best noise-canceling headphones of 2025 How to choose the best noise-canceling headphones for you Design When you’re shopping for the best wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of this guide, I focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear, active noise-canceling headphones are much more effective at blocking outside sounds since your ears are completely covered. For gamers, there are also gaming headsets that feature noise cancellation — some even have detachable microphones, so they can double as over-ear headphones. However, for the purpose of this article, we’re only going to be focusing on noise-canceling headphones rather than headsets. Look for models with a comfortable headband and memory foam ear cups to ensure you can wear them for long periods without discomfort. Many headphones also come with a range of color options, so if aesthetics matter to you, you’ll find plenty of choices beyond just black or white. Whether you’re looking for something neutral or a bold pop of color, brands now offer a variety of styles to match your personal taste. Finally, if you’re planning to wear your headphones for long periods of time, it’s important to pick a model with a comfortable fit. Memory foam ear cups, an adjustable headband, and lightweight materials can make all the difference during extended listening sessions. After all, great sound is only part of the equation; comfort matters just as much. Type of noise cancellation Next, you’ll want to look at the type of ANC a set of headphones offers. You’ll come across terms like “hybrid active noise cancellation” or “hybrid adaptive active noise cancellation,” and there are key differences between the two. A hybrid ANC setup uses microphones on the inside and on the outside of the device to detect outside noise and cancel it out. By analyzing input from both mics, a hybrid system can combat more sounds than “regular” ANC, but it does so at a constant level that doesn’t change. Adaptive ANC takes the hybrid configuration a step further by continuously adjusting the noise cancellation for changes in your environment and any leakage around the padding of the ear cups. Adaptive noise-canceling also does a better job with wind noise, which can really kill your vibe while using headphones outdoors. Some high-end headphones also support Dolby Atmos, which enhances spatial audio and makes everything from music to movies sound more immersive. For the purposes of this best headphones list, I’m only considering products with hybrid ANC or adaptive ANC setups because those are the most effective at blocking noise and improving your overall listening experience. Customization You’ll also want to check to see if the ANC system on a prospective set of headphones offers adjustable levels of noise cancellation or presets. These can help you dial in the amount of ANC you need for various environments, but it can also help you save battery life. Master & Dynamic, for example, has ANC presets that provide both maximum noise blocking and more efficient cancellation that is more energy efficient. Other companies may include a slider in their companion apps that let you adjust the ANC level to your liking. Some high-end models even allow you to fine-tune the ANC for specific types of environments. How we test noise-canceling headphones The primary way we test headphones is to wear them as much as possible. I prefer to do this over a one-to-two-week period, but sometimes deadlines don’t allow it. During this time, I listen to a mix of music and podcasts, while also using the headphones to take both voice and video calls. Since battery life for headphones can be 30 hours or more, I drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, I’ll typically power the headphones off several times and leave them that way during a review. This simulates real-world use and keeps me from having to constantly monitor the process for over 24 straight hours. To test ANC performance specifically, I use headphones in a variety of environments, from noisy coffee shops to quiet home offices. When my schedule allows, I use them during air travel since plane noise is a massive distraction to both work and relaxation. Even if I can’t hop on a flight, I’ll simulate a constant roar with white noise machines, bathroom fans, vacuums and more. I also make note of how well each device blocks human voices, which are a key stumbling block for a lot of ANC headphones. ANC-related features are something else to consider. Here, I do a thorough review of companion apps, testing each feature as I work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones I’m testing are an updated version of a previous model, I’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that I review. Other noise-canceling headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancellation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor, which is actually handy. All told, that’s not a lot for a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 is more expensive and not nearly as comfortable as the Px7 S3. Noble Audio FoKus Apollo While this is my top pick for overall sound quality in our main guide to the best wireless headphones, the ANC performance is less impressive than the Px7 S3. Bowers & Wilkins gets the nod here for its improved noise cancellation over the Px7 S2 and Px7 S2e, and its overall excellent audio quality. Noise-canceling headphones FAQs Does noise cancellation block all noise? Noise cancellation doesn’t block out all noise, though it does drastically reduce the volume of most external sounds. Is there a difference between wired vs wireless noise-canceling headphones? In terms of sound quality, if you have two headphones — one wired and one wireless — with similar specs, the difference is going to be very minimal. However, wireless headphones offer more convenience, allowing you to move around more freely with your headphones on, which is why they often feature noise cancellation to minimize external sounds. Does noise cancellation impact sound quality? ANC does bear some weight on sound quality, but the impact of this often doesn’t outweigh the benefits. Noise cancellation reduces ambient noise, allowing a greater focus on audio detail. For audiophiles, however, there may be a small difference in sound fidelity when ANC is turned on.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-noise-canceling-headphones-130029881.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/fujifilms-x-t30-iii-adds-a-film-simulation-dial-and-6k-video-072148245.html",
          "published_at": "Thu, 23 Oct 2025 07:21:48 +0000",
          "title": "Fujifilm's X-T30 III adds a film simulation dial and 6K video",
          "standfirst": "When Fujifilm launched the X-T50 last year, no one was sure what would happen with its aging X-T30 lineup. The company just answered that question with the launch of the X-T30 III, boosting the speed and improving autofocus of the last model, while adding a film simulation dial seen on other recent models. It's very light for travel or street photography, but has some powerful features like 6.2K video and subject-detect autofocus, all at a reasonable price. The original X-T30 first arrived in 2019 and was replaced in 2022 by the X-T30 II that was more of a mild update than an all-new camera. However, the X-T30 III has a number of key updates that bring it in line with other recent models like the X-M5 and X-T50. It does have the same 26.1MP X-Trans sensor as before (with a 1.5x crop compared to a full-frame camera), but now uses Fujifilm's latest image processor that doubles image processing speed and significantly improves video capabilities. Ryan Tuttle for Fujifilm The X-T30 III is meant to be taken on adventures, so it's still very light at just 378 grams or 13.33 ounces, a touch less than the previous model. Control-wise, the biggest addition is a film simulation dial just like the one on the X-M5 and X-T50, replacing the mode dial from the X-T30 II. It's designed to make it easy to switch between film simulations like Reala Ace and Nostalgic Neg, while offering three customizable positions to let users save \"recipes\" of their own making. Otherwise, the X-T30 III has a generous complement of dials and buttons something that allows for precise control but may intimidate newbies. The rear display tilts up but doesn't flip out, and the 2.36-million-dot electronic viewfinder is on the low end for resolution. The main feature missing on the X-T30 III is in-body stabilization, so you'll need either a stabilized (OIS) lens or electronic stabilization for video. Fujjifilm Burst shooting speeds are the same as before at 8 fps with the mechanical shutter and 20 fps in electronic mode. However, more of your shots are likely to be sharp thanks to the updated, faster autofocus. Along with the extra speed, Fujifilm introduced new AI subject detection modes including Auto-Tracking, Animals, Birds and Vehicles. Video also gets a big upgrade. The X-T30 III can now shot 6.2K 30 fps video using the entire sensor (up from 4K 30p before), or 4K at 60 fps with a mild 1.18x crop. All of those resolutions are available with 10-bit modes to boost dynamic range. However, the X-T30 III lacks in-body stabilization, has a weird 2.5mm microphone input and a display that only tilts and doesn't flip out. That makes it fine as a hybrid camera, but if you mostly shoot video, a model like the X-S20 may be a better choice. Fujifilm Other key features include a microHDMI port for RAW video output, a single SD memory card (that's of the low-speed UHS-I variety unfortunately), and improved battery life with up to 425 shots to a charge. Fujifilm also introduced a new lens, the Fujinon XC13-33mmF3.5-6.3 OIS that offers an interesting ultrawide full-frame equivalent zoom range of around 20-50mm. The X-T30 III is now on pre-order for $999 in multiple colors (black, charcoal silver and silver) with shipping set to start in November 2025. The Fujinon XC13-33mmF3.5-6.3 OIS will also ship around the same time for $399. This article originally appeared on Engadget at https://www.engadget.com/cameras/fujifilms-x-t30-iii-adds-a-film-simulation-dial-and-6k-video-072148245.html?src=rss",
          "content": "When Fujifilm launched the X-T50 last year, no one was sure what would happen with its aging X-T30 lineup. The company just answered that question with the launch of the X-T30 III, boosting the speed and improving autofocus of the last model, while adding a film simulation dial seen on other recent models. It's very light for travel or street photography, but has some powerful features like 6.2K video and subject-detect autofocus, all at a reasonable price. The original X-T30 first arrived in 2019 and was replaced in 2022 by the X-T30 II that was more of a mild update than an all-new camera. However, the X-T30 III has a number of key updates that bring it in line with other recent models like the X-M5 and X-T50. It does have the same 26.1MP X-Trans sensor as before (with a 1.5x crop compared to a full-frame camera), but now uses Fujifilm's latest image processor that doubles image processing speed and significantly improves video capabilities. Ryan Tuttle for Fujifilm The X-T30 III is meant to be taken on adventures, so it's still very light at just 378 grams or 13.33 ounces, a touch less than the previous model. Control-wise, the biggest addition is a film simulation dial just like the one on the X-M5 and X-T50, replacing the mode dial from the X-T30 II. It's designed to make it easy to switch between film simulations like Reala Ace and Nostalgic Neg, while offering three customizable positions to let users save \"recipes\" of their own making. Otherwise, the X-T30 III has a generous complement of dials and buttons something that allows for precise control but may intimidate newbies. The rear display tilts up but doesn't flip out, and the 2.36-million-dot electronic viewfinder is on the low end for resolution. The main feature missing on the X-T30 III is in-body stabilization, so you'll need either a stabilized (OIS) lens or electronic stabilization for video. Fujjifilm Burst shooting speeds are the same as before at 8 fps with the mechanical shutter and 20 fps in electronic mode. However, more of your shots are likely to be sharp thanks to the updated, faster autofocus. Along with the extra speed, Fujifilm introduced new AI subject detection modes including Auto-Tracking, Animals, Birds and Vehicles. Video also gets a big upgrade. The X-T30 III can now shot 6.2K 30 fps video using the entire sensor (up from 4K 30p before), or 4K at 60 fps with a mild 1.18x crop. All of those resolutions are available with 10-bit modes to boost dynamic range. However, the X-T30 III lacks in-body stabilization, has a weird 2.5mm microphone input and a display that only tilts and doesn't flip out. That makes it fine as a hybrid camera, but if you mostly shoot video, a model like the X-S20 may be a better choice. Fujifilm Other key features include a microHDMI port for RAW video output, a single SD memory card (that's of the low-speed UHS-I variety unfortunately), and improved battery life with up to 425 shots to a charge. Fujifilm also introduced a new lens, the Fujinon XC13-33mmF3.5-6.3 OIS that offers an interesting ultrawide full-frame equivalent zoom range of around 20-50mm. The X-T30 III is now on pre-order for $999 in multiple colors (black, charcoal silver and silver) with shipping set to start in November 2025. The Fujinon XC13-33mmF3.5-6.3 OIS will also ship around the same time for $399. This article originally appeared on Engadget at https://www.engadget.com/cameras/fujifilms-x-t30-iii-adds-a-film-simulation-dial-and-6k-video-072148245.html?src=rss",
          "feed_position": 39,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c61cba10-afdd-11f0-9fff-ba497027a57e"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html",
          "published_at": "Thu, 23 Oct 2025 07:00:37 +0000",
          "title": "The best wireless earbuds for 2025",
          "standfirst": "Wireless earbuds have become the go-to choice for listening on the move. Whether you’re at the gym, commuting or relaxing at home, the best wireless earbuds give you comfort, freedom and solid sound quality without tangled cables. They’re lightweight, slip easily into your pocket and connect quickly to your phone, tablet or laptop.The tricky part is choosing the right pair. Some models focus on powerful noise cancellation while others put battery life or affordability first. Then you’ve got features like water resistance for workouts or touch controls for quick track changes. With so many choices, finding the best wireless earbuds depends on what matters most to you, and that’s exactly what this guide will help you figure out. Table of contents Best wireless earbuds of 2025 What to look for in the best wireless earbuds How we test wireless earbuds Other wireless earbuds we tested Wireless earbuds FAQs Best wireless earbuds of 2025 What to look for in the best wireless earbuds When it comes to shopping for earphones, the first thing to consider is design or wear style. Do you prefer a semi-open fit like AirPods or do you want something that completely closes off your ears? If you’re shopping for earbuds with active noise cancellation, you'll want the latter, but a case can be made for the former if you want to wear them all day or frequent places where you need to be tuned in to the ambient sounds. The overall shape of earbuds can determine whether you get a comfortable fit, so can the size and weight, so you’ll want to consider all that before deciding. And remember: audio companies aren’t perfect, so despite lots of research, the earbud shape they decided on may not fit you well. Don’t be afraid to return ill-fitting earbuds for something that’s more comfortable. As wireless earbuds have become the norm, they’re now more reliable for basic things like consistent Bluetooth connectivity. Companies are still in a race to pack as much as they can into increasingly smaller designs. This typically means a longer list of features on the more premium sets of earbuds with basic functionality on the cheapest models. Carefully consider what you can’t live without when selecting your next earbuds, and make sure key items like automatic pausing and multipoint connectivity are on the spec sheet. You’ll also want to investigate the volume and touch controls as you’ll often have to sacrifice access to something else to make that adjustment via on-board taps or swipes. Some earbuds even offer app settings to tweak the audio profiles or firmware updates to improve performance over time. For those in the Apple ecosystem, features like auto-pairing with devices, especially with AirPods Pro 3, can be an added advantage, while Android users may want to look for models that offer similar cross-device functionality. When it comes to battery life, the average set of earbuds lasts about five hours on a single charge. You can find sets that last longer, but this is likely enough to get you through a work day if you’re docking the buds during lunch or the occasional meeting. You’ll want to check on how many extra charges are available via the case and if it supports wireless charging. Companies will also make lofty claims about call quality on wireless earbuds. Despite lots of promises, the reality is most earbuds still leave you sounding like you’re on speakerphone. There are some sets that deliver, but don’t get your hopes up unless reviews confirm the claims. Sound can be subjective, so we recommend trying before you buy if at all possible. This is especially true if you're an audiophile. We understand this isn’t easy when most of us do a lot of shopping online, but trying on a set of earbuds and listening to them for a few minutes can save you from an expensive case of buyer's remorse. If a store doesn’t allow a quick demo, most retailers have return policies that will let you take earbuds back you don’t like. Of course, you have to be willing to temporarily part with funds in order to do this. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all earbuds support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you, especially if you plan to use them for playback of high-quality audio. How we test wireless earbuds The primary way we test earbuds is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for earbuds is typically less than a full day, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). To judge audio quality, we listen to a range of genres, noting any differences in the sound profile across the styles. We also test at both low and high volumes to check for consistency in the tuning. To assess call quality, we’ll record audio samples with the earbuds’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the earbuds we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older buds. Ditto for the closest competition for each new set of earbuds that we review. Other wireless Bluetooth earbuds we tested Sony WF-C710N The WF-C710N is a set of compact and comfy earbuds that offer several of Sony’s best features. While the ANC performance is above average for this price ($120), sound quality isn’t as good as the company’s slightly more expensive options. Battery life fell below stated figures and call performance isn’t good enough to use these buds for work. Beats Powerbeats Pro 2 The newest version of the Powerbeats Pro have an improved, comfortable design, balanced bass and new H2 chips and a heart rate sensor inside. But heart rate support is currently limited on iOS. Samsung Galaxy Buds 3 The Galaxy Buds 3 combine ANC with an open-type design, which renders the noise-blocking abilities of the earbuds mostly useless. Still, there’s great low-end tone with ample bass when a track demands it. There are also lots of handy features, most of which require a Samsung phone. But at this price, there are better options from Google, Beats and Sony Sennheiser Momentum Sport I really like the overall shape of the Momentum Sport earbuds. They’re more comfortable than the Momentum True Wireless 4 and fit in my ears better. What’s more, the body temperature and heart rate sensors work well, sending those stats to a variety of apps. However, that sport-tracking feature works best with Polar’s app and devices, so there’s that consideration. Also, the audio quality and ANC performance isn’t as good as the MTW4, and these earbuds are pricey. Beats Solo Buds There’s a lot to like about the Solo Buds for $80. For me, the primary perk is they’re very comfortable to wear for long periods of time thanks to some thoughtful design considerations. You only get the basics here in terms of features and, as expected, the overall sound quality isn’t as good as the pricier models in the Beats lineup. You will get 18 hours of battery life though, since the company nixed the battery in the case and beefed up the listening time in the buds themselves. Bose Ultra Open Earbuds Bose created something very unique for this set of earbuds that allows you to stay in-tune with the world while listening to audio content. The clip-on design is very comfortable, but sound quality suffers due to the open-type fit, especially when it comes to bass and spatial audio. Audio-Technica ATH-TWX7 These stick buds have a compact design that’s comfortable to wear and the warm sound profile is great at times. However, overall audio performance is inconsistent and there’s no automatic pausing. Master & Dynamic MW09 Retooled audio, better ambient sound mode and reliable multipoint Bluetooth are the best things the MW09 has to offer. They’re expensive though, and you can find better ANC performance elsewhere. Wireless earbud FAQs What is considered good battery life for true wireless earbuds? Most wireless earbuds will last five hours on a single charge, at the least. You can find some pairs that have even better battery life, lasting between six and eight hours before they need more juice. All of the best wireless earbuds come with a charging case, which will provide additional hours of battery life — but you'll have to return each bud to the case in order to charge them up. Is sound quality better on headphones or earbuds? Comparing sound quality on earbuds and headphones is a bit like comparing apples and oranges. There are a lot of variables to consider and the differences in components make a direct comparison difficult. Personally, I prefer the audio quality from over-ear headphones, but I can tell you the sound from earbuds like Sennheiser’s Momentum True Wireless 3 is also outstanding. Which wireless earbuds have the longest battery life? With new models coming out all the time, tracking the hours of battery life for each this can be difficult to keep tabs on. The longest-lasting earbuds we’ve reviewed are Audio-Technica’s ATH-CKS5TW. The company states they last 15 hours, but the app was still showing 40 percent at that mark during our tests. The only downside is these earbuds debuted in 2019 and both technology and features have improved since. In terms of current models, Master & Dynamic’s MW08 offers 12 hours of use on a charge with ANC off (10 with ANC on) and JBL has multiple options with 10-hour batteries. What wireless earbuds are waterproof? There are plenty of options these days when it comes to increased water resistance. To determine the level of protection, you’ll want to look for an IP (ingress protection) rating. The first number indicates intrusion protection from things like dust. The second number is the level of moisture protection and you’ll want to make sure that figure is 7 or higher. At this water-resistance rating, earbuds can withstand full immersion for up to 30 minutes in depths up to one meter (3.28 feet). If either of the IP numbers is an X, that means it doesn’t have any special protection. For example, a pair of wireless earbuds that are IPX7 wouldn’t be built to avoid dust intrusion, but they would be ok if you dropped them in shallow water. Which earbuds stay in ears the best? A secure fit can vary wildly from person to person. All of our ears are different, so audio companies are designing their products to fit the most people they can with a single shape. This is why AirPods will easily fall out for some but stay put for others. Design touches like wing tips or fins typically come on fitness models and those elements can help keep things in place. You’ll likely just have to try earbuds on, and if they don’t fit well return them. What wireless earbuds work with PS5? PlayStation 5 doesn’t support Bluetooth audio without an adapter or dongle. Even Sony’s own gaming headsets come with a transmitter that connects to the console. There are universal options that allow you to use any headphones, headset or earbuds with a PS5. Once you have one, plug it into a USB port on the console and pair your earbuds with it. Recent updates September 2025: Updated to add AirPods Pro 3 to our top picks. May 2025: Updated to ensure top picks and buying advice remain accurate. March 2025: Updated the top pick for the best sounding wireless earbuds - runner up. January 2025: Updated the top pick for best sounding wireless earbuds. July 2024: Updated our list to include the Samsung Galaxy Buds 3 Pro.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html?src=rss",
          "content": "Wireless earbuds have become the go-to choice for listening on the move. Whether you’re at the gym, commuting or relaxing at home, the best wireless earbuds give you comfort, freedom and solid sound quality without tangled cables. They’re lightweight, slip easily into your pocket and connect quickly to your phone, tablet or laptop.The tricky part is choosing the right pair. Some models focus on powerful noise cancellation while others put battery life or affordability first. Then you’ve got features like water resistance for workouts or touch controls for quick track changes. With so many choices, finding the best wireless earbuds depends on what matters most to you, and that’s exactly what this guide will help you figure out. Table of contents Best wireless earbuds of 2025 What to look for in the best wireless earbuds How we test wireless earbuds Other wireless earbuds we tested Wireless earbuds FAQs Best wireless earbuds of 2025 What to look for in the best wireless earbuds When it comes to shopping for earphones, the first thing to consider is design or wear style. Do you prefer a semi-open fit like AirPods or do you want something that completely closes off your ears? If you’re shopping for earbuds with active noise cancellation, you'll want the latter, but a case can be made for the former if you want to wear them all day or frequent places where you need to be tuned in to the ambient sounds. The overall shape of earbuds can determine whether you get a comfortable fit, so can the size and weight, so you’ll want to consider all that before deciding. And remember: audio companies aren’t perfect, so despite lots of research, the earbud shape they decided on may not fit you well. Don’t be afraid to return ill-fitting earbuds for something that’s more comfortable. As wireless earbuds have become the norm, they’re now more reliable for basic things like consistent Bluetooth connectivity. Companies are still in a race to pack as much as they can into increasingly smaller designs. This typically means a longer list of features on the more premium sets of earbuds with basic functionality on the cheapest models. Carefully consider what you can’t live without when selecting your next earbuds, and make sure key items like automatic pausing and multipoint connectivity are on the spec sheet. You’ll also want to investigate the volume and touch controls as you’ll often have to sacrifice access to something else to make that adjustment via on-board taps or swipes. Some earbuds even offer app settings to tweak the audio profiles or firmware updates to improve performance over time. For those in the Apple ecosystem, features like auto-pairing with devices, especially with AirPods Pro 3, can be an added advantage, while Android users may want to look for models that offer similar cross-device functionality. When it comes to battery life, the average set of earbuds lasts about five hours on a single charge. You can find sets that last longer, but this is likely enough to get you through a work day if you’re docking the buds during lunch or the occasional meeting. You’ll want to check on how many extra charges are available via the case and if it supports wireless charging. Companies will also make lofty claims about call quality on wireless earbuds. Despite lots of promises, the reality is most earbuds still leave you sounding like you’re on speakerphone. There are some sets that deliver, but don’t get your hopes up unless reviews confirm the claims. Sound can be subjective, so we recommend trying before you buy if at all possible. This is especially true if you're an audiophile. We understand this isn’t easy when most of us do a lot of shopping online, but trying on a set of earbuds and listening to them for a few minutes can save you from an expensive case of buyer's remorse. If a store doesn’t allow a quick demo, most retailers have return policies that will let you take earbuds back you don’t like. Of course, you have to be willing to temporarily part with funds in order to do this. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all earbuds support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you, especially if you plan to use them for playback of high-quality audio. How we test wireless earbuds The primary way we test earbuds is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for earbuds is typically less than a full day, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). To judge audio quality, we listen to a range of genres, noting any differences in the sound profile across the styles. We also test at both low and high volumes to check for consistency in the tuning. To assess call quality, we’ll record audio samples with the earbuds’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the earbuds we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older buds. Ditto for the closest competition for each new set of earbuds that we review. Other wireless Bluetooth earbuds we tested Sony WF-C710N The WF-C710N is a set of compact and comfy earbuds that offer several of Sony’s best features. While the ANC performance is above average for this price ($120), sound quality isn’t as good as the company’s slightly more expensive options. Battery life fell below stated figures and call performance isn’t good enough to use these buds for work. Beats Powerbeats Pro 2 The newest version of the Powerbeats Pro have an improved, comfortable design, balanced bass and new H2 chips and a heart rate sensor inside. But heart rate support is currently limited on iOS. Samsung Galaxy Buds 3 The Galaxy Buds 3 combine ANC with an open-type design, which renders the noise-blocking abilities of the earbuds mostly useless. Still, there’s great low-end tone with ample bass when a track demands it. There are also lots of handy features, most of which require a Samsung phone. But at this price, there are better options from Google, Beats and Sony Sennheiser Momentum Sport I really like the overall shape of the Momentum Sport earbuds. They’re more comfortable than the Momentum True Wireless 4 and fit in my ears better. What’s more, the body temperature and heart rate sensors work well, sending those stats to a variety of apps. However, that sport-tracking feature works best with Polar’s app and devices, so there’s that consideration. Also, the audio quality and ANC performance isn’t as good as the MTW4, and these earbuds are pricey. Beats Solo Buds There’s a lot to like about the Solo Buds for $80. For me, the primary perk is they’re very comfortable to wear for long periods of time thanks to some thoughtful design considerations. You only get the basics here in terms of features and, as expected, the overall sound quality isn’t as good as the pricier models in the Beats lineup. You will get 18 hours of battery life though, since the company nixed the battery in the case and beefed up the listening time in the buds themselves. Bose Ultra Open Earbuds Bose created something very unique for this set of earbuds that allows you to stay in-tune with the world while listening to audio content. The clip-on design is very comfortable, but sound quality suffers due to the open-type fit, especially when it comes to bass and spatial audio. Audio-Technica ATH-TWX7 These stick buds have a compact design that’s comfortable to wear and the warm sound profile is great at times. However, overall audio performance is inconsistent and there’s no automatic pausing. Master & Dynamic MW09 Retooled audio, better ambient sound mode and reliable multipoint Bluetooth are the best things the MW09 has to offer. They’re expensive though, and you can find better ANC performance elsewhere. Wireless earbud FAQs What is considered good battery life for true wireless earbuds? Most wireless earbuds will last five hours on a single charge, at the least. You can find some pairs that have even better battery life, lasting between six and eight hours before they need more juice. All of the best wireless earbuds come with a charging case, which will provide additional hours of battery life — but you'll have to return each bud to the case in order to charge them up. Is sound quality better on headphones or earbuds? Comparing sound quality on earbuds and headphones is a bit like comparing apples and oranges. There are a lot of variables to consider and the differences in components make a direct comparison difficult. Personally, I prefer the audio quality from over-ear headphones, but I can tell you the sound from earbuds like Sennheiser’s Momentum True Wireless 3 is also outstanding. Which wireless earbuds have the longest battery life? With new models coming out all the time, tracking the hours of battery life for each this can be difficult to keep tabs on. The longest-lasting earbuds we’ve reviewed are Audio-Technica’s ATH-CKS5TW. The company states they last 15 hours, but the app was still showing 40 percent at that mark during our tests. The only downside is these earbuds debuted in 2019 and both technology and features have improved since. In terms of current models, Master & Dynamic’s MW08 offers 12 hours of use on a charge with ANC off (10 with ANC on) and JBL has multiple options with 10-hour batteries. What wireless earbuds are waterproof? There are plenty of options these days when it comes to increased water resistance. To determine the level of protection, you’ll want to look for an IP (ingress protection) rating. The first number indicates intrusion protection from things like dust. The second number is the level of moisture protection and you’ll want to make sure that figure is 7 or higher. At this water-resistance rating, earbuds can withstand full immersion for up to 30 minutes in depths up to one meter (3.28 feet). If either of the IP numbers is an X, that means it doesn’t have any special protection. For example, a pair of wireless earbuds that are IPX7 wouldn’t be built to avoid dust intrusion, but they would be ok if you dropped them in shallow water. Which earbuds stay in ears the best? A secure fit can vary wildly from person to person. All of our ears are different, so audio companies are designing their products to fit the most people they can with a single shape. This is why AirPods will easily fall out for some but stay put for others. Design touches like wing tips or fins typically come on fitness models and those elements can help keep things in place. You’ll likely just have to try earbuds on, and if they don’t fit well return them. What wireless earbuds work with PS5? PlayStation 5 doesn’t support Bluetooth audio without an adapter or dongle. Even Sony’s own gaming headsets come with a transmitter that connects to the console. There are universal options that allow you to use any headphones, headset or earbuds with a PS5. Once you have one, plug it into a USB port on the console and pair your earbuds with it. Recent updates September 2025: Updated to add AirPods Pro 3 to our top picks. May 2025: Updated to ensure top picks and buying advice remain accurate. March 2025: Updated the top pick for the best sounding wireless earbuds - runner up. January 2025: Updated the top pick for best sounding wireless earbuds. July 2024: Updated our list to include the Samsung Galaxy Buds 3 Pro.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html?src=rss",
          "feed_position": 40
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/amazons-smart-glasses-with-ai-will-help-its-drivers-deliver-packages-faster-041009681.html",
          "published_at": "Thu, 23 Oct 2025 04:10:09 +0000",
          "title": "Amazon's smart glasses with AI will help its drivers deliver packages faster",
          "standfirst": "Amazon has revealed that it's currently working on smart glasses designed for delivery drivers, confirming previous reports about the project. The company said that glasses use AI-powered sensing capabilities and computer vision to detect what their cameras are seeing. Drivers then get guidance through the glasses' heads-up display (HUD) embedded right into the lens. Based on Amazon's announcement, it's been working on the glasses for a while, and hundreds of delivery drivers had already tested early versions to provide the company with feedback. The glasses automatically activate after the driver parks their vehicle. They then show users the right packages to deliver, according to their location. Users will see the list of packages they have to take out on the HUD, and the glasses can even tell them if they pull out the right package from their pile. When they get out of their vehicle, the glasses will display turn-by-turn navigation to the delivery address and will also show them hazards along the way, as well as help them navigate complex locations like apartment buildings. Simply put, the device allows them to find delivery addresses and drop off packages without having to use their phones. Drivers will even be able to capture proof of delivery with the wearable. Amazon's glasses will be paired with a vest that's fitted with a controller and a dedicated emergency button drivers can press to call emergency services along their routes. The device comes with a swappable battery to ensure all-day use and can be fitted with prescription and transitional lenses if the drivers need them. Amazon expects future versions of the glasses to be able to notify drivers if they're dropping a package at the wrong address and to be able to detect and notify them about more hazardous elements, like if there's a pet in the yard. In the annual event wherein the company announced the device, Amazon transportation vice president Beryl Tomay said it \"reduces the need to manage a phone and a package\" and helps drivers \"stay at attention, which enhances their safety.\" She also said that among the testers, Amazon had seen time savings of 30 minutes for a given shit. The company didn't say anything about developing smart glasses for consumers, but The Information's previous report said that it's also working on a model for the general public slated to be released in late 2026 or early 2027. This article originally appeared on Engadget at https://www.engadget.com/wearables/amazons-smart-glasses-with-ai-will-help-its-drivers-deliver-packages-faster-041009681.html?src=rss",
          "content": "Amazon has revealed that it's currently working on smart glasses designed for delivery drivers, confirming previous reports about the project. The company said that glasses use AI-powered sensing capabilities and computer vision to detect what their cameras are seeing. Drivers then get guidance through the glasses' heads-up display (HUD) embedded right into the lens. Based on Amazon's announcement, it's been working on the glasses for a while, and hundreds of delivery drivers had already tested early versions to provide the company with feedback. The glasses automatically activate after the driver parks their vehicle. They then show users the right packages to deliver, according to their location. Users will see the list of packages they have to take out on the HUD, and the glasses can even tell them if they pull out the right package from their pile. When they get out of their vehicle, the glasses will display turn-by-turn navigation to the delivery address and will also show them hazards along the way, as well as help them navigate complex locations like apartment buildings. Simply put, the device allows them to find delivery addresses and drop off packages without having to use their phones. Drivers will even be able to capture proof of delivery with the wearable. Amazon's glasses will be paired with a vest that's fitted with a controller and a dedicated emergency button drivers can press to call emergency services along their routes. The device comes with a swappable battery to ensure all-day use and can be fitted with prescription and transitional lenses if the drivers need them. Amazon expects future versions of the glasses to be able to notify drivers if they're dropping a package at the wrong address and to be able to detect and notify them about more hazardous elements, like if there's a pet in the yard. In the annual event wherein the company announced the device, Amazon transportation vice president Beryl Tomay said it \"reduces the need to manage a phone and a package\" and helps drivers \"stay at attention, which enhances their safety.\" She also said that among the testers, Amazon had seen time savings of 30 minutes for a given shit. The company didn't say anything about developing smart glasses for consumers, but The Information's previous report said that it's also working on a model for the general public slated to be released in late 2026 or early 2027. This article originally appeared on Engadget at https://www.engadget.com/wearables/amazons-smart-glasses-with-ai-will-help-its-drivers-deliver-packages-faster-041009681.html?src=rss",
          "feed_position": 41
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/what-enterprises-can-take-away-from-microsoft-ceo-satya-nadellas-shareholder",
          "published_at": "Thu, 23 Oct 2025 01:34:00 GMT",
          "title": "What enterprises can take away from Microsoft CEO Satya Nadella's shareholder letter",
          "standfirst": "One of the leading architects of the current generative AI boom — Microsoft CEO Satya Nadella, famed for having the software giant take an early investment in OpenAI (and later saying he was \"good for my $80 billion\") — published his latest annual letter yesterday on LinkedIn (a Microsoft subsidiary), and it&#x27;s chock full of interesting ideas about the near-term future that enterprise technical decision makers would do well to pay attention to, as it could aid in their own planning and tech stack development.In a companion post on X, Nadella wrote, “AI is radically changing every layer of the tech stack, and we’re changing with it.\" The full letter reinforces that message: Microsoft sees itself not just participating in the AI revolution, but shaping its infrastructure, security, tooling and governance for decades to come.While the message is addressed to Microsoft shareholders, the implications reach much further. The letter is a strategic signal to enterprise engineering leaders: CIOs, CTOs, AI leads, platform architects and security directors. Nadella outlines the direction of Microsoft’s innovation, but also what it expects from its customers and partners. The AI era is here, but it will be built by those who combine technical vision with operational discipline.Below are the five most important takeaways for enterprise technical decision makers.1. Security and reliability are now the foundation of the AI stackNadella makes security the first priority in the letter and ties it directly to Microsoft’s relevance going forward. Through its Secure Future Initiative (SFI), Microsoft has assigned the equivalent of 34,000 engineers to secure its identity systems, networks and software supply chain. Its Quality Excellence Initiative (QEI) aims to increase platform resiliency and strengthen global service uptime.Microsoft’s positioning makes it clear that enterprises will no longer get away with “ship fast, harden later” AI deployments. Nadella calls security “non-negotiable,” signaling that AI infrastructure must now meet the standards of mission-critical software. That means identity-first architecture, zero-trust execution environments and change management discipline are now table stakes for enterprise AI.2. AI infrastructure strategy is hybrid, open and sovereignty-readyNadella commits Microsoft to building “planet-scale systems” and backs that up with numbers: more than 400 Azure datacenters across 70 regions, two gigawatts of new compute capacity added this year, and new liquid-cooled GPU clusters rolling out across Azure. Microsoft also introduced Fairwater, a massive new AI datacenter in Wisconsin positioned to deliver unprecedented scale. Just as important, Microsoft is now officially multi-model. Azure AI Foundry offers access to more than 11,000 models including OpenAI, Meta, Mistral, Cohere and xAI. Microsoft is no longer pushing a single-model future, but a hybrid AI strategy.Enterprises should interpret this as validation of “portfolio architectures,” where closed, open and domain-specific models coexist. Nadella also emphasizes growing investment in sovereign cloud offerings for regulated industries, previewing a world where AI systems will have to meet regional data residency and compliance requirements from day one.3. AI agents—not just chatbots—are now Microsoft’s futureThe AI shift inside Microsoft is no longer about copilots that answer questions. It is now about AI agents that perform work. Nadella points to the rollout of Agent Mode in Microsoft 365 Copilot, which turns natural language requests into multistep business workflows. GitHub Copilot evolves from code autocomplete into a “peer programmer” capable of executing tasks asynchronously. In security operations, Microsoft has deployed AI agents that autonomously respond to incidents. In healthcare, Copilot for Dragon Medical documents clinical encounters automatically.This represents a major architectural pivot. Enterprises will need to move beyond prompt-response interfaces and begin engineering agent ecosystems that safely take actions inside business systems. That requires workflow orchestration, API integration strategies and strong guardrails. Nadella’s letter frames this as the next software platform shift.4. Unified data platforms are required to unlock AI valueNadella devotes significant attention to Microsoft Fabric and OneLake, calling Fabric the company’s fastest-growing data and analytics product ever. Fabric promises to centralize enterprise data from multiple cloud and analytics environments. OneLake provides a universal storage layer that binds analytics and AI workloads together.Microsoft’s message is blunt: siloed data means stalled AI. Enterprise teams that want AI at scale must unify operational and analytical data into a single architecture, enforce consistent data contracts and standardize metadata governance. AI success is now a data engineering problem more than a model problem.5. Trust, compliance and responsible AI are now mandatory for deployment“People want technology they can trust,” Nadella writes. Microsoft now publishes Responsible AI Transparency Reports and aligns parts of its development process with UN human rights guidance. Microsoft is also committing to digital resilience in Europe and proactive safeguards against misuse of AI-generated content.This shifts responsible AI out of the realm of corporate messaging and into engineering practice. Enterprises will need model documentation, reproducibility practices, audit trails, risk monitoring and human-in-the-loop checkpoints. Nadella signals that compliance will become integrated with product delivery—not an afterthought layered on top.The real meaning of Microsoft’s AI strategyTaken together, these five pillars send a clear message to enterprise leaders: AI maturity is no longer about building prototypes or proving use cases. System-level readiness now defines success. Nadella frames Microsoft’s mission as helping customers “think in decades and execute in quarters,” and that is more than corporate poetry. It is a call to build AI platforms engineered for longevity.The companies that win in enterprise AI will be the ones that invest early in secure cloud foundations, unify their data architectures, enable agent-based workflows and embrace responsible AI as a prerequisite for scale—not a press release. Nadella is betting that the next industrial transformation will be powered by AI infrastructure, not AI demos. With this letter, he has made Microsoft’s ambition clear: to become the platform on which that transformation is built.",
          "content": "One of the leading architects of the current generative AI boom — Microsoft CEO Satya Nadella, famed for having the software giant take an early investment in OpenAI (and later saying he was \"good for my $80 billion\") — published his latest annual letter yesterday on LinkedIn (a Microsoft subsidiary), and it&#x27;s chock full of interesting ideas about the near-term future that enterprise technical decision makers would do well to pay attention to, as it could aid in their own planning and tech stack development.In a companion post on X, Nadella wrote, “AI is radically changing every layer of the tech stack, and we’re changing with it.\" The full letter reinforces that message: Microsoft sees itself not just participating in the AI revolution, but shaping its infrastructure, security, tooling and governance for decades to come.While the message is addressed to Microsoft shareholders, the implications reach much further. The letter is a strategic signal to enterprise engineering leaders: CIOs, CTOs, AI leads, platform architects and security directors. Nadella outlines the direction of Microsoft’s innovation, but also what it expects from its customers and partners. The AI era is here, but it will be built by those who combine technical vision with operational discipline.Below are the five most important takeaways for enterprise technical decision makers.1. Security and reliability are now the foundation of the AI stackNadella makes security the first priority in the letter and ties it directly to Microsoft’s relevance going forward. Through its Secure Future Initiative (SFI), Microsoft has assigned the equivalent of 34,000 engineers to secure its identity systems, networks and software supply chain. Its Quality Excellence Initiative (QEI) aims to increase platform resiliency and strengthen global service uptime.Microsoft’s positioning makes it clear that enterprises will no longer get away with “ship fast, harden later” AI deployments. Nadella calls security “non-negotiable,” signaling that AI infrastructure must now meet the standards of mission-critical software. That means identity-first architecture, zero-trust execution environments and change management discipline are now table stakes for enterprise AI.2. AI infrastructure strategy is hybrid, open and sovereignty-readyNadella commits Microsoft to building “planet-scale systems” and backs that up with numbers: more than 400 Azure datacenters across 70 regions, two gigawatts of new compute capacity added this year, and new liquid-cooled GPU clusters rolling out across Azure. Microsoft also introduced Fairwater, a massive new AI datacenter in Wisconsin positioned to deliver unprecedented scale. Just as important, Microsoft is now officially multi-model. Azure AI Foundry offers access to more than 11,000 models including OpenAI, Meta, Mistral, Cohere and xAI. Microsoft is no longer pushing a single-model future, but a hybrid AI strategy.Enterprises should interpret this as validation of “portfolio architectures,” where closed, open and domain-specific models coexist. Nadella also emphasizes growing investment in sovereign cloud offerings for regulated industries, previewing a world where AI systems will have to meet regional data residency and compliance requirements from day one.3. AI agents—not just chatbots—are now Microsoft’s futureThe AI shift inside Microsoft is no longer about copilots that answer questions. It is now about AI agents that perform work. Nadella points to the rollout of Agent Mode in Microsoft 365 Copilot, which turns natural language requests into multistep business workflows. GitHub Copilot evolves from code autocomplete into a “peer programmer” capable of executing tasks asynchronously. In security operations, Microsoft has deployed AI agents that autonomously respond to incidents. In healthcare, Copilot for Dragon Medical documents clinical encounters automatically.This represents a major architectural pivot. Enterprises will need to move beyond prompt-response interfaces and begin engineering agent ecosystems that safely take actions inside business systems. That requires workflow orchestration, API integration strategies and strong guardrails. Nadella’s letter frames this as the next software platform shift.4. Unified data platforms are required to unlock AI valueNadella devotes significant attention to Microsoft Fabric and OneLake, calling Fabric the company’s fastest-growing data and analytics product ever. Fabric promises to centralize enterprise data from multiple cloud and analytics environments. OneLake provides a universal storage layer that binds analytics and AI workloads together.Microsoft’s message is blunt: siloed data means stalled AI. Enterprise teams that want AI at scale must unify operational and analytical data into a single architecture, enforce consistent data contracts and standardize metadata governance. AI success is now a data engineering problem more than a model problem.5. Trust, compliance and responsible AI are now mandatory for deployment“People want technology they can trust,” Nadella writes. Microsoft now publishes Responsible AI Transparency Reports and aligns parts of its development process with UN human rights guidance. Microsoft is also committing to digital resilience in Europe and proactive safeguards against misuse of AI-generated content.This shifts responsible AI out of the realm of corporate messaging and into engineering practice. Enterprises will need model documentation, reproducibility practices, audit trails, risk monitoring and human-in-the-loop checkpoints. Nadella signals that compliance will become integrated with product delivery—not an afterthought layered on top.The real meaning of Microsoft’s AI strategyTaken together, these five pillars send a clear message to enterprise leaders: AI maturity is no longer about building prototypes or proving use cases. System-level readiness now defines success. Nadella frames Microsoft’s mission as helping customers “think in decades and execute in quarters,” and that is more than corporate poetry. It is a call to build AI platforms engineered for longevity.The companies that win in enterprise AI will be the ones that invest early in secure cloud foundations, unify their data architectures, enable agent-based workflows and embrace responsible AI as a prerequisite for scale—not a press release. Nadella is betting that the next industrial transformation will be powered by AI infrastructure, not AI demos. With this letter, he has made Microsoft’s ambition clear: to become the platform on which that transformation is built.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/QSvQwRJMpyn4Xku8ZnAyk/dd36ccdb1258c23fd9dbabf947ba7cd4/cfr0z3n_httpss.mj.runM4mKVYlCu30_Cut_and_paste_collage_style_ph_780082c3-eb52-4012-ad6c-016de100662a__1_.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/the-first-e-bike-from-rivian-spinoff-also-has-a-virtual-drivetrain-173000250.html",
          "published_at": "Wed, 22 Oct 2025 21:29:41 +0000",
          "title": "The first e-bike from Rivian spinoff Also has a virtual drivetrain",
          "standfirst": "Ever since Rivian spun off its \"micromobility business\" into a standalone startup called Also earlier this year, there's been much speculation about what kind of vehicles the company is working on. Now, Also is showing off its first products: a lineup of e-bikes and two pedal-assisted electric quads. The TM-B e-bike is Also's attempt at a do-it-all e-bike that can adapt to different use cases whether that's daily commuting, trail riding or kid and cargo-hauling. It sports a modular frame that can also accommodate a bench seat or rear cargo rack that supports up to 35KG of weight. The different seats can be easily swapped out without extra tools. Instead, a button on the bike’s touchscreen display controls a latching mechanism that releases the seat. It only comes in one frame size, but Also says it should be able to adapt to \"multiple body sizes,” thanks to different seat sizes and styles. The bench seat for the TM-B.Karissa Bell for EngadgetThe removable USB-C battery comes in two sizes: standard, which can power up to 60 miles of riding, and large, which maxes out at 100 miles of range. When you’re not riding, the batteries can also be used as a large external battery pack.In terms of power, the TM-B’s throttle tops out at 20MPH though the bike can reach speeds up to 28MPH with added pedaling. Also is taking an interesting approach to its drive system, with a setup it's labeled \"DreamRide.\" Instead of a mechanical connection between the bike's rear wheel and the pedals, the TM-B uses \"software-defined pedaling,\" In practice, this means that you pedaling is actually feeding the generator that powers the bike’s battery rather than directly pushing you forward. However, an Also rep told me that there is also a “limp mode” for when the bike runs out of juice so riders won’t get stranded. In those situations, pedaling will give the bike enough juice to hopefully get you to a spot where you can recharge.Also has envisioned the TM-B in a lot of scenarios, many of which involve hauling a lot of cargo.Karissa Bell for EngadgetSoftware-controlled pedaling probably won’t appeal to purists, but Also says it enables a much more customizable riding experience. When in auto mode, the bike will adapt to the speed you’re pedaling, though you can push on the throttle to get a boost. There’s also a manual mode that lets you select a “gear” (these are also software-controlled). It also uses regenerative braking, so tapping on the brakes helps recharge the battery. Though in my short test ride I found that I didn’t need to use the brakes much, because when I stopped pedaling the bike slowed down pretty quickly, kind of like taking your foot off the accelerator in an EV.The Also app and Portal display.AlsoGiven the bike's roots at Rivian, it's not surprising that there are also a bunch of other tech-enabled features, including a 5-inch touchscreen display, called \"Portal,\" that supports navigation, music playback and calling features via an accompanying app. There’s also a built-in security system that automatically locks the frame and rear wheel when you walk away. On the handlebars, there are customizable controls that can be used to adjust the volume and music playback, answer calls or navigate through display. Customizable controls on the left side fo the handlebar and a throttle on the right.Karissa Bell for EngadgetAlso is selling the TM-B in three configurations. The first to ship next spring will be the $4,500 TM-B Limited Launch Edition, which has a range up to 100 miles, support for standard and sport ride modes and features transparent purple accents. The $4,500 TM-B Performance has the same features as the limited edition model, but has a slightly different color scheme, and will be available within the \"first half\" of 2026. Finally, there's a base-level TM-B model with a range of up to 60 miles that only comes with standard ride modes. Also hasn't announced an exact price, but says it will cost less than $4,000 when it ships \"later in 2026.\" Pre-orders for the Launch Edition are open now and the other two bikes are available to reserve with a $50 deposit. The bikes will also be on display in Rivian showrooms later this year,Also's quad for commercial uses cases (left) and a smaller quad for families (right).AlsoThe company also previewed two electric, pedal-assisted quads it's calling TM-Q. The smaller quad is apparently meant for \"families and individuals seeking a safe, compact alternative to cars\" that can still haul “significant loads.” The larger TM-Q, on the other hand, is meant for commercial deliveries. Also has partnered with Amazon to develop fleets of such vehicles that can be used by delivery drivers. Both quads are intended to be used in bike lanes, according to Also. Also will partner with Amazon for a Prime-branded TM-Q.Karissa Bell for EngadgetThe company didn't share details about when these vehicles might be available or how much they'll cost. Update, October 22, 2025, 2:29PM PT: Added more details and photos from Also’s launch event.This article originally appeared on Engadget at https://www.engadget.com/transportation/the-first-e-bike-from-rivian-spinoff-also-has-a-virtual-drivetrain-173000250.html?src=rss",
          "content": "Ever since Rivian spun off its \"micromobility business\" into a standalone startup called Also earlier this year, there's been much speculation about what kind of vehicles the company is working on. Now, Also is showing off its first products: a lineup of e-bikes and two pedal-assisted electric quads. The TM-B e-bike is Also's attempt at a do-it-all e-bike that can adapt to different use cases whether that's daily commuting, trail riding or kid and cargo-hauling. It sports a modular frame that can also accommodate a bench seat or rear cargo rack that supports up to 35KG of weight. The different seats can be easily swapped out without extra tools. Instead, a button on the bike’s touchscreen display controls a latching mechanism that releases the seat. It only comes in one frame size, but Also says it should be able to adapt to \"multiple body sizes,” thanks to different seat sizes and styles. The bench seat for the TM-B.Karissa Bell for EngadgetThe removable USB-C battery comes in two sizes: standard, which can power up to 60 miles of riding, and large, which maxes out at 100 miles of range. When you’re not riding, the batteries can also be used as a large external battery pack.In terms of power, the TM-B’s throttle tops out at 20MPH though the bike can reach speeds up to 28MPH with added pedaling. Also is taking an interesting approach to its drive system, with a setup it's labeled \"DreamRide.\" Instead of a mechanical connection between the bike's rear wheel and the pedals, the TM-B uses \"software-defined pedaling,\" In practice, this means that you pedaling is actually feeding the generator that powers the bike’s battery rather than directly pushing you forward. However, an Also rep told me that there is also a “limp mode” for when the bike runs out of juice so riders won’t get stranded. In those situations, pedaling will give the bike enough juice to hopefully get you to a spot where you can recharge.Also has envisioned the TM-B in a lot of scenarios, many of which involve hauling a lot of cargo.Karissa Bell for EngadgetSoftware-controlled pedaling probably won’t appeal to purists, but Also says it enables a much more customizable riding experience. When in auto mode, the bike will adapt to the speed you’re pedaling, though you can push on the throttle to get a boost. There’s also a manual mode that lets you select a “gear” (these are also software-controlled). It also uses regenerative braking, so tapping on the brakes helps recharge the battery. Though in my short test ride I found that I didn’t need to use the brakes much, because when I stopped pedaling the bike slowed down pretty quickly, kind of like taking your foot off the accelerator in an EV.The Also app and Portal display.AlsoGiven the bike's roots at Rivian, it's not surprising that there are also a bunch of other tech-enabled features, including a 5-inch touchscreen display, called \"Portal,\" that supports navigation, music playback and calling features via an accompanying app. There’s also a built-in security system that automatically locks the frame and rear wheel when you walk away. On the handlebars, there are customizable controls that can be used to adjust the volume and music playback, answer calls or navigate through display. Customizable controls on the left side fo the handlebar and a throttle on the right.Karissa Bell for EngadgetAlso is selling the TM-B in three configurations. The first to ship next spring will be the $4,500 TM-B Limited Launch Edition, which has a range up to 100 miles, support for standard and sport ride modes and features transparent purple accents. The $4,500 TM-B Performance has the same features as the limited edition model, but has a slightly different color scheme, and will be available within the \"first half\" of 2026. Finally, there's a base-level TM-B model with a range of up to 60 miles that only comes with standard ride modes. Also hasn't announced an exact price, but says it will cost less than $4,000 when it ships \"later in 2026.\" Pre-orders for the Launch Edition are open now and the other two bikes are available to reserve with a $50 deposit. The bikes will also be on display in Rivian showrooms later this year,Also's quad for commercial uses cases (left) and a smaller quad for families (right).AlsoThe company also previewed two electric, pedal-assisted quads it's calling TM-Q. The smaller quad is apparently meant for \"families and individuals seeking a safe, compact alternative to cars\" that can still haul “significant loads.” The larger TM-Q, on the other hand, is meant for commercial deliveries. Also has partnered with Amazon to develop fleets of such vehicles that can be used by delivery drivers. Both quads are intended to be used in bike lanes, according to Also. Also will partner with Amazon for a Prime-branded TM-Q.Karissa Bell for EngadgetThe company didn't share details about when these vehicles might be available or how much they'll cost. Update, October 22, 2025, 2:29PM PT: Added more details and photos from Also’s launch event.This article originally appeared on Engadget at https://www.engadget.com/transportation/the-first-e-bike-from-rivian-spinoff-also-has-a-virtual-drivetrain-173000250.html?src=rss",
          "feed_position": 42,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/tmb_seat_swap.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/google-gemini-will-arrive-in-gm-cars-starting-next-year-181249237.html",
          "published_at": "Wed, 22 Oct 2025 18:12:50 +0000",
          "title": "Google Gemini will arrive in GM cars starting next year",
          "standfirst": "Google Gemini is coming to GM vehicles in 2026. The company will be integrating a conversational AI assistant powered by Google's platform into many of its cars, trucks and SUVs. GM says this assistant will be able to access vehicle data to suss out maintenance concerns, alerting the driver when necessary. The company also promises it'll be able to help plan routes and explain various features of the car. It should also be able to do stuff like turn on the heat or air conditioning, even before entering the vehicle. This will replace the \"Google built-in\" operating system that already exists in many GM vehicles. This OS already offers access to stuff like Google Maps, Google Assistant and related apps. The upcoming Gemini-based chat assistant will do the same type of things, but it should perform better. “One of the challenges with current voice assistants is that, if you’ve used the, you’ve probably also been frustrated by them because they’re trained on certain code words or they don’t understand accents very well or if you don’t say it quite right, you don’t get the right response,” GM VP Dave Richardson told TechCrunch. “What’s great about large language models is they don’t seem to be affected by that.\" One brand-new feature that Gemini will bring to the table is web integration. This will let drivers ask the chatbot questions pertaining to geographic location and the like. GM gives an example of someone asking about the history of a bridge they are passing over. The Gemini assistant will be available via the Play Store after launch as an over-the-air upgrade to Onstar-equipped vehicles. It won't be limited to newer releases, as GM says it'll work with vehicles from the model year 2015 and above. The company also says it's working on its own AI chatbot that has been \"custom-built for your vehicle.\" There's no timetable on that one. GM ran into hot water recently when it was found that it had been selling some customer information sourced from its OnStar Smart Driver program to insurance companies without user consent. This led to the FTC banning the company from selling any driver data for five years. Richardson says the Gemini integration will be privacy-focused and the software will let drivers control what information it can access and use. GM The company made these announcements at the GM Forward media event, where it also discussed other forthcoming initiatives. It has scheduled a rollout of its self-driving platform for 2028. It's also developing its own computing platform, also launching in 2028. This does mean that GM will be sunsetting integration with Apple CarPlay and Android Auto. This software will be phased out over the next few years. This article originally appeared on Engadget at https://www.engadget.com/transportation/google-gemini-will-arrive-in-gm-cars-starting-next-year-181249237.html?src=rss",
          "content": "Google Gemini is coming to GM vehicles in 2026. The company will be integrating a conversational AI assistant powered by Google's platform into many of its cars, trucks and SUVs. GM says this assistant will be able to access vehicle data to suss out maintenance concerns, alerting the driver when necessary. The company also promises it'll be able to help plan routes and explain various features of the car. It should also be able to do stuff like turn on the heat or air conditioning, even before entering the vehicle. This will replace the \"Google built-in\" operating system that already exists in many GM vehicles. This OS already offers access to stuff like Google Maps, Google Assistant and related apps. The upcoming Gemini-based chat assistant will do the same type of things, but it should perform better. “One of the challenges with current voice assistants is that, if you’ve used the, you’ve probably also been frustrated by them because they’re trained on certain code words or they don’t understand accents very well or if you don’t say it quite right, you don’t get the right response,” GM VP Dave Richardson told TechCrunch. “What’s great about large language models is they don’t seem to be affected by that.\" One brand-new feature that Gemini will bring to the table is web integration. This will let drivers ask the chatbot questions pertaining to geographic location and the like. GM gives an example of someone asking about the history of a bridge they are passing over. The Gemini assistant will be available via the Play Store after launch as an over-the-air upgrade to Onstar-equipped vehicles. It won't be limited to newer releases, as GM says it'll work with vehicles from the model year 2015 and above. The company also says it's working on its own AI chatbot that has been \"custom-built for your vehicle.\" There's no timetable on that one. GM ran into hot water recently when it was found that it had been selling some customer information sourced from its OnStar Smart Driver program to insurance companies without user consent. This led to the FTC banning the company from selling any driver data for five years. Richardson says the Gemini integration will be privacy-focused and the software will let drivers control what information it can access and use. GM The company made these announcements at the GM Forward media event, where it also discussed other forthcoming initiatives. It has scheduled a rollout of its self-driving platform for 2028. It's also developing its own computing platform, also launching in 2028. This does mean that GM will be sunsetting integration with Apple CarPlay and Android Auto. This software will be phased out over the next few years. This article originally appeared on Engadget at https://www.engadget.com/transportation/google-gemini-will-arrive-in-gm-cars-starting-next-year-181249237.html?src=rss",
          "feed_position": 47,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/adf23380-af6e-11f0-975e-b59d7cbc084f"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-vpn-deals-120056041.html",
          "published_at": "Wed, 22 Oct 2025 17:34:34 +0000",
          "title": "The best VPN deals: Get up to 88 percent off ProtonVPN, ExpressVPN, Surfshark and more",
          "standfirst": "A virtual private network (VPN) is useful in lots of ways every day, whether you're streaming foreign TV shows or keeping yourself anonymous online so advertisers can't track you. But while we strongly recommend using a VPN, it pays to do some research before investing in one — pricing can be opaque for these services, and you can't always trust how the providers portray their best deals. Even so, there are genuinely great deals to be had. VPN providers love to give out deep discounts to anybody willing to sign up for a year or more at once. This means you've got to pay out more upfront, but if you divide the cost by the months of service, you're actually paying less per month over time. With deals like this, VPN providers boost their subscriber numbers, and you get heavy price cuts on some of our favorite services. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-vpn-deals-120056041.html?src=rss",
          "content": "A virtual private network (VPN) is useful in lots of ways every day, whether you're streaming foreign TV shows or keeping yourself anonymous online so advertisers can't track you. But while we strongly recommend using a VPN, it pays to do some research before investing in one — pricing can be opaque for these services, and you can't always trust how the providers portray their best deals. Even so, there are genuinely great deals to be had. VPN providers love to give out deep discounts to anybody willing to sign up for a year or more at once. This means you've got to pay out more upfront, but if you divide the cost by the months of service, you're actually paying less per month over time. With deals like this, VPN providers boost their subscriber numbers, and you get heavy price cuts on some of our favorite services. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-vpn-deals-120056041.html?src=rss",
          "feed_position": 48
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/kai-fu-lees-brutal-assessment-america-is-already-losing-the-ai-hardware-war",
          "published_at": "Wed, 22 Oct 2025 12:30:00 GMT",
          "title": "Kai-Fu Lee's brutal assessment: America is already losing the AI hardware war to China",
          "standfirst": "China is on track to dominate consumer artificial intelligence applications and robotics manufacturing within years, but the United States will maintain its substantial lead in enterprise AI adoption and cutting-edge research, according to Kai-Fu Lee, one of the world&#x27;s most prominent AI scientists and investors.In a rare, unvarnished assessment delivered via video link from Beijing to the TED AI conference in San Francisco Tuesday, Lee — a former executive at Apple, Microsoft, and Google who now runs both a major venture capital firm and his own AI company — laid out a technology landscape splitting along geographic and economic lines, with profound implications for both commercial competition and national security.\"China&#x27;s robotics has the advantage of having integrated AI into much lower costs, better supply chain and fast turnaround, so companies like Unitree are actually the farthest ahead in the world in terms of building affordable, embodied humanoid AI,\" Lee said, referring to a Chinese robotics manufacturer that has undercut Western competitors on price while advancing capabilities.The comments, made to a room filled with Silicon Valley executives, investors, and researchers, represented one of the most detailed public assessments from Lee about the comparative strengths and weaknesses of the world&#x27;s two AI superpowers — and suggested that the race for artificial intelligence leadership is becoming less a single contest than a series of parallel competitions with different winners.Why venture capital is flowing in opposite directions in the U.S. and ChinaAt the heart of Lee&#x27;s analysis lies a fundamental difference in how capital flows in the two countries&#x27; innovation ecosystems. American venture capitalists, Lee said, are pouring money into generative AI companies building large language models and enterprise software, while Chinese investors are betting heavily on robotics and hardware.\"The VCs in the US don&#x27;t fund robotics the way the VCs do in China,\" Lee said. \"Just like the VCs in China don&#x27;t fund generative AI the way the VCs do in the US.\"This investment divergence reflects different economic incentives and market structures. In the United States, where companies have grown accustomed to paying for software subscriptions and where labor costs are high, enterprise AI tools that boost white-collar productivity command premium prices. In China, where software subscription models have historically struggled to gain traction but manufacturing dominates the economy, robotics offers a clearer path to commercialization.The result, Lee suggested, is that each country is pulling ahead in different domains — and may continue to do so.\"China&#x27;s got some challenges to overcome in getting a company funded as well as OpenAI or Anthropic,\" Lee acknowledged, referring to the leading American AI labs. \"But I think U.S., on the flip side, will have trouble developing the investment interest and value creation in the robotics\" sector.Why American companies dominate enterprise AI while Chinese firms struggle with subscriptionsLee was explicit about one area where the United States maintains what appears to be a durable advantage: getting businesses to actually adopt and pay for AI software.\"The enterprise adoption will clearly be led by the United States,\" Lee said. \"The Chinese companies have not yet developed a habit of paying for software on a subscription.\"This seemingly mundane difference in business culture — whether companies will pay monthly fees for software — has become a critical factor in the AI race. The explosion of spending on tools like GitHub Copilot, ChatGPT Enterprise, and other AI-powered productivity software has fueled American companies&#x27; ability to invest billions in further research and development.Lee noted that China has historically overcome similar challenges in consumer technology by developing alternative business models. \"In the early days of internet software, China was also well behind because people weren&#x27;t willing to pay for software,\" he said. \"But then advertising models, e-commerce models really propelled China forward.\"Still, he suggested, someone will need to \"find a new business model that isn&#x27;t just pay per software per use or per month basis. That&#x27;s going to not happen in China anytime soon.\"The implication: American companies building enterprise AI tools have a window — perhaps a substantial one — where they can generate revenue and reinvest in R&D without facing serious Chinese competition in their core market.How ByteDance, Alibaba and Tencent will outpace Meta and Google in consumer AIWhere Lee sees China pulling ahead decisively is in consumer-facing AI applications — the kind embedded in social media, e-commerce, and entertainment platforms that billions of people use daily.\"In terms of consumer usage, that&#x27;s likely to happen,\" Lee said, referring to China matching or surpassing the United States in AI deployment. \"The Chinese giants, like ByteDance and Alibaba and Tencent, will definitely move a lot faster than their equivalent in the United States, companies like Meta, YouTube and so on.\"Lee pointed to a cultural advantage: Chinese technology companies have spent the past decade obsessively optimizing for user engagement and product-market fit in brutally competitive markets. \"The Chinese giants really work tenaciously, and they have mastered the art of figuring out product market fit,\" he said. \"Now they have to add technology to it. So that is inevitably going to happen.\"This assessment aligns with recent industry observations. ByteDance&#x27;s TikTok became the world&#x27;s most downloaded app through sophisticated AI-driven content recommendation, and Chinese companies have pioneered AI-powered features in areas like live-streaming commerce and short-form video that Western companies later copied.Lee also noted that China has already deployed AI more widely in certain domains. \"There are a lot of areas where China has also done a great job, such as using computer vision, speech recognition, and translation more widely,\" he said.The surprising open-source shift that has Chinese models beating Meta&#x27;s LlamaPerhaps Lee&#x27;s most striking data point concerned open-source AI development — an area where China appears to have seized leadership from American companies in a remarkably short time.\"The 10 highest rated open source [models] are from China,\" Lee said. \"These companies have now eclipsed Meta&#x27;s Llama, which used to be number one.\"This represents a significant shift. Meta&#x27;s Llama models were widely viewed as the gold standard for open-source large language models as recently as early 2024. But Chinese companies — including Lee&#x27;s own firm, 01.AI, along with Alibaba, Baidu, and others — have released a flood of open-source models that, according to various benchmarks, now outperform their American counterparts.The open-source question has become a flashpoint in AI development. Lee made an extensive case for why open-source models will prove essential to the technology&#x27;s future, even as closed models from companies like OpenAI command higher prices and, often, superior performance.\"I think open source has a number of major advantages,\" Lee argued. With open-source models, \"you can examine it, tune it, improve it. It&#x27;s yours, and it&#x27;s free, and it&#x27;s important for building if you want to build an application or tune the model to do something specific.\"He drew an analogy to operating systems: \"People who work in operating systems loved Linux, and that&#x27;s why its adoption went through the roof. And I think in the future, open source will also allow people to tune a sovereign model for a country, make it work better for a particular language.\"Still, Lee predicted both approaches will coexist. \"I don&#x27;t think open source models will win,\" he said. \"I think just like we have Apple, which is closed, but provides a somewhat better experience than Android... I think we&#x27;re going to see more apps using open-source models, more engineers wanting to build open-source models, but I think more money will remain in the closed model.\"Why China&#x27;s manufacturing advantage makes the robotics race &#x27;not over, but&#x27; nearly decidedOn robotics, Lee&#x27;s message was blunt: the combination of China&#x27;s manufacturing prowess, lower costs, and aggressive investment has created an advantage that will be difficult for American companies to overcome.When asked directly whether the robotics race was already over with China victorious, Lee hedged only slightly. \"It&#x27;s not over, but I think the U.S. is still capable of coming up with the best robotic research ideas,\" he said. \"But the VCs in the U.S. don&#x27;t fund robotics the way the VCs do in China.\"The challenge is structural. Building robots requires not just software and AI, but hardware manufacturing at scale — precisely the kind of integrated supply chain and low-cost production that China has spent decades perfecting. While American labs at universities and companies like Boston Dynamics continue to produce impressive research prototypes, turning those prototypes into affordable commercial products requires the manufacturing ecosystem that China possesses.Companies like Unitree have demonstrated this advantage concretely. The company&#x27;s humanoid robots and quadrupedal robots cost a fraction of their American-made equivalents while offering comparable or superior capabilities — a price-to-performance ratio that could prove decisive in commercial markets.What worries Lee most: not AGI, but the race itselfDespite his generally measured tone about China&#x27;s AI development, Lee expressed concern about one area where he believes the global AI community faces real danger — not the far-future risk of superintelligent AI, but the near-term consequences of moving too fast.When asked about AGI risks, Lee reframed the question. \"I&#x27;m less afraid of AI becoming self-aware and causing danger for humans in the short term,\" he said, \"but more worried about it being used by bad people to do terrible things, or by the AI race pushing people to work so hard, so fast and furious and move fast and break things that they build products that have problems and holes to be exploited.\"He continued: \"I&#x27;m very worried about that. In fact, I think some terrible event will happen that will be a wake up call from this sort of problem.\"Lee&#x27;s perspective carries unusual weight because of his unique vantage point spanning both Chinese and American AI development. Over a career spanning more than three decades, he has held senior positions at Apple, Microsoft, and Google, while also founding Sinovation Ventures, which has invested in more than 400 companies across both countries. His AI company, 01.AI, founded in 2023, has released several open-source models that rank among the most capable in the world.For American companies and policymakers, Lee&#x27;s analysis presents a complex strategic picture. The United States appears to have clear advantages in enterprise AI software, fundamental research, and computing infrastructure. But China is moving faster in consumer applications, manufacturing robotics at lower costs, and potentially pulling ahead in open-source model development.The bifurcation suggests that rather than a single \"winner\" in AI, the world may be heading toward a technology landscape where different countries excel in different domains — with all the economic and geopolitical complications that implies.As the TED AI conference continued Wednesday, Lee&#x27;s assessment hung over subsequent discussions. His message seemed clear: the AI race is not one contest, but many — and the United States and China are each winning different races.Standing in the conference hall afterward, one venture capitalist, who asked not to be named, summed up the mood in the room: \"We&#x27;re not competing with China anymore. We&#x27;re competing on parallel tracks.\" Whether those tracks eventually converge — or diverge into entirely separate technology ecosystems — may be the defining question of the next decade.",
          "content": "China is on track to dominate consumer artificial intelligence applications and robotics manufacturing within years, but the United States will maintain its substantial lead in enterprise AI adoption and cutting-edge research, according to Kai-Fu Lee, one of the world&#x27;s most prominent AI scientists and investors.In a rare, unvarnished assessment delivered via video link from Beijing to the TED AI conference in San Francisco Tuesday, Lee — a former executive at Apple, Microsoft, and Google who now runs both a major venture capital firm and his own AI company — laid out a technology landscape splitting along geographic and economic lines, with profound implications for both commercial competition and national security.\"China&#x27;s robotics has the advantage of having integrated AI into much lower costs, better supply chain and fast turnaround, so companies like Unitree are actually the farthest ahead in the world in terms of building affordable, embodied humanoid AI,\" Lee said, referring to a Chinese robotics manufacturer that has undercut Western competitors on price while advancing capabilities.The comments, made to a room filled with Silicon Valley executives, investors, and researchers, represented one of the most detailed public assessments from Lee about the comparative strengths and weaknesses of the world&#x27;s two AI superpowers — and suggested that the race for artificial intelligence leadership is becoming less a single contest than a series of parallel competitions with different winners.Why venture capital is flowing in opposite directions in the U.S. and ChinaAt the heart of Lee&#x27;s analysis lies a fundamental difference in how capital flows in the two countries&#x27; innovation ecosystems. American venture capitalists, Lee said, are pouring money into generative AI companies building large language models and enterprise software, while Chinese investors are betting heavily on robotics and hardware.\"The VCs in the US don&#x27;t fund robotics the way the VCs do in China,\" Lee said. \"Just like the VCs in China don&#x27;t fund generative AI the way the VCs do in the US.\"This investment divergence reflects different economic incentives and market structures. In the United States, where companies have grown accustomed to paying for software subscriptions and where labor costs are high, enterprise AI tools that boost white-collar productivity command premium prices. In China, where software subscription models have historically struggled to gain traction but manufacturing dominates the economy, robotics offers a clearer path to commercialization.The result, Lee suggested, is that each country is pulling ahead in different domains — and may continue to do so.\"China&#x27;s got some challenges to overcome in getting a company funded as well as OpenAI or Anthropic,\" Lee acknowledged, referring to the leading American AI labs. \"But I think U.S., on the flip side, will have trouble developing the investment interest and value creation in the robotics\" sector.Why American companies dominate enterprise AI while Chinese firms struggle with subscriptionsLee was explicit about one area where the United States maintains what appears to be a durable advantage: getting businesses to actually adopt and pay for AI software.\"The enterprise adoption will clearly be led by the United States,\" Lee said. \"The Chinese companies have not yet developed a habit of paying for software on a subscription.\"This seemingly mundane difference in business culture — whether companies will pay monthly fees for software — has become a critical factor in the AI race. The explosion of spending on tools like GitHub Copilot, ChatGPT Enterprise, and other AI-powered productivity software has fueled American companies&#x27; ability to invest billions in further research and development.Lee noted that China has historically overcome similar challenges in consumer technology by developing alternative business models. \"In the early days of internet software, China was also well behind because people weren&#x27;t willing to pay for software,\" he said. \"But then advertising models, e-commerce models really propelled China forward.\"Still, he suggested, someone will need to \"find a new business model that isn&#x27;t just pay per software per use or per month basis. That&#x27;s going to not happen in China anytime soon.\"The implication: American companies building enterprise AI tools have a window — perhaps a substantial one — where they can generate revenue and reinvest in R&D without facing serious Chinese competition in their core market.How ByteDance, Alibaba and Tencent will outpace Meta and Google in consumer AIWhere Lee sees China pulling ahead decisively is in consumer-facing AI applications — the kind embedded in social media, e-commerce, and entertainment platforms that billions of people use daily.\"In terms of consumer usage, that&#x27;s likely to happen,\" Lee said, referring to China matching or surpassing the United States in AI deployment. \"The Chinese giants, like ByteDance and Alibaba and Tencent, will definitely move a lot faster than their equivalent in the United States, companies like Meta, YouTube and so on.\"Lee pointed to a cultural advantage: Chinese technology companies have spent the past decade obsessively optimizing for user engagement and product-market fit in brutally competitive markets. \"The Chinese giants really work tenaciously, and they have mastered the art of figuring out product market fit,\" he said. \"Now they have to add technology to it. So that is inevitably going to happen.\"This assessment aligns with recent industry observations. ByteDance&#x27;s TikTok became the world&#x27;s most downloaded app through sophisticated AI-driven content recommendation, and Chinese companies have pioneered AI-powered features in areas like live-streaming commerce and short-form video that Western companies later copied.Lee also noted that China has already deployed AI more widely in certain domains. \"There are a lot of areas where China has also done a great job, such as using computer vision, speech recognition, and translation more widely,\" he said.The surprising open-source shift that has Chinese models beating Meta&#x27;s LlamaPerhaps Lee&#x27;s most striking data point concerned open-source AI development — an area where China appears to have seized leadership from American companies in a remarkably short time.\"The 10 highest rated open source [models] are from China,\" Lee said. \"These companies have now eclipsed Meta&#x27;s Llama, which used to be number one.\"This represents a significant shift. Meta&#x27;s Llama models were widely viewed as the gold standard for open-source large language models as recently as early 2024. But Chinese companies — including Lee&#x27;s own firm, 01.AI, along with Alibaba, Baidu, and others — have released a flood of open-source models that, according to various benchmarks, now outperform their American counterparts.The open-source question has become a flashpoint in AI development. Lee made an extensive case for why open-source models will prove essential to the technology&#x27;s future, even as closed models from companies like OpenAI command higher prices and, often, superior performance.\"I think open source has a number of major advantages,\" Lee argued. With open-source models, \"you can examine it, tune it, improve it. It&#x27;s yours, and it&#x27;s free, and it&#x27;s important for building if you want to build an application or tune the model to do something specific.\"He drew an analogy to operating systems: \"People who work in operating systems loved Linux, and that&#x27;s why its adoption went through the roof. And I think in the future, open source will also allow people to tune a sovereign model for a country, make it work better for a particular language.\"Still, Lee predicted both approaches will coexist. \"I don&#x27;t think open source models will win,\" he said. \"I think just like we have Apple, which is closed, but provides a somewhat better experience than Android... I think we&#x27;re going to see more apps using open-source models, more engineers wanting to build open-source models, but I think more money will remain in the closed model.\"Why China&#x27;s manufacturing advantage makes the robotics race &#x27;not over, but&#x27; nearly decidedOn robotics, Lee&#x27;s message was blunt: the combination of China&#x27;s manufacturing prowess, lower costs, and aggressive investment has created an advantage that will be difficult for American companies to overcome.When asked directly whether the robotics race was already over with China victorious, Lee hedged only slightly. \"It&#x27;s not over, but I think the U.S. is still capable of coming up with the best robotic research ideas,\" he said. \"But the VCs in the U.S. don&#x27;t fund robotics the way the VCs do in China.\"The challenge is structural. Building robots requires not just software and AI, but hardware manufacturing at scale — precisely the kind of integrated supply chain and low-cost production that China has spent decades perfecting. While American labs at universities and companies like Boston Dynamics continue to produce impressive research prototypes, turning those prototypes into affordable commercial products requires the manufacturing ecosystem that China possesses.Companies like Unitree have demonstrated this advantage concretely. The company&#x27;s humanoid robots and quadrupedal robots cost a fraction of their American-made equivalents while offering comparable or superior capabilities — a price-to-performance ratio that could prove decisive in commercial markets.What worries Lee most: not AGI, but the race itselfDespite his generally measured tone about China&#x27;s AI development, Lee expressed concern about one area where he believes the global AI community faces real danger — not the far-future risk of superintelligent AI, but the near-term consequences of moving too fast.When asked about AGI risks, Lee reframed the question. \"I&#x27;m less afraid of AI becoming self-aware and causing danger for humans in the short term,\" he said, \"but more worried about it being used by bad people to do terrible things, or by the AI race pushing people to work so hard, so fast and furious and move fast and break things that they build products that have problems and holes to be exploited.\"He continued: \"I&#x27;m very worried about that. In fact, I think some terrible event will happen that will be a wake up call from this sort of problem.\"Lee&#x27;s perspective carries unusual weight because of his unique vantage point spanning both Chinese and American AI development. Over a career spanning more than three decades, he has held senior positions at Apple, Microsoft, and Google, while also founding Sinovation Ventures, which has invested in more than 400 companies across both countries. His AI company, 01.AI, founded in 2023, has released several open-source models that rank among the most capable in the world.For American companies and policymakers, Lee&#x27;s analysis presents a complex strategic picture. The United States appears to have clear advantages in enterprise AI software, fundamental research, and computing infrastructure. But China is moving faster in consumer applications, manufacturing robotics at lower costs, and potentially pulling ahead in open-source model development.The bifurcation suggests that rather than a single \"winner\" in AI, the world may be heading toward a technology landscape where different countries excel in different domains — with all the economic and geopolitical complications that implies.As the TED AI conference continued Wednesday, Lee&#x27;s assessment hung over subsequent discussions. His message seemed clear: the AI race is not one contest, but many — and the United States and China are each winning different races.Standing in the conference hall afterward, one venture capitalist, who asked not to be named, summed up the mood in the room: \"We&#x27;re not competing with China anymore. We&#x27;re competing on parallel tracks.\" Whether those tracks eventually converge — or diverge into entirely separate technology ecosystems — may be the defining question of the next decade.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/ayDtsYfCFDVHHKnTvWKwk/04173bcfce3f9d53ecd9fe3ecfd14d5c/nuneybits_Vector_art_of_Chinese_flag-coded_AI_chip_6c9fcafc-8614-4d3b-858f-d64bede8c2df.webp?w=300&q=30"
        }
      ],
      "featured_image": "https://s.yimg.com/os/creatr-uploaded-images/2024-10/ded6eb30-8fee-11ef-bfcf-f1599e27e076",
      "popularity_score": 2019.6902213888889,
      "ai_summary": [
        "The article provides guidance on selecting the best iPad model.",
        "It considers various user needs, such as streaming and productivity.",
        "The review includes testing of different iPad models available.",
        "Testing involves performance benchmarks and display comparisons.",
        "Battery life and speaker performance are also evaluated in testing."
      ]
    },
    {
      "id": "cluster_31",
      "coverage": 2,
      "updated_at": "Thu, 23 Oct 2025 21:04:00 +0000",
      "title": "Trump credits Benioff, Huang for decision not to ‘surge’ Fed troops into San Francisco",
      "neutral_headline": "Trump Credits Benioff, Huang for Decision Not to ‘Surge’ Fed Troops into San Francisco",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/23/trump-credits-benioff-huang-for-decision-not-to-surge-fed-troops-into-san-francisco/",
          "published_at": "Thu, 23 Oct 2025 21:04:00 +0000",
          "title": "Trump credits Benioff, Huang for decision not to ‘surge’ Fed troops into San Francisco",
          "standfirst": "Trump said he scrapped plans to send the National Guard into San Francisco after calls from Nvidia’s Jensen Huang and Salesforce’s Marc Benioff. Mayor Daniel Lurie confirmed the plan was canceled.",
          "content": "Trump said he scrapped plans to send the National Guard into San Francisco after calls from Nvidia’s Jensen Huang and Salesforce’s Marc Benioff. Mayor Daniel Lurie confirmed the plan was canceled.",
          "feed_position": 3
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251023/p44#a251023p44",
          "published_at": "Thu, 23 Oct 2025 16:10:04 -0400",
          "title": "Trump says he canceled plans for a \"surge\" of National Guard to San Francisco after speaking to \"great people like Jensen Huang, Marc Benioff, and others\" (Kate Rogers/CNBC)",
          "standfirst": "Kate Rogers / CNBC: Trump says he canceled plans for a &ldquo;surge&rdquo; of National Guard to San Francisco after speaking to &ldquo;great people like Jensen Huang, Marc Benioff, and others&rdquo; &mdash; President Donald Trump said in a post on Thursday that the federal government was preparing to &ldquo;surge&rdquo; &hellip;",
          "content": "Kate Rogers / CNBC: Trump says he canceled plans for a &ldquo;surge&rdquo; of National Guard to San Francisco after speaking to &ldquo;great people like Jensen Huang, Marc Benioff, and others&rdquo; &mdash; President Donald Trump said in a post on Thursday that the federal government was preparing to &ldquo;surge&rdquo; &hellip;",
          "feed_position": 13,
          "image_url": "http://www.techmeme.com/251023/i44.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/251023/i44.jpg",
      "popularity_score": 2009.7466102777778,
      "ai_summary": [
        "Trump stated he canceled plans to send National Guard to San Francisco.",
        "The decision followed calls from Jensen Huang and Marc Benioff.",
        "Mayor Daniel Lurie confirmed the plan's cancellation.",
        "Trump made the announcement in a post on Thursday.",
        "The federal government was preparing to \"surge\" troops."
      ]
    },
    {
      "id": "cluster_63",
      "coverage": 2,
      "updated_at": "Thu, 23 Oct 2025 18:05:37 +0000",
      "title": "‘War on Crypto Is Over’: Donald Trump Pardons Binance Founder CZ",
      "neutral_headline": "Trump pardons Binance founder Changpeng Zhao",
      "items": [
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/trump-pardons-cz-binance/",
          "published_at": "Thu, 23 Oct 2025 18:05:37 +0000",
          "title": "‘War on Crypto Is Over’: Donald Trump Pardons Binance Founder CZ",
          "standfirst": "After serving a federal prison sentence for violating anti-money-laundering laws and US sanctions, former crypto exchange CEO Changpeng Zhao has been pardoned by US president Donald Trump.",
          "content": "After serving a federal prison sentence for violating anti-money-laundering laws and US sanctions, former crypto exchange CEO Changpeng Zhao has been pardoned by US president Donald Trump.",
          "feed_position": 5,
          "image_url": "https://media.wired.com/photos/68fa4fd3c5809c60f31dd079/master/pass/Trump-Pardon-Binance-CEO-Business-2210816860.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/23/trump-pardons-binance-founder-changpeng-zhao/",
          "published_at": "Thu, 23 Oct 2025 16:41:18 +0000",
          "title": "Trump pardons Binance founder Changpeng Zhao",
          "standfirst": "Changpeng Zhao previously pleaded guilty to enabling money laundering while running the cryptocurrency exchange, and served four months in prison last year.",
          "content": "Changpeng Zhao previously pleaded guilty to enabling money laundering while running the cryptocurrency exchange, and served four months in prison last year.",
          "feed_position": 13
        }
      ],
      "featured_image": "https://media.wired.com/photos/68fa4fd3c5809c60f31dd079/master/pass/Trump-Pardon-Binance-CEO-Business-2210816860.jpg",
      "popularity_score": 2006.7735547222221,
      "ai_summary": [
        "Donald Trump pardoned Changpeng Zhao, the Binance founder.",
        "Zhao previously pleaded guilty to money laundering charges.",
        "He served four months in prison for enabling money laundering.",
        "The pardon occurred after Zhao's federal prison sentence.",
        "Zhao violated anti-money-laundering laws and US sanctions."
      ]
    },
    {
      "id": "cluster_18",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 22:08:40 +0000",
      "title": "With new acquisition, OpenAI signals plans to integrate deeper into the OS",
      "neutral_headline": "OpenAI Plans to Integrate Deeper into the OS",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/openai-acquires-the-team-that-made-apples-shortcuts/",
          "published_at": "Thu, 23 Oct 2025 22:08:40 +0000",
          "title": "With new acquisition, OpenAI signals plans to integrate deeper into the OS",
          "standfirst": "The acquired firm was working on a tool to control macOS directly with AI.",
          "content": "OpenAI has acquired Software Applications Incorporated (SAI), perhaps best known for the core team that produced what became Shortcuts on Apple platforms. More recently, the team has been working on Sky, a context-aware AI interface layer on top of macOS. The financial terms of the acquisition have not been publicly disclosed. “AI progress isn’t only about advancing intelligence—it’s about unlocking it through interfaces that understand context, adapt to your intent, and work seamlessly,” an OpenAI rep wrote in the company’s blog post about the acquisition. The post goes on to specify that OpenAI plans to “bring Sky’s deep macOS integration and product craft into ChatGPT, and all members of the team will join OpenAI.” That includes SAI co-founders Ari Weinstein (CEO), Conrad Kramer (CTO), and Kim Beverett (Product Lead)—all of whom worked together for several years at Apple after Apple acquired Weinstein and Kramer’s previous company, which produced an automation tool called Workflows, to integrate Shortcuts across Apple’s software platforms.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/openai-sky-1152x648.webp"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/openai-sky-1152x648.webp",
      "popularity_score": 358.8243880555556,
      "ai_summary": [
        "OpenAI acquired a firm working on macOS control with AI.",
        "The acquired tool aimed to directly control macOS.",
        "This acquisition signals OpenAI's integration plans.",
        "The integration involves deeper access to the operating system.",
        "The focus is on using AI to manage the operating system."
      ]
    },
    {
      "id": "cluster_21",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 21:54:39 +0000",
      "title": "Lawsuit: Reddit caught Perplexity “red-handed” stealing data from Google results",
      "neutral_headline": "Reddit Accuses Perplexity of Stealing Data",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/reddit-sues-to-block-perplexity-from-scraping-google-search-results/",
          "published_at": "Thu, 23 Oct 2025 21:54:39 +0000",
          "title": "Lawsuit: Reddit caught Perplexity “red-handed” stealing data from Google results",
          "standfirst": "Scraper accused of stealing Reddit content \"shocked\" by lawsuit.",
          "content": "In a lawsuit filed on Wednesday, Reddit accused an AI search engine, Perplexity, of conspiring with several companies to illegally scrape Reddit content from Google search results, allegedly dodging anti-scraping methods that require substantial investments from both Google and Reddit. Reddit alleged that Perplexity feeds off Reddit and Google, claiming to be “the world’s first answer engine” but really doing “nothing groundbreaking.” “Its answer engine simply uses a different company’s” large language model “to parse through a massive number of Google search results to see if it can answer a user’s question based on those results,” the lawsuit said. “But Perplexity can only run its ‘answer engine’ by wrongfully accessing and scraping Reddit content appearing in Google’s own search results from Google’s own search engine.”Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2236792840-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2236792840-1024x648.jpg",
      "popularity_score": 345.5907769444444,
      "ai_summary": [
        "Reddit filed a lawsuit against Perplexity.",
        "Reddit accuses Perplexity of stealing data from Google results.",
        "The lawsuit claims Perplexity scraped Reddit content.",
        "The lawsuit alleges Perplexity was caught \"red-handed\".",
        "The accused scraper expressed shock at the lawsuit."
      ]
    },
    {
      "id": "cluster_30",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 21:20:48 +0000",
      "title": "Researchers show that training on “junk data” can lead to LLM “brain rot”",
      "neutral_headline": "Junk Data\" Training Leads to LLM \"Brain Rot",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/researchers-show-that-training-on-junk-data-can-lead-to-llm-brain-rot/",
          "published_at": "Thu, 23 Oct 2025 21:20:48 +0000",
          "title": "Researchers show that training on “junk data” can lead to LLM “brain rot”",
          "standfirst": "Models trained on short, popular, and/or \"superficial\" tweets perform worse on benchmarks.",
          "content": "On the surface, it seems obvious that training an LLM with “high quality” data will lead to better performance than feeding it any old “low quality” junk you can find. Now, a group of researchers is attempting to quantify just how much this kind of low quality data can cause an LLM to experience effects akin to human “brain rot.” For a pre-print paper published this month, the researchers from Texas A&M, the University of Texas, and Purdue University drew inspiration from existing research showing how humans who consume “large volumes of trivial and unchallenging online content” can develop problems with attention, memory, and social cognition. That led them to what they’re calling the “LLM brain rot hypothesis,” summed up as the idea that “continual pre-training on junk web text induces lasting cognitive decline in LLMs.” Figuring out what counts as “junk web text” and what counts as “quality content” is far from a simple or fully objective process, of course. But the researchers used a few different metrics to tease a “junk dataset” and “control dataset” from HuggingFace’s corpus of 100 million tweets.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1908316227-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1908316227-1152x648.jpg",
      "popularity_score": 338.02661027777776,
      "ai_summary": [
        "Researchers found that training on \"junk data\" harms LLM performance.",
        "Models trained on short, popular tweets performed worse.",
        "Models trained on superficial tweets also showed poor results.",
        "The study used benchmarks to assess model performance.",
        "The research highlights the impact of data quality on LLMs."
      ]
    },
    {
      "id": "cluster_34",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 20:57:36 +0000",
      "title": "Dinosaurs may have flourished right up to when the asteroid hit",
      "neutral_headline": "Dinosaurs Flourished Before Asteroid Impact",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/dinosaurs-may-have-flourished-right-up-to-when-the-asteroid-hit/",
          "published_at": "Thu, 23 Oct 2025 20:57:36 +0000",
          "title": "Dinosaurs may have flourished right up to when the asteroid hit",
          "standfirst": "Fossil beds in New Mexico show diverse species present in the late Cretaceous.",
          "content": "The end of the dinosaurs was clearly linked to an asteroid impact that brought the Cretaceous period to a close. But the details of their end have remained a matter of debate since the impact crater was discovered. There is a lot of evidence that the impact alone should have been enough to do them in. But the asteroid arrived amid major volcanic eruptions associated with previous mass extinctions. And fossils dating to just before the impact have suggested that dinosaur-dominated ecosystems had become less diverse, making them more prone to collapse. Now, a new study has revealed that fossils we already know about originated within the last few hundred thousand years before the impact that killed off all dinosaurs except birds. The results indicate that species richness wasn’t likely to be a problem—at least in the neighborhood of the impact itself. Wyoming vs. New Mexico Most of what we know about the last days of the non-avian dinosaurs comes from the Hell Creek Formation, rich fossil beds in present-day Wyoming. These not only date from within a few hundred thousand years prior to the impact, but there may be deposits that capture the immediate aftermath of the impact. Beyond this area, which reflects the ecosystem of the northern Great Plains, we have little else. It hasn’t been clear whether the diversity of species present at Hell Creek reflects what was present more globally, or if there were regional differences in ecosystemsRead full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1386002288-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1386002288-1152x648.jpg",
      "popularity_score": 312.6399436111111,
      "ai_summary": [
        "Fossil beds in New Mexico show diverse dinosaur species.",
        "These species were present in the late Cretaceous period.",
        "The findings suggest dinosaurs thrived before the asteroid.",
        "The research provides insights into dinosaur populations.",
        "The study focuses on the period leading up to the impact."
      ]
    },
    {
      "id": "cluster_57",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 18:48:52 +0000",
      "title": "Microsoft makes Copilot “human-centered” with a ‘90s-style animated assistant",
      "neutral_headline": "Microsoft Introduces Animated Copilot Assistant",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/microsoft-makes-copilot-human-centered-with-a-90s-style-animated-assistant/",
          "published_at": "Thu, 23 Oct 2025 18:48:52 +0000",
          "title": "Microsoft makes Copilot “human-centered” with a ‘90s-style animated assistant",
          "standfirst": "\"Mico\" literally tries to put a face on Microsoft's chatbot-turned-assistant.",
          "content": "Microsoft said earlier this month that it wanted to add better voice controls to Copilot, Windows 11’s built-in chatbot-slash-virtual assistant. As described, this new version of Copilot sounds an awful lot like another stab at Cortana, the voice assistant that Microsoft tried (and failed) to get people to use in Windows 10 in the mid-to-late 2010s. Turns out that the company isn’t done trying to reformulate and revive ideas it has already tried before. As part of a push toward what it calls “human-centered AI,” Microsoft is now putting a face on Copilot. Literally, a face: “Mico” is an “expressive, customizable, and warm” blob with a face that dynamically “listens, reacts, and even changes colors to reflect your interactions” as you interact with Copilot. (Another important adjective for Mico: “optional.”) Mico (rhymes with “pico”) recalls old digital assistants like Clippy, Microsoft Bob, and Rover, ideas that Microsoft tried in the ’90s and early 2000s before mostly abandoning them.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Mico-1-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Mico-1-1152x648.jpeg",
      "popularity_score": 302.49438805555553,
      "ai_summary": [
        "Microsoft is introducing a \"human-centered\" Copilot.",
        "The assistant features a '90s-style animated design.",
        "The assistant is named \"Mico\".",
        "\"Mico\" aims to personalize the chatbot experience.",
        "The design change is intended to make Copilot more approachable."
      ]
    },
    {
      "id": "cluster_48",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 19:58:52 +0000",
      "title": "An NIH director joins MAHA, gets replaced by JD Vance’s close friend",
      "neutral_headline": "NIH Director Joins MAHA, Replaced by Vance Friend",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/an-nih-director-joins-maha-gets-replaced-by-jd-vances-close-friend/",
          "published_at": "Thu, 23 Oct 2025 19:58:52 +0000",
          "title": "An NIH director joins MAHA, gets replaced by JD Vance’s close friend",
          "standfirst": "The NTP produced controversial studies on cellphone radiation and fluoride.",
          "content": "The director of a federal health institute that has arguably produced two of the most controversial government studies in recent years has accepted a new federal role to advance the goals of the Make America Healthy Again movement. Meanwhile, the person replacing him as director is a close friend of Vice President JD Vance and was installed in a process that experts describe as completely outside standard hiring practices. The series of events—revealed in an email to staff last week from the National Institutes of Health Director Jay Bhattacharya—is only exacerbating the spiraling fears that science is being deeply corrupted by politics under the Trump administration. Richard Woychik, a molecular geneticist, is the outgoing director of the NIH’s National Institute of Environmental Health Sciences (NIEHS), which is located in Research Triangle Park, North Carolina. He has been director since 2020 and was recently appointed to a second five-year term, according to Science magazine. Woychik was hired at the institute in 2010, when he joined as deputy director, and was appointed acting director in 2019.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1291108057-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1291108057-1152x648.jpg",
      "popularity_score": 301.6610547222222,
      "ai_summary": [
        "An NIH director joined MAHA.",
        "The director was then replaced.",
        "The replacement is a close friend of JD Vance.",
        "The NTP produced controversial studies.",
        "These studies concerned cellphone radiation and fluoride."
      ]
    },
    {
      "id": "cluster_73",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 17:04:16 +0000",
      "title": "The first people to set foot in Australia were fossil hunters",
      "neutral_headline": "First Australians Were Fossil Hunters",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/the-first-people-to-set-foot-in-australia-were-fossil-hunters/",
          "published_at": "Thu, 23 Oct 2025 17:04:16 +0000",
          "title": "The first people to set foot in Australia were fossil hunters",
          "standfirst": "Europeans weren't the first people to collect fossils in Australia.",
          "content": "Australia’s First Peoples may or may not have hunted the continent’s megafauna to extinction, but they definitely collected fossils. A team of archaeologists examined the fossilized leg bone of an extinct kangaroo and realized that instead of evidence of butchery, cut marks on the bone reveal an ancient attempt at fossil collecting. That leaves Australia with little evidence of First Peoples hunting or butchering the continent’s extinct megafauna—and reopens the question of whether humans were responsible for the die-off of that continent’s giant Ice Age marsupials. Fossil hunting in the Ice Age In the unsolved case of whether humans hunted Australia’s Ice Age megafauna to extinction, the key piece of evidence so far is a tibia (one of the bones of the lower leg) from an extinct short-faced kangaroo. Instead of hopping like their modern relatives, these extinct kangaroos walked on their hind legs, probably placing all their weight on the tips of single hoofed toes. This particular kangaroo wasn’t quite fully grown when it died, which happened sometime between 44,500 and 55,200 years ago, based on uranium-series dating of the thin layer of rock covering most of the fossils in Mammoth Cave (in what’s now Western Australia).Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/rsosSimosthenurus_occidentalis-1152x648-1761239043.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/rsosSimosthenurus_occidentalis-1152x648-1761239043.jpg",
      "popularity_score": 278.7510547222222,
      "ai_summary": [
        "Europeans were not the first to collect fossils in Australia.",
        "The first people to collect fossils were in Australia.",
        "The article discusses the history of fossil collection.",
        "The focus is on the earliest fossil hunters.",
        "The research challenges previous assumptions."
      ]
    },
    {
      "id": "cluster_80",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 16:40:22 +0000",
      "title": "CS2 item market loses nearly $2B in value overnight due to “trade up” update",
      "neutral_headline": "CS2 Item Market Loses Value After Update",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/10/valve-upends-the-cs2-item-marketplace-with-new-trade-up-update/",
          "published_at": "Thu, 23 Oct 2025 16:40:22 +0000",
          "title": "CS2 item market loses nearly $2B in value overnight due to “trade up” update",
          "standfirst": "Once rare $14K knife now sells for $7K, some common guns jump from $10 to over $100.",
          "content": "From the outside, Counter-Strike 2 looks a lot like a game that’s primarily about shooting people. For millions of players, though, the game is more about collecting and/or buying rare in-game loot and flipping it for what can be very significant sums on the Steam Marketplace. Wednesday night, Valve sent that multi-billion-dollar market into turmoil as part of a so-called “small update.” Now, players can use the game’s “Trade Up contracts” to exchange five common, “Covert” items (also known as “reds”) for the kinds of knives and gloves that have until now been much harder to obtain. That “small update” has unsurprisingly had an immediate and sharp impact on the Marketplace price for those items. One rare knife that sold for over $14,000 less than 24 hours ago has seen its minimum price plummet over 50 percent as of this writing, according to the trackers at Pricempire. Meanwhile, the median sale price for a common P90 Asimov gun on the Steam Marketplace shot up from $10 on Wednesday to well over $100 as of this writing.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/cs2knife-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/cs2knife-1152x648.png",
      "popularity_score": 268.3527213888889,
      "ai_summary": [
        "The CS2 item market lost nearly $2 billion in value.",
        "This loss resulted from a \"trade up\" update.",
        "A rare knife's value dropped from $14K to $7K.",
        "Some common guns increased in price from $10 to over $100.",
        "The update significantly impacted item values."
      ]
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 16:25:00 +0000",
      "title": "Great hybrid V6, lousy HMI: Three days with a Ferrari 296 GTB",
      "neutral_headline": "Ferrari 296 GTB Review: Hybrid V6, Lousy HMI",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/great-hybrid-v6-lousy-hmi-three-days-with-a-ferrari-296-gtb/",
          "published_at": "Thu, 23 Oct 2025 16:25:00 +0000",
          "title": "Great hybrid V6, lousy HMI: Three days with a Ferrari 296 GTB",
          "standfirst": "Three days with a car revealed its character in more ways than one.",
          "content": "Ferrari provided flights from Washington, DC, to Austin, Texas, and accommodation so Ars could attend the Lone Star Le Mans. Ars does not accept paid editorial content. The first time I drove this generation of mid-engined Ferrari, it was on a curated route on the company’s home turf. As the Po Valley gives way to the Apennines, you find plenty of narrow winding roads, steep gradients, and hairpin turns. It was an engaging few hours of driving, but it was too brief to properly assess some of the 296’s technology. I found the ride firm but comfortable on rough Italian tarmac and the hybrid system easy to operate, flicking into calm-and-quiet electric-only mode through the villages I encountered. That was back in 2022 during the unveiling of Ferrari’s 499P race car. Last month, I met the 499P again as it visited the Circuit of the Americas in Austin, along with the rest of the World Endurance Championship. And that afforded another chance to get to know the 296, with three days rather than three hours to form an impression. Head west from Austin and you’ll find twisty roads that wrap around the hills. It would have been easy to spend an entire day out there, but that seemed repetitive—I’d experienced the 296’s back road behavior already. Plus, there were things to do at the racetrack, although I’ll admit I took the long way there and back each day.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2025-Ferrari-296-GTB-1-of-12-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2025-Ferrari-296-GTB-1-of-12-1152x648.jpg",
      "popularity_score": 258.09661027777776,
      "ai_summary": [
        "The article reviews the Ferrari 296 GTB.",
        "The review covers three days with the car.",
        "The car's character was revealed in various ways.",
        "The review highlights the hybrid V6 engine.",
        "The review criticizes the car's HMI."
      ]
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 15:33:04 +0000",
      "title": "Trump eyes government control of quantum computing firms with Intel-like deals",
      "neutral_headline": "Trump Considers Government Control of Quantum Computing Firms",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/trumps-industry-meddling-may-give-us-a-stake-in-quantum-computing-firms/",
          "published_at": "Thu, 23 Oct 2025 15:33:04 +0000",
          "title": "Trump eyes government control of quantum computing firms with Intel-like deals",
          "standfirst": "Some quantum computing firms seem optimistic about Trump's proposed deals.",
          "content": "Donald Trump is eyeing taking equity stakes in quantum computing firms in exchange for federal funding, The Wall Street Journal reported. At least five companies are weighing whether allowing the government to become a shareholder would be worth it to snag funding that the Trump administration has “earmarked for promising technology companies,” sources familiar with the potential deals told the WSJ. IonQ, Rigetti Computing, and D-Wave Quantum are currently in talks with the government over potential funding agreements, with minimum awards of $10 million each, some sources said. Quantum Computing Inc. and Atom Computing are reportedly “considering similar arrangements,” as are other companies in the sector, which is viewed as critical for scientific advancements and next-generation technologies.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2229574852-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2229574852-1152x648.jpg",
      "popularity_score": 247.2310547222222,
      "ai_summary": [
        "Trump is considering deals similar to those used with Intel for quantum computing firms.",
        "Some quantum computing firms express optimism about the proposed government deals.",
        "The specifics of the proposed government control are not yet fully detailed.",
        "The potential impact on the quantum computing industry remains uncertain.",
        "The government's role in this emerging technology is being actively discussed."
      ]
    },
    {
      "id": "cluster_96",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 15:04:47 +0000",
      "title": "Reports suggest Apple is already pulling back on the iPhone Air",
      "neutral_headline": "Apple Reportedly Pulling Back on iPhone Air Development",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/early-indicators-analyst-reports-suggest-apples-iphone-air-isnt-taking-off/",
          "published_at": "Thu, 23 Oct 2025 15:04:47 +0000",
          "title": "Reports suggest Apple is already pulling back on the iPhone Air",
          "standfirst": "New phone design compromises on camera and battery to achieve a lighter weight.",
          "content": "Apple’s iPhone Air was the company’s most interesting new iPhone this year, at least insofar as it was the one most different from previous iPhones. We came away impressed by its size and weight in our review. But early reports suggest that its novelty might not be translating into sales success. A note from analyst Ming-Chi Kuo, whose supply chain sources are often accurate about Apple’s future plans, said yesterday that demand for the iPhone Air “has fallen short of expectations” and that “both shipments and production capacity” were being scaled back to account for the lower-than-expected demand. Kuo’s note is backed up by reports from other analysts at Mizuho Securities (via MacRumors) and Nikkei Asia. Both of these reports say that demand for the iPhone 17 and 17 Pro models remains strong, indicating that this is just a problem for the iPhone Air and not a wider slowdown caused by tariffs or other external factors.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_3384-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_3384-1152x648.jpeg",
      "popularity_score": 163.75966583333334,
      "ai_summary": [
        "Reports indicate Apple is scaling back plans for the iPhone Air.",
        "The new phone design compromises camera and battery features.",
        "The primary goal is to achieve a lighter weight for the device.",
        "Specific details on the extent of the compromises are not yet available.",
        "The iPhone Air's release timeline may be affected by these changes."
      ]
    },
    {
      "id": "cluster_106",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 13:58:46 +0000",
      "title": "An outcast faces a deadly alien world in Predator: Badlands trailer",
      "neutral_headline": "Predator: Badlands Trailer Shows Alien World Violence",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/10/an-outcast-faces-a-deadly-alien-world-in-predator-badlands-trailer/",
          "published_at": "Thu, 23 Oct 2025 13:58:46 +0000",
          "title": "An outcast faces a deadly alien world in Predator: Badlands trailer",
          "standfirst": "\"The ways of your kind are ones of violence. Either you are hunted or you become the hunter.\"",
          "content": "We’ve got a new international trailer for Predator: Badlands, the latest installment in a popular franchise that’s been around since 1987. It’s directed by Dan Trachtenberg, who is very familiar with the franchise, having also directed 2022’s highly acclaimed standalone Predator movie, Prey. In April, Twentieth Century Studios released the first teaser, which involved multiple predators fighting or threatening one another, Elle Fanning looking very strange and cool as an android, and glimpses of new monsters and the alien world the movie focuses on. And the film was featured prominently at San Diego Comic-Con this summer. But it hasn’t quite wormed its way into the cultural zeitgeist for fall releases. Perhaps this latest trailer will boost its profile. This is a standalone film in the franchise, with a particular focus on the culture of the Predator species; in fact, the same conlanger who created the Na’Vi language for James Cameron’s Avatar franchise also created a written and verbal language for the Predators. (We hear a bit of the dialogue in the new trailer.) And this time around, the primary Predator is actually the film’s protagonist rather than an adversary. Per the official premise: “Set in the future on a deadly remote planet, Predator: Badlands follows a young Predator outcast (Dimitrius Schuster-Koloamatangi) who finds an unlikely ally in Thia (Elle Fanning) as he embarks on a treacherous journey in search of the ultimate adversary.”Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bloodlands1-1152x648-1761226866.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bloodlands1-1152x648-1761226866.jpg",
      "popularity_score": 150.65938805555555,
      "ai_summary": [
        "The trailer for Predator: Badlands features an outcast character.",
        "The setting is a deadly alien world filled with violence.",
        "The trailer includes the quote, \"Either you are hunted or you become the hunter.\"",
        "The film's plot involves survival against a dangerous alien species.",
        "The trailer offers a glimpse into the film's action and themes."
      ]
    },
    {
      "id": "cluster_121",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 11:00:08 +0000",
      "title": "We let OpenAI’s “Agent Mode” surf the web for us—here’s what happened",
      "neutral_headline": "OpenAI's Agent Mode Automates Web-Based Tasks",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/features/2025/10/we-let-openais-agent-mode-surf-the-web-for-us-heres-what-happened/",
          "published_at": "Thu, 23 Oct 2025 11:00:08 +0000",
          "title": "We let OpenAI’s “Agent Mode” surf the web for us—here’s what happened",
          "standfirst": "From scanning emails to building fansites, Atlas can ably automate some web-based tasks.",
          "content": "On Tuesday, OpenAI announced Atlas, a new web browser with ChatGPT integration, to let you “chat with a page,” as the company puts it. But Atlas also goes beyond the usual LLM back-and-forth with Agent Mode, a “preview mode” feature the company says can “get work done for you” by clicking, scrolling, and reading through various tabs. “Agentic” AI is far from new, of course; OpenAI itself rolled out a preview of the web browsing Operator agent in January and introduced the more generalized “ChatGPT agent” in July. Still, prominently featuring this capability in a major product release like this—even in “preview mode”—signals a clear push to get this kind of system in front of end users. I wanted to put Atlas’ Agent Mode through its paces to see if it could really save me time in doing the kinds of tedious online tasks I plod through every day. In each case, I’ll outline a web-based problem, lay out the Agent Mode prompt I devised to try to solve it, and describe the results. My final evaluation will rank each task on a 10-point scale, with 10 being “did exactly what I wanted with no problems” and one being “complete failure.”Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2022302070-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2022302070-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "OpenAI's \"Agent Mode\" can surf the web and perform tasks.",
        "The agent can scan emails and build fan websites.",
        "The agent is capable of automating some web-based tasks.",
        "The capabilities of the agent are being actively tested.",
        "The agent's performance is being evaluated in various scenarios."
      ]
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 20:29:11 +0000",
      "title": "General Motors will integrate AI into its cars, plus new hands-free assist",
      "neutral_headline": "General Motors Integrates AI into Cars, Adds Hands-Free Assist",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/ai-and-hands-free-driving-are-coming-to-gms-vehicles/",
          "published_at": "Wed, 22 Oct 2025 20:29:11 +0000",
          "title": "General Motors will integrate AI into its cars, plus new hands-free assist",
          "standfirst": "Do we want LLMs in our cars? GM thinks we do.",
          "content": "GM provided flights from Detroit to New York City and accommodation so Ars could attend its tech event. Ars does not accept paid editorial content. General Motors held a preview event today to show the world what it’s working on. We’ve already seen some projects, like the further development of lithium manganese-rich battery technology or backup power for EVs that can power a home or support the power grid. The most significant new announcement is that Cadillac will offer an Escalade IQ with a so-called “Level 3” conditional automated driving system in 2028. GM is referring to it as a “hands off, eyes off” system and says it will integrate advanced digital mapping, use of lidar and other systems, and advanced machine learning to handle the driving duties in a controlled environment up to 80 mph (129 km/h). This means you can theoretically watch a movie from the driver’s seat while your car takes you down the highway to the airport. Over time, the system’s operation areas will expand to cover even more roads, making driving unnecessary in many situations—unless, of course, you like to drive.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1776398279-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1776398279-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "General Motors plans to integrate AI into its vehicles.",
        "The company is also introducing a new hands-free assist feature.",
        "The integration of AI raises questions about its role in cars.",
        "GM believes consumers will embrace AI in their vehicles.",
        "The specific AI features and their functionality are being developed."
      ]
    },
    {
      "id": "cluster_107",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 13:42:41 +0000",
      "title": "Porsche does U-turn on electric vehicles, will focus on gas engines",
      "neutral_headline": "Porsche Shifts Focus Back to Gas Engines from Electric Vehicles",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/porsche-does-u-turn-on-electric-vehicles-will-focus-on-gas-engines/",
          "published_at": "Thu, 23 Oct 2025 13:42:41 +0000",
          "title": "Porsche does U-turn on electric vehicles, will focus on gas engines",
          "standfirst": "China weakness, US tariffs, and disappointing uptake of battery vehicles lurk in background.",
          "content": "Porsche’s new boss was a skeptic of battery motors for luxury vehicles long before he was picked to lead the revival of the petrol engine at the German sports car group. “The technology isn’t ready,” Michael Leiters told the Financial Times late last year while still in his old job as chief executive of British supercar manufacturer McLaren. Electric vehicles lacked the emotional thrill of noisy engines and were quicker to lose their value, he said. Leiters will take over at Porsche in January at a critical juncture for the Stuttgart-based company, as it tempers its electric ambitions and ploughs new investment into petrol engine models in an attempt to turn its fortunes around.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2019/10/02-Porsche-Taycan-4S--1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2019/10/02-Porsche-Taycan-4S--1152x648.jpg",
      "popularity_score": 141.39133222222222,
      "ai_summary": [
        "Porsche is changing its focus from electric vehicles.",
        "The company will concentrate on gas engines.",
        "Weakness in China, US tariffs, and uptake are factors.",
        "Disappointing sales of battery vehicles are also a factor.",
        "The shift reflects changing market conditions and challenges."
      ]
    },
    {
      "id": "cluster_118",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 11:15:12 +0000",
      "title": "California startup to demonstrate space weapon on its own dime",
      "neutral_headline": "California Startup Plans Space Weapon Demonstration",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/california-startup-to-demonstrate-space-weapon-on-its-own-dime/",
          "published_at": "Thu, 23 Oct 2025 11:15:12 +0000",
          "title": "California startup to demonstrate space weapon on its own dime",
          "standfirst": "\"All of the pieces that are required to make it viable exist.\"",
          "content": "Defense contractors are in full sales mode to win a piece of a potentially trillion-dollar pie for development of the Trump administration’s proposed Golden Dome missile shield. CEOs are touting their companies’ ability to rapidly spool up satellite, sensor, and rocket production. Publicly, they all agree with the assertion of Pentagon officials that US industry already possesses the technologies required to make a homeland missile defense system work. The challenge, they say, is tying all of it together under the umbrella of a sophisticated command and control network. Sensors must be able to detect and track missile threats, and that information must rapidly get to weapons that can shoot them down. Gen. Chance Saltzman, the Space Force’s top commander, likes to call Golden Dome a “systems of systems.”Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/apex_sbi-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/apex_sbi-1152x648.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "A California startup will demonstrate a space weapon.",
        "The demonstration will be funded by the startup itself.",
        "The startup claims all necessary components are available.",
        "The specific details of the weapon are not yet public.",
        "The demonstration's purpose is to showcase the technology."
      ]
    },
    {
      "id": "cluster_133",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 20:45:23 +0000",
      "title": "This may be the most bonkers tech job listing I’ve ever seen",
      "neutral_headline": "Tech Job Listing Described as \"Bonkers",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/10/the-tech-ceo-who-would-eat-dog-poop-if-it-means-winning/",
          "published_at": "Wed, 22 Oct 2025 20:45:23 +0000",
          "title": "This may be the most bonkers tech job listing I’ve ever seen",
          "standfirst": "Don't even apply if you're not a Tier 1 \"A-player.\"",
          "content": "Here’s a job pitch you don’t see often. What if, instead of “work-life balance,” you had no balance at all—your life was your work… and work happened seven days a week? Did I say days? I actually meant days and nights, because the job I’m talking about wants you to know that you will also work weekends and evenings, and that “it’s ok to send messages at 3am.”Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1149297973-1152x648-1761164087.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1149297973-1152x648-1761164087.jpg",
      "popularity_score": 139,
      "ai_summary": [
        "A tech job listing has been described as \"bonkers.\"",
        "The listing specifies a requirement for \"A-player\" candidates.",
        "The listing discourages applications from those not meeting criteria.",
        "The specific requirements of the job are not fully detailed.",
        "The listing reflects high expectations for potential employees."
      ]
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 21:42:47 +0000",
      "title": "Tesla profits fall 37% in Q3 despite healthy sales",
      "neutral_headline": "Tesla Profits Fall Despite Healthy Sales in Q3",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/tesla-profits-fall-37-in-q3-despite-healthy-sales/",
          "published_at": "Wed, 22 Oct 2025 21:42:47 +0000",
          "title": "Tesla profits fall 37% in Q3 despite healthy sales",
          "standfirst": "A loss of regulatory credits and increased expenses didn't help.",
          "content": "Tesla reported its financial results for the third quarter of 2025 this afternoon. Earlier this month, we learned that the electric vehicle manufacturer had a pretty good Q3 in terms of sales, which grew by 7.3 percent year over year and cleared out tens of thousands of cars from inventory in the process. However, that hasn’t translated into greater profitability. Even though revenues grew by 12 percent to $28 billion compared to the same period last year, Tesla’s operating expenses grew by 50 percent. As a result, its operating margin halved to just 5.8 percent. And so its profit for the quarter fell by 37 percent to $1.4 billion. Some growth in revenue came from its battery and solar division; this increased by 44 percent to $3.4 billion compared to Q3 2024. Services—including the Supercharger network, which is now open to an increasing number of other makes of EV—also grew, increasing by 25 percent to $3.4 billion. EV deliveries increased by 7 percent to 497,099, most of which were the Model 3 sedan and Model Y crossover. Automotive revenues grew slightly less, increasing 6 percent year over year to $21.2 billion.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/tesladown-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/tesladown-1024x648.jpg",
      "popularity_score": 136,
      "ai_summary": [
        "Tesla's profits decreased by 37% in the third quarter.",
        "The company experienced healthy sales during the period.",
        "A loss of regulatory credits contributed to the decline.",
        "Increased expenses also impacted the company's profits.",
        "The financial performance reflects various market factors."
      ]
    },
    {
      "id": "cluster_116",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 11:30:55 +0000",
      "title": "Texas lawmakers double down on Discovery, call for DOJ investigation into Smithsonian",
      "neutral_headline": "Texas Lawmakers Investigate Smithsonian, Discovery",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/texas-lawmakers-double-down-on-discovery-call-for-doj-investigation-into-smithsonian/",
          "published_at": "Thu, 23 Oct 2025 11:30:55 +0000",
          "title": "Texas lawmakers double down on Discovery, call for DOJ investigation into Smithsonian",
          "standfirst": "\"This is the dumbest plan I've ever heard in nearly five years in the United States Senate.\"",
          "content": "Have you heard the news that Texas’ senators want to chop up NASA’s retired space shuttle Discovery in order to move it from the Smithsonian to Houston? The lawmakers in question have and are now crying foul to the Department of Justice. Sens. John Cornyn (R-Texas) and Ted Cruz (R-Texas), together with Rep. Randy Weber (R-Texas), on Wednesday sent a letter to the DOJ urging the Smithsonian be investigated for allegedly violating the Anti-Lobbying Act. They claim that the institution—Discovery‘s home for the past 13 years—improperly used appropriated funds to influence Congress regarding the relocation of the winged orbiter. “Public reporting suggests the Smithsonian Institution has taken affirmative steps to oppose the passage and implementation of the shuttle’s relocation, as part of President Trump’s One Big Beautiful Bill Act,” wrote Cornyn and Cruz to Attorney General Pamela Bondi and Assistant Attorney General Brett Shumate. “These steps include lobbying the staff of the Senate Appropriations and Rules Committees to express disapproval, coordinating with members of the press to generate public opposition to the law’s passage and disseminating misinformation about the cost and logistics of the move.”Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/news-102225a-lg-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/news-102225a-lg-1152x648.jpg",
      "popularity_score": 133.1952211111111,
      "ai_summary": [
        "Texas lawmakers are calling for an investigation.",
        "The investigation targets the Smithsonian and Discovery.",
        "The lawmakers' concerns are related to specific content.",
        "One senator called the plan \"the dumbest\" they've heard.",
        "The investigation's scope and focus are being determined."
      ]
    },
    {
      "id": "cluster_130",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 22:35:41 +0000",
      "title": "Cache poisoning vulnerabilities found in 2 DNS resolving apps",
      "neutral_headline": "Cache Poisoning Vulnerabilities Found in DNS Apps",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/bind-warns-of-bugs-that-could-bring-dns-cache-attack-back-from-the-dead/",
          "published_at": "Wed, 22 Oct 2025 22:35:41 +0000",
          "title": "Cache poisoning vulnerabilities found in 2 DNS resolving apps",
          "standfirst": "At least one CVE could weaken defenses put in place following 2008 disclosure.",
          "content": "The makers of BIND, the Internet’s most widely used software for resolving domain names, are warning of two vulnerabilities that allow attackers to poison entire caches of results and send users to malicious destinations that are indistinguishable from the real ones. The vulnerabilities, tracked as CVE-2025-40778 and CVE-2025-40780, stem from a logic error and a weakness in generating pseudo-random numbers, respectively. They each carry a severity rating of 8.6. Separately, makers of the Domain Name System resolver software Unbound warned of similar vulnerabilities that were reported by the same researchers. The unbound vulnerability severity score is 5.6 Revisiting Kaminsky’s cache poisoning attack The vulnerabilities can be exploited to cause DNS resolvers located inside thousands of organizations to replace valid results for domain lookups with corrupted ones. The corrupted results would replace the IP addresses controlled by the domain name operator (for instance, 3.15.119.63 for arstechnica.com) with malicious ones controlled by the attacker. Patches for all three vulnerabilities became available on Wednesday.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/browser-security-threat-1152x627.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/browser-security-threat-1152x627.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Cache poisoning vulnerabilities were found in DNS apps.",
        "At least one CVE could weaken existing defenses.",
        "The vulnerabilities could compromise DNS security.",
        "The vulnerabilities were discovered in resolving apps.",
        "The impact of the vulnerabilities is being assessed."
      ]
    }
  ]
}