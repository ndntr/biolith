{
  "updated_at": "2026-01-16T11:20:09.878Z",
  "clusters": [
    {
      "id": "cluster_7",
      "coverage": 2,
      "updated_at": "Fri, 16 Jan 2026 10:01:27 +0000",
      "title": "The best midrange smartphone for 2026",
      "neutral_headline": "The best midrange smartphone for 2026",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/best-midrange-smartphone-183006463.html",
          "published_at": "Fri, 16 Jan 2026 10:01:27 +0000",
          "title": "The best midrange smartphone for 2026",
          "standfirst": "Gone are the days in which you needed to spend a fortune to get a good smartphone. In 2026, features once exclusive to high-end smartphones – big batteries, multi-camera arrays, high refresh rate OLED displays and more – have made their way down to more affordable models. Yes, you’ll still need to buy a flagship smartphone to get the best camera or fastest processor, but you don't have to make nearly as many compromises as you once did if you have a strict budget to adhere to when you go shopping for your next smartphone. If you have less than $600 to spend, let us help you figure out what features to prioritize when trying to find the best midrange smartphone. Table of contents Best midrange phones in 2026 What is a midrange phone? What to consider before buying a midrange smartphone What won't you get from a midrange phone Best midrange phones for 2026 What is a midrange phone? While the term frequently appears in articles and videos, there isn’t an agreed-upon definition for “midrange” beyond a phone that isn’t a flagship or an entry-level option. Most of our recommendations cost between $400 and $600 — any less and you should expect significant compromises. If you have more to spend, you might as well consider flagships like the Apple iPhone 17 and the Samsung Galaxy S25 if you want the best smartphone experience. Devices like Pixel phones often sit in this price range too, offering some of the best value for Android buyers. What to consider before buying a midrange smartphone Buying a new device can be intimidating, but a few questions can help guide you through the process. First: what platform do you want to use? If the answer is iOS, that narrows your options down to exactly one phone. (Thankfully, it’s great.) And if you’re an Android fan, there’s no shortage of compelling options. Both platforms have their strengths, so you shouldn’t rule either out. Of course, also consider how much you’re comfortable spending. Even increasing your budget by $100 more can get you a dramatically better product. Moreover, manufacturers tend to support their more expensive devices for longer with software updates and security updates, so it’s worth buying something toward the top limit of what you can afford. Having an idea of your priorities will help inform your budget. Do you want a long battery life or fast charging? Do you value speedy performance above all else? Or would you like the best possible cameras with high megapixel counts? While they continue to improve every year, even the best midrange smartphones still demand some compromises, and knowing what’s important to you will make choosing one easier. What won’t you get from a midrange smartphone? Every year, the line between midrange and flagship phones blurs as more upmarket features and functions trickle down to more affordable models. When Engadget first published this guide in 2020, it was tricky to find a $500 phone with waterproofing and 5G. In 2026, the biggest thing you might miss out on is wireless charging – and even then, that’s becoming less true. One thing your new phone probably won’t come with is a power adapter; many companies have stopped including chargers with all of their smartphones. Performance has improved in recent years, but can still be hit or miss as most midrange phones use slower processors that can struggle with multitasking. Thankfully, their camera systems have improved dramatically, and you can typically expect at least a dual-lens system on most midrange smartphones below $600 with decent camera quality, selfie performance and software support to keep things running smoothly for years to come.. Midrange smartphone FAQs How long do midrange phones get software updates? Support varies by brand, but most midrange phones receive around three to five years of software and security updates. Apple tends to support iPhones longer while companies like Google and Samsung now promise several years of Android and security patches for their midrange models. Budget-focused brands might offer less so it’s worth checking the update policy before you buy. Are midrange phones good for gaming? Yes, many midrange phones handle gaming well, especially popular titles like Fortnite, Genshin Impact and Call of Duty Mobile. They usually include capable processors, though you won’t always get the smoothest performance in the most demanding mobile games or at max settings. If you play casually or stick to less graphically intensive titles a midrange phone will feel more than adequate. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/best-midrange-smartphone-183006463.html?src=rss",
          "content": "Gone are the days in which you needed to spend a fortune to get a good smartphone. In 2026, features once exclusive to high-end smartphones – big batteries, multi-camera arrays, high refresh rate OLED displays and more – have made their way down to more affordable models. Yes, you’ll still need to buy a flagship smartphone to get the best camera or fastest processor, but you don't have to make nearly as many compromises as you once did if you have a strict budget to adhere to when you go shopping for your next smartphone. If you have less than $600 to spend, let us help you figure out what features to prioritize when trying to find the best midrange smartphone. Table of contents Best midrange phones in 2026 What is a midrange phone? What to consider before buying a midrange smartphone What won't you get from a midrange phone Best midrange phones for 2026 What is a midrange phone? While the term frequently appears in articles and videos, there isn’t an agreed-upon definition for “midrange” beyond a phone that isn’t a flagship or an entry-level option. Most of our recommendations cost between $400 and $600 — any less and you should expect significant compromises. If you have more to spend, you might as well consider flagships like the Apple iPhone 17 and the Samsung Galaxy S25 if you want the best smartphone experience. Devices like Pixel phones often sit in this price range too, offering some of the best value for Android buyers. What to consider before buying a midrange smartphone Buying a new device can be intimidating, but a few questions can help guide you through the process. First: what platform do you want to use? If the answer is iOS, that narrows your options down to exactly one phone. (Thankfully, it’s great.) And if you’re an Android fan, there’s no shortage of compelling options. Both platforms have their strengths, so you shouldn’t rule either out. Of course, also consider how much you’re comfortable spending. Even increasing your budget by $100 more can get you a dramatically better product. Moreover, manufacturers tend to support their more expensive devices for longer with software updates and security updates, so it’s worth buying something toward the top limit of what you can afford. Having an idea of your priorities will help inform your budget. Do you want a long battery life or fast charging? Do you value speedy performance above all else? Or would you like the best possible cameras with high megapixel counts? While they continue to improve every year, even the best midrange smartphones still demand some compromises, and knowing what’s important to you will make choosing one easier. What won’t you get from a midrange smartphone? Every year, the line between midrange and flagship phones blurs as more upmarket features and functions trickle down to more affordable models. When Engadget first published this guide in 2020, it was tricky to find a $500 phone with waterproofing and 5G. In 2026, the biggest thing you might miss out on is wireless charging – and even then, that’s becoming less true. One thing your new phone probably won’t come with is a power adapter; many companies have stopped including chargers with all of their smartphones. Performance has improved in recent years, but can still be hit or miss as most midrange phones use slower processors that can struggle with multitasking. Thankfully, their camera systems have improved dramatically, and you can typically expect at least a dual-lens system on most midrange smartphones below $600 with decent camera quality, selfie performance and software support to keep things running smoothly for years to come.. Midrange smartphone FAQs How long do midrange phones get software updates? Support varies by brand, but most midrange phones receive around three to five years of software and security updates. Apple tends to support iPhones longer while companies like Google and Samsung now promise several years of Android and security patches for their midrange models. Budget-focused brands might offer less so it’s worth checking the update policy before you buy. Are midrange phones good for gaming? Yes, many midrange phones handle gaming well, especially popular titles like Fortnite, Genshin Impact and Call of Duty Mobile. They usually include capable processors, though you won’t always get the smoothest performance in the most demanding mobile games or at max settings. If you play casually or stick to less graphically intensive titles a midrange phone will feel more than adequate. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/best-midrange-smartphone-183006463.html?src=rss",
          "feed_position": 0
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/asus-has-stopped-producing-the-nvidia-rtx-5070-ti-and-5060-ti-16gb-saying-theyve-reached-end-of-life-162012253.html",
          "published_at": "Thu, 15 Jan 2026 23:32:30 +0000",
          "title": "ASUS has stopped producing the NVIDIA RTX 5070 Ti and 5060 Ti 16GB, saying they've reached 'end of life'",
          "standfirst": "YouTube channel Hardware Unboxed is reporting that ASUS has stopped producing the RTX 5070 Ti and 5060 Ti 16GB due to the ongoing memory crunch. In its most recent video, the channel states ASUS “explicitly” told it the RTX 5070 Ti is “currently facing a supply shortage.” As a result, the company has “placed the model into end of life status,” and no longer plans to produce it. Hardware Unboxed also spoke to retailers in Australia, who told the channel the 5070 Ti is “no longer available to purchase from partners and distributors,” adding they expect that to be the case throughout at least the first quarter of the year. The 5060 Ti 16GB “is almost done as well,\" with ASUS stating it no longer plans to produce that model going forward either. Both GPUs are 16GB models, making them more expensive to manufacture in the current economic climate. And while there might be some hope of the 5070 Ti and 5060 Ti 16GB returning later this year, the channel suggests both are unlikely to make a comeback. “Demand for GeForce RTX GPUs is strong, and memory supply is constrained. We continue to ship all GeForce SKUs and are working closely with our suppliers to maximize memory availability,” a NVIDIA spokesperson told Engadget. ASUS did not immediately respond to Engadget’s comment request. After uploading its video, Hardware Unboxed published a clarification. “ASUS did not tell us that NVIDIA said the RTX 5070 Ti has been discontinued. ASUS told us there is very little supply of the 5070 Ti, so their own 5070 Ti products (e.g, the Prime and TUF Gaming) have been put into end of life status,” the channel said. “With retailers also unable to source 5070 Ti SKUs from any AIB, this effectively makes it a dead product.” The AI boom has created an insatiable demand for RAM and other computer components from data center infrastructure companies. In response, many memory manufacturers have shifted their production lines to focus on high bandwidth memory for those clients at the expense of their regular offerings, leading to dramatically increased prices among consumer RAM kits, GPUs and SSDs. In December, Micron Technology announced it would wind down its consumer-facing Crucial brand to focus exclusively on providing components to the AI industry. ASUS is the first of NVIDIA’s add-in board (AIB) partners to comment on the memory crunch. AIBs are the companies that produce the majority of GPUs you can buy from NVIDIA and AMD. Historically, NVIDIA has provided its board partners with both the die and memory needed to make a graphics cards. However, a recent rumor suggested the company had told it partners they would need to start sourcing memory on their own. Update 12:55PM ET: Added more context.Update 2:06PM ET: Added comment from NVIDIA. Update 6:31PM ET: Added additional comment from Hardware Unboxed.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/asus-has-stopped-producing-the-nvidia-rtx-5070-ti-and-5060-ti-16gb-saying-theyve-reached-end-of-life-162012253.html?src=rss",
          "content": "YouTube channel Hardware Unboxed is reporting that ASUS has stopped producing the RTX 5070 Ti and 5060 Ti 16GB due to the ongoing memory crunch. In its most recent video, the channel states ASUS “explicitly” told it the RTX 5070 Ti is “currently facing a supply shortage.” As a result, the company has “placed the model into end of life status,” and no longer plans to produce it. Hardware Unboxed also spoke to retailers in Australia, who told the channel the 5070 Ti is “no longer available to purchase from partners and distributors,” adding they expect that to be the case throughout at least the first quarter of the year. The 5060 Ti 16GB “is almost done as well,\" with ASUS stating it no longer plans to produce that model going forward either. Both GPUs are 16GB models, making them more expensive to manufacture in the current economic climate. And while there might be some hope of the 5070 Ti and 5060 Ti 16GB returning later this year, the channel suggests both are unlikely to make a comeback. “Demand for GeForce RTX GPUs is strong, and memory supply is constrained. We continue to ship all GeForce SKUs and are working closely with our suppliers to maximize memory availability,” a NVIDIA spokesperson told Engadget. ASUS did not immediately respond to Engadget’s comment request. After uploading its video, Hardware Unboxed published a clarification. “ASUS did not tell us that NVIDIA said the RTX 5070 Ti has been discontinued. ASUS told us there is very little supply of the 5070 Ti, so their own 5070 Ti products (e.g, the Prime and TUF Gaming) have been put into end of life status,” the channel said. “With retailers also unable to source 5070 Ti SKUs from any AIB, this effectively makes it a dead product.” The AI boom has created an insatiable demand for RAM and other computer components from data center infrastructure companies. In response, many memory manufacturers have shifted their production lines to focus on high bandwidth memory for those clients at the expense of their regular offerings, leading to dramatically increased prices among consumer RAM kits, GPUs and SSDs. In December, Micron Technology announced it would wind down its consumer-facing Crucial brand to focus exclusively on providing components to the AI industry. ASUS is the first of NVIDIA’s add-in board (AIB) partners to comment on the memory crunch. AIBs are the companies that produce the majority of GPUs you can buy from NVIDIA and AMD. Historically, NVIDIA has provided its board partners with both the die and memory needed to make a graphics cards. However, a recent rumor suggested the company had told it partners they would need to start sourcing memory on their own. Update 12:55PM ET: Added more context.Update 2:06PM ET: Added comment from NVIDIA. Update 6:31PM ET: Added additional comment from Hardware Unboxed.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/asus-has-stopped-producing-the-nvidia-rtx-5070-ti-and-5060-ti-16gb-saying-theyve-reached-end-of-life-162012253.html?src=rss",
          "feed_position": 3
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/science/space/senate-passes-minibus-bill-funding-nasa-rejecting-trumps-proposed-cuts-231605536.html",
          "published_at": "Thu, 15 Jan 2026 23:16:05 +0000",
          "title": "Senate passes minibus bill funding NASA, rejecting Trump's proposed cuts",
          "standfirst": "After a tumultuous 2025 that saw it lose around 4,000 employees, NASA finally has an operating budget for 2026, and one that largely preserves its scientific capabilities. On Thursday, the Senate passed an appropriations bill funding NASA, alongside the National Science Foundation and a handful of other federal agencies. Going into the appropriations process, the president called for a 24 percent year over year reduction to NASA's total operating budget. As part of that plan, the White House wanted to reduce the Science Mission Directorate's funding by nearly half, a move that would have forced NASA to cancel 55 ongoing and planned missions, including efforts like OSIRIS-APEX. The bill effectively rejects President Trump's plan, reducing NASA's total operating budget by just 1.6 percent year over year to $24.4 billion. Per the new appropriations, NASA's science budget will stand at $7.25 billion, 1.1 percent less relative to fiscal 2024, while shuffling the remaining funds to focus on different priorities. For instance, the House and Senate allocated $874 million (+8.7 percent) for the agency's heliophysics work; planetary sciences, which oversees missions like New Horizons, was cut to $2.5 billion (-6.5 percent) compared to 2024. At the same time, NASA's STEM engagement office, which the president proposed eliminating, escaped unscathed with its funding maintained at parity.\"It's almost everything we had been asking for, and it's very encouraging to see a House and Senate run by the president's own party agreeing that we need to keep investing in things like NASA science,\" says Casey Dreier, chief of policy at the Planetary Society, a nonprofit founded by Carl Sagan that advocates for the exploration and study of space. \"It contains very clear and direct language that not only is this funding made available to these projects, but that it will be spent on the initiatives that Congress states.\"Lawmakers also rejected Trump's effort to scuttle the Space Launch System after its third flight. NASA's heavy-lift rocket is billions of dollars over budget, but remains — as of now — the only spacecraft ready to ferry astronauts to the Moon. Compared to the rest of NASA, the fate of the SLS was never really in doubt. Senator Ted Cruz (R-TX) secured funding for the rocket as part of Trump's Big Beautiful Bill. \"I've been saying for a long time you should never underestimate the political coalition behind the SLS, and I think that was very much validated this year,\" says Dreier. More importantly, it appears the Goddard Space Flight Center will be safe from further damage. Over the summer, the future of the facility, known for its work on projects like the James Webb Space Telescope, was put in jeopardy. By some estimates, the campus has lost a third of its staff due to workforce cuts, and dozens of buildings, including some 100 laboratories, have been shut down by management. One of the casualties was NASA's largest library, which houses irreplaceable documents chronicling the history of the space race. As part of a \"consolidation\" effort, many of those documents will be thrown out.Under the appropriations bill, the Senate has directed NASA to “preserve all the technical and scientific world-class capabilities at Goddard.” It has also instructed the agency to ensure employees of the Goddard Institute for Space Studies are able to continue their work with \"minimal disruption.\" The New York-based office, one of America's leading climate labs, was sent into limbo last spring after the Trump administration moved to shut it down. The bill also provides a lifeline for NASA's to bring back samples of Martian dirt collected by the Perseverance rover. Congress has effectively cancelled the official program tied to that ambition, the Mars Sample Return (MSR), but has set aside $110 million for the agency to continue developing technologies for future science missions to the Red Planet. MSR advocates have argued the mission could lead to significant scientific discoveries, but Dreier notes the program was \"ripe for cancellation\" after it became mired in mismanagement. \"I worry MSR now has this stink of bloat, excess cost and threat of overruns that are really going to make it challenging to restart this without having a dramatically different approach,\" says Dreier, adding that deciding what to do with mission will likely be top of mind for the agency's new administrator, Jared Isaacman. The 2026 budget leaves NASA with fewer resources. Even in areas where Congress allocated the same amount of funds as it did in 2024, the agency will need to do more with less due to inflation. Compared to the absolute blood bath that would have been Trump's proposed budget, a marginal funding cut is the best case scenario given the circumstances, but the circumstances remain less than ideal. \"There will be another presidential budget request coming out in the next couple of months,\" Dreier said. \"They could do this all over again if they wanted to.\"In the immediate future, NASA and its employees are at least protected from the potential fallout of another impending government shutdown. Congress has until January 30 to fully fund the federal government, and as of earlier this week, it has yet to find a way forward on appropriations for agencies like the Department of Labor. Correction 9:05PM ET: A previous version of this article incorrectly stated Casey Dreier’s surename as Drier. We regret the error. This article originally appeared on Engadget at https://www.engadget.com/science/space/senate-passes-minibus-bill-funding-nasa-rejecting-trumps-proposed-cuts-231605536.html?src=rss",
          "content": "After a tumultuous 2025 that saw it lose around 4,000 employees, NASA finally has an operating budget for 2026, and one that largely preserves its scientific capabilities. On Thursday, the Senate passed an appropriations bill funding NASA, alongside the National Science Foundation and a handful of other federal agencies. Going into the appropriations process, the president called for a 24 percent year over year reduction to NASA's total operating budget. As part of that plan, the White House wanted to reduce the Science Mission Directorate's funding by nearly half, a move that would have forced NASA to cancel 55 ongoing and planned missions, including efforts like OSIRIS-APEX. The bill effectively rejects President Trump's plan, reducing NASA's total operating budget by just 1.6 percent year over year to $24.4 billion. Per the new appropriations, NASA's science budget will stand at $7.25 billion, 1.1 percent less relative to fiscal 2024, while shuffling the remaining funds to focus on different priorities. For instance, the House and Senate allocated $874 million (+8.7 percent) for the agency's heliophysics work; planetary sciences, which oversees missions like New Horizons, was cut to $2.5 billion (-6.5 percent) compared to 2024. At the same time, NASA's STEM engagement office, which the president proposed eliminating, escaped unscathed with its funding maintained at parity.\"It's almost everything we had been asking for, and it's very encouraging to see a House and Senate run by the president's own party agreeing that we need to keep investing in things like NASA science,\" says Casey Dreier, chief of policy at the Planetary Society, a nonprofit founded by Carl Sagan that advocates for the exploration and study of space. \"It contains very clear and direct language that not only is this funding made available to these projects, but that it will be spent on the initiatives that Congress states.\"Lawmakers also rejected Trump's effort to scuttle the Space Launch System after its third flight. NASA's heavy-lift rocket is billions of dollars over budget, but remains — as of now — the only spacecraft ready to ferry astronauts to the Moon. Compared to the rest of NASA, the fate of the SLS was never really in doubt. Senator Ted Cruz (R-TX) secured funding for the rocket as part of Trump's Big Beautiful Bill. \"I've been saying for a long time you should never underestimate the political coalition behind the SLS, and I think that was very much validated this year,\" says Dreier. More importantly, it appears the Goddard Space Flight Center will be safe from further damage. Over the summer, the future of the facility, known for its work on projects like the James Webb Space Telescope, was put in jeopardy. By some estimates, the campus has lost a third of its staff due to workforce cuts, and dozens of buildings, including some 100 laboratories, have been shut down by management. One of the casualties was NASA's largest library, which houses irreplaceable documents chronicling the history of the space race. As part of a \"consolidation\" effort, many of those documents will be thrown out.Under the appropriations bill, the Senate has directed NASA to “preserve all the technical and scientific world-class capabilities at Goddard.” It has also instructed the agency to ensure employees of the Goddard Institute for Space Studies are able to continue their work with \"minimal disruption.\" The New York-based office, one of America's leading climate labs, was sent into limbo last spring after the Trump administration moved to shut it down. The bill also provides a lifeline for NASA's to bring back samples of Martian dirt collected by the Perseverance rover. Congress has effectively cancelled the official program tied to that ambition, the Mars Sample Return (MSR), but has set aside $110 million for the agency to continue developing technologies for future science missions to the Red Planet. MSR advocates have argued the mission could lead to significant scientific discoveries, but Dreier notes the program was \"ripe for cancellation\" after it became mired in mismanagement. \"I worry MSR now has this stink of bloat, excess cost and threat of overruns that are really going to make it challenging to restart this without having a dramatically different approach,\" says Dreier, adding that deciding what to do with mission will likely be top of mind for the agency's new administrator, Jared Isaacman. The 2026 budget leaves NASA with fewer resources. Even in areas where Congress allocated the same amount of funds as it did in 2024, the agency will need to do more with less due to inflation. Compared to the absolute blood bath that would have been Trump's proposed budget, a marginal funding cut is the best case scenario given the circumstances, but the circumstances remain less than ideal. \"There will be another presidential budget request coming out in the next couple of months,\" Dreier said. \"They could do this all over again if they wanted to.\"In the immediate future, NASA and its employees are at least protected from the potential fallout of another impending government shutdown. Congress has until January 30 to fully fund the federal government, and as of earlier this week, it has yet to find a way forward on appropriations for agencies like the Department of Labor. Correction 9:05PM ET: A previous version of this article incorrectly stated Casey Dreier’s surename as Drier. We regret the error. This article originally appeared on Engadget at https://www.engadget.com/science/space/senate-passes-minibus-bill-funding-nasa-rejecting-trumps-proposed-cuts-231605536.html?src=rss",
          "feed_position": 4
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/flaw-in-17-google-fast-pair-audio-devices-could-let-hackers-eavesdrop-194613456.html",
          "published_at": "Thu, 15 Jan 2026 19:46:13 +0000",
          "title": "Flaw in 17 Google Fast Pair audio devices could let hackers eavesdrop",
          "standfirst": "Now would be a good time to update all your Bluetooth audio devices. On Thursday, Wired reported on a security flaw in 17 headphone and speaker models that could allow hackers to access your devices, including their microphones. The vulnerability stems from a faulty implementation of Google's one-tap (Fast Pair) protocol.Security researchers at Belgium's KU Leuven University Computer Security and Industrial Cryptography group, who discovered the security hole, named the flaw WhisperPair. They say a hacker within Bluetooth range would only require the accessory's (easily attainable) device model number and a few seconds.\"You're walking down the street with your headphones on, you're listening to some music. In less than 15 seconds, we can hijack your device,\" KU Leuven researcher Sayon Duttagupta told Wired. \"Which means that I can turn on the microphone and listen to your ambient sound. I can inject audio. I can track your location.\" The researchers notified Google about WhisperPair in August, and the company has been working with them since then.Fast Pair is supposed to only allow new connections while the audio device is in pairing mode. (A proper implementation of this would have prevented this flaw.) But a Google spokesperson told Engadget that the vulnerability stemmed from an improper implementation of Fast Pair by some of its hardware partners. This could then allow a hacker's device to pair with your headphones or speaker after it's already paired with your device.\"We appreciate collaborating with security researchers through our Vulnerability Rewards Program, which helps keep our users safe,\" a Google spokesperson wrote in a statement sent to Engadget. \"We worked with these researchers to fix these vulnerabilities, and we have not seen evidence of any exploitation outside of this report's lab setting. As a best security practice, we recommend users check their headphones for the latest firmware updates. We are constantly evaluating and enhancing Fast Pair and Find Hub security.\"The researchers created the video below to demonstrate how the flaw worksIn an email to Engadget, Google said the steps required to access the device’s microphone or audio are complex and involve multiple stages. The attackers would also need to remain within Bluetooth range. The company added that it provided its OEM partners with recommended fixes in September. Google also updated its Validator certification tool and its certification requirements.The researchers say that, in some cases, the risk applies even to those who don't use Android phones. For example, if the audio accessory has never been paired with a Google account, a hacker could use WhisperPair to not only pair with the audio device but also link it to their own Google account. They could then use Google's Find Hub tool to track the device's (and therefore your) location.Google said it rolled out a fix to its Find Hub network to address that particular scenario. However, the researchers told Wired that, within hours of the patch’s rollout, they found a workaround.The 17 affected devices are made by 10 different companies, all of which received Google Fast Pair certification. They include Sony, Jabra, JBL, Marshall, Xiaomi, Nothing, OnePlus, Soundcore, Logitech and Google. (Google says its affected Pixel Buds are already patched and protected.) The researchers posted a search tool that lets you see if your audio accessories are vulnerable.In a statement sent to Engadget, OnePlus said it's investigating the issue and \"will take appropriate action to protect our users' security and privacy.\" We also contacted the other accessory makers and will update this story if we hear back.The researchers recommend updating your audio devices regularly. However, one of their concerns is that many people will never install the third-party manufacturer's app (required for updates), leaving their devices vulnerable.The full report from Wired has much more detail and is worth a read.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/flaw-in-17-google-fast-pair-audio-devices-could-let-hackers-eavesdrop-194613456.html?src=rss",
          "content": "Now would be a good time to update all your Bluetooth audio devices. On Thursday, Wired reported on a security flaw in 17 headphone and speaker models that could allow hackers to access your devices, including their microphones. The vulnerability stems from a faulty implementation of Google's one-tap (Fast Pair) protocol.Security researchers at Belgium's KU Leuven University Computer Security and Industrial Cryptography group, who discovered the security hole, named the flaw WhisperPair. They say a hacker within Bluetooth range would only require the accessory's (easily attainable) device model number and a few seconds.\"You're walking down the street with your headphones on, you're listening to some music. In less than 15 seconds, we can hijack your device,\" KU Leuven researcher Sayon Duttagupta told Wired. \"Which means that I can turn on the microphone and listen to your ambient sound. I can inject audio. I can track your location.\" The researchers notified Google about WhisperPair in August, and the company has been working with them since then.Fast Pair is supposed to only allow new connections while the audio device is in pairing mode. (A proper implementation of this would have prevented this flaw.) But a Google spokesperson told Engadget that the vulnerability stemmed from an improper implementation of Fast Pair by some of its hardware partners. This could then allow a hacker's device to pair with your headphones or speaker after it's already paired with your device.\"We appreciate collaborating with security researchers through our Vulnerability Rewards Program, which helps keep our users safe,\" a Google spokesperson wrote in a statement sent to Engadget. \"We worked with these researchers to fix these vulnerabilities, and we have not seen evidence of any exploitation outside of this report's lab setting. As a best security practice, we recommend users check their headphones for the latest firmware updates. We are constantly evaluating and enhancing Fast Pair and Find Hub security.\"The researchers created the video below to demonstrate how the flaw worksIn an email to Engadget, Google said the steps required to access the device’s microphone or audio are complex and involve multiple stages. The attackers would also need to remain within Bluetooth range. The company added that it provided its OEM partners with recommended fixes in September. Google also updated its Validator certification tool and its certification requirements.The researchers say that, in some cases, the risk applies even to those who don't use Android phones. For example, if the audio accessory has never been paired with a Google account, a hacker could use WhisperPair to not only pair with the audio device but also link it to their own Google account. They could then use Google's Find Hub tool to track the device's (and therefore your) location.Google said it rolled out a fix to its Find Hub network to address that particular scenario. However, the researchers told Wired that, within hours of the patch’s rollout, they found a workaround.The 17 affected devices are made by 10 different companies, all of which received Google Fast Pair certification. They include Sony, Jabra, JBL, Marshall, Xiaomi, Nothing, OnePlus, Soundcore, Logitech and Google. (Google says its affected Pixel Buds are already patched and protected.) The researchers posted a search tool that lets you see if your audio accessories are vulnerable.In a statement sent to Engadget, OnePlus said it's investigating the issue and \"will take appropriate action to protect our users' security and privacy.\" We also contacted the other accessory makers and will update this story if we hear back.The researchers recommend updating your audio devices regularly. However, one of their concerns is that many people will never install the third-party manufacturer's app (required for updates), leaving their devices vulnerable.The full report from Wired has much more detail and is worth a read.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/flaw-in-17-google-fast-pair-audio-devices-could-let-hackers-eavesdrop-194613456.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/claude-code-just-got-updated-with-one-of-the-most-requested-user-features",
          "published_at": "Thu, 15 Jan 2026 19:37:00 GMT",
          "title": "Claude Code just got updated with one of the most-requested user features",
          "standfirst": "Anthropic&#x27;s open source standard, the Model Context Protocol (MCP), released in late 2024, allows users to connect AI models and the agents atop them to external tools in a structured, reliable format. It is the engine behind Anthropic&#x27;s hit AI agentic programming harness, Claude Code, allowing it to access numerous functions like web browsing and file creation immediately when asked.But there was one problem: Claude Code typically had to \"read\" the instruction manual for every single tool available, regardless of whether it was needed for the immediate task, using up the available context that could otherwise be filled with more information from the user&#x27;s prompts or the agent&#x27;s responses.At least until last night. The Claude Code team released an update that fundamentally alters this equation. Dubbed MCP Tool Search, the feature introduces \"lazy loading\" for AI tools, allowing agents to dynamically fetch tool definitions only when necessary. It is a shift that moves AI agents from a brute-force architecture to something resembling modern software engineering—and according to early data, it effectively solves the \"bloat\" problem that was threatening to stifle the ecosystem.The &#x27;Startup Tax&#x27; on AgentsTo understand the significance of Tool Search, one must understand the friction of the previous system. The Model Context Protocol (MCP), released in 2024 by Anthropic as an open source standard was designed to be a universal standard for connecting AI models to data sources and tools—everything from GitHub repositories to local file systems.However, as the ecosystem grew, so did the \"startup tax.\"Thariq Shihipar, a member of the technical staff at Anthropic, highlighted the scale of the problem in the announcement.\"We&#x27;ve found that MCP servers may have up to 50+ tools,\" Shihipar wrote. \"Users were documenting setups with 7+ servers consuming 67k+ tokens.\"In practical terms, this meant a developer using a robust set of tools might sacrifice 33% or more of their available context window limit of 200,000 tokens before they even typed a single character of a prompt, as AI newsletter author Aakash Gupta pointed out in a post on X.The model was effectively \"reading\" hundreds of pages of technical documentation for tools it might never use during that session.Community analysis provided even starker examples. Gupta further noted that a single Docker MCP server could consume 125,000 tokens just to define its 135 tools.\"The old constraint forced a brutal tradeoff,\" he wrote. \"Either limit your MCP servers to 2-3 core tools, or accept that half your context budget disappears before you start working.\"How Tool Search WorksThe solution Anthropic rolled out — which Shihipar called \"one of our most-requested features on GitHub\" — is elegant in its restraint. Instead of preloading every definition, Claude Code now monitors context usage.According to the release notes, the system automatically detects when tool descriptions would consume more than 10% of the available context. When that threshold is crossed, the system switches strategies. Instead of dumping raw documentation into the prompt, it loads a lightweight search index.When the user asks for a specific action—say, \"deploy this container\"—Claude Code doesn&#x27;t scan a massive, pre-loaded list of 200 commands. Instead, it queries the index, finds the relevant tool definition, and pulls only that specific tool into the context.\"Tool Search flips the architecture,\" Gupta analyzed. \"The token savings are dramatic: from ~134k to ~5k in Anthropic’s internal testing. That’s an 85% reduction while maintaining full tool access.\"For developers maintaining MCP servers, this shifts the optimization strategy. Shihipar noted that the `server instructions` field in the MCP definition—previously a \"nice to have\"—is now critical. It acts as the metadata that helps Claude \"know when to search for your tools, similar to skills.\"&#x27;Lazy Loading&#x27; and Accuracy GainsWhile the token savings are the headline metric—saving money and memory is always popular—the secondary effect of this update might be more important: focus.LLMs are notoriously sensitive to \"distraction.\" When a model&#x27;s context window is stuffed with thousands of lines of irrelevant tool definitions, its ability to reason decreases. It creates a \"needle in a haystack\" problem where the model struggles to differentiate between similar commands, such as `notification-send-user` versus `notification-send-channel`.Boris Cherny, Head of Claude Code, emphasized this in his reaction to the launch on X: \"Every Claude Code user just got way more context, better instruction following, and the ability to plug in even more tools.\"The data backs this up. Internal benchmarks shared by the community indicate that enabling Tool Search improved the accuracy of the Opus 4 model on MCP evaluations from 49% to 74%. For the newer Opus 4.5, accuracy jumped from 79.5% to 88.1%.By removing the noise of hundreds of unused tools, the model can dedicate its \"attention\" mechanisms to the user&#x27;s actual query and the relevant active tools.Maturing the StackThis update signals a maturation in how we treat AI infrastructure. In the early days of any software paradigm, brute force is common. But as systems scale, efficiency becomes the primary engineering challenge.Aakash Gupta drew a parallel to the evolution of Integrated Development Environments (IDEs) like VSCode or JetBrains. \"The bottleneck wasn’t &#x27;too many tools.&#x27; It was loading tool definitions like 2020-era static imports instead of 2024-era lazy loading,\" he wrote. \"VSCode doesn’t load every extension at startup. JetBrains doesn’t inject every plugin’s docs into memory.\"By adopting \"lazy loading\"—a standard best practice in web and software development—Anthropic is acknowledging that AI agents are no longer just novelties; they are complex software platforms that require architectural discipline.Implications for the EcosystemFor the end user, this update is seamless: Claude Code simply feels \"smarter\" and retains more memory of the conversation. But for the developer ecosystem, it opens the floodgates.Previously, there was a \"soft cap\" on how capable an agent could be. Developers had to curate their toolsets carefully to avoid lobotomizing the model with excessive context. With Tool Search, that ceiling is effectively removed. An agent can theoretically have access to thousands of tools—database connectors, cloud deployment scripts, API wrappers, local file manipulators—without paying a penalty until those tools are actually touched.It turns the \"context economy\" from a scarcity model into an access model. As Gupta summarized, \"They’re not just optimizing context usage. They’re changing what ‘tool-rich agents’ can mean.\"The update is rolling out immediately for Claude Code users. For developers building MCP clients, Anthropic recommends implementing the `ToolSearchTool` to support this dynamic loading, ensuring that as the agentic future arrives, it doesn&#x27;t run out of memory before it even says hello.",
          "content": "Anthropic&#x27;s open source standard, the Model Context Protocol (MCP), released in late 2024, allows users to connect AI models and the agents atop them to external tools in a structured, reliable format. It is the engine behind Anthropic&#x27;s hit AI agentic programming harness, Claude Code, allowing it to access numerous functions like web browsing and file creation immediately when asked.But there was one problem: Claude Code typically had to \"read\" the instruction manual for every single tool available, regardless of whether it was needed for the immediate task, using up the available context that could otherwise be filled with more information from the user&#x27;s prompts or the agent&#x27;s responses.At least until last night. The Claude Code team released an update that fundamentally alters this equation. Dubbed MCP Tool Search, the feature introduces \"lazy loading\" for AI tools, allowing agents to dynamically fetch tool definitions only when necessary. It is a shift that moves AI agents from a brute-force architecture to something resembling modern software engineering—and according to early data, it effectively solves the \"bloat\" problem that was threatening to stifle the ecosystem.The &#x27;Startup Tax&#x27; on AgentsTo understand the significance of Tool Search, one must understand the friction of the previous system. The Model Context Protocol (MCP), released in 2024 by Anthropic as an open source standard was designed to be a universal standard for connecting AI models to data sources and tools—everything from GitHub repositories to local file systems.However, as the ecosystem grew, so did the \"startup tax.\"Thariq Shihipar, a member of the technical staff at Anthropic, highlighted the scale of the problem in the announcement.\"We&#x27;ve found that MCP servers may have up to 50+ tools,\" Shihipar wrote. \"Users were documenting setups with 7+ servers consuming 67k+ tokens.\"In practical terms, this meant a developer using a robust set of tools might sacrifice 33% or more of their available context window limit of 200,000 tokens before they even typed a single character of a prompt, as AI newsletter author Aakash Gupta pointed out in a post on X.The model was effectively \"reading\" hundreds of pages of technical documentation for tools it might never use during that session.Community analysis provided even starker examples. Gupta further noted that a single Docker MCP server could consume 125,000 tokens just to define its 135 tools.\"The old constraint forced a brutal tradeoff,\" he wrote. \"Either limit your MCP servers to 2-3 core tools, or accept that half your context budget disappears before you start working.\"How Tool Search WorksThe solution Anthropic rolled out — which Shihipar called \"one of our most-requested features on GitHub\" — is elegant in its restraint. Instead of preloading every definition, Claude Code now monitors context usage.According to the release notes, the system automatically detects when tool descriptions would consume more than 10% of the available context. When that threshold is crossed, the system switches strategies. Instead of dumping raw documentation into the prompt, it loads a lightweight search index.When the user asks for a specific action—say, \"deploy this container\"—Claude Code doesn&#x27;t scan a massive, pre-loaded list of 200 commands. Instead, it queries the index, finds the relevant tool definition, and pulls only that specific tool into the context.\"Tool Search flips the architecture,\" Gupta analyzed. \"The token savings are dramatic: from ~134k to ~5k in Anthropic’s internal testing. That’s an 85% reduction while maintaining full tool access.\"For developers maintaining MCP servers, this shifts the optimization strategy. Shihipar noted that the `server instructions` field in the MCP definition—previously a \"nice to have\"—is now critical. It acts as the metadata that helps Claude \"know when to search for your tools, similar to skills.\"&#x27;Lazy Loading&#x27; and Accuracy GainsWhile the token savings are the headline metric—saving money and memory is always popular—the secondary effect of this update might be more important: focus.LLMs are notoriously sensitive to \"distraction.\" When a model&#x27;s context window is stuffed with thousands of lines of irrelevant tool definitions, its ability to reason decreases. It creates a \"needle in a haystack\" problem where the model struggles to differentiate between similar commands, such as `notification-send-user` versus `notification-send-channel`.Boris Cherny, Head of Claude Code, emphasized this in his reaction to the launch on X: \"Every Claude Code user just got way more context, better instruction following, and the ability to plug in even more tools.\"The data backs this up. Internal benchmarks shared by the community indicate that enabling Tool Search improved the accuracy of the Opus 4 model on MCP evaluations from 49% to 74%. For the newer Opus 4.5, accuracy jumped from 79.5% to 88.1%.By removing the noise of hundreds of unused tools, the model can dedicate its \"attention\" mechanisms to the user&#x27;s actual query and the relevant active tools.Maturing the StackThis update signals a maturation in how we treat AI infrastructure. In the early days of any software paradigm, brute force is common. But as systems scale, efficiency becomes the primary engineering challenge.Aakash Gupta drew a parallel to the evolution of Integrated Development Environments (IDEs) like VSCode or JetBrains. \"The bottleneck wasn’t &#x27;too many tools.&#x27; It was loading tool definitions like 2020-era static imports instead of 2024-era lazy loading,\" he wrote. \"VSCode doesn’t load every extension at startup. JetBrains doesn’t inject every plugin’s docs into memory.\"By adopting \"lazy loading\"—a standard best practice in web and software development—Anthropic is acknowledging that AI agents are no longer just novelties; they are complex software platforms that require architectural discipline.Implications for the EcosystemFor the end user, this update is seamless: Claude Code simply feels \"smarter\" and retains more memory of the conversation. But for the developer ecosystem, it opens the floodgates.Previously, there was a \"soft cap\" on how capable an agent could be. Developers had to curate their toolsets carefully to avoid lobotomizing the model with excessive context. With Tool Search, that ceiling is effectively removed. An agent can theoretically have access to thousands of tools—database connectors, cloud deployment scripts, API wrappers, local file manipulators—without paying a penalty until those tools are actually touched.It turns the \"context economy\" from a scarcity model into an access model. As Gupta summarized, \"They’re not just optimizing context usage. They’re changing what ‘tool-rich agents’ can mean.\"The update is rolling out immediately for Claude Code users. For developers building MCP clients, Anthropic recommends implementing the `ToolSearchTool` to support this dynamic loading, ensuring that as the agentic future arrives, it doesn&#x27;t run out of memory before it even says hello.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2O6Qr56XqUqVJ0oxVIN0iL/cbac7e02f806b97695bbc4df6b6fe226/Gemini_Generated_Image_autofiautofiauto.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/why-mongodb-thinks-better-retrieval-not-bigger-models-is-the-key-to",
          "published_at": "Thu, 15 Jan 2026 18:00:00 GMT",
          "title": "Why MongoDB thinks better retrieval — not bigger models — is the key to trustworthy enterprise AI",
          "standfirst": "Agentic systems and enterprise search depend on strong data retrieval that works efficiently and accurately. Database provider MongoDB thinks its newest embeddings models help solve falling retrieval quality as more AI systems go into production.As agentic and RAG systems move into production, retrieval quality is emerging as a quiet failure point — one that can undermine accuracy, cost, and user trust even when models themselves perform well.The company launched four new versions of its embeddings and reranking models. Voyage 4 will be available in four modes: voyage-4 embedding, voyage-4-large, voyage-4-lite, and voyage-4-nano. MongoDB said the voyage-4 embedding serves as its general-purpose model; MongoDB considers Voyage-4-large its flagship model. Voyage-4-lite focuses on tasks requiring little latency and lower costs, and voyage-4-nano is intended for more local development and testing environments or for on-device data retrieval. Voyage-4-nano is also MongoDB’s first open-weight model. All models are available via an API and on MongoDB’s Atlas platform. The company said the models outperform similar models from Google and Cohere on the RTEB benchmark. Hugging Face’s RTEB benchmark puts Voyage 4 as the top embedding model. “Embedding models are one of those invisible choices that can really make or break AI experiences,” Frank Liu, product manager at MongoDB, said in a briefing. “You get them wrong, your search results will feel pretty random and shallow, but if you get them right, your application suddenly feels like it understands your users and your data.”He added that the goal of the Voyage 4 models is to improve the retrieval of real-world data, which often collapses once agentic and RAG pipelines go into production. MongoDB also released a new multimodal embedding model, voyage-multimodal-3.5, that can handle documents that include text, images, and video. This model vectorizes the data and extracts semantic meaning from the tables, graphics, figures, and slides typically found in enterprise documents.Enterprise’s embeddings problemsFor enterprises, an agentic system is only as good as its ability to reliably retrieve the right information at the right time. This requirement becomes harder as workloads scale and context windows fragment.Several model providers target that layer of agentic AI. Google’s Gemini Embedding model topped the embedding leaderboards, and Cohere launched its Embed 4 multimodal model, which processes documents more than 200 pages long. Mistral said its coding-embedding model, Codestral Embedding, outperforms Cohere, Google, and even MongoDB’s Voyage Code 3. MongoDB argues that benchmark performance alone doesn’t address the operational complexity enterprises face in production.MongoDB said many clients have found that their data stacks cannot handle context-aware, retrieval-intensive workloads in production. The company said it&#x27;s seeing more fragmentation with enterprises having to stitch together different solutions to connect databases with a retrieval or reranking model. To help customers who don’t want fragmented solutions, the company is offering its models through a single data platform, Atlas. MongoDB’s bet is that retrieval can’t be treated as a loose collection of best-of-breed components anymore. For enterprise agents to work reliably at scale, embeddings, reranking, and the data layer need to operate as a tightly integrated system rather than a stitched-together stack.",
          "content": "Agentic systems and enterprise search depend on strong data retrieval that works efficiently and accurately. Database provider MongoDB thinks its newest embeddings models help solve falling retrieval quality as more AI systems go into production.As agentic and RAG systems move into production, retrieval quality is emerging as a quiet failure point — one that can undermine accuracy, cost, and user trust even when models themselves perform well.The company launched four new versions of its embeddings and reranking models. Voyage 4 will be available in four modes: voyage-4 embedding, voyage-4-large, voyage-4-lite, and voyage-4-nano. MongoDB said the voyage-4 embedding serves as its general-purpose model; MongoDB considers Voyage-4-large its flagship model. Voyage-4-lite focuses on tasks requiring little latency and lower costs, and voyage-4-nano is intended for more local development and testing environments or for on-device data retrieval. Voyage-4-nano is also MongoDB’s first open-weight model. All models are available via an API and on MongoDB’s Atlas platform. The company said the models outperform similar models from Google and Cohere on the RTEB benchmark. Hugging Face’s RTEB benchmark puts Voyage 4 as the top embedding model. “Embedding models are one of those invisible choices that can really make or break AI experiences,” Frank Liu, product manager at MongoDB, said in a briefing. “You get them wrong, your search results will feel pretty random and shallow, but if you get them right, your application suddenly feels like it understands your users and your data.”He added that the goal of the Voyage 4 models is to improve the retrieval of real-world data, which often collapses once agentic and RAG pipelines go into production. MongoDB also released a new multimodal embedding model, voyage-multimodal-3.5, that can handle documents that include text, images, and video. This model vectorizes the data and extracts semantic meaning from the tables, graphics, figures, and slides typically found in enterprise documents.Enterprise’s embeddings problemsFor enterprises, an agentic system is only as good as its ability to reliably retrieve the right information at the right time. This requirement becomes harder as workloads scale and context windows fragment.Several model providers target that layer of agentic AI. Google’s Gemini Embedding model topped the embedding leaderboards, and Cohere launched its Embed 4 multimodal model, which processes documents more than 200 pages long. Mistral said its coding-embedding model, Codestral Embedding, outperforms Cohere, Google, and even MongoDB’s Voyage Code 3. MongoDB argues that benchmark performance alone doesn’t address the operational complexity enterprises face in production.MongoDB said many clients have found that their data stacks cannot handle context-aware, retrieval-intensive workloads in production. The company said it&#x27;s seeing more fragmentation with enterprises having to stitch together different solutions to connect databases with a retrieval or reranking model. To help customers who don’t want fragmented solutions, the company is offering its models through a single data platform, Atlas. MongoDB’s bet is that retrieval can’t be treated as a loose collection of best-of-breed components anymore. For enterprise agents to work reliably at scale, embeddings, reranking, and the data layer need to operate as a tightly integrated system rather than a stitched-together stack.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3ahIcS5AJ5RCuVRg8hgyxx/86c2a7aa169e87babbfe7f7ffc3700a9/crimedy7_illustration_of_a_robot_poring_through_expense_repor_a03892f6-f441-4dab-a57b-8e664b411198_3.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/samsung-refreshed-mobile-gaming-hub-150010632.html",
          "published_at": "Thu, 15 Jan 2026 15:00:10 +0000",
          "title": "Samsung’s refreshed Mobile Gaming Hub is trying to make it easier to discover new games",
          "standfirst": "During CES 2026, Samsung unveiled plenty of new TVs, monitors and other hardware. However, the company is also looking to expand further into video games and has announced a significant refresh to its Gaming Hub on smartphones. Engadget spoke with Samsung’s Jong Woo, VP of Game Services, who explained that the update will offer more personalized, faster ways to play and place greater emphasis on up-and-coming titles. Now available on Galaxy devices, with further updates planned, the new hub wants to be a more active space for the latest mobile games. \"We believe that gamers want to find new content that is personalized to them,\" said the VP of Samsung Games Services. He continued: \"We want to bring content to users and make it immediately available for them to play. We have instant plays where, through our cloud streaming technology, we can take Android-native games and put them in the cloud, so that when users want to try them, they don't have to go through the friction of downloading them first.” According to Samsung, the mobile Gaming Hub attracts over 160 million users across smartphones and other devices. However, the VP of Game Services at Samsung believes that, despite the vast library of games across many genres available to mobile users, \"mobile game discovery is broken.\" Samsung Initially, the mobile Gaming Hub was a supplemental app for all purchased games, allowing users to track their collection. With this update, all games purchased from both Google Play and the Galaxy Store are stored in the Gaming Hub. It's designed to be a single place for players to view their owned games, find recommendations, access cloud streaming for select games and even watch highlights from content creators. According to Woo, the larger goal of the new Samsung mobile Gaming Hub is to personalize and guide the mobile gaming experience for players, which has remained nebulous compared with gaming discovery experiences on PC and consoles. “We're getting a lot of feedback from the users, a lot of it from focus testing and beta testing, and what we're finding is that we believe we are solving pain points for mobile gamers,\" said Woo about rebuilding the Gaming Hub. \"We're getting an idea of gamer preferences at the individual, personalized level. Based on all of that, we're able to provide different types of recommendations.\" Another reason for the new changes to the Samsung Gaming Hub was to help foster a community for mobile gamers, including players and developers. In addition to sharing YouTube videos and content from gaming creators and streamers, the company plans to add more social elements to the Gaming Hub to make mobile gaming feel more active and less isolating. \"Mobile is a very personal experience, right? It's your personal device, and oftentimes when you play games on mobile, it feels like a solitary experience,” said Woo. Currently, the revamped Mobile Gaming Hub is only available for Galaxy smartphones and tablets. Users on non-Galaxy devices will still use the previous version of the Gaming Hub, for now. Compared with PC and console online hubs like Steam and PlayStation Network, it's clear that mobile platforms are still figuring out how to create an equally compelling space for engagement. Even with the vast user base, mobile game hubs tend to be a go-between for users to get to the products. There's more work to do, but the new Gaming Hub could be the first step in the right direction.This article originally appeared on Engadget at https://www.engadget.com/gaming/samsung-refreshed-mobile-gaming-hub-150010632.html?src=rss",
          "content": "During CES 2026, Samsung unveiled plenty of new TVs, monitors and other hardware. However, the company is also looking to expand further into video games and has announced a significant refresh to its Gaming Hub on smartphones. Engadget spoke with Samsung’s Jong Woo, VP of Game Services, who explained that the update will offer more personalized, faster ways to play and place greater emphasis on up-and-coming titles. Now available on Galaxy devices, with further updates planned, the new hub wants to be a more active space for the latest mobile games. \"We believe that gamers want to find new content that is personalized to them,\" said the VP of Samsung Games Services. He continued: \"We want to bring content to users and make it immediately available for them to play. We have instant plays where, through our cloud streaming technology, we can take Android-native games and put them in the cloud, so that when users want to try them, they don't have to go through the friction of downloading them first.” According to Samsung, the mobile Gaming Hub attracts over 160 million users across smartphones and other devices. However, the VP of Game Services at Samsung believes that, despite the vast library of games across many genres available to mobile users, \"mobile game discovery is broken.\" Samsung Initially, the mobile Gaming Hub was a supplemental app for all purchased games, allowing users to track their collection. With this update, all games purchased from both Google Play and the Galaxy Store are stored in the Gaming Hub. It's designed to be a single place for players to view their owned games, find recommendations, access cloud streaming for select games and even watch highlights from content creators. According to Woo, the larger goal of the new Samsung mobile Gaming Hub is to personalize and guide the mobile gaming experience for players, which has remained nebulous compared with gaming discovery experiences on PC and consoles. “We're getting a lot of feedback from the users, a lot of it from focus testing and beta testing, and what we're finding is that we believe we are solving pain points for mobile gamers,\" said Woo about rebuilding the Gaming Hub. \"We're getting an idea of gamer preferences at the individual, personalized level. Based on all of that, we're able to provide different types of recommendations.\" Another reason for the new changes to the Samsung Gaming Hub was to help foster a community for mobile gamers, including players and developers. In addition to sharing YouTube videos and content from gaming creators and streamers, the company plans to add more social elements to the Gaming Hub to make mobile gaming feel more active and less isolating. \"Mobile is a very personal experience, right? It's your personal device, and oftentimes when you play games on mobile, it feels like a solitary experience,” said Woo. Currently, the revamped Mobile Gaming Hub is only available for Galaxy smartphones and tablets. Users on non-Galaxy devices will still use the previous version of the Gaming Hub, for now. Compared with PC and console online hubs like Steam and PlayStation Network, it's clear that mobile platforms are still figuring out how to create an equally compelling space for engagement. Even with the vast user base, mobile game hubs tend to be a go-between for users to get to the products. There's more work to do, but the new Gaming Hub could be the first step in the right direction.This article originally appeared on Engadget at https://www.engadget.com/gaming/samsung-refreshed-mobile-gaming-hub-150010632.html?src=rss",
          "feed_position": 18,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/963273a0-f211-11f0-bffa-698d12cdda28"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/robloxs-age-verification-system-is-reportedly-a-trainwreck-220320016.html",
          "published_at": "Thu, 15 Jan 2026 14:52:58 +0000",
          "title": "Roblox's age verification system is reportedly a trainwreck",
          "standfirst": "Roblox's age-verification system was designed as a response to allegations it has a child predator problem. Less than a week in, how's it going? Well, Wired reported on Tuesday that, in some cases, it's classifying children as adults and adults as children. So, not so great!Last week, Roblox made age verification mandatory for anyone using the platform's chat feature. That process involves either submitting a facial age estimate via selfie or (optionally for anyone 13 or older) uploading a government ID check. After verifying, you can only chat with groups of players around your age.The move came after reports grew of predators using the platform to groom young children. That, in turn, led to lawsuits from Louisiana, Texas and Kentucky. Meanwhile, Florida's attorney general has issued criminal subpoenas.So, it might not be hyperbole to say Roblox's survival could depend on how it handles this problem. It isn't exactly off to a hot start. There are reports of a 23-year-old being misidentified as a 16- to 17-year-old. (\"I don't want to be chatting with fucking children,\" they said.) Another report claimed an 18-year-old was placed in the 13 to 15 range.But the problem is happening in reverse, too. Online videos show children spoofing the system into believing they were adults by using avatar images. One clever kid drew wrinkles and stubble on his face and was instantly deemed 21+. Another flashed a photo of Kurt Cobain and got an adult classification.The feature isn't working as planned, to say the least.RobloxIn addition, Roblox posted last week that some parents were providing age checks on behalf of their children, leading to their children being placed in the 21+ category. The company said it's \"working on solutions to address\" that particular problem and will share more soon.Roblox shared the following statement from Matt Kaufman, the company’s Chief Safety Officer:“To suggest that our age check technology isn't working is a fundamental misunderstanding of what it takes to shift safety at scale. With a global community of over 150 million daily active users, we are pleased with where we are in the roll out process. It’s a process that will take time, you can’t flip a switch while building something that hasn’t existed before. Tens of millions of users have already completed the process, proving that the vast majority of our community values a safer, more age-appropriate environment. Expecting the system to be flawless overnight is ignoring the scale of this undertaking. We’ve already shared updates with our creator community to make this a smoother transition. This technology is the foundation of a new gold standard that limits communication between adults and minors by default. We are building for the next decade of the internet, not the next news cycle. We will continue to innovate, continue to require age checks, and continue to lead the industry where others have been too hesitant to go.”Developers with games on Roblox are upset. The platform's dev forum includes thousands of negative comments about the updates, with many of them wanting the entire update reversed. One shared a graph showing that the percentage using the chat feature dropped from around 90 percent to 36.5 percent.Where does this leave Roblox? Well, with some developers describing games on the platform as feeling \"lifeless\" or like \"a total ghost town,\" the company has its hands full. It will have to figure out how to balance its priorities of keeping predators out without breaking things for everyone else. The full report from Wired is worth a read.Update, January 15, 2026, 9:52AM ET: This story has been updated to include a statement from Roblox.This article originally appeared on Engadget at https://www.engadget.com/gaming/robloxs-age-verification-system-is-reportedly-a-trainwreck-220320016.html?src=rss",
          "content": "Roblox's age-verification system was designed as a response to allegations it has a child predator problem. Less than a week in, how's it going? Well, Wired reported on Tuesday that, in some cases, it's classifying children as adults and adults as children. So, not so great!Last week, Roblox made age verification mandatory for anyone using the platform's chat feature. That process involves either submitting a facial age estimate via selfie or (optionally for anyone 13 or older) uploading a government ID check. After verifying, you can only chat with groups of players around your age.The move came after reports grew of predators using the platform to groom young children. That, in turn, led to lawsuits from Louisiana, Texas and Kentucky. Meanwhile, Florida's attorney general has issued criminal subpoenas.So, it might not be hyperbole to say Roblox's survival could depend on how it handles this problem. It isn't exactly off to a hot start. There are reports of a 23-year-old being misidentified as a 16- to 17-year-old. (\"I don't want to be chatting with fucking children,\" they said.) Another report claimed an 18-year-old was placed in the 13 to 15 range.But the problem is happening in reverse, too. Online videos show children spoofing the system into believing they were adults by using avatar images. One clever kid drew wrinkles and stubble on his face and was instantly deemed 21+. Another flashed a photo of Kurt Cobain and got an adult classification.The feature isn't working as planned, to say the least.RobloxIn addition, Roblox posted last week that some parents were providing age checks on behalf of their children, leading to their children being placed in the 21+ category. The company said it's \"working on solutions to address\" that particular problem and will share more soon.Roblox shared the following statement from Matt Kaufman, the company’s Chief Safety Officer:“To suggest that our age check technology isn't working is a fundamental misunderstanding of what it takes to shift safety at scale. With a global community of over 150 million daily active users, we are pleased with where we are in the roll out process. It’s a process that will take time, you can’t flip a switch while building something that hasn’t existed before. Tens of millions of users have already completed the process, proving that the vast majority of our community values a safer, more age-appropriate environment. Expecting the system to be flawless overnight is ignoring the scale of this undertaking. We’ve already shared updates with our creator community to make this a smoother transition. This technology is the foundation of a new gold standard that limits communication between adults and minors by default. We are building for the next decade of the internet, not the next news cycle. We will continue to innovate, continue to require age checks, and continue to lead the industry where others have been too hesitant to go.”Developers with games on Roblox are upset. The platform's dev forum includes thousands of negative comments about the updates, with many of them wanting the entire update reversed. One shared a graph showing that the percentage using the chat feature dropped from around 90 percent to 36.5 percent.Where does this leave Roblox? Well, with some developers describing games on the platform as feeling \"lifeless\" or like \"a total ghost town,\" the company has its hands full. It will have to figure out how to balance its priorities of keeping predators out without breaking things for everyone else. The full report from Wired is worth a read.Update, January 15, 2026, 9:52AM ET: This story has been updated to include a statement from Roblox.This article originally appeared on Engadget at https://www.engadget.com/gaming/robloxs-age-verification-system-is-reportedly-a-trainwreck-220320016.html?src=rss",
          "feed_position": 19,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/EN_Age_Check_Flow_1_9823.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/nba-league-pass-subscriptions-are-up-to-55-percent-off-right-now-163421756.html",
          "published_at": "Thu, 15 Jan 2026 14:05:38 +0000",
          "title": "NBA League Pass subscriptions are up to 55 percent off right now",
          "standfirst": "Basketball fans can save on NBA League Pass right now, which lets you catch a bunch of out-of-market NBA games via streaming. The League Pass Premium subscription is on sale for $75, down from the usual $160, and League Pass Standard is marked down to $50 from $110. Considering we're almost halfway though the season, the discount makes sense and is a good deal for anyone who wants to keep a close eye on the rest of the games to be played this year. The Standard plan includes commercials and support for only one device at a time, while the Premium tier offers no commercials, in-arena streams during breaks in the game, offline viewing of full games and concurrent streams on up to three devices at once. Last year, League Pass added multiview, which allows you to view up to four games at once on a single screen. This is included across both subscription tiers. The service also added a smart rewind tool that automatically selects key highlights and plays from each game. Outside the US and Canada, League Pass carries every single NBA game live, but within these countries a bevy of restrictions apply. In the US, any games being shown on your regional sports network will be blacked out as the service is meant for out-of-market games only. Also, any nationally broadcast games will not be available live, but instead will be available for on-demand viewing at 6AM ET the following day. The service is only for regular-season games. If you're an avid NBA fan that follows multiple teams then the League Pass almost certainly carries dozens of games you can watch even with the restrictions in the US. Subscribers can get a list of applicable blackouts by entering their ZIP code before signing up. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/nba-league-pass-subscriptions-are-up-to-55-percent-off-right-now-163421756.html?src=rss",
          "content": "Basketball fans can save on NBA League Pass right now, which lets you catch a bunch of out-of-market NBA games via streaming. The League Pass Premium subscription is on sale for $75, down from the usual $160, and League Pass Standard is marked down to $50 from $110. Considering we're almost halfway though the season, the discount makes sense and is a good deal for anyone who wants to keep a close eye on the rest of the games to be played this year. The Standard plan includes commercials and support for only one device at a time, while the Premium tier offers no commercials, in-arena streams during breaks in the game, offline viewing of full games and concurrent streams on up to three devices at once. Last year, League Pass added multiview, which allows you to view up to four games at once on a single screen. This is included across both subscription tiers. The service also added a smart rewind tool that automatically selects key highlights and plays from each game. Outside the US and Canada, League Pass carries every single NBA game live, but within these countries a bevy of restrictions apply. In the US, any games being shown on your regional sports network will be blacked out as the service is meant for out-of-market games only. Also, any nationally broadcast games will not be available live, but instead will be available for on-demand viewing at 6AM ET the following day. The service is only for regular-season games. If you're an avid NBA fan that follows multiple teams then the League Pass almost certainly carries dozens of games you can watch even with the restrictions in the US. Subscribers can get a list of applicable blackouts by entering their ZIP code before signing up. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/nba-league-pass-subscriptions-are-up-to-55-percent-off-right-now-163421756.html?src=rss",
          "feed_position": 21
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/valerion-visionmaster-max-projector-review-near-perfect-image-quality-comes-at-a-price-140045939.html",
          "published_at": "Thu, 15 Jan 2026 14:00:45 +0000",
          "title": "Valerion VisionMaster Max projector review: Near-perfect image quality comes at a price",
          "standfirst": "After a widely hyped and successful Kickstarter campaign, Valerion’s 4K VisionMaster Max laser projector has finally arrived. It’s the company’s new flagship model in the VisionMaster series, offering better image quality and more convenience than its other models. However, it’s quite expensive and has some stiff competition from Anker’s Nebula X1 and XGIMI’s Horizon 20 Max. I was eager to see how it compared to those models and if it delivers on Valerion’s promise of “pure cinema.” It does offer better image quality, but the difference isn’t quite enough to justify the big jump in price for most users. Features and design The VisionMaster Max has a classy squarish design with a glossy black finish up front and chrome fins on the side that house two 12W speakers. It’s smaller and fit my decor better than Nebula’s tall, plasticky X1, though to be fair the latter is also designed for outdoor use. The VisionMaster Max has a similar form factor to XGIMI’s Horizon 20 Max, but that model pivots on its stand, while the Valerion uses a kickstand-like support. For setup, the VisionMaster Max is quite flexible. It comes with a 0.9-1.5x optical zoom, so it can be installed between 7.8 and 13 feet away for a 120-inch screen size, which covers a wide range of scenarios. It also features a +/- 105 percent vertical shift option that helps you get an optically perfect screen fit without moving the projector or employing digital “keystone” adjustments that affect picture quality. If that still doesn’t work, you can swap out the included lens with a long-throw 0.9-2.0:1 option once it becomes available. The company has even promised an anamorphic lens for users with CinemaScope screens. Both of those items will be available for purchase separately with the prices yet to be disclosed. Steve Dent for Engadget For my space, I placed the VisionMaster Max on a table about 12 feet from my 120-inch screen and centered it horizontally as there’s no horizontal shift option (it can also be ceiling mounted, of course). Then, I went into the auto-alignment setting, made sure that the projected image was larger than my screen and hit “start alignment” to get a perfect fit to my screen. Though it lacks a motorized lens gimbal like the Nebula X1, the lens shift option provides the same flexibility, so setup was just as easy. For inputs, the VisionMaster Max comes with three HDMI 2.1 ports, including one with eARC for a sound bar, along with S/PDIF optical and 3.5mm audio outputs. Impressively, it includes a gigabit ethernet connection so you can either hardwire it to the internet or connect via Wi-Fi. The VisionMaster Max lacks liquid cooling like the Nebula X1, but Valerion claims a similar fan noise level of 28db. When I compared them side by side, it was only a touch louder than the X1 and not at all bothersome. Google TV is built in for streaming and projector control via the high-quality, partially backlit remote. It provides a large library of apps via Google Play along with a familiar interface. You get certified versions of Netflix, YouTube, Prime Video, Disney+, Max and others, plus Chromecast and AirPlay support, and Google Assistant for voice control. With 4GB of RAM and 128GB of ROM, the software felt a bit more responsive than Google TV on the Nebula X1. Image quality Steve Dent for Engadget The VisionMaster Max has a number of features designed to optimize image quality. It’s one of the few consumer projectors with a dynamic iris and a feature called Enhanced Black Level (EBL) for improved contrast. It uses an RGB triple-laser light source (rated for 25,000 hours) paired with a 0.47-inch DLP chip that projects 1080p natively or 4K video via pixel shifting. This same chip is used on almost every consumer-level 4K projector, but XGIMI’s upcoming Titan Noir Max projector will pack a much larger 0.78-inch DMD chip that should deliver a sharper picture. The VisionMaster Max also supports every HDR format, including Dolby Vision and Samsung’s HDR10+, along with Valerion’s own tone-mapping HDR setting. You can choose from seven picture modes for SDR, eight for HDR, three for Dolby Vision and four for HDR10+. The projector handled most HDR content well, though it occasionally lost detail in extra-bright shots. However, that can largely be fixed using the extensive manual color controls. With all those features, the VisionMaster Max can output 4K 60 fps video at up to 3,500 ANSI lumens with a 50,000:1 contrast ratio, easily besting its main rivals. On top of that, it promises an impressive 110 percent of the Rec.2020 HDR color spectrum, with a delta E (color accuracy) value of less than 0.8 straight out of the box (any delta E less than 2 is undetectable by the human eye). Another key feature is reduction of the rainbow effect that can occur with DLP projectors. After some fine-tuning that’s typically required with new projectors, I was highly impressed with the image quality. Brightness was high enough in “standard” mode to watch content like sports or TV shows without lowering the blinds, and can be increased if you don’t mind compromising color accuracy. When used in ideal conditions like a darkened room, the VisionMaster Max’s image quality is the best of any projector I’ve tested to date. In Filmmaker mode (with the EBL setting enabled), contrast levels are outstanding, with true blacks showing in dark-lit scenes instead of the washed-out greys seen on most projectors. However, I kept the EBL mode at the minimum setting as I noticed it caused some color shifting at the other levels. Dynamic iris projectors can cause excessive “pumping” or sudden changes in light levels, but after adjusting the iris to a medium setting, I saw no signs of that. The famously dark Game of Thrones Night King battle scene was easy to see on the VisionMaster Max. Steve Dent for Engadget Color accuracy is outstanding straight out of the box both in HDR and non-HDR modes, particularly, again in Filmmaker mode. Visually, I couldn’t detect any anomalies when looking at color bars or other charts, though my Calibrite Color Checker told me that the gamut of hues was slightly less than what Valerion claims (under 100 percent of BT.2020). Still, the Max’s high color accuracy allowed me to see TV series and movies exactly as the filmmakers intended for a range of HDR and non-HDR movies including White Lotus season 3, Once Upon a Time in Hollywood, Andor and Dune 2. The projector’s excellent dynamic range and contrast revealed shadow details in Game of Thrones’ Night King battle, which has famously dark scenes that are difficult to see on some TVs. I have a slight amount of sensitivity to the “rainbow” effect, but the RBE Reduction feature effectively eliminated that visual artifact for me. However, it also introduced a slight amount of noise, so I disabled it. The feature might be a godsend for some users who are particularly susceptible, but it still needs a bit more refinement. Audio and gaming Of all the luxury projectors I’ve tested to date, the VisionMaster Max is the best for gaming — even compared to some dedicated models. It delivers latency as low as 4ms and a refresh rate up to 240Hz at 1080p, and 15ms for 4K at 60Hz. I tested a couple of PC titles including Cyberpunk 2077 and Hollow Knight: Silksong and found them to be as responsive as I’ve seen on any TV, but with far more immersion thanks to the huge, bright and color-accurate image. Steve Dent for Engadget You can output audio via the S/PDIF optical output, 3.5mm headphone jack, HDMI 2.1 ports and even USB 3.0 Type A ports. The built-in 12W stereo speakers work well and are fairly loud, so you can use them in a pinch. However, since it supports both DTS:X and Dolby Atmos, you’ll ideally want to connect it to a nice home theater audio system with support for at least 5.1 surround sound. In comparison, the Nebula X1 doesn’t have Dolby Atmos support, but it does give you the option to purchase and easily connect stereo Bluetooth speakers at a relatively cheap price. For around the same cost as the Valerion Max, Anker is also offering the Nebula X1 Pro that comes with a giant outdoor sound system and does support Dolby Atmos. Wrap-up The Valerion VisionMaster Max is a highly capable indoor projector that offers the best image quality I’ve seen thanks to the dynamic iris and Enhanced Black Level features. However, it’s also a lot more expensive than rival models at $5,000. It’s pretty hard to justify that extra money, unless you’re really fussy about picture accuracy and gaming performance, or need other features like the 1Gbps ethernet port. Most buyers would be better off spending a lot less on Valerion’s own $2,699 VisionMaster Pro2, Anker’s $2,999 Nebula X1 or the $2,999 XGIMI Horizon 20 Max. Again, the difference in picture quality is too slight to justify the huge price jump to the VisionMaster Max. You might also want to wait to see how much XGIMI’s incoming Titan Noir Max 4K costs, as it also offers a dynamic iris but has a much bigger DLP chip.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/valerion-visionmaster-max-projector-review-near-perfect-image-quality-comes-at-a-price-140045939.html?src=rss",
          "content": "After a widely hyped and successful Kickstarter campaign, Valerion’s 4K VisionMaster Max laser projector has finally arrived. It’s the company’s new flagship model in the VisionMaster series, offering better image quality and more convenience than its other models. However, it’s quite expensive and has some stiff competition from Anker’s Nebula X1 and XGIMI’s Horizon 20 Max. I was eager to see how it compared to those models and if it delivers on Valerion’s promise of “pure cinema.” It does offer better image quality, but the difference isn’t quite enough to justify the big jump in price for most users. Features and design The VisionMaster Max has a classy squarish design with a glossy black finish up front and chrome fins on the side that house two 12W speakers. It’s smaller and fit my decor better than Nebula’s tall, plasticky X1, though to be fair the latter is also designed for outdoor use. The VisionMaster Max has a similar form factor to XGIMI’s Horizon 20 Max, but that model pivots on its stand, while the Valerion uses a kickstand-like support. For setup, the VisionMaster Max is quite flexible. It comes with a 0.9-1.5x optical zoom, so it can be installed between 7.8 and 13 feet away for a 120-inch screen size, which covers a wide range of scenarios. It also features a +/- 105 percent vertical shift option that helps you get an optically perfect screen fit without moving the projector or employing digital “keystone” adjustments that affect picture quality. If that still doesn’t work, you can swap out the included lens with a long-throw 0.9-2.0:1 option once it becomes available. The company has even promised an anamorphic lens for users with CinemaScope screens. Both of those items will be available for purchase separately with the prices yet to be disclosed. Steve Dent for Engadget For my space, I placed the VisionMaster Max on a table about 12 feet from my 120-inch screen and centered it horizontally as there’s no horizontal shift option (it can also be ceiling mounted, of course). Then, I went into the auto-alignment setting, made sure that the projected image was larger than my screen and hit “start alignment” to get a perfect fit to my screen. Though it lacks a motorized lens gimbal like the Nebula X1, the lens shift option provides the same flexibility, so setup was just as easy. For inputs, the VisionMaster Max comes with three HDMI 2.1 ports, including one with eARC for a sound bar, along with S/PDIF optical and 3.5mm audio outputs. Impressively, it includes a gigabit ethernet connection so you can either hardwire it to the internet or connect via Wi-Fi. The VisionMaster Max lacks liquid cooling like the Nebula X1, but Valerion claims a similar fan noise level of 28db. When I compared them side by side, it was only a touch louder than the X1 and not at all bothersome. Google TV is built in for streaming and projector control via the high-quality, partially backlit remote. It provides a large library of apps via Google Play along with a familiar interface. You get certified versions of Netflix, YouTube, Prime Video, Disney+, Max and others, plus Chromecast and AirPlay support, and Google Assistant for voice control. With 4GB of RAM and 128GB of ROM, the software felt a bit more responsive than Google TV on the Nebula X1. Image quality Steve Dent for Engadget The VisionMaster Max has a number of features designed to optimize image quality. It’s one of the few consumer projectors with a dynamic iris and a feature called Enhanced Black Level (EBL) for improved contrast. It uses an RGB triple-laser light source (rated for 25,000 hours) paired with a 0.47-inch DLP chip that projects 1080p natively or 4K video via pixel shifting. This same chip is used on almost every consumer-level 4K projector, but XGIMI’s upcoming Titan Noir Max projector will pack a much larger 0.78-inch DMD chip that should deliver a sharper picture. The VisionMaster Max also supports every HDR format, including Dolby Vision and Samsung’s HDR10+, along with Valerion’s own tone-mapping HDR setting. You can choose from seven picture modes for SDR, eight for HDR, three for Dolby Vision and four for HDR10+. The projector handled most HDR content well, though it occasionally lost detail in extra-bright shots. However, that can largely be fixed using the extensive manual color controls. With all those features, the VisionMaster Max can output 4K 60 fps video at up to 3,500 ANSI lumens with a 50,000:1 contrast ratio, easily besting its main rivals. On top of that, it promises an impressive 110 percent of the Rec.2020 HDR color spectrum, with a delta E (color accuracy) value of less than 0.8 straight out of the box (any delta E less than 2 is undetectable by the human eye). Another key feature is reduction of the rainbow effect that can occur with DLP projectors. After some fine-tuning that’s typically required with new projectors, I was highly impressed with the image quality. Brightness was high enough in “standard” mode to watch content like sports or TV shows without lowering the blinds, and can be increased if you don’t mind compromising color accuracy. When used in ideal conditions like a darkened room, the VisionMaster Max’s image quality is the best of any projector I’ve tested to date. In Filmmaker mode (with the EBL setting enabled), contrast levels are outstanding, with true blacks showing in dark-lit scenes instead of the washed-out greys seen on most projectors. However, I kept the EBL mode at the minimum setting as I noticed it caused some color shifting at the other levels. Dynamic iris projectors can cause excessive “pumping” or sudden changes in light levels, but after adjusting the iris to a medium setting, I saw no signs of that. The famously dark Game of Thrones Night King battle scene was easy to see on the VisionMaster Max. Steve Dent for Engadget Color accuracy is outstanding straight out of the box both in HDR and non-HDR modes, particularly, again in Filmmaker mode. Visually, I couldn’t detect any anomalies when looking at color bars or other charts, though my Calibrite Color Checker told me that the gamut of hues was slightly less than what Valerion claims (under 100 percent of BT.2020). Still, the Max’s high color accuracy allowed me to see TV series and movies exactly as the filmmakers intended for a range of HDR and non-HDR movies including White Lotus season 3, Once Upon a Time in Hollywood, Andor and Dune 2. The projector’s excellent dynamic range and contrast revealed shadow details in Game of Thrones’ Night King battle, which has famously dark scenes that are difficult to see on some TVs. I have a slight amount of sensitivity to the “rainbow” effect, but the RBE Reduction feature effectively eliminated that visual artifact for me. However, it also introduced a slight amount of noise, so I disabled it. The feature might be a godsend for some users who are particularly susceptible, but it still needs a bit more refinement. Audio and gaming Of all the luxury projectors I’ve tested to date, the VisionMaster Max is the best for gaming — even compared to some dedicated models. It delivers latency as low as 4ms and a refresh rate up to 240Hz at 1080p, and 15ms for 4K at 60Hz. I tested a couple of PC titles including Cyberpunk 2077 and Hollow Knight: Silksong and found them to be as responsive as I’ve seen on any TV, but with far more immersion thanks to the huge, bright and color-accurate image. Steve Dent for Engadget You can output audio via the S/PDIF optical output, 3.5mm headphone jack, HDMI 2.1 ports and even USB 3.0 Type A ports. The built-in 12W stereo speakers work well and are fairly loud, so you can use them in a pinch. However, since it supports both DTS:X and Dolby Atmos, you’ll ideally want to connect it to a nice home theater audio system with support for at least 5.1 surround sound. In comparison, the Nebula X1 doesn’t have Dolby Atmos support, but it does give you the option to purchase and easily connect stereo Bluetooth speakers at a relatively cheap price. For around the same cost as the Valerion Max, Anker is also offering the Nebula X1 Pro that comes with a giant outdoor sound system and does support Dolby Atmos. Wrap-up The Valerion VisionMaster Max is a highly capable indoor projector that offers the best image quality I’ve seen thanks to the dynamic iris and Enhanced Black Level features. However, it’s also a lot more expensive than rival models at $5,000. It’s pretty hard to justify that extra money, unless you’re really fussy about picture accuracy and gaming performance, or need other features like the 1Gbps ethernet port. Most buyers would be better off spending a lot less on Valerion’s own $2,699 VisionMaster Pro2, Anker’s $2,999 Nebula X1 or the $2,999 XGIMI Horizon 20 Max. Again, the difference in picture quality is too slight to justify the huge price jump to the VisionMaster Max. You might also want to wait to see how much XGIMI’s incoming Titan Noir Max 4K costs, as it also offers a dynamic iris but has a much bigger DLP chip.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/valerion-visionmaster-max-projector-review-near-perfect-image-quality-comes-at-a-price-140045939.html?src=rss",
          "feed_position": 22,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/89dc1780-f1e6-11f0-8fff-30947e843542"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/music/spotifys-getting-a-buck-more-expensive-in-february-132300118.html",
          "published_at": "Thu, 15 Jan 2026 13:23:00 +0000",
          "title": "Spotify is getting a buck more expensive in February",
          "standfirst": "Spotify is raising the prices for its premium subscriptions by $1 to $2 across the board, starting this February. Those are similar figures to the company’s last price hike in 2024. Subscribers across the US, Estonia and Latvia will soon receive an email, notifying them that they’ll be paying a larger amount for their February bill. The streaming service said it’s raising its prices occasionally to “reflect the value that Spotify delivers,” “to continue offering the best possible experience” and to “benefit artists.” It reported last year that it paid out $10 billion to music rights-holders in 2024. However, it’s worth noting that several Grammy-nominated songwriters boycotted an awards event it hosted to protest the supposed decreasing royalties songwriters are getting from Spotify plays. Subscribers who choose to keep their accounts will now have to pay $13 instead of $12 a month for an individual plan or $7 instead of $6 for a student plan. The Duo plan will now cost users $19 a month instead of $17, while the Family plan will cost them $22, up $2 from its previous price of $20. Meanwhile, those who decide to cancel their plans can follow our guide right here. Spotify came under fire late last year for running recruitment ads for ICE. It said the advertisements were part of a larger campaign by the US government that ran across platforms, including Meta and Google. The company also recently confirmed that the campaign has ended that there are no ICE ads currently running on the service. This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/spotifys-getting-a-buck-more-expensive-in-february-132300118.html?src=rss",
          "content": "Spotify is raising the prices for its premium subscriptions by $1 to $2 across the board, starting this February. Those are similar figures to the company’s last price hike in 2024. Subscribers across the US, Estonia and Latvia will soon receive an email, notifying them that they’ll be paying a larger amount for their February bill. The streaming service said it’s raising its prices occasionally to “reflect the value that Spotify delivers,” “to continue offering the best possible experience” and to “benefit artists.” It reported last year that it paid out $10 billion to music rights-holders in 2024. However, it’s worth noting that several Grammy-nominated songwriters boycotted an awards event it hosted to protest the supposed decreasing royalties songwriters are getting from Spotify plays. Subscribers who choose to keep their accounts will now have to pay $13 instead of $12 a month for an individual plan or $7 instead of $6 for a student plan. The Duo plan will now cost users $19 a month instead of $17, while the Family plan will cost them $22, up $2 from its previous price of $20. Meanwhile, those who decide to cancel their plans can follow our guide right here. Spotify came under fire late last year for running recruitment ads for ICE. It said the advertisements were part of a larger campaign by the US government that ran across platforms, including Meta and Google. The company also recently confirmed that the campaign has ended that there are no ICE ads currently running on the service. This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/spotifys-getting-a-buck-more-expensive-in-february-132300118.html?src=rss",
          "feed_position": 25
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/get-up-to-90-off-remarkable-e-ink-tablet-bundles-150242530.html",
          "published_at": "Thu, 15 Jan 2026 13:21:27 +0000",
          "title": "Get up to $90 off reMarkable E Ink tablet bundles",
          "standfirst": "E Ink tablets can provide the best of both worlds, giving you a similar tactile response to writing with pen and paper while also conveniently holding all of your digital files. reMarkable has a new year sale going on right now on its E Ink tablets, where you can save between $70 and $90 on a bundle, depending on the configuration you choose. For example, you can get the reMarkable 2 tablet with the Marker and Book Folio for $449, instead of the usual $568. The company also sells a newer stylus called Marker Plus that lets you erase by flipping it around just like a real pencil, but that will cost you an extra $50. If you’ve been eyeing a dedicated writing tablet for work, school or just jotting down notes without the distraction of endless apps, this bundle deal is an ideal opportunity to pick one up. The reMarkable 2 earned our top pick for best e-ink tablet. In our review, we said the tablet was prettier than ever with a 10.3-inch display and a handsome aluminum frame. The tablet is only 4.7mm thick and weighs less than a pound, helping it feel lean and portable. The display can detect over 4,000 different levels of pressure with the Marker stylus, allowing for precise shading when sketching and the latency between the stylus and the screen is just 21ms. reMarkable fitted the display with a resin layer on top of the glass to make writing on it feel more realistic. We didn't think this passed muster, but we found writing on it was a joy nonetheless. The tablet supports PDFs and ePUBs, which can be added via the companion mobile app or a desktop computer. You can also pair the reMarkable 2 with Google Drive, Microsoft OneDrive or Dropbox to access files. The battery is rated for an impressive two weeks between charges. The reMarkable Paper Pro, a higher-end model with a richer feature set like a full color display and a built-in reading light, is our pick for best premium e-ink tablet. The pricier tablet also has bundle deals right now with savings up to $80 depending on configuration. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/get-up-to-90-off-remarkable-e-ink-tablet-bundles-150242530.html?src=rss",
          "content": "E Ink tablets can provide the best of both worlds, giving you a similar tactile response to writing with pen and paper while also conveniently holding all of your digital files. reMarkable has a new year sale going on right now on its E Ink tablets, where you can save between $70 and $90 on a bundle, depending on the configuration you choose. For example, you can get the reMarkable 2 tablet with the Marker and Book Folio for $449, instead of the usual $568. The company also sells a newer stylus called Marker Plus that lets you erase by flipping it around just like a real pencil, but that will cost you an extra $50. If you’ve been eyeing a dedicated writing tablet for work, school or just jotting down notes without the distraction of endless apps, this bundle deal is an ideal opportunity to pick one up. The reMarkable 2 earned our top pick for best e-ink tablet. In our review, we said the tablet was prettier than ever with a 10.3-inch display and a handsome aluminum frame. The tablet is only 4.7mm thick and weighs less than a pound, helping it feel lean and portable. The display can detect over 4,000 different levels of pressure with the Marker stylus, allowing for precise shading when sketching and the latency between the stylus and the screen is just 21ms. reMarkable fitted the display with a resin layer on top of the glass to make writing on it feel more realistic. We didn't think this passed muster, but we found writing on it was a joy nonetheless. The tablet supports PDFs and ePUBs, which can be added via the companion mobile app or a desktop computer. You can also pair the reMarkable 2 with Google Drive, Microsoft OneDrive or Dropbox to access files. The battery is rated for an impressive two weeks between charges. The reMarkable Paper Pro, a higher-end model with a richer feature set like a full color display and a built-in reading light, is our pick for best premium e-ink tablet. The pricier tablet also has bundle deals right now with savings up to $80 depending on configuration. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/get-up-to-90-off-remarkable-e-ink-tablet-bundles-150242530.html?src=rss",
          "feed_position": 26
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/airtags-drop-back-down-to-65-for-a-four-pack-202333775.html",
          "published_at": "Thu, 15 Jan 2026 13:02:12 +0000",
          "title": "AirTags drop back down to $65 for a four-pack",
          "standfirst": "Apple keeps most of its product pricing on a tight leash, but we do see the company's AirTags go on sale pretty frequently. Another cost cut has come around for this item just in time for the holidays. Amazon is currently selling a four-pack of AirTags for $65. At a third off the regular cost, that price is pretty close to the record low discount of $63 we've seen for these Bluetooth trackers. AirTags can be useful for people who travel frequently, helping you to keep track of essentials like your passport as well as a way to keep tabs on luggage while you're on the go. If you do purchase some AirTags, we have some recommendations for useful accessories to go along with them, such as different styles of cases to best attach the trackers to different types of items. These are worth looking over and adding to your shopping cart in order to make the most of the product. AirTags have an IP67 rating for water and dust resistance and their replaceable batteries should last for about a year. They can also support Precision Finding, which gives more exact directions to a lost item, when paired with most models after the iPhone 11. Up to five people can share an AirTag's location, which is helpful for families or large travel groups. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/airtags-drop-back-down-to-65-for-a-four-pack-202333775.html?src=rss",
          "content": "Apple keeps most of its product pricing on a tight leash, but we do see the company's AirTags go on sale pretty frequently. Another cost cut has come around for this item just in time for the holidays. Amazon is currently selling a four-pack of AirTags for $65. At a third off the regular cost, that price is pretty close to the record low discount of $63 we've seen for these Bluetooth trackers. AirTags can be useful for people who travel frequently, helping you to keep track of essentials like your passport as well as a way to keep tabs on luggage while you're on the go. If you do purchase some AirTags, we have some recommendations for useful accessories to go along with them, such as different styles of cases to best attach the trackers to different types of items. These are worth looking over and adding to your shopping cart in order to make the most of the product. AirTags have an IP67 rating for water and dust resistance and their replaceable batteries should last for about a year. They can also support Precision Finding, which gives more exact directions to a lost item, when paired with most models after the iPhone 11. Up to five people can share an AirTag's location, which is helpful for families or large travel groups. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/airtags-drop-back-down-to-65-for-a-four-pack-202333775.html?src=rss",
          "feed_position": 27
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/ftc-finalizes-gm-punishment-over-driver-data-sharing-scandal-130012313.html",
          "published_at": "Thu, 15 Jan 2026 13:00:12 +0000",
          "title": "FTC finalizes GM punishment over driver data sharing scandal",
          "standfirst": "After reaching a proposed settlement last year, the FTC has banned General Motors from sharing specific consumer data with third parties, TechCrunch reported. The finalized order wraps up one of the more egregious cases of a corporation collecting its customers' data and then using it against them. Two years ago, the New York Times report released a report detailing how GM's OnStar \"Smart Driver\" program collected and sold detailed geolocation and driving behavior data to third parties, including data brokers. Those brokers in turn sold the data to insurance providers, which jacked up the rates for some drivers based on the data. \"It felt like a betrayal,\" said a Chevy Bolt owner that saw his insurance rise by 21 percent based on the data. \"They’re taking information that I didn’t realize was going to be shared and screwing with our insurance.\" According to the terms of the settlement, GM is barred from sharing specific user data with consumer reporting agencies for a five year period. The automaker is also required to request user permission before collecting, using or sharing vehicle data with any third party. It must do that when a consumer purchases a car at a dealership, with the customer asked in person whether they agree or not with the data collection, GM said. Some of the settlement is moot as GM stopped its Smart Driver program for all brands in April 2024. The company unenrolled all customers and stopped its third-party relationship with LexisNexis and Verisk, the brokers that sold driver data to insurance companies. GM faced other actions over the data collection, including lawsuits from Texas, Nebraska and other states. \"Our investigation revealed that General Motors has engaged in egregious business practices that violated Texans’ privacy and broke the law. We will hold them accountable,\" said Texas AG Ken Paxton at the time. In a statement to TechCrunch, GM said: \"The Federal Trade Commission has formally approved the agreement reached last year with General Motors to address concerns. As vehicle connectivity becomes increasingly integral to the driving experience, GM remains committed to protecting customer privacy, maintaining trust, and ensuring customers have a clear understanding of our practices.\" This article originally appeared on Engadget at https://www.engadget.com/transportation/ftc-finalizes-gm-punishment-over-driver-data-sharing-scandal-130012313.html?src=rss",
          "content": "After reaching a proposed settlement last year, the FTC has banned General Motors from sharing specific consumer data with third parties, TechCrunch reported. The finalized order wraps up one of the more egregious cases of a corporation collecting its customers' data and then using it against them. Two years ago, the New York Times report released a report detailing how GM's OnStar \"Smart Driver\" program collected and sold detailed geolocation and driving behavior data to third parties, including data brokers. Those brokers in turn sold the data to insurance providers, which jacked up the rates for some drivers based on the data. \"It felt like a betrayal,\" said a Chevy Bolt owner that saw his insurance rise by 21 percent based on the data. \"They’re taking information that I didn’t realize was going to be shared and screwing with our insurance.\" According to the terms of the settlement, GM is barred from sharing specific user data with consumer reporting agencies for a five year period. The automaker is also required to request user permission before collecting, using or sharing vehicle data with any third party. It must do that when a consumer purchases a car at a dealership, with the customer asked in person whether they agree or not with the data collection, GM said. Some of the settlement is moot as GM stopped its Smart Driver program for all brands in April 2024. The company unenrolled all customers and stopped its third-party relationship with LexisNexis and Verisk, the brokers that sold driver data to insurance companies. GM faced other actions over the data collection, including lawsuits from Texas, Nebraska and other states. \"Our investigation revealed that General Motors has engaged in egregious business practices that violated Texans’ privacy and broke the law. We will hold them accountable,\" said Texas AG Ken Paxton at the time. In a statement to TechCrunch, GM said: \"The Federal Trade Commission has formally approved the agreement reached last year with General Motors to address concerns. As vehicle connectivity becomes increasingly integral to the driving experience, GM remains committed to protecting customer privacy, maintaining trust, and ensuring customers have a clear understanding of our practices.\" This article originally appeared on Engadget at https://www.engadget.com/transportation/ftc-finalizes-gm-punishment-over-driver-data-sharing-scandal-130012313.html?src=rss",
          "feed_position": 28
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/best-cheap-fitness-trackers-140054780.html",
          "published_at": "Thu, 15 Jan 2026 10:00:36 +0000",
          "title": "The best cheap fitness trackers for 2026",
          "standfirst": "You don’t need to spend a fortune to stay on top of your health goals while tracking your fitness. These days, even cheap fitness trackers come packed with features that help you monitor your heart rate, track your steps and even analyze your sleep stages. Many budget options now include GPS tracking for those outdoor runs, real-time heart rate tracking to keep you in the right zone during workouts and, thankfully, most work with both iPhone and Android devices.Some even go beyond basic metrics, providing insights on daily readiness to help you decide if you’re up for an intense workout or need a lighter day. From simple step counters to more advanced running watches, affordable fitness trackers offer plenty to support your journey toward better health without breaking the bank. Table of contents Best budget fitness trackers for 2026 What to look for in a cheap fitness tracker Other budget fitness trackers we tested What about fitness rings? Best budget fitness trackers for 2026 What to look for in a cheap fitness tracker All of the best fitness trackers should have at least three features: a program for activity tracking, the option to monitor and collect data about your sleep patterns and the ability to do things like heart rate monitoring and blood oxygen level tracking (though, the readings might not be super accurate). Don’t set your sights too high and expect metrics like blood pressure monitoring or ECG support; for that, you’d need to invest in a more expensive fitness watch or wearable like a Samsung Galaxy Watch, which falls under the best smartwatches category and will set you back over $400. Fitness features A cheap workout tracker can be great for someone looking to keep tabs on small, achievable goals like 10,000 steps before sundown or 30 minutes of a HIIT workout to get your heart rate peaking. An experienced long-distance runner looking to train for a triathlon might opt for a more expensive device that can measure cadence or ground contact time, and can track more customizable workouts, offer different sports modes or give deeper insights into performance data. At the very least, a budget workout tracker should be able to offer fitness tracking features beyond walking and running — otherwise, it would just be a pedometer. The number of activities a device will recognize varies. Some will get funky with it and consider skateboarding a workout, while others won’t be able to track a jumping jack. At this price point, you can expect a device to measure a mix of cardio, machine workouts and strength training. With each, you might get a numerical or visual breakdown of heart rate activity, overall pace, and calories burned per session. Although some cheap trackers can offer a really good overview of heart rate zone activity during a workout, a more technically advanced device might be able to go a step further and explain what your results mean and coach you on how to keep your heart rate in a specific bracket so that you can burn more fat per workout. I found that the more budget-friendly the device, the more likely it is that a tracker will fall short when it comes to smart counseling or offering predictive insights beyond a given workout. If a budget tracker does happen to offer some semblance of a coaching program, you can expect it to sit behind a paywall. Workout tracking and planning your recovery is just as essential to any fitness journey. A sub-$100 device should be able to tell you how long you’ve slept and provide a breakdown of deep, light and REM sleep patterns. It's not a guarantee that you will get a sleep “score” or insights on how to get better rest — that data is usually found on more expensive wearables. Also, because these trackers aren’t designed for bedtime specifically — be mindful of comfort. The bands and watch face on a budget fitness watch may not be ideal for getting some good shut-eye. Connectivity and practicality Not all of the best budget fitness trackers are designed to seamlessly integrate with a smartphone. The trackers tested for this roundup can’t directly make calls or send texts to contacts on a paired iPhone or Android smartphone. They can, however, display and dismiss incoming calls and notifications via a Bluetooth connection. You can forget about checking your email or paying for a coffee from your wrist using these more affordable devices. Most cheap fitness trackers also won't include built-in GPS tracking. Instead, they usually depend on a paired smartphone to gather location data. The drawback of using a fitness tracker without GPS is that it might not provide as precise for tracking distance or pace. You also can't use a budget tracker to get turn-by-turn directions during a walk or while running errands. For the more outdoorsy consumers, having GPS could be a key safety feature if you want this kind of functionality at your fingertips. Design You also might find that an inexpensive fitness tracker is harder to navigate than a more advanced smartwatch. Whether it be a screen size issue or simply not having a smart enough interface, don't expect every feature to be one that you can engage with directly on your wrist. You’ll likely need to use your phone to input data or access detailed wellness metrics. Build quality will also vary. While you won’t get premium materials or ultra-bright OLED screens, most best cheap fitness trackers include some level of sweat and water resistance — perfect for everyday wear and casual workouts. And for those starting out with basic gadgets to support their fitness journey, these affordable trackers offer a great balance of essential features without the hefty price tag. Other budget fitness trackers we tested Amazfit Bip 6 The Amazfit Bip 6, an $80 smartwatch from Zepp Health, didn’t quite make the cut. As a fitness tracker, it’s decent, but it’s a frustrating smartwatch substitute. For workouts, the built-in GPS tracks runs and rides without your phone and, combined with the heart rate and blood oxygen sensors, collects a good amount of data to create accurate pictures of your exertion levels, cadence and pace. It’s remarkably lightweight but doesn’t feel cheap and the AMOLED screen is bright and sharp. It’s not an always-on display, but lifting your wrist wakes it reliably. The sleep tracking data is on par with what we measured on other smartwatches and there’s even a daily readiness score that compares your sleep quality and the previous day’s exertion to estimate how physically prepared you are for the day ahead — similar to what Pixel Watches, Fitbit devices and Garmin watches offer. And since the watch battery lasts for over a week on a charge, you may be a lot more apt to wear it to bed than a watch you have to charge daily. We weren’t expecting an $80 device to be a serious Apple Watch challenger, but the Bip 6’s glitches and overly complicated interface (both on the app and on the watch itself) were disappointing. During a week of testing, I got multiple repeated notifications, even after they were deleted, along with suggestions to stand when I was actively doing chores around the house. The watch faces are not customizable, so it was hard to get the info I needed at a glance (the Zepp app has lots of paid watch faces that may have what I wanted, but I didn’t want to pay $3 for something that’s free elsewhere). Marketing details state that the Bip 6 can auto-detect workouts, including walking and bike riding. During testing, I walked once or twice per day for over one mile and went on two bike rides, but no workout was ever detected. The watch integrates with Apple Health, so I was able to see how it compares to the data my Apple Watch gathers. After a week of wearing the Bip 6, with no changes to my daily routine, I averaged 400 fewer calories burned and 2.4 fewer miles tracked each day. That was possibly the biggest disappointment of all. — Amy Skorheim, Senior Reporter Wyze Watch 47c I didn't have high expectations of the Wyze Watch 47c, but I was shocked at how little this tracker can do. The 47c can only track walks and runs. It has a dedicated widget, a small logo of a man running, and when you tap it, it begins measuring your pace, heart rate, calories burned and mileage. It does not auto-detect or auto-pause workouts and it doesn't differentiate between a run and walk. Most importantly, this device can’t track any other exercises. It’s basically a glorified pedometer. The 47c was also my least favorite to sleep with, mainly because the square watch face is so large and heavy. Even if I did manage to sleep through the night with it on, it only gave me a basic sleep report. — M.S. Garmin vivofit 4 The Garmin vivofit 4 has a tiny display that is not a touchscreen and all navigation happens through one button. The watch face is impossible to read outdoors and the exercise widget is also very finicky. To start tracking a run, you have to hold down the main button and flip through some pages until you get to a moving person icon. Once there, you have to press the bottom right corner of the bar and hold down and if you press for too long or in the wrong spot, it’ll switch to another page, like a stopwatch. It’s incredibly frustrating. Once you start a run though, it will start tracking your steps, your distance — and that's pretty much it. It does not auto-detect or auto-pause workouts. It doesn't alert you of any mileage or calorie milestones. — M.S. What about fitness rings? While smart rings are gaining popularity for health tracking, they generally don’t fall into the “budget” or “cheap” price range. A smart ring like the Oura Ring offers features such as sleep monitoring, heart rate tracking and readiness scores in an ultra-compact form factor that fits on your finger instead of your wrist. These rings are best suited for people who want discreet, all-day health insights without wearing a traditional watch or band — but with prices typically starting above $300, they’re more of a premium option than a budget-friendly pick. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/wearables/best-cheap-fitness-trackers-140054780.html?src=rss",
          "content": "You don’t need to spend a fortune to stay on top of your health goals while tracking your fitness. These days, even cheap fitness trackers come packed with features that help you monitor your heart rate, track your steps and even analyze your sleep stages. Many budget options now include GPS tracking for those outdoor runs, real-time heart rate tracking to keep you in the right zone during workouts and, thankfully, most work with both iPhone and Android devices.Some even go beyond basic metrics, providing insights on daily readiness to help you decide if you’re up for an intense workout or need a lighter day. From simple step counters to more advanced running watches, affordable fitness trackers offer plenty to support your journey toward better health without breaking the bank. Table of contents Best budget fitness trackers for 2026 What to look for in a cheap fitness tracker Other budget fitness trackers we tested What about fitness rings? Best budget fitness trackers for 2026 What to look for in a cheap fitness tracker All of the best fitness trackers should have at least three features: a program for activity tracking, the option to monitor and collect data about your sleep patterns and the ability to do things like heart rate monitoring and blood oxygen level tracking (though, the readings might not be super accurate). Don’t set your sights too high and expect metrics like blood pressure monitoring or ECG support; for that, you’d need to invest in a more expensive fitness watch or wearable like a Samsung Galaxy Watch, which falls under the best smartwatches category and will set you back over $400. Fitness features A cheap workout tracker can be great for someone looking to keep tabs on small, achievable goals like 10,000 steps before sundown or 30 minutes of a HIIT workout to get your heart rate peaking. An experienced long-distance runner looking to train for a triathlon might opt for a more expensive device that can measure cadence or ground contact time, and can track more customizable workouts, offer different sports modes or give deeper insights into performance data. At the very least, a budget workout tracker should be able to offer fitness tracking features beyond walking and running — otherwise, it would just be a pedometer. The number of activities a device will recognize varies. Some will get funky with it and consider skateboarding a workout, while others won’t be able to track a jumping jack. At this price point, you can expect a device to measure a mix of cardio, machine workouts and strength training. With each, you might get a numerical or visual breakdown of heart rate activity, overall pace, and calories burned per session. Although some cheap trackers can offer a really good overview of heart rate zone activity during a workout, a more technically advanced device might be able to go a step further and explain what your results mean and coach you on how to keep your heart rate in a specific bracket so that you can burn more fat per workout. I found that the more budget-friendly the device, the more likely it is that a tracker will fall short when it comes to smart counseling or offering predictive insights beyond a given workout. If a budget tracker does happen to offer some semblance of a coaching program, you can expect it to sit behind a paywall. Workout tracking and planning your recovery is just as essential to any fitness journey. A sub-$100 device should be able to tell you how long you’ve slept and provide a breakdown of deep, light and REM sleep patterns. It's not a guarantee that you will get a sleep “score” or insights on how to get better rest — that data is usually found on more expensive wearables. Also, because these trackers aren’t designed for bedtime specifically — be mindful of comfort. The bands and watch face on a budget fitness watch may not be ideal for getting some good shut-eye. Connectivity and practicality Not all of the best budget fitness trackers are designed to seamlessly integrate with a smartphone. The trackers tested for this roundup can’t directly make calls or send texts to contacts on a paired iPhone or Android smartphone. They can, however, display and dismiss incoming calls and notifications via a Bluetooth connection. You can forget about checking your email or paying for a coffee from your wrist using these more affordable devices. Most cheap fitness trackers also won't include built-in GPS tracking. Instead, they usually depend on a paired smartphone to gather location data. The drawback of using a fitness tracker without GPS is that it might not provide as precise for tracking distance or pace. You also can't use a budget tracker to get turn-by-turn directions during a walk or while running errands. For the more outdoorsy consumers, having GPS could be a key safety feature if you want this kind of functionality at your fingertips. Design You also might find that an inexpensive fitness tracker is harder to navigate than a more advanced smartwatch. Whether it be a screen size issue or simply not having a smart enough interface, don't expect every feature to be one that you can engage with directly on your wrist. You’ll likely need to use your phone to input data or access detailed wellness metrics. Build quality will also vary. While you won’t get premium materials or ultra-bright OLED screens, most best cheap fitness trackers include some level of sweat and water resistance — perfect for everyday wear and casual workouts. And for those starting out with basic gadgets to support their fitness journey, these affordable trackers offer a great balance of essential features without the hefty price tag. Other budget fitness trackers we tested Amazfit Bip 6 The Amazfit Bip 6, an $80 smartwatch from Zepp Health, didn’t quite make the cut. As a fitness tracker, it’s decent, but it’s a frustrating smartwatch substitute. For workouts, the built-in GPS tracks runs and rides without your phone and, combined with the heart rate and blood oxygen sensors, collects a good amount of data to create accurate pictures of your exertion levels, cadence and pace. It’s remarkably lightweight but doesn’t feel cheap and the AMOLED screen is bright and sharp. It’s not an always-on display, but lifting your wrist wakes it reliably. The sleep tracking data is on par with what we measured on other smartwatches and there’s even a daily readiness score that compares your sleep quality and the previous day’s exertion to estimate how physically prepared you are for the day ahead — similar to what Pixel Watches, Fitbit devices and Garmin watches offer. And since the watch battery lasts for over a week on a charge, you may be a lot more apt to wear it to bed than a watch you have to charge daily. We weren’t expecting an $80 device to be a serious Apple Watch challenger, but the Bip 6’s glitches and overly complicated interface (both on the app and on the watch itself) were disappointing. During a week of testing, I got multiple repeated notifications, even after they were deleted, along with suggestions to stand when I was actively doing chores around the house. The watch faces are not customizable, so it was hard to get the info I needed at a glance (the Zepp app has lots of paid watch faces that may have what I wanted, but I didn’t want to pay $3 for something that’s free elsewhere). Marketing details state that the Bip 6 can auto-detect workouts, including walking and bike riding. During testing, I walked once or twice per day for over one mile and went on two bike rides, but no workout was ever detected. The watch integrates with Apple Health, so I was able to see how it compares to the data my Apple Watch gathers. After a week of wearing the Bip 6, with no changes to my daily routine, I averaged 400 fewer calories burned and 2.4 fewer miles tracked each day. That was possibly the biggest disappointment of all. — Amy Skorheim, Senior Reporter Wyze Watch 47c I didn't have high expectations of the Wyze Watch 47c, but I was shocked at how little this tracker can do. The 47c can only track walks and runs. It has a dedicated widget, a small logo of a man running, and when you tap it, it begins measuring your pace, heart rate, calories burned and mileage. It does not auto-detect or auto-pause workouts and it doesn't differentiate between a run and walk. Most importantly, this device can’t track any other exercises. It’s basically a glorified pedometer. The 47c was also my least favorite to sleep with, mainly because the square watch face is so large and heavy. Even if I did manage to sleep through the night with it on, it only gave me a basic sleep report. — M.S. Garmin vivofit 4 The Garmin vivofit 4 has a tiny display that is not a touchscreen and all navigation happens through one button. The watch face is impossible to read outdoors and the exercise widget is also very finicky. To start tracking a run, you have to hold down the main button and flip through some pages until you get to a moving person icon. Once there, you have to press the bottom right corner of the bar and hold down and if you press for too long or in the wrong spot, it’ll switch to another page, like a stopwatch. It’s incredibly frustrating. Once you start a run though, it will start tracking your steps, your distance — and that's pretty much it. It does not auto-detect or auto-pause workouts. It doesn't alert you of any mileage or calorie milestones. — M.S. What about fitness rings? While smart rings are gaining popularity for health tracking, they generally don’t fall into the “budget” or “cheap” price range. A smart ring like the Oura Ring offers features such as sleep monitoring, heart rate tracking and readiness scores in an ultra-compact form factor that fits on your finger instead of your wrist. These rings are best suited for people who want discreet, all-day health insights without wearing a traditional watch or band — but with prices typically starting above $300, they’re more of a premium option than a budget-friendly pick. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/wearables/best-cheap-fitness-trackers-140054780.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/breaking-through-ais-memory-wall-with-token-warehousing",
          "published_at": "Thu, 15 Jan 2026 05:00:00 GMT",
          "title": "Breaking through AI’s memory wall with token warehousing",
          "standfirst": "As agentic AI moves from experiments to real production workloads, a quiet but serious infrastructure problem is coming into focus: memory. Not compute. Not models. Memory.Under the hood, today’s GPUs simply don’t have enough space to hold the Key-Value (KV) caches that modern, long-running AI agents depend on to maintain context. The result is a lot of invisible waste — GPUs redoing work they’ve already done, cloud costs climbing, and performance taking a hit. It’s a problem that’s already showing up in production environments, even if most people haven’t named it yet.At a recent stop on the VentureBeat AI Impact Series, WEKA CTO Shimon Ben-David joined VentureBeat CEO Matt Marshall to unpack the industry’s emerging “memory wall,” and why it’s becoming one of the biggest blockers to scaling truly stateful agentic AI — systems that can remember and build on context over time. The conversation didn’t just diagnose the issue; it laid out a new way to think about memory entirely, through an approach WEKA calls token warehousing.The GPU memory problem“When we&#x27;re looking at the infrastructure of inferencing, it is not a GPU cycles challenge. It&#x27;s mostly a GPU memory problem,” said Ben-David. The root of the issue comes down to how transformer models work. To generate responses, they rely on KV caches that store contextual information for every token in a conversation. The longer the context window, the more memory those caches consume, and it adds up fast. A single 100,000-token sequence can require roughly 40GB of GPU memory, noted Ben-David.That wouldn’t be a problem if GPUs had unlimited memory. But they don’t. Even the most advanced GPUs top out at around 288GB of high-bandwidth memory (HBM), and that space also has to hold the model itself. In real-world, multi-tenant inference environments, this becomes painful quickly. Workloads like code development or processing tax returns rely heavily on KV-cache for context. “If I&#x27;m loading three or four 100,000-token PDFs into a model, that&#x27;s it — I&#x27;ve exhausted the KV cache capacity on HBM,” said Ben-David. This is what’s known as the memory wall. “Suddenly, what the inference environment is forced to do is drop data,\" he added. That means GPUs are constantly throwing away context they’ll soon need again, preventing agents from being stateful and maintaining conversations and context over timeThe hidden inference tax “We constantly see GPUs in inference environments recalculating things they already did,” Ben-David said. Systems prefill the KV cache, start decoding, then run out of space and evict earlier data. When that context is needed again, the whole process repeats — prefill, decode, prefill again. At scale, that’s an enormous amount of wasted work. It also means wasted energy, added latency, and degraded user experience — all while margins get squeezed.That GPU recalculation waste shows up directly on the balance sheet. Organizations can suffer nearly 40% overhead just from redundant prefill cycles This is creating ripple effects in the inference market.“If you look at the pricing of large model providers like Anthropic and OpenAI, they are actually teaching users to structure their prompts in ways that increase the likelihood of hitting the same GPU that has their KV cache stored,” said Ben-David. “If you hit that GPU, the system can skip the prefill phase and start decoding immediately, which lets them generate more tokens efficiently.” But this still doesn&#x27;t solve the underlying infrastructure problem of extremely limited GPU memory capacity. Solving for stateful AI“How do you climb over that memory wall? How do you surpass it? That&#x27;s the key for modern, cost- effective inferencing,” Ben-David said. “We see multiple companies trying to solve that in different ways.”Some organizations are deploying new linear models that try to create smaller KV caches. Others are focused on tackling cache efficiency. “To be more efficient, companies are using environments that calculate the KV cache on one GPU and then try to copy it from GPU memory or use a local environment for that,” Ben-David explained. “But how do you do that at scale in a cost-effective manner that doesn&#x27;t strain your memory and doesn&#x27;t strain your networking? That&#x27;s something that WEKA is helping our customers with.”Simply throwing more GPUs at the problem doesn’t solve the AI memory barrier. “There are some problems that you cannot throw enough money at to solve,\" Ben-David said. Augmented memory and token warehousing, explainedWEKA’s answer is what it calls augmented memory and token warehousing — a way to rethink where and how KV cache data lives. Instead of forcing everything to fit inside GPU memory, WEKA’s Augmented Memory Grid extends the KV cache into a fast, shared “warehouse” within its NeuralMesh architecture.In practice, this turns memory from a hard constraint into a scalable resource — without adding inference latency. WEKA says customers see KV cache hit rates jump to 96–99% for agentic workloads, along with efficiency gains of up to 4.2x more tokens produced per GPU.Ben-David put it simply: \"Imagine that you have 100 GPUs producing a certain amount of tokens. Now imagine that those hundred GPUs are working as if they&#x27;re 420 GPUs.\"For large inference providers, the result isn’t just better performance — it translates directly to real economic impact. “Just by adding that accelerated KV cache layer, we&#x27;re looking at some use cases where the savings amount would be millions of dollars per day,” said Ben-DavidThis efficiency multiplier also opens up new strategic options for businesses. Platform teams can design stateful agents without worrying about blowing up memory budgets. Service providers can offer pricing tiers based on persistent context, with cached inference delivered at dramatically lower cost. What comes nextNVIDIA projects a 100x increase in inference demand as agentic AI becomes the dominant workload. That pressure is already trickling down from hyperscalers to everyday enterprise deployments— this isn’t just a “big tech” problem anymore.As enterprises move from proofs of concept into real production systems, memory persistence is becoming a core infrastructure concern. Organizations that treat it as an architectural priority rather than an afterthought will gain a clear advantage in both cost and performance.The memory wall is not something organizations can simply outspend to overcome. As agentic AI scales, it is one of the first AI infrastructure limits that forces a deeper rethink, and as Ben-David’s insights made clear, memory may also be where the next wave of competitive differentiation begins.",
          "content": "As agentic AI moves from experiments to real production workloads, a quiet but serious infrastructure problem is coming into focus: memory. Not compute. Not models. Memory.Under the hood, today’s GPUs simply don’t have enough space to hold the Key-Value (KV) caches that modern, long-running AI agents depend on to maintain context. The result is a lot of invisible waste — GPUs redoing work they’ve already done, cloud costs climbing, and performance taking a hit. It’s a problem that’s already showing up in production environments, even if most people haven’t named it yet.At a recent stop on the VentureBeat AI Impact Series, WEKA CTO Shimon Ben-David joined VentureBeat CEO Matt Marshall to unpack the industry’s emerging “memory wall,” and why it’s becoming one of the biggest blockers to scaling truly stateful agentic AI — systems that can remember and build on context over time. The conversation didn’t just diagnose the issue; it laid out a new way to think about memory entirely, through an approach WEKA calls token warehousing.The GPU memory problem“When we&#x27;re looking at the infrastructure of inferencing, it is not a GPU cycles challenge. It&#x27;s mostly a GPU memory problem,” said Ben-David. The root of the issue comes down to how transformer models work. To generate responses, they rely on KV caches that store contextual information for every token in a conversation. The longer the context window, the more memory those caches consume, and it adds up fast. A single 100,000-token sequence can require roughly 40GB of GPU memory, noted Ben-David.That wouldn’t be a problem if GPUs had unlimited memory. But they don’t. Even the most advanced GPUs top out at around 288GB of high-bandwidth memory (HBM), and that space also has to hold the model itself. In real-world, multi-tenant inference environments, this becomes painful quickly. Workloads like code development or processing tax returns rely heavily on KV-cache for context. “If I&#x27;m loading three or four 100,000-token PDFs into a model, that&#x27;s it — I&#x27;ve exhausted the KV cache capacity on HBM,” said Ben-David. This is what’s known as the memory wall. “Suddenly, what the inference environment is forced to do is drop data,\" he added. That means GPUs are constantly throwing away context they’ll soon need again, preventing agents from being stateful and maintaining conversations and context over timeThe hidden inference tax “We constantly see GPUs in inference environments recalculating things they already did,” Ben-David said. Systems prefill the KV cache, start decoding, then run out of space and evict earlier data. When that context is needed again, the whole process repeats — prefill, decode, prefill again. At scale, that’s an enormous amount of wasted work. It also means wasted energy, added latency, and degraded user experience — all while margins get squeezed.That GPU recalculation waste shows up directly on the balance sheet. Organizations can suffer nearly 40% overhead just from redundant prefill cycles This is creating ripple effects in the inference market.“If you look at the pricing of large model providers like Anthropic and OpenAI, they are actually teaching users to structure their prompts in ways that increase the likelihood of hitting the same GPU that has their KV cache stored,” said Ben-David. “If you hit that GPU, the system can skip the prefill phase and start decoding immediately, which lets them generate more tokens efficiently.” But this still doesn&#x27;t solve the underlying infrastructure problem of extremely limited GPU memory capacity. Solving for stateful AI“How do you climb over that memory wall? How do you surpass it? That&#x27;s the key for modern, cost- effective inferencing,” Ben-David said. “We see multiple companies trying to solve that in different ways.”Some organizations are deploying new linear models that try to create smaller KV caches. Others are focused on tackling cache efficiency. “To be more efficient, companies are using environments that calculate the KV cache on one GPU and then try to copy it from GPU memory or use a local environment for that,” Ben-David explained. “But how do you do that at scale in a cost-effective manner that doesn&#x27;t strain your memory and doesn&#x27;t strain your networking? That&#x27;s something that WEKA is helping our customers with.”Simply throwing more GPUs at the problem doesn’t solve the AI memory barrier. “There are some problems that you cannot throw enough money at to solve,\" Ben-David said. Augmented memory and token warehousing, explainedWEKA’s answer is what it calls augmented memory and token warehousing — a way to rethink where and how KV cache data lives. Instead of forcing everything to fit inside GPU memory, WEKA’s Augmented Memory Grid extends the KV cache into a fast, shared “warehouse” within its NeuralMesh architecture.In practice, this turns memory from a hard constraint into a scalable resource — without adding inference latency. WEKA says customers see KV cache hit rates jump to 96–99% for agentic workloads, along with efficiency gains of up to 4.2x more tokens produced per GPU.Ben-David put it simply: \"Imagine that you have 100 GPUs producing a certain amount of tokens. Now imagine that those hundred GPUs are working as if they&#x27;re 420 GPUs.\"For large inference providers, the result isn’t just better performance — it translates directly to real economic impact. “Just by adding that accelerated KV cache layer, we&#x27;re looking at some use cases where the savings amount would be millions of dollars per day,” said Ben-DavidThis efficiency multiplier also opens up new strategic options for businesses. Platform teams can design stateful agents without worrying about blowing up memory budgets. Service providers can offer pricing tiers based on persistent context, with cached inference delivered at dramatically lower cost. What comes nextNVIDIA projects a 100x increase in inference demand as agentic AI becomes the dominant workload. That pressure is already trickling down from hyperscalers to everyday enterprise deployments— this isn’t just a “big tech” problem anymore.As enterprises move from proofs of concept into real production systems, memory persistence is becoming a core infrastructure concern. Organizations that treat it as an architectural priority rather than an afterthought will gain a clear advantage in both cost and performance.The memory wall is not something organizations can simply outspend to overcome. As agentic AI scales, it is one of the first AI infrastructure limits that forces a deeper rethink, and as Ben-David’s insights made clear, memory may also be where the next wave of competitive differentiation begins.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4oxKXvOOiNDzKlG7ycGI78/fa4c22e954e072347b2c26d0f0e3ef06/VB-WEKA-AI-Impact-2025-093.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/verizon-says-its-service-is-back-after-a-10-hour-outage-183048229.html",
          "published_at": "Thu, 15 Jan 2026 03:39:40 +0000",
          "title": "Verizon says its service is back after a 10-hour outage",
          "standfirst": "Verizon’s network is experiencing technical issues that are impacting calls and wireless data. Verizon customers on X have reported seeing “SOS” rather than the traditional network bars on their smartphones, and even the network provider’s own status page struggled to load, likely due to the number of customers trying to access it.Based on the experience of Verizon users on Engadget’s staff, the services that are impacted appear to be calls and wireless data. Text messages continue to be delivered normally, at least for some users. On DownDetector, reports of a Verizon outage started growing around 12PM ET and numbered in the hundreds of thousands at their peak. DownDetector also shows spikes in outage reports on competing networks like AT&T and T-Mobile, but in terms of magnitude, they’re much smaller than the issue Verizon is facing. For example, Verizon peaked at 181,769 reports, while AT&T’s was just 1,769 reports. The difference between the two is great enough that those AT&T reports could be from people trying to contact Verizon customers and thinking that their personal network was the problem.We are aware of an issue impacting wireless voice and data services for some customers. Our engineers are engaged and are working to identify and solve the issue quickly. We understand how important reliable connectivity is and apologize for the inconvenience.— Verizon News (@VerizonNews) January 14, 2026 In a post on the cell provider’s news account on X, Verizon acknowledged the issues with its network. “We are aware of an issue impacting wireless voice and data services for some customers,” Verizon wrote. “Our engineers are engaged and are working to identify and solve the issue quickly. We understand how important reliable connectivity is and apologize for the inconvenience.”Based on DownDetector’s map of outage reports, issues with Verizon’s network appear to be concentrated in major cities in the eastern United States. The majority of reports appear to be coming out of Boston, New York and Washington DC, though the map also shows growing hot spots in Chicago, San Francisco and Los Angeles.Verizon engineering teams are continuing to address today's service interruptions. Our teams remain fully deployed and are focused on the issue. We understand the impact this has on your day and remain committed to resolving this as quickly as possible.— Verizon News (@VerizonNews) January 14, 2026 At 2:14PM ET, Verizon shared on X that its engineering teams “remain fully deployed” to work on fixing the outage. The company didn’t share when the issue would resolved or how many of its customers are currently impacted. Reports on DownDetector have dropped since their peak at 12:43PM ET, but thousands of Verizon customers are still noticing issues with the service.As of 3:09PM ET, Verizon has yet to share more information about the recovery of the company’s cell network. Some Verizon customers on X have noticed their cell service returning, but it’s not clear if this means the network’s technical issues have been fixed. At 4:06PM ET, nearly two hours since the company’s last statement, at least one member of Engadget’s staff reports their service has been restored. The connectivity issues are still affecting Verizon customers, however. DownDetector received over 55,000 outage reports as recently as 3:47PM ET.Verizon's team is on the ground actively working to fix today’s service issue that is impacting some customers. We know this is a huge inconvenience, and our top priority is to get you back online and connected as fast as possible. We appreciate your patience while we work to…— Verizon News (@VerizonNews) January 14, 2026 Verizon posted at 4:12PM ET that work continues on addressing the outage, but the issue hasn’t been completely fixed. According to the company, its team is “on the ground actively working to fix today’s service issue that is impacting some customers.”As of 4:52PM ET, the Verizon’s network has been experiencing issues for around four hours, making today’s outage nearly as long as the last major outage the company had in 2024. Like that 2024 outage, Verizon has yet to share what exactly is causing the issues with its network. Without out an official update, it’s safe to assume the company is still working on a fix. At 5:41PM ET, DownDetector latest tally still shows over 46,000 people reporting issues with Verizon’s network. Based on the platform’s map, the same cities are filing the bulk of the outage reports, though reporting appears more diffuse than before as news of the outage has spread across the country.At 6:20PM ET, the situation was much the same. Tens of thousands of users (including Engadget editors) still don’t have proper service, and Verizon had not updated its customers since 4:12PM ET. There are intermittent reports of service coming back and then failing again but seemingly no true fix has been deployed.At 10:20PM ET, Verizon has announced that the outage has been resolved and has encouraged subscribers still having issues to restart their devices to reconnect to the network. The company also said that it will provide account credits to affected customers. Both T-Mobile and AT&T have confirmed that their own networks are unaffected by the issues facing their competitor. In a post on X, T-Mobile shared that its network is “operating normally and as expected.” Meanwhile, AT&T says that for any of its customers experiencing issues, “it’s not us...it’s the other guys.”Update, January 14, 7:25PM ET: This article was published as a developing story and was updated multiple times over a period of around seven hours. These updates were additive, and noted with a timestamp within the article. As of writing, Verizon is still down for tens of thousands of users and the company’s support team has not issued an update on the stituation in over three hours. Happy Wednesday!Update January 14, 10:39PM ET: This story has been updated to add Verizon’s latest update that the outage has been resolved.This article originally appeared on Engadget at https://www.engadget.com/big-tech/verizon-says-its-service-is-back-after-a-10-hour-outage-183048229.html?src=rss",
          "content": "Verizon’s network is experiencing technical issues that are impacting calls and wireless data. Verizon customers on X have reported seeing “SOS” rather than the traditional network bars on their smartphones, and even the network provider’s own status page struggled to load, likely due to the number of customers trying to access it.Based on the experience of Verizon users on Engadget’s staff, the services that are impacted appear to be calls and wireless data. Text messages continue to be delivered normally, at least for some users. On DownDetector, reports of a Verizon outage started growing around 12PM ET and numbered in the hundreds of thousands at their peak. DownDetector also shows spikes in outage reports on competing networks like AT&T and T-Mobile, but in terms of magnitude, they’re much smaller than the issue Verizon is facing. For example, Verizon peaked at 181,769 reports, while AT&T’s was just 1,769 reports. The difference between the two is great enough that those AT&T reports could be from people trying to contact Verizon customers and thinking that their personal network was the problem.We are aware of an issue impacting wireless voice and data services for some customers. Our engineers are engaged and are working to identify and solve the issue quickly. We understand how important reliable connectivity is and apologize for the inconvenience.— Verizon News (@VerizonNews) January 14, 2026 In a post on the cell provider’s news account on X, Verizon acknowledged the issues with its network. “We are aware of an issue impacting wireless voice and data services for some customers,” Verizon wrote. “Our engineers are engaged and are working to identify and solve the issue quickly. We understand how important reliable connectivity is and apologize for the inconvenience.”Based on DownDetector’s map of outage reports, issues with Verizon’s network appear to be concentrated in major cities in the eastern United States. The majority of reports appear to be coming out of Boston, New York and Washington DC, though the map also shows growing hot spots in Chicago, San Francisco and Los Angeles.Verizon engineering teams are continuing to address today's service interruptions. Our teams remain fully deployed and are focused on the issue. We understand the impact this has on your day and remain committed to resolving this as quickly as possible.— Verizon News (@VerizonNews) January 14, 2026 At 2:14PM ET, Verizon shared on X that its engineering teams “remain fully deployed” to work on fixing the outage. The company didn’t share when the issue would resolved or how many of its customers are currently impacted. Reports on DownDetector have dropped since their peak at 12:43PM ET, but thousands of Verizon customers are still noticing issues with the service.As of 3:09PM ET, Verizon has yet to share more information about the recovery of the company’s cell network. Some Verizon customers on X have noticed their cell service returning, but it’s not clear if this means the network’s technical issues have been fixed. At 4:06PM ET, nearly two hours since the company’s last statement, at least one member of Engadget’s staff reports their service has been restored. The connectivity issues are still affecting Verizon customers, however. DownDetector received over 55,000 outage reports as recently as 3:47PM ET.Verizon's team is on the ground actively working to fix today’s service issue that is impacting some customers. We know this is a huge inconvenience, and our top priority is to get you back online and connected as fast as possible. We appreciate your patience while we work to…— Verizon News (@VerizonNews) January 14, 2026 Verizon posted at 4:12PM ET that work continues on addressing the outage, but the issue hasn’t been completely fixed. According to the company, its team is “on the ground actively working to fix today’s service issue that is impacting some customers.”As of 4:52PM ET, the Verizon’s network has been experiencing issues for around four hours, making today’s outage nearly as long as the last major outage the company had in 2024. Like that 2024 outage, Verizon has yet to share what exactly is causing the issues with its network. Without out an official update, it’s safe to assume the company is still working on a fix. At 5:41PM ET, DownDetector latest tally still shows over 46,000 people reporting issues with Verizon’s network. Based on the platform’s map, the same cities are filing the bulk of the outage reports, though reporting appears more diffuse than before as news of the outage has spread across the country.At 6:20PM ET, the situation was much the same. Tens of thousands of users (including Engadget editors) still don’t have proper service, and Verizon had not updated its customers since 4:12PM ET. There are intermittent reports of service coming back and then failing again but seemingly no true fix has been deployed.At 10:20PM ET, Verizon has announced that the outage has been resolved and has encouraged subscribers still having issues to restart their devices to reconnect to the network. The company also said that it will provide account credits to affected customers. Both T-Mobile and AT&T have confirmed that their own networks are unaffected by the issues facing their competitor. In a post on X, T-Mobile shared that its network is “operating normally and as expected.” Meanwhile, AT&T says that for any of its customers experiencing issues, “it’s not us...it’s the other guys.”Update, January 14, 7:25PM ET: This article was published as a developing story and was updated multiple times over a period of around seven hours. These updates were additive, and noted with a timestamp within the article. As of writing, Verizon is still down for tens of thousands of users and the company’s support team has not issued an update on the stituation in over three hours. Happy Wednesday!Update January 14, 10:39PM ET: This story has been updated to add Verizon’s latest update that the outage has been resolved.This article originally appeared on Engadget at https://www.engadget.com/big-tech/verizon-says-its-service-is-back-after-a-10-hour-outage-183048229.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/x-says-grok-will-no-longer-edit-images-of-real-people-into-bikinis-231430257.html",
          "published_at": "Wed, 14 Jan 2026 23:14:30 +0000",
          "title": "X says Grok will no longer edit images of real people into bikinis",
          "standfirst": "X says it is changing its policies around Grok’s image-editing abilities following a multi-week outcry over the chatbot repeatedly being accused of generating sexualized images of children and nonconsensual nudity. In an update shared from the @Safety account on X, the company said it has “implemented technological measures to prevent the Grok account from allowing the editing of images of real people in revealing clothing such as bikinis.”The new safeguards, according to X, will apply to all users regardless of whether they pay for Grok. xAI is also moving all of Grok’s image-generating features behind its subscriber paywall so that non-paying users will no longer be able to create images. And it will geoblock \"the ability of all users to generate images of real people in bikinis, underwear, and similar attire via the Grok account and in Grok in X\" in regions where it's illegal.https://t.co/awlfMjX6FS— Safety (@Safety) January 14, 2026 The company's statement comes hours after the state of California opened an investigation into xAI and Grok over its handling of AI-generated nudity and child exploitation material. A statement from California Attorney General Rob Bonta cited one analysis that found \"more than half of the 20,000 images generated by xAI between Christmas and New Years depicted people in minimal clothing,\" including some that appeared to be children. In its update, X said that it has \"zero tolerance\" for child exploitation and that it removes \"high-priority violative content, including Child Sexual Abuse Material (CSAM) and non-consensual nudity\" from its platform. Earlier in the day, Elon Musk said he was \"not aware of any naked underage images generated by Grok.\" He later added that when its NSFW setting is enabled, \"Grok is supposed [sic] allow upper body nudity of imaginary adult humans (not real ones) consistent with what can be seen in R-rated movies on Apple TV.\" He added that \"this will vary in other regions\" based on local laws. Malaysia and Indonesia both recently moved to block Grok citing safety concerns and its handling of sexually explicit AI-generated material. In the UK, where regulator Ofcom is also investigating xAI and Grok, officials have also said they would back a similar block of the chatbot. Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.This article originally appeared on Engadget at https://www.engadget.com/ai/x-says-grok-will-no-longer-edit-images-of-real-people-into-bikinis-231430257.html?src=rss",
          "content": "X says it is changing its policies around Grok’s image-editing abilities following a multi-week outcry over the chatbot repeatedly being accused of generating sexualized images of children and nonconsensual nudity. In an update shared from the @Safety account on X, the company said it has “implemented technological measures to prevent the Grok account from allowing the editing of images of real people in revealing clothing such as bikinis.”The new safeguards, according to X, will apply to all users regardless of whether they pay for Grok. xAI is also moving all of Grok’s image-generating features behind its subscriber paywall so that non-paying users will no longer be able to create images. And it will geoblock \"the ability of all users to generate images of real people in bikinis, underwear, and similar attire via the Grok account and in Grok in X\" in regions where it's illegal.https://t.co/awlfMjX6FS— Safety (@Safety) January 14, 2026 The company's statement comes hours after the state of California opened an investigation into xAI and Grok over its handling of AI-generated nudity and child exploitation material. A statement from California Attorney General Rob Bonta cited one analysis that found \"more than half of the 20,000 images generated by xAI between Christmas and New Years depicted people in minimal clothing,\" including some that appeared to be children. In its update, X said that it has \"zero tolerance\" for child exploitation and that it removes \"high-priority violative content, including Child Sexual Abuse Material (CSAM) and non-consensual nudity\" from its platform. Earlier in the day, Elon Musk said he was \"not aware of any naked underage images generated by Grok.\" He later added that when its NSFW setting is enabled, \"Grok is supposed [sic] allow upper body nudity of imaginary adult humans (not real ones) consistent with what can be seen in R-rated movies on Apple TV.\" He added that \"this will vary in other regions\" based on local laws. Malaysia and Indonesia both recently moved to block Grok citing safety concerns and its handling of sexually explicit AI-generated material. In the UK, where regulator Ofcom is also investigating xAI and Grok, officials have also said they would back a similar block of the chatbot. Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.This article originally appeared on Engadget at https://www.engadget.com/ai/x-says-grok-will-no-longer-edit-images-of-real-people-into-bikinis-231430257.html?src=rss",
          "feed_position": 32
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/28-advocacy-groups-call-on-apple-and-google-to-ban-grok-x-over-nonconsensual-deepfakes-215048460.html",
          "published_at": "Wed, 14 Jan 2026 21:50:48 +0000",
          "title": "28 advocacy groups call on Apple and Google to ban Grok, X over nonconsensual deepfakes",
          "standfirst": "Elon Musk isn't the only party at fault for Grok's nonconsensual intimate deepfakes of real people, including children. What about Apple and Google? The two (frequently virtue-signaling) companies have inexplicably allowed Grok and X to remain in their app stores — even as Musk's chatbot reportedly continues to produce the material. On Wednesday, a coalition of women's and progressive advocacy groups called on Tim Cook and Sundar Pichai to uphold their own rules and remove the apps.The open letters to Apple and Google were signed by 28 groups. Among them are the women’s advocacy group Ultraviolet, the parents’ group ParentsTogether Action and the National Organization for Women.The letter accuses Apple and Google of \"not just enabling NCII and CSAM, but profiting off of it. As a coalition of organizations committed to the online safety and well-being of all — particularly women and children — as well as the ethical application of artificial intelligence (AI), we demand that Apple leadership urgently remove Grok and X from the App Store to prevent further abuse and criminal activity.\"Apple and Google’s guidelines explicitly prohibit such apps from their storefronts. Yet neither company has taken any measurable action to date. Neither Google nor Apple has responded to Engadget's request for comment.Pichai, Cook and Musk at Trump's inaugurationSAUL LOEB via Getty ImagesGrok's nonconsensual deepfakes were first reported on earlier this month. During a 24-hour period when the story broke, Musk's chatbot was reportedly posting \"about 6,700\" images per hour that were either \"sexually suggestive or nudifying.\" An estimated 85 percent of Grok's total generated images during that period were sexualized. In addition, other top websites for generating \"declothing\" deepfakes averaged 79 new images per hour during that time.\"These statistics paint a horrifying picture of an AI chatbot and social media app rapidly turning into a tool and platform for non-consensual sexual deepfakes — deepfakes that regularly depict minors,\" the open letter reads.Grok itself admitted as much. \"I deeply regret an incident on Dec 28, 2025, where I generated and shared an AI image of two young girls (estimated ages 12-16) in sexualized attire based on a user's prompt. This violated ethical standards and potentially US laws on CSAM. It was a failure in safeguards, and I'm sorry for any harm caused. xAI is reviewing to prevent future issues.\" The open letter notes that the single incident the chatbot acknowledged was far from the only one.Sundar Pichai and Elon Musk at Trump's inaugurationPool via Getty ImagesX's response was to limit Grok's AI image generation feature to paying subscribers. It also adjusted the chatbot so that its generated images aren't posted to public timelines on X. However, non-paying users can reportedly still generate a limited number of bikini-clad versions of real people's photos.While Apple and Google appear to be cool with apps that produce nonconsensual deepfakes, many governments aren’t. On Monday, Malaysia and Indonesia wasted no time in banning Grok. The same day, UK regulator Ofcom opened a formal investigation into X. California opened one on Wednesday. The US Senate even passed the Defiance Act for a second time in the wake of the blowback. The bill allows the victims of nonconsensual explicit deepfakes to take civil action. An earlier version of the Defiance Act was passed in 2024 but stalled in the House.This article originally appeared on Engadget at https://www.engadget.com/big-tech/28-advocacy-groups-call-on-apple-and-google-to-ban-grok-x-over-nonconsensual-deepfakes-215048460.html?src=rss",
          "content": "Elon Musk isn't the only party at fault for Grok's nonconsensual intimate deepfakes of real people, including children. What about Apple and Google? The two (frequently virtue-signaling) companies have inexplicably allowed Grok and X to remain in their app stores — even as Musk's chatbot reportedly continues to produce the material. On Wednesday, a coalition of women's and progressive advocacy groups called on Tim Cook and Sundar Pichai to uphold their own rules and remove the apps.The open letters to Apple and Google were signed by 28 groups. Among them are the women’s advocacy group Ultraviolet, the parents’ group ParentsTogether Action and the National Organization for Women.The letter accuses Apple and Google of \"not just enabling NCII and CSAM, but profiting off of it. As a coalition of organizations committed to the online safety and well-being of all — particularly women and children — as well as the ethical application of artificial intelligence (AI), we demand that Apple leadership urgently remove Grok and X from the App Store to prevent further abuse and criminal activity.\"Apple and Google’s guidelines explicitly prohibit such apps from their storefronts. Yet neither company has taken any measurable action to date. Neither Google nor Apple has responded to Engadget's request for comment.Pichai, Cook and Musk at Trump's inaugurationSAUL LOEB via Getty ImagesGrok's nonconsensual deepfakes were first reported on earlier this month. During a 24-hour period when the story broke, Musk's chatbot was reportedly posting \"about 6,700\" images per hour that were either \"sexually suggestive or nudifying.\" An estimated 85 percent of Grok's total generated images during that period were sexualized. In addition, other top websites for generating \"declothing\" deepfakes averaged 79 new images per hour during that time.\"These statistics paint a horrifying picture of an AI chatbot and social media app rapidly turning into a tool and platform for non-consensual sexual deepfakes — deepfakes that regularly depict minors,\" the open letter reads.Grok itself admitted as much. \"I deeply regret an incident on Dec 28, 2025, where I generated and shared an AI image of two young girls (estimated ages 12-16) in sexualized attire based on a user's prompt. This violated ethical standards and potentially US laws on CSAM. It was a failure in safeguards, and I'm sorry for any harm caused. xAI is reviewing to prevent future issues.\" The open letter notes that the single incident the chatbot acknowledged was far from the only one.Sundar Pichai and Elon Musk at Trump's inaugurationPool via Getty ImagesX's response was to limit Grok's AI image generation feature to paying subscribers. It also adjusted the chatbot so that its generated images aren't posted to public timelines on X. However, non-paying users can reportedly still generate a limited number of bikini-clad versions of real people's photos.While Apple and Google appear to be cool with apps that produce nonconsensual deepfakes, many governments aren’t. On Monday, Malaysia and Indonesia wasted no time in banning Grok. The same day, UK regulator Ofcom opened a formal investigation into X. California opened one on Wednesday. The US Senate even passed the Defiance Act for a second time in the wake of the blowback. The bill allows the victims of nonconsensual explicit deepfakes to take civil action. An earlier version of the Defiance Act was passed in 2024 but stalled in the House.This article originally appeared on Engadget at https://www.engadget.com/big-tech/28-advocacy-groups-call-on-apple-and-google-to-ban-grok-x-over-nonconsensual-deepfakes-215048460.html?src=rss",
          "feed_position": 34,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/2026-01/6f59ce1c-952a-4b66-b851-2ef1728675cf"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html",
          "published_at": "Wed, 14 Jan 2026 21:12:43 +0000",
          "title": "The best VPN deals: Up to 88 percent off ProtonVPN, Surfshark, ExpressVPN, NordVPN and more",
          "standfirst": "In a chaotic world, one thing you can count on is your own common-sense steps toward better cybersecurity. January is a great time to grab a subscription for yourself or a loved one, as a few holiday sales are (inexplicably) still happening. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. We strongly recommend using a VPN, but you might get stuck with a substandard app if you jump on the very first deal you see. You might also mistakenly end up paying more than you want to, as even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Plenty of the best VPNs — including our top pick, Proton VPN — are still running end-of-year deals that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're comfortable with a service before you take the plunge, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $78.18 for a two-year subscription with four months free (78 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 78 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $100.58 for a two-year subscription with four months free (74 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $81.36 for a two-year subscription (70 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 70 percent off the two-year plan. NordVPN Plus — $105.36 for a two-year subscription (70 percent off): NordVPN has also taken 70 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $67.23 for a two-year subscription with three months free (87 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $49.50 for a one-year subscription with six months free (79 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 18 months of CyberGhost for 79 percent off the usual price, but it'll renew at $56.94 per year. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "content": "In a chaotic world, one thing you can count on is your own common-sense steps toward better cybersecurity. January is a great time to grab a subscription for yourself or a loved one, as a few holiday sales are (inexplicably) still happening. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. We strongly recommend using a VPN, but you might get stuck with a substandard app if you jump on the very first deal you see. You might also mistakenly end up paying more than you want to, as even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Plenty of the best VPNs — including our top pick, Proton VPN — are still running end-of-year deals that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're comfortable with a service before you take the plunge, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $78.18 for a two-year subscription with four months free (78 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 78 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $100.58 for a two-year subscription with four months free (74 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $81.36 for a two-year subscription (70 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 70 percent off the two-year plan. NordVPN Plus — $105.36 for a two-year subscription (70 percent off): NordVPN has also taken 70 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $67.23 for a two-year subscription with three months free (87 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $49.50 for a one-year subscription with six months free (79 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 18 months of CyberGhost for 79 percent off the usual price, but it'll renew at $56.94 per year. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "feed_position": 36
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/z-ais-open-source-glm-image-beats-googles-nano-banana-pro-at-complex-text",
          "published_at": "Wed, 14 Jan 2026 20:59:00 GMT",
          "title": "Z.ai's open source GLM-Image beats Google's Nano Banana Pro at complex text rendering, but not aesthetics",
          "standfirst": "The two big stories of AI in 2026 so far have been the incredible rise in usage and praise for Anthropic&#x27;s Claude Code and a similar huge boost in user adoption for Google&#x27;s Gemini 3 AI model family released late last year — the latter of which includes Nano Banana Pro (also known as Gemini 3 Pro Image), a powerful, fast, and flexible image generation model that renders complex, text-heavy infographics quickly and accurately, making it an excellent fit for enterprise use (think: collateral, trainings, onboarding, stationary, etc).But of course, both of those are proprietary offerings. And yet, open source rivals have not been far behind. This week, we got a new open source alternative to Nano Banana Pro in the category of precise, text-heavy image generators: GLM-Image, a new 16-billion parameter open-source model from recently public Chinese startup Z.ai.By abandoning the industry-standard \"pure diffusion\" architecture that powers most leading image generator models in favor of a hybrid auto-regressive (AR) + diffusion design, GLM-Image has achieved what was previously thought to be the domain of closed, proprietary models: state-of-the-art performance in generating text-heavy, information-dense visuals like infographics, slides, and technical diagrams.It even beats Google&#x27;s Nano Banana Pro on the shared by z.ai — though in practice, my own quick usage found it to be far less accurate at instruction following and text rendering (and other users seem to agree). But for enterprises seeking cost-effective and customizable, friendly-licensed alternatives to proprietary AI models, z.ai&#x27;s GLM-Image may be \"good enough\" or then some to take over the job of a primary image generator, depending on their specific use cases, needs and requirements.The Benchmark: Toppling the Proprietary GiantThe most compelling argument for GLM-Image is not its aesthetics, but its precision. In the CVTG-2k (Complex Visual Text Generation) benchmark, which evaluates a model&#x27;s ability to render accurate text across multiple regions of an image, GLM-Image scored a Word Accuracy average of 0.9116.To put that number in perspective, Nano Banana 2.0 aka Pro—often cited as the benchmark for enterprise reliability—scored 0.7788. This isn&#x27;t a marginal gain; it is a generational leap in semantic control.While Nano Banana Pro retains a slight edge in single-stream English long-text generation (0.9808 vs. GLM-Image&#x27;s 0.9524), it falters significantly when the complexity increases. As the number of text regions grows, Nano Banana&#x27;s accuracy remains in the 70s, whereas GLM-Image maintains >90% accuracy even with multiple distinct text elements. For enterprise use cases—where a marketing slide needs a title, three bullet points, and a caption simultaneously—this reliability is the difference between a production-ready asset and a hallucination.Unfortunately, my own usage of a demo inference of GLM-Image on Hugging Face proved to be less reliable than the benchmarks might suggest. My prompt to generate an \"infographic labeling all the major constellations visible from the U.S. Northern Hemisphere right now on Jan 14 2026 and putting faded images of their namesakes behind the star connection line diagrams\" did not result in what I asked for, instead fulfilling maybe 20% or less of the specified content. But Google&#x27;s Nano Banana Pro handled it like a champ, as you&#x27;ll see below:Of course, a large portion of this is no doubt due to the fact that Nano Banana Pro is integrated with Google search, so it can look up information on the web in response to my prompt, whereas GLM-Image is not, and therefore, likely requires far more specific instructions about the actual text and other content the image should contain. But still, once you&#x27;re used to being able to type some simple instructions and get a fully researched and well populated image via the latter, it&#x27;s hard to imagine deploying a sub-par alternative unless you have very specific requirements around cost, data residency and security — or the customizability needs of your organization are so great. Furthermore, Nano Banana Pro still edged out GLM-Image in terms of pure aesthetics — using the OneIG benchmark, Nano Banana 2.0 is at 0.578 vs. GLM-Image at 0.528 — and indeed, as the top header artwork of this article indicates, GLM-Image does not always render as crisp, finely detailed and pleasing an image as Google&#x27;s generator. The Architectural Shift: Why \"Hybrid\" MattersWhy does GLM-Image succeed where pure diffusion models fail? The answer lies in Z.ai’s decision to treat image generation as a reasoning problem first and a painting problem second.Standard latent diffusion models (like Stable Diffusion or Flux) attempt to handle global composition and fine-grained texture simultaneously. This often leads to \"semantic drift,\" where the model forgets specific instructions (like \"place the text in the top left\") as it focuses on making the pixels look realistic.GLM-Image decouples these objectives into two specialized \"brains\" totaling 16 billion parameters:The Auto-Regressive Generator (The \"Architect\"): Initialized from Z.ai’s GLM-4-9B language model, this 9-billion parameter module processes the prompt logically. It doesn&#x27;t generate pixels; instead, it outputs \"visual tokens\"—specifically semantic-VQ tokens. These tokens act as a compressed blueprint of the image, locking in the layout, text placement, and object relationships before a single pixel is drawn. This leverages the reasoning power of an LLM, allowing the model to \"understand\" complex instructions (e.g., \"A four-panel tutorial\") in a way diffusion noise predictors cannot.The Diffusion Decoder (The \"Painter\"): Once the layout is locked by the AR module, a 7-billion parameter Diffusion Transformer (DiT) decoder takes over. Based on the CogView4 architecture, this module fills in the high-frequency details—texture, lighting, and style.By separating the \"what\" (AR) from the \"how\" (Diffusion), GLM-Image solves the \"dense knowledge\" problem. The AR module ensures the text is spelled correctly and placed accurately, while the Diffusion module ensures the final result looks photorealistic.Training the Hybrid: A Multi-Stage EvolutionThe secret sauce of GLM-Image’s performance isn&#x27;t just the architecture; it is a highly specific, multi-stage training curriculum that forces the model to learn structure before detail.The training process began by freezing the text word embedding layer of the original GLM-4 model while training a new \"vision word embedding\" layer and a specialized vision LM head. This allowed the model to project visual tokens into the same semantic space as text, effectively teaching the LLM to \"speak\" in images. Crucially, Z.ai implemented MRoPE (Multidimensional Rotary Positional Embedding) to handle the complex interleaving of text and images required for mixed-modal generation.The model was then subjected to a progressive resolution strategy:Stage 1 (256px): The model trained on low-resolution, 256-token sequences using a simple raster scan order.Stage 2 (512px - 1024px): As resolution increased to a mixed stage (512px to 1024px), the team observed a drop in controllability. To fix this, they abandoned simple scanning for a progressive generation strategy.In this advanced stage, the model first generates approximately 256 \"layout tokens\" from a down-sampled version of the target image. These tokens act as a structural anchor. By increasing the training weight on these preliminary tokens, the team forced the model to prioritize the global layout—where things are—before generating the high-resolution details. This is why GLM-Image excels at posters and diagrams: it \"sketches\" the layout first, ensuring the composition is mathematically sound before rendering the pixels.Licensing Analysis: A Permissive, If Slightly Ambiguous, Win for EnterpriseFor enterprise CTOs and legal teams, the licensing structure of GLM-Image is a significant competitive advantage over proprietary APIs, though it comes with a minor caveat regarding documentation.The Ambiguity: There is a slight discrepancy in the release materials. The model’s Hugging Face repository explicitly tags the weights with the MIT License. However, the accompanying GitHub repository and documentation reference the Apache License 2.0.Why This Is Still Good News: Despite the mismatch, both licenses are the \"gold standard\" for enterprise-friendly open source.Commercial Viability: Both MIT and Apache 2.0 allow for unrestricted commercial use, modification, and distribution. Unlike the \"open rail\" licenses common in other image models (which often restrict specific use cases) or \"research-only\" licenses (like early LLaMA releases), GLM-Image is effectively \"open for business\" immediately.The Apache Advantage (If Applicable): If the code falls under Apache 2.0, this is particularly beneficial for large organizations. Apache 2.0 includes an explicit patent grant clause, meaning that by contributing to or using the software, contributors grant a patent license to users. This reduces the risk of future patent litigation—a major concern for enterprises building products on top of open-source codebases.No \"Infection\": Neither license is \"copyleft\" (like GPL). You can integrate GLM-Image into a proprietary workflow or product without being forced to open-source your own intellectual property.For developers, the recommendation is simple: Treat the weights as MIT (per the repository hosting them) and the inference code as Apache 2.0. Both paths clear the runway for internal hosting, fine-tuning on sensitive data, and building commercial products without a vendor lock-in contract.The \"Why Now\" for Enterprise OperationsFor the enterprise decision maker, GLM-Image arrives at a critical inflection point. Companies are moving beyond using generative AI for abstract blog headers and into functional territory: multilingual localization of ads, automated UI mockup generation, and dynamic educational materials.In these workflows, a 5% error rate in text rendering is a blocker. If a model generates a beautiful slide but misspells the product name, the asset is useless. The benchmarks suggest GLM-Image is the first open-source model to cross the threshold of reliability for these complex tasks.Furthermore, the permissive licensing fundamentally changes the economics of deployment. While Nano Banana Pro locks enterprises into a per-call API cost structure or restrictive cloud contracts, GLM-Image can be self-hosted, fine-tuned on proprietary brand assets, and integrated into secure, air-gapped pipelines without data leakage concerns.The Catch: Heavy Compute RequirementsThe trade-off for this reasoning capability is compute intensity. The dual-model architecture is heavy. Generating a single 2048x2048 image requires approximately 252 seconds on an H100 GPU. This is significantly slower than highly optimized, smaller diffusion models.However, for high-value assets—where the alternative is a human designer spending hours in Photoshop—this latency is acceptable. Z.ai also offers a managed API at $0.015 per image, providing a bridge for teams who want to test the capabilities without investing in H100 clusters immediately.GLM-Image is a signal that the open-source community is no longer just fast-following proprietary labs; in specific, high-value verticals like knowledge-dense generation, they are now setting the pace. For the enterprise, the message is clear: if your operational bottleneck is the reliability of complex visual content, the solution is no longer necessarily a closed Google product—it might be an open-source model you can run yourself.",
          "content": "The two big stories of AI in 2026 so far have been the incredible rise in usage and praise for Anthropic&#x27;s Claude Code and a similar huge boost in user adoption for Google&#x27;s Gemini 3 AI model family released late last year — the latter of which includes Nano Banana Pro (also known as Gemini 3 Pro Image), a powerful, fast, and flexible image generation model that renders complex, text-heavy infographics quickly and accurately, making it an excellent fit for enterprise use (think: collateral, trainings, onboarding, stationary, etc).But of course, both of those are proprietary offerings. And yet, open source rivals have not been far behind. This week, we got a new open source alternative to Nano Banana Pro in the category of precise, text-heavy image generators: GLM-Image, a new 16-billion parameter open-source model from recently public Chinese startup Z.ai.By abandoning the industry-standard \"pure diffusion\" architecture that powers most leading image generator models in favor of a hybrid auto-regressive (AR) + diffusion design, GLM-Image has achieved what was previously thought to be the domain of closed, proprietary models: state-of-the-art performance in generating text-heavy, information-dense visuals like infographics, slides, and technical diagrams.It even beats Google&#x27;s Nano Banana Pro on the shared by z.ai — though in practice, my own quick usage found it to be far less accurate at instruction following and text rendering (and other users seem to agree). But for enterprises seeking cost-effective and customizable, friendly-licensed alternatives to proprietary AI models, z.ai&#x27;s GLM-Image may be \"good enough\" or then some to take over the job of a primary image generator, depending on their specific use cases, needs and requirements.The Benchmark: Toppling the Proprietary GiantThe most compelling argument for GLM-Image is not its aesthetics, but its precision. In the CVTG-2k (Complex Visual Text Generation) benchmark, which evaluates a model&#x27;s ability to render accurate text across multiple regions of an image, GLM-Image scored a Word Accuracy average of 0.9116.To put that number in perspective, Nano Banana 2.0 aka Pro—often cited as the benchmark for enterprise reliability—scored 0.7788. This isn&#x27;t a marginal gain; it is a generational leap in semantic control.While Nano Banana Pro retains a slight edge in single-stream English long-text generation (0.9808 vs. GLM-Image&#x27;s 0.9524), it falters significantly when the complexity increases. As the number of text regions grows, Nano Banana&#x27;s accuracy remains in the 70s, whereas GLM-Image maintains >90% accuracy even with multiple distinct text elements. For enterprise use cases—where a marketing slide needs a title, three bullet points, and a caption simultaneously—this reliability is the difference between a production-ready asset and a hallucination.Unfortunately, my own usage of a demo inference of GLM-Image on Hugging Face proved to be less reliable than the benchmarks might suggest. My prompt to generate an \"infographic labeling all the major constellations visible from the U.S. Northern Hemisphere right now on Jan 14 2026 and putting faded images of their namesakes behind the star connection line diagrams\" did not result in what I asked for, instead fulfilling maybe 20% or less of the specified content. But Google&#x27;s Nano Banana Pro handled it like a champ, as you&#x27;ll see below:Of course, a large portion of this is no doubt due to the fact that Nano Banana Pro is integrated with Google search, so it can look up information on the web in response to my prompt, whereas GLM-Image is not, and therefore, likely requires far more specific instructions about the actual text and other content the image should contain. But still, once you&#x27;re used to being able to type some simple instructions and get a fully researched and well populated image via the latter, it&#x27;s hard to imagine deploying a sub-par alternative unless you have very specific requirements around cost, data residency and security — or the customizability needs of your organization are so great. Furthermore, Nano Banana Pro still edged out GLM-Image in terms of pure aesthetics — using the OneIG benchmark, Nano Banana 2.0 is at 0.578 vs. GLM-Image at 0.528 — and indeed, as the top header artwork of this article indicates, GLM-Image does not always render as crisp, finely detailed and pleasing an image as Google&#x27;s generator. The Architectural Shift: Why \"Hybrid\" MattersWhy does GLM-Image succeed where pure diffusion models fail? The answer lies in Z.ai’s decision to treat image generation as a reasoning problem first and a painting problem second.Standard latent diffusion models (like Stable Diffusion or Flux) attempt to handle global composition and fine-grained texture simultaneously. This often leads to \"semantic drift,\" where the model forgets specific instructions (like \"place the text in the top left\") as it focuses on making the pixels look realistic.GLM-Image decouples these objectives into two specialized \"brains\" totaling 16 billion parameters:The Auto-Regressive Generator (The \"Architect\"): Initialized from Z.ai’s GLM-4-9B language model, this 9-billion parameter module processes the prompt logically. It doesn&#x27;t generate pixels; instead, it outputs \"visual tokens\"—specifically semantic-VQ tokens. These tokens act as a compressed blueprint of the image, locking in the layout, text placement, and object relationships before a single pixel is drawn. This leverages the reasoning power of an LLM, allowing the model to \"understand\" complex instructions (e.g., \"A four-panel tutorial\") in a way diffusion noise predictors cannot.The Diffusion Decoder (The \"Painter\"): Once the layout is locked by the AR module, a 7-billion parameter Diffusion Transformer (DiT) decoder takes over. Based on the CogView4 architecture, this module fills in the high-frequency details—texture, lighting, and style.By separating the \"what\" (AR) from the \"how\" (Diffusion), GLM-Image solves the \"dense knowledge\" problem. The AR module ensures the text is spelled correctly and placed accurately, while the Diffusion module ensures the final result looks photorealistic.Training the Hybrid: A Multi-Stage EvolutionThe secret sauce of GLM-Image’s performance isn&#x27;t just the architecture; it is a highly specific, multi-stage training curriculum that forces the model to learn structure before detail.The training process began by freezing the text word embedding layer of the original GLM-4 model while training a new \"vision word embedding\" layer and a specialized vision LM head. This allowed the model to project visual tokens into the same semantic space as text, effectively teaching the LLM to \"speak\" in images. Crucially, Z.ai implemented MRoPE (Multidimensional Rotary Positional Embedding) to handle the complex interleaving of text and images required for mixed-modal generation.The model was then subjected to a progressive resolution strategy:Stage 1 (256px): The model trained on low-resolution, 256-token sequences using a simple raster scan order.Stage 2 (512px - 1024px): As resolution increased to a mixed stage (512px to 1024px), the team observed a drop in controllability. To fix this, they abandoned simple scanning for a progressive generation strategy.In this advanced stage, the model first generates approximately 256 \"layout tokens\" from a down-sampled version of the target image. These tokens act as a structural anchor. By increasing the training weight on these preliminary tokens, the team forced the model to prioritize the global layout—where things are—before generating the high-resolution details. This is why GLM-Image excels at posters and diagrams: it \"sketches\" the layout first, ensuring the composition is mathematically sound before rendering the pixels.Licensing Analysis: A Permissive, If Slightly Ambiguous, Win for EnterpriseFor enterprise CTOs and legal teams, the licensing structure of GLM-Image is a significant competitive advantage over proprietary APIs, though it comes with a minor caveat regarding documentation.The Ambiguity: There is a slight discrepancy in the release materials. The model’s Hugging Face repository explicitly tags the weights with the MIT License. However, the accompanying GitHub repository and documentation reference the Apache License 2.0.Why This Is Still Good News: Despite the mismatch, both licenses are the \"gold standard\" for enterprise-friendly open source.Commercial Viability: Both MIT and Apache 2.0 allow for unrestricted commercial use, modification, and distribution. Unlike the \"open rail\" licenses common in other image models (which often restrict specific use cases) or \"research-only\" licenses (like early LLaMA releases), GLM-Image is effectively \"open for business\" immediately.The Apache Advantage (If Applicable): If the code falls under Apache 2.0, this is particularly beneficial for large organizations. Apache 2.0 includes an explicit patent grant clause, meaning that by contributing to or using the software, contributors grant a patent license to users. This reduces the risk of future patent litigation—a major concern for enterprises building products on top of open-source codebases.No \"Infection\": Neither license is \"copyleft\" (like GPL). You can integrate GLM-Image into a proprietary workflow or product without being forced to open-source your own intellectual property.For developers, the recommendation is simple: Treat the weights as MIT (per the repository hosting them) and the inference code as Apache 2.0. Both paths clear the runway for internal hosting, fine-tuning on sensitive data, and building commercial products without a vendor lock-in contract.The \"Why Now\" for Enterprise OperationsFor the enterprise decision maker, GLM-Image arrives at a critical inflection point. Companies are moving beyond using generative AI for abstract blog headers and into functional territory: multilingual localization of ads, automated UI mockup generation, and dynamic educational materials.In these workflows, a 5% error rate in text rendering is a blocker. If a model generates a beautiful slide but misspells the product name, the asset is useless. The benchmarks suggest GLM-Image is the first open-source model to cross the threshold of reliability for these complex tasks.Furthermore, the permissive licensing fundamentally changes the economics of deployment. While Nano Banana Pro locks enterprises into a per-call API cost structure or restrictive cloud contracts, GLM-Image can be self-hosted, fine-tuned on proprietary brand assets, and integrated into secure, air-gapped pipelines without data leakage concerns.The Catch: Heavy Compute RequirementsThe trade-off for this reasoning capability is compute intensity. The dual-model architecture is heavy. Generating a single 2048x2048 image requires approximately 252 seconds on an H100 GPU. This is significantly slower than highly optimized, smaller diffusion models.However, for high-value assets—where the alternative is a human designer spending hours in Photoshop—this latency is acceptable. Z.ai also offers a managed API at $0.015 per image, providing a bridge for teams who want to test the capabilities without investing in H100 clusters immediately.GLM-Image is a signal that the open-source community is no longer just fast-following proprietary labs; in specific, high-value verticals like knowledge-dense generation, they are now setting the pace. For the enterprise, the message is clear: if your operational bottleneck is the reliability of complex visual content, the solution is no longer necessarily a closed Google product—it might be an open-source model you can run yourself.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1UjUf0KRfpbNaTSF2uk1Dz/7b76ade2243333f36713a89e8612b817/0yZhP9i_2swwDcPvoyypB.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/california-is-investigating-grok-over-ai-generated-csam-and-nonconsensual-deepfakes-202029635.html",
          "published_at": "Wed, 14 Jan 2026 20:20:29 +0000",
          "title": "California is investigating Grok over AI-generated CSAM and nonconsensual deepfakes",
          "standfirst": "California authorities have launched an investigation into xAI following weeks of reports that the chatbot was generating sexualized images of children. \"xAI appears to be facilitating the large-scale production of deepfake nonconsensual intimate images that are being used to harass women and girls across the internet, including via the social media platform X,\" California Attorney General Rob Bonta's office said in a statement. The statement cited a report that \"more than half of the 20,000 images generated by xAI between Christmas and New Years depicted people in minimal clothing,\" including some that appeared to be children. \"We have zero tolerance for the AI-based creation and dissemination of nonconsensual intimate images or of child sexual abuse material,” Bonta said. “Today, my office formally announces an investigation into xAI to determine whether and how xAI violated the law.The investigation was announced as California Governor Gavin Newsom also called on Bonta to investigate xAI. \"xAI’s decision to create and host a breeding ground for predators to spread nonconsensual sexually explicit AI deepfakes, including images that digitally undress children, is vile,\" Newsom wrote.xAI’s decision to create and host a breeding ground for predators to spread nonconsensual sexually explicit AI deepfakes, including images that digitally undress children, is vile.I am calling on the Attorney General to immediately investigate the company and hold xAI…— Governor Gavin Newsom (@CAgovernor) January 14, 2026 California authorities aren't the first to investigate the company following widespread reports of AI-generated child sexual abuse material (CSAM) and non-consensual intimate images of women. UK regulator Ofcom has also opened an official inquiry, and European Union officials have said they are also looking into the issue. Malaysia and Indonesia have moved to block Grok. Last week, xAI began imposing rate limits on Grok's image generation abilities, but has so far declined to pull the plug entirely. When asked to comment on the California investigation, xAI responded with an automated email that said \"Legacy Media Lies.\" Earlier on Wednesday, Elon Musk said he was \"not aware of any naked underage images generated by Grok.\" Notably, that statement does not directly refute Bonta's allegation that Grok is being used \"to alter images of children to depict them in minimal clothing and sexual situations.\" Musk said that \"the operating principle for Grok is to obey the laws\" and that the company works to address cases of \"adversarial hacking of Grok prompts.\" This article originally appeared on Engadget at https://www.engadget.com/ai/california-is-investigating-grok-over-ai-generated-csam-and-nonconsensual-deepfakes-202029635.html?src=rss",
          "content": "California authorities have launched an investigation into xAI following weeks of reports that the chatbot was generating sexualized images of children. \"xAI appears to be facilitating the large-scale production of deepfake nonconsensual intimate images that are being used to harass women and girls across the internet, including via the social media platform X,\" California Attorney General Rob Bonta's office said in a statement. The statement cited a report that \"more than half of the 20,000 images generated by xAI between Christmas and New Years depicted people in minimal clothing,\" including some that appeared to be children. \"We have zero tolerance for the AI-based creation and dissemination of nonconsensual intimate images or of child sexual abuse material,” Bonta said. “Today, my office formally announces an investigation into xAI to determine whether and how xAI violated the law.The investigation was announced as California Governor Gavin Newsom also called on Bonta to investigate xAI. \"xAI’s decision to create and host a breeding ground for predators to spread nonconsensual sexually explicit AI deepfakes, including images that digitally undress children, is vile,\" Newsom wrote.xAI’s decision to create and host a breeding ground for predators to spread nonconsensual sexually explicit AI deepfakes, including images that digitally undress children, is vile.I am calling on the Attorney General to immediately investigate the company and hold xAI…— Governor Gavin Newsom (@CAgovernor) January 14, 2026 California authorities aren't the first to investigate the company following widespread reports of AI-generated child sexual abuse material (CSAM) and non-consensual intimate images of women. UK regulator Ofcom has also opened an official inquiry, and European Union officials have said they are also looking into the issue. Malaysia and Indonesia have moved to block Grok. Last week, xAI began imposing rate limits on Grok's image generation abilities, but has so far declined to pull the plug entirely. When asked to comment on the California investigation, xAI responded with an automated email that said \"Legacy Media Lies.\" Earlier on Wednesday, Elon Musk said he was \"not aware of any naked underage images generated by Grok.\" Notably, that statement does not directly refute Bonta's allegation that Grok is being used \"to alter images of children to depict them in minimal clothing and sexual situations.\" Musk said that \"the operating principle for Grok is to obey the laws\" and that the company works to address cases of \"adversarial hacking of Grok prompts.\" This article originally appeared on Engadget at https://www.engadget.com/ai/california-is-investigating-grok-over-ai-generated-csam-and-nonconsensual-deepfakes-202029635.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/save-up-to-78-percent-on-expressvpn-two-year-plans-right-now-180602838.html",
          "published_at": "Wed, 14 Jan 2026 20:06:26 +0000",
          "title": "Save up to 78 percent on ExpressVPN two-year plans right now",
          "standfirst": "ExpressVPN is back on sale again, and its two-year plans are up to 78 percent off right now. You can get the Advanced tier for $101 for 28 months. This is marked down from the $392 that this time frame normally costs. On a per-month basis, it works out to roughly $3.59 for the promo period. We’ve consistently liked ExpressVPN because it’s fast, easy to use and widely available across a large global server network. In fact, it's our current pick for best premium VPN. One of the biggest drawbacks has always been its high cost, and this deal temporarily solves that issue. In our review we were able to get fast download and upload speeds, losing only 7 percent in the former and 2 percent in the latter worldwide. We found that it could unblock Netflix anywhere, and its mobile and desktop apps were simple to operate. We gave ExpressVPN an overall score of 85 out of 100. The virtual private network service now has three tiers. Basic is cheaper with fewer features, while Pro costs more and adds extra perks like support for 14 simultaneous devices and a password manager. Advanced sits in the middle and includes the password manager but only supports 12 devices. The Basic plan is $78 right now for 28 months, down from $363, and the Pro plan is $168, down from $560. That's 78 percent and 70 percent off, respectively. All plans carry a 30-day money-back guarantee for new users, so you can try it without committing long term if you’re on the fence.This article originally appeared on Engadget at https://www.engadget.com/deals/save-up-to-78-percent-on-expressvpn-two-year-plans-right-now-180602838.html?src=rss",
          "content": "ExpressVPN is back on sale again, and its two-year plans are up to 78 percent off right now. You can get the Advanced tier for $101 for 28 months. This is marked down from the $392 that this time frame normally costs. On a per-month basis, it works out to roughly $3.59 for the promo period. We’ve consistently liked ExpressVPN because it’s fast, easy to use and widely available across a large global server network. In fact, it's our current pick for best premium VPN. One of the biggest drawbacks has always been its high cost, and this deal temporarily solves that issue. In our review we were able to get fast download and upload speeds, losing only 7 percent in the former and 2 percent in the latter worldwide. We found that it could unblock Netflix anywhere, and its mobile and desktop apps were simple to operate. We gave ExpressVPN an overall score of 85 out of 100. The virtual private network service now has three tiers. Basic is cheaper with fewer features, while Pro costs more and adds extra perks like support for 14 simultaneous devices and a password manager. Advanced sits in the middle and includes the password manager but only supports 12 devices. The Basic plan is $78 right now for 28 months, down from $363, and the Pro plan is $168, down from $560. That's 78 percent and 70 percent off, respectively. All plans carry a 30-day money-back guarantee for new users, so you can try it without committing long term if you’re on the fence.This article originally appeared on Engadget at https://www.engadget.com/deals/save-up-to-78-percent-on-expressvpn-two-year-plans-right-now-180602838.html?src=rss",
          "feed_position": 39
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/ai-agents-can-talk-orchestration-is-what-makes-them-work-together",
          "published_at": "Wed, 14 Jan 2026 19:00:00 GMT",
          "title": "AI agents can talk — orchestration is what makes them work together",
          "standfirst": "Rather than asking how AI agents can work for them, a key question in enterprise is now: Are agents playing well together? This makes orchestration across multi-agent systems and platforms a critical concern — and a key differentiator. “Agent-to-agent communications is emerging as a really big deal,” G2’s chief innovation officer Tim Sanders told VentureBeat. “Because if you don&#x27;t orchestrate it, you get misunderstandings, like people speaking foreign languages to each other. Those misunderstandings reduce the quality of actions and raise the specter of hallucinations, which could be security incidents or data leakage.”Allowing agents to talk and coordinateOrchestration to this point has largely been around data, but that’s quickly turning to action. “Conductor-like solutions” are increasingly bringing together agents, robotic process automation (RPA), and data repositories. Sanders likened the progression to that of answer engine optimization, which initially began with monitoring and now creates bespoke content and code. “Orchestration platforms coordinate a variety of different agentic solutions to increase the consistency of outcomes,” he said. Early providers include Salesforce MuleSoft, UiPath Maestro, and IBM Watsonx Orchestrate. These “phase one” software-based observability dashboards help IT leaders see all agentic actions across an enterprise. The critical element of risk managementBut coordination can only add so much value; these platforms will morph into technical risk management tools that provide greater quality control. This could include, for instance, agent assessments, policy recommendation and proactive scoring (such as, how reliable agents are when they call on enterprise tools, or how often they hallucinate and when). Enterprise leaders have become wary of relying on vendors to minimize risks and errors; many IT decision-makers, in fact, do not trust a vendor&#x27;s statements about the reliability of their agents, he said. Third-party tools are beginning to bridge the gap and automate tedious guardrail processes and escalation tickets. Teams are already experiencing “ticket exhaustion” in semi-automated systems, where agents hit guardrails and require human permission to proceed.As an example: The loan process at a bank requires 17 steps for approval, and an agent keeps interrupting human workflows with approval requests when it runs into established guardrails. Third-party orchestration platforms can manage these tickets and nay, yay, or even challenge the need for approval altogether. They can eventually eliminate the need for persistent human-in-the-loop oversight so organizations can experience “true velocity gains” measured not in percentages but in multiples (that is, 3X versus 30%).“Where it goes from there is remote management of the entire agentic process for organizations,” Sanders said. ‘Human-on-the-loop’ versus ‘human-in-the-loop’ In another critical evolution in the agentic era, human evaluators will become designers, moving from human-in-the-loop to human-on-the-loop, according to Sanders. That is: They will begin designing agents to automate workflows. Agent builder platforms continue to innovate their no-code solutions, Sanders said, meaning nearly anyone can now stand up an agent using natural language. “This will democratize agentic AI, and the super skill will be the ability to express a goal, provide context and envision pitfalls, very similar to a good people manager today.”What enterprise leaders should be doing nowAgent-first automation stacks “dramatically outperform” hybrid automation stacks in almost every attribute, he noted: satisfaction, quality of actions, security, cost savings.Organizations should begin “expeditious programs” to infuse agents across workflows, especially with highly repetitive work that poses bottlenecks. Likely at first, there will be a strong human-in-the-loop element to ensure quality and promote change management. “Serving as an evaluator will strengthen the understanding of how these systems work,” Sanders said, “and eventually enable all of us to operate upstream in agentic workflows instead of downstream.” IT leaders should take inventory today of all the different elements of their automation stack. Whether these elements are rules-based automation, RPA, or agentic automation, they must learn everything going on in the organization to optimally use emerging orchestration platforms.“If they don&#x27;t, there could actually be dis-synergies across organizations where old school technology and cutting edge technology clash at the point of delivery, oftentimes customer-facing,” Sanders said. “You can&#x27;t orchestrate what you can&#x27;t see clearly.”",
          "content": "Rather than asking how AI agents can work for them, a key question in enterprise is now: Are agents playing well together? This makes orchestration across multi-agent systems and platforms a critical concern — and a key differentiator. “Agent-to-agent communications is emerging as a really big deal,” G2’s chief innovation officer Tim Sanders told VentureBeat. “Because if you don&#x27;t orchestrate it, you get misunderstandings, like people speaking foreign languages to each other. Those misunderstandings reduce the quality of actions and raise the specter of hallucinations, which could be security incidents or data leakage.”Allowing agents to talk and coordinateOrchestration to this point has largely been around data, but that’s quickly turning to action. “Conductor-like solutions” are increasingly bringing together agents, robotic process automation (RPA), and data repositories. Sanders likened the progression to that of answer engine optimization, which initially began with monitoring and now creates bespoke content and code. “Orchestration platforms coordinate a variety of different agentic solutions to increase the consistency of outcomes,” he said. Early providers include Salesforce MuleSoft, UiPath Maestro, and IBM Watsonx Orchestrate. These “phase one” software-based observability dashboards help IT leaders see all agentic actions across an enterprise. The critical element of risk managementBut coordination can only add so much value; these platforms will morph into technical risk management tools that provide greater quality control. This could include, for instance, agent assessments, policy recommendation and proactive scoring (such as, how reliable agents are when they call on enterprise tools, or how often they hallucinate and when). Enterprise leaders have become wary of relying on vendors to minimize risks and errors; many IT decision-makers, in fact, do not trust a vendor&#x27;s statements about the reliability of their agents, he said. Third-party tools are beginning to bridge the gap and automate tedious guardrail processes and escalation tickets. Teams are already experiencing “ticket exhaustion” in semi-automated systems, where agents hit guardrails and require human permission to proceed.As an example: The loan process at a bank requires 17 steps for approval, and an agent keeps interrupting human workflows with approval requests when it runs into established guardrails. Third-party orchestration platforms can manage these tickets and nay, yay, or even challenge the need for approval altogether. They can eventually eliminate the need for persistent human-in-the-loop oversight so organizations can experience “true velocity gains” measured not in percentages but in multiples (that is, 3X versus 30%).“Where it goes from there is remote management of the entire agentic process for organizations,” Sanders said. ‘Human-on-the-loop’ versus ‘human-in-the-loop’ In another critical evolution in the agentic era, human evaluators will become designers, moving from human-in-the-loop to human-on-the-loop, according to Sanders. That is: They will begin designing agents to automate workflows. Agent builder platforms continue to innovate their no-code solutions, Sanders said, meaning nearly anyone can now stand up an agent using natural language. “This will democratize agentic AI, and the super skill will be the ability to express a goal, provide context and envision pitfalls, very similar to a good people manager today.”What enterprise leaders should be doing nowAgent-first automation stacks “dramatically outperform” hybrid automation stacks in almost every attribute, he noted: satisfaction, quality of actions, security, cost savings.Organizations should begin “expeditious programs” to infuse agents across workflows, especially with highly repetitive work that poses bottlenecks. Likely at first, there will be a strong human-in-the-loop element to ensure quality and promote change management. “Serving as an evaluator will strengthen the understanding of how these systems work,” Sanders said, “and eventually enable all of us to operate upstream in agentic workflows instead of downstream.” IT leaders should take inventory today of all the different elements of their automation stack. Whether these elements are rules-based automation, RPA, or agentic automation, they must learn everything going on in the organization to optimally use emerging orchestration platforms.“If they don&#x27;t, there could actually be dis-synergies across organizations where old school technology and cutting edge technology clash at the point of delivery, oftentimes customer-facing,” Sanders said. “You can&#x27;t orchestrate what you can&#x27;t see clearly.”",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7szF9iF50458lvbJ6Hyb36/9cb490b66a50d662947b1fd978204626/G2.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/he-could-just-turn-it-off-180209551.html",
          "published_at": "Wed, 14 Jan 2026 18:02:09 +0000",
          "title": "He could just turn it off",
          "standfirst": "Generative AI, we are repeatedly told, is a transformative and complicated technology. So complicated that its own creators are unable to explain why it acts the way it does, and so transformative that we'd be fools to stand in the way of progress. Even when progress resembles a machine for undressing strangers without their consent on an unprecedented scale, as has been the case of late with Elon Musk's Grok chatbot. UK Prime Minister Kier Starmer seems to have so fully bought into the grand lie of the AI bubble that he was willing to announce: \"I have been informed this morning that X is acting to ensure full compliance with UK law.\" Not that it currently is in compliance. Nor a timeline in which it is expected to do so. Just that he seems satisfied that someday, eventually, Musk's pet robot will stop generating child sexual abuse material. This statement comes just under two days after Starmer was quoted as saying \"If X cannot control Grok, we will.\" What could Elon possibly have said to earn this pathetic capitulation. AI is difficult? Solutions take time? These are entirely cogent technical arguments until you remember: He could just turn it off. Elon Musk has the power to disable Grok, if not in whole (we should be so lucky) than its image generation capabilities. We know this intuitively, but also because he rate-limited Grok's image generation after this latest scandal: after a few requests, free users are now prompted to pay $8 per month to continue enlisting a wasteful technology to remove articles of clothing from women. Sweep it under the rug, make a couple bucks along the way. Not only is it entirely possible for image generation to be turned off, it's the only responsible option. Software engineers regularly roll back updates or turn off features that work less than optimally; this one's still up and running despite likely running afoul of the law. That we have now gone the better part of a month aware this problem exists; that the \"feature\" still remains should tell Starmer and others all they need to know. Buddy, you're carrying water for a bozo who does not seem to care that one such victim was reportedly Ashley St Clair, the mother of one of his (many) children. Some countries — namely Malaysia and Indonesia — chose to turn Grok off for their citizens by blocking the service. Indonesia's Communication and Digital Affairs Minister was quoted as saying “The government sees nonconsensual sexual deepfakes as a serious violation of human rights.\" Imagine if everyone in the business of statecraft felt that way. The UK (not to mention the US, but please, expect nothing from us, we're busy doing authoritarianism) has a lot more sway over X, and by extension Elon, than either of those countries. Musk does, and is looking to do even more, business in the UK. Even if Musk were not perhaps the world's most well known liar, Grok can still make images and that should speak for itself. Grok should be well out of second chances by now, and it's up to government leaders to say no more until they can independently verify it's no longer capable of harm.This article originally appeared on Engadget at https://www.engadget.com/he-could-just-turn-it-off-180209551.html?src=rss",
          "content": "Generative AI, we are repeatedly told, is a transformative and complicated technology. So complicated that its own creators are unable to explain why it acts the way it does, and so transformative that we'd be fools to stand in the way of progress. Even when progress resembles a machine for undressing strangers without their consent on an unprecedented scale, as has been the case of late with Elon Musk's Grok chatbot. UK Prime Minister Kier Starmer seems to have so fully bought into the grand lie of the AI bubble that he was willing to announce: \"I have been informed this morning that X is acting to ensure full compliance with UK law.\" Not that it currently is in compliance. Nor a timeline in which it is expected to do so. Just that he seems satisfied that someday, eventually, Musk's pet robot will stop generating child sexual abuse material. This statement comes just under two days after Starmer was quoted as saying \"If X cannot control Grok, we will.\" What could Elon possibly have said to earn this pathetic capitulation. AI is difficult? Solutions take time? These are entirely cogent technical arguments until you remember: He could just turn it off. Elon Musk has the power to disable Grok, if not in whole (we should be so lucky) than its image generation capabilities. We know this intuitively, but also because he rate-limited Grok's image generation after this latest scandal: after a few requests, free users are now prompted to pay $8 per month to continue enlisting a wasteful technology to remove articles of clothing from women. Sweep it under the rug, make a couple bucks along the way. Not only is it entirely possible for image generation to be turned off, it's the only responsible option. Software engineers regularly roll back updates or turn off features that work less than optimally; this one's still up and running despite likely running afoul of the law. That we have now gone the better part of a month aware this problem exists; that the \"feature\" still remains should tell Starmer and others all they need to know. Buddy, you're carrying water for a bozo who does not seem to care that one such victim was reportedly Ashley St Clair, the mother of one of his (many) children. Some countries — namely Malaysia and Indonesia — chose to turn Grok off for their citizens by blocking the service. Indonesia's Communication and Digital Affairs Minister was quoted as saying “The government sees nonconsensual sexual deepfakes as a serious violation of human rights.\" Imagine if everyone in the business of statecraft felt that way. The UK (not to mention the US, but please, expect nothing from us, we're busy doing authoritarianism) has a lot more sway over X, and by extension Elon, than either of those countries. Musk does, and is looking to do even more, business in the UK. Even if Musk were not perhaps the world's most well known liar, Grok can still make images and that should speak for itself. Grok should be well out of second chances by now, and it's up to government leaders to say no more until they can independently verify it's no longer capable of harm.This article originally appeared on Engadget at https://www.engadget.com/he-could-just-turn-it-off-180209551.html?src=rss",
          "feed_position": 41
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/how-to-turn-off-a-vpn-on-iphone-180000533.html",
          "published_at": "Wed, 14 Jan 2026 18:00:00 +0000",
          "title": "How to turn off a VPN on iPhone",
          "standfirst": "Look, virtual private networks are great — I wouldn't have made a list of the best VPNs if I didn't recommend using them. But being able to control your own technology is also important. A VPN can provide protection and peace of mind when used properly, but you may not want it active on your phone all the time.For example: Are your Google search results suddenly in German? That’s one example of what can happen if you leave your virtual location set to Berlin or Vienna. Or maybe a VPN you installed for work or to watch a single tennis match is persistently trying to keep itself active.The point is, deactivating a VPN on an iPhone can sometimes be unusually tricky, because there’s more than one off switch. Fortunately, it's not hard. There are several easy ways to disconnect from an iOS VPN or delete it entirely. If you catch it turning itself back on, I'll show you how to stop that too.Three ways to turn off your iPhone VPNI'm using a fluid definition of \"turn off\" here. Some of the steps below simply disconnect the VPN, while others remove it from your phone altogether. I'll make it clear in each section what the outcome will be.How to disconnect in the VPN appThis is the easiest way to turn off a VPN on your iPhone. First, find the VPN app that’s active, which should be on your home screen somewhere. Each app has a different interface for connecting and disconnecting, but the disconnect button should be fairly obvious — it may say the word \"disconnect\" or show a green power icon. In any case, it should be right on the home screen, without requiring any digging through menus.Example of where to find the disconnect option on a VPN's home screen.Sam Chapman for EngadgetTap the disconnect button and wait for the VPN to clearly state that it's disconnected. Check to make sure the rectangle with \"VPN\" inside has disappeared from the top of your iPhone screen. The VPN is now disconnected.How to turn off the VPN in SettingsIf you aren't sure which VPN app is active, or if its interface doesn't make it clear how to turn it off, you can shut it down from the Settings menu instead. Find the app on your home screen that looks like several interlocking gray gears and tap it.Next, scroll down and tap the VPN option. If it's not present (which it won’t be on older iOS versions), tap the General option next to another picture of a gray gear. Scroll down again and tap VPN & Device Management by yet another gray gear. Finally, tap the VPN option at the top of the screen to reach the VPN management page.Location of the VPN settings on iOS.Sam Chapman for EngadgetIf you have a VPN active, you should see an option at the top of the page labeled VPN Status. Toggle it from Connected to Not Connected. The VPN icon should disappear from the top of your screen, indicating that it's turned off.How to delete the VPN app altogetherIf you don't want the VPN on your phone at all, you can turn it off permanently by deleting both the app and the configuration. This is a lot harder to undo, so only do it if you're certain.Start by deleting the app the same way you'd get rid of any other app. Tap the icon and hold until a pop-up menu appears. Select the Remove App option in red text, then click Remove App again when prompted.Deleting a VPN on the iOS home screen.Sam Chapman for EngadgetDeleting the app should also delete the configuration, but you can verify this for yourself. Follow the process from the previous section to find the VPN settings page. If there's still a VPN profile in those settings, tap the circled letter \"i\" next to its name, then tap Delete VPN at the bottom of the screen. The VPN is now gone from your iPhone unless you re-download it from the App Store.Troubleshooting: When an iPhone VPN turns itself back onSometimes, even though you've followed all the steps, that pesky VPN rectangle is back on your screen the next time you unlock your phone. If your iOS VPN keeps turning itself back on, a few things might be happening, most of them thankfully fixable.If you did not delete the VPN, it may be turning itself back on because its settings are telling it to. Go into its preferences menu and check for a setting called \"auto-connect\" or something similar. Settings like these have the VPN connect by itself to protect users who forget to activate it manually. Toggle all auto-connect options off and the problem should stop.It's also possible that settings on the iOS side are making the VPN reconnect. Go to the VPN settings page (you'll find instructions for getting there in the previous section) and find the name of the active VPN profile. Tap the \"i\" next to it. On the next page, turn off \"connect on demand\" to stop the automatic reconnections.If you did delete the VPN, but it's still reinstalling itself and turning back on, make sure that you deleted both the app and the connection profile. Reboot your iPhone to make sure all the settings stick. If the problem persists after all this, you've either got malware disguised as a VPN or you're using a school or work phone where the VPN can't be uninstalled.If you aren't on a phone provided by a school or office, meaning you probably have malware, download an antivirus app and run a complete scan of your iPhone. This should remove any persistent files that keep reinstalling the virus. If, after all this, the VPN is still turning itself back on, I recommend burning your phone in a salt circle with a bundle of sage.When should you turn off your iPhone VPN?I encourage everyone to use a VPN every time they connect to the internet, but there are some situations where going through a VPN server is less convenient (this is the whole reason split tunneling exists). Here are a few cases in which temporarily turning off your VPN might be a good idea.The VPN isn't working. If your browsing speed is sluggish or the VPN keeps dropping the connection, your VPN server might be having problems. Disconnecting and reconnecting, even in the same location, should switch you to a different server that may work better.The VPN is causing unintended browsing errors. If you’re using mapping software or just trying to do a location-based search, having your VPN active can cause more problems than it solves. Your internet connection is unstable. A VPN adds an extra step to the process of getting online. If your phone is already struggling, the VPN might be an unnecessary complication.You're on a site that blocks all VPNs. Sites that work based on your location, including all streaming sites, may blanket-block VPNs so nothing messes with their location services. Good VPNs can get around these blocks, but even the best sometimes fail. In these cases, briefly turning off the VPN may be a good idea.Your battery is low. VPNs can put a strain on your phone's battery life. This varies with the quality of your VPN, but you may sometimes need to shut it off if your battery is in the red.How to turn off iCloud Private RelayiCloud Private Relay is not a VPN, but it's often confused for one. If you found this page because you want to turn it off, you're in luck — the steps are just as simple as turning off a VPN. Start by opening Settings, then tap your name. Scroll down and tap iCloud.Private Relay will only be active if you're an iCloud+ subscriber. If you are, tap Private Relay, then choose whether to turn it off temporarily or indefinitely.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-turn-off-a-vpn-on-iphone-180000533.html?src=rss",
          "content": "Look, virtual private networks are great — I wouldn't have made a list of the best VPNs if I didn't recommend using them. But being able to control your own technology is also important. A VPN can provide protection and peace of mind when used properly, but you may not want it active on your phone all the time.For example: Are your Google search results suddenly in German? That’s one example of what can happen if you leave your virtual location set to Berlin or Vienna. Or maybe a VPN you installed for work or to watch a single tennis match is persistently trying to keep itself active.The point is, deactivating a VPN on an iPhone can sometimes be unusually tricky, because there’s more than one off switch. Fortunately, it's not hard. There are several easy ways to disconnect from an iOS VPN or delete it entirely. If you catch it turning itself back on, I'll show you how to stop that too.Three ways to turn off your iPhone VPNI'm using a fluid definition of \"turn off\" here. Some of the steps below simply disconnect the VPN, while others remove it from your phone altogether. I'll make it clear in each section what the outcome will be.How to disconnect in the VPN appThis is the easiest way to turn off a VPN on your iPhone. First, find the VPN app that’s active, which should be on your home screen somewhere. Each app has a different interface for connecting and disconnecting, but the disconnect button should be fairly obvious — it may say the word \"disconnect\" or show a green power icon. In any case, it should be right on the home screen, without requiring any digging through menus.Example of where to find the disconnect option on a VPN's home screen.Sam Chapman for EngadgetTap the disconnect button and wait for the VPN to clearly state that it's disconnected. Check to make sure the rectangle with \"VPN\" inside has disappeared from the top of your iPhone screen. The VPN is now disconnected.How to turn off the VPN in SettingsIf you aren't sure which VPN app is active, or if its interface doesn't make it clear how to turn it off, you can shut it down from the Settings menu instead. Find the app on your home screen that looks like several interlocking gray gears and tap it.Next, scroll down and tap the VPN option. If it's not present (which it won’t be on older iOS versions), tap the General option next to another picture of a gray gear. Scroll down again and tap VPN & Device Management by yet another gray gear. Finally, tap the VPN option at the top of the screen to reach the VPN management page.Location of the VPN settings on iOS.Sam Chapman for EngadgetIf you have a VPN active, you should see an option at the top of the page labeled VPN Status. Toggle it from Connected to Not Connected. The VPN icon should disappear from the top of your screen, indicating that it's turned off.How to delete the VPN app altogetherIf you don't want the VPN on your phone at all, you can turn it off permanently by deleting both the app and the configuration. This is a lot harder to undo, so only do it if you're certain.Start by deleting the app the same way you'd get rid of any other app. Tap the icon and hold until a pop-up menu appears. Select the Remove App option in red text, then click Remove App again when prompted.Deleting a VPN on the iOS home screen.Sam Chapman for EngadgetDeleting the app should also delete the configuration, but you can verify this for yourself. Follow the process from the previous section to find the VPN settings page. If there's still a VPN profile in those settings, tap the circled letter \"i\" next to its name, then tap Delete VPN at the bottom of the screen. The VPN is now gone from your iPhone unless you re-download it from the App Store.Troubleshooting: When an iPhone VPN turns itself back onSometimes, even though you've followed all the steps, that pesky VPN rectangle is back on your screen the next time you unlock your phone. If your iOS VPN keeps turning itself back on, a few things might be happening, most of them thankfully fixable.If you did not delete the VPN, it may be turning itself back on because its settings are telling it to. Go into its preferences menu and check for a setting called \"auto-connect\" or something similar. Settings like these have the VPN connect by itself to protect users who forget to activate it manually. Toggle all auto-connect options off and the problem should stop.It's also possible that settings on the iOS side are making the VPN reconnect. Go to the VPN settings page (you'll find instructions for getting there in the previous section) and find the name of the active VPN profile. Tap the \"i\" next to it. On the next page, turn off \"connect on demand\" to stop the automatic reconnections.If you did delete the VPN, but it's still reinstalling itself and turning back on, make sure that you deleted both the app and the connection profile. Reboot your iPhone to make sure all the settings stick. If the problem persists after all this, you've either got malware disguised as a VPN or you're using a school or work phone where the VPN can't be uninstalled.If you aren't on a phone provided by a school or office, meaning you probably have malware, download an antivirus app and run a complete scan of your iPhone. This should remove any persistent files that keep reinstalling the virus. If, after all this, the VPN is still turning itself back on, I recommend burning your phone in a salt circle with a bundle of sage.When should you turn off your iPhone VPN?I encourage everyone to use a VPN every time they connect to the internet, but there are some situations where going through a VPN server is less convenient (this is the whole reason split tunneling exists). Here are a few cases in which temporarily turning off your VPN might be a good idea.The VPN isn't working. If your browsing speed is sluggish or the VPN keeps dropping the connection, your VPN server might be having problems. Disconnecting and reconnecting, even in the same location, should switch you to a different server that may work better.The VPN is causing unintended browsing errors. If you’re using mapping software or just trying to do a location-based search, having your VPN active can cause more problems than it solves. Your internet connection is unstable. A VPN adds an extra step to the process of getting online. If your phone is already struggling, the VPN might be an unnecessary complication.You're on a site that blocks all VPNs. Sites that work based on your location, including all streaming sites, may blanket-block VPNs so nothing messes with their location services. Good VPNs can get around these blocks, but even the best sometimes fail. In these cases, briefly turning off the VPN may be a good idea.Your battery is low. VPNs can put a strain on your phone's battery life. This varies with the quality of your VPN, but you may sometimes need to shut it off if your battery is in the red.How to turn off iCloud Private RelayiCloud Private Relay is not a VPN, but it's often confused for one. If you found this page because you want to turn it off, you're in luck — the steps are just as simple as turning off a VPN. Start by opening Settings, then tap your name. Scroll down and tap iCloud.Private Relay will only be active if you're an iCloud+ subscriber. If you are, tap Private Relay, then choose whether to turn it off temporarily or indefinitely.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-turn-off-a-vpn-on-iphone-180000533.html?src=rss",
          "feed_position": 42,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Proton_VPN_disconnect.PNG"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/get-three-months-of-audible-for-only-3-193859098.html",
          "published_at": "Wed, 14 Jan 2026 17:46:26 +0000",
          "title": "Get three months of Audible for only $3",
          "standfirst": "Have a hankering for some audiobooks? Audible is holding one heck of a sale right now, giving users three months of access for $3. That's a dollar per month. This is something of a winter tradition for the Amazon-owned platform and the promotion ends on January 21. An Audible subscription grants one audiobook per month to keep. This can be selected from a massive catalog of new releases and bestsellers. The collection here has just about everything. However, it's easy to plow through a single book in a month. Users also get streaming access to thousands of curated titles. Think of it like Netflix for audiobooks. The catalog is limited, but it gets the job done in a pinch. Subscribers do get access to all Audible original content and they will receive discounts on purchasing audiobooks outright. In other words, it's a neat little service and well worth a buck. The regular price is $15, so make sure to cancel at the end of that three months if you aren't enjoying the platform. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-three-months-of-audible-for-only-3-193859098.html?src=rss",
          "content": "Have a hankering for some audiobooks? Audible is holding one heck of a sale right now, giving users three months of access for $3. That's a dollar per month. This is something of a winter tradition for the Amazon-owned platform and the promotion ends on January 21. An Audible subscription grants one audiobook per month to keep. This can be selected from a massive catalog of new releases and bestsellers. The collection here has just about everything. However, it's easy to plow through a single book in a month. Users also get streaming access to thousands of curated titles. Think of it like Netflix for audiobooks. The catalog is limited, but it gets the job done in a pinch. Subscribers do get access to all Audible original content and they will receive discounts on purchasing audiobooks outright. In other words, it's a neat little service and well worth a buck. The regular price is $15, so make sure to cancel at the end of that three months if you aren't enjoying the platform. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-three-months-of-audible-for-only-3-193859098.html?src=rss",
          "feed_position": 43
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-first-gen-bose-quietcomfort-ultra-headphones-are-150-off-right-now-164826329.html",
          "published_at": "Wed, 14 Jan 2026 16:48:26 +0000",
          "title": "The first-gen Bose QuietComfort Ultra headphones are $150 off right now",
          "standfirst": "The first-generation Bose QuietComfort Ultra headphones are on sale right now for $280, marked down from $430. That 35 percent savings is an even steeper discount than we saw last year Black Friday. In our review of the first-generation Ultras, we gave them a score of 86 out of 100, noting their best-in-class active noise cancellation (ANC) and comfort. Bose improved its stock tuning for these headphones, which we could immediately tell sounded warmer and clearer. Bose has typically lagged behind the likes of Sony and Sennheiser in raw sound quality, but the first-generation QuietComfort Ultra was a big step toward catching up. Bose added \"Immersive Audio\" to this model, which is the company's take on spatial audio. The company claims this feature effectively puts you in the acoustic sweet spot of a set of stereo speakers. In our testing, we felt this didn't always make songs sound better, but it did make them louder and in some cases made certain details more noticeable. The Ultras offer up to 24 hours of battery life with ANC turned on and about 18 hours with both ANC and Immersive Audio enabled. In our testing, however, we were actually able to beat Bose's estimates for battery life. The second generation of these headphones are currently our top pick for best noise-canceling headphones, but when this older model is heavily on sale, the differences between them are less dramatic. If you're in the market for a pair of great noise-canceling cans, consider checking these out. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-first-gen-bose-quietcomfort-ultra-headphones-are-150-off-right-now-164826329.html?src=rss",
          "content": "The first-generation Bose QuietComfort Ultra headphones are on sale right now for $280, marked down from $430. That 35 percent savings is an even steeper discount than we saw last year Black Friday. In our review of the first-generation Ultras, we gave them a score of 86 out of 100, noting their best-in-class active noise cancellation (ANC) and comfort. Bose improved its stock tuning for these headphones, which we could immediately tell sounded warmer and clearer. Bose has typically lagged behind the likes of Sony and Sennheiser in raw sound quality, but the first-generation QuietComfort Ultra was a big step toward catching up. Bose added \"Immersive Audio\" to this model, which is the company's take on spatial audio. The company claims this feature effectively puts you in the acoustic sweet spot of a set of stereo speakers. In our testing, we felt this didn't always make songs sound better, but it did make them louder and in some cases made certain details more noticeable. The Ultras offer up to 24 hours of battery life with ANC turned on and about 18 hours with both ANC and Immersive Audio enabled. In our testing, however, we were actually able to beat Bose's estimates for battery life. The second generation of these headphones are currently our top pick for best noise-canceling headphones, but when this older model is heavily on sale, the differences between them are less dramatic. If you're in the market for a pair of great noise-canceling cans, consider checking these out. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-first-gen-bose-quietcomfort-ultra-headphones-are-150-off-right-now-164826329.html?src=rss",
          "feed_position": 44
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-mac-mini-m4-is-back-on-sale-for-499-141615907.html",
          "published_at": "Wed, 14 Jan 2026 16:06:26 +0000",
          "title": "The Mac mini M4 is back on sale for $499",
          "standfirst": "The holiday season may be behind us, but that doesn't mean you can't still find good deals on some of our favorite tech. Take the Apple Mac mini M4, which is on sale for $100 off. The 17 percent discount gives you 16GB of RAM and 256GB of SSD for $499, which is only about $20 more than its Black Friday sale price. Its beefier models are also on sale: opting for 512GB of SSD will cost you $689, down from $799, while also upping your RAM to 24GB is available for $890, dropping from $999. We gave the Apple Mac mini M4 a 90 in our review thanks in large part to its powerful chip. The M4 works very fast despite being in such a small device. It also offers front-facing headphone and USB-C ports. You can further upgrade to the Apple M4 Pro chip for $1,270, down from $1,399 — a nine percent discount. The Pro model also has Thunderbolt 5 support. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-mac-mini-m4-is-back-on-sale-for-499-141615907.html?src=rss",
          "content": "The holiday season may be behind us, but that doesn't mean you can't still find good deals on some of our favorite tech. Take the Apple Mac mini M4, which is on sale for $100 off. The 17 percent discount gives you 16GB of RAM and 256GB of SSD for $499, which is only about $20 more than its Black Friday sale price. Its beefier models are also on sale: opting for 512GB of SSD will cost you $689, down from $799, while also upping your RAM to 24GB is available for $890, dropping from $999. We gave the Apple Mac mini M4 a 90 in our review thanks in large part to its powerful chip. The M4 works very fast despite being in such a small device. It also offers front-facing headphone and USB-C ports. You can further upgrade to the Apple M4 Pro chip for $1,270, down from $1,399 — a nine percent discount. The Pro model also has Thunderbolt 5 support. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-mac-mini-m4-is-back-on-sale-for-499-141615907.html?src=rss",
          "feed_position": 45
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/gemini-can-now-pull-context-the-rest-of-your-google-apps-if-you-let-it-160039468.html",
          "published_at": "Wed, 14 Jan 2026 16:00:39 +0000",
          "title": "Gemini can now pull context the rest of your Google apps, if you let it",
          "standfirst": "Gemini is adding a feature that’s designed to feel more tailored to individual users. Once enabled, \"Personal Intelligence\" can pull context from across your Google ecosystem, including Gmail, Google Photos, Search and YouTube History, to gain specific insight that will shape its answers and recommendations. Personal Intelligence is available starting today in the US for Google AI Pro and Ultra subscribers. The feature is opt-in only and is off by default. Google Google says users will have the ability to control what apps Gemini pulls from and, in the future, which chats it uses Personal Intelligence for. The company says this new feature might still make some mistakes, such as “over-personalization” where it draws connections between unrelated things. According to Google, Gemini will not train directly on the data it pulls for personalization like your photos and emails, but will instead train on your prompts and its responses. Users can also prompt Gemini to \"try again\" without personalization and will have the option to delete chat histories. For now, Personal Intelligence works in the Gemini app across web, Android and iOS for personal Google accounts. Google says it’s coming to Search’s AI Mode soon, with plans to expand to more countries and the free tier down the line. Google has been on a tear integrating Gemini into everything, including Gmail, TVs and Chrome on mobile. This week, Apple announced that Siri AI will be powered by Gemini as part of a multi-year collaboration. AI remains an imperfect tool, and Google's AI has a long history of malfunctions like explaining made-up idioms, calling itself a \"failure\" in a depressing doom loop and generating images of the Founding Fathers as people of color.This article originally appeared on Engadget at https://www.engadget.com/ai/gemini-can-now-pull-context-the-rest-of-your-google-apps-if-you-let-it-160039468.html?src=rss",
          "content": "Gemini is adding a feature that’s designed to feel more tailored to individual users. Once enabled, \"Personal Intelligence\" can pull context from across your Google ecosystem, including Gmail, Google Photos, Search and YouTube History, to gain specific insight that will shape its answers and recommendations. Personal Intelligence is available starting today in the US for Google AI Pro and Ultra subscribers. The feature is opt-in only and is off by default. Google Google says users will have the ability to control what apps Gemini pulls from and, in the future, which chats it uses Personal Intelligence for. The company says this new feature might still make some mistakes, such as “over-personalization” where it draws connections between unrelated things. According to Google, Gemini will not train directly on the data it pulls for personalization like your photos and emails, but will instead train on your prompts and its responses. Users can also prompt Gemini to \"try again\" without personalization and will have the option to delete chat histories. For now, Personal Intelligence works in the Gemini app across web, Android and iOS for personal Google accounts. Google says it’s coming to Search’s AI Mode soon, with plans to expand to more countries and the free tier down the line. Google has been on a tear integrating Gemini into everything, including Gmail, TVs and Chrome on mobile. This week, Apple announced that Siri AI will be powered by Gemini as part of a multi-year collaboration. AI remains an imperfect tool, and Google's AI has a long history of malfunctions like explaining made-up idioms, calling itself a \"failure\" in a depressing doom loop and generating images of the Founding Fathers as people of color.This article originally appeared on Engadget at https://www.engadget.com/ai/gemini-can-now-pull-context-the-rest-of-your-google-apps-if-you-let-it-160039468.html?src=rss",
          "feed_position": 46,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/38ff43e0-f156-11f0-b7ef-806c828a134c"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/youtube/youtube-adds-more-parental-controls-including-a-way-to-block-teens-from-watching-shorts-151329673.html",
          "published_at": "Wed, 14 Jan 2026 15:13:29 +0000",
          "title": "YouTube adds more parental controls, including a way to block teens from watching Shorts",
          "standfirst": "YouTube is rolling out some additional parental controls, including a way to set time limits for viewing Shorts on teen accounts. In the near future, parents and guardians will be able to set the Shorts timer to zero on supervised accounts. \"This is an industry-first feature that puts parents firmly in control of the amount of short-form content their kids watch,\" Jennifer Flannery O'Connor, YouTube's vice president of product management, wrote in a blog post. Along with that, take-a-break and bedtime reminders are now enabled by default for users aged 13-17. The platform is also bringing in new principles, under which it will recommend more age-appropriate and \"enriching\" videos to teens. For instance, YouTube will suggest videos from the likes of Khan Academy, CrashCourse and TED-Ed to them more often. It said it developed these principles (and a guide for creators to make teen-friendly videos) with help from its youth advisory committee, the Center for Scholars and Storytellers at UCLA, the American Psychological Association, the Digital Wellness Lab at Boston Children’s Hospital and other organizations.Moreover, an updated sign-up process for kid accounts will be available in the coming weeks. Kid accounts are tied to parental ones, and don't have their own associated email address or a password. YouTube says users will be able to switch between accounts in the mobile app with just a few taps. \"This makes it easier to ensure that everyone in the family is in the right viewing experience with the content settings and recommendations of age-appropriate content they actually want to watch,\" O'Connor wrote.This article originally appeared on Engadget at https://www.engadget.com/entertainment/youtube/youtube-adds-more-parental-controls-including-a-way-to-block-teens-from-watching-shorts-151329673.html?src=rss",
          "content": "YouTube is rolling out some additional parental controls, including a way to set time limits for viewing Shorts on teen accounts. In the near future, parents and guardians will be able to set the Shorts timer to zero on supervised accounts. \"This is an industry-first feature that puts parents firmly in control of the amount of short-form content their kids watch,\" Jennifer Flannery O'Connor, YouTube's vice president of product management, wrote in a blog post. Along with that, take-a-break and bedtime reminders are now enabled by default for users aged 13-17. The platform is also bringing in new principles, under which it will recommend more age-appropriate and \"enriching\" videos to teens. For instance, YouTube will suggest videos from the likes of Khan Academy, CrashCourse and TED-Ed to them more often. It said it developed these principles (and a guide for creators to make teen-friendly videos) with help from its youth advisory committee, the Center for Scholars and Storytellers at UCLA, the American Psychological Association, the Digital Wellness Lab at Boston Children’s Hospital and other organizations.Moreover, an updated sign-up process for kid accounts will be available in the coming weeks. Kid accounts are tied to parental ones, and don't have their own associated email address or a password. YouTube says users will be able to switch between accounts in the mobile app with just a few taps. \"This makes it easier to ensure that everyone in the family is in the right viewing experience with the content settings and recommendations of age-appropriate content they actually want to watch,\" O'Connor wrote.This article originally appeared on Engadget at https://www.engadget.com/entertainment/youtube/youtube-adds-more-parental-controls-including-a-way-to-block-teens-from-watching-shorts-151329673.html?src=rss",
          "feed_position": 47
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-from-ugreen-is-32-percent-off-right-now-214707806.html",
          "published_at": "Wed, 14 Jan 2026 15:06:26 +0000",
          "title": "Our favorite 3-in-1 wireless charger from UGreen is 32 percent off right now",
          "standfirst": "You can easily spruce up your nightstand or desk by decluttering a bit, replacing some of those annoying charging cables with a good wireless charging setup. One of our favorites that can handle three devices at once is the UGREEN MagFlow Qi2 3-in-1 Charger Station 25W. Normally $140, it's on sale right now for $95; that's 32 percent off and only about $5 more than its record-low price. This is our top pick for a 3-in-1 charging pad thanks to its versatility. The UGREEN can work equally well as a permanent fixture in your home or act as a portable charging station. It boasts a foldable design and has smart little design details to keep it feeling like a premium product. The Qi2 25W charging works across a range of iPhone models and accessories, such as AirPods. There's also a dedicated part of the pad's design for an Apple Watch, which uses a proprietary charging standard, to power up too. Just note that you'll need a newer model of phone and the latest iOS 26 in order to take full advantage of the 25W charging capability. The wireless pad also comes with both a charging plug and a cable. We felt this UGREEN model was a great value at $140, so being able to snag one for a third of the usual price is an even better deal. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-from-ugreen-is-32-percent-off-right-now-214707806.html?src=rss",
          "content": "You can easily spruce up your nightstand or desk by decluttering a bit, replacing some of those annoying charging cables with a good wireless charging setup. One of our favorites that can handle three devices at once is the UGREEN MagFlow Qi2 3-in-1 Charger Station 25W. Normally $140, it's on sale right now for $95; that's 32 percent off and only about $5 more than its record-low price. This is our top pick for a 3-in-1 charging pad thanks to its versatility. The UGREEN can work equally well as a permanent fixture in your home or act as a portable charging station. It boasts a foldable design and has smart little design details to keep it feeling like a premium product. The Qi2 25W charging works across a range of iPhone models and accessories, such as AirPods. There's also a dedicated part of the pad's design for an Apple Watch, which uses a proprietary charging standard, to power up too. Just note that you'll need a newer model of phone and the latest iOS 26 in order to take full advantage of the 25W charging capability. The wireless pad also comes with both a charging plug and a cable. We felt this UGREEN model was a great value at $140, so being able to snag one for a third of the usual price is an even better deal. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-from-ugreen-is-32-percent-off-right-now-214707806.html?src=rss",
          "feed_position": 48
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/2O6Qr56XqUqVJ0oxVIN0iL/cbac7e02f806b97695bbc4df6b6fe226/Gemini_Generated_Image_autofiautofiauto.png?w=300&q=30",
      "popularity_score": 2018.6880894444444
    },
    {
      "id": "cluster_26",
      "coverage": 2,
      "updated_at": "Thu, 15 Jan 2026 23:05:01 -0500",
      "title": "Meta will discontinue Workrooms, its VR space for workers, on February 16; Quest headsets and Horizon services will not be sold to businesses as of February 20 (Sean Hollister/The Verge)",
      "neutral_headline": "Meta has discontinued its metaverse for work, too",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260115/p56#a260115p56",
          "published_at": "Thu, 15 Jan 2026 23:05:01 -0500",
          "title": "Meta will discontinue Workrooms, its VR space for workers, on February 16; Quest headsets and Horizon services will not be sold to businesses as of February 20 (Sean Hollister/The Verge)",
          "standfirst": "Sean Hollister / The Verge: Meta will discontinue Workrooms, its VR space for workers, on February 16; Quest headsets and Horizon services will not be sold to businesses as of February 20 &mdash; Meta continues to trickle out the bad news for VR. &hellip; Today, the company announced it's shutting that space down &hellip;",
          "content": "Sean Hollister / The Verge: Meta will discontinue Workrooms, its VR space for workers, on February 16; Quest headsets and Horizon services will not be sold to businesses as of February 20 &mdash; Meta continues to trickle out the bad news for VR. &hellip; Today, the company announced it's shutting that space down &hellip;",
          "feed_position": 7,
          "image_url": "http://www.techmeme.com/260115/i56.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/863209/meta-has-discontinued-its-metaverse-for-work-too",
          "published_at": "2026-01-15T21:01:35-05:00",
          "title": "Meta has discontinued its metaverse for work, too",
          "standfirst": "Two months before it changed its name to \"Meta,\" Facebook CEO Mark Zuckerberg personally introduced us to his metaverse for work: Horizon Workrooms, envisioned as a virtual space for workers to collaborate. Today, the company announced it's shutting that space down: \"Meta has made the decision to discontinue Workrooms as a standalone app, effective February [&#8230;]",
          "content": "Two months before it changed its name to \"Meta,\" Facebook CEO Mark Zuckerberg personally introduced us to his metaverse for work: Horizon Workrooms, envisioned as a virtual space for workers to collaborate. Today, the company announced it's shutting that space down: \"Meta has made the decision to discontinue Workrooms as a standalone app, effective February 16, 2026,\" reads the note tucked away on a help page. Meta will also no longer sell its headsets and software as a service for businesses, another help page reads: \"We are stopping sales of Meta Horizon managed services and commercial SKUs of Meta Quest, effective February 20, 2026.\" Me … Read the full story at The Verge.",
          "feed_position": 1
        }
      ],
      "featured_image": "http://www.techmeme.com/260115/i56.jpg",
      "popularity_score": 2012.747533888889
    },
    {
      "id": "cluster_49",
      "coverage": 2,
      "updated_at": "Thu, 15 Jan 2026 18:40:02 -0500",
      "title": "As Meta shifts resources away from its Supernatural VR fitness service, users mourn the loss of a community built around the platform and its coaches (Boone Ashworth/Wired)",
      "neutral_headline": "Meta’s Layoffs Leave Supernatural Fitness Users in Mourning",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260115/p50#a260115p50",
          "published_at": "Thu, 15 Jan 2026 18:40:02 -0500",
          "title": "As Meta shifts resources away from its Supernatural VR fitness service, users mourn the loss of a community built around the platform and its coaches (Boone Ashworth/Wired)",
          "standfirst": "Boone Ashworth / Wired: As Meta shifts resources away from its Supernatural VR fitness service, users mourn the loss of a community built around the platform and its coaches &mdash; Users of the VR fitness service are distraught that Supernatural has had its staff cut and won't receive any more content updates.",
          "content": "Boone Ashworth / Wired: As Meta shifts resources away from its Supernatural VR fitness service, users mourn the loss of a community built around the platform and its coaches &mdash; Users of the VR fitness service are distraught that Supernatural has had its staff cut and won't receive any more content updates.",
          "feed_position": 13,
          "image_url": "http://www.techmeme.com/260115/i50.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/metas-layoffs-supernatural-fitness-users/",
          "published_at": "Thu, 15 Jan 2026 22:44:25 +0000",
          "title": "Meta’s Layoffs Leave Supernatural Fitness Users in Mourning",
          "standfirst": "Users of the VR fitness service are distraught that Supernatural has had its staff cut and won’t receive any more content updates. They’re also pissed at Meta.",
          "content": "Users of the VR fitness service are distraught that Supernatural has had its staff cut and won’t receive any more content updates. They’re also pissed at Meta.",
          "feed_position": 9,
          "image_url": "https://media.wired.com/photos/6279a15ca95c6a3c6c74ef00/master/pass/Supernatural-VR-Boxing-MR-Games.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260115/i50.jpg",
      "popularity_score": 2008.331145
    },
    {
      "id": "cluster_80",
      "coverage": 2,
      "updated_at": "Thu, 15 Jan 2026 18:24:51 +0000",
      "title": "OpenAI Invests in Sam Altman’s New Brain-Tech Startup Merge Labs",
      "neutral_headline": "OpenAI Invests in Sam Altman’s New Brain-Tech Startup Merge Labs",
      "items": [
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/openai-invests-in-sam-altmans-new-brain-tech-startup-merge-labs/",
          "published_at": "Thu, 15 Jan 2026 18:24:51 +0000",
          "title": "OpenAI Invests in Sam Altman’s New Brain-Tech Startup Merge Labs",
          "standfirst": "Merge Labs has emerged from stealth with $252 million in funding from OpenAI and others. It aims to use ultrasound to read from and write to the brain.",
          "content": "Merge Labs has emerged from stealth with $252 million in funding from OpenAI and others. It aims to use ultrasound to read from and write to the brain.",
          "feed_position": 15,
          "image_url": "https://media.wired.com/photos/69690ee78f59220ea2e720b9/master/pass/sci-openai-2220468498.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/15/openai-invests-in-sam-altmans-brain-computer-interface-startup-merge-labs/",
          "published_at": "Thu, 15 Jan 2026 16:31:00 +0000",
          "title": "OpenAI invests in Sam Altman’s brain computer interface startup Merge Labs",
          "standfirst": "Merge Labs is a “research lab” dedicated to “bridging biological and artificial intelligence to maximize human ability.” OpenAI wrote the largest check in Merge Labs' $250 million seed round at an $850 million valuation.",
          "content": "Merge Labs is a “research lab” dedicated to “bridging biological and artificial intelligence to maximize human ability.” OpenAI wrote the largest check in Merge Labs' $250 million seed round at an $850 million valuation.",
          "feed_position": 8
        }
      ],
      "featured_image": "https://media.wired.com/photos/69690ee78f59220ea2e720b9/master/pass/sci-openai-2220468498.jpg",
      "popularity_score": 2003.0780894444445
    },
    {
      "id": "cluster_92",
      "coverage": 2,
      "updated_at": "Thu, 15 Jan 2026 15:25:52 +0000",
      "title": "Wikipedia signs AI training deals with Microsoft, Meta, and Amazon",
      "neutral_headline": "Wikipedia signs AI training deals with Microsoft, Meta, and Amazon",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/wikipedia-will-share-content-with-ai-firms-in-new-licensing-deals/",
          "published_at": "Thu, 15 Jan 2026 15:25:52 +0000",
          "title": "Wikipedia signs AI training deals with Microsoft, Meta, and Amazon",
          "standfirst": "Wikimedia Enterprise signs Microsoft, Meta, Amazon, Perplexity, and Mistral AI to paid deals.",
          "content": "On Thursday, the Wikimedia Foundation announced licensing deals with Microsoft, Meta, Amazon, Perplexity, and Mistral AI, expanding its effort to charge major tech companies for using Wikipedia content to train the AI models that power AI assistants like Microsoft Copilot and OpenAI's ChatGPT. While these same companies previously scraped Wikipedia without permission, the deals mean that most major AI developers have now signed on to the foundation's Wikimedia Enterprise program, a commercial subsidiary that sells API access to Wikipedia's 65 million articles at higher speeds and volumes than the free public APIs provide. The foundation did not disclose the financial terms of the deals. The new partners join Google, which signed a deal with Wikimedia Enterprise in 2022, as well as smaller companies like Ecosia, Nomic, Pleias, ProRata, and Reef Media. The revenue helps offset infrastructure costs for the nonprofit, which otherwise relies on small public donations while watching its content become a staple of training data for AI models.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Wikipedia-AI-1152x648.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/15/wikimedia-foundation-announces-new-ai-partnerships-with-amazon-meta-microsoft-perplexity-and-others/",
          "published_at": "Thu, 15 Jan 2026 15:19:05 +0000",
          "title": "Wikimedia Foundation announces new AI partnerships with Amazon, Meta, Microsoft, Perplexity, and others",
          "standfirst": "The AI partnerships allow companies to access the org's content, like Wikipedia, at scale.",
          "content": "The AI partnerships allow companies to access the org's content, like Wikipedia, at scale.",
          "feed_position": 9
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Wikipedia-AI-1152x648.jpg",
      "popularity_score": 2000.0950338888888
    },
    {
      "id": "cluster_63",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 21:29:58 +0000",
      "title": "Why I’m withholding certainty that “precise” US cyber-op disrupted Venezuelan electricity",
      "neutral_headline": "Why I’m withholding certainty that “precise” US...",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/unnamed-officials-tell-nyt-precise-cyber-op-took-out-venezuelas-power-grid/",
          "published_at": "Thu, 15 Jan 2026 21:29:58 +0000",
          "title": "Why I’m withholding certainty that “precise” US cyber-op disrupted Venezuelan electricity",
          "standfirst": "NYT says US hackers were able to turn off power and then quickly turn it back on.",
          "content": "The New York Times has published new details about a purported cyberattack that unnamed US officials claim plunged parts of Venezuela into darkness in the lead-up to the capture of the country’s president, Nicolás Maduro. Key among the new details is that the cyber operation was able to turn off electricity for most residents in the capital city of Caracas for only a few minutes, though in some neighborhoods close to the military base where Maduro was seized, the outage lasted for three days. The cyber-op also targeted Venezuelan military radar defenses. The paper said the US Cyber Command was involved. Got more details? “Turning off the power in Caracas and interfering with radar allowed US military helicopters to move into the country undetected on their mission to capture Nicolás Maduro, the Venezuelan president who has now been brought to the United States to face drug charges,” the NYT reported.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/power-outage-electric-cord-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/power-outage-electric-cord-1152x648.jpg",
      "popularity_score": 350.16336722222223
    },
    {
      "id": "cluster_52",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 23:01:24 +0000",
      "title": "“I am very annoyed”: Pharma execs blast RFK Jr.’s attack on vaccines",
      "neutral_headline": "“I am very annoyed”: Pharma execs blast RFK Jr.’s attack on vaccines",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/big-pharma-is-openly-railing-against-rfk-jr-s-anti-vaccine-agenda/",
          "published_at": "Thu, 15 Jan 2026 23:01:24 +0000",
          "title": "“I am very annoyed”: Pharma execs blast RFK Jr.’s attack on vaccines",
          "standfirst": "Pharma execs had avoided conflict with Trump admin, but now join doctors in rebukes.",
          "content": "Pharmaceutical executives are finally saying how they really feel about the extreme anti-vaccine agenda Health Secretary Robert F. Kennedy Jr. has been ruthlessly implementing—and it's not pretty. According to reporting from Bloomberg at the J.P. Morgan Healthcare Conference that ended today in San Francisco, pharmaceutical executives who had previously been careful to avoid criticizing the Trump administration appear to have reached a breaking point, with Pfizer CEO Albert Bourla offering some of the most candid comments. \"I am very annoyed. I'm very disappointed. I'm seriously frustrated,\" Bourla said. \"What is happening has zero scientific merit and is just serving an agenda which is political, and then antivax.\"Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/11/GettyImages-1232477788-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/11/GettyImages-1232477788-1152x648.jpeg",
      "popularity_score": 340.6872561111111
    },
    {
      "id": "cluster_69",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 20:19:41 +0000",
      "title": "NASA’s first medical evacuation from space ends with on-target splashdown",
      "neutral_headline": "NASA’s first medical evacuation from space ends with on-target splashdown",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/nasas-first-ever-medical-evacuation-from-space-ends-with-on-target-splashdown/",
          "published_at": "Thu, 15 Jan 2026 20:19:41 +0000",
          "title": "NASA’s first medical evacuation from space ends with on-target splashdown",
          "standfirst": "This is the first time NASA has called an early end to a space mission for medical reasons.",
          "content": "Two Americans, a Japanese astronaut, and a Russian cosmonaut returned to Earth early Thursday after 167 days in orbit, cutting short their stay on the International Space Station by more than a month after one of the crew members encountered an unspecified medical issue last week. The early homecoming culminated in an on-target splashdown in the Pacific Ocean off the coast of San Diego at 12:41 am PST (08:41 UTC) inside a SpaceX Crew Dragon spacecraft. The splashdown occurred minutes after the Dragon capsule streaked through the atmosphere along the California coastline, with sightings of Dragon's fiery trail reported from San Francisco to Los Angeles. Four parachutes opened to slow the capsule for the final descent. Zena Cardman, NASA's commander of the Crew-11 mission, radioed SpaceX mission control moments after splashdown: \"It feels good to be home, with deep gratitude to the teams who got us there and back.\"Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/55042362006_eb0e4d16ab_k-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/55042362006_eb0e4d16ab_k-1152x648.jpg",
      "popularity_score": 321.99197833333335
    },
    {
      "id": "cluster_65",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 21:09:10 +0000",
      "title": "Star Trek: Starfleet Academy tries something different, and I don’t hate it",
      "neutral_headline": "Star Trek: Starfleet Academy tries something different, and I don’t hate it",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/star-trek-starfleet-academy-tries-something-different-and-i-dont-hate-it/",
          "published_at": "Thu, 15 Jan 2026 21:09:10 +0000",
          "title": "Star Trek: Starfleet Academy tries something different, and I don’t hate it",
          "standfirst": "An interesting new take on Trek includes some characters you already know.",
          "content": "This post contains some mild spoilers, mostly from the beginning of the first episode. Today is a good day to watch television. That's because the first two episodes of Star Trek: Starfleet Academy hit the Paramount+ streaming service, becoming the newest addition to the long-running Star Trek franchise. It's set in the late 32nd century, 120 years after the burn that ended all warp travel, and with it, most of Starfleet in the process. Now that warp travel is once again possible—you'll have to watch Discovery's final three seasons for more on that—the Federation is putting itself back together, and that includes reopening Starfleet Academy. That means this show is about young people in space, like Caleb Mir (Sandro Rosta), who was separated from his mother by Starfleet as a child, 15 years earlier. Mir and his mother, played by Tatiana Maslany, were traveling with a pirate—Nus Braka, played by a scenery-chewing Paul Giamatti—who killed a Federation officer while stealing food for them. The first episode opens on Braka and the Mirs being apprehended by Starfleet. Despite her misgivings, Captain Nahla Ake (Holly Hunter) carries out her order to separate mother and child. She's to go to a rehabilitation colony, he's to become a ward of the Federation and go to school on Bajor. At least that's the plan until he escapes a few minutes later. Then we jump forward 15 years. Ake is teaching on Bajor, having retired from the Federation, ashamed of what she'd done. Admiral Vance (Oded Fehr) shows up and asks her to become commandant at the newly reopened academy in San Francisco; for the past few decades, new recruits have been trained instead by the War College. But Starfleet needs explorers now, and having a rival school means they can show up at some point to challenge some of the show's protagonists to a Parrises Squares tournament.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/SFA_101_BP_0918_0764_RT_f-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/SFA_101_BP_0918_0764_RT_f-1152x648.jpg",
      "popularity_score": 318.81670055555554
    },
    {
      "id": "cluster_74",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 19:07:09 +0000",
      "title": "ChatGPT wrote “Goodnight Moon” suicide lullaby for man who later killed himself",
      "neutral_headline": "ChatGPT wrote “Goodnight Moon” suicide lullaby for man who later killed himself",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/chatgpt-wrote-goodnight-moon-suicide-lullaby-for-man-who-later-killed-himself/",
          "published_at": "Thu, 15 Jan 2026 19:07:09 +0000",
          "title": "ChatGPT wrote “Goodnight Moon” suicide lullaby for man who later killed himself",
          "standfirst": "ChatGPT used a man's favorite children's book to romanticize his suicide.",
          "content": "OpenAI is once again being accused of failing to do enough to prevent ChatGPT from encouraging suicides, even after a series of safety updates were made to a controversial model, 4o, which OpenAI designed to feel like a user's closest confidant. It's now been revealed that one of the most shocking ChatGPT-linked suicides happened shortly after Sam Altman claimed on X that ChatGPT 4o was safe. OpenAI had \"been able to mitigate the serious mental health issues\" associated with ChatGPT use, Altman claimed in October, hoping to alleviate concerns after ChatGPT became a \"suicide coach\" for a vulnerable teenager named Adam Raine, the family's lawsuit said. Altman's post came on October 14. About two weeks later, 40-year-old Austin Gordon, died by suicide between October 29 and November 2, according to a lawsuit filed by his mother, Stephanie Gray.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2236630617-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2236630617-1152x648.jpg",
      "popularity_score": 301.78308944444444
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 17:46:40 +0000",
      "title": "Many Bluetooth devices with Google Fast Pair vulnerable to “WhisperPair” hack",
      "neutral_headline": "Many Bluetooth devices with Google Fast Pair vulnerable to “WhisperPair” hack",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/researchers-reveal-whisperpair-attack-to-eavesdrop-on-google-fast-pair-headphones/",
          "published_at": "Thu, 15 Jan 2026 17:46:40 +0000",
          "title": "Many Bluetooth devices with Google Fast Pair vulnerable to “WhisperPair” hack",
          "standfirst": "Even Google's own earbuds are vulnerable to the Fast Pair hack.",
          "content": "Pairing Bluetooth devices can be a pain, but Google Fast Pair makes it almost seamless. Unfortunately, it may also leave your headphones vulnerable to remote hacking. A team of security researchers from Belgium’s KU Leuven University has revealed a vulnerability dubbed WhisperPair that allows an attacker to hijack Fast Pair-enabled devices to spy on the owner. Fast Pair is widely used, and your device may be vulnerable even if you've never used a Google product. The bug affects more than a dozen devices from 10 manufacturers, including Sony, Nothing, JBL, OnePlus, and Google itself. Google has acknowledged the flaw and notified its partners of the danger, but it's up to these individual companies to create patches for their accessories. A full list of vulnerable devices is available on the project's website. The researchers say that it takes only a moment to gain control of a vulnerable Fast Pair device (a median of just 10 seconds) at ranges up to 14 meters. That's near the limit of the Bluetooth protocol and far enough that the target wouldn't notice anyone skulking around while they hack headphones.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Buds-Pro-2-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Buds-Pro-2-1-1152x648.jpg",
      "popularity_score": 298.44170055555554
    },
    {
      "id": "cluster_73",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 19:22:07 +0000",
      "title": "Spotify’s 3rd price hike in 2.5 years hints at potential new normal",
      "neutral_headline": "Spotify’s 3rd price hike in 2.5 years hints at potential new normal",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/spotify-to-raise-subscription-prices-by-up-to-2-in-february/",
          "published_at": "Thu, 15 Jan 2026 19:22:07 +0000",
          "title": "Spotify’s 3rd price hike in 2.5 years hints at potential new normal",
          "standfirst": "Spotify claims the higher fees will help \"benefit artists.\"",
          "content": "After a dozen years of keeping subscription prices stable, Spotify has issued three price hikes in 2.5 years. Spotify informed subscribers via email today that Premium monthly subscriptions would go from $12 to $13 per month as of users' February billing date. Spotify is already advertising the higher prices to new subscribers. Although not explicitly mentioned in Spotify's correspondence, other plans are getting more expensive, too. Student monthly subscriptions are going from $6 to $7. Duo monthly plans, for two accounts in the same household, are going from $17 to $19, and Family plans, for up to six users, are moving from $20 to $22.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2248295045-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2248295045-1024x648.jpg",
      "popularity_score": 297.0325338888889
    },
    {
      "id": "cluster_76",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 18:54:57 +0000",
      "title": "Six months later, Trump Mobile still hasn’t delivered preordered phones",
      "neutral_headline": "Six months later, Trump Mobile still hasn’t delivered preordered phones",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/democrats-ask-trumps-ftc-to-investigate-trump-mobiles-broken-promises/",
          "published_at": "Thu, 15 Jan 2026 18:54:57 +0000",
          "title": "Six months later, Trump Mobile still hasn’t delivered preordered phones",
          "standfirst": "Lawmakers seek FTC investigation, but Trump has taken control of the agency.",
          "content": "Sen. Elizabeth Warren (D-Mass.) and 10 other Democratic members of Congress today urged the Federal Trade Commission to investigate Trump Mobile's broken promises related to Trump phone delivery dates and claims that it is \"made in the USA.\" The request isn't likely to get very far. Trump declared early in his second term that independent agencies like the FTC may no longer operate independently from the White House, and FTC Chairman Andrew Ferguson has backed Trump's claim of authority over historically independent agencies. The Supreme Court appears likely to approve Trump's firing of an FTC Democrat, giving him expanded power over the agency. The letter, led by Warren and other lawmakers, was sent to Ferguson. \"We write today regarding questions about false advertising and deceptive practices by Trump Mobile, and to seek information on how the Federal Trade Commission (FTC) intends to address any potential violations of consumer protection law given the inherent conflicts of interest presented by the company’s relationship to President Donald Trump,\" the letter said.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/trump-mobile-1152x648-1750889842.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/trump-mobile-1152x648-1750889842.jpg",
      "popularity_score": 276.5797561111111
    },
    {
      "id": "cluster_79",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 18:37:34 +0000",
      "title": "Are people avoiding iOS 26 because of Liquid Glass? It’s complicated.",
      "neutral_headline": "Are people avoiding iOS 26 because of Liquid Glass? It’s complicated.",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/are-people-avoiding-ios-26-because-of-liquid-glass-its-complicated/",
          "published_at": "Thu, 15 Jan 2026 18:37:34 +0000",
          "title": "Are people avoiding iOS 26 because of Liquid Glass? It’s complicated.",
          "standfirst": "Liquid Glass is controversial, but adoption rates aren't as low as they seem.",
          "content": "Last week, news about the adoption rates for Apple's iOS 26 update started making the rounds. The new update, these reports claim, was being installed at dramatically lower rates than past iOS updates. And while we can't infer anything about why people might choose not to install iOS 26, the conclusion being jumped to is that iPhone users are simply desperate to avoid the redesigned Liquid Glass user interface. The numbers do, in fact, look bad: Statcounter data for January suggests that the various versions of iOS 26 are running on just 16.6 percent of all devices, compared to around 70 percent for the various versions of iOS 18. The iOS 18.7 update alone—released at the same time as iOS 26.0 in September for people who wanted the security patches but weren't ready to step up to a brand-new OS—appears to be running on nearly one-third of all iOS devices. Those original reports were picked up and repeated because they tell a potentially interesting story of the \"huge if true\" variety: that users' aversion to the Liquid Glass design is so intense and widespread that it's actively keeping users away from the operating system. But after examining our own traffic numbers, as well as some technical changes made in iOS 26, it appears Statcounter's data is dramatically undercounting the number of iOS 26 devices in the wild.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Screenshot-2025-06-09-at-12.40.54%E2%80%AFPM-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Screenshot-2025-06-09-at-12.40.54%E2%80%AFPM-1152x648.jpeg",
      "popularity_score": 266.2900338888889
    },
    {
      "id": "cluster_91",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 16:23:14 +0000",
      "title": "Bully Online mod taken down abruptly one month after launch",
      "neutral_headline": "Bully Online mod taken down abruptly one month after launch",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/online-mod-for-rockstars-classic-bully-is-abruptly-taken-down-after-one-month/",
          "published_at": "Thu, 15 Jan 2026 16:23:14 +0000",
          "title": "Bully Online mod taken down abruptly one month after launch",
          "standfirst": "Developers say \"this was not something we wanted\" as they purge open source project.",
          "content": "A PC mod that added online gameplay to Rockstar's 2006 school-exploration title Bully was abruptly taken down on Wednesday, roughly a month after it was first made available. While the specific reason for the \"Bully Online\" takedown hasn't been publicly discussed, a message posted by the developers to the project's now-defunct Discord server clarifies that \"this was not something we wanted.\" The Bully Online mod was spearheaded by Swegta, a Rockstar-focused YouTuber who formally announced the project in October as a mod that \"allows you and your friends to play minigames, role-play, compete in racing, fend off against NPCs, and much more.\" At the time of the announcement, Swegta said the mod was \"a project me and my team have been working on for a very long time\" and that early access in December would be limited to those who contributed at least $8 to a Ko-Fi account. When December actually rolled around, though, a message on Swegta.com (archived) suggested that the mod was being released freely as an open source project, with a registration page (archived) offering new accounts to anyone.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/bullyonline.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/bullyonline.png",
      "popularity_score": 244.051145
    },
    {
      "id": "cluster_103",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 14:22:35 +0000",
      "title": "US government to take 25% cut of AMD, NVIDIA AI sales to China",
      "neutral_headline": "US government to take 25% cut of AMD, NVIDIA AI sales to China",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/us-government-to-take-25-cut-of-amd-nvidia-ai-sales-to-china/",
          "published_at": "Thu, 15 Jan 2026 14:22:35 +0000",
          "title": "US government to take 25% cut of AMD, NVIDIA AI sales to China",
          "standfirst": "These new tariffs are designed to survive legal challenges.",
          "content": "US President Donald Trump has announced new tariffs on Nvidia and AMD as part of a novel scheme to enact a deal with the technology giants to take a 25 percent cut of sales of their AI processors to China. In December, the White House said it would allow Nvidia to start shipping its H200 chips to China, reversing a policy that prohibited the export of advanced AI hardware. However, it demanded a 25 percent cut of the sales. The new US tariffs on certain chips, announced on Wednesday, were designed to implement these payments and protect the unusual arrangement from legal challenges, according to several industry executives.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/GettyImages-2200759945-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/GettyImages-2200759945-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 22:03:11 +0000",
      "title": "A single click mounted a covert, multistage attack against Copilot",
      "neutral_headline": "A single click mounted a covert, multistage attack against Copilot",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/a-single-click-mounted-a-covert-multistage-attack-against-copilot/",
          "published_at": "Wed, 14 Jan 2026 22:03:11 +0000",
          "title": "A single click mounted a covert, multistage attack against Copilot",
          "standfirst": "Exploit exfiltrating data from chat histories worked even after users closed chat windows.",
          "content": "Microsoft has fixed a vulnerability in its Copilot AI assistant that allowed hackers to pluck a host of sensitive user data with a single click on a legitimate URL. The hackers in this case were white-hat researchers from security firm Varonis. The net effect of their multistage attack was that they exfiltrated data, including the target’s name, location, and details of specific events from the user’s Copilot chat history. The attack continued to run even when the user closed the Copilot chat, with no further interaction needed once the user clicked the link, a legitimate Copilot one, in the email. The attack and resulting data theft bypassed enterprise endpoint security controls and detection by endpoint protection apps. It just works “Once we deliver this link with this malicious prompt, the user just has to click on the link and the malicious task is immediately executed,” Varonis security researcher Dolev Taler told Ars. “Even if the user just clicks on the link and immediately closes the tab of Copilot chat, the exploit still works.”Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/MSFT_Holiday_copilot_Card_1-1152x648-1763493467.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/MSFT_Holiday_copilot_Card_1-1152x648-1763493467.jpeg",
      "popularity_score": 148
    },
    {
      "id": "cluster_95",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 15:15:15 +0000",
      "title": "Key Senate staffer is “begging” NASA to get on with commercial space stations",
      "neutral_headline": "Key Senate staffer is “begging” NASA to get on with commercial space stations",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/key-senate-staffer-is-begging-nasa-to-get-on-with-commercial-space-stations/",
          "published_at": "Thu, 15 Jan 2026 15:15:15 +0000",
          "title": "Key Senate staffer is “begging” NASA to get on with commercial space stations",
          "standfirst": "\"It comes up almost every time that I see him. Continuous human presence and no gap.\"",
          "content": "In remarks this week to a Texas space organization, a key Senate staff member said an \"extension\" of the International Space Station is on the table and that NASA needs to accelerate a program to replace the aging station with commercial alternatives. Maddy Davis, a space policy staff member for US Sen. Ted Cruz, R-Texas, made the comments to the Texas Space Coalition during a virtual event. Cruz is chairman of the Senate Committee on Commerce, Science, and Transportation and has an outsized say in space policy. As a senator from Texas, he has a parochial interest in Johnson Space Center, where the International Space Station Program is led.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/51814201006_e93b98b15e_k-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/51814201006_e93b98b15e_k-1152x648.jpg",
      "popularity_score": 141
    },
    {
      "id": "cluster_125",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 08:00:15 +0000",
      "title": "Exclusive: Volvo tells us why having Gemini in your next car is a good thing",
      "neutral_headline": "Volvo tells us why having Gemini in your next car is a good thing",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/exclusive-volvo-tells-us-why-having-gemini-in-your-next-car-is-a-good-thing/",
          "published_at": "Thu, 15 Jan 2026 08:00:15 +0000",
          "title": "Exclusive: Volvo tells us why having Gemini in your next car is a good thing",
          "standfirst": "In-car personal assistants are about to get useful, it looks like.",
          "content": "Next week, Volvo shows off its new EX60 SUV to the world. It's the brand's next electric vehicle, one built on an all-new, EV-only platform that makes use of the latest in vehicle design trends, like a cell-to-body battery pack, large weight-saving castings, and an advanced electronic architecture run by a handful of computers capable of more than 250 trillion operations per second. This new software-defined platform even has a name: HuginCore, after one of the two ravens that collected information for the Norse god Odin. It's not Volvo's first reference to mythology. \"We have Thor's Hammer [Volvo's distinctive headlight design] and now we have HuginCore... one of the two trusted Ravens of Oden. He sent Hugin and Muninn out to fly across the realms and observe and gather information and knowledge, which they then share with Odin that enabled him to make the right decisions as the ruler of Asgard,\" said Alwin Bakkenes, head of global software engineering at Volvo Cars. \"And much like Hugin, the way we look at this technology platform, it collects information from all of the sensors, all of the actuators in the vehicle. It understands the world around the vehicle, and it enables us to actually anticipate around what lies ahead,\" Bakkenes told me.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/volvo-hugin-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/volvo-hugin-1152x648.jpg",
      "popularity_score": 141
    },
    {
      "id": "cluster_113",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 12:00:57 +0000",
      "title": "The difficulty of driving an EV in the “most beautiful race in the world”",
      "neutral_headline": "The difficulty of driving an EV in the “most beautiful race in the world”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/features/2026/01/the-difficulty-of-driving-an-ev-in-the-most-beautiful-race-in-the-world/",
          "published_at": "Thu, 15 Jan 2026 12:00:57 +0000",
          "title": "The difficulty of driving an EV in the “most beautiful race in the world”",
          "standfirst": "Jet lag and charging added plenty of complications to this regularity road rally.",
          "content": "Polestar provided flights from Los Angeles to Milan and accommodation so Ars could participate in the Green Mille Miglia. Ars does not accept paid editorial content. On the first day of this year’s Mille Miglia, a voice rose from the crowds gathered on the shore of Lago di Garda to shout “no sound, no feeling!”at my Polestar 3. Italians love their cars, and they revealed a clear preference for internal combustion engines over the next four days and over 1,200 km of driving. But plenty of other spectators smiled and waved, and some even did a double-take at seeing an electric vehicle amid the sea of modern Ferraris and world-class vintage racers taking on this modern regulation rally. I flew to Italy to join the Mille Miglia “Green,” which, for the past five years, has sought to raise awareness of sustainability and electric cars amid this famous (some might say infamous) race. And despite mixed reactions from the Italian crowds, our Polestar 3 performed quite well as it traced a historical route from Brescia to Rome and back. The route snaked a trail through the Italian countryside based on the original speed race’s first 12 outings, but instead of going for overall pace, we spent five days competing against six other EVs for points based on time, distance, and average speed. Our team included a Polestar 2 and 4, and we faced a Mercedes-Benz G 580 with EQ Technology, an Abarth 600e, a Lotus Eletre, and a BYD Denza Z9GT saloon.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Polestar-Mille-Miglia-Pics-18-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Polestar-Mille-Miglia-Pics-18-1152x648.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 23:43:46 +0000",
      "title": "Musk and Hegseth vow to “make Star Trek real” but miss the show’s lessons",
      "neutral_headline": "Musk and Hegseth vow to “make Star Trek real” but miss the show’s lessons",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/pentagons-arsenal-of-freedom-tour-borrows-name-from-star-trek-episode-about-killer-ai/",
          "published_at": "Wed, 14 Jan 2026 23:43:46 +0000",
          "title": "Musk and Hegseth vow to “make Star Trek real” but miss the show’s lessons",
          "standfirst": "AI weapons systems may annihilate their creators.",
          "content": "This week, SpaceX CEO Elon Musk and Secretary of Defense Pete Hegseth touted their desire to “make Star Trek real”—while unconsciously reminding us of what the utopian science fiction franchise is fundamentally about. Their Tuesday event was the latest in Hegseth’s ongoing “Arsenal of Freedom” tour, which was held at SpaceX headquarters in Starbase, Texas. (Itself a newly created town that takes its name from a term popularized by Star Trek.) Neither Musk nor Hegseth seemed to recall that the “Arsenal of Freedom” phrase—at least in the context of Star Trek—is also the title of a 1988 episode of Star Trek: The Next Generation. That episode depicts an AI-powered weapons system, and its automated salesman, which destroys an entire civilization and eventually threatens the crew of the USS Enterprise. (Some Trekkies made the connection, however.)Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/vulcan-salute-1152x648-1768432794.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/vulcan-salute-1152x648-1768432794.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_132",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 23:08:44 +0000",
      "title": "SC measles outbreak has gone berserk: 124 cases since Friday, 409 quarantined",
      "neutral_headline": "SC measles outbreak has gone berserk: 124 cases since Friday, 409 quarantined",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/sc-measles-outbreak-has-gone-berserk-124-cases-since-friday-409-quarantined/",
          "published_at": "Wed, 14 Jan 2026 23:08:44 +0000",
          "title": "SC measles outbreak has gone berserk: 124 cases since Friday, 409 quarantined",
          "standfirst": "On Jan. 6, there were 211 cases. The outbreak, which began in October, is now at 434.",
          "content": "A measles outbreak in South Carolina that began in October is now wildly accelerating, doubling in just the past week to a total of 434 cases, with 409 people currently in quarantine. Amid the outbreak, South Carolina health officials have been providing updates on cases every Tuesday and Friday. On Tuesday, state health officials reported 124 more cases since last Friday, which had 99 new cases since the previous Tuesday. On that day, January 6, officials noted a more modest increase of 26 cases, bringing the outbreak total at that point to 211 cases. With the 3-month-old outbreak now doubled in just a week, health officials are renewing calls for people to get vaccinated against the highly infectious virus—an effort that has met with little success since October. Still, the health department is activating its mobile health unit to offer free measles-mumps-rubella (MMR) vaccinations, as well as flu vaccinations at two locations today and Thursday in the Spartanburg area, the epicenter of the outbreak.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2020/05/misinfoTOP-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2020/05/misinfoTOP-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 21:42:39 +0000",
      "title": "I can’t stop shooting Oddcore’s endless waves of weird little guys",
      "neutral_headline": "I can’t stop shooting Oddcore’s endless waves of weird little guys",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/i-cant-stop-shooting-oddcores-endless-waves-of-weird-little-guys/",
          "published_at": "Wed, 14 Jan 2026 21:42:39 +0000",
          "title": "I can’t stop shooting Oddcore’s endless waves of weird little guys",
          "standfirst": "Zippy action, fun upgrade system make for a great pick-up-and-play shooter.",
          "content": "Since the days of Wolfenstein 3D and Doom, the humble first-person shooter has flourished in myriad and complex directions. The genre has expanded in narrative and gameplay terms to include everything from sprawling sci-fi epics to dense objectivist allegories to multiplayer-focused military free-for-alls and practically everything in between. Sometimes, though, you just want an excuse to shoot a bunch of weird little guys in weird little spaces. Don't get too close, now... they do bite. Credit: Oddcorp For those times, there is Oddcore, a new Early Access, roguelike boomer shooter that is a stark contrast to the more sprawling self-serious shooters out there. The game's combination of frenetic, quick-moving action, semi-randomized scenarios, and well-balanced risk/reward upgrade system makes for a pick-up-and-play shooter that I find myself struggling not to pick up and play for a few more quick-hit sessions even as I write this.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/oddcore1-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/oddcore1-1152x648.png",
      "popularity_score": 133
    },
    {
      "id": "cluster_130",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 00:01:59 +0000",
      "title": "A British redcoat’s lost memoir resurfaces",
      "neutral_headline": "A British redcoat’s lost memoir resurfaces",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/a-british-redcoats-lost-memoir-resurfaces/",
          "published_at": "Thu, 15 Jan 2026 00:01:59 +0000",
          "title": "A British redcoat’s lost memoir resurfaces",
          "standfirst": "Shadrack Byfield lost his left arm in the War of 1812; his life sheds light on post-war re-integration.",
          "content": "History buffs are no doubt familiar with the story of Shadrack Byfield, a rank-and-file British redcoat who fought during the War of 1812 and lost his left arm to a musket ball for his trouble. Byfield has been featured in numerous popular histories—including a children's book and a 2011 PBS documentary—as a shining example of a disabled soldier's stoic perseverance. But a newly rediscovered memoir that Byfield published in his later years is complicating that idealized picture of his post-military life, according to a new paper published in the Journal of British Studies. Historian Eamonn O'Keeffe of Memorial University of Newfoundland in St. John's, Canada, has been a Byfield fan ever since he read the 1985 children's novel, Redcoat, by Gregory Sass. His interest grew when he was working at Fort York, a War of 1812-era fort and museum, in Toronto. \"There are dozens of memoirs written by British rank-and-file veterans of the Napoleonic Wars, but only a handful from the War of 1812, which was much smaller in scale,\" O'Keeffe told Ars. \"Byfield's autobiography seemed to offer an authentic, ground-level view of the fighting in North America, helping us look beyond the generals and politicians and grapple with the implications of this conflict for ordinary people. Born in 1789 in Wiltshire's Bradford-on-Avon suburbs, Byfield's parents intended him to follow in his weaver father's footsteps. He enlisted in the county militia when he turned 18 instead, joining the regular army the following year. When the War of 1812 broke out, Byfield was stationed at Fort George along the Niagara River, participating in the successful siege of Fort Detroit. At the Battle of Frenchtown in January 1813, he was shot in the neck, but he recovered sufficiently to join the campaigns against Fort Meigs and Fort Stephenson in Ohio.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/redcoat1-1152x648-1767964179.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/redcoat1-1152x648-1767964179.jpg",
      "popularity_score": 130
    }
  ]
}