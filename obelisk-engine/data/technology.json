{
  "updated_at": "2025-11-13T07:19:31.949Z",
  "clusters": [
    {
      "id": "cluster_40",
      "coverage": 2,
      "updated_at": "Wed, 12 Nov 2025 20:30:38 +0000",
      "title": "One of our favorite budgeting apps is half off before Black Friday",
      "neutral_headline": "Budgeting App Monarch Money Offers Discount Before Black Friday",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/one-of-our-favorite-budgeting-apps-is-half-off-before-black-friday-174011108.html",
          "published_at": "Wed, 12 Nov 2025 20:30:38 +0000",
          "title": "One of our favorite budgeting apps is half off before Black Friday",
          "standfirst": "Monarch Money is one of our favorite budgeting apps and, fittingly enough, there's a way for newcomers to save money on a subscription right now. If you use the code MONARCHVIP at checkout, you can get an annual plan for 50 percent off. It typically costs $100, but you can get 12 months of access for $50 with this code. There are some key caveats here. The discount is only for new users, and it can't be combined with other offers. The code only works when you sign up through the web. You can't redeem it through the Monarch mobile app. We feel that Monarch has a steeper learning curve than some other budget trackers and that certain aspects of the app are slightly more complex than they probably need to be. But it offers a great deal of customization and granularity, which outweighs our misgivings. On the main dashboard, you'll see your net worth along with your latest transactions, spending versus the previous month, your income so far for the month and details about upcoming bills, your investments and goals you've set. There's also a link to a month-in-review page, which offers an in-depth overview of what's been happening with your money that month. You'll also be able to take a peek at how your net worth has changed over time. Monarch can connect to your bank and track Apple Card, Apple Cash and Savings accounts. It can pull in your transactions and balance history automatically and detect your recurring expenses and income. The app can even keep your car valuation up to date. While it might take a little work to set up Monarch (and you might have to tweak things here and there), it's a detailed budgeting app that can help you keep better track of your income, expenditure and net worth. If you're a former Mint user (RIP), Monarch Money is a great alternative if you haven't yet found a Mint replacement. But it's worth mentioning that our favorite Mint replacement service, Quicken Simplifi, also has a sale going on right now. It's offering 50 percent off when you sign up for an annual subscription, billed at $3 per month with the discount. That comes out to $36 for the first year. This article originally appeared on Engadget at https://www.engadget.com/deals/one-of-our-favorite-budgeting-apps-is-half-off-before-black-friday-174011108.html?src=rss",
          "content": "Monarch Money is one of our favorite budgeting apps and, fittingly enough, there's a way for newcomers to save money on a subscription right now. If you use the code MONARCHVIP at checkout, you can get an annual plan for 50 percent off. It typically costs $100, but you can get 12 months of access for $50 with this code. There are some key caveats here. The discount is only for new users, and it can't be combined with other offers. The code only works when you sign up through the web. You can't redeem it through the Monarch mobile app. We feel that Monarch has a steeper learning curve than some other budget trackers and that certain aspects of the app are slightly more complex than they probably need to be. But it offers a great deal of customization and granularity, which outweighs our misgivings. On the main dashboard, you'll see your net worth along with your latest transactions, spending versus the previous month, your income so far for the month and details about upcoming bills, your investments and goals you've set. There's also a link to a month-in-review page, which offers an in-depth overview of what's been happening with your money that month. You'll also be able to take a peek at how your net worth has changed over time. Monarch can connect to your bank and track Apple Card, Apple Cash and Savings accounts. It can pull in your transactions and balance history automatically and detect your recurring expenses and income. The app can even keep your car valuation up to date. While it might take a little work to set up Monarch (and you might have to tweak things here and there), it's a detailed budgeting app that can help you keep better track of your income, expenditure and net worth. If you're a former Mint user (RIP), Monarch Money is a great alternative if you haven't yet found a Mint replacement. But it's worth mentioning that our favorite Mint replacement service, Quicken Simplifi, also has a sale going on right now. It's offering 50 percent off when you sign up for an annual subscription, billed at $3 per month with the discount. That comes out to $36 for the first year. This article originally appeared on Engadget at https://www.engadget.com/deals/one-of-our-favorite-budgeting-apps-is-half-off-before-black-friday-174011108.html?src=rss",
          "feed_position": 2
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/valve-announces-new-steam-machine-and-steam-controller-182836847.html",
          "published_at": "Wed, 12 Nov 2025 19:31:01 +0000",
          "title": "Valve announces new Steam Machine and Steam Controller",
          "standfirst": "Valve is making another run at offering a console-style experience in your living room. The company has announced a new Steam Machine and Steam Controller that let you play PC games on your TV in the same way the Steam Deck lets you play them on the go. Better yet, it’s planning to release them both in early 2026.The Steam Machine works like a console, but is technically a compact PC running Linux-based SteamOS. The boxy device features a customizable front plate and LED light strip, with a USB-A port and a microSD card slot available up front, and DisplayPort 1.4, HDMI 2.0 and ethernet ports on the back. Inside, the Steam Machine is powered by what Valve describes as a “semi-custom AMD Zen 4” CPU and a “semi-Custom AMD RDNA3 ” GPU with “16GB DDR5 + 8GB GDDR6 VRAM” and either 512GB or 2TB of SSD storage.Valve says the Steam Machine has “roughly six times the horsepower” of the Steam Deck, and is capable of supporting 4K gaming at 60 FPS with FSR. Interestingly, Valve is also pitching the device as a way to stream more demanding games to your Steam Deck, the Steam Frame VR headset the company also announced today or any device running Steam Link.Someone holding the new Steam Controller, with trackpads visible.ValveWhile you could use the Steam Machine with a traditional Bluetooth controller, Valve has created its own solution. The new Steam Controller puts all of the various control methods of the Steam Deck into a wireless controller. That includes sticks, face buttons, grip buttons, triggers and bumpers, but also trackpads for mouse controls and gyro controls, too. The Steam Controller works over both Bluetooth or a wired connection, and Valve is also including a charging dongle that doubles as a wireless transmitter for the fastest possible connection.Like the original Steam Controller, your input method can be individually customized for each game, and profiles can be shared. Valve also says the new controller will work with any device that runs Steam, including the Steam Deck, Steam Machine and Steam Frame.Missing from Valve’s announcement is any kind of official price. Early hands-ons with both the Steam Machine and Steam Controller suggest Valve wants the devices to be competitively priced with equivalent PCs and game controllers. Given the extra power and features, though, it seems like they might not be as much of a deal as the $400 Steam Deck was at launch.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/valve-announces-new-steam-machine-and-steam-controller-182836847.html?src=rss",
          "content": "Valve is making another run at offering a console-style experience in your living room. The company has announced a new Steam Machine and Steam Controller that let you play PC games on your TV in the same way the Steam Deck lets you play them on the go. Better yet, it’s planning to release them both in early 2026.The Steam Machine works like a console, but is technically a compact PC running Linux-based SteamOS. The boxy device features a customizable front plate and LED light strip, with a USB-A port and a microSD card slot available up front, and DisplayPort 1.4, HDMI 2.0 and ethernet ports on the back. Inside, the Steam Machine is powered by what Valve describes as a “semi-custom AMD Zen 4” CPU and a “semi-Custom AMD RDNA3 ” GPU with “16GB DDR5 + 8GB GDDR6 VRAM” and either 512GB or 2TB of SSD storage.Valve says the Steam Machine has “roughly six times the horsepower” of the Steam Deck, and is capable of supporting 4K gaming at 60 FPS with FSR. Interestingly, Valve is also pitching the device as a way to stream more demanding games to your Steam Deck, the Steam Frame VR headset the company also announced today or any device running Steam Link.Someone holding the new Steam Controller, with trackpads visible.ValveWhile you could use the Steam Machine with a traditional Bluetooth controller, Valve has created its own solution. The new Steam Controller puts all of the various control methods of the Steam Deck into a wireless controller. That includes sticks, face buttons, grip buttons, triggers and bumpers, but also trackpads for mouse controls and gyro controls, too. The Steam Controller works over both Bluetooth or a wired connection, and Valve is also including a charging dongle that doubles as a wireless transmitter for the fastest possible connection.Like the original Steam Controller, your input method can be individually customized for each game, and profiles can be shared. Valve also says the new controller will work with any device that runs Steam, including the Steam Deck, Steam Machine and Steam Frame.Missing from Valve’s announcement is any kind of official price. Early hands-ons with both the Steam Machine and Steam Controller suggest Valve wants the devices to be competitively priced with equivalent PCs and game controllers. Given the extra power and features, though, it seems like they might not be as much of a deal as the $400 Steam Deck was at launch.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/valve-announces-new-steam-machine-and-steam-controller-182836847.html?src=rss",
          "feed_position": 6,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Valve-Steam-Controller.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/weibos-new-open-source-ai-model-vibethinker-1-5b-outperforms-deepseek-r1-on",
          "published_at": "Wed, 12 Nov 2025 19:31:00 GMT",
          "title": "Weibo's new open source AI model VibeThinker-1.5B outperforms DeepSeek-R1 on $7,800 post-training budget",
          "standfirst": "Another day in late 2025, another impressive result from a Chinese company in open source artificial intelligence.Chinese social networking company Weibo&#x27;s AI division recently released its open source VibeThinker-1.5B—a 1.5 billion parameter large language model (LLM) that is a fine-tuned variant of rival Chinese tech firm Alibaba&#x27;s Qwen2.5-Math-1.5B. It&#x27;s available now for free download and usage by researchers and enterprise developers—even for commercial purposes—under a permissive MIT License on Hugging Face, GitHub and ModelScope, with a technical report on open access science publishing site arxiv.org.And yet, despite its compact size, VibeThinker-1.5B achieves benchmark-topping reasoning performance on math and code tasks, rivaling or surpassing models hundreds of times its size, even outperforming Chinese rival DeepSeek&#x27;s famed R1 that went viral at the start of this year—a 671-billion parameter model—on formal reasoning benchmark.It further eclipses Mistral AI&#x27;s Magistral Medium and holds its own against Anthropic&#x27;s Claude Opus 4 and OpenAI&#x27;s gpt-oss-20B Medium, all while requiring a fraction of the infrastructure and investment.It also does so having been post-trained on a budget of merely $7800 USD for compute resources (3900 GPU hours on Nvidia H800s) — far less than the tens, or even hundreds, of thousands of dollars typically required to fine-tune models of similar or larger scale.Recall this is not the total cost of the model&#x27;s development, however: LLMs are trained in stages. First comes pre-training, when the model learns basic language structure and general knowledge by predicting the next word across enormous amounts of text from the internet, books, and articles. This gives it fluency but not much sense of how to follow instructions or hold a conversationPost-training comes next, using much smaller, higher-quality datasets—typically collections of example questions, prompts, and expert-written answers—to teach the model how to respond helpfully, reason through problems, and align with human expectations. Still, Weibo&#x27;s post-training cost effectiveness on VibeThinker-1.5B is noteworthy and should be commended.The open-source release upends assumptions about parameter scale, compute intensity, and the minimum viable size for high-performance LLMs.A Different Training Approach: Spectrum-to-SignalVibeThinker-1.5B owes its performance not to scale, but to the training framework behind it: the Spectrum-to-Signal Principle (SSP).Instead of optimizing a model purely for single-answer correctness (Pass@1), the SSP framework decouples supervised fine-tuning (SFT) and reinforcement learning (RL) into two distinct phases with different goals:SFT (“Spectrum Phase”): The model is trained to maximize diversity across potential correct answers, improving its Pass@K score. This builds a wide range of plausible solution paths.RL (“Signal Phase”): A second-stage reinforcement learning system (called MaxEnt-Guided Policy Optimization, or MGPO) is used to identify and amplify the most correct paths from this diverse solution pool. MGPO prioritizes problems where the model is most uncertain, using entropy-based weighting to focus learning.The authors argue this separation allows small models to explore reasoning space more effectively—achieving signal amplification without relying on massive parameter counts.VibeThinker-1.5B makes a compelling case that the industry’s reliance on parameter scaling as the only route to better reasoning performance may be outdated. By adopting a diversity-first training pipeline, WeiboAI has shown that smaller, more accessible models can match and even outperform billion-dollar systems in logic-heavy tasks.The low resource footprint is among the most significant aspects of VibeThinker-1.5B. At under $8,000, the post-training cost is 30–60x lower than models like DeepSeek R1 and MiniMax-M1, which cost between $294K and $535K to train.Performance Across DomainsDespite its small size, VibeThinker-1.5B delivers cross-domain reasoning that outpaces many larger open-source and commercial models:ModelAIME25LiveCodeBench v6GPQA-DiamondVibeThinker-1.5B74.451.146.7GPT-OSS-20B-Medium72.154.966.0Claude Opus 469.256.679.6MiniMax M1 (456B)74.662.369.2DeepSeek R1 (671B)70.065.971.5Kimi K2 (1.09T)49.553.775.1VibeThinker was benchmarked against both reasoning-centric models (Magistral, Claude, OpenAI o3-mini) and non-reasoning LLMs (GPT-4.1, Kimi K2, DeepSeek V3). Across structured reasoning benchmarks, the model consistently outperformed non-reasoning models, regardless of size:On AIME24 (math), it beat Kimi K2 (1.09T) by over 10 points (80.3 vs. 69.6).On LiveCodeBench v6, it surpassed Claude Opus 4 (51.1 vs. 47.4).On GPQA, it scored below GPT-4.1 and Claude, but still doubled its base model (from 16.4 to 46.7).This supports the authors’ claim that size is not the only path to reasoning capability—with proper training design, smaller models can reach or even exceed the performance of far larger systems in targeted tasks.Notably, it achieves parity with models hundreds of times larger on math and code, though it lags behind in general knowledge reasoning (GPQA), where larger models maintain an edge.This suggests a potential specialization trade-off: while VibeThinker excels at structured logical tasks, it has less capacity for wide-ranging encyclopedic recall, a known limitation of smaller architectures.Guidance for Enterprise AdoptionThe release includes recommended inference settings (temperature = 0.6, top_p = 0.95, max tokens = 40960).The model is small enough to be deployed on edge devices, including mobile phones and vehicle-embedded systems, while inference costs are estimated to be 20–70x cheaper than with large models.This positions VibeThinker-1.5B not just as a research achievement, but as a potential foundation for cost-efficient, locally deployable reasoning systems.Weibo’s Strategy and Market PositionWeibo, launched by Sina Corporation in 2009, remains a cornerstone of China’s social media ecosystem. Often described as China’s version of X (formerly Twitter), the platform blends microblogging, multimedia content, and trending-topic features with a regulatory environment shaped by tight government oversight. Despite counting 600 million monthly active users (more than twice that of X), investors are not optimistic about its advertising revenue growth potential in the near term, and Weibo is navigating intensifying competition from video-first platforms like Douyin, which are drawing younger users and increasing time-spent elsewhere. In response, Weibo has leaned into creator-economy monetization, live-streaming, and vertical video—adding tools for influencer engagement, e-commerce integration, and richer analytics for brands.The platform’s role as a digital public square also makes it a focus of regulatory scrutiny. Chinese authorities continue to apply pressure on issues ranging from content governance to data security. In September 2025, Weibo was among the platforms cited in official warnings, highlighting its ongoing exposure to policy risks.Weibo’s push into AI R&D—exemplified by the release of VibeThinker-1.5B—signals a shift in ambition. Beyond being a media platform, Weibo is positioning itself as a player in the next phase of Chinese AI development, using its capital reserves, user behavior data, and in-house research capacity to pursue adjacent technical domains.What It Means for Enterprise Technical Decision MakersFor engineering leaders and enterprise AI teams, VibeThinker’s release has practical implications for everything from orchestration pipelines to cost modeling. A 1.5B-parameter model that outperforms 100x larger models on math and programming tasks doesn’t just save compute—it shifts the architectural balance. It enables LLM inference on constrained infrastructure, reduces latency at the edge, and lowers the barrier to entry for applications that otherwise would have required API access to closed, frontier-scale models.That matters for enterprise ML leads trying to deploy reasoning-capable agents within existing systems, or for platform owners tasked with integrating LLMs into automated workflows. It also speaks to those running reinforcement learning from human feedback (RLHF) pipelines or managing inference optimization across hybrid cloud environments. The model’s post-training methodology—particularly its entropy-targeted reinforcement learning approach—offers a roadmap for teams looking to refine smaller checkpoints instead of relying on large-scale pretraining.VibeThinker’s benchmark transparency and data decontamination steps also address another emerging priority in enterprise AI: auditability. While its performance on general-knowledge tests still trails large frontier models, its task-specific reliability makes it an attractive candidate for controlled environments where correctness matters more than coverage.In short, VibeThinker-1.5B isn’t just a research milestone—it’s a strong candidate for practical enterprise use, deployment and learnings. It suggests that a new class of compact, reasoning-optimized models is viable for enterprise use cases that were previously the domain of far larger systems. For organizations trying to balance cost, latency, interpretability, and control, it’s a good new option to the long, growing list of Chinese open source offerings.",
          "content": "Another day in late 2025, another impressive result from a Chinese company in open source artificial intelligence.Chinese social networking company Weibo&#x27;s AI division recently released its open source VibeThinker-1.5B—a 1.5 billion parameter large language model (LLM) that is a fine-tuned variant of rival Chinese tech firm Alibaba&#x27;s Qwen2.5-Math-1.5B. It&#x27;s available now for free download and usage by researchers and enterprise developers—even for commercial purposes—under a permissive MIT License on Hugging Face, GitHub and ModelScope, with a technical report on open access science publishing site arxiv.org.And yet, despite its compact size, VibeThinker-1.5B achieves benchmark-topping reasoning performance on math and code tasks, rivaling or surpassing models hundreds of times its size, even outperforming Chinese rival DeepSeek&#x27;s famed R1 that went viral at the start of this year—a 671-billion parameter model—on formal reasoning benchmark.It further eclipses Mistral AI&#x27;s Magistral Medium and holds its own against Anthropic&#x27;s Claude Opus 4 and OpenAI&#x27;s gpt-oss-20B Medium, all while requiring a fraction of the infrastructure and investment.It also does so having been post-trained on a budget of merely $7800 USD for compute resources (3900 GPU hours on Nvidia H800s) — far less than the tens, or even hundreds, of thousands of dollars typically required to fine-tune models of similar or larger scale.Recall this is not the total cost of the model&#x27;s development, however: LLMs are trained in stages. First comes pre-training, when the model learns basic language structure and general knowledge by predicting the next word across enormous amounts of text from the internet, books, and articles. This gives it fluency but not much sense of how to follow instructions or hold a conversationPost-training comes next, using much smaller, higher-quality datasets—typically collections of example questions, prompts, and expert-written answers—to teach the model how to respond helpfully, reason through problems, and align with human expectations. Still, Weibo&#x27;s post-training cost effectiveness on VibeThinker-1.5B is noteworthy and should be commended.The open-source release upends assumptions about parameter scale, compute intensity, and the minimum viable size for high-performance LLMs.A Different Training Approach: Spectrum-to-SignalVibeThinker-1.5B owes its performance not to scale, but to the training framework behind it: the Spectrum-to-Signal Principle (SSP).Instead of optimizing a model purely for single-answer correctness (Pass@1), the SSP framework decouples supervised fine-tuning (SFT) and reinforcement learning (RL) into two distinct phases with different goals:SFT (“Spectrum Phase”): The model is trained to maximize diversity across potential correct answers, improving its Pass@K score. This builds a wide range of plausible solution paths.RL (“Signal Phase”): A second-stage reinforcement learning system (called MaxEnt-Guided Policy Optimization, or MGPO) is used to identify and amplify the most correct paths from this diverse solution pool. MGPO prioritizes problems where the model is most uncertain, using entropy-based weighting to focus learning.The authors argue this separation allows small models to explore reasoning space more effectively—achieving signal amplification without relying on massive parameter counts.VibeThinker-1.5B makes a compelling case that the industry’s reliance on parameter scaling as the only route to better reasoning performance may be outdated. By adopting a diversity-first training pipeline, WeiboAI has shown that smaller, more accessible models can match and even outperform billion-dollar systems in logic-heavy tasks.The low resource footprint is among the most significant aspects of VibeThinker-1.5B. At under $8,000, the post-training cost is 30–60x lower than models like DeepSeek R1 and MiniMax-M1, which cost between $294K and $535K to train.Performance Across DomainsDespite its small size, VibeThinker-1.5B delivers cross-domain reasoning that outpaces many larger open-source and commercial models:ModelAIME25LiveCodeBench v6GPQA-DiamondVibeThinker-1.5B74.451.146.7GPT-OSS-20B-Medium72.154.966.0Claude Opus 469.256.679.6MiniMax M1 (456B)74.662.369.2DeepSeek R1 (671B)70.065.971.5Kimi K2 (1.09T)49.553.775.1VibeThinker was benchmarked against both reasoning-centric models (Magistral, Claude, OpenAI o3-mini) and non-reasoning LLMs (GPT-4.1, Kimi K2, DeepSeek V3). Across structured reasoning benchmarks, the model consistently outperformed non-reasoning models, regardless of size:On AIME24 (math), it beat Kimi K2 (1.09T) by over 10 points (80.3 vs. 69.6).On LiveCodeBench v6, it surpassed Claude Opus 4 (51.1 vs. 47.4).On GPQA, it scored below GPT-4.1 and Claude, but still doubled its base model (from 16.4 to 46.7).This supports the authors’ claim that size is not the only path to reasoning capability—with proper training design, smaller models can reach or even exceed the performance of far larger systems in targeted tasks.Notably, it achieves parity with models hundreds of times larger on math and code, though it lags behind in general knowledge reasoning (GPQA), where larger models maintain an edge.This suggests a potential specialization trade-off: while VibeThinker excels at structured logical tasks, it has less capacity for wide-ranging encyclopedic recall, a known limitation of smaller architectures.Guidance for Enterprise AdoptionThe release includes recommended inference settings (temperature = 0.6, top_p = 0.95, max tokens = 40960).The model is small enough to be deployed on edge devices, including mobile phones and vehicle-embedded systems, while inference costs are estimated to be 20–70x cheaper than with large models.This positions VibeThinker-1.5B not just as a research achievement, but as a potential foundation for cost-efficient, locally deployable reasoning systems.Weibo’s Strategy and Market PositionWeibo, launched by Sina Corporation in 2009, remains a cornerstone of China’s social media ecosystem. Often described as China’s version of X (formerly Twitter), the platform blends microblogging, multimedia content, and trending-topic features with a regulatory environment shaped by tight government oversight. Despite counting 600 million monthly active users (more than twice that of X), investors are not optimistic about its advertising revenue growth potential in the near term, and Weibo is navigating intensifying competition from video-first platforms like Douyin, which are drawing younger users and increasing time-spent elsewhere. In response, Weibo has leaned into creator-economy monetization, live-streaming, and vertical video—adding tools for influencer engagement, e-commerce integration, and richer analytics for brands.The platform’s role as a digital public square also makes it a focus of regulatory scrutiny. Chinese authorities continue to apply pressure on issues ranging from content governance to data security. In September 2025, Weibo was among the platforms cited in official warnings, highlighting its ongoing exposure to policy risks.Weibo’s push into AI R&D—exemplified by the release of VibeThinker-1.5B—signals a shift in ambition. Beyond being a media platform, Weibo is positioning itself as a player in the next phase of Chinese AI development, using its capital reserves, user behavior data, and in-house research capacity to pursue adjacent technical domains.What It Means for Enterprise Technical Decision MakersFor engineering leaders and enterprise AI teams, VibeThinker’s release has practical implications for everything from orchestration pipelines to cost modeling. A 1.5B-parameter model that outperforms 100x larger models on math and programming tasks doesn’t just save compute—it shifts the architectural balance. It enables LLM inference on constrained infrastructure, reduces latency at the edge, and lowers the barrier to entry for applications that otherwise would have required API access to closed, frontier-scale models.That matters for enterprise ML leads trying to deploy reasoning-capable agents within existing systems, or for platform owners tasked with integrating LLMs into automated workflows. It also speaks to those running reinforcement learning from human feedback (RLHF) pipelines or managing inference optimization across hybrid cloud environments. The model’s post-training methodology—particularly its entropy-targeted reinforcement learning approach—offers a roadmap for teams looking to refine smaller checkpoints instead of relying on large-scale pretraining.VibeThinker’s benchmark transparency and data decontamination steps also address another emerging priority in enterprise AI: auditability. While its performance on general-knowledge tests still trails large frontier models, its task-specific reliability makes it an attractive candidate for controlled environments where correctness matters more than coverage.In short, VibeThinker-1.5B isn’t just a research milestone—it’s a strong candidate for practical enterprise use, deployment and learnings. It suggests that a new class of compact, reasoning-optimized models is viable for enterprise use cases that were previously the domain of far larger systems. For organizations trying to balance cost, latency, interpretability, and control, it’s a good new option to the long, growing list of Chinese open source offerings.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4s7atIbhZpkjUNIE9NqvrE/de645440ccc36273944e9ba58f78fea7/ChatGPT_Image_Nov_12__2025__02_29_18_PM.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/valves-steam-frame-vr-headset-is-finally-official-and-its-coming-in-2026-181909387.html",
          "published_at": "Wed, 12 Nov 2025 19:26:01 +0000",
          "title": "Valve’s Steam Frame VR headset is finally official and it's coming in 2026",
          "standfirst": "Valve made a triumphant return to the hardware market with the Steam Deck and its OLED-toting counterpart, and now it’s having another crack at virtual reality with the Steam Frame. The Steam Frame is the long-rumored headset from Valve that had previously been codenamed \"Deckard.\" The company also announced a new Steam controller and PC called the Steam Machine. All three devices are coming in early 2026. Valve is holding off on announcing pricing and exact availability of the new hardware. There are Steam Frame dev kits available for developers. Valve says the Steam Frame is a wireless, \"streaming-first\" headset and you can hop into your games as soon as you pop it on. It supports both VR and flatscreen games. The company made a plug-and-play 6GHz wireless adapter that you slot into your PC (or Steam Machine). It has a dual-radio setup to help minimize interference, with one radio dedicated to streaming audio and visuals to the headset, and the other for Wi-Fi. A standalone VR headset But you don't need a PC to play games on the Steam Frame. As with Meta Quest headsets, it can run games as a standalone device. The headset has a Snapdragon 8 Gen 3 chipset, 16GB of RAM and up to 1TB of built-in UFS storage. There's a microSD card slot, along with support for Wi-Fi 7 and Bluetooth 5.3. Of course, the headset is powered by SteamOS. As with the Steam Deck and Steam Machine, there'll be a Steam Frame verified program, so you can see at a glance which games will run on the Steam Frame in standalone mode. What's more, the Steam Frame will support Android games. It seems Valve is hoping that developers who made games and VR experiences for Android-based headsets (such as the Meta Quest lineup) will bring them to Steam. The Steam Frame runs on a rechargeable 21.6Wh Li-ion battery. There's one USB-C 2.0 port at the back that you'll use for both charging and data transfers. You can recharge the battery at a rate of up to 45W. It's unclear how long the Steam Frame's battery will run on a charge. The battery is positioned on the rear of the headstrap. So you won't necessarily need to have an external battery pack that's attached to the system by an annoying cable. It'll be possible to swap the standard headstrap (into which the audio drivers are integrated) for a different option, perhaps one with a larger battery. Even with the battery built into the headstrap, Valve says the Steam Frame weighs just under a pound at 440 grams. The core module — the front part — is 185 grams (6.5oz) and the headstrap weighs 245 grams (8.6 ounces). Image optimization tech The Steam Frame has an optimization feature called Foveated Streaming. Valve says this uses low-latency eye-tracking (powered by two internal cameras) to optimize the detail in the image wherever your eyes are looking. The company claims it can offer a \"10x improvement in image quality and effective bandwidth.\" Foveated Streaming is said to work for every game in your Steam library. The headset has dual 2160 x 2160 LCD panels with refresh rates of up to 144Hz, a field of view of up to 110 degrees and an IPD target range of 60mm to 70mm. Valve added that \"thin and light custom pancake lenses provide edge-to-edge sharpness and a large eye box.\" The company says the maximum width for eye glasses is 140mm. As for audio, the Steam Frame has dual stereo speakers on each side with support for high-fidelity audio. Valve says the speakers on each side are \"oriented in opposite directions to cancel out vibrations,\" which can impact the tracking system. Speaking of which, the headset has four high-res monochrome cameras for controller and headset tracking — the Steam Frame uses inside-out tracking. Valve says there are infrared LEDs on the outside of the device that can help support tracking in dark environments. There's monochrome passthrough support too. Valve Steam Frame controllers Naturally, you'll need a way to play all of the games, so the headset comes with a pair of Steam Frame controllers. The headset tracks the positions of the controllers for VR games, with full 6-DOF tracking and IMU support. They have a split gamepad format with a D-pad, thumbsticks, ABXY buttons, triggers and bumpers. They're designed to work with your entire Steam library, and they certainly look a bit more intuitive than the PlayStation VR2 controllers. Rather than going down the Hall effect route, Valve opted for magnetic thumbsticks, which support capacitive finger tracking. Each controller is said to run for around 40 hours before you'll have to swap out the AA battery that powers it. If you'd rather play games on the Steam Frame with the new Steam Controller, you'll absolutely be able to do that. The Steam Frame is far from Valve's first VR headset. It released the Valve Index in 2019, and previously worked with HTC on its Vive headsets, which were initially consumer VR products before HTC shifted its focus to business and enterprise. While none of Valve’s previous PC-focused headsets had the mainstream impact of Meta’s Quest lineup or arguably even PlayStation VR (which by all accounts is still an active platform, not that Sony’s release calendar backs it up), the company is responsible for what is probably the medium’s greatest-ever game in Half-Life: Alyx. And with SteamOS on the Steam Deck being such a hit that other companies are practically begging Valve to let them put it in their own rival handhelds, it’s easy to imagine the Steam Frame becoming a serious rival to the Meta Quest.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/valves-steam-frame-vr-headset-is-finally-official-and-its-coming-in-2026-181909387.html?src=rss",
          "content": "Valve made a triumphant return to the hardware market with the Steam Deck and its OLED-toting counterpart, and now it’s having another crack at virtual reality with the Steam Frame. The Steam Frame is the long-rumored headset from Valve that had previously been codenamed \"Deckard.\" The company also announced a new Steam controller and PC called the Steam Machine. All three devices are coming in early 2026. Valve is holding off on announcing pricing and exact availability of the new hardware. There are Steam Frame dev kits available for developers. Valve says the Steam Frame is a wireless, \"streaming-first\" headset and you can hop into your games as soon as you pop it on. It supports both VR and flatscreen games. The company made a plug-and-play 6GHz wireless adapter that you slot into your PC (or Steam Machine). It has a dual-radio setup to help minimize interference, with one radio dedicated to streaming audio and visuals to the headset, and the other for Wi-Fi. A standalone VR headset But you don't need a PC to play games on the Steam Frame. As with Meta Quest headsets, it can run games as a standalone device. The headset has a Snapdragon 8 Gen 3 chipset, 16GB of RAM and up to 1TB of built-in UFS storage. There's a microSD card slot, along with support for Wi-Fi 7 and Bluetooth 5.3. Of course, the headset is powered by SteamOS. As with the Steam Deck and Steam Machine, there'll be a Steam Frame verified program, so you can see at a glance which games will run on the Steam Frame in standalone mode. What's more, the Steam Frame will support Android games. It seems Valve is hoping that developers who made games and VR experiences for Android-based headsets (such as the Meta Quest lineup) will bring them to Steam. The Steam Frame runs on a rechargeable 21.6Wh Li-ion battery. There's one USB-C 2.0 port at the back that you'll use for both charging and data transfers. You can recharge the battery at a rate of up to 45W. It's unclear how long the Steam Frame's battery will run on a charge. The battery is positioned on the rear of the headstrap. So you won't necessarily need to have an external battery pack that's attached to the system by an annoying cable. It'll be possible to swap the standard headstrap (into which the audio drivers are integrated) for a different option, perhaps one with a larger battery. Even with the battery built into the headstrap, Valve says the Steam Frame weighs just under a pound at 440 grams. The core module — the front part — is 185 grams (6.5oz) and the headstrap weighs 245 grams (8.6 ounces). Image optimization tech The Steam Frame has an optimization feature called Foveated Streaming. Valve says this uses low-latency eye-tracking (powered by two internal cameras) to optimize the detail in the image wherever your eyes are looking. The company claims it can offer a \"10x improvement in image quality and effective bandwidth.\" Foveated Streaming is said to work for every game in your Steam library. The headset has dual 2160 x 2160 LCD panels with refresh rates of up to 144Hz, a field of view of up to 110 degrees and an IPD target range of 60mm to 70mm. Valve added that \"thin and light custom pancake lenses provide edge-to-edge sharpness and a large eye box.\" The company says the maximum width for eye glasses is 140mm. As for audio, the Steam Frame has dual stereo speakers on each side with support for high-fidelity audio. Valve says the speakers on each side are \"oriented in opposite directions to cancel out vibrations,\" which can impact the tracking system. Speaking of which, the headset has four high-res monochrome cameras for controller and headset tracking — the Steam Frame uses inside-out tracking. Valve says there are infrared LEDs on the outside of the device that can help support tracking in dark environments. There's monochrome passthrough support too. Valve Steam Frame controllers Naturally, you'll need a way to play all of the games, so the headset comes with a pair of Steam Frame controllers. The headset tracks the positions of the controllers for VR games, with full 6-DOF tracking and IMU support. They have a split gamepad format with a D-pad, thumbsticks, ABXY buttons, triggers and bumpers. They're designed to work with your entire Steam library, and they certainly look a bit more intuitive than the PlayStation VR2 controllers. Rather than going down the Hall effect route, Valve opted for magnetic thumbsticks, which support capacitive finger tracking. Each controller is said to run for around 40 hours before you'll have to swap out the AA battery that powers it. If you'd rather play games on the Steam Frame with the new Steam Controller, you'll absolutely be able to do that. The Steam Frame is far from Valve's first VR headset. It released the Valve Index in 2019, and previously worked with HTC on its Vive headsets, which were initially consumer VR products before HTC shifted its focus to business and enterprise. While none of Valve’s previous PC-focused headsets had the mainstream impact of Meta’s Quest lineup or arguably even PlayStation VR (which by all accounts is still an active platform, not that Sony’s release calendar backs it up), the company is responsible for what is probably the medium’s greatest-ever game in Half-Life: Alyx. And with SteamOS on the Steam Deck being such a hit that other companies are practically begging Valve to let them put it in their own rival handhelds, it’s easy to imagine the Steam Frame becoming a serious rival to the Meta Quest.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/valves-steam-frame-vr-headset-is-finally-official-and-its-coming-in-2026-181909387.html?src=rss",
          "feed_position": 7,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-11/5cfcae20-bffd-11f0-9bdf-3763c02a40b3"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056913.html",
          "published_at": "Wed, 12 Nov 2025 18:59:24 +0000",
          "title": "The best VPN deals: 88 percent discounts on ProtonVPN, Surfshark, ExpressVPN, NordVPN and more",
          "standfirst": "A virtual private network (VPN) is useful in several ways — a good one can stream foreign TV shows and events, protect your information from cybercrime and thwart those online trackers that show you creepily invasive ads. Although we strongly recommend using a VPN, a bit of comparison shopping goes a long way in this market. The pricing you see on VPN websites is often not an accurate portrayal of what you'll actually pay. Even so, there are some great bargains on the table. VPN providers want to boost their subscriber numbers, so they give out steep discounts to customers who sign up for a year or more at once. This is a win for you as well — while you pay out more upfront, if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $59.95 for a two-year subscription with five months free (79 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79.20 for a three-year subscription with four months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like Black Friday/Cyber Monday. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056913.html?src=rss",
          "content": "A virtual private network (VPN) is useful in several ways — a good one can stream foreign TV shows and events, protect your information from cybercrime and thwart those online trackers that show you creepily invasive ads. Although we strongly recommend using a VPN, a bit of comparison shopping goes a long way in this market. The pricing you see on VPN websites is often not an accurate portrayal of what you'll actually pay. Even so, there are some great bargains on the table. VPN providers want to boost their subscriber numbers, so they give out steep discounts to customers who sign up for a year or more at once. This is a win for you as well — while you pay out more upfront, if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $59.95 for a two-year subscription with five months free (79 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79.20 for a three-year subscription with four months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like Black Friday/Cyber Monday. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056913.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/xbox/backbone-launches-pro-xbox-edition-controller-with-bluetooth-and-an-updated-design-170018809.html",
          "published_at": "Wed, 12 Nov 2025 17:00:18 +0000",
          "title": "Backbone launches Pro Xbox Edition controller with Bluetooth and an updated design",
          "standfirst": "Backbone just released a new Pro version of its Xbox controller. The Backbone Pro Xbox Edition looks like an improvement over the pre-existing One controller in nearly every way. It's still a USB-C shell that wraps around a phone or related device, but the actual controller is now more in league with an actual Xbox gamepad. It features full-size control sticks, hall effect triggers and two customizable back buttons. Most of the inputs can be remapped. This should make plowing through that Game Pass library an absolute breeze. To that end, this controller has Bluetooth. This means you won't have to rely on a smartphone or whatever device can physically attach to the gamepad. Game Pass has become available on all kinds of platforms in recent years, from PCs and smart TVs to Meta Quest VR headsets. This opens up all of that. The company promises a simplified \"tap and play\" experience. Backbone This Bluetooth mode does offer 40 hours of battery life per charge. The smartphone powers it when using it in a wired configuration, so it'll last as long as the phone does. The controllers pair with a proprietary app that allows for the aforementioned remapping and other customization options. The controller is available right now at brick and mortar locations like Best Buy and digital storefronts such as Amazon. It costs $180 and ships with a free month of Game Pass Ultimate. The only potential downside here is Game Pass itself. The price keeps going up.This article originally appeared on Engadget at https://www.engadget.com/gaming/xbox/backbone-launches-pro-xbox-edition-controller-with-bluetooth-and-an-updated-design-170018809.html?src=rss",
          "content": "Backbone just released a new Pro version of its Xbox controller. The Backbone Pro Xbox Edition looks like an improvement over the pre-existing One controller in nearly every way. It's still a USB-C shell that wraps around a phone or related device, but the actual controller is now more in league with an actual Xbox gamepad. It features full-size control sticks, hall effect triggers and two customizable back buttons. Most of the inputs can be remapped. This should make plowing through that Game Pass library an absolute breeze. To that end, this controller has Bluetooth. This means you won't have to rely on a smartphone or whatever device can physically attach to the gamepad. Game Pass has become available on all kinds of platforms in recent years, from PCs and smart TVs to Meta Quest VR headsets. This opens up all of that. The company promises a simplified \"tap and play\" experience. Backbone This Bluetooth mode does offer 40 hours of battery life per charge. The smartphone powers it when using it in a wired configuration, so it'll last as long as the phone does. The controllers pair with a proprietary app that allows for the aforementioned remapping and other customization options. The controller is available right now at brick and mortar locations like Best Buy and digital storefronts such as Amazon. It costs $180 and ships with a free month of Game Pass Ultimate. The only potential downside here is Game Pass itself. The price keeps going up.This article originally appeared on Engadget at https://www.engadget.com/gaming/xbox/backbone-launches-pro-xbox-edition-controller-with-bluetooth-and-an-updated-design-170018809.html?src=rss",
          "feed_position": 15,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-11/f4c1cce0-bf17-11f0-b7fa-17b2464448fd"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/black-friday-deals-for-2025-are-here-early-we-found-the-best-tech-sales-from-apple-amazon-lego-anker-and-others-100052831.html",
          "published_at": "Wed, 12 Nov 2025 16:00:37 +0000",
          "title": "Black Friday deals for 2025 are here early: We found the best tech sales from Apple, Amazon, Lego, Anker and others",
          "standfirst": "November has turned into Black Friday and vice versa. What was once a one-day shopping sprint has turned into a month-long marathon, with retailers rolling out discounts week after week. Thanks to this, it can be easy to get deal fatigue after a while — but no one wants to miss out on a good discount, regardless of if you’re buying for yourself or someone else. We’re tracking all of the best Black Friday deals you can get right now so you don’t have to go searching for them.Engadget can help if you have tech on your shopping list this year. Here, we’ve curated the best Black Friday tech deals you can get right now, and we'll continue to update this post as we get closer to the big day at the end of November. Note that you probably have the best chance of snagging record-low prices when we get to about one week before Thanksgiving, but these deals available now are worth considering. Black Friday deals to shop now Apple AirTags (four pack) for $65 (34 percent off): iPhone users who frequently misplace things should invest in a few AirTags. Slip them into your wallet, bag, jacket and other belongings to keep track of their locations in the Find My app. Just make sure that, if you're going to attach one to your keys, you also pick up an AirTag holder to go along with it. Ninja Dual-Zone air fryer (10-quart) for $180 (22 percent off): If you cook for large crowds on Thanksgiving and other occasions, this is the air fryer to get. Not only is it a large, 10-quart capacity model, but it also has two separate cooking areas. You can crisp up potatoes on one side and brussel sprouts on the other with no issues. Use the Smart Finish feature to cook two separate foods in different ways and have them both be done at the same time, or Match Cook to copy the cooking method in both chambers. LEGO Star Wars Millennium Falcon A New Hope 25th Anniversary Collectable 75375 for $68 (20 percent off): This is a set that any Star Wars fan will love to build and then love to display once it's complete. The 921-piece set features a fully-detailed Millennium Falcone, buildable stand and nameplate. It's one of many Lego Black Friday deals you can get right now. Nintendo Switch 2 + Mario Kart World bundle for $499: Black Friday Nintendo sales were announced recently and, unsurprisingly, there won't be many true deals out there this year. There are no straight discounts on the Switch 2 console, so your best bet is to pick up a bundle that saves you some cash on a Switch 2 game. One of the best is the Mario Kart Wold bundle, but Pokémon fans should consider the Pokémon Legends: Z-A bundle, too. Apple Watch SE 3 for $200 ($50 off): The SE has been our top pick for the best Apple Watch for those on a budget, and the latest model only solidifies that further. It has the same chipset found in the latest flagship Apple Watches, fast-charging capabilities, an always-on display and most of the same activity-tracking features you'll find in more expensive model. Apple Mac Mini M4 for $499 ($100 off): Desktop users looking for an upgrade should consider the latest Mac Mini, which runs on the M4 chip and 16GB of RAM as standard in the base configuration. This version has a smaller design that takes up less space, front-facing USB-C ports and a headphone jack, plus Thunderbolt 5 support. Jisulife Life 7 handheld fan for $25 (14 percent off): This handy little fan is a must-have if you life in a warm climate or have a tropical vacation planned anytime soon. It can be used as a table or handheld fan and even be worn around the neck so you don't have to hold it at all. Its 5,000 mAh battery allows it to last hours on a single charge, and the small display in the middle of the fan's blades show its remaining battery level. Leebin 2025 electric spin scrubber for $40 (43 percent off, Prime exclusive): This weird little scrubber makes cleaning my bathroom and shower much less of a pain. Just choose the brush head you need for your job and the rotating head takes care of most of the hard work. I love the adjustable handle, which extends from 12 to 50 inches so you can get into hard-to-reach places without breaking a sweat. Monarch Money budgeting app (one year) for $50 (50 percent off with code MONARCHVIP): One of our favorite budgeting apps, Monarch Money gives you a lot of control over the organization of your funds. There's a helpful goals feature for when you're planning out big purchases or financial milestones you want to hit, and we found the month-in-review recap it provides to be more thorough than other budgeting apps we tried. There's even Zillow integration for folks looking to buy a home. SanDisk microSD Express card (256GB) for $60 (12 percent off): If you have a Switch 2, no regular microSD card will do if you want to expand the console's storage. You need a newer microSD Express card, and currently there are only a handful on the market. We did some testing to find the best microSD Express card for the Switch 2 and found that performance was, in general, very similar amongst all the readily available cards. We recommend getting whichever fits within your budget at the capacity you want. Google TV Streamer 4K for $75 ($25 off): Our top pick for the best streaming device right now, the latest version of Google's streamer supports 4K video and an excellent, easy-to-use interface that will feel familiar to anyone who's seen a set with the Google TV technology built in. It provides access to all of the major streaming services including Netflix, Disney+, HBO Max, YouTube and more, plus it has a handy on-screen pop up that lets you control all compatible smart home devices right from your TV. Also available at Walmart. Cosori 9-in-1 air fryer for $90 (25 percent off): I personally have this air fryer, one of our top picks, in my house and I've used it for over a year with no issues. I love that it makes good use of vertical space so it doesn't take up too much space on my counter, and its rounded-square shape allows me to cook more food than you'd think in one go in the basket. It crisps all kinds of foods up well and generally takes a lot of the guess work (and time) out of making a good meal. Dyson 360 Vis Nav robot vacuum for $400 ($600 off): This is one of the best robot vacuums you can get, period. It doesn't have a self-emptying base, but its superior suction power almost makes up for that. It's one of the strongest robot vacuums I've ever tested, and it has excellent obstacle avoidance. The latter means you will rarely, if ever, have to attend to it getting caught on the edge of a carpet or getting stuck under a piece of furniture. If a cordless stick vacuum is what you're looking for, don't forget to check out all of the other Dyson Black Friday deals. EcoFlow Black Friday deals — get up to 80 percent off: Portable power stations are an investment, but they can be crucial pieces of tech during emergencies. The top pick from our friends at Yahoo Tech has been heavily discounted in this early Black Friday sale. You can pick up the EcoFlow Delta Pro 3 for $1,400 off, down to $2,299, or the power station with an extra battery bundled in for $2,699 off, down to $3,599. Black Friday FAQs When is Black Friday 2025? Black Friday 2025 lands on November 28. Which stores have Black Friday deals? Many physical retail stores have Black Friday deals including Walmart, Target, Best Buy and others. Even more retailers have online Black Friday deals, including Amazon, GameStop, Costco and others. When do Black Friday sales start? Gone are the times when Black Friday sales were one-day-only affairs. Now, Black Friday deals are often available starting on Thanksgiving, or even earlier. Last year, we saw Black Friday deals online begin the week before Black Friday proper. When do Black Friday sales end? Black Friday and Cyber Monday have blended a lot over the past few years. Now, you can expect to see a good portion of Black Friday deals extend through the weekend and into Cyber Monday. It's not uncommon for Black Friday deals to expire at the end of Cyber Monday. Which retailers have the best Black Friday tech deals? The best Black Friday tech deals are typically available online at retailers like Amazon, Walmart, Best Buy and Target. It's also a good idea to check the store websites of the companies that make the products you want — for example, if you're looking for a Sonos speaker, check the Sonos website on Black Friday. Most of the time, you'll find the best Black Friday tech deals are matched at multiple retailers. Does Apple have Black Friday sales? No, you will usually not find Black Friday sales at Apple stores or on Apple's website. However, you can find Black Friday deals on Apple devices elsewhere; we recommend checking Amazon, Best Buy and other big retailers for discounts on iPads, Apple Watches and more on Black Friday. Does Amazon have Black Friday sales? Yes, Amazon has Black Friday sales. The online retailer's site will look similar to Prime Day on Black Friday, with discounts on all sorts of items from household essentials to fashion to tech.This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-deals-for-2025-are-here-early-we-found-the-best-tech-sales-from-apple-amazon-lego-anker-and-others-100052831.html?src=rss",
          "content": "November has turned into Black Friday and vice versa. What was once a one-day shopping sprint has turned into a month-long marathon, with retailers rolling out discounts week after week. Thanks to this, it can be easy to get deal fatigue after a while — but no one wants to miss out on a good discount, regardless of if you’re buying for yourself or someone else. We’re tracking all of the best Black Friday deals you can get right now so you don’t have to go searching for them.Engadget can help if you have tech on your shopping list this year. Here, we’ve curated the best Black Friday tech deals you can get right now, and we'll continue to update this post as we get closer to the big day at the end of November. Note that you probably have the best chance of snagging record-low prices when we get to about one week before Thanksgiving, but these deals available now are worth considering. Black Friday deals to shop now Apple AirTags (four pack) for $65 (34 percent off): iPhone users who frequently misplace things should invest in a few AirTags. Slip them into your wallet, bag, jacket and other belongings to keep track of their locations in the Find My app. Just make sure that, if you're going to attach one to your keys, you also pick up an AirTag holder to go along with it. Ninja Dual-Zone air fryer (10-quart) for $180 (22 percent off): If you cook for large crowds on Thanksgiving and other occasions, this is the air fryer to get. Not only is it a large, 10-quart capacity model, but it also has two separate cooking areas. You can crisp up potatoes on one side and brussel sprouts on the other with no issues. Use the Smart Finish feature to cook two separate foods in different ways and have them both be done at the same time, or Match Cook to copy the cooking method in both chambers. LEGO Star Wars Millennium Falcon A New Hope 25th Anniversary Collectable 75375 for $68 (20 percent off): This is a set that any Star Wars fan will love to build and then love to display once it's complete. The 921-piece set features a fully-detailed Millennium Falcone, buildable stand and nameplate. It's one of many Lego Black Friday deals you can get right now. Nintendo Switch 2 + Mario Kart World bundle for $499: Black Friday Nintendo sales were announced recently and, unsurprisingly, there won't be many true deals out there this year. There are no straight discounts on the Switch 2 console, so your best bet is to pick up a bundle that saves you some cash on a Switch 2 game. One of the best is the Mario Kart Wold bundle, but Pokémon fans should consider the Pokémon Legends: Z-A bundle, too. Apple Watch SE 3 for $200 ($50 off): The SE has been our top pick for the best Apple Watch for those on a budget, and the latest model only solidifies that further. It has the same chipset found in the latest flagship Apple Watches, fast-charging capabilities, an always-on display and most of the same activity-tracking features you'll find in more expensive model. Apple Mac Mini M4 for $499 ($100 off): Desktop users looking for an upgrade should consider the latest Mac Mini, which runs on the M4 chip and 16GB of RAM as standard in the base configuration. This version has a smaller design that takes up less space, front-facing USB-C ports and a headphone jack, plus Thunderbolt 5 support. Jisulife Life 7 handheld fan for $25 (14 percent off): This handy little fan is a must-have if you life in a warm climate or have a tropical vacation planned anytime soon. It can be used as a table or handheld fan and even be worn around the neck so you don't have to hold it at all. Its 5,000 mAh battery allows it to last hours on a single charge, and the small display in the middle of the fan's blades show its remaining battery level. Leebin 2025 electric spin scrubber for $40 (43 percent off, Prime exclusive): This weird little scrubber makes cleaning my bathroom and shower much less of a pain. Just choose the brush head you need for your job and the rotating head takes care of most of the hard work. I love the adjustable handle, which extends from 12 to 50 inches so you can get into hard-to-reach places without breaking a sweat. Monarch Money budgeting app (one year) for $50 (50 percent off with code MONARCHVIP): One of our favorite budgeting apps, Monarch Money gives you a lot of control over the organization of your funds. There's a helpful goals feature for when you're planning out big purchases or financial milestones you want to hit, and we found the month-in-review recap it provides to be more thorough than other budgeting apps we tried. There's even Zillow integration for folks looking to buy a home. SanDisk microSD Express card (256GB) for $60 (12 percent off): If you have a Switch 2, no regular microSD card will do if you want to expand the console's storage. You need a newer microSD Express card, and currently there are only a handful on the market. We did some testing to find the best microSD Express card for the Switch 2 and found that performance was, in general, very similar amongst all the readily available cards. We recommend getting whichever fits within your budget at the capacity you want. Google TV Streamer 4K for $75 ($25 off): Our top pick for the best streaming device right now, the latest version of Google's streamer supports 4K video and an excellent, easy-to-use interface that will feel familiar to anyone who's seen a set with the Google TV technology built in. It provides access to all of the major streaming services including Netflix, Disney+, HBO Max, YouTube and more, plus it has a handy on-screen pop up that lets you control all compatible smart home devices right from your TV. Also available at Walmart. Cosori 9-in-1 air fryer for $90 (25 percent off): I personally have this air fryer, one of our top picks, in my house and I've used it for over a year with no issues. I love that it makes good use of vertical space so it doesn't take up too much space on my counter, and its rounded-square shape allows me to cook more food than you'd think in one go in the basket. It crisps all kinds of foods up well and generally takes a lot of the guess work (and time) out of making a good meal. Dyson 360 Vis Nav robot vacuum for $400 ($600 off): This is one of the best robot vacuums you can get, period. It doesn't have a self-emptying base, but its superior suction power almost makes up for that. It's one of the strongest robot vacuums I've ever tested, and it has excellent obstacle avoidance. The latter means you will rarely, if ever, have to attend to it getting caught on the edge of a carpet or getting stuck under a piece of furniture. If a cordless stick vacuum is what you're looking for, don't forget to check out all of the other Dyson Black Friday deals. EcoFlow Black Friday deals — get up to 80 percent off: Portable power stations are an investment, but they can be crucial pieces of tech during emergencies. The top pick from our friends at Yahoo Tech has been heavily discounted in this early Black Friday sale. You can pick up the EcoFlow Delta Pro 3 for $1,400 off, down to $2,299, or the power station with an extra battery bundled in for $2,699 off, down to $3,599. Black Friday FAQs When is Black Friday 2025? Black Friday 2025 lands on November 28. Which stores have Black Friday deals? Many physical retail stores have Black Friday deals including Walmart, Target, Best Buy and others. Even more retailers have online Black Friday deals, including Amazon, GameStop, Costco and others. When do Black Friday sales start? Gone are the times when Black Friday sales were one-day-only affairs. Now, Black Friday deals are often available starting on Thanksgiving, or even earlier. Last year, we saw Black Friday deals online begin the week before Black Friday proper. When do Black Friday sales end? Black Friday and Cyber Monday have blended a lot over the past few years. Now, you can expect to see a good portion of Black Friday deals extend through the weekend and into Cyber Monday. It's not uncommon for Black Friday deals to expire at the end of Cyber Monday. Which retailers have the best Black Friday tech deals? The best Black Friday tech deals are typically available online at retailers like Amazon, Walmart, Best Buy and Target. It's also a good idea to check the store websites of the companies that make the products you want — for example, if you're looking for a Sonos speaker, check the Sonos website on Black Friday. Most of the time, you'll find the best Black Friday tech deals are matched at multiple retailers. Does Apple have Black Friday sales? No, you will usually not find Black Friday sales at Apple stores or on Apple's website. However, you can find Black Friday deals on Apple devices elsewhere; we recommend checking Amazon, Best Buy and other big retailers for discounts on iPads, Apple Watches and more on Black Friday. Does Amazon have Black Friday sales? Yes, Amazon has Black Friday sales. The online retailer's site will look similar to Prime Day on Black Friday, with discounts on all sorts of items from household essentials to fashion to tech.This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-deals-for-2025-are-here-early-we-found-the-best-tech-sales-from-apple-amazon-lego-anker-and-others-100052831.html?src=rss",
          "feed_position": 18
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/framework-laptop-16-2025-upgrade-review-the-rtx-5070-is-the-star-160000464.html",
          "published_at": "Wed, 12 Nov 2025 16:00:00 +0000",
          "title": "Framework Laptop 16 (2025 upgrade) review: The RTX 5070 is the star",
          "standfirst": "Plenty of companies have promised to produce a gaming laptop that could be upgraded over time. If we’re honest, nobody has managed to properly deliver on that pledge until now, as Framework launches a meaningful CPU and GPU upgrade for the Laptop 16. Almost two years after the machine first went on sale, you can now swap out its discrete Radeon RX 7700S for NVIDIA’s GeForce RTX 5070. If the company deserves a standing ovation for that feat, then it gets an extra prize for bringing an NVIDIA GPU to AMD’s hinterland. Hardware Framework’s late-2025 upgrade for the laptop is arguably more important than every product it’s released since its very first. It’s the first chance for users (of any laptop, really) to swap out or add a discrete GPU to an existing machine. If you bought the first-generation model, you could have relied on the integrated graphics, or equipped it with a discrete Radeon RX 7700S. Now, you get the option to buy NVIDIA’s GeForce RTX 5070 with 8GB DDR7 RAM which you can add to the chassis yourself. The company has also repackaged the existing Radeon RX 7700S with the promise of less fan noise and better thermal performance than the previous model. The new GPU pulls some of the focus away from the new mainboards, which are equipped with a choice of AMD’s Ryzen AI 7 350 or Ryzen AI 9 HZ 370, both of which promise to deliver 45W TDP. As before, you can equip the board with up to 86GB RAM, one or two SSDs, and your pick of ports via the six expansion card slots housed in the chassis. If you’re buying the laptop new, you’ll get a raft of smaller upgrades, starting with a new 165Hz, 2,560 x 1,600 panel which supports NVIDIA G-Sync. Plus, a new top cover, improved keyboard, number pad, webcam, Wi-Fi 7 support and an upgraded 240W power adapter. Sadly, I can’t talk about these as I was testing the upgrade from the 2024 model which just included the new mainboard and GPU module. Framework did listen to gripes about that rear-slung USB-C port which previously didn’t support charging. It was an omission that severely vexed my colleague Devindra Hardawar in his review of the original machine. But now, if you splurge for the RTX 5070, you can now use the rear port in the way that most people would intend. (If you’re unfamiliar, the Laptop 16’s discrete GPUs are packaged in self-contained “Expansion Modules” that go into the back of the chassis. The Radeon version could only be used for accessories and/or connecting additional displays.) Rounding out the changes is Framework’s continual promise that it’s improved the cooling situation. The thermal paste has been switched out for Honeywell PTM, there’s a new, redesigned fan geometry and tweaked pipes for better airflow. And, look, I don’t want to ding Framework for failing to deliver on one promise when it’s kept so many others. But if you’ve followed the company for any length of time, you already know what I’m gonna say in the In-use section. The obligatory AMD port compromise Graphic showing which ports work with which cards with an AMD mainboard. Framework As is custom whenever discussing an AMD-toting Framework machine, you’ll need to memorize the diagram of which expansion card slots will work with which devices. We’re not going to ding Framework for an issue present in all AMD hardware, and the only reason it’s noticeable here is that you have the choice of which ports to use for what. You don’t have the sort of universal port flexibility that you might otherwise be expecting. Installation Laptop 16 is bigger and more complex than its smaller siblings, but that doesn’t mean it’s any harder to maintain. The company’s iFixit-style guides hold your hand so well that popping the mid plate off should feel as natural as breathing. And you get a real sense of how well the components are laid out when you’re asked to take them all apart and put them back together. The company says replacing the mainboard and graphics module should take you an hour, which is far too generous. It took me about 22 minutes to get everything swapped in and set up, to the point where I think installing the new drivers was more laborious than this. I can’t stress enough how much of a feat it is to have a modular, upgradeable gaming laptop that offers you the chance to leap a generation. Being able to pull out a two-year-old Radeon to swap in a fresh RTX is the stuff of dreams (for some people, at least). Imagine how long it’ll be possible to keep this machine going if this type of bi-annual upgrade cycle continues. This isn’t a particularly difficult process, making it easy enough for those folks who would otherwise blanch at the idea. In-use Image of the 2025 mainboard and expansion modules for the Framework Laptop 16. Daniel Cooper for Engadget Of course, strapping such a powerful chip and graphics [INAUDIBLE DUE TO FAN NOISE] lead to issues. As discrete components, both the mainboard and expansion module need their own self-contained cooling. That’s never going to be as efficient as a holistically designed laptop. When you’re not taxing the machine, it’s not an issue at all, it’s only when you use it for its intended purpose that it becomes a serious problem. If you want to play games with this thing, get headphones or put the subtitles on, and don’t even think about using this in public. Did… did you hear that? CAN YOU HEAR ME? I SAID… AS DISCRETE COMPONENTS… And that’s before we get to the heat that this thing kicks out. I’ve got my unit on a stand with about four inches of clearance from the desk. I put my hand underneath the chassis to feel how warm it was getting and it was enough to make me never want to put this on my lap, ever. It’s a shame the noise and heat is such a bear as it’s a machine with sufficient grunt to impress many a jaded enthusiast. I set Cyberpunk 2077 to the highest settings I could (Ray Tracing: Overdrive) on 1080p, and it was able to comfortably produce 140 fps. Setting it to the defaults (Ray Tracing: Low, but the resolution set to the display’s maximum) it was able to crank out 182 fps. You’ll find similarly-impressive performance if you use the Laptop 16 more for productivity than gaming. It compressed a 38GB 4K video file down to an 8GB HD mp4 in 28 minutes and 29 seconds. Using LM Studio, I was able to run Google’s Gemma 3 27B model with what I’d call fairly decent performance. Certainly, the chatbot wasn’t responding as quickly as Gemini would online, but it was hardly stuttering. I’d say that the performance here is more or less what you’d expect from the specs, with the one downside being that godawful fan noise. Pricing If you buy a new Laptop 16 pre-built from Framework, the Ryzen AI 7 configuration starts at $1,500, the AI 9 at $1,800. Add in the RTX 5070 and you can add another $699 to that price, which is the same cost as if you buy the GPU standalone as an upgrade. Or, if money’s tight, you could buy the new machine now and then add in the 5070 whenever you’d like — that’s the benefit of modularity. It should be obvious you can get laptops with these sorts of components for less if you look elsewhere. In the run-up to the holiday season, I’ve seen machines — such as HP’s Omen Max — offer a Ryzen AI 7 and an RTX 5070 Ti for under $2,000. But here you’re not just buying a laptop, you’re buying into Framework’s broader ethos. You’ll get the fastest machine it can sell you right now, plus the ability to cheaply swap out to the next big thing in a couple years’ time without the cost of buying a new machine. As I said back when reviewing the Ryzen AI 300 upgrades for the Laptop 13 earlier this year, Framework is well placed to take advantage of the world’s political situation. If the price of a whole new laptop skyrockets, then you can at least make a saving by just replacing what you need. Wrap-up I wonder if “Should you get one?” is the best question to ask and answer given the singular furrow Framework is ploughing. If you want a powerful laptop where every part can be replaced or upgraded, you don’t really have a serious alternative. Laptop 16’s natural target market is professionals and enthusiasts who value modularity and longevity over everything else. These new components give you enough power to play games, run AI models locally and whatever other demanding tasks you’ll throw at it. As for everyone else, it’s a question of how willing you are to accept the heat, the noise and the slightly agricultural aesthetics. After all, this machine isn’t the sort of gadget you’ll be looking to move on in a few years’ time, it’ll be one you’re committing to for a long while. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/framework-laptop-16-2025-upgrade-review-the-rtx-5070-is-the-star-160000464.html?src=rss",
          "content": "Plenty of companies have promised to produce a gaming laptop that could be upgraded over time. If we’re honest, nobody has managed to properly deliver on that pledge until now, as Framework launches a meaningful CPU and GPU upgrade for the Laptop 16. Almost two years after the machine first went on sale, you can now swap out its discrete Radeon RX 7700S for NVIDIA’s GeForce RTX 5070. If the company deserves a standing ovation for that feat, then it gets an extra prize for bringing an NVIDIA GPU to AMD’s hinterland. Hardware Framework’s late-2025 upgrade for the laptop is arguably more important than every product it’s released since its very first. It’s the first chance for users (of any laptop, really) to swap out or add a discrete GPU to an existing machine. If you bought the first-generation model, you could have relied on the integrated graphics, or equipped it with a discrete Radeon RX 7700S. Now, you get the option to buy NVIDIA’s GeForce RTX 5070 with 8GB DDR7 RAM which you can add to the chassis yourself. The company has also repackaged the existing Radeon RX 7700S with the promise of less fan noise and better thermal performance than the previous model. The new GPU pulls some of the focus away from the new mainboards, which are equipped with a choice of AMD’s Ryzen AI 7 350 or Ryzen AI 9 HZ 370, both of which promise to deliver 45W TDP. As before, you can equip the board with up to 86GB RAM, one or two SSDs, and your pick of ports via the six expansion card slots housed in the chassis. If you’re buying the laptop new, you’ll get a raft of smaller upgrades, starting with a new 165Hz, 2,560 x 1,600 panel which supports NVIDIA G-Sync. Plus, a new top cover, improved keyboard, number pad, webcam, Wi-Fi 7 support and an upgraded 240W power adapter. Sadly, I can’t talk about these as I was testing the upgrade from the 2024 model which just included the new mainboard and GPU module. Framework did listen to gripes about that rear-slung USB-C port which previously didn’t support charging. It was an omission that severely vexed my colleague Devindra Hardawar in his review of the original machine. But now, if you splurge for the RTX 5070, you can now use the rear port in the way that most people would intend. (If you’re unfamiliar, the Laptop 16’s discrete GPUs are packaged in self-contained “Expansion Modules” that go into the back of the chassis. The Radeon version could only be used for accessories and/or connecting additional displays.) Rounding out the changes is Framework’s continual promise that it’s improved the cooling situation. The thermal paste has been switched out for Honeywell PTM, there’s a new, redesigned fan geometry and tweaked pipes for better airflow. And, look, I don’t want to ding Framework for failing to deliver on one promise when it’s kept so many others. But if you’ve followed the company for any length of time, you already know what I’m gonna say in the In-use section. The obligatory AMD port compromise Graphic showing which ports work with which cards with an AMD mainboard. Framework As is custom whenever discussing an AMD-toting Framework machine, you’ll need to memorize the diagram of which expansion card slots will work with which devices. We’re not going to ding Framework for an issue present in all AMD hardware, and the only reason it’s noticeable here is that you have the choice of which ports to use for what. You don’t have the sort of universal port flexibility that you might otherwise be expecting. Installation Laptop 16 is bigger and more complex than its smaller siblings, but that doesn’t mean it’s any harder to maintain. The company’s iFixit-style guides hold your hand so well that popping the mid plate off should feel as natural as breathing. And you get a real sense of how well the components are laid out when you’re asked to take them all apart and put them back together. The company says replacing the mainboard and graphics module should take you an hour, which is far too generous. It took me about 22 minutes to get everything swapped in and set up, to the point where I think installing the new drivers was more laborious than this. I can’t stress enough how much of a feat it is to have a modular, upgradeable gaming laptop that offers you the chance to leap a generation. Being able to pull out a two-year-old Radeon to swap in a fresh RTX is the stuff of dreams (for some people, at least). Imagine how long it’ll be possible to keep this machine going if this type of bi-annual upgrade cycle continues. This isn’t a particularly difficult process, making it easy enough for those folks who would otherwise blanch at the idea. In-use Image of the 2025 mainboard and expansion modules for the Framework Laptop 16. Daniel Cooper for Engadget Of course, strapping such a powerful chip and graphics [INAUDIBLE DUE TO FAN NOISE] lead to issues. As discrete components, both the mainboard and expansion module need their own self-contained cooling. That’s never going to be as efficient as a holistically designed laptop. When you’re not taxing the machine, it’s not an issue at all, it’s only when you use it for its intended purpose that it becomes a serious problem. If you want to play games with this thing, get headphones or put the subtitles on, and don’t even think about using this in public. Did… did you hear that? CAN YOU HEAR ME? I SAID… AS DISCRETE COMPONENTS… And that’s before we get to the heat that this thing kicks out. I’ve got my unit on a stand with about four inches of clearance from the desk. I put my hand underneath the chassis to feel how warm it was getting and it was enough to make me never want to put this on my lap, ever. It’s a shame the noise and heat is such a bear as it’s a machine with sufficient grunt to impress many a jaded enthusiast. I set Cyberpunk 2077 to the highest settings I could (Ray Tracing: Overdrive) on 1080p, and it was able to comfortably produce 140 fps. Setting it to the defaults (Ray Tracing: Low, but the resolution set to the display’s maximum) it was able to crank out 182 fps. You’ll find similarly-impressive performance if you use the Laptop 16 more for productivity than gaming. It compressed a 38GB 4K video file down to an 8GB HD mp4 in 28 minutes and 29 seconds. Using LM Studio, I was able to run Google’s Gemma 3 27B model with what I’d call fairly decent performance. Certainly, the chatbot wasn’t responding as quickly as Gemini would online, but it was hardly stuttering. I’d say that the performance here is more or less what you’d expect from the specs, with the one downside being that godawful fan noise. Pricing If you buy a new Laptop 16 pre-built from Framework, the Ryzen AI 7 configuration starts at $1,500, the AI 9 at $1,800. Add in the RTX 5070 and you can add another $699 to that price, which is the same cost as if you buy the GPU standalone as an upgrade. Or, if money’s tight, you could buy the new machine now and then add in the 5070 whenever you’d like — that’s the benefit of modularity. It should be obvious you can get laptops with these sorts of components for less if you look elsewhere. In the run-up to the holiday season, I’ve seen machines — such as HP’s Omen Max — offer a Ryzen AI 7 and an RTX 5070 Ti for under $2,000. But here you’re not just buying a laptop, you’re buying into Framework’s broader ethos. You’ll get the fastest machine it can sell you right now, plus the ability to cheaply swap out to the next big thing in a couple years’ time without the cost of buying a new machine. As I said back when reviewing the Ryzen AI 300 upgrades for the Laptop 13 earlier this year, Framework is well placed to take advantage of the world’s political situation. If the price of a whole new laptop skyrockets, then you can at least make a saving by just replacing what you need. Wrap-up I wonder if “Should you get one?” is the best question to ask and answer given the singular furrow Framework is ploughing. If you want a powerful laptop where every part can be replaced or upgraded, you don’t really have a serious alternative. Laptop 16’s natural target market is professionals and enthusiasts who value modularity and longevity over everything else. These new components give you enough power to play games, run AI models locally and whatever other demanding tasks you’ll throw at it. As for everyone else, it’s a question of how willing you are to accept the heat, the noise and the slightly agricultural aesthetics. After all, this machine isn’t the sort of gadget you’ll be looking to move on in a few years’ time, it’ll be one you’re committing to for a long while. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/framework-laptop-16-2025-upgrade-review-the-rtx-5070-is-the-star-160000464.html?src=rss",
          "feed_position": 19,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/FW16Ports.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/the-youtube-tv-disney-blackout-continues-how-to-watch-wednesday-nba-games-and-prep-for-weekend-college-football-173330100.html",
          "published_at": "Wed, 12 Nov 2025 15:21:13 +0000",
          "title": "The YouTube TV Disney blackout continues: How to watch Wednesday NBA games and prep for weekend college football",
          "standfirst": "Engadget The Disney/YouTube TV saga, now in its second week, is still showing no sign of a resolution. While the blackout is painful for subscribers who have been left without access to over 20 channels, Disney is also feeling the pinch, with reports estimating they're losing $4.3 million per day during the dispute. The good news for YouTube subscribers is that the platform has finally started issuing $20 credits as consolation for their troubles, but will that be enough to keep their base from jumping ship and finding a new streaming service? As a reminder of how we got here, the Walt Disney Co. pulled its channels from YouTube TV on Oct. 30 after the two companies failed to reach new terms on their latest carriage agreement, and YouTube TV subscribers have gone without NFL, NBA and NCAA games on ABC and ESPN's suite of channels for two straight weekends. With no agreement in sight, YouTube TV subscribers will be left in the dark for tonight's NBA games, too. Tonight's basketball games between the Orlando Magic vs. New York Knicks and Los Angeles Lakers vs. Oklahoma City Thunder both air on ESPN, so if you want to catch either game (or watch The Golden Bachelor season finale on ABC!), you'll need to seek out alternative viewing methods. And unfortunately for YouTube TV's negotiating position, there are plenty of options. One of the cheapest ways to watch ESPN is with a Sling Day Pass — for just $5/day, you can tune into any and all ESPN programming with no other commitments. If you want a full switch from YouTube TV, there's Hulu + Live TV, DirecTV, or Fubo, where you can watch all the Disney-owned channels. (Remember, unlike a lot of cable plans, you can easily pause or cancel YouTube TV or any of these alternatives, so long as you have month-to-month subscriptions.) Below, we've outlined some of your best options to watch ESPN, the Disney Channel, ABC and more, all pulled from our list of best live TV streaming services to cut cable, as well as a comprehensive list of which channels have been affected, and the biggest sporting events of the week that won't be available to YouTube TV subscribers. What games are on ESPN/ABC this week? If you're wondering what games you might miss as a result of the YouTube TV/Disney blackout, here's a list of some upcoming sports you may not want to miss: NBA Wednesday, Nov. 12 7 p.m. | Orlando Magic vs. New York Knicks | ESPN 9:35 p.m. | Los Angeles Lakers vs. Oklahoma City Thunder | ESPN NCAA Football Thursday, Nov. 13 7:30 p.m. | Troy at Old Dominion | ESPN Friday, Nov. 14 5:30 p.m. | South Carolina State at North Carolina Central | ESPN27:30 p.m. | Clemson at No. 20 Louisville | ESPN Grab an ESPN bundle so you won't miss the NFL, NBA or any other games Get Hulu + Live TV at a great price Try Fubo free for a week and get $30 your first month Try DirecTV free for 5 days, and get $30 off your first month What about Sling \"day passes\"? You may have heard that Sling offers day, weekend and week passes to its streaming programming for as little as $5 per day. That is an option if you're looking for just some of the ESPN channels (the Sling Orange tier), but ABC isn't included. (If you're just looking to catch one of this week's big games, like Monday Night Football on ESPN, it's a great short-term solution.) If you want a longer-term solution, you can get both ESPN and ABC with Sling's Orange and Blue package ($30 a month to start, $61 thereafter), but you'll need to add on the Sports Extra package for ESPNU, which requires an additional charge. Get your local Disney/ABC programming for free Need your local ABC programming? Your station may have its own free local streaming news channel (many do), you can see if The Roku Channel carries your local station's news, or download your local news station app if it's a Nexstar channel. The other alternative — if you're within the broadcast radius of a local ABC affiliate — is to get an over-the-air antenna. You can plug in your ZIP code at antennaweb.org to see what channels are in your area. This off-brand unit has worked very well in our initial testing — it's under $30, and the channels are truly free. Which channels are no longer available on YouTube TV? Every channel that's owned by The Walt Disney Company is currently blacked out on YouTube TV. Those channels are: ABC ABC News Live ACC Network Disney Channel Disney Junior Disney XD ESPN ESPNews ESPN2 ESPNU Freeform FX FXM FXX Localish Nat Geo Nat Geo Wild SEC Network ESPN Deportes Baby TV Español Nat Geo Mundo Update Nov. 10 2025, 4:43PM ET: This story has been updated to include news on the $20 rebate for YouTube TV subscribers, as well as to update the list of upcoming football games for the week. Update Nov. 6 2025, 4:38PM ET: This story has been updated to include viewing info for weekend college football games, as well as the next Monday Night Football. Update Nov. 5 2025, 12:32PM ET: This story has been updated to include detailed info on tonight's ESPN NBA games. Update Nov. 3 2025, 6:36PM ET: This story has been updated to include YouTube TV's latest response to Disney's request to restore its channels for just 24 hours.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/the-youtube-tv-disney-blackout-continues-how-to-watch-wednesday-nba-games-and-prep-for-weekend-college-football-173330100.html?src=rss",
          "content": "Engadget The Disney/YouTube TV saga, now in its second week, is still showing no sign of a resolution. While the blackout is painful for subscribers who have been left without access to over 20 channels, Disney is also feeling the pinch, with reports estimating they're losing $4.3 million per day during the dispute. The good news for YouTube subscribers is that the platform has finally started issuing $20 credits as consolation for their troubles, but will that be enough to keep their base from jumping ship and finding a new streaming service? As a reminder of how we got here, the Walt Disney Co. pulled its channels from YouTube TV on Oct. 30 after the two companies failed to reach new terms on their latest carriage agreement, and YouTube TV subscribers have gone without NFL, NBA and NCAA games on ABC and ESPN's suite of channels for two straight weekends. With no agreement in sight, YouTube TV subscribers will be left in the dark for tonight's NBA games, too. Tonight's basketball games between the Orlando Magic vs. New York Knicks and Los Angeles Lakers vs. Oklahoma City Thunder both air on ESPN, so if you want to catch either game (or watch The Golden Bachelor season finale on ABC!), you'll need to seek out alternative viewing methods. And unfortunately for YouTube TV's negotiating position, there are plenty of options. One of the cheapest ways to watch ESPN is with a Sling Day Pass — for just $5/day, you can tune into any and all ESPN programming with no other commitments. If you want a full switch from YouTube TV, there's Hulu + Live TV, DirecTV, or Fubo, where you can watch all the Disney-owned channels. (Remember, unlike a lot of cable plans, you can easily pause or cancel YouTube TV or any of these alternatives, so long as you have month-to-month subscriptions.) Below, we've outlined some of your best options to watch ESPN, the Disney Channel, ABC and more, all pulled from our list of best live TV streaming services to cut cable, as well as a comprehensive list of which channels have been affected, and the biggest sporting events of the week that won't be available to YouTube TV subscribers. What games are on ESPN/ABC this week? If you're wondering what games you might miss as a result of the YouTube TV/Disney blackout, here's a list of some upcoming sports you may not want to miss: NBA Wednesday, Nov. 12 7 p.m. | Orlando Magic vs. New York Knicks | ESPN 9:35 p.m. | Los Angeles Lakers vs. Oklahoma City Thunder | ESPN NCAA Football Thursday, Nov. 13 7:30 p.m. | Troy at Old Dominion | ESPN Friday, Nov. 14 5:30 p.m. | South Carolina State at North Carolina Central | ESPN27:30 p.m. | Clemson at No. 20 Louisville | ESPN Grab an ESPN bundle so you won't miss the NFL, NBA or any other games Get Hulu + Live TV at a great price Try Fubo free for a week and get $30 your first month Try DirecTV free for 5 days, and get $30 off your first month What about Sling \"day passes\"? You may have heard that Sling offers day, weekend and week passes to its streaming programming for as little as $5 per day. That is an option if you're looking for just some of the ESPN channels (the Sling Orange tier), but ABC isn't included. (If you're just looking to catch one of this week's big games, like Monday Night Football on ESPN, it's a great short-term solution.) If you want a longer-term solution, you can get both ESPN and ABC with Sling's Orange and Blue package ($30 a month to start, $61 thereafter), but you'll need to add on the Sports Extra package for ESPNU, which requires an additional charge. Get your local Disney/ABC programming for free Need your local ABC programming? Your station may have its own free local streaming news channel (many do), you can see if The Roku Channel carries your local station's news, or download your local news station app if it's a Nexstar channel. The other alternative — if you're within the broadcast radius of a local ABC affiliate — is to get an over-the-air antenna. You can plug in your ZIP code at antennaweb.org to see what channels are in your area. This off-brand unit has worked very well in our initial testing — it's under $30, and the channels are truly free. Which channels are no longer available on YouTube TV? Every channel that's owned by The Walt Disney Company is currently blacked out on YouTube TV. Those channels are: ABC ABC News Live ACC Network Disney Channel Disney Junior Disney XD ESPN ESPNews ESPN2 ESPNU Freeform FX FXM FXX Localish Nat Geo Nat Geo Wild SEC Network ESPN Deportes Baby TV Español Nat Geo Mundo Update Nov. 10 2025, 4:43PM ET: This story has been updated to include news on the $20 rebate for YouTube TV subscribers, as well as to update the list of upcoming football games for the week. Update Nov. 6 2025, 4:38PM ET: This story has been updated to include viewing info for weekend college football games, as well as the next Monday Night Football. Update Nov. 5 2025, 12:32PM ET: This story has been updated to include detailed info on tonight's ESPN NBA games. Update Nov. 3 2025, 6:36PM ET: This story has been updated to include YouTube TV's latest response to Disney's request to restore its channels for just 24 hours.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/the-youtube-tv-disney-blackout-continues-how-to-watch-wednesday-nba-games-and-prep-for-weekend-college-football-173330100.html?src=rss",
          "feed_position": 20,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-11/0c8d0fa0-bb59-11f0-ab9e-898961c799a9"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/nintendo-announces-its-black-friday-and-cyber-monday-2025-sale-switch-2-bundles-switch-game-deals-accessories-and-more-155223057.html",
          "published_at": "Wed, 12 Nov 2025 15:15:35 +0000",
          "title": "Nintendo announces its Black Friday and Cyber Monday 2025 sale: Switch 2 bundles, Switch game deals, accessories and more",
          "standfirst": "Nintendo gear is always sought after during the holiday shopping season, but this year likely more so than others. The Nintendo Switch 2 is the console launch of 2025 and it will undoubtedly be at the top of many wish lists for both kids and adults alike. If you were hoping to save a bit on the console during the Black Friday shopping season, you may be disappointed. The Nintendo Black Friday sale was just announced, and unsurprisingly, there aren't a lot of true \"deals\" to be had. This is typical of Nintendo — legit Nintendo Black Friday deals are hard to come by — but there are ways to at least get the best value for your money if you're going to pick up a Switch 2 before the year is out. As has been the case for many years, the marquee Nintendo deals for the holidays come in the form of console bundles. When the Switch 2 launched earlier this year, it was available as just the console only for $449 or bundled with Mario Kart World for $499. Both options are still available now, but there's a new bundle to consider as well — the console with the new Pokémon Legends: Z-A game, which also costs $499. Considering the games by themselves cost $70 each, you do save a bit by picking up a console bundle. you can pick up the console and its bundles at most retailers including Amazon, Walmart, Best Buy and others. When it comes to deals on Nintendo Switch 2 games, the Nintendo eShop will have Cyber Deals starting on November 20, running through December 3. The shop will feature \"holiday offers on select games,\" so it appears we'll all just have to go to the online store on November 20 to see the games on offer. Starting on November 23, select retailers will have discounts on some physical Switch games including Princess Peach: Showtime!, The Legend of Zelda: Echoes of Wisdom, Luigi’s Mansion 3 and Kirby’s Return to Dream Land Deluxe. Those will each be $40, while other games like Super Mario Odyssey, Nintendo Switch Sports, Paper Mario: The Thousand-Year Door and Splatoon 3 will be $30. Even if you can't get huge discounts on Nintendo consoles or new games this year, that doesn't mean you can't find decent deals on other Nintendo gear. There are plenty of great ideas for gifts for the Nintendo fan in your life, and Engadget's Sam Rutherford got to see a bunch of them in person when he attended Nintendo's holiday showcase. From collectibles to clothing to plushies and holiday decor, there's really a ton to choose from — but you may want to pace yourself if you're also a Nintendo fan finding things that you want to pick up for yourself in the process of looking for good gifts. Here are just some of the best Nintendo gift ideas that you can look out for during Black Friday and Cyber Monday. This article originally appeared on Engadget at https://www.engadget.com/deals/nintendo-announces-its-black-friday-and-cyber-monday-2025-sale-switch-2-bundles-switch-game-deals-accessories-and-more-155223057.html?src=rss",
          "content": "Nintendo gear is always sought after during the holiday shopping season, but this year likely more so than others. The Nintendo Switch 2 is the console launch of 2025 and it will undoubtedly be at the top of many wish lists for both kids and adults alike. If you were hoping to save a bit on the console during the Black Friday shopping season, you may be disappointed. The Nintendo Black Friday sale was just announced, and unsurprisingly, there aren't a lot of true \"deals\" to be had. This is typical of Nintendo — legit Nintendo Black Friday deals are hard to come by — but there are ways to at least get the best value for your money if you're going to pick up a Switch 2 before the year is out. As has been the case for many years, the marquee Nintendo deals for the holidays come in the form of console bundles. When the Switch 2 launched earlier this year, it was available as just the console only for $449 or bundled with Mario Kart World for $499. Both options are still available now, but there's a new bundle to consider as well — the console with the new Pokémon Legends: Z-A game, which also costs $499. Considering the games by themselves cost $70 each, you do save a bit by picking up a console bundle. you can pick up the console and its bundles at most retailers including Amazon, Walmart, Best Buy and others. When it comes to deals on Nintendo Switch 2 games, the Nintendo eShop will have Cyber Deals starting on November 20, running through December 3. The shop will feature \"holiday offers on select games,\" so it appears we'll all just have to go to the online store on November 20 to see the games on offer. Starting on November 23, select retailers will have discounts on some physical Switch games including Princess Peach: Showtime!, The Legend of Zelda: Echoes of Wisdom, Luigi’s Mansion 3 and Kirby’s Return to Dream Land Deluxe. Those will each be $40, while other games like Super Mario Odyssey, Nintendo Switch Sports, Paper Mario: The Thousand-Year Door and Splatoon 3 will be $30. Even if you can't get huge discounts on Nintendo consoles or new games this year, that doesn't mean you can't find decent deals on other Nintendo gear. There are plenty of great ideas for gifts for the Nintendo fan in your life, and Engadget's Sam Rutherford got to see a bunch of them in person when he attended Nintendo's holiday showcase. From collectibles to clothing to plushies and holiday decor, there's really a ton to choose from — but you may want to pace yourself if you're also a Nintendo fan finding things that you want to pick up for yourself in the process of looking for good gifts. Here are just some of the best Nintendo gift ideas that you can look out for during Black Friday and Cyber Monday. This article originally appeared on Engadget at https://www.engadget.com/deals/nintendo-announces-its-black-friday-and-cyber-monday-2025-sale-switch-2-bundles-switch-game-deals-accessories-and-more-155223057.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/even-realities-g2-first-look-this-years-best-looking-new-smart-glasses-still-need-work-151500132.html",
          "published_at": "Wed, 12 Nov 2025 15:15:00 +0000",
          "title": "Even Realities G2 first look: This year's best-looking new smart glasses still need work",
          "standfirst": "A lot of people think the original Google Glass failed because of subpar tech. But the larger issue was that they were so ugly that people simply didn't want to wear them. And when it's a device that sits on your face, that's kind of important. Thankfully, that's a lesson Even Realities seemingly took to heart when it made the G1, which combined the stylishness of proper eyewear with built-in waveguide displays. Now the company is back with its second-gen smart glasses — the G2 — which offer even better optics, an updated UI and a companion ring (the R1) to their expanded list of features. While the design of the Even G2 hasn't changed a ton from its predecessor, that's not a bad thing as there wasn't much to fix. Compared to every other pair of smart glasses on sale today, these look the most like normal eyewear. Meanwhile, thanks to a titanium and magnesium alloy design and the company's very intentional decision not to include onboard cameras or speakers, the new model only weighs 36 grams, so they're also super comfortable. You even get two styles to choose from (panto or rectangular) along with a few different finishes (gray, brown and green), so chances are there's a combination that will work with your wardrobe. The Even G2 also features an IP67 rating for dust and water resistance, so you don't need to worry about wearing them in adverse conditions. The G2's battery life can last up to two days, while its case has juice for up to seven additional charges. Sam Rutherford for EngadgetThe G2’s optics are based on the company's new Even HAO 2.0 (Holistic Adaptive Optics) that use custom-designed dual waveguides to produce a green heads-up display. It’s not only brighter and sharper than before but also features a wider field of view. Now admittedly, that's not quite as impressive as the single RGB display in something like the Ray-Ban Meta Display. But considering that the Even G2 is way less chunky and sports significantly longer battery life (up to two days plus seven full recharges from its included case), that feels like a worthy trade-off to deliver increased usability.However, the biggest upgrade for the G2 is an expanded roster of smart features. In addition to showing notifications, turn-by-turn directions and the teleprompter functionality available on the previous model, Even has developed a much more robust UI that lets you read the news, track stock prices and create lists using your voice. There is now an onboard AI assistant and LLM that can translate speech on the fly or pick out key words during a conversation to give more background and context about unfamiliar terms. This means the glasses can handle a lot of tasks you'd normally need your phone for, which is great if you're walking around, or similarly indisposed, and would rather keep your hands free. In addition to basic health and fitness tracking, the R1 ring also has a tiny built-in touchpad (denoted by the four dots) to make it easier to navigate the G2's new UI and menus. Sam Rutherford for EngadgetWhile you can access most of these features using voice controls, the icing on the cake is the R1 companion ring that makes better use of the new UI. Not only does it track some basic health and fitness data (steps, heart rate, sleep, SpO2 and more), it also serves as a tiny touchpad so you can check notifications, revisit your notes and more without anyone nearby knowing what you're up to. All told, the G2 glasses and the R1 ring create a very stylish and discreet package that allows you to stay connected and keep your phone in your pocket. That said, you might want to wait before throwing money down on these. I've been testing the G2 and R1 over the past few days, and even though I really like the hardware, the company's software just isn't ready yet. It's important to note that I've been using a beta version of the Even Realties app, so encountering some bugs was not entirely unexpected. But even so, the touch controls on the ring feel imprecise and occasionally erratic. Many of the fitness metrics aren't being properly recorded and both devices have had a difficult time staying paired to the app. Even little things, like the auto brightness settings (which don't work at the moment) or ability to add more sources to the glasses' news feed, feel janky. The only outlet I've been able to successfully use is ABC. While the tech and features of the G2 are very interesting, I've run into a number of software issues while using a beta version of the app. Sam Rutherford for EngadgetGranted, some of the G2 and R1's issues that I've run into, like wonky touch input and the unfinished health tracking, are known problems that are currently being worked on by Even Realities. Still, this feels like a situation where the launch of these devices should have been delayed until the company could smooth out these hiccups.But if you are undeterred, the Even G2 Display Smart Glasses and Even R1 Smart Ring go on sale today for $599 and $249, respectively. For everyone else, I'm hoping to check back in on these devices after the company pushes out some software updates. I’m eager to see if they can eventually live up to their potential as an interesting alternative to bigger, chunkier and more intrusive smartglass alternatives like the Ray-Ban Meta Displays.This article originally appeared on Engadget at https://www.engadget.com/mobile/even-realities-g2-first-look-this-years-best-looking-new-smart-glasses-still-need-work-151500132.html?src=rss",
          "content": "A lot of people think the original Google Glass failed because of subpar tech. But the larger issue was that they were so ugly that people simply didn't want to wear them. And when it's a device that sits on your face, that's kind of important. Thankfully, that's a lesson Even Realities seemingly took to heart when it made the G1, which combined the stylishness of proper eyewear with built-in waveguide displays. Now the company is back with its second-gen smart glasses — the G2 — which offer even better optics, an updated UI and a companion ring (the R1) to their expanded list of features. While the design of the Even G2 hasn't changed a ton from its predecessor, that's not a bad thing as there wasn't much to fix. Compared to every other pair of smart glasses on sale today, these look the most like normal eyewear. Meanwhile, thanks to a titanium and magnesium alloy design and the company's very intentional decision not to include onboard cameras or speakers, the new model only weighs 36 grams, so they're also super comfortable. You even get two styles to choose from (panto or rectangular) along with a few different finishes (gray, brown and green), so chances are there's a combination that will work with your wardrobe. The Even G2 also features an IP67 rating for dust and water resistance, so you don't need to worry about wearing them in adverse conditions. The G2's battery life can last up to two days, while its case has juice for up to seven additional charges. Sam Rutherford for EngadgetThe G2’s optics are based on the company's new Even HAO 2.0 (Holistic Adaptive Optics) that use custom-designed dual waveguides to produce a green heads-up display. It’s not only brighter and sharper than before but also features a wider field of view. Now admittedly, that's not quite as impressive as the single RGB display in something like the Ray-Ban Meta Display. But considering that the Even G2 is way less chunky and sports significantly longer battery life (up to two days plus seven full recharges from its included case), that feels like a worthy trade-off to deliver increased usability.However, the biggest upgrade for the G2 is an expanded roster of smart features. In addition to showing notifications, turn-by-turn directions and the teleprompter functionality available on the previous model, Even has developed a much more robust UI that lets you read the news, track stock prices and create lists using your voice. There is now an onboard AI assistant and LLM that can translate speech on the fly or pick out key words during a conversation to give more background and context about unfamiliar terms. This means the glasses can handle a lot of tasks you'd normally need your phone for, which is great if you're walking around, or similarly indisposed, and would rather keep your hands free. In addition to basic health and fitness tracking, the R1 ring also has a tiny built-in touchpad (denoted by the four dots) to make it easier to navigate the G2's new UI and menus. Sam Rutherford for EngadgetWhile you can access most of these features using voice controls, the icing on the cake is the R1 companion ring that makes better use of the new UI. Not only does it track some basic health and fitness data (steps, heart rate, sleep, SpO2 and more), it also serves as a tiny touchpad so you can check notifications, revisit your notes and more without anyone nearby knowing what you're up to. All told, the G2 glasses and the R1 ring create a very stylish and discreet package that allows you to stay connected and keep your phone in your pocket. That said, you might want to wait before throwing money down on these. I've been testing the G2 and R1 over the past few days, and even though I really like the hardware, the company's software just isn't ready yet. It's important to note that I've been using a beta version of the Even Realties app, so encountering some bugs was not entirely unexpected. But even so, the touch controls on the ring feel imprecise and occasionally erratic. Many of the fitness metrics aren't being properly recorded and both devices have had a difficult time staying paired to the app. Even little things, like the auto brightness settings (which don't work at the moment) or ability to add more sources to the glasses' news feed, feel janky. The only outlet I've been able to successfully use is ABC. While the tech and features of the G2 are very interesting, I've run into a number of software issues while using a beta version of the app. Sam Rutherford for EngadgetGranted, some of the G2 and R1's issues that I've run into, like wonky touch input and the unfinished health tracking, are known problems that are currently being worked on by Even Realities. Still, this feels like a situation where the launch of these devices should have been delayed until the company could smooth out these hiccups.But if you are undeterred, the Even G2 Display Smart Glasses and Even R1 Smart Ring go on sale today for $599 and $249, respectively. For everyone else, I'm hoping to check back in on these devices after the company pushes out some software updates. I’m eager to see if they can eventually live up to their potential as an interesting alternative to bigger, chunkier and more intrusive smartglass alternatives like the Ray-Ban Meta Displays.This article originally appeared on Engadget at https://www.engadget.com/mobile/even-realities-g2-first-look-this-years-best-looking-new-smart-glasses-still-need-work-151500132.html?src=rss",
          "feed_position": 23,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Even-G2-edited.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/even-realities-g2-smart-glasses-can-be-controlled-with-a-smart-ring-151500125.html",
          "published_at": "Wed, 12 Nov 2025 15:15:00 +0000",
          "title": "Even Realities' G2 smart glasses can be controlled with a smart ring",
          "standfirst": "Even Realities is releasing the next version of its lightweight smart glasses, and this time it’s pairing them with an entirely new device that will act as both a controller and health tracker. The Even G2 Display Smart Glasses are a more refined version of the G1 smart glasses, and you'll be able to interact with them without having to touch the frames or uses voice commands thanks to the new Even R1 Smart Ring.The G2 features an updated version of the Even Realities' HAO optical engine (a combination of micro-LED projectors, waveguides and digitally surfaced lenses), that still displays text in bright green, but now with added depth and sharpness. For example, Even Realities says the new glasses can display pop-ups like AI prompts and notifications at a different depth from the glasses' normal interface, so you don't lose the context of whatever you're reading. The G2 also supports a wider range of prescription lenses (from -12 to +12 diopters), making them more accessible to people who already wear glasses.In comparison to the G1, Even Realities says the G2 has 54 percent slimmer temples and, in a first for the company, is IP67-rated for dust and water resistance. The G2 also gets two days of battery life in comparison to the G1's one and a half days, and its charging case can provide up to seven full charges.A ceramic and titanium R1 smart ring with a flat side.Even RealitiesWhile the G2 glasses can still be controlled by tapping a built-in touchpad or using voice commands, the R1 Smart Ring will let you interact with the smart glasses without moving your arm. The R1 is made from ceramic and medical-grade stainless steel, and features a flat touchpad surface for activating the G2's interface. Besides a touch sensor for navigation, the R1 also includes an optical heart rate sensor and accelerometer for tracking your heart rate and steps, which can be viewed on the G2. While less technically advanced than the Neural Band Meta included with the Meta Ray-Ban Display Glasses, Even Realities ring seems like it can make controlling its glasses similarly discrete, while being useful in its own right as a health tracker.Even Realities is also adding a new AI skill alongside its glasses and ring. The G2 supports the same translation, notifications and teleprompter features as the company's last model, but this time includes a feature called \"Conversate\" that attempts to offer AI-generated information during conversations. Even Realities says Conversate can provide explanations, context and follow-up questions during a conversation, and then generate a summary and key points once you're finished talking. The whole thing sounds a bit distracting, but might be something you have to demo to understand.A pair of Even G2 Display Smart Glasses in a charging case.Even RealitiesThat extra layer of complication seems inherent to the pitch for both the G2 glasses and the R1 ring. While Even Realities has made its smart glasses more convenient, and they're definitely not trying to be a phone replacement in the same way Meta's glasses are, they do seem like they'll have more of a learning curve than the last generation.The Even G2 Display Smart Glasses and Even R1 Smart Ring are available to order today, November 12, for $599 and $249, respectively. Even Realities says that anyone who purchases the G2 will be able to receive the R1 and other accessories for 50 percent off for a limited time.This article originally appeared on Engadget at https://www.engadget.com/wearables/even-realities-g2-smart-glasses-can-be-controlled-with-a-smart-ring-151500125.html?src=rss",
          "content": "Even Realities is releasing the next version of its lightweight smart glasses, and this time it’s pairing them with an entirely new device that will act as both a controller and health tracker. The Even G2 Display Smart Glasses are a more refined version of the G1 smart glasses, and you'll be able to interact with them without having to touch the frames or uses voice commands thanks to the new Even R1 Smart Ring.The G2 features an updated version of the Even Realities' HAO optical engine (a combination of micro-LED projectors, waveguides and digitally surfaced lenses), that still displays text in bright green, but now with added depth and sharpness. For example, Even Realities says the new glasses can display pop-ups like AI prompts and notifications at a different depth from the glasses' normal interface, so you don't lose the context of whatever you're reading. The G2 also supports a wider range of prescription lenses (from -12 to +12 diopters), making them more accessible to people who already wear glasses.In comparison to the G1, Even Realities says the G2 has 54 percent slimmer temples and, in a first for the company, is IP67-rated for dust and water resistance. The G2 also gets two days of battery life in comparison to the G1's one and a half days, and its charging case can provide up to seven full charges.A ceramic and titanium R1 smart ring with a flat side.Even RealitiesWhile the G2 glasses can still be controlled by tapping a built-in touchpad or using voice commands, the R1 Smart Ring will let you interact with the smart glasses without moving your arm. The R1 is made from ceramic and medical-grade stainless steel, and features a flat touchpad surface for activating the G2's interface. Besides a touch sensor for navigation, the R1 also includes an optical heart rate sensor and accelerometer for tracking your heart rate and steps, which can be viewed on the G2. While less technically advanced than the Neural Band Meta included with the Meta Ray-Ban Display Glasses, Even Realities ring seems like it can make controlling its glasses similarly discrete, while being useful in its own right as a health tracker.Even Realities is also adding a new AI skill alongside its glasses and ring. The G2 supports the same translation, notifications and teleprompter features as the company's last model, but this time includes a feature called \"Conversate\" that attempts to offer AI-generated information during conversations. Even Realities says Conversate can provide explanations, context and follow-up questions during a conversation, and then generate a summary and key points once you're finished talking. The whole thing sounds a bit distracting, but might be something you have to demo to understand.A pair of Even G2 Display Smart Glasses in a charging case.Even RealitiesThat extra layer of complication seems inherent to the pitch for both the G2 glasses and the R1 ring. While Even Realities has made its smart glasses more convenient, and they're definitely not trying to be a phone replacement in the same way Meta's glasses are, they do seem like they'll have more of a learning curve than the last generation.The Even G2 Display Smart Glasses and Even R1 Smart Ring are available to order today, November 12, for $599 and $249, respectively. Even Realities says that anyone who purchases the G2 will be able to receive the R1 and other accessories for 50 percent off for a limited time.This article originally appeared on Engadget at https://www.engadget.com/wearables/even-realities-g2-smart-glasses-can-be-controlled-with-a-smart-ring-151500125.html?src=rss",
          "feed_position": 24,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Even-R1-Smart-Ring.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/one-year-of-headspace-drops-to-only-35-with-this-black-friday-deal-163051565.html",
          "published_at": "Wed, 12 Nov 2025 15:00:36 +0000",
          "title": "One year of Headspace drops to only $35 with this Black Friday deal.",
          "standfirst": "Meditation app Headspace is bringing back one of its biggest annual deals this Black Friday. Through December 4, you’ll be able to get 50 percent off the regular annual subscription price, bringing a full year of guided meditations, sleep sounds and mindfulness tools down to $35 per year. If you’ve been looking to build a better daily routine, this discount makes it easier to start. Headspace has become one of the most recognizable names in digital mindfulness. The app blends practical meditation guidance with structured courses and calming soundscapes designed to make everyday stress easier to manage. Its programs cover everything from beginner-friendly introductions to mindfulness to focused content on topics like anxiety, productivity and sleep. Subscribers get access to hundreds of guided sessions led by the Headspace team, including short daily practices that can be completed in a few spare minutes, plus longer courses that help build consistency. The app’s Sleepcasts and soundscapes are unique, designed to create a steady nighttime routine that promotes better rest. For mornings, there are breathing exercises and motivational mini-sessions that can help set focus for the day ahead. Headspace also includes personalized progress tracking, mood check-ins and optional reminders that make it easier to stay consistent with your new mindfulness habits. For anyone new to meditation, the app’s clear structure is a major strength. You don’t have to know where to start, since it suggests sessions based on your goals or current mood. This annual deal is ideal for users who want to stick with mindfulness practice over time, or anyone interested in incorporating a new habit into their lives. Paying for the year upfront typically saves money compared with the monthly plan, and the discount brings that cost down even further. Whether you’re learning the basics of meditation or refining an existing routine, the full library provides enough variety to keep things engaging throughout the year. If you’re still comparing wellness apps, check out our guide to the best meditation apps to see how Headspace stacks up against other options. But for those ready to commit to a calmer routine, this annual offer is one of the simplest ways to start the habit at a lower cost.This article originally appeared on Engadget at https://www.engadget.com/deals/one-year-of-headspace-drops-to-only-35-with-this-black-friday-deal-163051565.html?src=rss",
          "content": "Meditation app Headspace is bringing back one of its biggest annual deals this Black Friday. Through December 4, you’ll be able to get 50 percent off the regular annual subscription price, bringing a full year of guided meditations, sleep sounds and mindfulness tools down to $35 per year. If you’ve been looking to build a better daily routine, this discount makes it easier to start. Headspace has become one of the most recognizable names in digital mindfulness. The app blends practical meditation guidance with structured courses and calming soundscapes designed to make everyday stress easier to manage. Its programs cover everything from beginner-friendly introductions to mindfulness to focused content on topics like anxiety, productivity and sleep. Subscribers get access to hundreds of guided sessions led by the Headspace team, including short daily practices that can be completed in a few spare minutes, plus longer courses that help build consistency. The app’s Sleepcasts and soundscapes are unique, designed to create a steady nighttime routine that promotes better rest. For mornings, there are breathing exercises and motivational mini-sessions that can help set focus for the day ahead. Headspace also includes personalized progress tracking, mood check-ins and optional reminders that make it easier to stay consistent with your new mindfulness habits. For anyone new to meditation, the app’s clear structure is a major strength. You don’t have to know where to start, since it suggests sessions based on your goals or current mood. This annual deal is ideal for users who want to stick with mindfulness practice over time, or anyone interested in incorporating a new habit into their lives. Paying for the year upfront typically saves money compared with the monthly plan, and the discount brings that cost down even further. Whether you’re learning the basics of meditation or refining an existing routine, the full library provides enough variety to keep things engaging throughout the year. If you’re still comparing wellness apps, check out our guide to the best meditation apps to see how Headspace stacks up against other options. But for those ready to commit to a calmer routine, this annual offer is one of the simplest ways to start the habit at a lower cost.This article originally appeared on Engadget at https://www.engadget.com/deals/one-year-of-headspace-drops-to-only-35-with-this-black-friday-deal-163051565.html?src=rss",
          "feed_position": 25
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/walmart-subscriptions-are-only-49-for-black-friday-and-it-includes-access-to-peacock-192739301.html",
          "published_at": "Wed, 12 Nov 2025 14:05:37 +0000",
          "title": "Walmart+ subscriptions are only $49 for Black Friday, and it includes access to Peacock",
          "standfirst": "If you've wanted to check out The Paper or any other new NBC show on Peacock, you can do so now while spending less thanks to this hack. Walmart, believe it or not, comes into play here: the retailer is offering Walmart+ subscriptions for half off right now, bringing the cost down to $49 for your first year. Thanks to a streaming benefit for subscribers, you can then sign up for Peacock at no extra cost. Walmart+ subscribers are able to choose between a Peacock Premium or a Paramount+ Essential subscription. Considering Peacock premium would run you $110 for the year on its own, signing up for Walmart+ while this discount is available gets you access to the streaming service for less than half the normal cost. Just about every major streaming service has raised its prices in the last year, including HBO Max, Disney+, Netflix, Apple TV and YouTube TV, so saving some money on one of them just might be worth the effort. Cord cutting is not nearly as affordable as it used to be, so finding a deal like this is pretty helpful. Walmart+ itself offers myriad additional benefits like early access to Black Friday deals, free shipping on orders over $35, discounts on gas, free online veterinary care and more. Earlier this year, Walmart+ subscribers got first dibs on the Nintendo Switch 2 at the retailer. You can also use that free shipping to take advantage of Walmart's drone delivery program in a handful of select cities.This article originally appeared on Engadget at https://www.engadget.com/deals/walmart-subscriptions-are-only-49-for-black-friday-and-it-includes-access-to-peacock-192739301.html?src=rss",
          "content": "If you've wanted to check out The Paper or any other new NBC show on Peacock, you can do so now while spending less thanks to this hack. Walmart, believe it or not, comes into play here: the retailer is offering Walmart+ subscriptions for half off right now, bringing the cost down to $49 for your first year. Thanks to a streaming benefit for subscribers, you can then sign up for Peacock at no extra cost. Walmart+ subscribers are able to choose between a Peacock Premium or a Paramount+ Essential subscription. Considering Peacock premium would run you $110 for the year on its own, signing up for Walmart+ while this discount is available gets you access to the streaming service for less than half the normal cost. Just about every major streaming service has raised its prices in the last year, including HBO Max, Disney+, Netflix, Apple TV and YouTube TV, so saving some money on one of them just might be worth the effort. Cord cutting is not nearly as affordable as it used to be, so finding a deal like this is pretty helpful. Walmart+ itself offers myriad additional benefits like early access to Black Friday deals, free shipping on orders over $35, discounts on gas, free online veterinary care and more. Earlier this year, Walmart+ subscribers got first dibs on the Nintendo Switch 2 at the retailer. You can also use that free shipping to take advantage of Walmart's drone delivery program in a handful of select cities.This article originally appeared on Engadget at https://www.engadget.com/deals/walmart-subscriptions-are-only-49-for-black-friday-and-it-includes-access-to-peacock-192739301.html?src=rss",
          "feed_position": 28
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/how-deductive-ai-saved-doordash-1-000-engineering-hours-by-automating",
          "published_at": "Wed, 12 Nov 2025 14:00:00 GMT",
          "title": "How Deductive AI saved DoorDash 1,000 engineering hours by automating software debugging",
          "standfirst": "As software systems grow more complex and AI tools generate code faster than ever, a fundamental problem is getting worse: Engineers are drowning in debugging work, spending up to half their time hunting down the causes of software failures instead of building new products. The challenge has become so acute that it&#x27;s creating a new category of tooling — AI agents that can diagnose production failures in minutes instead of hours.Deductive AI, a startup emerging from stealth mode Wednesday, believes it has found a solution by applying reinforcement learning — the same technology that powers game-playing AI systems — to the messy, high-stakes world of production software incidents. The company announced it has raised $7.5 million in seed funding led by CRV, with participation from Databricks Ventures, Thomvest Ventures, and PrimeSet, to commercialize what it calls \"AI SRE agents\" that can diagnose and help fix software failures at machine speed.The pitch resonates with a growing frustration inside engineering organizations: Modern observability tools can show that something broke, but they rarely explain why. When a production system fails at 3 a.m., engineers still face hours of manual detective work, cross-referencing logs, metrics, deployment histories, and code changes across dozens of interconnected services to identify the root cause.\"The complexities and inter-dependencies of modern infrastructure means that investigating the root cause of an outage or incident can feel like searching for a needle in a haystack, except the haystack is the size of a football field, it&#x27;s made of a million other needles, it&#x27;s constantly reshuffling itself, and is on fire — and every second you don&#x27;t find it equals lost revenue,\" said Sameer Agarwal, Deductive&#x27;s co-founder and chief technology officer, in an exclusive interview with VentureBeat.Deductive&#x27;s system builds what the company calls a \"knowledge graph\" that maps relationships across codebases, telemetry data, engineering discussions, and internal documentation. When an incident occurs, multiple AI agents work together to form hypotheses, test them against live system evidence, and converge on a root cause — mimicking the investigative workflow of experienced site reliability engineers, but completing the process in minutes rather than hours.The technology has already shown measurable impact at some of the world&#x27;s most demanding production environments. DoorDash&#x27;s advertising platform, which runs real-time auctions that must complete in under 100 milliseconds, has integrated Deductive into its incident response workflow. The company has set an ambitious 2026 goal of resolving production incidents within 10 minutes.\"Our Ads Platform operates at a pace where manual, slow-moving investigations are no longer viable. Every minute of downtime directly affects company revenue,\" said Shahrooz Ansari, Senior Director of Engineering at DoorDash, in an interview with VentureBeat. \"Deductive has become a critical extension of our team, rapidly synthesizing signals across dozens of services and surfacing the insights that matter—within minutes.\"DoorDash estimates that Deductive has root-caused approximately 100 production incidents over the past few months, translating to more than 1,000 hours of annual engineering productivity and a revenue impact \"in millions of dollars,\" according to Ansari. At location intelligence company Foursquare, Deductive reduced the time to diagnose Apache Spark job failures by 90% —t urning a process that previously took hours or days into one that completes in under 10 minutes — while generating over $275,000 in annual savings.Why AI-generated code is creating a debugging crisisThe timing of Deductive&#x27;s launch reflects a brewing tension in software development: AI coding assistants are enabling engineers to generate code faster than ever, but the resulting software is often harder to understand and maintain.\"Vibe coding,\" a term popularized by AI researcher Andrej Karpathy, refers to using natural-language prompts to generate code through AI assistants. While these tools accelerate development, they can introduce what Agarwal describes as \"redundancies, breaks in architectural boundaries, assumptions, or ignored design patterns\" that accumulate over time.\"Most AI-generated code still introduces redundancies, breaks architectural boundaries, makes assumptions, or ignores established design patterns,\" Agarwal told Venturebeat. \"In many ways, we now need AI to help clean up the mess that AI itself is creating.\"The claim that engineers spend roughly half their time on debugging isn&#x27;t hyperbole. The Association for Computing Machinery reports that developers spend 35% to 50% of their time validating and debugging software. More recently, Harness&#x27;s State of Software Delivery 2025 report found that 67% of developers are spending more time debugging AI-generated code.\"We&#x27;ve seen world-class engineers spending half of their time debugging instead of building,\" said Rakesh Kothari, Deductive&#x27;s co-founder and CEO. \"And as vibe coding generates new code at a rate we&#x27;ve never seen, this problem is only going to get worse.\"How Deductive&#x27;s AI agents actually investigate production failuresDeductive&#x27;s technical approach differs substantially from the AI features being added to existing observability platforms like Datadog or New Relic. Most of those systems use large language models to summarize data or identify correlations, but they lack what Agarwal calls \"code-aware reasoning\"—the ability to understand not just that something broke, but why the code behaves the way it does.\"Most enterprises use multiple observability tools across different teams and services, so no vendor has a single holistic view of how their systems behave, fail, and recover—nor are they able to pair that with an understanding of the code that defines system behavior,\" Agarwal explained. \"These are key ingredients to resolving software incidents and it is exactly the gap Deductive fills.\"The system connects to existing infrastructure using read-only API access to observability platforms, code repositories, incident management tools, and chat systems. It then continuously builds and updates its knowledge graph, mapping dependencies between services and tracking deployment histories.When an alert fires, Deductive launches what the company describes as a multi-agent investigation. Different agents specialize in different aspects of the problem: one might analyze recent code changes, another examines trace data, while a third correlates the timing of the incident with recent deployments. The agents share findings and iteratively refine their hypotheses.The critical difference from rule-based automation is Deductive&#x27;s use of reinforcement learning. The system learns from every incident which investigative steps led to correct diagnoses and which were dead ends. When engineers provide feedback, the system incorporates that signal into its learning model.\"Each time it observes an investigation, it learns which steps, data sources, and decisions led to the right outcome,\" Agarwal said. \"It learns how to think through problems, not just point them out.\"At DoorDash, a recent latency spike in an API initially appeared to be an isolated service issue. Deductive&#x27;s investigation revealed that the root cause was actually timeout errors from a downstream machine learning platform undergoing a deployment. The system connected these dots by analyzing log volumes, traces, and deployment metadata across multiple services.\"Without Deductive, our team would have had to manually correlate the latency spike across all logs, traces, and deployment histories,\" Ansari said. \"Deductive was able to explain not just what changed, but how and why it impacted production behavior.\"The company keeps humans in the loop—for nowWhile Deductive&#x27;s technology could theoretically push fixes directly to production systems, the company has deliberately chosen to keep humans in the loop—at least for now.\"While our system is capable of deeper automation and could push fixes to production, currently, we recommend precise fixes and mitigations that engineers can review, validate, and apply,\" Agarwal said. \"We believe maintaining a human in the loop is essential for trust, transparency and operational safety.\"However, he acknowledged that \"over time, we do think that deeper automation will come and how humans operate in the loop will evolve.\"Databricks and ThoughtSpot veterans bet on reasoning over observabilityThe founding team brings deep expertise from building some of Silicon Valley&#x27;s most successful data infrastructure platforms. Agarwal earned his Ph.D. at UC Berkeley, where he created BlinkDB, an influential system for approximate query processing. He was among the first engineers at Databricks, where he helped build Apache Spark. Kothari was an early engineer at ThoughtSpot, where he led teams focused on distributed query processing and large-scale system optimization.The investor syndicate reflects both the technical credibility and market opportunity. Beyond CRV&#x27;s Max Gazor, the round included participation from Ion Stoica, founder of Databricks and Anyscale; Ajeet Singh, founder of Nutanix and ThoughtSpot; and Ben Sigelman, founder of Lightstep.Rather than competing with platforms like Datadog or PagerDuty, Deductive positions itself as a complementary layer that sits on top of existing tools. The pricing model reflects this: Instead of charging based on data volume, Deductive charges based on the number of incidents investigated, plus a base platform fee.The company offers both cloud-hosted and self-hosted deployment options and emphasizes that it doesn&#x27;t store customer data on its servers or use it to train models for other customers — a critical assurance given the proprietary nature of both code and production system behavior.With fresh capital and early customer traction at companies like DoorDash, Foursquare, and Kumo AI, Deductive plans to expand its team and deepen the system&#x27;s reasoning capabilities from reactive incident analysis to proactive prevention. The near-term vision: helping teams predict problems before they occur.DoorDash&#x27;s Ansari offers a pragmatic endorsement of where the technology stands today: \"Investigations that were previously manual and time-consuming are now automated, allowing engineers to shift their energy toward prevention, business impact, and innovation.\"In an industry where every second of downtime translates to lost revenue, that shift from firefighting to building increasingly looks less like a luxury and more like table stakes.",
          "content": "As software systems grow more complex and AI tools generate code faster than ever, a fundamental problem is getting worse: Engineers are drowning in debugging work, spending up to half their time hunting down the causes of software failures instead of building new products. The challenge has become so acute that it&#x27;s creating a new category of tooling — AI agents that can diagnose production failures in minutes instead of hours.Deductive AI, a startup emerging from stealth mode Wednesday, believes it has found a solution by applying reinforcement learning — the same technology that powers game-playing AI systems — to the messy, high-stakes world of production software incidents. The company announced it has raised $7.5 million in seed funding led by CRV, with participation from Databricks Ventures, Thomvest Ventures, and PrimeSet, to commercialize what it calls \"AI SRE agents\" that can diagnose and help fix software failures at machine speed.The pitch resonates with a growing frustration inside engineering organizations: Modern observability tools can show that something broke, but they rarely explain why. When a production system fails at 3 a.m., engineers still face hours of manual detective work, cross-referencing logs, metrics, deployment histories, and code changes across dozens of interconnected services to identify the root cause.\"The complexities and inter-dependencies of modern infrastructure means that investigating the root cause of an outage or incident can feel like searching for a needle in a haystack, except the haystack is the size of a football field, it&#x27;s made of a million other needles, it&#x27;s constantly reshuffling itself, and is on fire — and every second you don&#x27;t find it equals lost revenue,\" said Sameer Agarwal, Deductive&#x27;s co-founder and chief technology officer, in an exclusive interview with VentureBeat.Deductive&#x27;s system builds what the company calls a \"knowledge graph\" that maps relationships across codebases, telemetry data, engineering discussions, and internal documentation. When an incident occurs, multiple AI agents work together to form hypotheses, test them against live system evidence, and converge on a root cause — mimicking the investigative workflow of experienced site reliability engineers, but completing the process in minutes rather than hours.The technology has already shown measurable impact at some of the world&#x27;s most demanding production environments. DoorDash&#x27;s advertising platform, which runs real-time auctions that must complete in under 100 milliseconds, has integrated Deductive into its incident response workflow. The company has set an ambitious 2026 goal of resolving production incidents within 10 minutes.\"Our Ads Platform operates at a pace where manual, slow-moving investigations are no longer viable. Every minute of downtime directly affects company revenue,\" said Shahrooz Ansari, Senior Director of Engineering at DoorDash, in an interview with VentureBeat. \"Deductive has become a critical extension of our team, rapidly synthesizing signals across dozens of services and surfacing the insights that matter—within minutes.\"DoorDash estimates that Deductive has root-caused approximately 100 production incidents over the past few months, translating to more than 1,000 hours of annual engineering productivity and a revenue impact \"in millions of dollars,\" according to Ansari. At location intelligence company Foursquare, Deductive reduced the time to diagnose Apache Spark job failures by 90% —t urning a process that previously took hours or days into one that completes in under 10 minutes — while generating over $275,000 in annual savings.Why AI-generated code is creating a debugging crisisThe timing of Deductive&#x27;s launch reflects a brewing tension in software development: AI coding assistants are enabling engineers to generate code faster than ever, but the resulting software is often harder to understand and maintain.\"Vibe coding,\" a term popularized by AI researcher Andrej Karpathy, refers to using natural-language prompts to generate code through AI assistants. While these tools accelerate development, they can introduce what Agarwal describes as \"redundancies, breaks in architectural boundaries, assumptions, or ignored design patterns\" that accumulate over time.\"Most AI-generated code still introduces redundancies, breaks architectural boundaries, makes assumptions, or ignores established design patterns,\" Agarwal told Venturebeat. \"In many ways, we now need AI to help clean up the mess that AI itself is creating.\"The claim that engineers spend roughly half their time on debugging isn&#x27;t hyperbole. The Association for Computing Machinery reports that developers spend 35% to 50% of their time validating and debugging software. More recently, Harness&#x27;s State of Software Delivery 2025 report found that 67% of developers are spending more time debugging AI-generated code.\"We&#x27;ve seen world-class engineers spending half of their time debugging instead of building,\" said Rakesh Kothari, Deductive&#x27;s co-founder and CEO. \"And as vibe coding generates new code at a rate we&#x27;ve never seen, this problem is only going to get worse.\"How Deductive&#x27;s AI agents actually investigate production failuresDeductive&#x27;s technical approach differs substantially from the AI features being added to existing observability platforms like Datadog or New Relic. Most of those systems use large language models to summarize data or identify correlations, but they lack what Agarwal calls \"code-aware reasoning\"—the ability to understand not just that something broke, but why the code behaves the way it does.\"Most enterprises use multiple observability tools across different teams and services, so no vendor has a single holistic view of how their systems behave, fail, and recover—nor are they able to pair that with an understanding of the code that defines system behavior,\" Agarwal explained. \"These are key ingredients to resolving software incidents and it is exactly the gap Deductive fills.\"The system connects to existing infrastructure using read-only API access to observability platforms, code repositories, incident management tools, and chat systems. It then continuously builds and updates its knowledge graph, mapping dependencies between services and tracking deployment histories.When an alert fires, Deductive launches what the company describes as a multi-agent investigation. Different agents specialize in different aspects of the problem: one might analyze recent code changes, another examines trace data, while a third correlates the timing of the incident with recent deployments. The agents share findings and iteratively refine their hypotheses.The critical difference from rule-based automation is Deductive&#x27;s use of reinforcement learning. The system learns from every incident which investigative steps led to correct diagnoses and which were dead ends. When engineers provide feedback, the system incorporates that signal into its learning model.\"Each time it observes an investigation, it learns which steps, data sources, and decisions led to the right outcome,\" Agarwal said. \"It learns how to think through problems, not just point them out.\"At DoorDash, a recent latency spike in an API initially appeared to be an isolated service issue. Deductive&#x27;s investigation revealed that the root cause was actually timeout errors from a downstream machine learning platform undergoing a deployment. The system connected these dots by analyzing log volumes, traces, and deployment metadata across multiple services.\"Without Deductive, our team would have had to manually correlate the latency spike across all logs, traces, and deployment histories,\" Ansari said. \"Deductive was able to explain not just what changed, but how and why it impacted production behavior.\"The company keeps humans in the loop—for nowWhile Deductive&#x27;s technology could theoretically push fixes directly to production systems, the company has deliberately chosen to keep humans in the loop—at least for now.\"While our system is capable of deeper automation and could push fixes to production, currently, we recommend precise fixes and mitigations that engineers can review, validate, and apply,\" Agarwal said. \"We believe maintaining a human in the loop is essential for trust, transparency and operational safety.\"However, he acknowledged that \"over time, we do think that deeper automation will come and how humans operate in the loop will evolve.\"Databricks and ThoughtSpot veterans bet on reasoning over observabilityThe founding team brings deep expertise from building some of Silicon Valley&#x27;s most successful data infrastructure platforms. Agarwal earned his Ph.D. at UC Berkeley, where he created BlinkDB, an influential system for approximate query processing. He was among the first engineers at Databricks, where he helped build Apache Spark. Kothari was an early engineer at ThoughtSpot, where he led teams focused on distributed query processing and large-scale system optimization.The investor syndicate reflects both the technical credibility and market opportunity. Beyond CRV&#x27;s Max Gazor, the round included participation from Ion Stoica, founder of Databricks and Anyscale; Ajeet Singh, founder of Nutanix and ThoughtSpot; and Ben Sigelman, founder of Lightstep.Rather than competing with platforms like Datadog or PagerDuty, Deductive positions itself as a complementary layer that sits on top of existing tools. The pricing model reflects this: Instead of charging based on data volume, Deductive charges based on the number of incidents investigated, plus a base platform fee.The company offers both cloud-hosted and self-hosted deployment options and emphasizes that it doesn&#x27;t store customer data on its servers or use it to train models for other customers — a critical assurance given the proprietary nature of both code and production system behavior.With fresh capital and early customer traction at companies like DoorDash, Foursquare, and Kumo AI, Deductive plans to expand its team and deepen the system&#x27;s reasoning capabilities from reactive incident analysis to proactive prevention. The near-term vision: helping teams predict problems before they occur.DoorDash&#x27;s Ansari offers a pragmatic endorsement of where the technology stands today: \"Investigations that were previously manual and time-consuming are now automated, allowing engineers to shift their energy toward prevention, business impact, and innovation.\"In an industry where every second of downtime translates to lost revenue, that shift from firefighting to building increasingly looks less like a luxury and more like table stakes.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7mfhEiM01EDWrgDZYpDbte/23713914379b94e43303f9965ccc40ae/nuneybits_Vector_art_of_robot_holding_blueprint_193c9fc5-bbb5-46ea-9ff6-1a08bb03716e.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/music/new-streaming-app-coda-music-is-rolling-out-tools-for-labeling-and-blocking-ai-generated-tunes-140000530.html",
          "published_at": "Wed, 12 Nov 2025 14:00:00 +0000",
          "title": "New streaming app Coda Music is rolling out tools for labeling and blocking AI-generated tunes",
          "standfirst": "At this point, the streaming music landscape feels pretty well settled. Giants like Spotify, Amazon, Apple and YouTube duke it out at the top, while plenty of other players like Qobuz, Tidal, Deezer try their best to stand out from the pack. Somewhat surprisingly, though, a new player emerged in September. Coda Music used the recent backlash around Spotify co-founder Daniel Ek as a way to differentiate itself from the number one streamer, calling out Ek’s controversial funding of defense technology firm Helsing earlier in the year. (Spotify’s refusal to stop airing ICE recruitment ads certainly hasn’t helped the platform, either.)Today, the fledgling service is announcing a new feature that feels designed to answer another of the recent Spotify controversies: AI slop music flooding the platform. In response, Coda Music is launching AI identification tools with the purpose of finding and labeling songs that weren’t composed by actual humans.There are a few prongs to Coda’s approach. For starters, any artist added to Coda will be reviewed for AI origins, and their profile will be labeled “AI Artist” so that listeners know what they’re getting into. Coda is also letting users flag profiles of artists if they suspect the music is AI-generated; the company will then review them and label them if necessary. Finally, there’s a toggle in settings that just lets you turn off AI artists entirely. Obviously, how useful this setting is will depend on how good Coda gets at labeling AI-created music as such, but I can definitely see the appeal in just flipping that to “off” and avoiding as much slop as possible. Besides its stance on AI and the assurance that the company does not “invest in war,” there are a few other differentiators about Coda Music. The company says that it currently paying the “highest per-stream rate” in the industry — while at the same time, it acknowledges that no one is paying enough to artists. “The real problem isn’t how much is paid per stream, it’s that streaming alone doesn’t pay enough,” the company’s website says. “And minor improvements to a fundamentally flawed per stream model will not help.”To that end, the company also lets users pick an “independent or qualifying artist” who gets $1 of their monthly subscription fee. Sure, it’s only a dollar, but it’s the kind of thing that sweetens the pot at least a little bit for musicians. And Coda has good reason to want to make itself visible to users and artists alike. The last major differentiator for Coda is the company’s ambitions to turn its app into a social, music-sharing feed where you get recommendations from humans rather than algorithms. To that end, users can share anything from the app in their feed, and it also allows you to share external links and photos as well (go ahead and post your blurry images from that NIN concert!). The app’s home page prominently features fan-made playlists and recommended users to follow in addition to the usual suggestions based on what you’re listening to already. And there’s a social tab where you can see posts from people you follow; share songs, artists or albums; and see posts from artists you follow. That last part is key, as Coda wants artists interacting and sharing as well as just end users.It reminds me a little bit of the Fan Groups feature that Amazon Music just announced — and as with that feature, the problem facing Coda is getting people to start contributing to a new network rather than just posting things on whatever app they’re already using. Fortunately, music nerds love a community, so it’ll be interesting to see if this takes off at all. As for the new features for reporting and filtering out AI music, Coda says they’re available as of today in its iOS and Android apps. The company doesn’t have a web interface yet, but says it is coming soon. If ducking AI-generated tunes is something that catches your attention, Coda currently costs $11 a month, or $17 per month for a family plan with up to four listeners. This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/new-streaming-app-coda-music-is-rolling-out-tools-for-labeling-and-blocking-ai-generated-tunes-140000530.html?src=rss",
          "content": "At this point, the streaming music landscape feels pretty well settled. Giants like Spotify, Amazon, Apple and YouTube duke it out at the top, while plenty of other players like Qobuz, Tidal, Deezer try their best to stand out from the pack. Somewhat surprisingly, though, a new player emerged in September. Coda Music used the recent backlash around Spotify co-founder Daniel Ek as a way to differentiate itself from the number one streamer, calling out Ek’s controversial funding of defense technology firm Helsing earlier in the year. (Spotify’s refusal to stop airing ICE recruitment ads certainly hasn’t helped the platform, either.)Today, the fledgling service is announcing a new feature that feels designed to answer another of the recent Spotify controversies: AI slop music flooding the platform. In response, Coda Music is launching AI identification tools with the purpose of finding and labeling songs that weren’t composed by actual humans.There are a few prongs to Coda’s approach. For starters, any artist added to Coda will be reviewed for AI origins, and their profile will be labeled “AI Artist” so that listeners know what they’re getting into. Coda is also letting users flag profiles of artists if they suspect the music is AI-generated; the company will then review them and label them if necessary. Finally, there’s a toggle in settings that just lets you turn off AI artists entirely. Obviously, how useful this setting is will depend on how good Coda gets at labeling AI-created music as such, but I can definitely see the appeal in just flipping that to “off” and avoiding as much slop as possible. Besides its stance on AI and the assurance that the company does not “invest in war,” there are a few other differentiators about Coda Music. The company says that it currently paying the “highest per-stream rate” in the industry — while at the same time, it acknowledges that no one is paying enough to artists. “The real problem isn’t how much is paid per stream, it’s that streaming alone doesn’t pay enough,” the company’s website says. “And minor improvements to a fundamentally flawed per stream model will not help.”To that end, the company also lets users pick an “independent or qualifying artist” who gets $1 of their monthly subscription fee. Sure, it’s only a dollar, but it’s the kind of thing that sweetens the pot at least a little bit for musicians. And Coda has good reason to want to make itself visible to users and artists alike. The last major differentiator for Coda is the company’s ambitions to turn its app into a social, music-sharing feed where you get recommendations from humans rather than algorithms. To that end, users can share anything from the app in their feed, and it also allows you to share external links and photos as well (go ahead and post your blurry images from that NIN concert!). The app’s home page prominently features fan-made playlists and recommended users to follow in addition to the usual suggestions based on what you’re listening to already. And there’s a social tab where you can see posts from people you follow; share songs, artists or albums; and see posts from artists you follow. That last part is key, as Coda wants artists interacting and sharing as well as just end users.It reminds me a little bit of the Fan Groups feature that Amazon Music just announced — and as with that feature, the problem facing Coda is getting people to start contributing to a new network rather than just posting things on whatever app they’re already using. Fortunately, music nerds love a community, so it’ll be interesting to see if this takes off at all. As for the new features for reporting and filtering out AI music, Coda says they’re available as of today in its iOS and Android apps. The company doesn’t have a web interface yet, but says it is coming soon. If ducking AI-generated tunes is something that catches your attention, Coda currently costs $11 a month, or $17 per month for a family plan with up to four listeners. This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/new-streaming-app-coda-music-is-rolling-out-tools-for-labeling-and-blocking-ai-generated-tunes-140000530.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/grab-a-pair-of-airpods-4-earbuds-for-only-85-before-black-friday-162917254.html",
          "published_at": "Wed, 12 Nov 2025 13:45:37 +0000",
          "title": "Grab a pair of AirPods 4 earbuds for only $85 before Black Friday",
          "standfirst": "Black Friday Apple deals are already trickling in, and one of the best we're tracking is on the AirPods 4. They're down to $85 right now, which is a new record low. While these buds don't provide active noise cancellation, they're still a great option for those who want all of the conveniences of a pair of Apple earbuds in an affordable package. The Apple AirPods 4 are the best budget AirPods you can get in 2025, with Apple's H2 audio chip to support some of the more advanced audio features from more expensive models. They offer Voice Isolation, Personalized Spatial Audio with dynamic head tracking and more. If you get the model without active noise cancellation, you won't have features like Transparency Mode and Conversation Awareness, or Apple's hearing health tools. But, the entry-level model still offers great sound quality for the price. This model also features the redesigned shape, which makes for a more comfortable and secure fit so you don't have to worry about them falling out of your ears. A force sensor on the stem allows for basic touch controls, including play and pause, play next track, previous track and answer a call. You can also summon Siri by pressing and holding the stem. You can expect to get up to 5 hours of battery life on a charge with the non-ANC model, and up to 30 hours using the USB-C charging case. This article originally appeared on Engadget at https://www.engadget.com/deals/grab-a-pair-of-airpods-4-earbuds-for-only-85-before-black-friday-162917254.html?src=rss",
          "content": "Black Friday Apple deals are already trickling in, and one of the best we're tracking is on the AirPods 4. They're down to $85 right now, which is a new record low. While these buds don't provide active noise cancellation, they're still a great option for those who want all of the conveniences of a pair of Apple earbuds in an affordable package. The Apple AirPods 4 are the best budget AirPods you can get in 2025, with Apple's H2 audio chip to support some of the more advanced audio features from more expensive models. They offer Voice Isolation, Personalized Spatial Audio with dynamic head tracking and more. If you get the model without active noise cancellation, you won't have features like Transparency Mode and Conversation Awareness, or Apple's hearing health tools. But, the entry-level model still offers great sound quality for the price. This model also features the redesigned shape, which makes for a more comfortable and secure fit so you don't have to worry about them falling out of your ears. A force sensor on the stem allows for basic touch controls, including play and pause, play next track, previous track and answer a call. You can also summon Siri by pressing and holding the stem. You can expect to get up to 5 hours of battery life on a charge with the non-ANC model, and up to 30 hours using the USB-C charging case. This article originally appeared on Engadget at https://www.engadget.com/deals/grab-a-pair-of-airpods-4-earbuds-for-only-85-before-black-friday-162917254.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/pick-up-apples-mac-mini-m4-for-100-off-with-this-black-friday-deal-150749841.html",
          "published_at": "Wed, 12 Nov 2025 13:16:27 +0000",
          "title": "Pick up Apple's Mac mini M4 for $100 off with this Black Friday deal",
          "standfirst": "While there are lots of great Black Friday sales on cheaper devices, it's the big ticket items that really make a world of difference. Take Apple's 2024 Mac mini M4, which has dropped to $499 from $599 as part of early Black Friday deals. The 17 percent discount brings Apple's mini desktop computer with 16GB of RAM and 256GB of SSD to only $30 more than its all-time low. We gave the Mac mini M4 a 90 in our review, in part, because it packs an incredible amount of power into such a small design. It also has front facing USB-C and headphone ports, a first for the Mac mini lineup. Plus, it starts with 16GB of RAM, an upgrade from its predecessors. However, if you want more memory or storage, the other Mac Mini M4 models are also on sale. You can get 16GB of RAM and 512GB of SSD for $690, down from $799. Then there's the option for 24GB of RAM and 512GB of SSD at $890, down from $999. Plus, if you want to bundle in three years of AppleCare+, each model ends up being about $100 cheaper than normal. If you're looking to build a desktop setup from scratch, there's a small but notable discount on Apple's Magic Trackpad as well. It's down to $120, which is only seven percent off its usual price but it's the cheapest we've seen it. This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-apples-mac-mini-m4-for-100-off-with-this-black-friday-deal-150749841.html?src=rss",
          "content": "While there are lots of great Black Friday sales on cheaper devices, it's the big ticket items that really make a world of difference. Take Apple's 2024 Mac mini M4, which has dropped to $499 from $599 as part of early Black Friday deals. The 17 percent discount brings Apple's mini desktop computer with 16GB of RAM and 256GB of SSD to only $30 more than its all-time low. We gave the Mac mini M4 a 90 in our review, in part, because it packs an incredible amount of power into such a small design. It also has front facing USB-C and headphone ports, a first for the Mac mini lineup. Plus, it starts with 16GB of RAM, an upgrade from its predecessors. However, if you want more memory or storage, the other Mac Mini M4 models are also on sale. You can get 16GB of RAM and 512GB of SSD for $690, down from $799. Then there's the option for 24GB of RAM and 512GB of SSD at $890, down from $999. Plus, if you want to bundle in three years of AppleCare+, each model ends up being about $100 cheaper than normal. If you're looking to build a desktop setup from scratch, there's a small but notable discount on Apple's Magic Trackpad as well. It's down to $120, which is only seven percent off its usual price but it's the cheapest we've seen it. This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-apples-mac-mini-m4-for-100-off-with-this-black-friday-deal-150749841.html?src=rss",
          "feed_position": 32
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/our-favorite-streaming-device-drops-to-a-record-low-ahead-of-black-friday-173858910.html",
          "published_at": "Wed, 12 Nov 2025 12:59:04 +0000",
          "title": "Our favorite streaming device drops to a record low ahead of Black Friday",
          "standfirst": "If you'd rather not spend the money on a brand new TV this year, you can make an old set feel new again with a streaming device. Our favorite streaming device is on sale right now ahead of Black Friday: you can grab the Google TV Streamer 4K for only $75, which is the lowest price we've seen so far. The Google TV Streamer is our top pick for an all-in-one streaming device. It has a faster processor than Google's previous streaming devices (22 percent faster, according to the company), so you can switch between apps and different media without lagging. It also has more storage and memory, at 32GB and 4GB, respectively. Google TV streamer has an intuitive interface and keeps all of your favorite content from different streaming apps organized in one menu. It also seamlessly integrates Google Home, allowing you to control your smart home devices from a slideout panel on the TV. The 4K streamer comes in a set-top wedge design, rather than the dongle of Chromecasts past, but you'll have to pick up an HDMI cable separately if you don't already have one you can use. It comes with a small remote that you can ping by pressing a button on the streamer for when you inevitably misplace it. In her review of the device, Engadget's Amy Skorheim called the Google TV streamer \"a full-featured, competent device with an interface that’s better than most at pulling together all the disparate threads of a streaming experience.\" One of its only downsides is the relatively high cost at $100, so don't let this deal go to waste. In addition to the streaming device, Google has a bunch of other tech on sale for Black Friday. The entry-level Nest thermostat is on sale for $90 right now, and the Nest Wi-Fi Pro 6E router has dropped to $120 for a single-pack; that's 40 percent off. This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-streaming-device-drops-to-a-record-low-ahead-of-black-friday-173858910.html?src=rss",
          "content": "If you'd rather not spend the money on a brand new TV this year, you can make an old set feel new again with a streaming device. Our favorite streaming device is on sale right now ahead of Black Friday: you can grab the Google TV Streamer 4K for only $75, which is the lowest price we've seen so far. The Google TV Streamer is our top pick for an all-in-one streaming device. It has a faster processor than Google's previous streaming devices (22 percent faster, according to the company), so you can switch between apps and different media without lagging. It also has more storage and memory, at 32GB and 4GB, respectively. Google TV streamer has an intuitive interface and keeps all of your favorite content from different streaming apps organized in one menu. It also seamlessly integrates Google Home, allowing you to control your smart home devices from a slideout panel on the TV. The 4K streamer comes in a set-top wedge design, rather than the dongle of Chromecasts past, but you'll have to pick up an HDMI cable separately if you don't already have one you can use. It comes with a small remote that you can ping by pressing a button on the streamer for when you inevitably misplace it. In her review of the device, Engadget's Amy Skorheim called the Google TV streamer \"a full-featured, competent device with an interface that’s better than most at pulling together all the disparate threads of a streaming experience.\" One of its only downsides is the relatively high cost at $100, so don't let this deal go to waste. In addition to the streaming device, Google has a bunch of other tech on sale for Black Friday. The entry-level Nest thermostat is on sale for $90 right now, and the Nest Wi-Fi Pro 6E router has dropped to $120 for a single-pack; that's 40 percent off. This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-streaming-device-drops-to-a-record-low-ahead-of-black-friday-173858910.html?src=rss",
          "feed_position": 35
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/openai-reboots-chatgpt-experience-with-gpt-5-1-after-mixed-reviews-of-gpt-5",
          "published_at": "Wed, 12 Nov 2025 05:00:00 GMT",
          "title": "OpenAI reboots ChatGPT experience with GPT-5.1 after mixed reviews of GPT-5",
          "standfirst": "ChatGPT is about to become faster and more conversational as OpenAI upgrades its flagship model GPT-5 to GPT-5.1.OpenAI announced two updates to the GPT-5 series: GPT-5.1 Instant and GPT-5.1 Thinking. Both models are now accessible on ChatGPT. GPT-5.1 Instant, essentially the default and most-used model, is now “warmer, more intelligent, and better at following your instructions,” according to OpenAI. Meanwhile, GPT-5.1 Thinking is an advanced reasoning model that responds faster for simple tasks and more persistently on complex ones.“We heard clearly from users that great AI should not only be smart, but also enjoyable to talk to,” OpenAI said in a blog post. “GPT-5.1 improves meaningfully on both intelligence and communication style.” The company added that both models offer a way for users to “shape ChatGPT’s tone,” allowing people to control how the chat platform responds depending on the conversation they are having. Both models were rolled out to ChatGPT Pro, Plus, Go and Business users, as well as the free tier. Those on the Enterprise and Edu plans will get a seven-day early-access toggle for the models before GPT-5.1 becomes the default model. OpenAI said the models can also be accessible through the API, both with adapted reasoning. OpenAI has noted that it will soon update GPT-5 Pro to version 5.1. Instant and Thinking models The 5.1 tag reflects improvements to the base model, and OpenAI considers these part of the GPT-5 family, trained on the same stack and data as its reasoning models. The biggest difference between 5.1 and 5 is its more natural and conversational tone, OpenAI CEO for Applications Fidji Simo said in a Substack post. “Based on early testing, it often surprises people with its playfulness while remaining clear and useful,” OpenAI said in its post. Instant can use adaptive reasoning to help it decide when it needs to think about its answers, especially when it comes to more complicated questions. OpenAI noted that it has improved the model&#x27;s instruction following, so that while it continues to respond quickly, it also directly addresses the user’s query. Recent model releases, such as Baidu’s ERNIE-4.5-VL-28B-A3B-Thinking, have been outperforming GPT-5 in benchmarks like instruction-following. GPT-5.1 Thinking can figure out on its own how much reasoning power it should devote to a prompt. It adapts to the type and complexity of a query, so it will take longer to answer a fuller, complex question than a simple summary request. OpenAI said evaluations showed that GPT-5.1 Thinking spends less time and therefore uses fewer tokens on simple tasks compared to GPT-5, outperforming the base model in speed of response. One thing enterprises should note is that GPT-5.1 Thinking answers “with less jargon and fewer undefined terms.” OpenAI said removing jargony responses makes Thinking more approachable when it comes to explaining technical concepts.More personalizationAnother big update to ChatGPT is increased personalization. This allows users to toggle between a friendly and authoritative chat platform experience in their conversations. ChatGPT already allows users to choose preset options for model tone, but the new update expands these options “to better reflect the most common ways people use ChatGPT.”Options include \"default,\" \"friendly\" (formerly \"listener\"), \"efficient\" (previously \"robot\"), \"professional,\" \"candid\" and \"quirky.\" Two other personalities, \"cynical\" and \"nerdy,\" remain unchanged. “We think many people will find that GPT-5.1 does a better job of bringing IQ and EQ together, but one default clearly can’t meet everyone’s needs,\" Simo said. \"That’s why we’re also making it easier to customize ChatGPT with a range of presets to choose from. The model has the same capabilities whether you select default or one of these options, but the style of its responses will differ — more formal or familiar, more playful or direct, more or less jargon or slang. Of course, eight personalities still don&#x27;t cover the full range of human diversity, but we know from our research that many people prefer simple, guided control over too many settings or open-ended options.\"People can also adjust how much ChatGPT uses emojis. OpenAI offers granular controls for responses and is experimenting with the ability to make the models more concise, warm or scannable.Saving a rolloutOpenAI’s GPT-5 rollout was…less than perfect. While company executives, including CEO Sam Altman, touted the new model’s capabilities, a decision to initially sunset older and beloved models on ChatGPT was met with dissatisfaction. Worse yet, many early adopters found that GPT-5 didn’t perform better than older options in domains such as math, science and writing. This led Altman to walk back some of his statements around model removal, blaming performance issues on GPT-5’s router. The router, which automatically directs queries to the most suited models, is not going away, as GPT-5.1 Auto will route prompts to the model type that can best answer queries. OpenAI is careful to note that GPT-5 models Instant, Thinking and Pro are still available in ChatGPT’s model dropdown, although paid subscribers only have three months to compare these older versions with the 5.1 update. The sunset period for GPT-5, however, will not impact models like GPT-4o.“Going forward, when we introduce new ChatGPT models, our approach is to give people ample space to evaluate what’s changed and share feedback, allowing us to continue innovating our frontier models while transitioning smoothly,” the company said. “Sunset periods will be communicated clearly and with plenty of advance notice.”",
          "content": "ChatGPT is about to become faster and more conversational as OpenAI upgrades its flagship model GPT-5 to GPT-5.1.OpenAI announced two updates to the GPT-5 series: GPT-5.1 Instant and GPT-5.1 Thinking. Both models are now accessible on ChatGPT. GPT-5.1 Instant, essentially the default and most-used model, is now “warmer, more intelligent, and better at following your instructions,” according to OpenAI. Meanwhile, GPT-5.1 Thinking is an advanced reasoning model that responds faster for simple tasks and more persistently on complex ones.“We heard clearly from users that great AI should not only be smart, but also enjoyable to talk to,” OpenAI said in a blog post. “GPT-5.1 improves meaningfully on both intelligence and communication style.” The company added that both models offer a way for users to “shape ChatGPT’s tone,” allowing people to control how the chat platform responds depending on the conversation they are having. Both models were rolled out to ChatGPT Pro, Plus, Go and Business users, as well as the free tier. Those on the Enterprise and Edu plans will get a seven-day early-access toggle for the models before GPT-5.1 becomes the default model. OpenAI said the models can also be accessible through the API, both with adapted reasoning. OpenAI has noted that it will soon update GPT-5 Pro to version 5.1. Instant and Thinking models The 5.1 tag reflects improvements to the base model, and OpenAI considers these part of the GPT-5 family, trained on the same stack and data as its reasoning models. The biggest difference between 5.1 and 5 is its more natural and conversational tone, OpenAI CEO for Applications Fidji Simo said in a Substack post. “Based on early testing, it often surprises people with its playfulness while remaining clear and useful,” OpenAI said in its post. Instant can use adaptive reasoning to help it decide when it needs to think about its answers, especially when it comes to more complicated questions. OpenAI noted that it has improved the model&#x27;s instruction following, so that while it continues to respond quickly, it also directly addresses the user’s query. Recent model releases, such as Baidu’s ERNIE-4.5-VL-28B-A3B-Thinking, have been outperforming GPT-5 in benchmarks like instruction-following. GPT-5.1 Thinking can figure out on its own how much reasoning power it should devote to a prompt. It adapts to the type and complexity of a query, so it will take longer to answer a fuller, complex question than a simple summary request. OpenAI said evaluations showed that GPT-5.1 Thinking spends less time and therefore uses fewer tokens on simple tasks compared to GPT-5, outperforming the base model in speed of response. One thing enterprises should note is that GPT-5.1 Thinking answers “with less jargon and fewer undefined terms.” OpenAI said removing jargony responses makes Thinking more approachable when it comes to explaining technical concepts.More personalizationAnother big update to ChatGPT is increased personalization. This allows users to toggle between a friendly and authoritative chat platform experience in their conversations. ChatGPT already allows users to choose preset options for model tone, but the new update expands these options “to better reflect the most common ways people use ChatGPT.”Options include \"default,\" \"friendly\" (formerly \"listener\"), \"efficient\" (previously \"robot\"), \"professional,\" \"candid\" and \"quirky.\" Two other personalities, \"cynical\" and \"nerdy,\" remain unchanged. “We think many people will find that GPT-5.1 does a better job of bringing IQ and EQ together, but one default clearly can’t meet everyone’s needs,\" Simo said. \"That’s why we’re also making it easier to customize ChatGPT with a range of presets to choose from. The model has the same capabilities whether you select default or one of these options, but the style of its responses will differ — more formal or familiar, more playful or direct, more or less jargon or slang. Of course, eight personalities still don&#x27;t cover the full range of human diversity, but we know from our research that many people prefer simple, guided control over too many settings or open-ended options.\"People can also adjust how much ChatGPT uses emojis. OpenAI offers granular controls for responses and is experimenting with the ability to make the models more concise, warm or scannable.Saving a rolloutOpenAI’s GPT-5 rollout was…less than perfect. While company executives, including CEO Sam Altman, touted the new model’s capabilities, a decision to initially sunset older and beloved models on ChatGPT was met with dissatisfaction. Worse yet, many early adopters found that GPT-5 didn’t perform better than older options in domains such as math, science and writing. This led Altman to walk back some of his statements around model removal, blaming performance issues on GPT-5’s router. The router, which automatically directs queries to the most suited models, is not going away, as GPT-5.1 Auto will route prompts to the model type that can best answer queries. OpenAI is careful to note that GPT-5 models Instant, Thinking and Pro are still available in ChatGPT’s model dropdown, although paid subscribers only have three months to compare these older versions with the 5.1 update. The sunset period for GPT-5, however, will not impact models like GPT-4o.“Going forward, when we introduce new ChatGPT models, our approach is to give people ample space to evaluate what’s changed and share feedback, allowing us to continue innovating our frontier models while transitioning smoothly,” the company said. “Sunset periods will be communicated clearly and with plenty of advance notice.”",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3CpLfvpU0TfycKYEA3DBLw/f7dc8b8d4db1e3eef3d0b619d662879e/crimedy7_illustration_of_a_conversation_abstract_--ar_169_--v_5a880096-9873-4985-85ae-e8c247d831fc_0.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/baidu-just-dropped-an-open-source-multimodal-ai-that-it-claims-beats-gpt-5",
          "published_at": "Wed, 12 Nov 2025 00:00:00 GMT",
          "title": "Baidu just dropped an open-source multimodal AI that it claims beats GPT-5 and Gemini",
          "standfirst": "Baidu Inc., China&#x27;s largest search engine company, released a new artificial intelligence model on Monday that its developers claim outperforms competitors from Google and OpenAI on several vision-related benchmarks despite using a fraction of the computing resources typically required for such systems.The model, dubbed ERNIE-4.5-VL-28B-A3B-Thinking, is the latest salvo in an escalating competition among technology companies to build AI systems that can understand and reason about images, videos, and documents alongside traditional text — capabilities increasingly critical for enterprise applications ranging from automated document processing to industrial quality control.What sets Baidu&#x27;s release apart is its efficiency: the model activates just 3 billion parameters during operation while maintaining 28 billion total parameters through a sophisticated routing architecture. According to documentation released with the model, this design allows it to match or exceed the performance of much larger competing systems on tasks involving document understanding, chart analysis, and visual reasoning while consuming significantly less computational power and memory.\"Built upon the powerful ERNIE-4.5-VL-28B-A3B architecture, the newly upgraded ERNIE-4.5-VL-28B-A3B-Thinking achieves a remarkable leap forward in multimodal reasoning capabilities,\" Baidu wrote in the model&#x27;s technical documentation on Hugging Face, the AI model repository where the system was released.The company said the model underwent \"an extensive mid-training phase\" that incorporated \"a vast and highly diverse corpus of premium visual-language reasoning data,\" dramatically boosting its ability to align visual and textual information semantically.How the model mimics human visual problem-solving through dynamic image analysisPerhaps the model&#x27;s most distinctive feature is what Baidu calls \"Thinking with Images\" — a capability that allows the AI to dynamically zoom in and out of images to examine fine-grained details, mimicking how humans approach visual problem-solving tasks.\"The model thinks like a human, capable of freely zooming in and out of images to grasp every detail and uncover all information,\" according to the model card. When paired with tools like image search, Baidu claims this feature \"dramatically elevates the model&#x27;s ability to process fine-grained details and handle long-tail visual knowledge.\"This approach marks a departure from traditional vision-language models, which typically process images at a fixed resolution. By allowing dynamic image examination, the system can theoretically handle scenarios requiring both broad context and granular detail—such as analyzing complex technical diagrams or detecting subtle defects in manufacturing quality control.The model also supports what Baidu describes as enhanced \"visual grounding\" capabilities with \"more precise grounding and flexible instruction execution, easily triggering grounding functions in complex industrial scenarios,\" suggesting potential applications in robotics, warehouse automation, and other settings where AI systems must identify and locate specific objects in visual scenes.Baidu&#x27;s performance claims draw scrutiny as independent testing remains pendingBaidu&#x27;s assertion that the model outperforms Google&#x27;s Gemini 2.5 Pro and OpenAI&#x27;s GPT-5-High on various document and chart understanding benchmarks has drawn attention across social media, though independent verification of these claims remains pending.The company released the model under the permissive Apache 2.0 license, allowing unrestricted commercial use—a strategic decision that contrasts with the more restrictive licensing approaches of some competitors and could accelerate enterprise adoption.\"Apache 2.0 is smart,\" wrote one X user responding to Baidu&#x27;s announcement, highlighting the competitive advantage of open licensing in the enterprise market.According to Baidu&#x27;s documentation, the model demonstrates six core capabilities beyond traditional text processing. In visual reasoning, the system can perform what Baidu describes as \"multi-step reasoning, chart analysis, and causal reasoning capabilities in complex visual tasks,\" aided by what the company characterizes as \"large-scale reinforcement learning.\" For STEM problem solving, Baidu claims that \"leveraging its powerful visual abilities, the model achieves a leap in performance on STEM tasks like solving problems from photos.\" The visual grounding capability allows the model to identify and locate objects within images with what Baidu characterizes as industrial-grade precision. Through tool integration, the system can invoke external functions including image search capabilities to access information beyond its training data.For video understanding, Baidu claims the model possesses \"outstanding temporal awareness and event localization abilities, accurately identifying content changes across different time segments in a video.\" Finally, the thinking with images feature enables the dynamic zoom functionality that distinguishes this model from competitors.Inside the mixture-of-experts architecture that powers efficient multimodal processingUnder the hood, ERNIE-4.5-VL-28B-A3B-Thinking employs a Mixture-of-Experts (MoE) architecture — a design pattern that has become increasingly popular for building efficient large-scale AI systems. Rather than activating all 28 billion parameters for every task, the model uses a routing mechanism to selectively activate only the 3 billion parameters most relevant to each specific input.This approach offers substantial practical advantages for enterprise deployments. According to Baidu&#x27;s documentation, the model can run on a single 80GB GPU — hardware readily available in many corporate data centers — making it significantly more accessible than competing systems that may require multiple high-end accelerators.The technical documentation reveals that Baidu employed several advanced training techniques to achieve the model&#x27;s capabilities. The company used \"cutting-edge multimodal reinforcement learning techniques on verifiable tasks, integrating GSPO and IcePop strategies to stabilize MoE training combined with dynamic difficulty sampling for exceptional learning efficiency.\"Baidu also notes that in response to \"strong community demand,\" the company \"significantly strengthened the model&#x27;s grounding performance with improved instruction-following capabilities.\"The new model fits into Baidu&#x27;s ambitious multimodal AI ecosystemThe new release is one component of Baidu&#x27;s broader ERNIE 4.5 model family, which the company unveiled in June 2025. That family comprises 10 distinct variants, including Mixture-of-Experts models ranging from the flagship ERNIE-4.5-VL-424B-A47B with 424 billion total parameters down to a compact 0.3 billion parameter dense model.According to Baidu&#x27;s technical report on the ERNIE 4.5 family, the models incorporate \"a novel heterogeneous modality structure, which supports parameter sharing across modalities while also allowing dedicated parameters for each individual modality.\"This architectural choice addresses a longstanding challenge in multimodal AI development: training systems on both visual and textual data without one modality degrading the performance of the other. Baidu claims this design \"has the advantage to enhance multimodal understanding without compromising, and even improving, performance on text-related tasks.\"The company reported achieving 47% Model FLOPs Utilization (MFU) — a measure of training efficiency — during pre-training of its largest ERNIE 4.5 language model, using the PaddlePaddle deep learning framework developed in-house.Comprehensive developer tools aim to simplify enterprise deployment and integrationFor organizations looking to deploy the model, Baidu has released a comprehensive suite of development tools through ERNIEKit, what the company describes as an \"industrial-grade training and compression development toolkit.\"The model offers full compatibility with popular open-source frameworks including Hugging Face Transformers, vLLM (a high-performance inference engine), and Baidu&#x27;s own FastDeploy toolkit. This multi-platform support could prove critical for enterprise adoption, allowing organizations to integrate the model into existing AI infrastructure without wholesale platform changes.Sample code released by Baidu shows a relatively straightforward implementation path. Using the Transformers library, developers can load and run the model with approximately 30 lines of Python code, according to the documentation on Hugging Face.For production deployments requiring higher throughput, Baidu provides vLLM integration with specialized support for the model&#x27;s \"reasoning-parser\" and \"tool-call-parser\" capabilities — features that enable the dynamic image examination and external tool integration that distinguish this model from earlier systems.The company also offers FastDeploy, a proprietary inference toolkit that Baidu claims delivers \"production-ready, easy-to-use multi-hardware deployment solutions\" with support for various quantization schemes that can reduce memory requirements and increase inference speed.Why this release matters for the enterprise AI market at a critical inflection pointThe release comes at a pivotal moment in the enterprise AI market. As organizations move beyond experimental chatbot deployments toward production systems that process documents, analyze visual data, and automate complex workflows, demand for capable and cost-effective vision-language models has intensified.Several enterprise use cases appear particularly well-suited to the model&#x27;s capabilities. Document processing — extracting information from invoices, contracts, and forms — represents a massive market where accurate chart and table understanding directly translates to cost savings through automation. Manufacturing quality control, where AI systems must detect visual defects, could benefit from the model&#x27;s grounding capabilities. Customer service applications that handle images from users could leverage the multi-step visual reasoning.The model&#x27;s efficiency profile may prove especially attractive to mid-market organizations and startups that lack the computing budgets of large technology companies. By fitting on a single 80GB GPU — hardware costing roughly $10,000 to $30,000 depending on the specific model — the system becomes economically viable for a much broader range of organizations than models requiring multi-GPU setups costing hundreds of thousands of dollars.\"With all these new models, where&#x27;s the best place to actually build and scale? Access to compute is everything,\" wrote one X user in response to Baidu&#x27;s announcement, highlighting the persistent infrastructure challenges facing organizations attempting to deploy advanced AI systems.The Apache 2.0 licensing further lowers barriers to adoption. Unlike models released under more restrictive licenses that may limit commercial use or require revenue sharing, organizations can deploy ERNIE-4.5-VL-28B-A3B-Thinking in production applications without ongoing licensing fees or usage restrictions.Competition intensifies as Chinese tech giant takes aim at Google and OpenAIBaidu&#x27;s release intensifies competition in the vision-language model space, where Google, OpenAI, Anthropic, and Chinese companies including Alibaba and ByteDance have all released capable systems in recent months.The company&#x27;s performance claims — if validated by independent testing — would represent a significant achievement. Google&#x27;s Gemini 2.5 Pro and OpenAI&#x27;s GPT-5-High are substantially larger models backed by the deep resources of two of the world&#x27;s most valuable technology companies. That a more compact, openly available model could match or exceed their performance on specific tasks would suggest the field is advancing more rapidly than some analysts anticipated.\"Impressive that ERNIE is outperforming Gemini 2.5 Pro,\" wrote one social media commenter, expressing surprise at the claimed results.However, some observers counseled caution about benchmark comparisons. \"It&#x27;s fascinating to see how multimodal models are evolving, especially with features like &#x27;Thinking with Images,&#x27;\" wrote one X user. \"That said, I&#x27;m curious if ERNIE-4.5&#x27;s edge over competitors like Gemini-2.5-Pro and GPT-5-High primarily lies in specific use cases like document and chart\" understanding rather than general-purpose vision tasks.Industry analysts note that benchmark performance often fails to capture real-world behavior across the diverse scenarios enterprises encounter. A model that excels at document understanding may struggle with creative visual tasks or real-time video analysis. Organizations evaluating these systems typically conduct extensive internal testing on representative workloads before committing to production deployments.Technical limitations and infrastructure requirements that enterprises must considerDespite its capabilities, the model faces several technical challenges common to large vision-language systems. The minimum requirement of 80GB of GPU memory, while more accessible than some competitors, still represents a significant infrastructure investment. Organizations without existing GPU infrastructure would need to procure specialized hardware or rely on cloud computing services, introducing ongoing operational costs.The model&#x27;s context window — the amount of text and visual information it can process simultaneously — is listed as 128K tokens in Baidu&#x27;s documentation. While substantial, this may prove limiting for some document processing scenarios involving very long technical manuals or extensive video content.Questions also remain about the model&#x27;s behavior on adversarial inputs, out-of-distribution data, and edge cases. Baidu&#x27;s documentation does not provide detailed information about safety testing, bias mitigation, or failure modes — considerations increasingly important for enterprise deployments where errors could have financial or safety implications.What technical decision-makers need to evaluate beyond the benchmark numbersFor technical decision-makers evaluating the model, several implementation factors warrant consideration beyond raw performance metrics.The model&#x27;s MoE architecture, while efficient during inference, adds complexity to deployment and optimization. Organizations must ensure their infrastructure can properly route inputs to the appropriate expert subnetworks — a capability not universally supported across all deployment platforms.The \"Thinking with Images\" feature, while innovative, requires integration with image manipulation tools to achieve its full potential. Baidu&#x27;s documentation suggests this capability works best \"when paired with tools like image zooming and image search,\" implying that organizations may need to build additional infrastructure to fully leverage this functionality.The model&#x27;s video understanding capabilities, while highlighted in marketing materials, come with practical constraints. Processing video requires substantially more computational resources than static images, and the documentation does not specify maximum video length or optimal frame rates.Organizations considering deployment should also evaluate Baidu&#x27;s ongoing commitment to the model. Open-source AI models require continuing maintenance, security updates, and potential retraining as data distributions shift over time. While the Apache 2.0 license ensures the model remains available, future improvements and support depend on Baidu&#x27;s strategic priorities.Developer community responds with enthusiasm tempered by practical requestsEarly response from the AI research and development community has been cautiously optimistic. Developers have requested versions of the model in additional formats including GGUF (a quantization format popular for local deployment) and MNN (a mobile neural network framework), suggesting interest in running the system on resource-constrained devices.\"Release MNN and GGUF so I can run it on my phone,\" wrote one developer, highlighting demand for mobile deployment options.Other developers praised Baidu&#x27;s technical choices while requesting additional resources. \"Fantastic model! Did you use discoveries from PaddleOCR?\" asked one user, referencing Baidu&#x27;s open-source optical character recognition toolkit.The model&#x27;s lengthy name—ERNIE-4.5-VL-28B-A3B-Thinking—drew lighthearted commentary. \"ERNIE-4.5-VL-28B-A3B-Thinking might be the longest model name in history,\" joked one observer. \"But hey, if you&#x27;re outperforming Gemini-2.5-Pro with only 3B active params, you&#x27;ve earned the right to a dramatic name!\"Baidu plans to showcase the ERNIE lineup during its Baidu World 2025 conference on November 13, where the company is expected to provide additional details about the model&#x27;s development, performance validation, and future roadmap.The release marks a strategic move by Baidu to establish itself as a major player in the global AI infrastructure market. While Chinese AI companies have historically focused primarily on domestic markets, the open-source release under a permissive license signals ambitions to compete internationally with Western AI giants.For enterprises, the release adds another capable option to a rapidly expanding menu of AI models. Organizations no longer face a binary choice between building proprietary systems or licensing closed-source models from a handful of vendors. The proliferation of capable open-source alternatives like ERNIE-4.5-VL-28B-A3B-Thinking is reshaping the economics of AI deployment and accelerating adoption across industries.Whether the model delivers on its performance promises in real-world deployments remains to be seen. But for organizations seeking powerful, cost-effective tools for visual understanding and reasoning, one thing is certain. As one developer succinctly summarized: \"Open source plus commercial use equals chef&#x27;s kiss. Baidu not playing around.\"",
          "content": "Baidu Inc., China&#x27;s largest search engine company, released a new artificial intelligence model on Monday that its developers claim outperforms competitors from Google and OpenAI on several vision-related benchmarks despite using a fraction of the computing resources typically required for such systems.The model, dubbed ERNIE-4.5-VL-28B-A3B-Thinking, is the latest salvo in an escalating competition among technology companies to build AI systems that can understand and reason about images, videos, and documents alongside traditional text — capabilities increasingly critical for enterprise applications ranging from automated document processing to industrial quality control.What sets Baidu&#x27;s release apart is its efficiency: the model activates just 3 billion parameters during operation while maintaining 28 billion total parameters through a sophisticated routing architecture. According to documentation released with the model, this design allows it to match or exceed the performance of much larger competing systems on tasks involving document understanding, chart analysis, and visual reasoning while consuming significantly less computational power and memory.\"Built upon the powerful ERNIE-4.5-VL-28B-A3B architecture, the newly upgraded ERNIE-4.5-VL-28B-A3B-Thinking achieves a remarkable leap forward in multimodal reasoning capabilities,\" Baidu wrote in the model&#x27;s technical documentation on Hugging Face, the AI model repository where the system was released.The company said the model underwent \"an extensive mid-training phase\" that incorporated \"a vast and highly diverse corpus of premium visual-language reasoning data,\" dramatically boosting its ability to align visual and textual information semantically.How the model mimics human visual problem-solving through dynamic image analysisPerhaps the model&#x27;s most distinctive feature is what Baidu calls \"Thinking with Images\" — a capability that allows the AI to dynamically zoom in and out of images to examine fine-grained details, mimicking how humans approach visual problem-solving tasks.\"The model thinks like a human, capable of freely zooming in and out of images to grasp every detail and uncover all information,\" according to the model card. When paired with tools like image search, Baidu claims this feature \"dramatically elevates the model&#x27;s ability to process fine-grained details and handle long-tail visual knowledge.\"This approach marks a departure from traditional vision-language models, which typically process images at a fixed resolution. By allowing dynamic image examination, the system can theoretically handle scenarios requiring both broad context and granular detail—such as analyzing complex technical diagrams or detecting subtle defects in manufacturing quality control.The model also supports what Baidu describes as enhanced \"visual grounding\" capabilities with \"more precise grounding and flexible instruction execution, easily triggering grounding functions in complex industrial scenarios,\" suggesting potential applications in robotics, warehouse automation, and other settings where AI systems must identify and locate specific objects in visual scenes.Baidu&#x27;s performance claims draw scrutiny as independent testing remains pendingBaidu&#x27;s assertion that the model outperforms Google&#x27;s Gemini 2.5 Pro and OpenAI&#x27;s GPT-5-High on various document and chart understanding benchmarks has drawn attention across social media, though independent verification of these claims remains pending.The company released the model under the permissive Apache 2.0 license, allowing unrestricted commercial use—a strategic decision that contrasts with the more restrictive licensing approaches of some competitors and could accelerate enterprise adoption.\"Apache 2.0 is smart,\" wrote one X user responding to Baidu&#x27;s announcement, highlighting the competitive advantage of open licensing in the enterprise market.According to Baidu&#x27;s documentation, the model demonstrates six core capabilities beyond traditional text processing. In visual reasoning, the system can perform what Baidu describes as \"multi-step reasoning, chart analysis, and causal reasoning capabilities in complex visual tasks,\" aided by what the company characterizes as \"large-scale reinforcement learning.\" For STEM problem solving, Baidu claims that \"leveraging its powerful visual abilities, the model achieves a leap in performance on STEM tasks like solving problems from photos.\" The visual grounding capability allows the model to identify and locate objects within images with what Baidu characterizes as industrial-grade precision. Through tool integration, the system can invoke external functions including image search capabilities to access information beyond its training data.For video understanding, Baidu claims the model possesses \"outstanding temporal awareness and event localization abilities, accurately identifying content changes across different time segments in a video.\" Finally, the thinking with images feature enables the dynamic zoom functionality that distinguishes this model from competitors.Inside the mixture-of-experts architecture that powers efficient multimodal processingUnder the hood, ERNIE-4.5-VL-28B-A3B-Thinking employs a Mixture-of-Experts (MoE) architecture — a design pattern that has become increasingly popular for building efficient large-scale AI systems. Rather than activating all 28 billion parameters for every task, the model uses a routing mechanism to selectively activate only the 3 billion parameters most relevant to each specific input.This approach offers substantial practical advantages for enterprise deployments. According to Baidu&#x27;s documentation, the model can run on a single 80GB GPU — hardware readily available in many corporate data centers — making it significantly more accessible than competing systems that may require multiple high-end accelerators.The technical documentation reveals that Baidu employed several advanced training techniques to achieve the model&#x27;s capabilities. The company used \"cutting-edge multimodal reinforcement learning techniques on verifiable tasks, integrating GSPO and IcePop strategies to stabilize MoE training combined with dynamic difficulty sampling for exceptional learning efficiency.\"Baidu also notes that in response to \"strong community demand,\" the company \"significantly strengthened the model&#x27;s grounding performance with improved instruction-following capabilities.\"The new model fits into Baidu&#x27;s ambitious multimodal AI ecosystemThe new release is one component of Baidu&#x27;s broader ERNIE 4.5 model family, which the company unveiled in June 2025. That family comprises 10 distinct variants, including Mixture-of-Experts models ranging from the flagship ERNIE-4.5-VL-424B-A47B with 424 billion total parameters down to a compact 0.3 billion parameter dense model.According to Baidu&#x27;s technical report on the ERNIE 4.5 family, the models incorporate \"a novel heterogeneous modality structure, which supports parameter sharing across modalities while also allowing dedicated parameters for each individual modality.\"This architectural choice addresses a longstanding challenge in multimodal AI development: training systems on both visual and textual data without one modality degrading the performance of the other. Baidu claims this design \"has the advantage to enhance multimodal understanding without compromising, and even improving, performance on text-related tasks.\"The company reported achieving 47% Model FLOPs Utilization (MFU) — a measure of training efficiency — during pre-training of its largest ERNIE 4.5 language model, using the PaddlePaddle deep learning framework developed in-house.Comprehensive developer tools aim to simplify enterprise deployment and integrationFor organizations looking to deploy the model, Baidu has released a comprehensive suite of development tools through ERNIEKit, what the company describes as an \"industrial-grade training and compression development toolkit.\"The model offers full compatibility with popular open-source frameworks including Hugging Face Transformers, vLLM (a high-performance inference engine), and Baidu&#x27;s own FastDeploy toolkit. This multi-platform support could prove critical for enterprise adoption, allowing organizations to integrate the model into existing AI infrastructure without wholesale platform changes.Sample code released by Baidu shows a relatively straightforward implementation path. Using the Transformers library, developers can load and run the model with approximately 30 lines of Python code, according to the documentation on Hugging Face.For production deployments requiring higher throughput, Baidu provides vLLM integration with specialized support for the model&#x27;s \"reasoning-parser\" and \"tool-call-parser\" capabilities — features that enable the dynamic image examination and external tool integration that distinguish this model from earlier systems.The company also offers FastDeploy, a proprietary inference toolkit that Baidu claims delivers \"production-ready, easy-to-use multi-hardware deployment solutions\" with support for various quantization schemes that can reduce memory requirements and increase inference speed.Why this release matters for the enterprise AI market at a critical inflection pointThe release comes at a pivotal moment in the enterprise AI market. As organizations move beyond experimental chatbot deployments toward production systems that process documents, analyze visual data, and automate complex workflows, demand for capable and cost-effective vision-language models has intensified.Several enterprise use cases appear particularly well-suited to the model&#x27;s capabilities. Document processing — extracting information from invoices, contracts, and forms — represents a massive market where accurate chart and table understanding directly translates to cost savings through automation. Manufacturing quality control, where AI systems must detect visual defects, could benefit from the model&#x27;s grounding capabilities. Customer service applications that handle images from users could leverage the multi-step visual reasoning.The model&#x27;s efficiency profile may prove especially attractive to mid-market organizations and startups that lack the computing budgets of large technology companies. By fitting on a single 80GB GPU — hardware costing roughly $10,000 to $30,000 depending on the specific model — the system becomes economically viable for a much broader range of organizations than models requiring multi-GPU setups costing hundreds of thousands of dollars.\"With all these new models, where&#x27;s the best place to actually build and scale? Access to compute is everything,\" wrote one X user in response to Baidu&#x27;s announcement, highlighting the persistent infrastructure challenges facing organizations attempting to deploy advanced AI systems.The Apache 2.0 licensing further lowers barriers to adoption. Unlike models released under more restrictive licenses that may limit commercial use or require revenue sharing, organizations can deploy ERNIE-4.5-VL-28B-A3B-Thinking in production applications without ongoing licensing fees or usage restrictions.Competition intensifies as Chinese tech giant takes aim at Google and OpenAIBaidu&#x27;s release intensifies competition in the vision-language model space, where Google, OpenAI, Anthropic, and Chinese companies including Alibaba and ByteDance have all released capable systems in recent months.The company&#x27;s performance claims — if validated by independent testing — would represent a significant achievement. Google&#x27;s Gemini 2.5 Pro and OpenAI&#x27;s GPT-5-High are substantially larger models backed by the deep resources of two of the world&#x27;s most valuable technology companies. That a more compact, openly available model could match or exceed their performance on specific tasks would suggest the field is advancing more rapidly than some analysts anticipated.\"Impressive that ERNIE is outperforming Gemini 2.5 Pro,\" wrote one social media commenter, expressing surprise at the claimed results.However, some observers counseled caution about benchmark comparisons. \"It&#x27;s fascinating to see how multimodal models are evolving, especially with features like &#x27;Thinking with Images,&#x27;\" wrote one X user. \"That said, I&#x27;m curious if ERNIE-4.5&#x27;s edge over competitors like Gemini-2.5-Pro and GPT-5-High primarily lies in specific use cases like document and chart\" understanding rather than general-purpose vision tasks.Industry analysts note that benchmark performance often fails to capture real-world behavior across the diverse scenarios enterprises encounter. A model that excels at document understanding may struggle with creative visual tasks or real-time video analysis. Organizations evaluating these systems typically conduct extensive internal testing on representative workloads before committing to production deployments.Technical limitations and infrastructure requirements that enterprises must considerDespite its capabilities, the model faces several technical challenges common to large vision-language systems. The minimum requirement of 80GB of GPU memory, while more accessible than some competitors, still represents a significant infrastructure investment. Organizations without existing GPU infrastructure would need to procure specialized hardware or rely on cloud computing services, introducing ongoing operational costs.The model&#x27;s context window — the amount of text and visual information it can process simultaneously — is listed as 128K tokens in Baidu&#x27;s documentation. While substantial, this may prove limiting for some document processing scenarios involving very long technical manuals or extensive video content.Questions also remain about the model&#x27;s behavior on adversarial inputs, out-of-distribution data, and edge cases. Baidu&#x27;s documentation does not provide detailed information about safety testing, bias mitigation, or failure modes — considerations increasingly important for enterprise deployments where errors could have financial or safety implications.What technical decision-makers need to evaluate beyond the benchmark numbersFor technical decision-makers evaluating the model, several implementation factors warrant consideration beyond raw performance metrics.The model&#x27;s MoE architecture, while efficient during inference, adds complexity to deployment and optimization. Organizations must ensure their infrastructure can properly route inputs to the appropriate expert subnetworks — a capability not universally supported across all deployment platforms.The \"Thinking with Images\" feature, while innovative, requires integration with image manipulation tools to achieve its full potential. Baidu&#x27;s documentation suggests this capability works best \"when paired with tools like image zooming and image search,\" implying that organizations may need to build additional infrastructure to fully leverage this functionality.The model&#x27;s video understanding capabilities, while highlighted in marketing materials, come with practical constraints. Processing video requires substantially more computational resources than static images, and the documentation does not specify maximum video length or optimal frame rates.Organizations considering deployment should also evaluate Baidu&#x27;s ongoing commitment to the model. Open-source AI models require continuing maintenance, security updates, and potential retraining as data distributions shift over time. While the Apache 2.0 license ensures the model remains available, future improvements and support depend on Baidu&#x27;s strategic priorities.Developer community responds with enthusiasm tempered by practical requestsEarly response from the AI research and development community has been cautiously optimistic. Developers have requested versions of the model in additional formats including GGUF (a quantization format popular for local deployment) and MNN (a mobile neural network framework), suggesting interest in running the system on resource-constrained devices.\"Release MNN and GGUF so I can run it on my phone,\" wrote one developer, highlighting demand for mobile deployment options.Other developers praised Baidu&#x27;s technical choices while requesting additional resources. \"Fantastic model! Did you use discoveries from PaddleOCR?\" asked one user, referencing Baidu&#x27;s open-source optical character recognition toolkit.The model&#x27;s lengthy name—ERNIE-4.5-VL-28B-A3B-Thinking—drew lighthearted commentary. \"ERNIE-4.5-VL-28B-A3B-Thinking might be the longest model name in history,\" joked one observer. \"But hey, if you&#x27;re outperforming Gemini-2.5-Pro with only 3B active params, you&#x27;ve earned the right to a dramatic name!\"Baidu plans to showcase the ERNIE lineup during its Baidu World 2025 conference on November 13, where the company is expected to provide additional details about the model&#x27;s development, performance validation, and future roadmap.The release marks a strategic move by Baidu to establish itself as a major player in the global AI infrastructure market. While Chinese AI companies have historically focused primarily on domestic markets, the open-source release under a permissive license signals ambitions to compete internationally with Western AI giants.For enterprises, the release adds another capable option to a rapidly expanding menu of AI models. Organizations no longer face a binary choice between building proprietary systems or licensing closed-source models from a handful of vendors. The proliferation of capable open-source alternatives like ERNIE-4.5-VL-28B-A3B-Thinking is reshaping the economics of AI deployment and accelerating adoption across industries.Whether the model delivers on its performance promises in real-world deployments remains to be seen. But for organizations seeking powerful, cost-effective tools for visual understanding and reasoning, one thing is certain. As one developer succinctly summarized: \"Open source plus commercial use equals chef&#x27;s kiss. Baidu not playing around.\"",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6PAfmxLhH2Yv7BpN8vczIt/f33baa764e279c49d01c5a10da8eef61/nuneybits_Vector_art_of_a_GPU_made_out_of_computer_code_and_the_59f97a50-f492-452f-bd5d-1d6e6e904c4a.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/metas-spice-framework-lets-ai-systems-teach-themselves-to-reason",
          "published_at": "Tue, 11 Nov 2025 22:21:00 GMT",
          "title": "Meta’s SPICE framework lets AI systems teach themselves to reason",
          "standfirst": "Researchers at Meta FAIR and the National University of Singapore have developed a new reinforcement learning framework for self-improving AI systems. Called Self-Play In Corpus Environments (SPICE), the framework pits two AI agents against each other, creating its own challenges and gradually improving without human supervision.While currently a proof-of-concept, this self-play mechanism could provide a basis for future AI systems that can dynamically adapt to their environments, making them more robust against the unpredictability of real-world applications.The challenge of self-improving AIThe goal of self-improving AI is to create systems that can enhance their capabilities by interacting with their environment. A common approach is reinforcement learning with verifiable rewards (RLVR), where models are rewarded for providing the correct answers to problems. This is often limited by its reliance on human-curated problem sets and domain-specific reward engineering, which makes it difficult to scale.Self-play, where a model improves by competing against itself, is another promising paradigm. But existing self-play methods for language models are often limited by two critical factors. Factual errors in generated questions and answers compound, leading to a feedback loop of hallucinations. When the problem generator and solver have information symmetry (i.e., share the same knowledge base) they fail to generate genuinely new challenges and fall into repetitive patterns. As the researchers note in their paper, “These systematic empirical failures indicate that self-improvement requires interaction with an external source providing diverse, verifiable feedback, rather than closed-loop pure introspection.”How SPICE worksSPICE is a self-play framework where a single model acts in two distinct roles. A \"Challenger\" constructs a curriculum of challenging problems from a large corpus of documents. A \"Reasoner\" then attempts to solve these problems without access to the source documents. This setup breaks the information symmetry that limits other self-play methods, as the Reasoner does not have access to the documents and knowledge that the Challenger uses to generate the problems.Grounding the tasks in a vast and diverse corpus of documents prevents hallucination by anchoring questions and answers in real-world content. This is important because for AI systems to reliably self-improve, they need external grounding sources. Therefore, LLM agents should learn from interactions with humans and the real world, not just their own outputs, to avoid compounding errors.The adversarial dynamic between the two roles creates an automatic curriculum. The Challenger is rewarded for generating problems that are both diverse and at the frontier of the Reasoner&#x27;s capability (not too easy and also not impossible). The Reasoner is rewarded for answering correctly. This symbiotic interaction pushes both agents to continuously discover and overcome new challenges. Because the system uses raw documents instead of pre-defined question-answer pairs, it can generate diverse task formats, such as multiple-choice and free-form questions. This flexibility allows SPICE to be applied to any domain, breaking the bottleneck that has confined previous methods to narrow fields like math and code. It also reduces dependence on expensive human-curated datasets for specialized domains like legal or medical analysis.SPICE in actionThe researchers evaluated SPICE on several base models, including Qwen3-4B-Base and OctoThinker-3B-Hybrid-Base. They compared its performance against baselines such as the base model with no training, a Reasoner model trained with a fixed \"Strong Challenger\" (Qwen3-32B-Instruct), and pure self-play methods like R-Zero and Absolute Zero. The evaluation covered a wide range of mathematical and general reasoning benchmarks.Across all models, SPICE consistently outperformed the baselines, delivering significant improvements in both mathematical and general reasoning tasks. The results show that the reasoning capabilities developed through corpus-grounded self-play transfer broadly across different models, thanks to the diverse external knowledge corpus they used.A key finding is that the adversarial dynamic creates an effective automatic curriculum. As training progresses, the Challenger learns to generate increasingly difficult problems. In one experiment, the Reasoner&#x27;s pass rate on a fixed set of problems increased from 55% to 85% over time, showing its improved capabilities. Meanwhile, later versions of the Challenger were able to generate questions that dropped the pass rate of an early-stage Reasoner from 55% to 35%, confirming that both roles co-evolve successfully.The researchers conclude that this approach presents a paradigm shift in self-improving reasoning methods from “closed-loop self-play that often stagnates due to hallucination drift, to open-ended improvement through interaction with the vast, verifiable knowledge embedded in web document corpora.”Currently, the corpus used for SPICE represents human experience captured in text. The ultimate goal is for self-improving systems to generate questions based on interactions with reality, including the physical world, the internet, and human interactions across multiple modalities like video, audio, and sensor data.",
          "content": "Researchers at Meta FAIR and the National University of Singapore have developed a new reinforcement learning framework for self-improving AI systems. Called Self-Play In Corpus Environments (SPICE), the framework pits two AI agents against each other, creating its own challenges and gradually improving without human supervision.While currently a proof-of-concept, this self-play mechanism could provide a basis for future AI systems that can dynamically adapt to their environments, making them more robust against the unpredictability of real-world applications.The challenge of self-improving AIThe goal of self-improving AI is to create systems that can enhance their capabilities by interacting with their environment. A common approach is reinforcement learning with verifiable rewards (RLVR), where models are rewarded for providing the correct answers to problems. This is often limited by its reliance on human-curated problem sets and domain-specific reward engineering, which makes it difficult to scale.Self-play, where a model improves by competing against itself, is another promising paradigm. But existing self-play methods for language models are often limited by two critical factors. Factual errors in generated questions and answers compound, leading to a feedback loop of hallucinations. When the problem generator and solver have information symmetry (i.e., share the same knowledge base) they fail to generate genuinely new challenges and fall into repetitive patterns. As the researchers note in their paper, “These systematic empirical failures indicate that self-improvement requires interaction with an external source providing diverse, verifiable feedback, rather than closed-loop pure introspection.”How SPICE worksSPICE is a self-play framework where a single model acts in two distinct roles. A \"Challenger\" constructs a curriculum of challenging problems from a large corpus of documents. A \"Reasoner\" then attempts to solve these problems without access to the source documents. This setup breaks the information symmetry that limits other self-play methods, as the Reasoner does not have access to the documents and knowledge that the Challenger uses to generate the problems.Grounding the tasks in a vast and diverse corpus of documents prevents hallucination by anchoring questions and answers in real-world content. This is important because for AI systems to reliably self-improve, they need external grounding sources. Therefore, LLM agents should learn from interactions with humans and the real world, not just their own outputs, to avoid compounding errors.The adversarial dynamic between the two roles creates an automatic curriculum. The Challenger is rewarded for generating problems that are both diverse and at the frontier of the Reasoner&#x27;s capability (not too easy and also not impossible). The Reasoner is rewarded for answering correctly. This symbiotic interaction pushes both agents to continuously discover and overcome new challenges. Because the system uses raw documents instead of pre-defined question-answer pairs, it can generate diverse task formats, such as multiple-choice and free-form questions. This flexibility allows SPICE to be applied to any domain, breaking the bottleneck that has confined previous methods to narrow fields like math and code. It also reduces dependence on expensive human-curated datasets for specialized domains like legal or medical analysis.SPICE in actionThe researchers evaluated SPICE on several base models, including Qwen3-4B-Base and OctoThinker-3B-Hybrid-Base. They compared its performance against baselines such as the base model with no training, a Reasoner model trained with a fixed \"Strong Challenger\" (Qwen3-32B-Instruct), and pure self-play methods like R-Zero and Absolute Zero. The evaluation covered a wide range of mathematical and general reasoning benchmarks.Across all models, SPICE consistently outperformed the baselines, delivering significant improvements in both mathematical and general reasoning tasks. The results show that the reasoning capabilities developed through corpus-grounded self-play transfer broadly across different models, thanks to the diverse external knowledge corpus they used.A key finding is that the adversarial dynamic creates an effective automatic curriculum. As training progresses, the Challenger learns to generate increasingly difficult problems. In one experiment, the Reasoner&#x27;s pass rate on a fixed set of problems increased from 55% to 85% over time, showing its improved capabilities. Meanwhile, later versions of the Challenger were able to generate questions that dropped the pass rate of an early-stage Reasoner from 55% to 35%, confirming that both roles co-evolve successfully.The researchers conclude that this approach presents a paradigm shift in self-improving reasoning methods from “closed-loop self-play that often stagnates due to hallucination drift, to open-ended improvement through interaction with the vast, verifiable knowledge embedded in web document corpora.”Currently, the corpus used for SPICE represents human experience captured in text. The ultimate goal is for self-improving systems to generate questions based on interactions with reality, including the physical world, the internet, and human interactions across multiple modalities like video, audio, and sensor data.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/UAYtncQWQ2a2g1rzWOCHR/19d3e60c8a6eef26b99a5a492491bbec/Adversarial_AI_training.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/only-9-of-developers-think-ai-code-can-be-used-without-human-oversight",
          "published_at": "Tue, 11 Nov 2025 19:43:00 GMT",
          "title": "Only 9% of developers think AI code can be used without human oversight, BairesDev survey reveals",
          "standfirst": "Senior software developers are preparing for a major shift in how they work as artificial intelligence becomes central to their workflows, according to BairesDev’s latest Dev Barometer report published today. VentureBeat was given an exclusive early look and the findings below come directly from that report. The quarterly global survey, which polled 501 developers and 19 project managers across 92 software initiatives, finds that nearly two-thirds (65%) of senior developers expect their roles to be redefined by AI in 2026. The data highlights a transformation underway in software development: fewer routine coding tasks, more emphasis on design and strategy, and a rising need for AI fluency.From Coders to StrategistsAmong those anticipating change, 74% say they expect to shift from hands-on coding to designing solutions. Another 61% plan to integrate AI-generated code into their workflows, and half foresee spending more time on system strategy and architecture.“It’s not about lines of code anymore,” said Justice Erolin, Chief Technology Officer at BairesDev, in a recent interview with VentureBeat conducted over video call. “It’s about the quality and type of code, and the kind of work developers are doing.”Erolin said the company is watching developers evolve from individual contributors into system thinkers.“AI is great at code scaffolding and generating unit tests, saving developers around eight hours a week,” he explained. “That time can now be used for solution architecture and strategy work—areas where AI still falls short.”The survey’s data reflects this shift. Developers are moving toward higher-value tasks while automation takes over much of the repetitive coding that once occupied junior engineers.Erolin noted that BairesDev’s internal data mirrors these findings. “We’re seeing a shift where senior engineers with AI tools are outperforming, and even replacing, the traditional senior-plus-junior team setup,” he said.Realism About AI’s LimitsDespite widespread enthusiasm, developers remain cautious about AI’s reliability.Over half (56%) describe AI-generated code as “somewhat reliable,” saying it still requires validation for accuracy and security. Only 9% trust it enough to use without human oversight.Erolin agreed with that sentiment. “AI doesn’t replace human oversight,” he said. “Even as tools improve, developers still need to understand how individual components fit into the bigger system.” He added that the biggest constraint in large language models today is “their context window”—the limited ability to retain and reason across entire systems. “Engineers need to think holistically about architecture, not just individual lines of code,” he said.The CTO described 2025 as a turning point for how engineers use AI tools like GitHub Copilot, Cursor, Claude, and OpenAI’s models. “We’re tracking what tools and models our engineers use,” he said. “But the bigger story is how those tools impact learning, productivity, and oversight.”That tempered optimism aligns with BairesDev’s previous Dev Barometer findings, which reported that 92% of developers were already using AI-assisted coding by Q3 2025, saving an average of 7.3 hours per week.A Year of UpskillingIn 2025, AI integration already brought tangible professional benefits. 74% of developers said the technology strengthened their technical skills, 50% reported better work-life balance, and 37% said AI tools expanded their career opportunities.Erolin said the company is seeing AI emerge as “a top use case for upskilling.” Developers use it to “learn new technologies faster and fill knowledge gaps,” he noted. “When developers understand how AI works and its limitations, they can use it to enhance—not replace—their critical thinking. They prompt better and learn more efficiently.”Still, he warned of a potential long-term risk in the industry’s current trajectory. “If junior engineers are being replaced or not hired, we’ll face a shortage of qualified senior engineers in ten years as current ones retire,” Erolin said.The Dev Barometer findings echo that concern. Developers expect leaner teams, but many also worry that fewer entry-level opportunities could lead to long-term talent pipeline issues.Leaner Teams, New PrioritiesDevelopers expect 2026 to bring smaller, more specialized teams. 58% say automation will reduce entry-level tasks, while 63% expect new career paths to emerge as AI redefines team structures. 59% anticipate that AI will create entirely new specialized roles.According to BairesDev’s data, developers currently divide their time between writing code (48%), debugging (42%), and documentation (35%). Only 19% report focusing primarily on creative problem-solving and innovation—a share that’s expected to grow as AI removes lower-level coding tasks.The report also highlights where developers see the fastest-growing areas for 2026: AI/ML (67%), data analytics (46%), and cybersecurity (45%). In parallel, 63% of project managers said developers will need more training in AI, cloud, and security.Erolin described the next generation of developers as “T-shaped engineers”—people with broad system knowledge and deep expertise in one or more areas. “The most important developer moving forward will be the T-shaped engineer,” he said. “Broad in understanding, deep in skill.”AI as an Industry StandardThe Q4 Dev Barometer frames AI not as an experiment but as a foundation for how teams will operate in 2026. Developers are moving beyond using AI as a coding shortcut and instead incorporating it into architecture, validation, and design decisions.Erolin emphasized that BairesDev is already adapting its internal teams to this new reality. “Our engineers are full-time with us, and we staff them out where they’re needed,” he said. “Some clients need help for six months to a year; others outsource their entire dev team to us.”He said BairesDev provides “about 5,000 software engineers from Latin America, offering clients timezone-aligned, culturally aligned, and highly fluent English-speaking talent.”As developers integrate AI deeper into their daily work, Erolin believes the competitive advantage will belong to those who understand both the technology’s capabilities and its constraints. “When developers learn to collaborate with AI instead of compete against it, that’s when the real productivity and creativity gains happen,” he said.Background: Who BairesDev IsFounded in Buenos Aires in 2009 by Nacho De Marco and Paul Azorin, BairesDev began with a mission to connect what it describes as the “top 1%” of Latin American developers with global companies seeking high-quality software solutions. The company grew from those early roots into a major nearshore software development and staffing provider, offering everything from individual developer placements to full end-to-end project outsourcing.Today, BairesDev claims to have delivered more than 1,200 projects across 130+ industries, serving hundreds of clients ranging from startups to Fortune 500 firms such as Google, Adobe, and Rolls-Royce. It operates with a remote-first model and a workforce of over 4,000 professionals across more than 40 countries, aligning its teams to North American time zones.The company emphasizes three core advantages: access to elite technical talent across 100+ technologies, rapid scalability for project needs, and nearshore proximity for real-time collaboration. It reports client relationships averaging over three years and a satisfaction rate around 91%.BairesDev’s unique position—bridging Latin American talent with global enterprise clients—gives it an unusually data-rich perspective on how AI is transforming software development at scale.The TakeawayThe Dev Barometer’s Q4 2025 results suggest 2026 will mark a turning point for software engineering. Developers are becoming system architects rather than pure coders, AI literacy is becoming a baseline requirement, and traditional entry-level roles may give way to new, specialized positions.As AI becomes embedded in every stage of development—from design to testing—developers who can combine technical fluency with strategic thinking are set to lead the next era of software creation.",
          "content": "Senior software developers are preparing for a major shift in how they work as artificial intelligence becomes central to their workflows, according to BairesDev’s latest Dev Barometer report published today. VentureBeat was given an exclusive early look and the findings below come directly from that report. The quarterly global survey, which polled 501 developers and 19 project managers across 92 software initiatives, finds that nearly two-thirds (65%) of senior developers expect their roles to be redefined by AI in 2026. The data highlights a transformation underway in software development: fewer routine coding tasks, more emphasis on design and strategy, and a rising need for AI fluency.From Coders to StrategistsAmong those anticipating change, 74% say they expect to shift from hands-on coding to designing solutions. Another 61% plan to integrate AI-generated code into their workflows, and half foresee spending more time on system strategy and architecture.“It’s not about lines of code anymore,” said Justice Erolin, Chief Technology Officer at BairesDev, in a recent interview with VentureBeat conducted over video call. “It’s about the quality and type of code, and the kind of work developers are doing.”Erolin said the company is watching developers evolve from individual contributors into system thinkers.“AI is great at code scaffolding and generating unit tests, saving developers around eight hours a week,” he explained. “That time can now be used for solution architecture and strategy work—areas where AI still falls short.”The survey’s data reflects this shift. Developers are moving toward higher-value tasks while automation takes over much of the repetitive coding that once occupied junior engineers.Erolin noted that BairesDev’s internal data mirrors these findings. “We’re seeing a shift where senior engineers with AI tools are outperforming, and even replacing, the traditional senior-plus-junior team setup,” he said.Realism About AI’s LimitsDespite widespread enthusiasm, developers remain cautious about AI’s reliability.Over half (56%) describe AI-generated code as “somewhat reliable,” saying it still requires validation for accuracy and security. Only 9% trust it enough to use without human oversight.Erolin agreed with that sentiment. “AI doesn’t replace human oversight,” he said. “Even as tools improve, developers still need to understand how individual components fit into the bigger system.” He added that the biggest constraint in large language models today is “their context window”—the limited ability to retain and reason across entire systems. “Engineers need to think holistically about architecture, not just individual lines of code,” he said.The CTO described 2025 as a turning point for how engineers use AI tools like GitHub Copilot, Cursor, Claude, and OpenAI’s models. “We’re tracking what tools and models our engineers use,” he said. “But the bigger story is how those tools impact learning, productivity, and oversight.”That tempered optimism aligns with BairesDev’s previous Dev Barometer findings, which reported that 92% of developers were already using AI-assisted coding by Q3 2025, saving an average of 7.3 hours per week.A Year of UpskillingIn 2025, AI integration already brought tangible professional benefits. 74% of developers said the technology strengthened their technical skills, 50% reported better work-life balance, and 37% said AI tools expanded their career opportunities.Erolin said the company is seeing AI emerge as “a top use case for upskilling.” Developers use it to “learn new technologies faster and fill knowledge gaps,” he noted. “When developers understand how AI works and its limitations, they can use it to enhance—not replace—their critical thinking. They prompt better and learn more efficiently.”Still, he warned of a potential long-term risk in the industry’s current trajectory. “If junior engineers are being replaced or not hired, we’ll face a shortage of qualified senior engineers in ten years as current ones retire,” Erolin said.The Dev Barometer findings echo that concern. Developers expect leaner teams, but many also worry that fewer entry-level opportunities could lead to long-term talent pipeline issues.Leaner Teams, New PrioritiesDevelopers expect 2026 to bring smaller, more specialized teams. 58% say automation will reduce entry-level tasks, while 63% expect new career paths to emerge as AI redefines team structures. 59% anticipate that AI will create entirely new specialized roles.According to BairesDev’s data, developers currently divide their time between writing code (48%), debugging (42%), and documentation (35%). Only 19% report focusing primarily on creative problem-solving and innovation—a share that’s expected to grow as AI removes lower-level coding tasks.The report also highlights where developers see the fastest-growing areas for 2026: AI/ML (67%), data analytics (46%), and cybersecurity (45%). In parallel, 63% of project managers said developers will need more training in AI, cloud, and security.Erolin described the next generation of developers as “T-shaped engineers”—people with broad system knowledge and deep expertise in one or more areas. “The most important developer moving forward will be the T-shaped engineer,” he said. “Broad in understanding, deep in skill.”AI as an Industry StandardThe Q4 Dev Barometer frames AI not as an experiment but as a foundation for how teams will operate in 2026. Developers are moving beyond using AI as a coding shortcut and instead incorporating it into architecture, validation, and design decisions.Erolin emphasized that BairesDev is already adapting its internal teams to this new reality. “Our engineers are full-time with us, and we staff them out where they’re needed,” he said. “Some clients need help for six months to a year; others outsource their entire dev team to us.”He said BairesDev provides “about 5,000 software engineers from Latin America, offering clients timezone-aligned, culturally aligned, and highly fluent English-speaking talent.”As developers integrate AI deeper into their daily work, Erolin believes the competitive advantage will belong to those who understand both the technology’s capabilities and its constraints. “When developers learn to collaborate with AI instead of compete against it, that’s when the real productivity and creativity gains happen,” he said.Background: Who BairesDev IsFounded in Buenos Aires in 2009 by Nacho De Marco and Paul Azorin, BairesDev began with a mission to connect what it describes as the “top 1%” of Latin American developers with global companies seeking high-quality software solutions. The company grew from those early roots into a major nearshore software development and staffing provider, offering everything from individual developer placements to full end-to-end project outsourcing.Today, BairesDev claims to have delivered more than 1,200 projects across 130+ industries, serving hundreds of clients ranging from startups to Fortune 500 firms such as Google, Adobe, and Rolls-Royce. It operates with a remote-first model and a workforce of over 4,000 professionals across more than 40 countries, aligning its teams to North American time zones.The company emphasizes three core advantages: access to elite technical talent across 100+ technologies, rapid scalability for project needs, and nearshore proximity for real-time collaboration. It reports client relationships averaging over three years and a satisfaction rate around 91%.BairesDev’s unique position—bridging Latin American talent with global enterprise clients—gives it an unusually data-rich perspective on how AI is transforming software development at scale.The TakeawayThe Dev Barometer’s Q4 2025 results suggest 2026 will mark a turning point for software engineering. Developers are becoming system architects rather than pure coders, AI literacy is becoming a baseline requirement, and traditional entry-level roles may give way to new, specialized positions.As AI becomes embedded in every stage of development—from design to testing—developers who can combine technical fluency with strategic thinking are set to lead the next era of software creation.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5CiQuierRq34dYmuxJUNHb/a86df483038c29162f381f3fc96559f7/cfr0z3n_aerial_view_extended_view_of_hundreds_of_software_dev_51f077e9-5eef-4c86-bf4e-2dabd7ab231b_1.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/remix-in-google-messages-brings-ai-photo-editing-to-even-more-phones-190000445.html",
          "published_at": "Tue, 11 Nov 2025 19:00:00 +0000",
          "title": "Remix in Google Messages brings AI photo editing to even more phones",
          "standfirst": "Google's November 2025 Pixel Drop is available today, and it includes some new features that should benefit more than just the Pixel phones and tablets Google typically targets. A new messaging feature called Remix in Google Messages expands access to Gemini-powered photo editing, and Google's improving its Scam Detection and Pixel VIP features, too.Remix in Google Messages is essentially Google's Nano Banana photo editing tool, but available directly in Google Messages. The feature uses the same image model as Gemini and Google Photos, and lets Messages users tweak photos directly in a chat. Importantly, the edited photos are viewable by anyone in the chat, even if they're not on Android. The feature is available in English in the US, UK, Australia, Canada, India, Ireland and New Zealand with RCS enabled. Google says remixed images can also be sent over MMS.In the Google Photos app, those photo editing skills will now also be even more personalized. Google says eligible Android users with Ask Photos and Face Groups enabled, can refer to people in their photos by name while they edit. The Photos app can use past photos of your labelled friends to make tweaks like adding a smile or opening someone's eyes without having to be provided a previous reference.Power Saving Mode in action.GoogleFor anyone who owns one of the latest Pixel 10 phones, the Pixel Drop includes a new Power Saving Mode in Google Maps that blacks out the screen and only shows essential information and directions. Google claims the feature and extend battery life for up to four hours. The company hasn’t announced any plans, but the feature seems like it could be an equally good fit on Android Auto.Scam Detection is Android's built-in feature for identifying scam calls and warning you with a notification. As part of the Pixel Drop, Scam Detection will now also work with messages, warning you in your notifications on Pixel 6 devices and up if you could be dealing with fraud. As part of the update, Scam Detection is also now available in the UK, Ireland, India, Australia and Canada. The update also includes support for Notification Summaries on the Pixel 9 and up, which summarize frequent group chat notifications as a recap in your notification shade. If you've marked anyone as a Pixel VIP (a feature added back in June), Android will now also prioritize their messages so you don't miss them.Alongside those more practical features, Google is also introducing a new seasonal Wicked: For Good theme pack on Pixel 6 and newer devices. The theme pack is accessible via a new Theme Packs app that was released earlier in November. While it uses existing options like your wallpaper and icon settings to set \"Glinda\" and \"Elphaba\" themes, the convenience of Theme Packs is the ability to change all those settings at once. It's unfortunate Google's introducing the tool with an ad, but it could prove useful down the line.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/remix-in-google-messages-brings-ai-photo-editing-to-even-more-phones-190000445.html?src=rss",
          "content": "Google's November 2025 Pixel Drop is available today, and it includes some new features that should benefit more than just the Pixel phones and tablets Google typically targets. A new messaging feature called Remix in Google Messages expands access to Gemini-powered photo editing, and Google's improving its Scam Detection and Pixel VIP features, too.Remix in Google Messages is essentially Google's Nano Banana photo editing tool, but available directly in Google Messages. The feature uses the same image model as Gemini and Google Photos, and lets Messages users tweak photos directly in a chat. Importantly, the edited photos are viewable by anyone in the chat, even if they're not on Android. The feature is available in English in the US, UK, Australia, Canada, India, Ireland and New Zealand with RCS enabled. Google says remixed images can also be sent over MMS.In the Google Photos app, those photo editing skills will now also be even more personalized. Google says eligible Android users with Ask Photos and Face Groups enabled, can refer to people in their photos by name while they edit. The Photos app can use past photos of your labelled friends to make tweaks like adding a smile or opening someone's eyes without having to be provided a previous reference.Power Saving Mode in action.GoogleFor anyone who owns one of the latest Pixel 10 phones, the Pixel Drop includes a new Power Saving Mode in Google Maps that blacks out the screen and only shows essential information and directions. Google claims the feature and extend battery life for up to four hours. The company hasn’t announced any plans, but the feature seems like it could be an equally good fit on Android Auto.Scam Detection is Android's built-in feature for identifying scam calls and warning you with a notification. As part of the Pixel Drop, Scam Detection will now also work with messages, warning you in your notifications on Pixel 6 devices and up if you could be dealing with fraud. As part of the update, Scam Detection is also now available in the UK, Ireland, India, Australia and Canada. The update also includes support for Notification Summaries on the Pixel 9 and up, which summarize frequent group chat notifications as a recap in your notification shade. If you've marked anyone as a Pixel VIP (a feature added back in June), Android will now also prioritize their messages so you don't miss them.Alongside those more practical features, Google is also introducing a new seasonal Wicked: For Good theme pack on Pixel 6 and newer devices. The theme pack is accessible via a new Theme Packs app that was released earlier in November. While it uses existing options like your wallpaper and icon settings to set \"Glinda\" and \"Elphaba\" themes, the convenience of Theme Packs is the ability to change all those settings at once. It's unfortunate Google's introducing the tool with an ad, but it could prove useful down the line.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/remix-in-google-messages-brings-ai-photo-editing-to-even-more-phones-190000445.html?src=rss",
          "feed_position": 46,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Google-Maps-November-Pixel-Drop.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/get-half-off-our-favorite-budgeting-app-for-black-friday-140025864.html",
          "published_at": "Tue, 11 Nov 2025 17:01:26 +0000",
          "title": "Black Friday deals include half off our favorite budgeting app",
          "standfirst": "Now's the time of year you might be reconsidering how you budget your finances, or establishing a plan if you don't have one already. While it's possible to do it all yourself, budgeting apps can automate some processes and make it easier to see where your money is going and patterns, both good and bad, that might be occurring. For Black Friday, you can get 50 percent off our favorite budgeting app, Quicken Simplifi. The Quicken Simplifi app is down to $3 monthly from $6 monthly, adding up to $36 for the year. Quicken Classic, the company's \"original desktop software\" for \"experienced investors\" is also half off at $6 monthly, down from $12 monthly. The sale starts today and is available until Wednesday, December 3. One of the many things that sets Quicken Simplifi apart from its competitors is its sleek, easy to use interface. The setup is pretty straightforward and it allows for your spouse or financial advisor to act as co-manager of the account. It also clearly shows figures like net worth, recent spending, upcoming recurring payments and more. Plus, there's an option to say if you're expecting a refund. Quicken Simplifi unfortunately doesn't offer a free trial so testing it out with a discount means less money invested if it's not for you. This article originally appeared on Engadget at https://www.engadget.com/deals/get-half-off-our-favorite-budgeting-app-for-black-friday-140025864.html?src=rss",
          "content": "Now's the time of year you might be reconsidering how you budget your finances, or establishing a plan if you don't have one already. While it's possible to do it all yourself, budgeting apps can automate some processes and make it easier to see where your money is going and patterns, both good and bad, that might be occurring. For Black Friday, you can get 50 percent off our favorite budgeting app, Quicken Simplifi. The Quicken Simplifi app is down to $3 monthly from $6 monthly, adding up to $36 for the year. Quicken Classic, the company's \"original desktop software\" for \"experienced investors\" is also half off at $6 monthly, down from $12 monthly. The sale starts today and is available until Wednesday, December 3. One of the many things that sets Quicken Simplifi apart from its competitors is its sleek, easy to use interface. The setup is pretty straightforward and it allows for your spouse or financial advisor to act as co-manager of the account. It also clearly shows figures like net worth, recent spending, upcoming recurring payments and more. Plus, there's an option to say if you're expecting a refund. Quicken Simplifi unfortunately doesn't offer a free trial so testing it out with a discount means less money invested if it's not for you. This article originally appeared on Engadget at https://www.engadget.com/deals/get-half-off-our-favorite-budgeting-app-for-black-friday-140025864.html?src=rss",
          "feed_position": 47
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/google-photos-now-has-six-more-ai-powered-features-170000125.html",
          "published_at": "Tue, 11 Nov 2025 17:00:00 +0000",
          "title": "Google Photos now has six more AI-powered features",
          "standfirst": "Google Photos introduced a fresh batch of a half-dozen AI-powered features today. First is personalized photo editing. Using \"Help me edit,\" you can now make adjustments to portraits and group shots, such as removing sunglasses or fixing closed eyes. Google says that the AI uses other images stored in a user's face groups to make accurate changes to the people in your photo library. The \"Help me edit\" voice- or text-controlled photo editing tool is also starting to roll out to iOS users in the US.Next, the company is integrating its Nano Banana image editor into Google Photos. Users can make open-ended restyling requests in the \"Help me edit\" tool, such as making a picture look like a Renaissance painting or a mosaic. Nano Banana will also power a new Create with AI section, which will provide templates based on popular requests to jumpstart the AI editing process. This feature will roll out to the Create tab for Android users in the US and India beginning next week. Later on, Google will begin personalizing these templates to the particular hobbies and experiences captured in a person's photo library. Following a \"pause\" and restart in June, the Ask Photos tool is also expanding. The feature for AI-powered searches of the Google photo library will be available in more than 100 new markets and will support 17 new languages starting this week. Finally, Google Photos is getting a new Ask button aimed at delivering more details about a specific image. After tapping the button, a user can type questions about the content of the photo, find similar pictures in their library or begin describing desired edits. This feature is rolling out just in the US for now, but on both Android and iOS platforms.This article originally appeared on Engadget at https://www.engadget.com/ai/google-photos-now-has-six-more-ai-powered-features-170000125.html?src=rss",
          "content": "Google Photos introduced a fresh batch of a half-dozen AI-powered features today. First is personalized photo editing. Using \"Help me edit,\" you can now make adjustments to portraits and group shots, such as removing sunglasses or fixing closed eyes. Google says that the AI uses other images stored in a user's face groups to make accurate changes to the people in your photo library. The \"Help me edit\" voice- or text-controlled photo editing tool is also starting to roll out to iOS users in the US.Next, the company is integrating its Nano Banana image editor into Google Photos. Users can make open-ended restyling requests in the \"Help me edit\" tool, such as making a picture look like a Renaissance painting or a mosaic. Nano Banana will also power a new Create with AI section, which will provide templates based on popular requests to jumpstart the AI editing process. This feature will roll out to the Create tab for Android users in the US and India beginning next week. Later on, Google will begin personalizing these templates to the particular hobbies and experiences captured in a person's photo library. Following a \"pause\" and restart in June, the Ask Photos tool is also expanding. The feature for AI-powered searches of the Google photo library will be available in more than 100 new markets and will support 17 new languages starting this week. Finally, Google Photos is getting a new Ask button aimed at delivering more details about a specific image. After tapping the button, a user can type questions about the content of the photo, find similar pictures in their library or begin describing desired edits. This feature is rolling out just in the US for now, but on both Android and iOS platforms.This article originally appeared on Engadget at https://www.engadget.com/ai/google-photos-now-has-six-more-ai-powered-features-170000125.html?src=rss",
          "feed_position": 48
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Valve-Steam-Controller.jpg",
      "popularity_score": 2009.1850144444445,
      "ai_summary": [
        "Monarch Money is offering a 50% discount on annual plans for new users.",
        "The discount code MONARCHVIP provides access for $50, down from $100.",
        "The offer is only valid for new users and cannot be combined with others.",
        "The discount code must be used when signing up through the web.",
        "Monarch Money offers customization and detailed tracking of finances."
      ]
    },
    {
      "id": "cluster_43",
      "coverage": 2,
      "updated_at": "Wed, 12 Nov 2025 20:10:21 GMT",
      "title": "Google's Private AI Compute promises good-as-local privacy in the Gemini cloud",
      "neutral_headline": "Google's Private AI Compute Promises Cloud Privacy",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/googles-private-ai-compute-promises-good-as-local-privacy-in-the-gemini-cloud/",
          "published_at": "Wed, 12 Nov 2025 20:10:21 GMT",
          "title": "Google's Private AI Compute promises good-as-local privacy in the Gemini cloud",
          "standfirst": "The aim: Move AI functionality back to the cloud, while maintaining the privacy of on-device processing. Can Google have it both ways?",
          "content": "The aim: Move AI functionality back to the cloud, while maintaining the privacy of on-device processing. Can Google have it both ways?",
          "feed_position": 7
        },
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/11/google-says-new-cloud-based-private-ai-compute-is-just-as-secure-as-local-processing/",
          "published_at": "Tue, 11 Nov 2025 21:34:10 +0000",
          "title": "Google says new cloud-based “Private AI Compute” is just as secure as local processing",
          "standfirst": "New system allows devices to connect directly to secure space in Google's AI servers.",
          "content": "Google’s current mission is to weave generative AI into as many products as it can, getting everyone accustomed to, and maybe even dependent on, working with confabulatory robots. That means it needs to feed the bots a lot of your data, and that’s getting easier with the company’s new Private AI Compute. Google claims its new secure cloud environment will power better AI experiences without sacrificing your privacy. The pitch sounds a lot like Apple’s Private Cloud Compute. Google’s Private AI Compute runs on “one seamless Google stack” powered by the company’s custom Tensor Processing Units (TPUs). These chips have integrated secure elements, and the new system allows devices to connect directly to the protected space via an encrypted link. Google’s TPUs rely on an AMD-based Trusted Execution Environment (TEE) that encrypts and isolates memory from the host. Theoretically, that means no one else—not even Google itself—can access your data. Google says independent analysis by NCC Group shows that Private AI Compute meets its strict privacy guidelines.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Private_Inference-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Private_Inference-1152x648.jpg",
      "popularity_score": 2008.8469588888888,
      "ai_summary": [
        "Google's Private AI Compute aims to move AI to the cloud while maintaining privacy.",
        "The system allows devices to connect directly to secure spaces in Google's AI servers.",
        "The goal is to provide AI functionality with the same privacy as local processing.",
        "Google is working to balance cloud-based AI with user data protection.",
        "The technology is designed to enhance privacy in AI applications."
      ]
    },
    {
      "id": "cluster_48",
      "coverage": 2,
      "updated_at": "Wed, 12 Nov 2025 20:00:00 +0000",
      "title": "ElevenLabs strike deals with celebs to create AI audio",
      "neutral_headline": "Matthew McConaughey and Michael Caine sign voice deal with AI company",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/11/12/elevenlabs-strike-deals-with-celebs-to-create-ai-audio/",
          "published_at": "Wed, 12 Nov 2025 20:00:00 +0000",
          "title": "ElevenLabs strike deals with celebs to create AI audio",
          "standfirst": "ElevenLabs struck a deal with actors Michael Caine and Matthew McConaughey to AI-generate their voices.",
          "content": "ElevenLabs struck a deal with actors Michael Caine and Matthew McConaughey to AI-generate their voices.",
          "feed_position": 4
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/culture/2025/nov/11/matthew-mcconaughey-michael-caine-ai-voice",
          "published_at": "Tue, 11 Nov 2025 18:10:29 GMT",
          "title": "Matthew McConaughey and Michael Caine sign voice deal with AI company",
          "standfirst": "The voices of the Oscar-winning actors can now be used to create AI-generated versions in a new deal with ElevenLabsOscar-winning actors Matthew McConaughey and Michael Caine have both signed a deal with the AI audio company ElevenLabs.The New York-based company can now create AI-generated versions of their voices as part of a bid to solve a “key ethical challenge” in the artificial intelligence industry’s alliance with Hollywood. Continue reading...",
          "content": "The voices of the Oscar-winning actors can now be used to create AI-generated versions in a new deal with ElevenLabsOscar-winning actors Matthew McConaughey and Michael Caine have both signed a deal with the AI audio company ElevenLabs.The New York-based company can now create AI-generated versions of their voices as part of a bid to solve a “key ethical challenge” in the artificial intelligence industry’s alliance with Hollywood. Continue reading...",
          "feed_position": 4
        }
      ],
      "popularity_score": 2008.674458888889,
      "ai_summary": [
        "ElevenLabs has signed deals with Michael Caine and Matthew McConaughey.",
        "The deals allow ElevenLabs to AI-generate the actors' voices.",
        "The company aims to address ethical challenges in AI and Hollywood.",
        "AI-generated voices will be used for various applications.",
        "The agreement marks a step forward in AI voice technology."
      ]
    },
    {
      "id": "cluster_56",
      "coverage": 2,
      "updated_at": "Wed, 12 Nov 2025 19:18:59 +0000",
      "title": "Court rules that OpenAI violated German copyright law; orders it to pay damages",
      "neutral_headline": "ChatGPT violated copyright law by ‘learning’ from song lyrics, German court rules",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/11/12/court-rules-that-openai-violated-german-copyright-law-ordered-it-to-pay-damages/",
          "published_at": "Wed, 12 Nov 2025 19:18:59 +0000",
          "title": "Court rules that OpenAI violated German copyright law; orders it to pay damages",
          "standfirst": "A German court ruled that OpenAI’s ChatGPT violated the nation’s copyright laws by training its language models on licensed musical work without permission.",
          "content": "A German court ruled that OpenAI’s ChatGPT violated the nation’s copyright laws by training its language models on licensed musical work without permission.",
          "feed_position": 6
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2025/nov/11/chatgpt-violated-copyright-laws-german-court-rules",
          "published_at": "Tue, 11 Nov 2025 17:00:39 GMT",
          "title": "ChatGPT violated copyright law by ‘learning’ from song lyrics, German court rules",
          "standfirst": "OpenAI ordered to pay undisclosed damages for training its language models on artists’ work without permissionA court in Munich has ruled that OpenAI’s chatbot ChatGPT violated German copyright laws by using hits from top-selling musicians to train its language models in what creative industry advocates described as a landmark European ruling.The Munich regional court sided in favour of Germany’s music rights society GEMA, which said ChatGPT had harvested protected lyrics by popular artists to “learn” from them. Continue reading...",
          "content": "OpenAI ordered to pay undisclosed damages for training its language models on artists’ work without permissionA court in Munich has ruled that OpenAI’s chatbot ChatGPT violated German copyright laws by using hits from top-selling musicians to train its language models in what creative industry advocates described as a landmark European ruling.The Munich regional court sided in favour of Germany’s music rights society GEMA, which said ChatGPT had harvested protected lyrics by popular artists to “learn” from them. Continue reading...",
          "feed_position": 2
        }
      ],
      "popularity_score": 2007.9908477777778,
      "ai_summary": [
        "A German court ruled that OpenAI's ChatGPT violated copyright laws.",
        "ChatGPT used licensed musical works to train its language models.",
        "OpenAI was ordered to pay undisclosed damages for copyright infringement.",
        "The ruling involved the use of lyrics from popular artists.",
        "The court sided with Germany's music rights society GEMA."
      ]
    },
    {
      "id": "cluster_28",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 22:54:47 +0000",
      "title": "OpenAI walks a tricky tightrope with GPT-5.1’s eight new personalities",
      "neutral_headline": "OpenAI Navigates GPT-5.1 with New Personality Controls",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/11/openai-walks-a-tricky-tightrope-with-gpt-5-1s-eight-new-personalities/",
          "published_at": "Wed, 12 Nov 2025 22:54:47 +0000",
          "title": "OpenAI walks a tricky tightrope with GPT-5.1’s eight new personalities",
          "standfirst": "New controls attempt to please critics on both sides with a balance between bland and habit-forming.",
          "content": "On Wednesday, OpenAI released GPT-5.1 Instant and GPT-5.1 Thinking, two updated versions of its flagship AI models now available in ChatGPT. The company is wrapping the models in the language of anthropomorphism, claiming that they’re warmer, more conversational, and better at following instructions. The release follows complaints earlier this year that its previous models were excessively cheerful and sycophantic, along with an opposing controversy among users over how OpenAI modified the default GPT-5 output style after several suicide lawsuits. The company now faces intense scrutiny from lawyers and regulators that could threaten its future operations. In that kind of environment, it’s difficult to just release a new AI model, throw out a few stats, and move on like the company could even a year ago. But here are the basics: The new GPT-5.1 Instant model will serve as ChatGPT’s faster default option for most tasks, while GPT-5.1 Thinking is a simulated reasoning model that attempts to handle more complex problem-solving tasks.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-1152x648.jpg",
      "popularity_score": 359.58751416666667,
      "ai_summary": [
        "OpenAI is introducing eight new personalities in GPT-5.1.",
        "The new controls aim to balance user experience and habit formation.",
        "OpenAI is trying to satisfy critics on both sides of the issue.",
        "The goal is to create a more engaging and user-friendly AI.",
        "The changes reflect ongoing efforts to refine AI behavior."
      ]
    },
    {
      "id": "cluster_31",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 22:12:36 +0000",
      "title": "With another record broken, the world’s busiest spaceport keeps getting busier",
      "neutral_headline": "World's Busiest Spaceport Breaks Records, Gets Busier",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/with-another-record-broken-the-worlds-busiest-spaceport-keeps-getting-busier/",
          "published_at": "Wed, 12 Nov 2025 22:12:36 +0000",
          "title": "With another record broken, the world’s busiest spaceport keeps getting busier",
          "standfirst": "It's not just the number of rocket launches, but how much stuff they're carrying into orbit.",
          "content": "CAPE CANAVERAL, Florida—Another Falcon 9 rocket fired off its launch pad here on Monday night, taking with it another 29 Starlink Internet satellites to orbit. This was the 94th orbital launch from Florida’s Space Coast so far in 2025, breaking the previous record for the most satellite launches in a calendar year from the world’s busiest spaceport. Monday night’s launch came two days after a Chinese Long March 11 rocket lifted off from an oceangoing platform on the opposite side of the world, marking humanity’s 255th mission to reach orbit this year, a new annual record for global launch activity. As of Wednesday, a handful of additional missions have pushed the global figure this year to 259, putting the world on pace for around 300 orbital launches by the end of 2025. This will more than double the global tally of 135 orbital launches in 2021.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/IMG_9791-1-1152x648-1762927742.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/IMG_9791-1-1152x648-1762927742.jpg",
      "popularity_score": 341.8844586111111,
      "ai_summary": [
        "The world's busiest spaceport continues to break records.",
        "The increase is due to the number of rocket launches.",
        "The amount of cargo being carried into orbit is also increasing.",
        "Spaceport activity is growing in both launch frequency and payload.",
        "The trend indicates a growing space industry."
      ]
    },
    {
      "id": "cluster_39",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 20:38:01 +0000",
      "title": "Microsoft releases update-fixing update for update-eligible Windows 10 PCs",
      "neutral_headline": "Microsoft Releases Update-Fixing Update for Windows 10",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/11/microsoft-releases-update-fixing-update-for-update-eligible-windows-10-pcs/",
          "published_at": "Wed, 12 Nov 2025 20:38:01 +0000",
          "title": "Microsoft releases update-fixing update for update-eligible Windows 10 PCs",
          "standfirst": "A bug was keeping Windows 10 PCs from enrolling in Microsoft's ESU program.",
          "content": "Officially, Windows 10 died last month, a little over a decade after its initial release. But the old operating system’s enduring popularity has prompted Microsoft to promise between one and three years of Extended Security Updates (ESUs) for many Windows 10 PCs. For individuals with Windows 10 PCs, it’s relatively easy to get an additional year of updates at no cost. Or at least, it’s supposed to be. Bugs initially identified by Windows Latest were keeping some Windows 10 PCs from successfully enrolling in the ESU program, preventing those PCs from signing up to grab the free updates. And because each Windows 10 PC has to be manually enrolled in the program, a broken enrollment process also meant broken security updates. To fix the problems, Microsoft released an update for Windows 10 22H2 (KB5071959) this week that both acknowledges and fixes an issue “where the enrollment wizard may fail during enrollment.” It’s being offered to all Windows 10 PCs regardless of whether they’re enrolled in the ESU program “as it resolves an issue that was preventing affected customers from receiving essential security updates.”Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/12/win10-new-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/12/win10-new-1152x648.jpg",
      "popularity_score": 334.3080697222222,
      "ai_summary": [
        "Microsoft released an update to fix an update issue for Windows 10 PCs.",
        "A bug prevented Windows 10 PCs from enrolling in the ESU program.",
        "The update addresses the enrollment problem.",
        "The fix ensures that eligible PCs can receive updates.",
        "Microsoft is working to maintain Windows 10 support."
      ]
    },
    {
      "id": "cluster_41",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 20:28:52 +0000",
      "title": "An explosion 92 million miles away just grounded Jeff Bezos’ New Glenn rocket",
      "neutral_headline": "Explosion Grounds Jeff Bezos' New Glenn Rocket Launch",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/an-explosion-92-million-miles-away-just-grounded-jeff-bezos-new-glenn-rocket/",
          "published_at": "Wed, 12 Nov 2025 20:28:52 +0000",
          "title": "An explosion 92 million miles away just grounded Jeff Bezos’ New Glenn rocket",
          "standfirst": "\"NASA is postponing launch until space weather conditions improve.\"",
          "content": "CAPE CANAVERAL, Florida—The second flight of Blue Origin’s New Glenn rocket was postponed again Wednesday as a supercharged wave of magnetized plasma from the Sun enveloped the Earth, triggering colorful auroral displays and concerns over possible impacts to communications, navigation, and power grids. Solar storms like the one this week can also affect satellite operations. That is the worry that caused NASA to hold off on launching a pair of science probes from Cape Canaveral Space Force Station, Florida, on Wednesday aboard Blue Origin’s New Glenn rocket. In a statement, Blue Origin said NASA, its customer on the upcoming launch, decided to postpone the mission to send the agency’s two ESCAPADE spacecraft on a journey to Mars.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Oct_2_M7pt3_Flare_171-304-131_Crop-1152x648-1762966677.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Oct_2_M7pt3_Flare_171-304-131_Crop-1152x648-1762966677.jpg",
      "popularity_score": 312.1555697222222,
      "ai_summary": [
        "An explosion 92 million miles away has delayed the New Glenn rocket launch.",
        "NASA is postponing the launch due to space weather conditions.",
        "The launch was scheduled for a specific date.",
        "Space weather conditions are impacting the launch schedule.",
        "The delay is related to solar activity."
      ]
    },
    {
      "id": "cluster_49",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 19:53:07 +0000",
      "title": "Well-received big-budget Alien Earth TV series gets a second season",
      "neutral_headline": "Alien Earth TV Series Gets Second Season",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/11/alien-earth-and-series-creator-noah-hawley-will-return-for-season-2/",
          "published_at": "Wed, 12 Nov 2025 19:53:07 +0000",
          "title": "Well-received big-budget Alien Earth TV series gets a second season",
          "standfirst": "Production will move from Thailand to London, suggesting a new setting.",
          "content": "Alien Earth will return to FX (and Disney+ and Hulu) for a second season, thanks to a new deal between Disney and series creator Noah Hawley. The new season has no air date yet, but we do know one thing about it: It will be shot in London. The first season was shot in Thailand, and most of the story took place in Southeast Asia, so the change in shooting location suggests a new setting for much of the next season. Production on season two will reportedly begin next year. For those who watched season one to its conclusion, season two probably seemed like a sure thing; the finale resolved many of the core conflicts of that first batch of episodes, but also was clearly intended to be the launching point for a new storyline in season two.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/alien-earth-facehugger-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/alien-earth-facehugger-1152x648.jpg",
      "popularity_score": 301.5597363888889,
      "ai_summary": [
        "The big-budget Alien Earth TV series has been renewed for a second season.",
        "Production will move from Thailand to London.",
        "The move suggests a change in setting for the new season.",
        "The series has been well-received by viewers.",
        "The second season is in development."
      ]
    },
    {
      "id": "cluster_57",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 19:17:52 +0000",
      "title": "Audi goes full minimalism for its first-ever Formula 1 livery",
      "neutral_headline": "Audi Unveils Minimalist Formula 1 Livery",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/11/audi-goes-full-minimalism-for-its-first-ever-formula-1-livery/",
          "published_at": "Wed, 12 Nov 2025 19:17:52 +0000",
          "title": "Audi goes full minimalism for its first-ever Formula 1 livery",
          "standfirst": "Audi says it wants to be an F1 title contender by 2030.",
          "content": "Audi provided flights from Washington, DC, to Munich and accommodation so Ars could visit its motorsports facility and see its F1 car. Ars does not accept paid editorial content. MUNICH, Germany—Audi’s long-awaited Formula 1 team gave the world its first look at what the Audi R26 will look like when it takes to the track next year. Well, sort of—the car you see here is a generic show car for the 2026 aero regulations, but the livery you see, plus the sponsors’ logos, will race next year. “By entering the pinnacle of motorsport, Audi is making a clear, ambitious statement. It is the next chapter in the company’s renewal. Formula 1 will be a catalyst for the change towards a leaner, faster, and more innovative Audi,” said Gernot Döllner, Audi’s CEO. “We are not entering Formula 1 just to be there. We want to win. At the same time, we know that you don’t become a top team in Formula 1 overnight. It takes time, perseverance, and tireless questioning of the status quo. By 2030, we want to fight for the World Championship title,” Döllner said. After the complicated liveries of cars like the R18 or Audi's Formula E program, the R26 is refreshingly simple. Credit: Jonathan Gitlin None of the sponsors have been announced yet, so the car is bare for now. Credit: Jonathan Gitlin The view Audi hopes its rivals get next year. Credit: Jonathan Gitlin Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Audi-F1-livery-reveal-8-of-9-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Audi-F1-livery-reveal-8-of-9-1152x648.jpg",
      "popularity_score": 296.9722363888889,
      "ai_summary": [
        "Audi has revealed its minimalist livery for its first Formula 1 entry.",
        "The company aims to be an F1 title contender by 2030.",
        "The livery design reflects Audi's branding.",
        "Audi is preparing for its Formula 1 debut.",
        "The team is focused on achieving success in the sport."
      ]
    },
    {
      "id": "cluster_70",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 18:37:26 +0000",
      "title": "Super Mario Galaxy Movie trailer introduces Princess Rosalina",
      "neutral_headline": "Super Mario Galaxy Movie Trailer Introduces Princess Rosalina",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/11/nintendo-drops-official-trailer-for-super-mario-galaxy-movie/",
          "published_at": "Wed, 12 Nov 2025 18:37:26 +0000",
          "title": "Super Mario Galaxy Movie trailer introduces Princess Rosalina",
          "standfirst": "It's a sequel to 2023's Super Mario Bros. Movie, which racked up $1.36 billion at the box office.",
          "content": "The Super Mario Bros. Movie dominated the box office in 2023, racking up $1.36 billion and snagging several Oscar nominations for good measure. So naturally there’s a sequel, and Nintendo just dropped the official trailer for The Super Mario Galaxy Movie, due out next spring. (Spoilers for the 2023 film below.) The first attempt at a Super Mario movie adaptation in 1993 was notoriously a dismal failure, although it still has its ’90s-nostalgic fans. But 2023’s Super Mario Bros. Movie won over gaming fans who were skeptical about another adaption—including Ars Senior Gaming Editor Kyle Orland. “This film version captures all the fun and vibrancy of the Mario games, with enough references to familiar characters, items, and locations to make even a die-hard Mario fan’s head spin,” he wrote in his 2023 review, adding that, despite a few flaws, the film was “everything that a 10-year-old version of me could ever have dreamed a Mario movie could be.”Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/galaxy6-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/galaxy6-1152x648.jpg",
      "popularity_score": 285.2983475,
      "ai_summary": [
        "A trailer for the Super Mario Galaxy Movie has been released.",
        "The movie is a sequel to the 2023 Super Mario Bros. Movie.",
        "The 2023 film earned $1.36 billion at the box office.",
        "Princess Rosalina is a featured character in the new movie.",
        "The sequel is highly anticipated by fans."
      ]
    },
    {
      "id": "cluster_66",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 18:59:38 +0000",
      "title": "Quantum computing tech keeps edging forward",
      "neutral_headline": "Quantum Computing Tech Advances with New Developments",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/11/quantum-roundup-lots-of-companies-announcing-new-tech/",
          "published_at": "Wed, 12 Nov 2025 18:59:38 +0000",
          "title": "Quantum computing tech keeps edging forward",
          "standfirst": "IBM follows through on its June promises, plus more trapped ion news.",
          "content": "The end of the year is usually a busy time in the quantum computing arena, as companies often try to announce that they’ve reached major milestones before the year wraps up. This year has been no exception. And while not all of these announcements involve interesting new architectures like the one we looked at recently, they’re a good way to mark progress in the field, and they often involve the sort of smaller, incremental steps needed to push the field forward. What follows is a quick look at a handful of announcements from the past few weeks that struck us as potentially interesting. IBM follows through IBM is one of the companies announcing a brand-new architecture this year. That’s not at all a surprise, given that the company promised to do so back in June; this week sees the company confirming that it has built the two processors it said it would earlier in the year. These include one called Loon, which is focused on the architecture that IBM will use to host error-corrected logical qubits. Loon represents two major changes for the company: a shift to nearest-neighbor connections and the addition of long-distance connections.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/IBM-Quantum-Loon-Wafer_2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/IBM-Quantum-Loon-Wafer_2-1152x648.jpg",
      "popularity_score": 277.6683475,
      "ai_summary": [
        "Quantum computing technology continues to make progress.",
        "IBM is following through on its June promises.",
        "There are also new developments in trapped ion technology.",
        "The field is seeing ongoing advancements.",
        "The developments are contributing to quantum computing progress."
      ]
    },
    {
      "id": "cluster_74",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 18:27:27 +0000",
      "title": "OpenAI slams court order that lets NYT read 20 million complete user chats",
      "neutral_headline": "OpenAI slams court order that lets NYT read 20 million complete user chats",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/11/openai-fights-order-to-hand-over-20-million-private-chatgpt-conversations/",
          "published_at": "Wed, 12 Nov 2025 18:27:27 +0000",
          "title": "OpenAI slams court order that lets NYT read 20 million complete user chats",
          "standfirst": "OpenAI: NYT wants evidence of ChatGPT users trying to get around news paywall.",
          "content": "OpenAI wants a court to reverse a ruling forcing the ChatGPT maker to give 20 million user chats to The New York Times and other news plaintiffs that sued it over alleged copyright infringement. Although OpenAI previously offered 20 million user chats as a counter to the NYT’s demand for 120 million, the AI company says a court order requiring production of the chats is too broad. “The logs at issue here are complete conversations: each log in the 20 million sample represents a complete exchange of multiple prompt-output pairs between a user and ChatGPT,” OpenAI said today in a filing in US District Court for the Southern District of New York. “Disclosure of those logs is thus much more likely to expose private information [than individual prompt-output pairs], in the same way that eavesdropping on an entire conversation reveals more private information than a 5-second conversation fragment.” OpenAI’s filing said that “more than 99.99%” of the chats “have nothing to do with this case.” It asked the district court to “vacate the order and order News Plaintiffs to respond to OpenAI’s proposal for identifying relevant logs.” OpenAI could also seek review in a federal court of appeals.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/chatgpt-app-icon-1152x648-1762971088.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/chatgpt-app-icon-1152x648-1762971088.jpg",
      "popularity_score": 275.1319586111111,
      "ai_summary": [
        "OpenAI is criticizing a court order.",
        "The order would allow the New York Times to read user chats.",
        "The NYT wants evidence of users trying to bypass paywalls.",
        "OpenAI is concerned about user privacy.",
        "The legal dispute involves user data access."
      ]
    },
    {
      "id": "cluster_76",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 18:00:43 +0000",
      "title": "Valve rejoins the VR hardware wars with standalone Steam Frame",
      "neutral_headline": "Valve Announces New Standalone VR Headset with SteamOS",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/11/valve-rejoins-the-vr-hardware-wars-with-standalone-steam-frame/",
          "published_at": "Wed, 12 Nov 2025 18:00:43 +0000",
          "title": "Valve rejoins the VR hardware wars with standalone Steam Frame",
          "standfirst": "SteamOS-powered headset sports semi-modular design, wireless \"low-latency\" PC streaming.",
          "content": "Six years ago, Valve made its second big virtual reality push, launching the Valve Index headset alongside VR blockbuster Half-Life Alyx. Since then, the company seems to have lost interest in virtual reality gaming, letting competitors like Meta release regular standalone hardware updates as the PC-tethered Index continued to age. Now, after years of rumors, Valve is finally ready to officially rejoin the VR hardware race. The Steam Frame, set to launch in early 2026, will run both VR and traditional Steam games locally through SteamOS or stream them wirelessly from a local PC. Powered by a Snapdragon 8 Gen 3 processor with 16 GB of RAM, the Steam Frame sports a 2160 x 2160 resolution display per eye at an “up to 110 degrees” field-of-view and up to 144 Hz. That’s all roughly in line with 2023’s Meta Quest 3, which runs on the slightly less performant Snapdragon XR2 Gen 2 processor. Valve’s new headset will be available in models sporting 256GB and 1TB or internal storage, both with the option for expansion via a microSD card slot. Pricing details have not yet been revealed publicly.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/SF_headsetControllers_3Q-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/SF_headsetControllers_3Q-1152x648.jpg",
      "popularity_score": 249.68640305555556,
      "ai_summary": [
        "Valve is re-entering the virtual reality hardware market with a standalone headset.",
        "The headset will run on SteamOS and feature a semi-modular design.",
        "It will support wireless, low-latency PC streaming for enhanced performance.",
        "Details about the headset's specifications and pricing are yet to be released.",
        "The new device aims to provide a more accessible VR experience for users."
      ]
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 17:14:16 +0000",
      "title": "Meta’s star AI scientist Yann LeCun plans to leave for own startup",
      "neutral_headline": "Meta AI Scientist Yann LeCun Plans to Launch Own Startup",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/11/metas-star-ai-scientist-yann-lecun-plans-to-leave-for-own-startup/",
          "published_at": "Wed, 12 Nov 2025 17:14:16 +0000",
          "title": "Meta’s star AI scientist Yann LeCun plans to leave for own startup",
          "standfirst": "AI pioneer reportedly frustrated with Meta's shift from research to rapid product releases.",
          "content": "Meta’s chief AI scientist and Turing Award winner Yann LeCun plans to leave the company to launch his own startup focused on a different type of AI called “world models,” the Financial Times reported. The French-US scientist has reportedly told associates he will depart in the coming months and is already in early talks to raise funds for the new venture. The departure comes as CEO Mark Zuckerberg radically overhauled Meta’s AI operations after deciding the company had fallen behind rivals such as OpenAI and Google. World models are hypothetical AI systems that some AI engineers expect to develop an internal “understanding” of the physical world by learning from video and spatial data rather than text alone. Unlike current large language models (such as the kind that power ChatGPT) that predict the next segment of data in a sequence, world models would ideally simulate cause-and-effect scenarios, understand physics, and enable machines to reason and plan more like animals do. LeCun has said this architecture could take a decade to fully develop. While some AI experts believe that Transformer-based AI models—such as large language models, video synthesis models, and interactive world synthesis models—have emergently modeled physics or absorbed the structural rules of the physical world from training data examples, the evidence so far generally points to sophisticated pattern-matching rather than a base understanding of how the physical world actually works.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/11/GettyImages-1691376215-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/11/GettyImages-1691376215-1152x648.jpg",
      "popularity_score": 153.91223638888889,
      "ai_summary": [
        "Yann LeCun, a prominent AI scientist, intends to leave Meta for a startup.",
        "LeCun is reportedly frustrated with Meta's shift toward product-focused releases.",
        "His departure signals a potential shift in Meta's research priorities.",
        "The new startup's focus and goals remain undisclosed at this time.",
        "LeCun is a pioneer in the field of artificial intelligence research."
      ]
    },
    {
      "id": "cluster_89",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 16:56:47 +0000",
      "title": "Good Luck, Have Fun, Don’t Die trailer ushers in AI apocalypse",
      "neutral_headline": "Trailer Released for \"Good Luck, Have Fun, Don't Die\" Film",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/11/sam-rockwells-a-time-traveler-in-good-luck-have-fun-dont-die-trailer/",
          "published_at": "Wed, 12 Nov 2025 16:56:47 +0000",
          "title": "Good Luck, Have Fun, Don’t Die trailer ushers in AI apocalypse",
          "standfirst": "\"I'm not gonna sugarcoat it. You're in for a really weird night.\"",
          "content": "Director Gore Verbinski has racked up an impressive filmography over the years, from The Ring and the first three installments of the Pirates of the Caribbean franchise to the 2011 Oscar-nominated animated Western Rango. Granted, he’s had his share of failures (*cough* The Lone Ranger *cough*), but if this trailer is any indication, Verbinski has another winner on his hands with the absurdist sci-fi dark comedy Good Luck, Have Fun, Don’t Die. Sam Rockwell stars as the otherwise unnamed “Man from the Future,” who shows up at a Los Angeles diner looking like a homeless person but claiming to be a time traveler from an apocalyptic future. He’s there to recruit the locals into his war against a rogue AI, although the diner patrons are understandably dubious about his sanity. (“I come from a nightmare apocalypse,” he assures the crowd about his grubby appearance. “This is the height of f*@ing fashion!”) Somehow, he convinces a handful of Angelenos to join his crusade, and judging by the remaining footage, all kinds of chaos breaks out. In addition to the eminently watchable Rockwell, the cast includes Haley Lu Richardson as Ingrid, Michael Pena as Mark, Zazie Beetz as Janet, and Juno Temple as Susan. Dino Fetscher, Anna Acton, Asim Chaudhury, Daniel Barnett, and Dominique Maher also appear in as-yet-undisclosed roles. Matthew Robinson (The Invention of Lying, Love and Monsters) penned the script. This is Verbinski’s first indie film, and Tom Ortenberg, CEO of distributor Briarcliff Entertainment, praised it as “wildly original, endlessly entertaining, and unlike anything audiences have seen before.” Color us intrigued.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/goodluck-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/goodluck-1152x648.jpg",
      "popularity_score": 153.6208475,
      "ai_summary": [
        "A trailer for the film \"Good Luck, Have Fun, Don't Die\" has been released.",
        "The film explores themes related to an artificial intelligence apocalypse.",
        "The trailer promises a unique and unconventional viewing experience.",
        "The release date and further details about the film are still pending.",
        "The film's title suggests a dark and potentially humorous tone."
      ]
    },
    {
      "id": "cluster_95",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 16:00:39 +0000",
      "title": "Review: New Framework Laptop 16 takes a fresh stab at the upgradeable laptop GPU",
      "neutral_headline": "Framework Laptop 16 Review Highlights Upgradeable GPU",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/11/review-new-framework-laptop-16-takes-a-fresh-stab-at-the-upgradeable-laptop-gpu/",
          "published_at": "Wed, 12 Nov 2025 16:00:39 +0000",
          "title": "Review: New Framework Laptop 16 takes a fresh stab at the upgradeable laptop GPU",
          "standfirst": "New components make it more useful and powerful but no less odd.",
          "content": "The original Framework Laptop 16 was trying to crack a problem that laptop makers have wrestled with on and off for years: Can you deliver a reasonably powerful, portable workstation and gaming laptop that supports graphics card upgrades just like a desktop PC? Specs at a glance: Framework Laptop 16 (2025) OS Windows 11 25H2 CPU AMD Ryzen AI 7 350 (4 Zen 5 cores, 4 Zen 5c cores) RAM 32GB DDR5-5600 (upgradeable) GPU AMD Radeon 860M (integrated)/Nvidia GeForce RTX 5070 Mobile (dedicated) SSD 1TB Western Digital Black SN770 Battery 85 WHr Display 16-inch 2560×1600 165 Hz matte non-touchscreen Connectivity 6x recessed USB-C ports (2x USB 4, 4x USB 3.2) with customizable “Expansion Card” dongles Weight 4.63 pounds (2.1 kg) without GPU, 5.29 pounds (2.4 kg) with GPU Price as tested Roughly $2,649 for pre-built edition; $2,517 for DIY edition with no OS Even in these days of mostly incremental, not-too-exciting GPU upgrades, the graphics card in a gaming PC or graphics-centric workstation will still feel its age faster than your CPU will. And the chance to upgrade that one component for hundreds of dollars instead of spending thousands replacing the entire machine is an appealing proposition. Upgradeable, swappable GPUs would also make your laptop more flexible—you can pick and choose from various GPUs from multiple vendors based on what you want and need, whether that’s raw performance, power efficiency, Linux support, or CUDA capabilities.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/IMG_1624-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/IMG_1624-1152x648.jpeg",
      "popularity_score": 148.68529194444443,
      "ai_summary": [
        "A review of the new Framework Laptop 16 has been published.",
        "The laptop features an upgradeable GPU, a key selling point.",
        "New components enhance the laptop's performance and functionality.",
        "The design remains somewhat unconventional despite improvements.",
        "The review assesses the laptop's overall usefulness and power."
      ]
    },
    {
      "id": "cluster_132",
      "coverage": 1,
      "updated_at": "Tue, 11 Nov 2025 21:20:32 +0000",
      "title": "Ryanair tries forcing app downloads by eliminating paper boarding passes",
      "neutral_headline": "Ryanair to Eliminate Paper Boarding Passes, Force App Use",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/11/ryanair-tries-forcing-app-downloads-by-eliminating-paper-boarding-passes/",
          "published_at": "Tue, 11 Nov 2025 21:20:32 +0000",
          "title": "Ryanair tries forcing app downloads by eliminating paper boarding passes",
          "standfirst": "Ryanair CEO admits \"there’ll be some teething problems.\"",
          "content": "Ryanair is trying to force users to download its mobile app by eliminating paper boarding passes, starting on November 12. As announced in February and subsequently delayed from earlier start dates, Europe’s biggest airline is moving to digital-only boarding passes, meaning customers will no longer be able to print physical ones. In order to access their boarding passes, Ryanair flyers will have to download Ryanair’s app. “Almost 100 percent of passengers have smartphones, and we want to move everybody onto that smartphone technology,” Ryanair CEO Michael O’Leary said recently on The Independent’s daily travel podcast.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-1200216952-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-1200216952-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Ryanair is eliminating paper boarding passes to encourage app downloads.",
        "The airline's CEO acknowledges potential \"teething problems\" with the change.",
        "The move aims to streamline boarding processes and reduce costs.",
        "Passengers will be required to use the Ryanair mobile application.",
        "The policy change is expected to affect all Ryanair flights."
      ]
    },
    {
      "id": "cluster_79",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 17:35:36 +0000",
      "title": "Corals survived past climate changes by retreating to the deeps",
      "neutral_headline": "Corals Survived Past Climate Changes by Retreating Deep",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/11/corals-survived-past-climate-changes-by-retreating-to-the-deeps/",
          "published_at": "Wed, 12 Nov 2025 17:35:36 +0000",
          "title": "Corals survived past climate changes by retreating to the deeps",
          "standfirst": "A recent die-off in Florida puts the spotlight on corals' survival strategies.",
          "content": "Scientists have found that the 2023 marine heat wave caused “functional extinction” of two Acropora reef-building coral species living in the Florida Reef, which stretches from the Dry Tortugas National Park to Miami. “At this point, we do not think there’s much of a chance for natural recovery—their numbers are so low that successful reproduction is incredibly unlikely,” said Ross Cunning, a coral biologist at the John G. Shedd Aquarium. This isn’t the first time corals have faced the borderline of extinction over the last 460 million years, and they have always managed to bounce back and recolonize habitats lost during severe climate changes. The problem is that we won’t live long enough to see them doing that again.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-1708146111-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-1708146111-1152x648.jpg",
      "popularity_score": 147.26779194444444,
      "ai_summary": [
        "Research indicates corals survived past climate changes by retreating.",
        "A recent die-off in Florida highlights coral survival strategies.",
        "Corals may have sought refuge in deeper, cooler waters.",
        "The study provides insights into coral resilience and adaptation.",
        "Understanding these strategies is crucial for conservation efforts."
      ]
    },
    {
      "id": "cluster_118",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 10:00:37 +0000",
      "title": "Google vows to stop scam E-Z Pass and USPS texts plaguing Americans",
      "neutral_headline": "Google Vows to Stop Scam E-Z Pass and USPS Texts",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/11/google-vows-to-stop-scam-e-z-pass-and-usps-texts-plaguing-americans/",
          "published_at": "Wed, 12 Nov 2025 10:00:37 +0000",
          "title": "Google vows to stop scam E-Z Pass and USPS texts plaguing Americans",
          "standfirst": "\"Phishing for dummies\" kits make it easier to scam millions, Google alleged.",
          "content": "Google is suing to stop phishing attacks that target millions globally, including campaigns that fake toll notices, offer bogus e-commerce deals, and impersonate financial institutions. In a complaint filed Wednesday, the tech giant accused “a cybercriminal group in China” of selling “phishing for dummies” kits. The kits help unsavvy fraudsters easily “execute a large-scale phishing campaign,” tricking hordes of unsuspecting people into “disclosing sensitive information like passwords, credit card numbers, or banking information, often by impersonating well-known brands, government agencies, or even people the victim knows.” These branded “Lighthouse” kits offer two versions of software, depending on whether bad actors want to launch SMS and e-commerce scams. “Members may subscribe to weekly, monthly, seasonal, annual, or permanent licenses,” Google alleged. Kits include “hundreds of templates for fake websites, domain set-up tools for those fake websites, and other features designed to dupe victims into believing they are entering sensitive information on a legitimate website.”Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-950213928-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-950213928-1152x648.jpg",
      "popularity_score": 145,
      "ai_summary": [
        "Google is working to stop scam texts impersonating E-Z Pass and USPS.",
        "\"Phishing for dummies\" kits make scams easier to execute.",
        "Google aims to protect users from fraudulent activities.",
        "The company is taking steps to identify and block these scams.",
        "Millions of Americans have been targeted by these phishing attempts."
      ]
    },
    {
      "id": "cluster_77",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 18:00:37 +0000",
      "title": "Steam Deck minus the screen: Valve announces new Steam Machine, Controller hardware",
      "neutral_headline": "Valve Announces New Steam Machine and Controller Hardware",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/11/steam-deck-minus-the-screen-valve-announces-new-steam-machine-controller-hardware/",
          "published_at": "Wed, 12 Nov 2025 18:00:37 +0000",
          "title": "Steam Deck minus the screen: Valve announces new Steam Machine, Controller hardware",
          "standfirst": "SteamOS-powered cube for your TV targets early 2026 launch, no pricing details.",
          "content": "Nearly four years after the Steam Deck changed the world of portable gaming, Valve is getting ready to release SteamOS-powered hardware designed for the living room TV, or even as a desktop PC gaming replacement. The simply named Steam Machine and Steam Controller, both planned to ship in early 2026, are “optimized for gaming on Steam and designed for players to get even more out of their Steam Library,” Valve said in a press release. A Steam Machine spec sheet shared by Valve lists a “semi-custom” six-core AMD Zen 4 CPU clocked at up to 4.8 Ghz alongside an AMD RDNA3 GPU with 28 compute units. The motherboard will include 16GB of DDR5 RAM and an additional 8GB of dedicated DDR6 VRAM for the GPU. The new hardware will come in two configurations with 512GB or 2TB of unspecified “SSD storage,” though Valve isn’t sharing pricing for either just yet. If you squint, you can make out a few ports on this unmarked black square. Credit: Valve A strip of LEDs adds a touch of color to the front face of the Steam Machine. I'm a fan of the big fan. Credit: Valve Those chips and numbers suggest the Steam Machine will have roughly the same horsepower as a mid-range desktop gaming PC from a few years back. But Valve says its “Machine”—which it ranks as “over 6x more powerful than the Steam Deck”—is powerful enough to support ray-tracing and/or 4K, 60 fps gaming using FSR upscaling.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/SM_3Q-1152x648-1762899545.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/SM_3Q-1152x648-1762899545.jpg",
      "popularity_score": 139.6847363888889,
      "ai_summary": [
        "Valve is launching a new Steam Machine and controller hardware.",
        "The Steam Machine is a SteamOS-powered cube for television use.",
        "The device is targeted for an early 2026 launch.",
        "Pricing details for the new hardware have not been released.",
        "The new controller is designed to work with the Steam Machine."
      ]
    },
    {
      "id": "cluster_129",
      "coverage": 1,
      "updated_at": "Tue, 11 Nov 2025 23:26:04 +0000",
      "title": "Original Mac calculator design came from letting Steve Jobs play with menus for 10 minutes",
      "neutral_headline": "Original Mac Calculator Design From Steve Jobs' Menu Play",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/11/original-mac-calculators-design-came-from-letting-steve-jobs-play-with-sliders-for-ten-minutes/",
          "published_at": "Tue, 11 Nov 2025 23:26:04 +0000",
          "title": "Original Mac calculator design came from letting Steve Jobs play with menus for 10 minutes",
          "standfirst": "In 1982, a young Mac developer turned Jobs into a UI designer—and accidentally invented a new technique.",
          "content": "In February 1982, Apple employee #8 Chris Espinosa faced a problem that would feel familiar to anyone who has ever had a micromanaging boss: Steve Jobs wouldn’t stop critiquing his calculator design for the Mac. After days of revision cycles, the 21-year-old programmer found an elegant solution: He built what he called the “Steve Jobs Roll Your Own Calculator Construction Set” and let Jobs design it himself. This delightful true story comes from Andy Hertzfeld’s Folklore.org, a legendary tech history site that chronicles the development of the original Macintosh, which was released in January 1984. I ran across the story again recently and thought it was worth sharing as a fun anecdote in an age where influential software designs often come by committee. Design by menu Chris Espinosa started working for Apple at age 14 in 1976 as the company’s youngest employee. By 1981, while studying at UC Berkeley, Jobs convinced Espinosa to drop out and work on the Mac team full time.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/calc_hero_1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/calc_hero_1-1152x648.jpg",
      "popularity_score": 139,
      "ai_summary": [
        "The original Mac calculator design came from Steve Jobs' input.",
        "A developer let Jobs play with menus for ten minutes.",
        "This interaction led to the accidental invention of a new technique.",
        "The event occurred in 1982 during the Mac's development.",
        "Jobs' involvement shaped the user interface design."
      ]
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 13:22:11 +0000",
      "title": "Formula with “cleanest ingredients” recalled after 15 babies get botulism",
      "neutral_headline": "Formula Recalled After 15 Babies Develop Botulism",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/11/formula-with-cleanest-ingredients-recalled-after-15-babies-get-botulism/",
          "published_at": "Wed, 12 Nov 2025 13:22:11 +0000",
          "title": "Formula with “cleanest ingredients” recalled after 15 babies get botulism",
          "standfirst": "Cases span 12 states. All affected babies have been hospitalized, but no deaths reported.",
          "content": "The maker of a specialty baby formula that touted having the “cleanest ingredients” and a “Purity Award” is recalling all of its products and lots amid an ongoing, multi-state outbreak of infant botulism. The outbreak was initially announced over the weekend by California and federal health officials. At that time, 13 cases of infant botulism had been flagged across 10 states. But on Tuesday, the outbreak expanded to 15 cases in 12 states. All 15 infants have been hospitalized, but no deaths have been reported. States reporting infant botulism linked to ByHeart formula. Credit: FDA The California Department of Public Health (CDPH) was the first to flag the outbreak. The department is the world’s sole source of the infant botulism treatment called BabyBIG, which is made of human-derived anti-botulism antibodies and is effective at easing symptoms and shortening recovery times. California health officials noted an unusual uptick in case reports and found they were linked to a specific formula: ByHeart Whole Nutrition Infant Formula. The department then did its own testing of some leftover formula, which was positive for the bacterium that causes botulism, Clostridium botulinum.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Screen-Shot-2025-11-11-at-7.10.57-PM-1084x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Screen-Shot-2025-11-11-at-7.10.57-PM-1084x648.png",
      "popularity_score": 135.04418083333334,
      "ai_summary": [
        "A formula with \"cleanest ingredients\" has been recalled.",
        "Fifteen babies across twelve states have contracted botulism.",
        "All affected babies have been hospitalized due to the illness.",
        "No deaths have been reported in connection with the recall.",
        "The recall is due to potential contamination of the formula."
      ]
    }
  ]
}