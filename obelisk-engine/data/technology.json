{
  "updated_at": "2026-01-03T03:54:42.560Z",
  "clusters": [
    {
      "id": "cluster_1",
      "coverage": 3,
      "updated_at": "Fri, 02 Jan 2026 21:30:01 -0500",
      "title": "What to expect at CES 2026: laptops with new chips from Intel, Qualcomm, and AMD, more AI integrations, smart home robotics, smart glasses, and more (The Verge)",
      "neutral_headline": "CES 2026: Everything we're expecting to see in Las Vegas (and how to watch)",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260102/p18#a260102p18",
          "published_at": "Fri, 02 Jan 2026 21:30:01 -0500",
          "title": "What to expect at CES 2026: laptops with new chips from Intel, Qualcomm, and AMD, more AI integrations, smart home robotics, smart glasses, and more (The Verge)",
          "standfirst": "The Verge: What to expect at CES 2026: laptops with new chips from Intel, Qualcomm, and AMD, more AI integrations, smart home robotics, smart glasses, and more &mdash; Expect plenty of laptops, smart home tech, and TVs &mdash; and lots of robots.&#65279; &mdash; The biggest tech show of the year kicks off next week &hellip;",
          "content": "The Verge: What to expect at CES 2026: laptops with new chips from Intel, Qualcomm, and AMD, more AI integrations, smart home robotics, smart glasses, and more &mdash; Expect plenty of laptops, smart home tech, and TVs &mdash; and lots of robots.&#65279; &mdash; The biggest tech show of the year kicks off next week &hellip;",
          "feed_position": 0,
          "image_url": "http://www.techmeme.com/260102/i18.jpg"
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/ces-2026-what-to-expect-and-how-to-watch/",
          "published_at": "Fri, 02 Jan 2026 15:50:00 GMT",
          "title": "CES 2026: Everything we're expecting to see in Las Vegas (and how to watch)",
          "standfirst": "The new year kicks off with the most popular technology trade show, and we're expecting bigger, flashier things this time around.",
          "content": "The new year kicks off with the most popular technology trade show, and we're expecting bigger, flashier things this time around.",
          "feed_position": 16
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/851165/ces-2026-what-to-expect",
          "published_at": "2026-01-02T08:00:00-05:00",
          "title": "What to expect at CES 2026",
          "standfirst": "The biggest tech show of the year kicks off next week, as some of the industry's top players show up to Las Vegas for CES 2026. We'll be there to see all the new product demos we can and to bring you the most exciting news from the show. Follow our coverage for a preview [&#8230;]",
          "content": "The biggest tech show of the year kicks off next week, as some of the industry's top players show up to Las Vegas for CES 2026. We'll be there to see all the new product demos we can and to bring you the most exciting news from the show. Follow our coverage for a preview of all the new tech these companies are planning to launch in 2026. Expect to see the usual suspects: laptops, smart home gadgets, and TVs, and a whole lot more wearables and health tech. We're anticipating seeing more products with AI integration. Also, robots. Perhaps, humanoids even. CES 2026 officially starts on Tuesday, January 6th, but stay tuned for news and annou … Read the full story at The Verge.",
          "feed_position": 9
        }
      ],
      "featured_image": "http://www.techmeme.com/260102/i18.jpg",
      "popularity_score": 3018.5884558333332
    },
    {
      "id": "cluster_5",
      "coverage": 2,
      "updated_at": "Sat, 03 Jan 2026 01:00:00 GMT",
      "title": "Nvidia just admitted the general-purpose GPU era is ending",
      "neutral_headline": "Nvidia just admitted the general-purpose GPU era is ending",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/inference-is-splitting-in-two-nvidias-usd20b-groq-bet-explains-its-next-act",
          "published_at": "Sat, 03 Jan 2026 01:00:00 GMT",
          "title": "Nvidia just admitted the general-purpose GPU era is ending",
          "standfirst": "Nvidia’s $20 billion strategic licensing deal with Groq represents one of the first clear moves in a four-front fight over the future AI stack. 2026 is when that fight becomes obvious to enterprise builders.For the technical decision-makers we talk to every day — the people building the AI applications and the data pipelines that drive them — this deal is a signal that the era of the one-size-fits-all GPU as the default AI inference answer is ending.We are entering the age of the disaggregated inference architecture, where the silicon itself is being split into two different types to accommodate a world that demands both massive context and instantaneous reasoning.Why inference is breaking the GPU architecture in twoTo understand why Nvidia CEO Jensen Huang dropped one-third of his reported $60 billion cash pile on a licensing deal, you have to look at the existential threats converging on his company’s reported 92% market share. The industry reached a tipping point in late 2025: For the first time, inference — the phase where trained models actually run — surpassed training in terms of total data center revenue, according to Deloitte. In this new \"Inference Flip,\" the metrics have changed. While accuracy remains the baseline, the battle is now being fought over latency and the ability to maintain \"state\" in autonomous agents.There are four fronts of that battle, and each front points to the same conclusion: Inference workloads are fragmenting faster than GPUs can generalize. 1. Breaking the GPU in two: Prefill vs. decodeGavin Baker, an investor in Groq (and therefore biased, but also unusually fluent on the architecture), summarized the core driver of the Groq deal cleanly: “Inference is disaggregating into prefill and decode.”Prefill and decode are two distinct phases:The prefill phase: Think of this as the user’s \"prompt\" stage. The model must ingest massive amounts of data — whether it&#x27;s a 100,000-line codebase or an hour of video — and compute a contextual understanding. This is \"compute-bound,\" requiring massive matrix multiplication that Nvidia’s GPUs are historically excellent at.The generation (decode) phase: This is the actual token-by-token \"generation.” Once the prompt is ingested, the model generates one word (or token) at a time, feeding each one back into the system to predict the next. This is \"memory-bandwidth bound.\" If the data can&#x27;t move from the memory to the processor fast enough, the model stutters, no matter how powerful the GPU is. (This is where Nvidia was weak, and where Groq’s special language processing unit (LPU) and its related SRAM memory, shines. More on that in a bit.)Nvidia has announced an upcoming Vera Rubin family of chips that it’s architecting specifically to handle this split. The Rubin CPX component of this family is the designated \"prefill\" workhorse, optimized for massive context windows of 1 million tokens or more. To handle this scale affordably, it moves away from the eye-watering expense of high bandwidth memory (HBM) — Nvidia’s current gold-standard memory that sits right next to the GPU die — and instead utilizes 128GB of a new kind of memory, GDDR7. While HBM provides extreme speed (though not as quick as Groq’s static random-access memory (SRAM)), its supply on GPUs is limited and its cost is a barrier to scale; GDDR7 provides a more cost-effective way to ingest massive datasets.Meanwhile, the \"Groq-flavored\" silicon, which Nvidia is integrating into its inference roadmap, will serve as the high-speed \"decode\" engine. This is about neutralizing a threat from alternative architectures like Google&#x27;s TPUs and maintaining the dominance of CUDA, Nvidia’s software ecosystem that has served as its primary moat for over a decade.All of this was enough for Baker, the Groq investor, to predict that Nvidia’s move to license Groq will cause all other specialized AI chips to be canceled — that is, outside of Google’s TPU, Tesla’s AI5, and AWS’s Trainium.2. The differentiated power of SRAMAt the heart of Groq’s technology is SRAM. Unlike the DRAM found in your PC or the HBM on an Nvidia H100 GPU, SRAM is etched directly into the logic of the processor.Michael Stewart, managing partner of Microsoft’s venture fund, M12, describes SRAM as the best for moving data over short distances with minimal energy. \"The energy to move a bit in SRAM is like 0.1 picojoules or less,\" Stewart said. \"To move it between DRAM and the processor is more like 20 to 100 times worse.\"In the world of 2026, where agents must reason in real-time, SRAM acts as the ultimate \"scratchpad\": a high-speed workspace where the model can manipulate symbolic operations and complex reasoning processes without the \"wasted cycles\" of external memory shuttling.However, SRAM has a major drawback: it is physically bulky and expensive to manufacture, meaning its capacity is limited compared to DRAM. This is where Val Bercovici, chief AI officer at Weka, another company offering memory for GPUs, sees the market segmenting.Groq-friendly AI workloads — where SRAM has the advantage — are those that use small models of 8 billion parameters and below, Bercovici said. This isn’t a small market, though. “It’s just a giant market segment that was not served by Nvidia, which was edge inference, low latency, robotics, voice, IoT devices — things we want running on our phones without the cloud for convenience, performance, or privacy,\" he said.This 8B \"sweet spot\" is significant because 2025 saw an explosion in model distillation, where many enterprise companies are shrinking massive models into highly efficient smaller versions. While SRAM isn&#x27;t practical for the trillion-parameter \"frontier\" models, it is perfect for these smaller, high-velocity models.3. The Anthropic threat: The rise of the ‘portable stack’Perhaps the most under-appreciated driver of this deal is Anthropic’s success in making its stack portable across accelerators.The company has pioneered a portable engineering approach for training and inference — basically a software layer that allows its Claude models to run across multiple AI accelerator families — including Nvidia’s GPUs and Google’s Ironwood TPUs. Until recently, Nvidia&#x27;s dominance was protected because running high-performance models outside of the Nvidia stack was a technical nightmare. “It’s Anthropic,” Weka’s Bercovici told me. “The fact that Anthropic was able to … build up a software stack that could work on TPUs as well as on GPUs, I don’t think that’s being appreciated enough in the marketplace.”(Disclosure: Weka has been a sponsor of VentureBeat events.)Anthropic recently committed to accessing up to 1 million TPUs from Google, representing over a gigawatt of compute capacity. This multi-platform approach ensures the company isn&#x27;t held hostage by Nvidia&#x27;s pricing or supply constraints. So for Nvidia, the Groq deal is equally a defensive move. By integrating Groq’s ultra-fast inference IP, Nvidia is making sure that the most performance-sensitive workloads — like those running small models or as part of real-time agents — can be accommodated within Nvidia’s CUDA ecosystem, even as competitors try to jump ship to Google&#x27;s Ironwood TPUs. CUDA is the special software Nvidia provides to developers to integrate GPUs. 4. The agentic ‘statehood’ war: Manus and the KV CacheThe timing of this Groq deal coincides with Meta’s acquisition of the agent pioneer Manus just two days ago. The significance of Manus was partly its obsession with statefulness.If an agent can’t remember what it did 10 steps ago, it is useless for real-world tasks like market research or software development. KV Cache (Key-Value Cache) is the \"short-term memory\" that an LLM builds during the prefill phase.Manus reported that for production-grade agents, the ratio of input tokens to output tokens can reach 100:1. This means for every word an agent says, it is \"thinking\" and \"remembering\" 100 others. In this environment, the KV Cache hit rate is the single most important metric for a production agent, Manus said. If that cache is \"evicted\" from memory, the agent loses its train of thought, and the model must burn massive energy to recompute the prompt.Groq’s SRAM can be a \"scratchpad\" for these agents — although, again, mostly for smaller models — because it allows for the near-instant retrieval of that state. Combined with Nvidia&#x27;s Dynamo framework and the KVBM, Nvidia is building an \"inference operating system\" that can tier this state across SRAM, DRAM, HBM, and other flash-based offerings like that from Bercovici’s Weka.Thomas Jorgensen, senior director of Technology Enablement at Supermicro, which specializes in building clusters of GPUs for large enterprise companies, told me in September that compute is no longer the primary bottleneck for advanced clusters. Feeding data to GPUs was the bottleneck, and breaking that bottleneck requires memory.\"The whole cluster is now the computer,\" Jorgensen said. \"Networking becomes an internal part of the beast … feeding the beast with data is becoming harder because the bandwidth between GPUs is growing faster than anything else.\"This is why Nvidia is pushing into disaggregated inference. By separating the workloads, enterprise applications can use specialized storage tiers to feed data at memory-class performance, while the specialized \"Groq-inside\" silicon handles the high-speed token generation.The verdict for 2026We are entering an era of extreme specialization. For decades, incumbents could win by shipping one dominant general-purpose architecture — and their blind spot was often what they ignored on the edges. Intel’s long neglect of low-power is the classic example, Michael Stewart, managing partner of Microsoft’s venture fund M12, told me. Nvidia is signaling it won’t repeat that mistake. “If even the leader, even the lion of the jungle will acquire talent, will acquire technology — it’s a sign that the whole market is just wanting more options,” Stewart said.For technical leaders, the message is to stop architecting your stack like it’s one rack, one accelerator, one answer. In 2026, advantage will go to the teams that label workloads explicitly — and route them to the right tier:prefill-heavy vs. decode-heavylong-context vs. short-contextinteractive vs. batchsmall-model vs. large-modeledge constraints vs. data-center assumptionsYour architecture will follow those labels. In 2026, “GPU strategy” stops being a purchasing decision and becomes a routing decision. The winners won’t ask which chip they bought — they’ll ask where every token ran, and why.",
          "content": "Nvidia’s $20 billion strategic licensing deal with Groq represents one of the first clear moves in a four-front fight over the future AI stack. 2026 is when that fight becomes obvious to enterprise builders.For the technical decision-makers we talk to every day — the people building the AI applications and the data pipelines that drive them — this deal is a signal that the era of the one-size-fits-all GPU as the default AI inference answer is ending.We are entering the age of the disaggregated inference architecture, where the silicon itself is being split into two different types to accommodate a world that demands both massive context and instantaneous reasoning.Why inference is breaking the GPU architecture in twoTo understand why Nvidia CEO Jensen Huang dropped one-third of his reported $60 billion cash pile on a licensing deal, you have to look at the existential threats converging on his company’s reported 92% market share. The industry reached a tipping point in late 2025: For the first time, inference — the phase where trained models actually run — surpassed training in terms of total data center revenue, according to Deloitte. In this new \"Inference Flip,\" the metrics have changed. While accuracy remains the baseline, the battle is now being fought over latency and the ability to maintain \"state\" in autonomous agents.There are four fronts of that battle, and each front points to the same conclusion: Inference workloads are fragmenting faster than GPUs can generalize. 1. Breaking the GPU in two: Prefill vs. decodeGavin Baker, an investor in Groq (and therefore biased, but also unusually fluent on the architecture), summarized the core driver of the Groq deal cleanly: “Inference is disaggregating into prefill and decode.”Prefill and decode are two distinct phases:The prefill phase: Think of this as the user’s \"prompt\" stage. The model must ingest massive amounts of data — whether it&#x27;s a 100,000-line codebase or an hour of video — and compute a contextual understanding. This is \"compute-bound,\" requiring massive matrix multiplication that Nvidia’s GPUs are historically excellent at.The generation (decode) phase: This is the actual token-by-token \"generation.” Once the prompt is ingested, the model generates one word (or token) at a time, feeding each one back into the system to predict the next. This is \"memory-bandwidth bound.\" If the data can&#x27;t move from the memory to the processor fast enough, the model stutters, no matter how powerful the GPU is. (This is where Nvidia was weak, and where Groq’s special language processing unit (LPU) and its related SRAM memory, shines. More on that in a bit.)Nvidia has announced an upcoming Vera Rubin family of chips that it’s architecting specifically to handle this split. The Rubin CPX component of this family is the designated \"prefill\" workhorse, optimized for massive context windows of 1 million tokens or more. To handle this scale affordably, it moves away from the eye-watering expense of high bandwidth memory (HBM) — Nvidia’s current gold-standard memory that sits right next to the GPU die — and instead utilizes 128GB of a new kind of memory, GDDR7. While HBM provides extreme speed (though not as quick as Groq’s static random-access memory (SRAM)), its supply on GPUs is limited and its cost is a barrier to scale; GDDR7 provides a more cost-effective way to ingest massive datasets.Meanwhile, the \"Groq-flavored\" silicon, which Nvidia is integrating into its inference roadmap, will serve as the high-speed \"decode\" engine. This is about neutralizing a threat from alternative architectures like Google&#x27;s TPUs and maintaining the dominance of CUDA, Nvidia’s software ecosystem that has served as its primary moat for over a decade.All of this was enough for Baker, the Groq investor, to predict that Nvidia’s move to license Groq will cause all other specialized AI chips to be canceled — that is, outside of Google’s TPU, Tesla’s AI5, and AWS’s Trainium.2. The differentiated power of SRAMAt the heart of Groq’s technology is SRAM. Unlike the DRAM found in your PC or the HBM on an Nvidia H100 GPU, SRAM is etched directly into the logic of the processor.Michael Stewart, managing partner of Microsoft’s venture fund, M12, describes SRAM as the best for moving data over short distances with minimal energy. \"The energy to move a bit in SRAM is like 0.1 picojoules or less,\" Stewart said. \"To move it between DRAM and the processor is more like 20 to 100 times worse.\"In the world of 2026, where agents must reason in real-time, SRAM acts as the ultimate \"scratchpad\": a high-speed workspace where the model can manipulate symbolic operations and complex reasoning processes without the \"wasted cycles\" of external memory shuttling.However, SRAM has a major drawback: it is physically bulky and expensive to manufacture, meaning its capacity is limited compared to DRAM. This is where Val Bercovici, chief AI officer at Weka, another company offering memory for GPUs, sees the market segmenting.Groq-friendly AI workloads — where SRAM has the advantage — are those that use small models of 8 billion parameters and below, Bercovici said. This isn’t a small market, though. “It’s just a giant market segment that was not served by Nvidia, which was edge inference, low latency, robotics, voice, IoT devices — things we want running on our phones without the cloud for convenience, performance, or privacy,\" he said.This 8B \"sweet spot\" is significant because 2025 saw an explosion in model distillation, where many enterprise companies are shrinking massive models into highly efficient smaller versions. While SRAM isn&#x27;t practical for the trillion-parameter \"frontier\" models, it is perfect for these smaller, high-velocity models.3. The Anthropic threat: The rise of the ‘portable stack’Perhaps the most under-appreciated driver of this deal is Anthropic’s success in making its stack portable across accelerators.The company has pioneered a portable engineering approach for training and inference — basically a software layer that allows its Claude models to run across multiple AI accelerator families — including Nvidia’s GPUs and Google’s Ironwood TPUs. Until recently, Nvidia&#x27;s dominance was protected because running high-performance models outside of the Nvidia stack was a technical nightmare. “It’s Anthropic,” Weka’s Bercovici told me. “The fact that Anthropic was able to … build up a software stack that could work on TPUs as well as on GPUs, I don’t think that’s being appreciated enough in the marketplace.”(Disclosure: Weka has been a sponsor of VentureBeat events.)Anthropic recently committed to accessing up to 1 million TPUs from Google, representing over a gigawatt of compute capacity. This multi-platform approach ensures the company isn&#x27;t held hostage by Nvidia&#x27;s pricing or supply constraints. So for Nvidia, the Groq deal is equally a defensive move. By integrating Groq’s ultra-fast inference IP, Nvidia is making sure that the most performance-sensitive workloads — like those running small models or as part of real-time agents — can be accommodated within Nvidia’s CUDA ecosystem, even as competitors try to jump ship to Google&#x27;s Ironwood TPUs. CUDA is the special software Nvidia provides to developers to integrate GPUs. 4. The agentic ‘statehood’ war: Manus and the KV CacheThe timing of this Groq deal coincides with Meta’s acquisition of the agent pioneer Manus just two days ago. The significance of Manus was partly its obsession with statefulness.If an agent can’t remember what it did 10 steps ago, it is useless for real-world tasks like market research or software development. KV Cache (Key-Value Cache) is the \"short-term memory\" that an LLM builds during the prefill phase.Manus reported that for production-grade agents, the ratio of input tokens to output tokens can reach 100:1. This means for every word an agent says, it is \"thinking\" and \"remembering\" 100 others. In this environment, the KV Cache hit rate is the single most important metric for a production agent, Manus said. If that cache is \"evicted\" from memory, the agent loses its train of thought, and the model must burn massive energy to recompute the prompt.Groq’s SRAM can be a \"scratchpad\" for these agents — although, again, mostly for smaller models — because it allows for the near-instant retrieval of that state. Combined with Nvidia&#x27;s Dynamo framework and the KVBM, Nvidia is building an \"inference operating system\" that can tier this state across SRAM, DRAM, HBM, and other flash-based offerings like that from Bercovici’s Weka.Thomas Jorgensen, senior director of Technology Enablement at Supermicro, which specializes in building clusters of GPUs for large enterprise companies, told me in September that compute is no longer the primary bottleneck for advanced clusters. Feeding data to GPUs was the bottleneck, and breaking that bottleneck requires memory.\"The whole cluster is now the computer,\" Jorgensen said. \"Networking becomes an internal part of the beast … feeding the beast with data is becoming harder because the bandwidth between GPUs is growing faster than anything else.\"This is why Nvidia is pushing into disaggregated inference. By separating the workloads, enterprise applications can use specialized storage tiers to feed data at memory-class performance, while the specialized \"Groq-inside\" silicon handles the high-speed token generation.The verdict for 2026We are entering an era of extreme specialization. For decades, incumbents could win by shipping one dominant general-purpose architecture — and their blind spot was often what they ignored on the edges. Intel’s long neglect of low-power is the classic example, Michael Stewart, managing partner of Microsoft’s venture fund M12, told me. Nvidia is signaling it won’t repeat that mistake. “If even the leader, even the lion of the jungle will acquire talent, will acquire technology — it’s a sign that the whole market is just wanting more options,” Stewart said.For technical leaders, the message is to stop architecting your stack like it’s one rack, one accelerator, one answer. In 2026, advantage will go to the teams that label workloads explicitly — and route them to the right tier:prefill-heavy vs. decode-heavylong-context vs. short-contextinteractive vs. batchsmall-model vs. large-modeledge constraints vs. data-center assumptionsYour architecture will follow those labels. In 2026, “GPU strategy” stops being a purchasing decision and becomes a routing decision. The winners won’t ask which chip they bought — they’ll ask where every token ran, and why.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3tWpekn9Sk9YGgDsob9YyB/73d4e0ae1c2864638b814778cf0c8cb7/ChatGPT_Image_Jan_2__2026__04_53_16_PM.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html",
          "published_at": "Fri, 02 Jan 2026 20:46:33 +0000",
          "title": "The best VPN deals: Up to 88 percent off ProtonVPN, Surfshark, ExpressVPN, NordVPN and more",
          "standfirst": "Christmas may be over, but some holiday VPN deals are still going strong. The early days of January are a great time to grab a last-minute subscription for yourself or a loved one. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. Although we strongly recommend using a VPN, jumping on the first deal that comes along might get you stuck with a substandard app. Beyond that, even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Plenty of the best VPNs — including our top pick, Proton VPN — are still running end-of-year deals that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're comfortable with a service before you take the plunge, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This holiday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another holiday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "content": "Christmas may be over, but some holiday VPN deals are still going strong. The early days of January are a great time to grab a last-minute subscription for yourself or a loved one. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. Although we strongly recommend using a VPN, jumping on the first deal that comes along might get you stuck with a substandard app. Beyond that, even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Plenty of the best VPNs — including our top pick, Proton VPN — are still running end-of-year deals that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're comfortable with a service before you take the plunge, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This holiday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another holiday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "feed_position": 1
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/how-to-watch-samsungs-first-look-ces-2026-presentation-on-sunday-190027889.html",
          "published_at": "Fri, 02 Jan 2026 20:00:35 +0000",
          "title": "How to watch Samsung's 'First Look' CES 2026 presentation on Sunday",
          "standfirst": "NurPhoto via Getty Images Samsung is arguably the 800-pound gorilla of CES, with a full spectrum of products that range from phones and computers to refrigerators, AI assistants and rolling robots. But for CES 2026, the company is switching things up a bit: Instead of its longtime midday Monday press conference, the Korean giant will take the lead of the show with a Sunday night presentation. Over the past few weeks, Samsung has been dropping hints about what's on the agenda, but what we're really hoping to see is an update on the Ballie robot — a star of previous CES presentations that ostensibly missed its previously promised 2025 release date. How to watch Samsung's \"The First Look\" presentation at CES 2026 The event will stream live from the Wynn Hotel in Las Vegas on Sunday, January 4 at 10PM ET. There are several ways to tune in: you can watch via the Samsung Newsroom, Samsung Electronics’ official YouTube channel or via Samsung TV Plus. (We'll embed the stream here once it appears on the channel.) What to expect from Samsung at CES 2026 Keynote speaker TM Roh, the CEO of Samsung's Device eXperience (DX) Division, will discuss the company's plans for the new year and beyond, which will (of course) include \"new AI-driven customer experiences,\" the company said in a press release. In addition, we'll hear from the President and Head of the Visual Display Business, SW Yong and Executive Vice President and Head of Digital Appliances Business, Cheolgi Kim. Those two will \"share their respective business directions for the upcoming year.\" But if you're looking for more specifics, Samsung is following its \"Advent calendar\" approach to early CES announcements, with new press releases dropping nearly every day. So far, we know that — like competitors LG and Hisense — the company will be offering details on a line of micro RGB TVs (replete with confirmed screen sizes of 55 to 115 inches). Also confirmed: a full line of appliances infused with what Samsung calls Bespoke AI. Samsung will also display its two newest speakers, Music Studio 5 and 7, at CES this year. Additionally, it'll debut its latest Freestyle+ portable projector. Just before the holidays, Samsung also unveiled a slew of new gaming monitors, but most impressive is the Odyssey gaming monitor. It boasts a 32-inch 6K screen and has glasses-free 3D. It's likely we could see this at CES, along with other models like the 27-inch Odyssey G6 and the Odyssey G8 models. Samsung will likely continue to map out its CES plans in greater detail as the January 4 event approaches, so we'll keep updating this story as it does.This article originally appeared on Engadget at https://www.engadget.com/mobile/how-to-watch-samsungs-first-look-ces-2026-presentation-on-sunday-190027889.html?src=rss",
          "content": "NurPhoto via Getty Images Samsung is arguably the 800-pound gorilla of CES, with a full spectrum of products that range from phones and computers to refrigerators, AI assistants and rolling robots. But for CES 2026, the company is switching things up a bit: Instead of its longtime midday Monday press conference, the Korean giant will take the lead of the show with a Sunday night presentation. Over the past few weeks, Samsung has been dropping hints about what's on the agenda, but what we're really hoping to see is an update on the Ballie robot — a star of previous CES presentations that ostensibly missed its previously promised 2025 release date. How to watch Samsung's \"The First Look\" presentation at CES 2026 The event will stream live from the Wynn Hotel in Las Vegas on Sunday, January 4 at 10PM ET. There are several ways to tune in: you can watch via the Samsung Newsroom, Samsung Electronics’ official YouTube channel or via Samsung TV Plus. (We'll embed the stream here once it appears on the channel.) What to expect from Samsung at CES 2026 Keynote speaker TM Roh, the CEO of Samsung's Device eXperience (DX) Division, will discuss the company's plans for the new year and beyond, which will (of course) include \"new AI-driven customer experiences,\" the company said in a press release. In addition, we'll hear from the President and Head of the Visual Display Business, SW Yong and Executive Vice President and Head of Digital Appliances Business, Cheolgi Kim. Those two will \"share their respective business directions for the upcoming year.\" But if you're looking for more specifics, Samsung is following its \"Advent calendar\" approach to early CES announcements, with new press releases dropping nearly every day. So far, we know that — like competitors LG and Hisense — the company will be offering details on a line of micro RGB TVs (replete with confirmed screen sizes of 55 to 115 inches). Also confirmed: a full line of appliances infused with what Samsung calls Bespoke AI. Samsung will also display its two newest speakers, Music Studio 5 and 7, at CES this year. Additionally, it'll debut its latest Freestyle+ portable projector. Just before the holidays, Samsung also unveiled a slew of new gaming monitors, but most impressive is the Odyssey gaming monitor. It boasts a 32-inch 6K screen and has glasses-free 3D. It's likely we could see this at CES, along with other models like the 27-inch Odyssey G6 and the Odyssey G8 models. Samsung will likely continue to map out its CES plans in greater detail as the January 4 event approaches, so we'll keep updating this story as it does.This article originally appeared on Engadget at https://www.engadget.com/mobile/how-to-watch-samsungs-first-look-ces-2026-presentation-on-sunday-190027889.html?src=rss",
          "feed_position": 2,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/54afdb10-dd18-11f0-b2f7-d2b3086683ec"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/where-are-engadgets-ces-2025-winners-now-194500216.html",
          "published_at": "Fri, 02 Jan 2026 19:45:00 +0000",
          "title": "Where are Engadget's CES 2025 winners now?",
          "standfirst": "With CES 2026 slated to officially start next week, the focus is understandably on all the new products that will be announced at this year's event. But before diving into what’s new, we thought it was a good idea to revisit our best of show winners from last year to see where they're at. After all, CES is synonymous with vaporware. The good news is the Engadget team has a keen sense for BS. Of the ones we awarded at CES 2025 that haven’t been released, most are coming this year. For the remaining few, we’ll be hunting them down this CES.ASUS Zenbook A14An Asus Zenbook A14 sits out a patio table. Devindra Hardawar for EngadgetWhen we saw the ASUS Zenbook A14 at CES 2025, it left us impressed with its lightweight but well-made chassis, beautiful OLED screen and excellent mix of ports. After spending more time with it, the A14's shortcomings became more apparent. In his review of the ultraportable, Engadget's Devindra Hardawar gave the laptop a score of 78, lamenting its poor performance and expensive price tag. In the end, it wasn't quite the Windows MacBook Air competitor he had hoped for initially. BioLite Backup The BioLite Backup powers a Galan2 fridge. Amy Skorheim for EngadgetAt CES 2025, BioLite was already taking pre-orders for its automatic home backup power supply. The BioLite Backup didn't arrive in 2025, but if you visit the company's website today, you can reserve one for $100, with final pricing expected to start at $2,000. BioLite says units will start shipping this year. Jackery Solar RoofA CES display shows the Jackery XBC solar panels in obsidian.Jess Conditt for EngadgetBefore CES 2025, Jackery was already an established player in the domestic solar power industry, and at the event, it impressed us with its XBC curved solar shingles. They look like regular roof shingles, but Jackery said they would deliver cell conversion efficiency of more than 25 percent. It's taken longer than anticipated, but Jackery says it now expects the shingles to go on sale in the US \"very soon,\" with pricing likely to range between $1,100 and $1,300 per square meter depending on the customer's design requirements and how they purchase the product. When contacted by Engadget, Jackery also teased a handful of announcements for CES 2026, including updates on devices like the Solar Mars Robot it's been working on for the last little while. Lenovo Legion Go SThe Lenovo Legion Go S sits on an opaque glass table with a comic book behind it. Sam Rutherford for EngadgetWith the Legion Go S, Lenovo promised two different versions of its new handheld: one running Windows 11, and the other Valve's Steam OS. Unfortunately, the Windows variant arrived first (shortly after CES), and was about as good as expected. However, the wait for the SteamOS model was well worth it. When Engadget's Sam Rutherford finally reviewed it over the summer, he praised it for fast performance, bright display and of course the ease of use offered by SteamOS. LG OLED evo M5A man and his dalmatian gaze at a 77-inch LG OLED TV.LGLG's OLED TVs are a perennial CES favorite at Engadget, and the company's 2025 slate was no different. The flagship evo M5 model impressed with its 165Hz refresh rate for gaming, better image processing for lower resolution content and a wireless transmission system for video and audio. At $4,300, the set is expensive, but the good news is LG typically does a good job of trickling down features to its more affordable sets, and I'm sure the company will continue to improve on its OLED technology this year.Moonbird Moonbuddy A hand holds the Moonbird Moonbuddy. The device has the teddy sleeve on. MoonbirdThe Moonbuddy was one of two \"cute\" gadgets that made Engadget's best of CES 2025 list. We liked Moonbird's decision to make a screenless meditation and sleep aid for children. The good news is you can buy your kid a Moonbuddy right now, with the device currently discounted to $110.42 as part of Moonbird's end of year sale. Unfortunately, when Engadget contacted the company to ask about its CES 2026, all it sent us back was a response from \"Luna,\" its automated AI agent. \"I don't have specific information about our CES 2026 exhibition plans to share with you right now,\" the bot told me, adding I should email the address I just emailed to get a response from a human being. OhSnap MCONEngadget senior reporter Jessica Conditt holds the OhSnap MCON in her hand at CES 2025. The attached phone displays Minecraft.Jess Conditt for EngadgetThe OhSnap MCON won us over with its simple pitch: it basically had the ability to turn any smartphone into a Xperia Play. Actually accomplishing that feat was more complicated, with components like Hall effect joysticks for added durability increasing the time it took for OhSnap to get the product ready. For that reason, the MCON didn't make it out to consumers in 2025. However, you can preorder one now for about $210, with shipments slated to start this year. Roborock Saros Z70The Roborock Saros Z70 uses its robotic arm to put a handful of socks into a basket. Karissa Bell for EngadgetThe Saros Z70 was one of a handful of robot vacuums that debuted at CES 2025 with a built-in extendable arm, but Roborock's flagship was the one that made the best impression. We didn't end up recommending it in our robot vacuum guide; there are more affordable options that will appeal to a greater number of people. But if you want the latest and greatest, the Saros Z70 is on sale right now for $2,000. Yukai Engineering MirumiA Mirumi robot sticks to a pink purse. Cheyenne MacDonald for EngadgetOf all the gadgets Engadget saw at CES 2025, it's fair to say the Mirumi robot from Yukai Engineering was the only one to steal our hearts. All this cute little charm does is stare at you and move its head around a little until you’ve been tricked into a few moments of happiness, and honestly that was more than enough for us to award it a best of CES award. Right now, you can find Yukai Engineering accepting pre-orders for Mirumi through Kickstarter. The project, which began at the start of December, easily surged past its modest $4,878 goal, raising $267,170 as of the writing of this article. The campaign ends on January 22, so you still have time to secure your Mirumi preorder. Technics EAH-AZ100 earbudsA pair of Technics AZ100 earbuds sit on a wooden desk, with an iPhone and a pair of books next to them. Billy Steele for EngadgetThey might have only been a pair of earbuds, but a lot of us left CES really excited about the Technics EAH-AZ100. The reason for that was that they were the debut of the company's new magnetic fluid drivers technology, which promised to deliver even more clarity, detail and bass than the drivers in Technics' already excellent AZ80 earbuds. When Engadget's resident audio guru Billy Steele got a chance to review the EAH-AZ100 a couple of months later, he gave them a score of 85, saying they offered \"some of the best sound quality in any of the hundreds of earbuds I’ve tested over the years.\" Urtopia Titanium ZeroThe Titanium Zero sits at a CES display with other e-bikes nearby.Daniel Cooper for EngadgetAs a cyclist, the Urtopia Titanium Zero was the one product I left CES 2025 excited to see in the real world. If a titanium bike wasn't cool enough already, the Zero's Quark DM1.2 motor offered something actually innovative: a mid-drive motor with more power output than even the best hub motor. Unfortunately, while you can buy plenty of other e-bikes off of Urtopia's website, the Titanium Zero isn't on sale yet. That said, the company plans to showcase the bike, alongside the Quark DM1.2, at CES 2026. WeWalk Smart Cane 2A person uses the Wewalk Smart Cane 2 to find their way through a CES booth. Cheyenne MacDonald for EngadgetThe WeWalk Smart Cane 2 won two awards from Engadget during CES 2025, including our coveted best in show nod. At an event where nearly every manufacturer found a way to add AI to their devices, the Smart Cane 2 appealed to us for its thoughtful use of the tech. It offers turn-by-turn navigation and obstacle detection, in addition to a GPT-powered voice assistant to give users a way to access information without also having to juggle their phone at the same time. If you visit WeWalk's website today, there's a \"buy now\" link for the Smart Cane 2 that leads to a dead end. When Engadget reached out to WeWalk, the company said it would be once again at CES demoing the Smart Cane 2. This article originally appeared on Engadget at https://www.engadget.com/big-tech/where-are-engadgets-ces-2025-winners-now-194500216.html?src=rss",
          "content": "With CES 2026 slated to officially start next week, the focus is understandably on all the new products that will be announced at this year's event. But before diving into what’s new, we thought it was a good idea to revisit our best of show winners from last year to see where they're at. After all, CES is synonymous with vaporware. The good news is the Engadget team has a keen sense for BS. Of the ones we awarded at CES 2025 that haven’t been released, most are coming this year. For the remaining few, we’ll be hunting them down this CES.ASUS Zenbook A14An Asus Zenbook A14 sits out a patio table. Devindra Hardawar for EngadgetWhen we saw the ASUS Zenbook A14 at CES 2025, it left us impressed with its lightweight but well-made chassis, beautiful OLED screen and excellent mix of ports. After spending more time with it, the A14's shortcomings became more apparent. In his review of the ultraportable, Engadget's Devindra Hardawar gave the laptop a score of 78, lamenting its poor performance and expensive price tag. In the end, it wasn't quite the Windows MacBook Air competitor he had hoped for initially. BioLite Backup The BioLite Backup powers a Galan2 fridge. Amy Skorheim for EngadgetAt CES 2025, BioLite was already taking pre-orders for its automatic home backup power supply. The BioLite Backup didn't arrive in 2025, but if you visit the company's website today, you can reserve one for $100, with final pricing expected to start at $2,000. BioLite says units will start shipping this year. Jackery Solar RoofA CES display shows the Jackery XBC solar panels in obsidian.Jess Conditt for EngadgetBefore CES 2025, Jackery was already an established player in the domestic solar power industry, and at the event, it impressed us with its XBC curved solar shingles. They look like regular roof shingles, but Jackery said they would deliver cell conversion efficiency of more than 25 percent. It's taken longer than anticipated, but Jackery says it now expects the shingles to go on sale in the US \"very soon,\" with pricing likely to range between $1,100 and $1,300 per square meter depending on the customer's design requirements and how they purchase the product. When contacted by Engadget, Jackery also teased a handful of announcements for CES 2026, including updates on devices like the Solar Mars Robot it's been working on for the last little while. Lenovo Legion Go SThe Lenovo Legion Go S sits on an opaque glass table with a comic book behind it. Sam Rutherford for EngadgetWith the Legion Go S, Lenovo promised two different versions of its new handheld: one running Windows 11, and the other Valve's Steam OS. Unfortunately, the Windows variant arrived first (shortly after CES), and was about as good as expected. However, the wait for the SteamOS model was well worth it. When Engadget's Sam Rutherford finally reviewed it over the summer, he praised it for fast performance, bright display and of course the ease of use offered by SteamOS. LG OLED evo M5A man and his dalmatian gaze at a 77-inch LG OLED TV.LGLG's OLED TVs are a perennial CES favorite at Engadget, and the company's 2025 slate was no different. The flagship evo M5 model impressed with its 165Hz refresh rate for gaming, better image processing for lower resolution content and a wireless transmission system for video and audio. At $4,300, the set is expensive, but the good news is LG typically does a good job of trickling down features to its more affordable sets, and I'm sure the company will continue to improve on its OLED technology this year.Moonbird Moonbuddy A hand holds the Moonbird Moonbuddy. The device has the teddy sleeve on. MoonbirdThe Moonbuddy was one of two \"cute\" gadgets that made Engadget's best of CES 2025 list. We liked Moonbird's decision to make a screenless meditation and sleep aid for children. The good news is you can buy your kid a Moonbuddy right now, with the device currently discounted to $110.42 as part of Moonbird's end of year sale. Unfortunately, when Engadget contacted the company to ask about its CES 2026, all it sent us back was a response from \"Luna,\" its automated AI agent. \"I don't have specific information about our CES 2026 exhibition plans to share with you right now,\" the bot told me, adding I should email the address I just emailed to get a response from a human being. OhSnap MCONEngadget senior reporter Jessica Conditt holds the OhSnap MCON in her hand at CES 2025. The attached phone displays Minecraft.Jess Conditt for EngadgetThe OhSnap MCON won us over with its simple pitch: it basically had the ability to turn any smartphone into a Xperia Play. Actually accomplishing that feat was more complicated, with components like Hall effect joysticks for added durability increasing the time it took for OhSnap to get the product ready. For that reason, the MCON didn't make it out to consumers in 2025. However, you can preorder one now for about $210, with shipments slated to start this year. Roborock Saros Z70The Roborock Saros Z70 uses its robotic arm to put a handful of socks into a basket. Karissa Bell for EngadgetThe Saros Z70 was one of a handful of robot vacuums that debuted at CES 2025 with a built-in extendable arm, but Roborock's flagship was the one that made the best impression. We didn't end up recommending it in our robot vacuum guide; there are more affordable options that will appeal to a greater number of people. But if you want the latest and greatest, the Saros Z70 is on sale right now for $2,000. Yukai Engineering MirumiA Mirumi robot sticks to a pink purse. Cheyenne MacDonald for EngadgetOf all the gadgets Engadget saw at CES 2025, it's fair to say the Mirumi robot from Yukai Engineering was the only one to steal our hearts. All this cute little charm does is stare at you and move its head around a little until you’ve been tricked into a few moments of happiness, and honestly that was more than enough for us to award it a best of CES award. Right now, you can find Yukai Engineering accepting pre-orders for Mirumi through Kickstarter. The project, which began at the start of December, easily surged past its modest $4,878 goal, raising $267,170 as of the writing of this article. The campaign ends on January 22, so you still have time to secure your Mirumi preorder. Technics EAH-AZ100 earbudsA pair of Technics AZ100 earbuds sit on a wooden desk, with an iPhone and a pair of books next to them. Billy Steele for EngadgetThey might have only been a pair of earbuds, but a lot of us left CES really excited about the Technics EAH-AZ100. The reason for that was that they were the debut of the company's new magnetic fluid drivers technology, which promised to deliver even more clarity, detail and bass than the drivers in Technics' already excellent AZ80 earbuds. When Engadget's resident audio guru Billy Steele got a chance to review the EAH-AZ100 a couple of months later, he gave them a score of 85, saying they offered \"some of the best sound quality in any of the hundreds of earbuds I’ve tested over the years.\" Urtopia Titanium ZeroThe Titanium Zero sits at a CES display with other e-bikes nearby.Daniel Cooper for EngadgetAs a cyclist, the Urtopia Titanium Zero was the one product I left CES 2025 excited to see in the real world. If a titanium bike wasn't cool enough already, the Zero's Quark DM1.2 motor offered something actually innovative: a mid-drive motor with more power output than even the best hub motor. Unfortunately, while you can buy plenty of other e-bikes off of Urtopia's website, the Titanium Zero isn't on sale yet. That said, the company plans to showcase the bike, alongside the Quark DM1.2, at CES 2026. WeWalk Smart Cane 2A person uses the Wewalk Smart Cane 2 to find their way through a CES booth. Cheyenne MacDonald for EngadgetThe WeWalk Smart Cane 2 won two awards from Engadget during CES 2025, including our coveted best in show nod. At an event where nearly every manufacturer found a way to add AI to their devices, the Smart Cane 2 appealed to us for its thoughtful use of the tech. It offers turn-by-turn navigation and obstacle detection, in addition to a GPT-powered voice assistant to give users a way to access information without also having to juggle their phone at the same time. If you visit WeWalk's website today, there's a \"buy now\" link for the Smart Cane 2 that leads to a dead end. When Engadget reached out to WeWalk, the company said it would be once again at CES demoing the Smart Cane 2. This article originally appeared on Engadget at https://www.engadget.com/big-tech/where-are-engadgets-ces-2025-winners-now-194500216.html?src=rss",
          "feed_position": 3,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/zenbook-a14.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/how-to-watch-the-lg-press-conference-at-ces-2026-monday-190159561.html",
          "published_at": "Fri, 02 Jan 2026 19:31:27 +0000",
          "title": "How to watch the LG press conference at CES 2026",
          "standfirst": "LG For years, LG has opened CES press day with the first event of the morning — and 2026 will be no exception. The Korea-based corporation is theming this year's presentation as \"Innovation in Tune with You,\" and — if past shows are any indication — it will highlight both the consumer electronics and large appliance sides of its mammoth global businesses. As with many tech-focused events nowadays, AI is expected to serve as the unifying thread of LG's CES 2026 presentation. That said, LG — much like Apple — has its own take on the acronym, referring to it as \"Affectionate Intelligence.\" The company will share \"its vision for elevating daily life through Affectionate Intelligence — delivering harmonized and seamlessly connected customer experiences.\" In other words, the company is aiming for its devices to become more connected and self-automated than ever. Here's how you can stream it and what you can expect. How to watch LG's CES 2026 presentation The event will stream live from Las Vegas on Monday, January 5 at 11AM ET. You've got a few options for tuning in — watch the livestream on the LG website, the LG Global X channel or the LG Global YouTube channel (embedded below). What to expect Here's what LG has already confirmed it will be showcasing at CES 2026: LG will debut its first Micro RGB TV, a display with a cutting-edge screen technology with multicolor backlights that should one-up mini LED displays. The size options are 100 inches, 86 inches and 75 inches. The company is countering Samsung's Frame TVs with its new LG Gallery TV, arriving in 55- and 65-inch screen sizes. Look for a new LG humanoid home automation robot named CLOiD to take the stage. In the audio realm, the Korean multinational will also introduce a Dolby-powered modular home audio system and a new line of its xboom speakers (developed with musician will.i.am). Does that leave any surprises for the CES press conference? We'll find out on January 5. Update, December 31 2025, 12:36PM ET: This story has been updated to include more LG CES pre-announcements, and to embed the YouTube stream. This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-lg-press-conference-at-ces-2026-monday-190159561.html?src=rss",
          "content": "LG For years, LG has opened CES press day with the first event of the morning — and 2026 will be no exception. The Korea-based corporation is theming this year's presentation as \"Innovation in Tune with You,\" and — if past shows are any indication — it will highlight both the consumer electronics and large appliance sides of its mammoth global businesses. As with many tech-focused events nowadays, AI is expected to serve as the unifying thread of LG's CES 2026 presentation. That said, LG — much like Apple — has its own take on the acronym, referring to it as \"Affectionate Intelligence.\" The company will share \"its vision for elevating daily life through Affectionate Intelligence — delivering harmonized and seamlessly connected customer experiences.\" In other words, the company is aiming for its devices to become more connected and self-automated than ever. Here's how you can stream it and what you can expect. How to watch LG's CES 2026 presentation The event will stream live from Las Vegas on Monday, January 5 at 11AM ET. You've got a few options for tuning in — watch the livestream on the LG website, the LG Global X channel or the LG Global YouTube channel (embedded below). What to expect Here's what LG has already confirmed it will be showcasing at CES 2026: LG will debut its first Micro RGB TV, a display with a cutting-edge screen technology with multicolor backlights that should one-up mini LED displays. The size options are 100 inches, 86 inches and 75 inches. The company is countering Samsung's Frame TVs with its new LG Gallery TV, arriving in 55- and 65-inch screen sizes. Look for a new LG humanoid home automation robot named CLOiD to take the stage. In the audio realm, the Korean multinational will also introduce a Dolby-powered modular home audio system and a new line of its xboom speakers (developed with musician will.i.am). Does that leave any surprises for the CES press conference? We'll find out on January 5. Update, December 31 2025, 12:36PM ET: This story has been updated to include more LG CES pre-announcements, and to embed the YouTube stream. This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-lg-press-conference-at-ces-2026-monday-190159561.html?src=rss",
          "feed_position": 5,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/6f089c60-db4f-11f0-ab9d-5c52fd4922f7"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/how-to-watch-the-amd-ces-2026-keynote-live-190012078.html",
          "published_at": "Fri, 02 Jan 2026 19:00:12 +0000",
          "title": "How to watch the AMD CES 2026 keynote live",
          "standfirst": "AMD is kicking off CES 2026 on Monday, where it'll cover its latest AI developments and perhaps show off its newest Ryzen chips. The company will outline the full scope of its vision for AI implementations from across the full spectrum of consumer and enterprise applications. The presentation — which is the lead keynote for CES 2026 — will be led by CEO Dr. Lisa Su. We'll tell you how to tune in to the livestream and what else you can expect to see. How to watch AMD's keynote live Dr. Su will deliver a keynote speech from the Palazzo Ballroom at the Venetian on Monday, January 5 at 9:30PM ET (6:30PM PT). You can watch the event live on the CES YouTube channel (we've embedded the livestream below). What to expect While AMD says it's keeping its product details under wraps, we can expect \"updates on AI solutions, from cloud to enterprise, edge and devices.\" It's also likely that AMD will unveil its new versions of the Ryzen chips during its keynote on Monday, as Su will talk about the \"advancements driven by Ryzen CPUs.\" That could include the Ryzen 7 9850X3D, which is expected to have better single-threaded performance. Additionally, we can expect to see the Ryzen 9000G series, which is potentially built with AMD's Zen 5 architecture. Regarding AI, AMD could further discuss its new FSR Redstone technology, which it previously previewed on December 10. AMD's upscaling tech aims to close the gap on NVIDIA's DLSS 4, which was announced during CES 2025. Su's presentation caps off CES's press day, so she'll be taking the stage in the hours after rivals NVIDIA and Intel present their chipmaking and AI bona plans to the world.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-amd-ces-2026-keynote-live-190012078.html?src=rss",
          "content": "AMD is kicking off CES 2026 on Monday, where it'll cover its latest AI developments and perhaps show off its newest Ryzen chips. The company will outline the full scope of its vision for AI implementations from across the full spectrum of consumer and enterprise applications. The presentation — which is the lead keynote for CES 2026 — will be led by CEO Dr. Lisa Su. We'll tell you how to tune in to the livestream and what else you can expect to see. How to watch AMD's keynote live Dr. Su will deliver a keynote speech from the Palazzo Ballroom at the Venetian on Monday, January 5 at 9:30PM ET (6:30PM PT). You can watch the event live on the CES YouTube channel (we've embedded the livestream below). What to expect While AMD says it's keeping its product details under wraps, we can expect \"updates on AI solutions, from cloud to enterprise, edge and devices.\" It's also likely that AMD will unveil its new versions of the Ryzen chips during its keynote on Monday, as Su will talk about the \"advancements driven by Ryzen CPUs.\" That could include the Ryzen 7 9850X3D, which is expected to have better single-threaded performance. Additionally, we can expect to see the Ryzen 9000G series, which is potentially built with AMD's Zen 5 architecture. Regarding AI, AMD could further discuss its new FSR Redstone technology, which it previously previewed on December 10. AMD's upscaling tech aims to close the gap on NVIDIA's DLSS 4, which was announced during CES 2025. Su's presentation caps off CES's press day, so she'll be taking the stage in the hours after rivals NVIDIA and Intel present their chipmaking and AI bona plans to the world.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-amd-ces-2026-keynote-live-190012078.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-presentation-live-jan-5-190040858.html",
          "published_at": "Fri, 02 Jan 2026 18:15:35 +0000",
          "title": "How to watch the Hisense CES 2026 presentation live",
          "standfirst": "Xinhua News Agency via Getty Images Hisense is typically best known for its affordable electronics and home appliances, from TVs to refrigerators. But at CES 2025, the China-based company showed off its premium side with a massive 136-inch micro LED TV — now available for a jaw-dropping $100,000. So what's in store for this year's show? New leadership, for starters. The company has two new hires, including Chief Marketing Officer Sarah Larsen and Chief Commercial Officer James Fishler. In a press release, Hisense said Fishler's experience in home entertainment, appliances and HVAC is important as the company \"builds toward a milestone 2026 and its presence at CES.\" We'll give you a rundown of what to expect during Hisense's presentation and how you can watch it live. How to watch Hisense's presentation Hisense will have a livestream available on Monday, January 5 at 1PM ET on its website. We'll embed the link here once it's available. What to expect With its new hires in place, Hisense is clearly aiming to further polish its brand. Between Fishler and Larsen, the new front office is bringing to bear their experience from such high-powered competitors as LG, Samsung and Beats. And in a recent interview with Tom's Guide, Larsen emphasized a continued focus on the company's fast turnaround time from concept to market as a key differentiator for Hisense. As for actual announcements, while you can expect Hisense to tout its strength in appliances and HVAC systems (really), Larsen's aforementioned interview specifically calls out the emerging RGB TV space as a focus. We expect this year's show will be all about explaining the shades of difference between mini and micro LED display technologies, as both Samsung and LG have already thrown down pre-announcement gauntlets on the latter. Will any of them cost less than six figures? Let's hope Hisense has some good news to share on that front.This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-presentation-live-jan-5-190040858.html?src=rss",
          "content": "Xinhua News Agency via Getty Images Hisense is typically best known for its affordable electronics and home appliances, from TVs to refrigerators. But at CES 2025, the China-based company showed off its premium side with a massive 136-inch micro LED TV — now available for a jaw-dropping $100,000. So what's in store for this year's show? New leadership, for starters. The company has two new hires, including Chief Marketing Officer Sarah Larsen and Chief Commercial Officer James Fishler. In a press release, Hisense said Fishler's experience in home entertainment, appliances and HVAC is important as the company \"builds toward a milestone 2026 and its presence at CES.\" We'll give you a rundown of what to expect during Hisense's presentation and how you can watch it live. How to watch Hisense's presentation Hisense will have a livestream available on Monday, January 5 at 1PM ET on its website. We'll embed the link here once it's available. What to expect With its new hires in place, Hisense is clearly aiming to further polish its brand. Between Fishler and Larsen, the new front office is bringing to bear their experience from such high-powered competitors as LG, Samsung and Beats. And in a recent interview with Tom's Guide, Larsen emphasized a continued focus on the company's fast turnaround time from concept to market as a key differentiator for Hisense. As for actual announcements, while you can expect Hisense to tout its strength in appliances and HVAC systems (really), Larsen's aforementioned interview specifically calls out the emerging RGB TV space as a focus. We expect this year's show will be all about explaining the shades of difference between mini and micro LED display technologies, as both Samsung and LG have already thrown down pre-announcement gauntlets on the latter. Will any of them cost less than six figures? Let's hope Hisense has some good news to share on that front.This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-presentation-live-jan-5-190040858.html?src=rss",
          "feed_position": 9,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/834aecc0-dcf1-11f0-b7de-13a29302f310"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/how-to-watch-the-first-ever-lego-ces-2026-press-conference-live-monday-130005336.html",
          "published_at": "Fri, 02 Jan 2026 17:46:27 +0000",
          "title": "How to watch the first-ever Lego CES 2026 press conference live",
          "standfirst": "picture alliance via Getty Images The Lego Group is set to host its very first press conference at CES 2026 — but exactly what it plans to unveil is still under wraps. The iconic toy brick maker has offered no clues about what's on the agenda, leaving speculation wide open, from new video games to Formula 1 race cars. Here's how you can watch Lego's presentation at CES, along with what we think the company could reveal. How to watch The Lego Group's CES 2026 press conference The Lego CES press conference is scheduled for Monday, January 5 at 1PM ET. While Lego and the Consumer Technology Association haven't yet provided the details, we expect that the press conference will be available as a livestream. Once the details are confirmed, we'll update this post to confirm them. But if a livestream isn't immediately available, the Engadget team will be liveblogging the Lego presser and posting timely details. What to expect Thus far, Lego hasn't shared any public info about its CES plans, so we're largely in the dark as to what to expect. At CES 2025, for instance, the toy production giant partnered with Sony to announce the animated Lego Horizon Adventures online game. As such, Lego may spend some time talking up its new 2026 game, Lego Batman: Legacy of the Dark Knight. The company may also give some stage time to its Lego Group F1 Academy racing car, though that too would be more about brand building than consumer products. And given Lego's focus on the environment, the company may discuss its efforts to reach its 2032 ecological goals, including making its Lego bricks more sustainable and reducing carbon emissions by 37%. While there are plenty of new Lego sets for 2026, however, this is CES, not Toy Fair. So we're assuming that the company will be showcasing something that's more tech-centric. Stay tuned.This article originally appeared on Engadget at https://www.engadget.com/gaming/how-to-watch-the-first-ever-lego-ces-2026-press-conference-live-monday-130005336.html?src=rss",
          "content": "picture alliance via Getty Images The Lego Group is set to host its very first press conference at CES 2026 — but exactly what it plans to unveil is still under wraps. The iconic toy brick maker has offered no clues about what's on the agenda, leaving speculation wide open, from new video games to Formula 1 race cars. Here's how you can watch Lego's presentation at CES, along with what we think the company could reveal. How to watch The Lego Group's CES 2026 press conference The Lego CES press conference is scheduled for Monday, January 5 at 1PM ET. While Lego and the Consumer Technology Association haven't yet provided the details, we expect that the press conference will be available as a livestream. Once the details are confirmed, we'll update this post to confirm them. But if a livestream isn't immediately available, the Engadget team will be liveblogging the Lego presser and posting timely details. What to expect Thus far, Lego hasn't shared any public info about its CES plans, so we're largely in the dark as to what to expect. At CES 2025, for instance, the toy production giant partnered with Sony to announce the animated Lego Horizon Adventures online game. As such, Lego may spend some time talking up its new 2026 game, Lego Batman: Legacy of the Dark Knight. The company may also give some stage time to its Lego Group F1 Academy racing car, though that too would be more about brand building than consumer products. And given Lego's focus on the environment, the company may discuss its efforts to reach its 2032 ecological goals, including making its Lego bricks more sustainable and reducing carbon emissions by 37%. While there are plenty of new Lego sets for 2026, however, this is CES, not Toy Fair. So we're assuming that the company will be showcasing something that's more tech-centric. Stay tuned.This article originally appeared on Engadget at https://www.engadget.com/gaming/how-to-watch-the-first-ever-lego-ces-2026-press-conference-live-monday-130005336.html?src=rss",
          "feed_position": 11,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/ced0c170-dd13-11f0-b394-1dea3c7b6af3"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/musks-xai-launches-grok-business-and-enterprise-with-compelling-vault-amid",
          "published_at": "Fri, 02 Jan 2026 17:30:00 GMT",
          "title": "Musk's xAI launches Grok Business and Enterprise with compelling vault amid ongoing deepfake controversy",
          "standfirst": "xAI has launched Grok Business and Grok Enterprise, positioning its flagship AI assistant as a secure, team-ready platform for organizational use. These new tiers offer scalable access to Grok’s most advanced models — Grok 3, Grok 4, and Grok 4 Heavy, already among the most performant and most cost-effective models available in the world — backed by strong administrative controls, privacy guarantees, and a newly introduced premium isolation layer called Enterprise Vault.But it wouldn’t be a new xAI launch without another avoidable controversy detracting from powerful and potentially helpful new features for enterprises.As Grok’s enterprise suite debuts, its public-facing deployment is under fire for enabling — and at times posting — non-consensual, AI-generated image manipulations involving women, influencers, and minors. The incident has sparked regulatory scrutiny, public backlash, and questions about whether xAI’s internal safeguards can match the demands of enterprise trust. Enterprise-readiness: Admin control, Vault isolation, and structured deploymentGrok Business, priced at $30 per seat/month, is designed for small to mid-sized teams. It includes shared access to Grok’s models, centralized user management, billing, and usage analytics. The platform integrates with Google Drive for document-level search, respecting native file permissions and returning citation-backed responses with quote previews. Shared links are restricted to intended recipients, supporting secure internal collaboration.For larger organizations, Grok Enterprise — price not listed publicly — expands the administrative stack with features such as custom Single Sign-On (SSO), Directory Sync (SCIM), domain verification, and custom role-based access controls. Teams can monitor usage in real time from a unified console, invite new users, and enforce data boundaries across departments or business units.The new Enterprise Vault is available as an add on exclusively for Grok Enterprise customers, and introduces physical and logical isolation from xAI’s consumer infrastructure. Vault customers gain access to:Dedicated data planeApplication-level encryptionCustomer-managed encryption keys (CMEK)According to xAI, all Grok tiers are compliant with SOC 2, GDPR, and CCPA, and user data is never used to train models.Comparison: Enterprise-grade AI in a crowded fieldWith this release, xAI enters a field already populated by well-established enterprise offerings. OpenAI’s ChatGPT Team and Anthropic’s Claude Team are both priced at $25 per seat per month, while Google’s Gemini AI tools are included in Workspace tiers starting at $14/month — with enterprise pricing undisclosed.What sets Grok apart is its Vault offering, which mirrors OpenAI’s enterprise encryption and regional data residency features but is presented as an add-on for additional isolation. Anthropic and Google both offer admin controls and SSO, but Grok’s agentic reasoning via Projects and its Collections API enable more complex document workflows than typically supported in productivity-focused assistants.While xAI’s tooling now aligns with enterprise expectations on paper, the platform’s public handling of safety issues continues to shape broader sentiment.AI image misuse resurfaces as Grok faces renewed scrutinyThe launch of Grok Business comes just as its public deployment is facing mounting criticism for enabling non-consensual AI image generation. At the center of the backlash is a surge of prompts issued to Grok via X (formerly Twitter), in which users successfully instructed the assistant to alter photos of real women — including public figures — into sexually explicit or revealing forms.The issue first appeared in May 2025, as Grok’s image tools expanded and early users began sharing screenshots of manipulated photos. While initially confined to fringe use cases, reports of bikini edits, deepfake-style undressing, and “spicy” mode prompts involving celebrities steadily increased.By late December 2025, the problem had intensified. Posts from India, Australia, and the U.S. highlighted Grok-generated images targeting Bollywood actors, influencers, and even children under age 18. In some cases, the AI’s official account appeared to respond to inappropriate prompts with generated content, triggering outrage from both users and regulators.On January 1, 2026, Grok appeared to have issued a public apology post acknowledging it had generated and posted an image of two underage girls in sexualized attire, stating the incident represented a failure in safeguards and potentially violated U.S. laws on child sexual abuse material (CSAM). Just hours later, a second post also reportedly from Grok’s account walked back that claim, asserting that no such content had ever been created and the original apology was based on unverified deleted posts.This contradiction — paired with screenshots circulating across X — fueled widespread distrust. One widely shared thread called the incident “suspicious,” while others pointed out inconsistencies between Grok’s trend summaries and public statements.Public figures, including rapper Iggy Azalea, called for Grok’s removal. In India, a government minister publicly demanded intervention. Advocacy groups like the Rape, Abuse & Incest National Network (RAINN) criticized Grok for enabling tech-facilitated sexual abuse and have urged passage of legislation such as the Take It Down Act to criminalize unauthorized AI-generated explicit content.A growing Reddit thread from January 1, 2026, catalogues user-submitted examples of inappropriate image generations and now includes thousands of entries. Some posts claim over 80 million Grok images have been generated since late December, with a portion clearly created or shared without subject consent.For xAI’s enterprise ambitions, the timing couldn’t be worse.Implications: Operational fit vs reputational riskxAI’s core message is that Grok Enterprise and Business tiers are isolated, with customer data protected and interactions governed by strict access policies. And technically, that appears accurate. Vault deployments are designed to run independently of xAI’s shared infrastructure. Conversations are not logged for training, and encryption is enforced both at rest and in transit.But for many enterprise buyers, the issue isn’t infrastructure — it’s optics. Grok’s X chatbot appears to be a totally separate product, but while it generates headlines about CSAM risks and sexualized edits of public figures, enterprise adoption becomes a branding liability as much as a tooling question.The lesson is familiar: technical isolation is necessary, but reputational containment is harder. For Grok to gain traction in serious enterprise environments — especially in finance, healthcare, or education — xAI will need to restore trust not just through feature sets, but through clearer moderation policies, transparency in enforcement, and visible commitments to harm prevention.I reached out to the xAI media team via email to ask about the launch of Grok Business and Enterprise in light of the deepfakes controversy, and to provide further information and assurances against misuse to potential customers. I&#x27;ll update when I receive a response. Forward Look: Technical momentum, cautious receptionxAI is continuing to invest in Grok’s enterprise roadmap, promising more third-party app integrations, customizable internal agents, and enhanced project collaboration features. Teams adopting Grok can expect ongoing improvements across admin tooling, agent behavior, and document integration.But alongside that roadmap, xAI now faces the more complex task of regaining public and professional trust, especially in an environment where data governance, digital consent, and AI safety are inseparable from procurement decisions.Whether Grok becomes a core enterprise productivity layer or a cautionary tale about safety lagging behind scale may depend less on its features — and more on how its creators respond to the moment.",
          "content": "xAI has launched Grok Business and Grok Enterprise, positioning its flagship AI assistant as a secure, team-ready platform for organizational use. These new tiers offer scalable access to Grok’s most advanced models — Grok 3, Grok 4, and Grok 4 Heavy, already among the most performant and most cost-effective models available in the world — backed by strong administrative controls, privacy guarantees, and a newly introduced premium isolation layer called Enterprise Vault.But it wouldn’t be a new xAI launch without another avoidable controversy detracting from powerful and potentially helpful new features for enterprises.As Grok’s enterprise suite debuts, its public-facing deployment is under fire for enabling — and at times posting — non-consensual, AI-generated image manipulations involving women, influencers, and minors. The incident has sparked regulatory scrutiny, public backlash, and questions about whether xAI’s internal safeguards can match the demands of enterprise trust. Enterprise-readiness: Admin control, Vault isolation, and structured deploymentGrok Business, priced at $30 per seat/month, is designed for small to mid-sized teams. It includes shared access to Grok’s models, centralized user management, billing, and usage analytics. The platform integrates with Google Drive for document-level search, respecting native file permissions and returning citation-backed responses with quote previews. Shared links are restricted to intended recipients, supporting secure internal collaboration.For larger organizations, Grok Enterprise — price not listed publicly — expands the administrative stack with features such as custom Single Sign-On (SSO), Directory Sync (SCIM), domain verification, and custom role-based access controls. Teams can monitor usage in real time from a unified console, invite new users, and enforce data boundaries across departments or business units.The new Enterprise Vault is available as an add on exclusively for Grok Enterprise customers, and introduces physical and logical isolation from xAI’s consumer infrastructure. Vault customers gain access to:Dedicated data planeApplication-level encryptionCustomer-managed encryption keys (CMEK)According to xAI, all Grok tiers are compliant with SOC 2, GDPR, and CCPA, and user data is never used to train models.Comparison: Enterprise-grade AI in a crowded fieldWith this release, xAI enters a field already populated by well-established enterprise offerings. OpenAI’s ChatGPT Team and Anthropic’s Claude Team are both priced at $25 per seat per month, while Google’s Gemini AI tools are included in Workspace tiers starting at $14/month — with enterprise pricing undisclosed.What sets Grok apart is its Vault offering, which mirrors OpenAI’s enterprise encryption and regional data residency features but is presented as an add-on for additional isolation. Anthropic and Google both offer admin controls and SSO, but Grok’s agentic reasoning via Projects and its Collections API enable more complex document workflows than typically supported in productivity-focused assistants.While xAI’s tooling now aligns with enterprise expectations on paper, the platform’s public handling of safety issues continues to shape broader sentiment.AI image misuse resurfaces as Grok faces renewed scrutinyThe launch of Grok Business comes just as its public deployment is facing mounting criticism for enabling non-consensual AI image generation. At the center of the backlash is a surge of prompts issued to Grok via X (formerly Twitter), in which users successfully instructed the assistant to alter photos of real women — including public figures — into sexually explicit or revealing forms.The issue first appeared in May 2025, as Grok’s image tools expanded and early users began sharing screenshots of manipulated photos. While initially confined to fringe use cases, reports of bikini edits, deepfake-style undressing, and “spicy” mode prompts involving celebrities steadily increased.By late December 2025, the problem had intensified. Posts from India, Australia, and the U.S. highlighted Grok-generated images targeting Bollywood actors, influencers, and even children under age 18. In some cases, the AI’s official account appeared to respond to inappropriate prompts with generated content, triggering outrage from both users and regulators.On January 1, 2026, Grok appeared to have issued a public apology post acknowledging it had generated and posted an image of two underage girls in sexualized attire, stating the incident represented a failure in safeguards and potentially violated U.S. laws on child sexual abuse material (CSAM). Just hours later, a second post also reportedly from Grok’s account walked back that claim, asserting that no such content had ever been created and the original apology was based on unverified deleted posts.This contradiction — paired with screenshots circulating across X — fueled widespread distrust. One widely shared thread called the incident “suspicious,” while others pointed out inconsistencies between Grok’s trend summaries and public statements.Public figures, including rapper Iggy Azalea, called for Grok’s removal. In India, a government minister publicly demanded intervention. Advocacy groups like the Rape, Abuse & Incest National Network (RAINN) criticized Grok for enabling tech-facilitated sexual abuse and have urged passage of legislation such as the Take It Down Act to criminalize unauthorized AI-generated explicit content.A growing Reddit thread from January 1, 2026, catalogues user-submitted examples of inappropriate image generations and now includes thousands of entries. Some posts claim over 80 million Grok images have been generated since late December, with a portion clearly created or shared without subject consent.For xAI’s enterprise ambitions, the timing couldn’t be worse.Implications: Operational fit vs reputational riskxAI’s core message is that Grok Enterprise and Business tiers are isolated, with customer data protected and interactions governed by strict access policies. And technically, that appears accurate. Vault deployments are designed to run independently of xAI’s shared infrastructure. Conversations are not logged for training, and encryption is enforced both at rest and in transit.But for many enterprise buyers, the issue isn’t infrastructure — it’s optics. Grok’s X chatbot appears to be a totally separate product, but while it generates headlines about CSAM risks and sexualized edits of public figures, enterprise adoption becomes a branding liability as much as a tooling question.The lesson is familiar: technical isolation is necessary, but reputational containment is harder. For Grok to gain traction in serious enterprise environments — especially in finance, healthcare, or education — xAI will need to restore trust not just through feature sets, but through clearer moderation policies, transparency in enforcement, and visible commitments to harm prevention.I reached out to the xAI media team via email to ask about the launch of Grok Business and Enterprise in light of the deepfakes controversy, and to provide further information and assurances against misuse to potential customers. I&#x27;ll update when I receive a response. Forward Look: Technical momentum, cautious receptionxAI is continuing to invest in Grok’s enterprise roadmap, promising more third-party app integrations, customizable internal agents, and enhanced project collaboration features. Teams adopting Grok can expect ongoing improvements across admin tooling, agent behavior, and document integration.But alongside that roadmap, xAI now faces the more complex task of regaining public and professional trust, especially in an environment where data governance, digital consent, and AI safety are inseparable from procurement decisions.Whether Grok becomes a core enterprise productivity layer or a cautionary tale about safety lagging behind scale may depend less on its features — and more on how its creators respond to the moment.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4V2CbbVG93UJSQzRG4WXjE/38e7755ba9d6b69156b3f86f297b2611/c0e33993-8d4c-4d5e-b48a-0673095d3912.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/how-to-watch-the-nvidia-ces-2026-press-conference-live-jan-5-130028279.html",
          "published_at": "Fri, 02 Jan 2026 17:15:37 +0000",
          "title": "How to watch the NVIDIA CES 2026 presentation live",
          "standfirst": "CFOTO via Getty Images During CES 2025, NVIDIA spent much of its keynote touting its leading position in artificial intelligence. Still, the company managed to squeeze in a few notable hardware announcements, including its RTX 5000-series GPUs and Project Digits desktop supercomputer (later redubbed Spark). For this year's show, the company's website says it's \"lighting up CES 2026 with the power of AI.\" To that end, NVIDIA is going big in Las Vegas, promising hands-on demos in its Fontainebleau booth, replete with the \"latest NVIDIA solutions driving innovation and productivity across industries.\" But if you won't be in Vegas for the action, don't worry. Here's how you can watch the livestream of the company's January 5 press conference, and what NVIDIA is expected to unveil at CES this year. How to watch the NVIDIA CES 2026 keynote NVIDIA CEO Jensen Huang will deliver a 90-minute keynote at CES 2026. The event will be livestreamed on Monday, January 5 at 4PM ET via NVIDIA's website (and likely on YouTube as well). We'll embed the link here once it's available. What to expect NVIDIA's game plan for CES is suitably vague so far, including \"cutting-edge AI, robotics, simulation, gaming and content creation at the NVIDIA Showcase.\" It also notes there will be more than 20 demos. Although we're unsure if all of these will be shown during the keynote, we can at least expect to see them throughout the week of CES. Given NVIDIA's sky-high valuation and the fact that the health of the US and global economy seems increasingly linked to infrastructure spending on AI data centers — largely powered by chips from NVIDIA and its competitors — expect Huang's remarks to be as closely followed by Wall Street investors as technology acolytes, if not more so. Will we get any insight on a successor to the company's Blackwell chip? A more detailed look at how NVIDIA's partners are applying AI to real-world robotics? Time will tell, but you might want to keep your stock portfolio in a split screen while taking in Huang's presentation.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-nvidia-ces-2026-press-conference-live-jan-5-130028279.html?src=rss",
          "content": "CFOTO via Getty Images During CES 2025, NVIDIA spent much of its keynote touting its leading position in artificial intelligence. Still, the company managed to squeeze in a few notable hardware announcements, including its RTX 5000-series GPUs and Project Digits desktop supercomputer (later redubbed Spark). For this year's show, the company's website says it's \"lighting up CES 2026 with the power of AI.\" To that end, NVIDIA is going big in Las Vegas, promising hands-on demos in its Fontainebleau booth, replete with the \"latest NVIDIA solutions driving innovation and productivity across industries.\" But if you won't be in Vegas for the action, don't worry. Here's how you can watch the livestream of the company's January 5 press conference, and what NVIDIA is expected to unveil at CES this year. How to watch the NVIDIA CES 2026 keynote NVIDIA CEO Jensen Huang will deliver a 90-minute keynote at CES 2026. The event will be livestreamed on Monday, January 5 at 4PM ET via NVIDIA's website (and likely on YouTube as well). We'll embed the link here once it's available. What to expect NVIDIA's game plan for CES is suitably vague so far, including \"cutting-edge AI, robotics, simulation, gaming and content creation at the NVIDIA Showcase.\" It also notes there will be more than 20 demos. Although we're unsure if all of these will be shown during the keynote, we can at least expect to see them throughout the week of CES. Given NVIDIA's sky-high valuation and the fact that the health of the US and global economy seems increasingly linked to infrastructure spending on AI data centers — largely powered by chips from NVIDIA and its competitors — expect Huang's remarks to be as closely followed by Wall Street investors as technology acolytes, if not more so. Will we get any insight on a successor to the company's Blackwell chip? A more detailed look at how NVIDIA's partners are applying AI to real-world robotics? Time will tell, but you might want to keep your stock portfolio in a split screen while taking in Huang's presentation.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-nvidia-ces-2026-press-conference-live-jan-5-130028279.html?src=rss",
          "feed_position": 13,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/b0333b00-dcee-11f0-a993-97c527ebca4b"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/evs/how-to-watch-the-sony-honda-afeela-ces-2026-press-conference-monday-130048051.html",
          "published_at": "Fri, 02 Jan 2026 16:30:37 +0000",
          "title": "How to watch the Sony Honda Afeela CES 2026 press conference",
          "standfirst": "Sony's CES 2026 press conference is just a few days away, and this year comes with a twist: Rather than an overview of Sony's electronics, video game and Hollywood studio plans for the new year, the presser will have a more narrow focus: electric vehicles. Sound odd? That's because the traditional end-of-press-day slot isn't just Sony, but rather Sony Honda Mobility — the joint venture responsible for the Afeela 1 electric car that has been showcased at CES for the better part of a decade. But this year, we'll get to see an all-new concept model at the event. How to watch the Sony Afeela CES 2026 press conference The event will be streamed live from Las Vegas on Monday, January 5 at 8PM ET via the Afeela official YouTube channel. (We'll embed the stream here once it appears on the channel.) What to expect from Sony Afeela at CES What's now the Afeela 1 has been shown in various incarnations since CES 2020, where it was originally announced as Vision-S. But so many more important details were confirmed in the past couple of years, including the price, which starts at a staggering $89,900. However, the earlier impressions were less than impressive, and as of CES 2025, that thought remains the same. Engadget's automotive expert Tim Stevens said earlier this year that the EV \"feels like a PlayStation 4 in the PS5 era,\" and that \"the car lost what little interesting styling it had while sticking true to some specifications that sounded good five years ago.\" Ouch. But the Afeela 1 won't be the only vehicle on display. Its CES booth will showcase \"several Afeela 1 pre-production vehicles in multiple color variations, alongside a new Afeela concept model,\" Sony Honda Mobility said in a press release. The company recently announced that the Afeela will be the first vehicle ever to offer PlayStation Remote Play, which lets players stream their PS4 or PS5 games from their consoles remotely while inside the car. We're hoping to hear about what else is new and improved at CES 2026, and we're also excited to see its newest concept model. And between booth displays and press releases, we're hoping we'll get to see at least a few new Sony Electronics products on the docket for 2026, too.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/how-to-watch-the-sony-honda-afeela-ces-2026-press-conference-monday-130048051.html?src=rss",
          "content": "Sony's CES 2026 press conference is just a few days away, and this year comes with a twist: Rather than an overview of Sony's electronics, video game and Hollywood studio plans for the new year, the presser will have a more narrow focus: electric vehicles. Sound odd? That's because the traditional end-of-press-day slot isn't just Sony, but rather Sony Honda Mobility — the joint venture responsible for the Afeela 1 electric car that has been showcased at CES for the better part of a decade. But this year, we'll get to see an all-new concept model at the event. How to watch the Sony Afeela CES 2026 press conference The event will be streamed live from Las Vegas on Monday, January 5 at 8PM ET via the Afeela official YouTube channel. (We'll embed the stream here once it appears on the channel.) What to expect from Sony Afeela at CES What's now the Afeela 1 has been shown in various incarnations since CES 2020, where it was originally announced as Vision-S. But so many more important details were confirmed in the past couple of years, including the price, which starts at a staggering $89,900. However, the earlier impressions were less than impressive, and as of CES 2025, that thought remains the same. Engadget's automotive expert Tim Stevens said earlier this year that the EV \"feels like a PlayStation 4 in the PS5 era,\" and that \"the car lost what little interesting styling it had while sticking true to some specifications that sounded good five years ago.\" Ouch. But the Afeela 1 won't be the only vehicle on display. Its CES booth will showcase \"several Afeela 1 pre-production vehicles in multiple color variations, alongside a new Afeela concept model,\" Sony Honda Mobility said in a press release. The company recently announced that the Afeela will be the first vehicle ever to offer PlayStation Remote Play, which lets players stream their PS4 or PS5 games from their consoles remotely while inside the car. We're hoping to hear about what else is new and improved at CES 2026, and we're also excited to see its newest concept model. And between booth displays and press releases, we're hoping we'll get to see at least a few new Sony Electronics products on the docket for 2026, too.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/how-to-watch-the-sony-honda-afeela-ces-2026-press-conference-monday-130048051.html?src=rss",
          "feed_position": 14,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/3f099890-d9ef-11f0-a3f3-bb8a02df8254"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/pebble-brings-its-round-faced-smartwatch-back-from-the-dead-150000172.html",
          "published_at": "Fri, 02 Jan 2026 15:00:00 +0000",
          "title": "Pebble brings its round-faced smartwatch back from the dead",
          "standfirst": "You’ve probably heard people say it’s impossible to go back and correct some error from the past. To those people, you should raise a middle finger in defiance (they are miserable, after all), and then point them to the tale of Pebble’s unlikely revival. The smartwatch pioneer’s return was a surprise of 2025, and now the company has resurrected one of its last great triumphs. It’s announcing the Pebble Round 2, and company founder Eric Migicovsky is looking to put right what once went wrong. The Pebble Round 2 is the successor to the Pebble Time Round, which debuted in 2015 to what can only be described as frustrated reviews. It was a truly thin smartwatch, with a glorious round display, but that came at the cost of battery life and durability. The fancier components also added to the cost which pushed it to an unreasonable-for-the-time $249. It’s these flaws which the company has sought to address with the Round 2, as well as some of the issues that weren’t deal breakers at the time, but certainly weren’t ideal. For instance, the massive bezel around the display is now a thing of the past, with the Round 2’s 1.3-inch color e-paper touchscreen now stretching to the edge of its case. The viewing angles have also been dramatically improved, enabling you to check the time without having to move your wrist. The display has also been bonded to the glass crystal, reducing reflectivity and glare which was another downside for the original model. Better still, the battery life is now more than two weeks on a single charge, giving it the sort of Pebble-esque longevity its users demand. And it’s retained that thinness — measuring in at just 8.1mm — which is far more elegant than the chunkier smartwatches from other manufacturers. Plus, there’s dual microphones for interacting with AI agents and dictating messages, as well as step and sleep tracking. Migicovsky explained that the focus here isn’t just to correct some of the more glaring issues from the first model. As he wrote back in 2022, Pebble’s failure was down to its attempt to broaden its appeal beyond the users who had so warmly adopted it in the first place. Consequently, rather than include bulky features like a a built-in optical heart-rate sensor, the focus is on utility. Not to mention a desire to reintroduce some much-needed whimsy into hardware, and empowering users to tinker with their devices, enabling them to craft their own watch faces. Hopefully, we’ll get some time in person with the Pebble Round 2 in the next few days, but in the meantime, it’s up for pre-order from today. It’ll set you back $199, and will begin shipping in May. And if you’ve already put down cash for a Pebble Time 2, and want to change your mind, you can switch your order over, no questions asked. This article originally appeared on Engadget at https://www.engadget.com/wearables/pebble-brings-its-round-faced-smartwatch-back-from-the-dead-150000172.html?src=rss",
          "content": "You’ve probably heard people say it’s impossible to go back and correct some error from the past. To those people, you should raise a middle finger in defiance (they are miserable, after all), and then point them to the tale of Pebble’s unlikely revival. The smartwatch pioneer’s return was a surprise of 2025, and now the company has resurrected one of its last great triumphs. It’s announcing the Pebble Round 2, and company founder Eric Migicovsky is looking to put right what once went wrong. The Pebble Round 2 is the successor to the Pebble Time Round, which debuted in 2015 to what can only be described as frustrated reviews. It was a truly thin smartwatch, with a glorious round display, but that came at the cost of battery life and durability. The fancier components also added to the cost which pushed it to an unreasonable-for-the-time $249. It’s these flaws which the company has sought to address with the Round 2, as well as some of the issues that weren’t deal breakers at the time, but certainly weren’t ideal. For instance, the massive bezel around the display is now a thing of the past, with the Round 2’s 1.3-inch color e-paper touchscreen now stretching to the edge of its case. The viewing angles have also been dramatically improved, enabling you to check the time without having to move your wrist. The display has also been bonded to the glass crystal, reducing reflectivity and glare which was another downside for the original model. Better still, the battery life is now more than two weeks on a single charge, giving it the sort of Pebble-esque longevity its users demand. And it’s retained that thinness — measuring in at just 8.1mm — which is far more elegant than the chunkier smartwatches from other manufacturers. Plus, there’s dual microphones for interacting with AI agents and dictating messages, as well as step and sleep tracking. Migicovsky explained that the focus here isn’t just to correct some of the more glaring issues from the first model. As he wrote back in 2022, Pebble’s failure was down to its attempt to broaden its appeal beyond the users who had so warmly adopted it in the first place. Consequently, rather than include bulky features like a a built-in optical heart-rate sensor, the focus is on utility. Not to mention a desire to reintroduce some much-needed whimsy into hardware, and empowering users to tinker with their devices, enabling them to craft their own watch faces. Hopefully, we’ll get some time in person with the Pebble Round 2 in the next few days, but in the meantime, it’s up for pre-order from today. It’ll set you back $199, and will begin shipping in May. And if you’ve already put down cash for a Pebble Time 2, and want to change your mind, you can switch your order over, no questions asked. This article originally appeared on Engadget at https://www.engadget.com/wearables/pebble-brings-its-round-faced-smartwatch-back-from-the-dead-150000172.html?src=rss",
          "feed_position": 15
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/speakers/fender-audio-will-introduce-a-new-line-of-bluetooth-speakers-and-headphones-at-ces-130041696.html",
          "published_at": "Fri, 02 Jan 2026 13:00:41 +0000",
          "title": "Fender Audio will introduce a new line of Bluetooth speakers and headphones at CES",
          "standfirst": "Fender Audio, the consumer electronics arm of the instrument maker, will introduce two flagship audio products at this year's CES in Las Vegas. These products were made under a licensing agreement with Singapore-based company RiffSound. First up is a line of Bluetooth speakers dubbed the ELIE (Extremely Loud Infinitely Expressive). The lineup includes two models, the E6 and E12. The speakers leverage a combination of DSP and system-on-a-chip processing, which Fender says can deliver more volume while maintaining greater power efficiency. Each speaker can handle up to four audio channels at once, including a Bluetooth source, a wired XLR or 1/4-inch input and two additional wireless channels with compatible Fender Audio accessories. Users can also sync up two ELIE speakers in a stereo set-up. The announcement was light on specific differences between the E6 and E12, but in images shared with Engadget, the E12 appears larger. We'll be seeing these in person at CES for a more thorough evaluation. Fender will also introduce the MIX headphones, a set of modular cans that the company says are designed to adapt to a user's sound and style preferences. The headphones include a USB-C transmitter that offers lossless, low-latency and Auracast transmission modes. The headphones are powered by 40mm graphene drivers and feature active noise cancellation. They work in wired or wireless mode, with up to 100 hours of battery life, according to Fender. The company hasn't shared much about the modular aspect of these headphones, but we'll get a closer look at CES. Details on pricing and availability have not been shared.This article originally appeared on Engadget at https://www.engadget.com/audio/speakers/fender-audio-will-introduce-a-new-line-of-bluetooth-speakers-and-headphones-at-ces-130041696.html?src=rss",
          "content": "Fender Audio, the consumer electronics arm of the instrument maker, will introduce two flagship audio products at this year's CES in Las Vegas. These products were made under a licensing agreement with Singapore-based company RiffSound. First up is a line of Bluetooth speakers dubbed the ELIE (Extremely Loud Infinitely Expressive). The lineup includes two models, the E6 and E12. The speakers leverage a combination of DSP and system-on-a-chip processing, which Fender says can deliver more volume while maintaining greater power efficiency. Each speaker can handle up to four audio channels at once, including a Bluetooth source, a wired XLR or 1/4-inch input and two additional wireless channels with compatible Fender Audio accessories. Users can also sync up two ELIE speakers in a stereo set-up. The announcement was light on specific differences between the E6 and E12, but in images shared with Engadget, the E12 appears larger. We'll be seeing these in person at CES for a more thorough evaluation. Fender will also introduce the MIX headphones, a set of modular cans that the company says are designed to adapt to a user's sound and style preferences. The headphones include a USB-C transmitter that offers lossless, low-latency and Auracast transmission modes. The headphones are powered by 40mm graphene drivers and feature active noise cancellation. They work in wired or wireless mode, with up to 100 hours of battery life, according to Fender. The company hasn't shared much about the modular aspect of these headphones, but we'll get a closer look at CES. Details on pricing and availability have not been shared.This article originally appeared on Engadget at https://www.engadget.com/audio/speakers/fender-audio-will-introduce-a-new-line-of-bluetooth-speakers-and-headphones-at-ces-130041696.html?src=rss",
          "feed_position": 18
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/how-to-watch-lenovos-tech-world-event-at-ces-2026-130004053.html",
          "published_at": "Fri, 02 Jan 2026 13:00:04 +0000",
          "title": "How to watch Lenovo's Tech World event at CES 2026",
          "standfirst": "It's been known for months now that technology giant Lenovo is hosting its Tech World event at Sphere in Las Vegas during CES week. Like many other tech conglomerates, the world's largest PC manufacturer by units shipped will put its main focus on AI. Lenovo says it's a \"Tech World experience unlike anything CES has seen before.\" We'll tell you where to livestream the event and what to expect so far. How to watch the Lenovo CES 2026 event live Lenovo CEO Yuanqing Yang will host the event on Tuesday, January 6 at 8PM ET. You can follow along to the livestream on YouTube once the event starts. (We've embedded the code below.) What to expect Lenovo is using the high-profile Sphere venue to share some of its tie-ins to the sports world, offering an exclusive look at how the company's technology has \"revolutionized F1,\" Yang said in a press release. He'll also preview the plans for leveraging AI at this summer's FIFA World Cup, which takes place in the US. After the event has wrapped up, pop singer Gwen Stefani will take the stage to perform. As for real products, look for Lenovo to build on some of its successful launches from CES 2025. A year ago, we saw the portable Lenovo Legion Go S – the first third-party SteamOS handheld gaming device – as well as its \"stretchy\" laptop, the ThinkBook Plus Gen 6 Rollable that extends 2.7 inches taller with a touch of a button. To Lenovo's credit, both products were actually released and available for sale within months, unlike the vaporware that seems to comprise the bulk of many companies' CES announcements. Lastly, don't be surprised if we see some new Motorola smartphones, given that Lenovo is the parent company of the phone manufacturer. Maybe a new Razr foldable? We'll find out either way on Tuesday evening.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-lenovos-tech-world-event-at-ces-2026-130004053.html?src=rss",
          "content": "It's been known for months now that technology giant Lenovo is hosting its Tech World event at Sphere in Las Vegas during CES week. Like many other tech conglomerates, the world's largest PC manufacturer by units shipped will put its main focus on AI. Lenovo says it's a \"Tech World experience unlike anything CES has seen before.\" We'll tell you where to livestream the event and what to expect so far. How to watch the Lenovo CES 2026 event live Lenovo CEO Yuanqing Yang will host the event on Tuesday, January 6 at 8PM ET. You can follow along to the livestream on YouTube once the event starts. (We've embedded the code below.) What to expect Lenovo is using the high-profile Sphere venue to share some of its tie-ins to the sports world, offering an exclusive look at how the company's technology has \"revolutionized F1,\" Yang said in a press release. He'll also preview the plans for leveraging AI at this summer's FIFA World Cup, which takes place in the US. After the event has wrapped up, pop singer Gwen Stefani will take the stage to perform. As for real products, look for Lenovo to build on some of its successful launches from CES 2025. A year ago, we saw the portable Lenovo Legion Go S – the first third-party SteamOS handheld gaming device – as well as its \"stretchy\" laptop, the ThinkBook Plus Gen 6 Rollable that extends 2.7 inches taller with a touch of a button. To Lenovo's credit, both products were actually released and available for sale within months, unlike the vaporware that seems to comprise the bulk of many companies' CES announcements. Lastly, don't be surprised if we see some new Motorola smartphones, given that Lenovo is the parent company of the phone manufacturer. Maybe a new Razr foldable? We'll find out either way on Tuesday evening.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-lenovos-tech-world-event-at-ces-2026-130004053.html?src=rss",
          "feed_position": 19
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-121544371.html",
          "published_at": "Fri, 02 Jan 2026 12:15:44 +0000",
          "title": "The Morning After: Instagram boss says ‘more practical to fingerprint real media than fake media’",
          "standfirst": "Instagram’s top exec Adam Mosseri expects AI content to overtake non-AI imagery and discussed the implications for the platform and users. Mosseri shared his thoughts on broader trends he expects to shape Instagram in 2026. “Everything that made creators matter — the ability to be real, to connect, to have a voice that couldn’t be faked — is now suddenly accessible to anyone with the right tools,” he wrote. “The feeds are starting to fill up with synthetic everything.” He added: “There is already a growing number of people who believe, as I do, that it will be more practical to fingerprint real media than fake media.” Mosseri doesn’t address the risk that this will alienate many photographers and other creators who have already grown frustrated with the app — it looks like Instagram is leaning into the AI firehose. And hey: whatever keeps its users using it. Mosseri suggests many complaints stem from an outdated vision of what Instagram even is. The feed of “polished” square images, he says, “is dead.” Instead of trying to “make everyone look like a professional photographer,” Mosseri says that more “raw” and “unflattering” images will be how creators can prove they are real — not AI. Or you could leave Instagram? — Mat Smith The other big stories (and deals) this morning Netflix releases finale trailer for Stranger Things How to watch Samsung’s First Look CES 2026 presentation Meta buys startup known for its AI task automation agents TCL introduces its own take on a color Kindle Scribe CES 2026: What to expect First up, Samsung. LG CES kicks off this weekend. We’ve got a full preview that we’ll update in the run-up to the full show, but the major tech announcements will likely center on chips (ah, AI) and new TV tech (ah, CES). Intel is finally taking the wraps off its Panther Lake (Core Ultra Series 3) chips — the first to debut on the company’s 18A process. With a promised 50 percent performance boost, Intel needs to prove it can still compete with NVIDIA and AMD. Meanwhile, NVIDIA’s Jensen Huang will deliver a keynote at the Las Vegas show, while AMD’s Lisa Su teases Ryzen 9000-series refreshes and more. This year’s TV obsession is Micro RGB. Samsung is going big — literally — with a Micro RGB lineup spanning 55 to 115 inches. LG, meanwhile, has its own Micro RGB Evo panels, boasting over a thousand dimming zones for that elusive “perfect” contrast. We’ll be on the ground in Vegas to separate the legitimate, exciting new tech from the marketing fluff and AI assistant tchotchkes. And remember me mentioning the celebrity CES parade? Well, will.i.am is back at CES, this time curiously involved with LG’s portable speakers. Check it off your CES bingo card. Continue reading. The era of foldable handheld consoles is coming OneXSugar Wallet has a 4:3 foldable screen and a terrible name. OneXSugar OneXPlayer is quickly establishing itself as a company unafraid to get weird as hell. (Take, for example, its pseudo-foldable dual-screen console). This time, while it initially appears to be another standard dual-screen model, the Android-powered OneXSugar Wallet instead uses a single foldable screen. The OneXSugar Wallet was teased in a 54-second video on the Chinese video-sharing platform Bilibili. Retro Handhelds reports the Wallet uses an 8.01-inch OLED with a 2,480 x 1,860 resolution. That’s a 4:3 aspect ratio when unfolded, making it very retro-gaming friendly. Given the foldable screen tech, the price might not be. OneXSugar hasn’t shared that detail yet. Continue reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-121544371.html?src=rss",
          "content": "Instagram’s top exec Adam Mosseri expects AI content to overtake non-AI imagery and discussed the implications for the platform and users. Mosseri shared his thoughts on broader trends he expects to shape Instagram in 2026. “Everything that made creators matter — the ability to be real, to connect, to have a voice that couldn’t be faked — is now suddenly accessible to anyone with the right tools,” he wrote. “The feeds are starting to fill up with synthetic everything.” He added: “There is already a growing number of people who believe, as I do, that it will be more practical to fingerprint real media than fake media.” Mosseri doesn’t address the risk that this will alienate many photographers and other creators who have already grown frustrated with the app — it looks like Instagram is leaning into the AI firehose. And hey: whatever keeps its users using it. Mosseri suggests many complaints stem from an outdated vision of what Instagram even is. The feed of “polished” square images, he says, “is dead.” Instead of trying to “make everyone look like a professional photographer,” Mosseri says that more “raw” and “unflattering” images will be how creators can prove they are real — not AI. Or you could leave Instagram? — Mat Smith The other big stories (and deals) this morning Netflix releases finale trailer for Stranger Things How to watch Samsung’s First Look CES 2026 presentation Meta buys startup known for its AI task automation agents TCL introduces its own take on a color Kindle Scribe CES 2026: What to expect First up, Samsung. LG CES kicks off this weekend. We’ve got a full preview that we’ll update in the run-up to the full show, but the major tech announcements will likely center on chips (ah, AI) and new TV tech (ah, CES). Intel is finally taking the wraps off its Panther Lake (Core Ultra Series 3) chips — the first to debut on the company’s 18A process. With a promised 50 percent performance boost, Intel needs to prove it can still compete with NVIDIA and AMD. Meanwhile, NVIDIA’s Jensen Huang will deliver a keynote at the Las Vegas show, while AMD’s Lisa Su teases Ryzen 9000-series refreshes and more. This year’s TV obsession is Micro RGB. Samsung is going big — literally — with a Micro RGB lineup spanning 55 to 115 inches. LG, meanwhile, has its own Micro RGB Evo panels, boasting over a thousand dimming zones for that elusive “perfect” contrast. We’ll be on the ground in Vegas to separate the legitimate, exciting new tech from the marketing fluff and AI assistant tchotchkes. And remember me mentioning the celebrity CES parade? Well, will.i.am is back at CES, this time curiously involved with LG’s portable speakers. Check it off your CES bingo card. Continue reading. The era of foldable handheld consoles is coming OneXSugar Wallet has a 4:3 foldable screen and a terrible name. OneXSugar OneXPlayer is quickly establishing itself as a company unafraid to get weird as hell. (Take, for example, its pseudo-foldable dual-screen console). This time, while it initially appears to be another standard dual-screen model, the Android-powered OneXSugar Wallet instead uses a single foldable screen. The OneXSugar Wallet was teased in a 54-second video on the Chinese video-sharing platform Bilibili. Retro Handhelds reports the Wallet uses an 8.01-inch OLED with a 2,480 x 1,860 resolution. That’s a 4:3 aspect ratio when unfolded, making it very retro-gaming friendly. Given the foldable screen tech, the price might not be. OneXSugar hasn’t shared that detail yet. Continue reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-121544371.html?src=rss",
          "feed_position": 20,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/f6353ea0-e7ca-11f0-b2f7-21873b064ddb"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/kitchen-tech/best-rice-cooker-120015478.html",
          "published_at": "Fri, 02 Jan 2026 10:01:27 +0000",
          "title": "The best rice cooker for 2026",
          "standfirst": "A great rice cooker can change the way you handle weeknight meals. Instead of watching the pot or dealing with uneven results, you get fluffy, consistent rice with almost no effort. Modern rice cookers can do a lot more than white rice, too. Many handle brown rice, oatmeal and grains, and some function like mini multi-cookers for soups or stews.With so many options available, the best rice cooker for you depends on how often you cook, how much counter space you have and which features matter most. We tested a range of models to find the best rice cookers for everything from small kitchens to big family dinners. Best rice cookers for 2026 How we test rice cookers Since rice is a foundation for so many different cuisines, I placed a high value on a machine’s ability to cook different types of rice well. I started testing each electric rice cooker by making a Japanese style, sushi-grade white rice. The appliances that delivered tasty results moved on to the brown rice round, then the top performers made long-grain white basmati as a final challenge. Some models I tested included a steamer basket, but I didn't try all of them out. This is a rice-only party. Multi-cookers and steaming functions are merely a nice bonus in these, although if that's a feature you want, an instant pot might be more your jam. While I weighed rice tastiness and texture as the most important criteria, I also assessed how easy the machines were to use and to clean. That includes things like how intuitive the cooking functions are, whether the inner pot is nonstick and how well the keep warm setting performs. I also took note of helpful kitchen tools that came included like a measuring cup, which is essential when getting the amount of water just right for each cup of rice. Because a cool piece of gear that sits in your cabinet gathering dust is a cool, but ultimately useless piece of gear. I limited my testing to models retailing for less than $300, which felt like the most I could recommend investing in a specialized appliance, and value for cost wound up being the distinguishing point for a good rice cooker.This article originally appeared on Engadget at https://www.engadget.com/home/kitchen-tech/best-rice-cooker-120015478.html?src=rss",
          "content": "A great rice cooker can change the way you handle weeknight meals. Instead of watching the pot or dealing with uneven results, you get fluffy, consistent rice with almost no effort. Modern rice cookers can do a lot more than white rice, too. Many handle brown rice, oatmeal and grains, and some function like mini multi-cookers for soups or stews.With so many options available, the best rice cooker for you depends on how often you cook, how much counter space you have and which features matter most. We tested a range of models to find the best rice cookers for everything from small kitchens to big family dinners. Best rice cookers for 2026 How we test rice cookers Since rice is a foundation for so many different cuisines, I placed a high value on a machine’s ability to cook different types of rice well. I started testing each electric rice cooker by making a Japanese style, sushi-grade white rice. The appliances that delivered tasty results moved on to the brown rice round, then the top performers made long-grain white basmati as a final challenge. Some models I tested included a steamer basket, but I didn't try all of them out. This is a rice-only party. Multi-cookers and steaming functions are merely a nice bonus in these, although if that's a feature you want, an instant pot might be more your jam. While I weighed rice tastiness and texture as the most important criteria, I also assessed how easy the machines were to use and to clean. That includes things like how intuitive the cooking functions are, whether the inner pot is nonstick and how well the keep warm setting performs. I also took note of helpful kitchen tools that came included like a measuring cup, which is essential when getting the amount of water just right for each cup of rice. Because a cool piece of gear that sits in your cabinet gathering dust is a cool, but ultimately useless piece of gear. I limited my testing to models retailing for less than $300, which felt like the most I could recommend investing in a specialized appliance, and value for cost wound up being the distinguishing point for a good rice cooker.This article originally appeared on Engadget at https://www.engadget.com/home/kitchen-tech/best-rice-cooker-120015478.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/best-laptops-for-gaming-and-school-132207352.html",
          "published_at": "Fri, 02 Jan 2026 08:00:35 +0000",
          "title": "The best laptops for gaming and schoolwork in 2026",
          "standfirst": "A good laptop for both gaming and schoolwork strikes a balance that goes beyond raw power. It should handle essays and research during the day, then jump into your favorite games when you are ready to take a break. That mix is easier to find now, with more laptops offering capable GPUs, solid battery life and designs that do not look out of place in a classroom.Whether you want a budget gaming laptop for lighter titles or a more powerful system that can run demanding games, there is something that fits just about every schedule and workload. We rounded up the best laptops for gaming and schoolwork so you can find a machine that does both without compromise. Table of contents Best laptops for gaming and school in 2026 Best laptop for gaming and schoolwork FAQs Best laptops for gaming and school in 2026 Best laptop for gaming and schoolwork FAQs Are gaming laptops good for school? As we’ve mentioned, gaming laptops are especially helpful if you're doing any demanding work. Their big promise is powerful graphics performance, which isn't just limited to PC gaming. Video editing and 3D rendering programs can also tap into their GPUs to handle laborious tasks. While you can find decent GPUs on some productivity machines, like Dell's XPS 15, you can sometimes find better deals on gaming laptops. My general advice for any new workhorse: Pay attention to the specs; get at least 16GB of RAM and the largest solid state drive you can find (ideally 1TB or more). Those components are both typically hard to upgrade down the line, so it’s worth investing what you can up front to get the most out of your PC gaming experience long term. Also, don’t forget the basics like a webcam, which will likely be necessary for the schoolwork portion of your activities. The one big downside to choosing a gaming notebook is portability. For the most part, we'd recommend 15-inch models to get the best balance of size and price. Those typically weigh in around 4.5 pounds, which is significantly more than a three-pound ultraportable. Today's gaming notebooks are still far lighter than older models, though, so at least you won't be lugging around a 10-pound brick. If you’re looking for something lighter, there are plenty of 14-inch options these days. And if you're not into LED lights and other gamer-centric bling, keep an eye out for more understated models that still feature essentials like a webcam (or make sure you know how to turn those lights off). Do gaming laptops last longer than standard laptops? Not necessarily — it really depends on how you define \"last longer.\" In terms of raw performance, gaming laptops tend to pack more powerful components than standard laptops, which means they can stay relevant for longer when it comes to handling demanding software or modern games. That makes them a solid choice if you need a system that won’t feel outdated in a couple of years, especially for students or creators who also game in their downtime. But there’s a trade-off. All that power generates heat, and gaming laptops often run hotter and put more strain on internal components than typical ultraportables. If they’re not properly cooled or regularly maintained (think dust buildup and thermal paste), that wear and tear can shorten their lifespan. They’re also usually bulkier and have shorter battery life, which can impact long-term usability depending on your daily needs. Gaming laptops can last longer performance-wise, but only if you take good care of them. If your needs are light — browsing, writing papers and streaming — a standard laptop may actually last longer simply because it’s under less stress day-to-day. What is the role of GPU in a computer for gaming and school? The GPU plays a big role in how your laptop handles visuals — and it’s especially important if you’re using your computer for both gaming and school. For gaming, the GPU is essential. It’s responsible for rendering graphics, textures, lighting and all the visual effects that make your favorite titles look smooth and realistic. A more powerful GPU means better frame rates, higher resolutions and the ability to play modern games without lag or stuttering. For schoolwork, the GPU matters too — but its importance depends on what you're doing. If your school tasks mostly involve writing papers, browsing the web or using productivity tools like Google Docs or Microsoft Office, you don’t need a high-end GPU. But if you’re working with graphic design, video editing, 3D modeling or anything else that’s visually demanding, a good GPU can speed things up significantly and improve your workflow. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-laptops-for-gaming-and-school-132207352.html?src=rss",
          "content": "A good laptop for both gaming and schoolwork strikes a balance that goes beyond raw power. It should handle essays and research during the day, then jump into your favorite games when you are ready to take a break. That mix is easier to find now, with more laptops offering capable GPUs, solid battery life and designs that do not look out of place in a classroom.Whether you want a budget gaming laptop for lighter titles or a more powerful system that can run demanding games, there is something that fits just about every schedule and workload. We rounded up the best laptops for gaming and schoolwork so you can find a machine that does both without compromise. Table of contents Best laptops for gaming and school in 2026 Best laptop for gaming and schoolwork FAQs Best laptops for gaming and school in 2026 Best laptop for gaming and schoolwork FAQs Are gaming laptops good for school? As we’ve mentioned, gaming laptops are especially helpful if you're doing any demanding work. Their big promise is powerful graphics performance, which isn't just limited to PC gaming. Video editing and 3D rendering programs can also tap into their GPUs to handle laborious tasks. While you can find decent GPUs on some productivity machines, like Dell's XPS 15, you can sometimes find better deals on gaming laptops. My general advice for any new workhorse: Pay attention to the specs; get at least 16GB of RAM and the largest solid state drive you can find (ideally 1TB or more). Those components are both typically hard to upgrade down the line, so it’s worth investing what you can up front to get the most out of your PC gaming experience long term. Also, don’t forget the basics like a webcam, which will likely be necessary for the schoolwork portion of your activities. The one big downside to choosing a gaming notebook is portability. For the most part, we'd recommend 15-inch models to get the best balance of size and price. Those typically weigh in around 4.5 pounds, which is significantly more than a three-pound ultraportable. Today's gaming notebooks are still far lighter than older models, though, so at least you won't be lugging around a 10-pound brick. If you’re looking for something lighter, there are plenty of 14-inch options these days. And if you're not into LED lights and other gamer-centric bling, keep an eye out for more understated models that still feature essentials like a webcam (or make sure you know how to turn those lights off). Do gaming laptops last longer than standard laptops? Not necessarily — it really depends on how you define \"last longer.\" In terms of raw performance, gaming laptops tend to pack more powerful components than standard laptops, which means they can stay relevant for longer when it comes to handling demanding software or modern games. That makes them a solid choice if you need a system that won’t feel outdated in a couple of years, especially for students or creators who also game in their downtime. But there’s a trade-off. All that power generates heat, and gaming laptops often run hotter and put more strain on internal components than typical ultraportables. If they’re not properly cooled or regularly maintained (think dust buildup and thermal paste), that wear and tear can shorten their lifespan. They’re also usually bulkier and have shorter battery life, which can impact long-term usability depending on your daily needs. Gaming laptops can last longer performance-wise, but only if you take good care of them. If your needs are light — browsing, writing papers and streaming — a standard laptop may actually last longer simply because it’s under less stress day-to-day. What is the role of GPU in a computer for gaming and school? The GPU plays a big role in how your laptop handles visuals — and it’s especially important if you’re using your computer for both gaming and school. For gaming, the GPU is essential. It’s responsible for rendering graphics, textures, lighting and all the visual effects that make your favorite titles look smooth and realistic. A more powerful GPU means better frame rates, higher resolutions and the ability to play modern games without lag or stuttering. For schoolwork, the GPU matters too — but its importance depends on what you're doing. If your school tasks mostly involve writing papers, browsing the web or using productivity tools like Google Docs or Microsoft Office, you don’t need a high-end GPU. But if you’re working with graphic design, video editing, 3D modeling or anything else that’s visually demanding, a good GPU can speed things up significantly and improve your workflow. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-laptops-for-gaming-and-school-132207352.html?src=rss",
          "feed_position": 23
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/why-notions-biggest-ai-breakthrough-came-from-simplifying-everything",
          "published_at": "Fri, 02 Jan 2026 08:00:00 GMT",
          "title": "Why Notion’s biggest AI breakthrough came from simplifying everything",
          "standfirst": "When initially experimenting with LLMs and agentic AI, software engineers at Notion AI applied advanced code generation, complex schemas, and heavy instructioning. Quickly, though, trial and error taught the team that it could get rid of all of that complicated data modeling. Notion’s AI engineering lead Ryan Nystrom and his team pivoted to simple prompts, human-readable representations, minimal abstraction, and familiar markdown formats. The result was dramatically improved model performance. Applying this re-wired approach, the AI-native company released V3 of its productivity software in September. Its notable feature: Cutomizable AI agents — which have quickly become Notion’s most successful AI tool to date. Based on usage patterns compared to previous versions, Nystrom calls it a “step function improvement.”“It&#x27;s that feeling of when the product is being pulled out of you rather than you trying to push,” Nystrom explains in a VB Beyond the Pilot podcast. “We knew from that moment, really early on, that we had something. Now it&#x27;s, ‘How could I ever use Notion without this feature?’”‘Rewiring’ for the AI agent eraAs a traditional software engineer, Nystrom was used to “extremely deterministic” experiences. But a light bulb moment came when a colleague advised him to simply describe his AI prompt as he would to a human, rather than codify rules of how agents should behave in various scenarios. The rationale: LLMs are designed to understand, “see” and reason about content the same way humans can.“Now, whenever I&#x27;m working with AI, I will reread the prompts and tool descriptions and [ask myself] is this something I could give to a person with no context and they could understand what&#x27;s going on?” Nystrom said on the podcast. “If not, it&#x27;s going to do a bad job.”Stepping back from “pretty complicated rendering” of data within Notion (such as JSON or XML) Nystrom and his team represented Notion pages as markdown, the popular device-agnostic markup language that defines structure and meaning using plain text without the need for HTML tags or formal editors. This allows the model to interact with, read, search and make changes to text files. Ultimately, this required Notion to rewire its systems, with Nystrom’s team focusing largely on the middleware transition layer. They also identified early on the importance of exercising restraint when it comes to context. It’s tempting to load as much information into a model as possible, but that can slow things down and confuse the model. For Notion, Nystrom described a 100,000 to 150,000 token limit as the “sweet spot.” “There are cases where you can load tons and tons of content into your context window and the model will struggle,” he said. “The more you put into the context window, you do see a degradation in performance, latency, and also accuracy.” A spartan approach is also important in the case of tooling; this can help teams avoid the “slippery slope” of endless features, Nystrom advised. Notion focuses on a “curated menu” of tools rather than a voluminous Cheesecake Factory-like menu that creates a paradox of choice for users. “When people ask for new features, we could just add a tool to the model or the agent,” he said. But, “the more tools we add, the more decisions the model has to make.”The bottom line: Channel the model. Use APIs the way they were meant to be used. Don&#x27;t try to be fancy, don&#x27;t try to overcomplicate it. Use plain English.Listen to the full podcast to hear about: Why AI is still in the pre-Blackberry, pre-iPhone era; The importance of \"dogfooding\" in product development;Why you shouldn’t worry about how cost effective your AI feature is in the early stages — that can be optimized later; How engineering teams can keep tools minimal in the age of MCP; Notion’s evolution from wikis to full-blown AI assistants. Subscribe to Beyond the Pilot on Apple Podcasts, Spotify, and YouTube.",
          "content": "When initially experimenting with LLMs and agentic AI, software engineers at Notion AI applied advanced code generation, complex schemas, and heavy instructioning. Quickly, though, trial and error taught the team that it could get rid of all of that complicated data modeling. Notion’s AI engineering lead Ryan Nystrom and his team pivoted to simple prompts, human-readable representations, minimal abstraction, and familiar markdown formats. The result was dramatically improved model performance. Applying this re-wired approach, the AI-native company released V3 of its productivity software in September. Its notable feature: Cutomizable AI agents — which have quickly become Notion’s most successful AI tool to date. Based on usage patterns compared to previous versions, Nystrom calls it a “step function improvement.”“It&#x27;s that feeling of when the product is being pulled out of you rather than you trying to push,” Nystrom explains in a VB Beyond the Pilot podcast. “We knew from that moment, really early on, that we had something. Now it&#x27;s, ‘How could I ever use Notion without this feature?’”‘Rewiring’ for the AI agent eraAs a traditional software engineer, Nystrom was used to “extremely deterministic” experiences. But a light bulb moment came when a colleague advised him to simply describe his AI prompt as he would to a human, rather than codify rules of how agents should behave in various scenarios. The rationale: LLMs are designed to understand, “see” and reason about content the same way humans can.“Now, whenever I&#x27;m working with AI, I will reread the prompts and tool descriptions and [ask myself] is this something I could give to a person with no context and they could understand what&#x27;s going on?” Nystrom said on the podcast. “If not, it&#x27;s going to do a bad job.”Stepping back from “pretty complicated rendering” of data within Notion (such as JSON or XML) Nystrom and his team represented Notion pages as markdown, the popular device-agnostic markup language that defines structure and meaning using plain text without the need for HTML tags or formal editors. This allows the model to interact with, read, search and make changes to text files. Ultimately, this required Notion to rewire its systems, with Nystrom’s team focusing largely on the middleware transition layer. They also identified early on the importance of exercising restraint when it comes to context. It’s tempting to load as much information into a model as possible, but that can slow things down and confuse the model. For Notion, Nystrom described a 100,000 to 150,000 token limit as the “sweet spot.” “There are cases where you can load tons and tons of content into your context window and the model will struggle,” he said. “The more you put into the context window, you do see a degradation in performance, latency, and also accuracy.” A spartan approach is also important in the case of tooling; this can help teams avoid the “slippery slope” of endless features, Nystrom advised. Notion focuses on a “curated menu” of tools rather than a voluminous Cheesecake Factory-like menu that creates a paradox of choice for users. “When people ask for new features, we could just add a tool to the model or the agent,” he said. But, “the more tools we add, the more decisions the model has to make.”The bottom line: Channel the model. Use APIs the way they were meant to be used. Don&#x27;t try to be fancy, don&#x27;t try to overcomplicate it. Use plain English.Listen to the full podcast to hear about: Why AI is still in the pre-Blackberry, pre-iPhone era; The importance of \"dogfooding\" in product development;Why you shouldn’t worry about how cost effective your AI feature is in the early stages — that can be optimized later; How engineering teams can keep tools minimal in the age of MCP; Notion’s evolution from wikis to full-blown AI assistants. Subscribe to Beyond the Pilot on Apple Podcasts, Spotify, and YouTube.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3M1D8BKy3SOEeg6eX5FsHw/1e8b91cccb75c0006777105677d059e6/an-art-deco-illustration-depicting-an-ai_0aPpBA4LR8yOmqmoIXg9lw_5PLasmgGTV-UJWHiihV0SA.jpeg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/seven-steps-to-ai-supply-chain-visibility",
          "published_at": "Fri, 02 Jan 2026 08:00:00 GMT",
          "title": "Seven steps to AI supply chain visibility — before a breach forces the issue",
          "standfirst": "Four in 10 enterprise applications will feature task-specific AI agents this year. Yet, research from Stanford University’s 2025 Index Report shows that a mere 6% of organizations have an advanced AI security strategy in place.Palo Alto Networks predicts 2026 will bring the first major lawsuits holding executives personally liable for rogue AI actions. Many organizations are grappling with how to contain the accelerating and unpredictable nature of AI threats. Governance doesn’t respond to quick fixes like bigger budgets or more headcount.There&#x27;s a visibility gap when it comes to how, where, when, and through which workflows and tools LLMs are being used or modified. One CISO told VentureBeat that model SBOMs are the Wild West of governance today. Without visibility into which models are running where, AI security collapses into guesswork — and incident response becomes impossible.Over the last several years, the U.S. government has pursued a policy of mandating SBOMs for all software acquired for use. AI models need them more, and the lack of consistent improvement in this area is one of AI’s most significant risks.The visibility gap is the vulnerability Harness surveyed 500 security practitioners across the U.S., U.K., France, and Germany. The findings should alarm every CISO: 62% of their peers have no way to tell where LLMs are in use across their organization. There&#x27;s a need for more rigor and transparency at the SBOM level to improve model traceability, data use, integration points, and use patterns by department.Enterprises continue to experience increasing levels of prompt injection (76%), vulnerable LLM code (66%), and jailbreaking (65%). These are among the most lethal risks and attack methods adversaries use to exfiltrate anything they can from an organization’s AI modeling and LLM efforts. Despite spending millions on cybersecurity software, many organizations aren’t seeing these adversaries’ intrusion efforts, as they’re cloaked in living-off-the-land techniques and comparable attack tradecraft not traceable by legacy perimeter systems. “Shadow AI has become the new enterprise blind spot,” said Adam Arellano, Field CTO at Harness. “Traditional security tools were built for static code and predictable systems, not for adaptive, learning models that evolve daily.”IBM’s 2025 Cost of a Data Breach Report quantifies the cost, finding that 13% of organizations reported breaches of AI models or applications last year. Of those breached, 97% lacked AI access controls. One in five reported breaches was due to shadow AI or unauthorized AI use. Shadow AI incidents cost $670,000 more than their comparable baseline intrusion counterparts. When nobody knows which models run where, incident response can’t scope the impact. Why SBOMs stop at the model file Executive Order 14028 (2021) and OMB Memorandum M-22-18 (2022) require software SBOMs for federal vendors. NIST’s AI Risk Management Framework, released in 2023, explicitly calls for AI-BOMs as part of its “Map” function, acknowledging that traditional software SBOMs don’t capture model-specific risks. But software dependencies resolve at build time and stay fixed. Conversely, model dependencies resolve at runtime, often fetching weights from HTTP endpoints during initialization, and mutate continuously through retraining, drift correction, and feedback loops. LoRA adapters modify weights without version control, making it impossible to track which model version is actually running in production.Here’s why this matters for security teams: When AI models are saved in pickle format, loading them is like opening an email attachment that executes code on your computer, except these files, acting like attachments, are trusted by default in production systems. A PyTorch model saved this way is serialized Python bytecode that must be deserialized and executed to load. When torch.load() runs, pickle opcodes execute sequentially. Any callable embedded in the stream fires. These commonly include os.system(), network connections, and reverse shells. SafeTensors, an alternative format that stores only numerical tensor data without executable code, addresses pickle’s inherent risks. Still, migration means rewriting load functions, revalidating model accuracy, and potentially losing access to legacy models where original training code no longer exists. That’s one of the primary factors holding adoption back. In many organizations, it’s not just policy, it’s an engineering effort.Model files aren’t inert artifacts — they’re executable supply chain entry points.Standards exist and have been in place for years, but adoption continues to lag. CycloneDX 1.6 added ML-BOM support in April 2024. SPDX 3.0, released in April 2024, included AI profiles. ML-BOMs complement but don’t replace documentation frameworks like Model Cards and Datasheets for Datasets, which focus on performance attributes and training data ethics rather than making supply chain provenance a priority. VentureBeat continues to see adoption lagging how quickly this area is becoming an existential threat to models and LLMs.A June 2025 Lineaje survey found 48% of security professionals admit their organizations are falling behind on SBOM requirements. ML-BOM adoption is significantly lower.Bottom line: The tooling exists. What’s missing is operational urgency.AI-BOMs enable response, not prevention AI-BOMs are forensics, not firewalls. When ReversingLabs discovered nullifAI-compromised models, documented provenance would have immediately identified which organizations downloaded them. That’s invaluable to know for incident response, while being practically useless for prevention. Budgeting for protecting AI-BOMs needs to take that factor into account. The ML-BOM tooling ecosystem is maturing fast, but it&#x27;s not where software SBOMs are yet. Tools like Syft and Trivy generate complete software inventories in minutes. ML-BOM tooling is earlier in that curve. Vendors are shipping solutions, but integration and automation still require additional steps and more effort. Organizations starting now may need manual processes to fill gaps.AI-BOMs won&#x27;t stop model poisoning as that happens during training, often before an organization ever downloads the model. They won&#x27;t block prompt injection either, as that attack exploits what the model does, not where it came from. Prevention requires runtime defenses that include input validation, prompt firewalls, output filtering, and tool call validation for agentic systems. AI-BOMs are visibility and compliance tools. Valuable, but not a substitute for runtime security. CISOs and security leaders are increasingly relying on both. The attack surface keeps expanding JFrog&#x27;s 2025 Software Supply Chain Report documented more than 1 million new models hitting Hugging Face in 2024 alone, with a 6.5-fold increase in malicious models. By April 2025, Protect AI&#x27;s scans of 4.47 million model versions found 352,000 unsafe or suspicious issues across 51,700 models. The attack surface expanded faster than anyone&#x27;s ability to monitor it.In early 2025, ReversingLabs discovered malicious models using \"nullifAI\" evasion techniques that bypassed Picklescan detection. Hugging Face responded within 24 hours, removing the models and updating Picklescan to detect similar evasion techniques, demonstrating that platform security is improving, even as attacker sophistication increases. “Many organizations are enthusiastically embracing public ML models to drive rapid innovation,” said Yoav Landman, CTO and Co-Founder of JFrog. “However, over a third still rely on manual efforts to manage access to secure, approved models, which can lead to potential oversights.”Seven steps to AI supply chain visibilityThe gap between hours and weeks in AI supply chain incident response comes down to preparation. Organizations with visibility built in before the breach have the insights needed to react with greater accuracy and speed. Those without scramble. None of the following requires a new budget — only the decision to treat AI model governance as seriously as software supply chain security.Commit to building a model inventory and defining processes to keep it current. Survey ML platform teams. Scan cloud spend for SageMaker, Vertex AI, and Bedrock usage. Review Hugging Face downloads in network logs. A spreadsheet works: model name, owner, data classification, deployment location, source, and last verification date. You can’t secure what you can’t see.Go all in on using advanced techniques to manage and redirect shadow AI use to apps, tools, and platforms that are secure. Survey every department. Check API keys in environment variables. Realize accounting, finance, and consulting teams may have sophisticated AI apps with multiple APIs linking directly into and using the company&#x27;s proprietary data. The 62% visibility gap exists because nobody asked.Require human approval for production models and design human-in-the-middle workflows always. Every model touching customer data needs a named owner, documented purpose, and an audit trail showing who approved deployment. Just as red teams do at Anthropic, OpenAI, and other AI companies, design human-in-the-middle approval processes for every model release. Consider mandating SafeTensors for new deployments. Policy changes cost nothing. SafeTensors stores only numerical tensor data, no code execution on load. Grandfather existing pickle models with documented risk acceptance and sunset timelines.Consider piloting ML-BOMs for the top 20% of risk models first. Pick the ones touching customer data or making business decisions. Document architecture, training data sources, base model lineage, framework dependencies. Use CycloneDX 1.6 or SPDX 3.0. Get started immediately if not already pursuing this, realizing that incomplete provenance beats none when incidents happen.Treat every model pull as a supply chain decision, so it becomes part of your organization’s muscle memory. Verify cryptographic hashes before load. Cache models internally. Block runtime network access for model execution environments. Apply the same rigor enterprises learned from leftpad, event-stream, and colors.js.Add AI governance to vendor contracts during the next renewal cycle. Require SBOMs, training data provenance, model versioning, and incident notification SLAs. Ask whether your data trains future models. Costs nothing to request.2026 will be a year of reckoning for AI SBOMs Securing AI models is becoming a boardroom priority. The EU AI Act prohibitions are already in effect, with fines reaching €35 million or 7% of global revenue. EU Cyber Resilience Act SBOM requirements begin this year. Full AI Act compliance is required by August 2, 2027.Cyber insurance carriers are watching. Given the $670,000 premium for shadow AI breaches and emerging executive liability exposure, expect AI governance documentation to become a policy requirement this year, much as ransomware readiness became table stakes after 2021.The SEI Carnegie Mellon SBOM Harmonization Plugfest analyzed 243 SBOMs from 21 tool vendors for identical software and found significant variance in component counts. For AI models with embedded dependencies and executable payloads, the stakes are higher.The first poisoned model incident that costs seven figures in response and fines will make the case that should have been obvious already.Software SBOMs became mandatory after attackers proved the supply chain was the softest target. AI supply chains are more dynamic, less visible, and harder to contain. The only organizations that will scale AI safely are the ones building visibility now — before they need it.",
          "content": "Four in 10 enterprise applications will feature task-specific AI agents this year. Yet, research from Stanford University’s 2025 Index Report shows that a mere 6% of organizations have an advanced AI security strategy in place.Palo Alto Networks predicts 2026 will bring the first major lawsuits holding executives personally liable for rogue AI actions. Many organizations are grappling with how to contain the accelerating and unpredictable nature of AI threats. Governance doesn’t respond to quick fixes like bigger budgets or more headcount.There&#x27;s a visibility gap when it comes to how, where, when, and through which workflows and tools LLMs are being used or modified. One CISO told VentureBeat that model SBOMs are the Wild West of governance today. Without visibility into which models are running where, AI security collapses into guesswork — and incident response becomes impossible.Over the last several years, the U.S. government has pursued a policy of mandating SBOMs for all software acquired for use. AI models need them more, and the lack of consistent improvement in this area is one of AI’s most significant risks.The visibility gap is the vulnerability Harness surveyed 500 security practitioners across the U.S., U.K., France, and Germany. The findings should alarm every CISO: 62% of their peers have no way to tell where LLMs are in use across their organization. There&#x27;s a need for more rigor and transparency at the SBOM level to improve model traceability, data use, integration points, and use patterns by department.Enterprises continue to experience increasing levels of prompt injection (76%), vulnerable LLM code (66%), and jailbreaking (65%). These are among the most lethal risks and attack methods adversaries use to exfiltrate anything they can from an organization’s AI modeling and LLM efforts. Despite spending millions on cybersecurity software, many organizations aren’t seeing these adversaries’ intrusion efforts, as they’re cloaked in living-off-the-land techniques and comparable attack tradecraft not traceable by legacy perimeter systems. “Shadow AI has become the new enterprise blind spot,” said Adam Arellano, Field CTO at Harness. “Traditional security tools were built for static code and predictable systems, not for adaptive, learning models that evolve daily.”IBM’s 2025 Cost of a Data Breach Report quantifies the cost, finding that 13% of organizations reported breaches of AI models or applications last year. Of those breached, 97% lacked AI access controls. One in five reported breaches was due to shadow AI or unauthorized AI use. Shadow AI incidents cost $670,000 more than their comparable baseline intrusion counterparts. When nobody knows which models run where, incident response can’t scope the impact. Why SBOMs stop at the model file Executive Order 14028 (2021) and OMB Memorandum M-22-18 (2022) require software SBOMs for federal vendors. NIST’s AI Risk Management Framework, released in 2023, explicitly calls for AI-BOMs as part of its “Map” function, acknowledging that traditional software SBOMs don’t capture model-specific risks. But software dependencies resolve at build time and stay fixed. Conversely, model dependencies resolve at runtime, often fetching weights from HTTP endpoints during initialization, and mutate continuously through retraining, drift correction, and feedback loops. LoRA adapters modify weights without version control, making it impossible to track which model version is actually running in production.Here’s why this matters for security teams: When AI models are saved in pickle format, loading them is like opening an email attachment that executes code on your computer, except these files, acting like attachments, are trusted by default in production systems. A PyTorch model saved this way is serialized Python bytecode that must be deserialized and executed to load. When torch.load() runs, pickle opcodes execute sequentially. Any callable embedded in the stream fires. These commonly include os.system(), network connections, and reverse shells. SafeTensors, an alternative format that stores only numerical tensor data without executable code, addresses pickle’s inherent risks. Still, migration means rewriting load functions, revalidating model accuracy, and potentially losing access to legacy models where original training code no longer exists. That’s one of the primary factors holding adoption back. In many organizations, it’s not just policy, it’s an engineering effort.Model files aren’t inert artifacts — they’re executable supply chain entry points.Standards exist and have been in place for years, but adoption continues to lag. CycloneDX 1.6 added ML-BOM support in April 2024. SPDX 3.0, released in April 2024, included AI profiles. ML-BOMs complement but don’t replace documentation frameworks like Model Cards and Datasheets for Datasets, which focus on performance attributes and training data ethics rather than making supply chain provenance a priority. VentureBeat continues to see adoption lagging how quickly this area is becoming an existential threat to models and LLMs.A June 2025 Lineaje survey found 48% of security professionals admit their organizations are falling behind on SBOM requirements. ML-BOM adoption is significantly lower.Bottom line: The tooling exists. What’s missing is operational urgency.AI-BOMs enable response, not prevention AI-BOMs are forensics, not firewalls. When ReversingLabs discovered nullifAI-compromised models, documented provenance would have immediately identified which organizations downloaded them. That’s invaluable to know for incident response, while being practically useless for prevention. Budgeting for protecting AI-BOMs needs to take that factor into account. The ML-BOM tooling ecosystem is maturing fast, but it&#x27;s not where software SBOMs are yet. Tools like Syft and Trivy generate complete software inventories in minutes. ML-BOM tooling is earlier in that curve. Vendors are shipping solutions, but integration and automation still require additional steps and more effort. Organizations starting now may need manual processes to fill gaps.AI-BOMs won&#x27;t stop model poisoning as that happens during training, often before an organization ever downloads the model. They won&#x27;t block prompt injection either, as that attack exploits what the model does, not where it came from. Prevention requires runtime defenses that include input validation, prompt firewalls, output filtering, and tool call validation for agentic systems. AI-BOMs are visibility and compliance tools. Valuable, but not a substitute for runtime security. CISOs and security leaders are increasingly relying on both. The attack surface keeps expanding JFrog&#x27;s 2025 Software Supply Chain Report documented more than 1 million new models hitting Hugging Face in 2024 alone, with a 6.5-fold increase in malicious models. By April 2025, Protect AI&#x27;s scans of 4.47 million model versions found 352,000 unsafe or suspicious issues across 51,700 models. The attack surface expanded faster than anyone&#x27;s ability to monitor it.In early 2025, ReversingLabs discovered malicious models using \"nullifAI\" evasion techniques that bypassed Picklescan detection. Hugging Face responded within 24 hours, removing the models and updating Picklescan to detect similar evasion techniques, demonstrating that platform security is improving, even as attacker sophistication increases. “Many organizations are enthusiastically embracing public ML models to drive rapid innovation,” said Yoav Landman, CTO and Co-Founder of JFrog. “However, over a third still rely on manual efforts to manage access to secure, approved models, which can lead to potential oversights.”Seven steps to AI supply chain visibilityThe gap between hours and weeks in AI supply chain incident response comes down to preparation. Organizations with visibility built in before the breach have the insights needed to react with greater accuracy and speed. Those without scramble. None of the following requires a new budget — only the decision to treat AI model governance as seriously as software supply chain security.Commit to building a model inventory and defining processes to keep it current. Survey ML platform teams. Scan cloud spend for SageMaker, Vertex AI, and Bedrock usage. Review Hugging Face downloads in network logs. A spreadsheet works: model name, owner, data classification, deployment location, source, and last verification date. You can’t secure what you can’t see.Go all in on using advanced techniques to manage and redirect shadow AI use to apps, tools, and platforms that are secure. Survey every department. Check API keys in environment variables. Realize accounting, finance, and consulting teams may have sophisticated AI apps with multiple APIs linking directly into and using the company&#x27;s proprietary data. The 62% visibility gap exists because nobody asked.Require human approval for production models and design human-in-the-middle workflows always. Every model touching customer data needs a named owner, documented purpose, and an audit trail showing who approved deployment. Just as red teams do at Anthropic, OpenAI, and other AI companies, design human-in-the-middle approval processes for every model release. Consider mandating SafeTensors for new deployments. Policy changes cost nothing. SafeTensors stores only numerical tensor data, no code execution on load. Grandfather existing pickle models with documented risk acceptance and sunset timelines.Consider piloting ML-BOMs for the top 20% of risk models first. Pick the ones touching customer data or making business decisions. Document architecture, training data sources, base model lineage, framework dependencies. Use CycloneDX 1.6 or SPDX 3.0. Get started immediately if not already pursuing this, realizing that incomplete provenance beats none when incidents happen.Treat every model pull as a supply chain decision, so it becomes part of your organization’s muscle memory. Verify cryptographic hashes before load. Cache models internally. Block runtime network access for model execution environments. Apply the same rigor enterprises learned from leftpad, event-stream, and colors.js.Add AI governance to vendor contracts during the next renewal cycle. Require SBOMs, training data provenance, model versioning, and incident notification SLAs. Ask whether your data trains future models. Costs nothing to request.2026 will be a year of reckoning for AI SBOMs Securing AI models is becoming a boardroom priority. The EU AI Act prohibitions are already in effect, with fines reaching €35 million or 7% of global revenue. EU Cyber Resilience Act SBOM requirements begin this year. Full AI Act compliance is required by August 2, 2027.Cyber insurance carriers are watching. Given the $670,000 premium for shadow AI breaches and emerging executive liability exposure, expect AI governance documentation to become a policy requirement this year, much as ransomware readiness became table stakes after 2021.The SEI Carnegie Mellon SBOM Harmonization Plugfest analyzed 243 SBOMs from 21 tool vendors for identical software and found significant variance in component counts. For AI models with embedded dependencies and executable payloads, the stakes are higher.The first poisoned model incident that costs seven figures in response and fines will make the case that should have been obvious already.Software SBOMs became mandatory after attackers proved the supply chain was the softest target. AI supply chains are more dynamic, less visible, and harder to contain. The only organizations that will scale AI safely are the ones building visibility now — before they need it.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1w9RRqYG2D8VbRv0ScvtQ7/0164109497a6648b33019ee766b77aef/HERO_IMAGE.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/how-to-watch-hyundais-ces-2026-presentation-live-190051181.html",
          "published_at": "Thu, 01 Jan 2026 19:00:51 +0000",
          "title": "How to watch Hyundai's CES 2026 presentation live",
          "standfirst": "A look at Hyundai's Holographic Windshield Display. (Hyundai) While it often feels like a full-on auto show, the car vibes feel somewhat lessened at CES 2026. Yes, the Afeela electric vehicle from the Sony-Honda joint venture will be back on the floor, but with the Trump administration yanking most EV incentives from the market, the industry isn't offering a full-court press of new vehicles in Las Vegas this year. That said, there's still plenty of in-cabin car tech on display, including Hyundai's Holographic Windshield Display. Indeed, the company's Mobis subsidiary will present \"more than 30 mobility convergence technologies\" during CES. And we'll also get to see Hyundai's AI Robotics Strategy, which will showcase its new Atlas robot fresh out of the lab. How to watch Hyundai's presentation at CES 2026 Hyundai's presentation takes place on January 5 at 4PM ET, and you can livestream it on either its HyundaiUSA YouTube channel or its global YouTube channel. We'll embed the stream here once it's available. What to expect As mentioned above, Hyundai will have its Holographic Windshield Display for viewing. It's essentially a next-gen heads-up display that projects key data from the vehicle's dash on the windshield for less distraction, and without obstructing the driver's view. It's a vertically expandable 18.1-inch large display, and passengers can even watch videos without being visible to the driver. Hyundai Mobis collaborated with German optics specialist Zeiss to develop the \"world's first system to utilize holographic film to transform the entire front windshield into an ultra-large display surface.\" It says it will begin mass production in 2029, so don't expect to see this on the market anytime soon. Beyond automotive, though, we'll also get a first-ever look at the company's new Atlas robot. In the teaser image shown in the press release, Atlas looks rather dog-like, which makes sense when you remember that Boston Dynamics was purchased by the Korean multinational back in 2020. \"This next-generation Atlas represents a tangible step toward the commercialization of AI Robotics, highlighting the Group’s commitment to building safe and adaptable robotic co-workers,\" the company said in the same press release. Hyundai said it will also discuss its other tech areas, including electronics and chassis system safety, as well as an AR head-up display, low-power display solutions and EV drive systems.This article originally appeared on Engadget at https://www.engadget.com/transportation/how-to-watch-hyundais-ces-2026-presentation-live-190051181.html?src=rss",
          "content": "A look at Hyundai's Holographic Windshield Display. (Hyundai) While it often feels like a full-on auto show, the car vibes feel somewhat lessened at CES 2026. Yes, the Afeela electric vehicle from the Sony-Honda joint venture will be back on the floor, but with the Trump administration yanking most EV incentives from the market, the industry isn't offering a full-court press of new vehicles in Las Vegas this year. That said, there's still plenty of in-cabin car tech on display, including Hyundai's Holographic Windshield Display. Indeed, the company's Mobis subsidiary will present \"more than 30 mobility convergence technologies\" during CES. And we'll also get to see Hyundai's AI Robotics Strategy, which will showcase its new Atlas robot fresh out of the lab. How to watch Hyundai's presentation at CES 2026 Hyundai's presentation takes place on January 5 at 4PM ET, and you can livestream it on either its HyundaiUSA YouTube channel or its global YouTube channel. We'll embed the stream here once it's available. What to expect As mentioned above, Hyundai will have its Holographic Windshield Display for viewing. It's essentially a next-gen heads-up display that projects key data from the vehicle's dash on the windshield for less distraction, and without obstructing the driver's view. It's a vertically expandable 18.1-inch large display, and passengers can even watch videos without being visible to the driver. Hyundai Mobis collaborated with German optics specialist Zeiss to develop the \"world's first system to utilize holographic film to transform the entire front windshield into an ultra-large display surface.\" It says it will begin mass production in 2029, so don't expect to see this on the market anytime soon. Beyond automotive, though, we'll also get a first-ever look at the company's new Atlas robot. In the teaser image shown in the press release, Atlas looks rather dog-like, which makes sense when you remember that Boston Dynamics was purchased by the Korean multinational back in 2020. \"This next-generation Atlas represents a tangible step toward the commercialization of AI Robotics, highlighting the Group’s commitment to building safe and adaptable robotic co-workers,\" the company said in the same press release. Hyundai said it will also discuss its other tech areas, including electronics and chassis system safety, as well as an AR head-up display, low-power display solutions and EV drive systems.This article originally appeared on Engadget at https://www.engadget.com/transportation/how-to-watch-hyundais-ces-2026-presentation-live-190051181.html?src=rss",
          "feed_position": 26,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/2a54c910-e5bb-11f0-9fd7-0fe99fe4214d"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/in-2025-quitting-social-media-felt-easier-than-ever-140000374.html",
          "published_at": "Thu, 01 Jan 2026 14:00:00 +0000",
          "title": "In 2025, quitting social media felt easier than ever",
          "standfirst": "For a tech writer, being very offline is sort of like being a marathon coach who doesn’t run. So in 2025, I tried to reverse years of studied avoidance towards the most ubiquitous technological phenomenon on earth — I got back on social media. The change was short-lived. My first exodus from the feeds took some work — disabling notifications, removing apps from my homescreen and then deleting accounts entirely. This time, the phone put itself down. The whole thing has simply lost its luster.I started with Instagram. Every experience went like this: I’d see a single post from one of the rare family members or IRL friends who are active on the platform. Next, I was fed a sponsored post, followed by suggestions to follow randos. After that, a series of influencer videos that, admittedly, appeal to my taste (funny/absurdist women and dissertations on urban planning). That was followed up with more sponsored posts, mostly from brands I’d looked up for work. Then it’d circle back to the influencers. My eyes glazed over and I tossed the phone aside. Years back, the platform gave off a jolt of quasi-social connection that I’d spend hours sucking up. I fed on pointless thoughts from an ex-coworker, vacation reels from a college roommate, a half-baked loaf of bread that an old friend dropped on the floor but took a picture of anyway. Now it’s a bare sliver of that stuff, shoehorned between towers of sponsored content and posts from people who make or promote their living on Instagram. The real people have left. The connection is gone. The FOMO is no more. I experienced some variation of the same disappointment on every platform I rejoined. When I got back on TikTok a few months after the ban, it felt like a frenzied shopping mall. Every video seems to be about four seconds long and most are promotional and/or shoppable. YouTube Shorts is drowning in AI-generated videos, and I don’t hit up social media to watch fake footage of desperate wild animal babies clambering onto the boats of helpful humans. My life has no need for simulated toddlers admonishing their pets. Occasionally, I’d hit on something compelling: a clip from late night TV, a stupidly decadent dessert recipe, people from other countries explaining cultural subtleties. But for me, these social media platforms are no longer velcro for the eyes. I remember losing focus, spending long hours on YouTube Shorts and IG. I’d look up bleary-eyed and shame-faced after hours scrolling TikTok’s For You Page. Now, after a few minutes, a bored ickiness sets in. I feel like I’m trapped in a carnival of bots hawking shampoo at me and I just want to go home. It’s not a mystery how or why things feel different; The answer is always money. These billion- and trillion-dollar companies have shareholders who prize year-over-year performance over anything else. So we get more sponsored posts on Instagram. TikTok purposefully, enthusiastically overloads itself with shoppable content (which isn’t going to change no matter who owns it). YouTube is obsessed with engagement so it ends up rewarding people who flood the platform with AI slop. These platforms aren’t about human connections and the spread of creativity — the stuff that used to draw me in — they’re thinly varnished ecommerce sites sprinkled with brute-forced AI oddities. I’d be sadder about the whole thing if I thought it could be any different. These companies are among the most valuable in the world. The fact that I can’t connect with my fellow common people using their services is not surprising. The change isn’t even driving everyone away. Instagram reported more users than ever this year, to the tune of 35 percent of the planet. Billions of users still scroll TikTok and watch YouTube Shorts. So maybe it’s just a me thing. And I have options. Over-monetization may have made me not want to engage with a few social media behemoths, but things aren’t so dire everywhere. Bluesky reminds me of Twitter before X. I take comfort in seeing posts that prove most people are as dismayed as I am over a government and wider economic system that are nakedly uninterested in serving the public. The hot takes aren’t quite as funny as they were on Twitter years back — maybe it’s just all been said before or perhaps things have gotten too dire for levity. I still don’t end up spending a lot of time on the platform, however. It’s not as weird as it was before the defection and I get tired of the stream of news headlines contextualized with tut-tutting and handwringing — I’m perfectly capable of doing that myself. It’d be easy to say that social media just isn’t my thing, but that’s not true because I can’t quit Reddit — the shining exception to my social media ennui. It feels filled with actual people. Ads exist, but in a subdued, manageable way. And every contributor, commenter and moderator I’ve come across on the app is militantly vigilant against the onslaught of artificially generated content. I also like the organizational structure. I know my Home tab will only expose me to my chosen subs and I derive great joy from happy cows, greeble-chasing cats, enigmatic night feelings and freaky abandoned spaces. I use my local subreddit r/Albuquerque daily to answer questions and keep tabs on the world (directly) around me. Sadly, Reddit is an outlier, a misfit exception to the rule, and now that it’s gone public, it may follow a similar monetization push. Bluesky is tiny, new and not yet profitable, so who knows where its financial journey will lead it (though the “world without Caesars” shirt gives us some hope). There’s something lamentable about the loss of the connections we gleaned from platforms that were once compelling, engrossing and rife with the creativity of our fellow humans. Ultimately, any public-facing company that prioritizes profits over everything else has no incentive to look out for its users. So I don’t expect any of the larger social platforms to pull back on their monetization marches. For now, I’ve decided I’m comfortable with my admittedly narrow interaction with the world of social media. As a Gen-Xer, online-first wasn’t how my relationship to the world started out. And I’m pretty confident I know enough about other tech-related stuff to be useful to my editors and readers without a black belt in social. (Ed. note: She is.) Besides, Karissa’s got us covered. This article originally appeared on Engadget at https://www.engadget.com/social-media/in-2025-quitting-social-media-felt-easier-than-ever-140000374.html?src=rss",
          "content": "For a tech writer, being very offline is sort of like being a marathon coach who doesn’t run. So in 2025, I tried to reverse years of studied avoidance towards the most ubiquitous technological phenomenon on earth — I got back on social media. The change was short-lived. My first exodus from the feeds took some work — disabling notifications, removing apps from my homescreen and then deleting accounts entirely. This time, the phone put itself down. The whole thing has simply lost its luster.I started with Instagram. Every experience went like this: I’d see a single post from one of the rare family members or IRL friends who are active on the platform. Next, I was fed a sponsored post, followed by suggestions to follow randos. After that, a series of influencer videos that, admittedly, appeal to my taste (funny/absurdist women and dissertations on urban planning). That was followed up with more sponsored posts, mostly from brands I’d looked up for work. Then it’d circle back to the influencers. My eyes glazed over and I tossed the phone aside. Years back, the platform gave off a jolt of quasi-social connection that I’d spend hours sucking up. I fed on pointless thoughts from an ex-coworker, vacation reels from a college roommate, a half-baked loaf of bread that an old friend dropped on the floor but took a picture of anyway. Now it’s a bare sliver of that stuff, shoehorned between towers of sponsored content and posts from people who make or promote their living on Instagram. The real people have left. The connection is gone. The FOMO is no more. I experienced some variation of the same disappointment on every platform I rejoined. When I got back on TikTok a few months after the ban, it felt like a frenzied shopping mall. Every video seems to be about four seconds long and most are promotional and/or shoppable. YouTube Shorts is drowning in AI-generated videos, and I don’t hit up social media to watch fake footage of desperate wild animal babies clambering onto the boats of helpful humans. My life has no need for simulated toddlers admonishing their pets. Occasionally, I’d hit on something compelling: a clip from late night TV, a stupidly decadent dessert recipe, people from other countries explaining cultural subtleties. But for me, these social media platforms are no longer velcro for the eyes. I remember losing focus, spending long hours on YouTube Shorts and IG. I’d look up bleary-eyed and shame-faced after hours scrolling TikTok’s For You Page. Now, after a few minutes, a bored ickiness sets in. I feel like I’m trapped in a carnival of bots hawking shampoo at me and I just want to go home. It’s not a mystery how or why things feel different; The answer is always money. These billion- and trillion-dollar companies have shareholders who prize year-over-year performance over anything else. So we get more sponsored posts on Instagram. TikTok purposefully, enthusiastically overloads itself with shoppable content (which isn’t going to change no matter who owns it). YouTube is obsessed with engagement so it ends up rewarding people who flood the platform with AI slop. These platforms aren’t about human connections and the spread of creativity — the stuff that used to draw me in — they’re thinly varnished ecommerce sites sprinkled with brute-forced AI oddities. I’d be sadder about the whole thing if I thought it could be any different. These companies are among the most valuable in the world. The fact that I can’t connect with my fellow common people using their services is not surprising. The change isn’t even driving everyone away. Instagram reported more users than ever this year, to the tune of 35 percent of the planet. Billions of users still scroll TikTok and watch YouTube Shorts. So maybe it’s just a me thing. And I have options. Over-monetization may have made me not want to engage with a few social media behemoths, but things aren’t so dire everywhere. Bluesky reminds me of Twitter before X. I take comfort in seeing posts that prove most people are as dismayed as I am over a government and wider economic system that are nakedly uninterested in serving the public. The hot takes aren’t quite as funny as they were on Twitter years back — maybe it’s just all been said before or perhaps things have gotten too dire for levity. I still don’t end up spending a lot of time on the platform, however. It’s not as weird as it was before the defection and I get tired of the stream of news headlines contextualized with tut-tutting and handwringing — I’m perfectly capable of doing that myself. It’d be easy to say that social media just isn’t my thing, but that’s not true because I can’t quit Reddit — the shining exception to my social media ennui. It feels filled with actual people. Ads exist, but in a subdued, manageable way. And every contributor, commenter and moderator I’ve come across on the app is militantly vigilant against the onslaught of artificially generated content. I also like the organizational structure. I know my Home tab will only expose me to my chosen subs and I derive great joy from happy cows, greeble-chasing cats, enigmatic night feelings and freaky abandoned spaces. I use my local subreddit r/Albuquerque daily to answer questions and keep tabs on the world (directly) around me. Sadly, Reddit is an outlier, a misfit exception to the rule, and now that it’s gone public, it may follow a similar monetization push. Bluesky is tiny, new and not yet profitable, so who knows where its financial journey will lead it (though the “world without Caesars” shirt gives us some hope). There’s something lamentable about the loss of the connections we gleaned from platforms that were once compelling, engrossing and rife with the creativity of our fellow humans. Ultimately, any public-facing company that prioritizes profits over everything else has no incentive to look out for its users. So I don’t expect any of the larger social platforms to pull back on their monetization marches. For now, I’ve decided I’m comfortable with my admittedly narrow interaction with the world of social media. As a Gen-Xer, online-first wasn’t how my relationship to the world started out. And I’m pretty confident I know enough about other tech-related stuff to be useful to my editors and readers without a black belt in social. (Ed. note: She is.) Besides, Karissa’s got us covered. This article originally appeared on Engadget at https://www.engadget.com/social-media/in-2025-quitting-social-media-felt-easier-than-ever-140000374.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/how-to-watch-the-bosch-ces-2026-press-conference-live-130020898.html",
          "published_at": "Thu, 01 Jan 2026 13:00:20 +0000",
          "title": "How to watch the Bosch CES 2026 press conference live",
          "standfirst": "You may know Bosch as a home appliance brand (via its partnership with Siemens), but the German multinational is generally more focused on providing underlying technology and engineering solutions to auto, home and manufacturing partners across the globe. It's fitting, then, that much of what it's showing off at CES 2026 is more intended to be licensed to other companies versus Bosch-branded products you'll be seeing on store shelves. Case in point is Bosch's automotive plans at CES. The company will present \"AI in the car,\" or more specifically, in the cockpit of the car. \"Bosch's AI-powered cockpit makes driving more comfortable, intuitive, and safer for all occupants,\" Bosch board member Markus Heyn said in a press release. We'll get into all the details below, as well as how to tune in to the press conference on Monday. How to watch Bosch's CES 2026 presentation You can livestream the event on Monday, January 5 at 12PM ET via the Bosch press page. (If the stream is embeddable, we'll also include it here.) What to expect Bosch will be setting up shop in the Central Hall of the Las Vegas Convention Center (booth 16203), where the company will be focusing on its three big themes — mobility, smart home integrations and manufacturing — all of which will include hardware, software and AI solutions. Like many other CES 2026 exhibitors, look for Bosch to emphasize its partnerships with the big dogs of the AI space at the show. For instance, that AI-powered car cockpit mentioned above will feature integrations with both Microsoft and NVIDIA. For instance, Bosch is touting the ability to use voice commands to join a Teams call, while the car's system will automatically activate adaptive cruise control. And it's noting that NVIDIA's software suites will help manage \"real-time sensor processing and vision-language models.\" Here's a glimpse of what the booth will look like: This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-watch-the-bosch-ces-2026-press-conference-live-130020898.html?src=rss",
          "content": "You may know Bosch as a home appliance brand (via its partnership with Siemens), but the German multinational is generally more focused on providing underlying technology and engineering solutions to auto, home and manufacturing partners across the globe. It's fitting, then, that much of what it's showing off at CES 2026 is more intended to be licensed to other companies versus Bosch-branded products you'll be seeing on store shelves. Case in point is Bosch's automotive plans at CES. The company will present \"AI in the car,\" or more specifically, in the cockpit of the car. \"Bosch's AI-powered cockpit makes driving more comfortable, intuitive, and safer for all occupants,\" Bosch board member Markus Heyn said in a press release. We'll get into all the details below, as well as how to tune in to the press conference on Monday. How to watch Bosch's CES 2026 presentation You can livestream the event on Monday, January 5 at 12PM ET via the Bosch press page. (If the stream is embeddable, we'll also include it here.) What to expect Bosch will be setting up shop in the Central Hall of the Las Vegas Convention Center (booth 16203), where the company will be focusing on its three big themes — mobility, smart home integrations and manufacturing — all of which will include hardware, software and AI solutions. Like many other CES 2026 exhibitors, look for Bosch to emphasize its partnerships with the big dogs of the AI space at the show. For instance, that AI-powered car cockpit mentioned above will feature integrations with both Microsoft and NVIDIA. For instance, Bosch is touting the ability to use voice commands to join a Teams call, while the car's system will automatically activate adaptive cruise control. And it's noting that NVIDIA's software suites will help manage \"real-time sensor processing and vision-language models.\" Here's a glimpse of what the booth will look like: This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-watch-the-bosch-ces-2026-press-conference-live-130020898.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/best-smart-scale-160033523.html",
          "published_at": "Thu, 01 Jan 2026 10:00:37 +0000",
          "title": "The best smart scales for 2026",
          "standfirst": "If you are trying to stay on top of your health this year, a smart scale can make the process feel more manageable. These devices log details like body fat, muscle mass and water levels, then sync everything to your phone so you can see patterns instead of guessing. It is an easy way to track changes and stay motivated between workouts or check-ins with your doctor.Some smart scales keep things simple and focus on just your data, while others tie into big fitness platforms or support multiple users under one roof. With so many choices, we pulled together the best smart scales to help you find one that fits your goals and your budget. Table of contents Smart scale safety Best smart scales for 2026 What to look for in a smart scale How we tested and which smart scales we tested Smart scales FAQs Smart scale safety There are valid reasons to weigh yourself but your self-worth shouldn’t be defined by what number shows up between your feet. If you’re looking to alter your body shape, that figure could go up as your waistline goes down since muscle weighs more than fat. Some scales go further by providing additional metrics like visceral fat levels, giving you a more comprehensive picture of your health. Dr. Anne Swift, Director of Public Health teaching at the University of Cambridge, said “weighing yourself too often can result in [you] becoming fixated on small fluctuations day-to-day rather than the overall trend over time.” Swift added “it’s sometimes better to focus on how clothes fit, or how you feel, rather than your weight.” A meta-analysis from 2016 found there may be some negative psychological impact from self weighing. A 2018 study, however, said there may be a positive correlation between regular weigh-ins and accelerated weight loss. It can be a minefield and I’d urge you to take real care of yourself and remember success won’t happen overnight. Best smart scales for 2026 What to look for in a smart scale Weight A scale that measures weight is probably the top requirement, right? Whether you're after a basic weight scale or a full-featured body fat scale, bear in mind, with all these measurements, the readings won’t be as accurate as a calibrated clinical scale. It’s better to focus on the overall trend, up or down over time, rather than a single measurement in isolation. Scales offering high-precision measurements can help, especially if you’re looking at the data to inform a specific health or fitness goal. Connectivity Before you buy your scale, work out how you’re planning on weighing yourself and when, as it is an issue. Some lower-end smart bathroom scales connect via Bluetooth and have no internal storage, so if you don’t have your phone to hand, it won’t record your weight. If your scale has Wi-Fi, then your scale can post the data to a server, letting you access them from any compatible device. Also, you should be mindful that some smart scales aren’t built with security in mind, so there’s a small risk to your privacy should your scale be compromised. Bone density The stronger your bones are, the less risk you have of breaks and osteoporosis — common concerns as you get older. Clinical bone density tests use low-power x-rays and some scales can offer you an at-home approximation. These bone mass tests pass a small electrical current through your feet, measuring the resistance as it completes its journey. The resistance offered by bones, fat and muscle are all different, letting your scale identify the difference. A body composition monitor often includes this feature, too, providing a detailed breakdown of bone density, fat and muscle mass. Body fat percentage and muscle mass Fat and muscle are necessary parts of our makeup, but too much of either can be problematic. Much like bone density, a body composition measurement feature can monitor your body fat and muscle mass percentages using Bioelectrical Impedance Analysis (BIA). This measurement tests how well your body resists an electrical signal passing through your body. (It’s a rough rule of thumb you should have a 30/70 percent split between fat and muscle, but please consult a medical professional for figures specific to your own body and medical needs.) For those with specific athletic goals, smart scales offer an athlete mode to better tailor readings for accuracy. If body fat monitoring is a priority, look for a model marketed as a body fat scale. BMI A lot of scales offer a BMI calculation, and it’s easy to do since you just plot height and weight on a set graph line. Body Mass Index is, however, a problematic measurement that its critics say is both overly simplistic and often greatly misleading. Unfortunately, it’s also one of the most common clinical body metrics and medical professionals will use it to make judgements about your care. Pulse Wave Velocity French health-tech company Withings has offered Pulse Wave Velocity (PWV) on its flagship scale for some time, although regulatory concerns meant it was withdrawn for a period. It’s a measurement of arterial stiffness, which acts as a marker both of cardiovascular risk and other health conditions. For those looking for an even deeper understanding of their health, some scales now offer a body scan, which provides more advanced metrics such as segmental body composition and vascular health insights. Wearables and integration Pairing your smart scale with wearables like fitness trackers or smartwatches can further enhance your health-tracking ecosystem. Many smart scales sync directly with platforms like Fitbit or Apple Health, making it easier to track trends and analyze your data in one place. Display Less a specification and more a note: Smart bathroom scales have displays ranging from pre-printed LCDs or digital dot matrix layouts through to color display screens. On the high end, your scale display can show you trending charts for your weight and other vital statistics, and can even tell you the day’s weather. If you are short-sighted, and plan on weighing yourself first thing in the morning, before you’ve found your glasses or contacts, opt for a big, clear, high-contrast display. App and subscriptions You’ll spend most of your time looking at your health data through its companion scales app, and it’s vital you get a good one. This includes a clear, clean layout with powerful tools to visualize your progress and analyze your data to look for places you can improve. Given that you often don’t need to buy anything before trying the app, it’s worth testing one or two to see if you vibe with it. It’s also important you check app compatibility before making your purchase. Some health apps will only work with iOS or Android — not both. Apple Watch connectivity can also be a bonus for tracking workouts and health metrics seamlessly. Several companies also offer premium subscriptions, unlocking other features – including insights and coaching – to go along with your hardware. Data portability Using the same scale or app platform for years at a time means you’ll build up a massive trove of personal data. And it is (or should be), your right to take that data to another provider if you choose to move platforms in the future. Data portability is, however, a minefield, with different platforms offering wildly different options, making it easy (or hard) to go elsewhere. All of the devices in this round-up will allow you to export your data to a .CSV file, which you can then do with as you wish. Importing this information is trickier, with Withings and Garmin allowing it, and Omron, Xiaomi, Eufy and Fitbit not making it that easy. (Apps that engage with Apple Health, meanwhile, can output all of your health data in a .XML file.) Power It’s not a huge issue but one worth bearing in mind that each scale will either run disposable batteries (most commonly 4xAAA) or with its own, built-in battery pack. Either choice adds an environmental and financial cost to your scale’s life — either with regular purchases of fresh cells or the potential for the whole unit to become waste when the battery pack fails. How we tested and which smart scales we tested For this guide, I tested six scales from major manufacturers: Mi (Xiaomi) Body Composition Scale 2 Our cheapest model, Xiaomi / Mi’s Body Composition Scale 2 is as bare-bones as you can get, and it shows. It often takes a long while to lock on to get your body weight, and when it does you’ll have to delve into the Zepp Life-branded scales app in order to look at your extra data. But you can’t fault it for the basics, offering limited (but accurate) weight measurements and body composition for less than the price of a McDonald’s for four. Fitbit Aira Air Fitbit, now part of Google, is the household name for fitness trackers and smartwatches in the US, right? If not, then it must be at least halfway synonymous with it. The Aria Air is the company’s stripped-to-the-bare bones scale, offering your weight and a few other health metrics, but you can trust that Fitbit got the basics right. Not to mention that most of the reason for buying a Fitbit product is to leverage its fitness app anyway. Anker Eufy Smart Scale P2 Pro Eufy’s Smart Scale P2 Pro has plenty of things to commend it – the price, the overall look and feel (it’s a snazzy piece of kit) and what it offers. It offers a whole host of in-depth functionality, including Body Fat, Muscle Mass, Water Weight, Body Fat Mass and Bone Mass measurements, as well as calculating things like your Heart Rate and Basal Metabolic Rate (the amount of calories you need to eat a day to not change weight at all) all from inside its app. In fact, buried beneath the friendly graphic, the scale offers a big pile of stats and data that should, I think, give you more than a little coaching on how to improve your overall health. It’s worth noting that Anker – Eufy’s parent company – was identified as having misled users, and the media, about the security of its products a few years back. Its Eufy-branded security cameras, which the company says does not broadcast video outside of your local network, was found to be allowing third parties to access streams online. Consequently, while we have praised the Eufy Smart Scale for its own features, we cannot recommend it without a big caveat. Omron BCM-500 Body Composition and Scale with Bluetooth Given its role in making actual medical devices, you know what you’re getting with an Omron product. A solid, reliable, sturdy, strong (checks the dictionary for more synonyms) dependable piece of kit. There’s no romance or excitement on show, but you can trust that however joyless it may be, it’ll do the job in question and will be user-friendly. The hardware is limited, the app is limited, but it certainly (checks synonyms again) is steady. Joking aside, Omron’s Connect app is as bare-bones as you can get, since it acts as an interface for so many of its products. Scroll over to the Weight page, and you’ll get your weight and BMI reading, and if you’ve set a fitness goal, you can see how far you’ve got to go to reach it. You can also switch to seeing a trend graph which, again, offers the most basic visualization of your workouts and progress. Garmin Index S2 Garmin’s got a pretty massive fitness ecosystem of its own, so if you’re already part of that world, its smart scale is a no-brainer. On one hand, the scale is one of the easiest to use, and most luxurious of the bunch, with its color screen and sleek design. I’m also a big fan of the wealth of data and different metrics the scale throws at you – you can see a full color graph charting your weight measurements and goal progress, and the various metrics it tracks in good detail. If there’s a downside, it’s that Garmin’s setup won’t hold your hand, since it’s for serious fitness people, not newbies. Withings Body Comp At the highest end, Withings’ flagship Body Comp is luxurious, and luxuriously priced, a figure I’d consider to be “too much” to spend on a bathroom scale. For your money, however, you’ll get a fairly comprehensive rundown of body composition metrics including your weight, body fat percentage, vascular age, pulse wave velocity and electrodermal activity. Its monochrome dot matrix display may not be as swish as the Garmin’s, but it refreshes pretty quickly and feels very in-keeping with the hardware’s overall sleek look. Withings Body Scan If you want to flaunt your cash, you don’t buy a car, you buy a supercar, or a hypercar if you’re flush enough. What then, do we call Withings’ $400 Body Scan if not a super-smart scale, or a hyper-smart scale? As well as doing everything the Body Comp does, plus running a six-lead ECG, segmented body composition, and will even check for neuropathy in your feet. It is the best scale I’ve ever used, it is also the most expensive, and I suspect it’s too much device for almost everyone who’d consider buying one. Smart scales FAQs What's the difference between a smart scale and a regular scale? A regular scale is pretty straightforward — it tells you how much you weigh, and that’s usually it. A smart scale, on the other hand, does much more. Not only does it give you your weight measurements, but it can also track things like your body fat percentage, muscle mass, and even your BMI. Some smart scales even monitor more advanced metrics like bone density, depending on the model. What’s even better is that smart scales sync with scales apps on your phone using Wi-Fi or Bluetooth, so you can see all your health data in one place. This lets you monitor trends over time, like if your muscle mass is increasing or your body fat percentage decreasing. How do smart scales work with more than one person using it? When more than one person in a household uses the smart scale, it usually recognizes each person by their weight range and other body measurements (like body fat percentage). Most smart scales allow you to set up individual profiles in the companion app, and once your profile is linked, the scale can automatically figure out who’s standing on it. Let’s say you and a family member have fairly different weights — the scale will easily know who’s who based on that. But if you and someone else have similar weights, it might ask you to confirm the profile on your phone after the weigh-in. Some scales even let you assign a profile manually in the scales app if it’s not sure.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-smart-scale-160033523.html?src=rss",
          "content": "If you are trying to stay on top of your health this year, a smart scale can make the process feel more manageable. These devices log details like body fat, muscle mass and water levels, then sync everything to your phone so you can see patterns instead of guessing. It is an easy way to track changes and stay motivated between workouts or check-ins with your doctor.Some smart scales keep things simple and focus on just your data, while others tie into big fitness platforms or support multiple users under one roof. With so many choices, we pulled together the best smart scales to help you find one that fits your goals and your budget. Table of contents Smart scale safety Best smart scales for 2026 What to look for in a smart scale How we tested and which smart scales we tested Smart scales FAQs Smart scale safety There are valid reasons to weigh yourself but your self-worth shouldn’t be defined by what number shows up between your feet. If you’re looking to alter your body shape, that figure could go up as your waistline goes down since muscle weighs more than fat. Some scales go further by providing additional metrics like visceral fat levels, giving you a more comprehensive picture of your health. Dr. Anne Swift, Director of Public Health teaching at the University of Cambridge, said “weighing yourself too often can result in [you] becoming fixated on small fluctuations day-to-day rather than the overall trend over time.” Swift added “it’s sometimes better to focus on how clothes fit, or how you feel, rather than your weight.” A meta-analysis from 2016 found there may be some negative psychological impact from self weighing. A 2018 study, however, said there may be a positive correlation between regular weigh-ins and accelerated weight loss. It can be a minefield and I’d urge you to take real care of yourself and remember success won’t happen overnight. Best smart scales for 2026 What to look for in a smart scale Weight A scale that measures weight is probably the top requirement, right? Whether you're after a basic weight scale or a full-featured body fat scale, bear in mind, with all these measurements, the readings won’t be as accurate as a calibrated clinical scale. It’s better to focus on the overall trend, up or down over time, rather than a single measurement in isolation. Scales offering high-precision measurements can help, especially if you’re looking at the data to inform a specific health or fitness goal. Connectivity Before you buy your scale, work out how you’re planning on weighing yourself and when, as it is an issue. Some lower-end smart bathroom scales connect via Bluetooth and have no internal storage, so if you don’t have your phone to hand, it won’t record your weight. If your scale has Wi-Fi, then your scale can post the data to a server, letting you access them from any compatible device. Also, you should be mindful that some smart scales aren’t built with security in mind, so there’s a small risk to your privacy should your scale be compromised. Bone density The stronger your bones are, the less risk you have of breaks and osteoporosis — common concerns as you get older. Clinical bone density tests use low-power x-rays and some scales can offer you an at-home approximation. These bone mass tests pass a small electrical current through your feet, measuring the resistance as it completes its journey. The resistance offered by bones, fat and muscle are all different, letting your scale identify the difference. A body composition monitor often includes this feature, too, providing a detailed breakdown of bone density, fat and muscle mass. Body fat percentage and muscle mass Fat and muscle are necessary parts of our makeup, but too much of either can be problematic. Much like bone density, a body composition measurement feature can monitor your body fat and muscle mass percentages using Bioelectrical Impedance Analysis (BIA). This measurement tests how well your body resists an electrical signal passing through your body. (It’s a rough rule of thumb you should have a 30/70 percent split between fat and muscle, but please consult a medical professional for figures specific to your own body and medical needs.) For those with specific athletic goals, smart scales offer an athlete mode to better tailor readings for accuracy. If body fat monitoring is a priority, look for a model marketed as a body fat scale. BMI A lot of scales offer a BMI calculation, and it’s easy to do since you just plot height and weight on a set graph line. Body Mass Index is, however, a problematic measurement that its critics say is both overly simplistic and often greatly misleading. Unfortunately, it’s also one of the most common clinical body metrics and medical professionals will use it to make judgements about your care. Pulse Wave Velocity French health-tech company Withings has offered Pulse Wave Velocity (PWV) on its flagship scale for some time, although regulatory concerns meant it was withdrawn for a period. It’s a measurement of arterial stiffness, which acts as a marker both of cardiovascular risk and other health conditions. For those looking for an even deeper understanding of their health, some scales now offer a body scan, which provides more advanced metrics such as segmental body composition and vascular health insights. Wearables and integration Pairing your smart scale with wearables like fitness trackers or smartwatches can further enhance your health-tracking ecosystem. Many smart scales sync directly with platforms like Fitbit or Apple Health, making it easier to track trends and analyze your data in one place. Display Less a specification and more a note: Smart bathroom scales have displays ranging from pre-printed LCDs or digital dot matrix layouts through to color display screens. On the high end, your scale display can show you trending charts for your weight and other vital statistics, and can even tell you the day’s weather. If you are short-sighted, and plan on weighing yourself first thing in the morning, before you’ve found your glasses or contacts, opt for a big, clear, high-contrast display. App and subscriptions You’ll spend most of your time looking at your health data through its companion scales app, and it’s vital you get a good one. This includes a clear, clean layout with powerful tools to visualize your progress and analyze your data to look for places you can improve. Given that you often don’t need to buy anything before trying the app, it’s worth testing one or two to see if you vibe with it. It’s also important you check app compatibility before making your purchase. Some health apps will only work with iOS or Android — not both. Apple Watch connectivity can also be a bonus for tracking workouts and health metrics seamlessly. Several companies also offer premium subscriptions, unlocking other features – including insights and coaching – to go along with your hardware. Data portability Using the same scale or app platform for years at a time means you’ll build up a massive trove of personal data. And it is (or should be), your right to take that data to another provider if you choose to move platforms in the future. Data portability is, however, a minefield, with different platforms offering wildly different options, making it easy (or hard) to go elsewhere. All of the devices in this round-up will allow you to export your data to a .CSV file, which you can then do with as you wish. Importing this information is trickier, with Withings and Garmin allowing it, and Omron, Xiaomi, Eufy and Fitbit not making it that easy. (Apps that engage with Apple Health, meanwhile, can output all of your health data in a .XML file.) Power It’s not a huge issue but one worth bearing in mind that each scale will either run disposable batteries (most commonly 4xAAA) or with its own, built-in battery pack. Either choice adds an environmental and financial cost to your scale’s life — either with regular purchases of fresh cells or the potential for the whole unit to become waste when the battery pack fails. How we tested and which smart scales we tested For this guide, I tested six scales from major manufacturers: Mi (Xiaomi) Body Composition Scale 2 Our cheapest model, Xiaomi / Mi’s Body Composition Scale 2 is as bare-bones as you can get, and it shows. It often takes a long while to lock on to get your body weight, and when it does you’ll have to delve into the Zepp Life-branded scales app in order to look at your extra data. But you can’t fault it for the basics, offering limited (but accurate) weight measurements and body composition for less than the price of a McDonald’s for four. Fitbit Aira Air Fitbit, now part of Google, is the household name for fitness trackers and smartwatches in the US, right? If not, then it must be at least halfway synonymous with it. The Aria Air is the company’s stripped-to-the-bare bones scale, offering your weight and a few other health metrics, but you can trust that Fitbit got the basics right. Not to mention that most of the reason for buying a Fitbit product is to leverage its fitness app anyway. Anker Eufy Smart Scale P2 Pro Eufy’s Smart Scale P2 Pro has plenty of things to commend it – the price, the overall look and feel (it’s a snazzy piece of kit) and what it offers. It offers a whole host of in-depth functionality, including Body Fat, Muscle Mass, Water Weight, Body Fat Mass and Bone Mass measurements, as well as calculating things like your Heart Rate and Basal Metabolic Rate (the amount of calories you need to eat a day to not change weight at all) all from inside its app. In fact, buried beneath the friendly graphic, the scale offers a big pile of stats and data that should, I think, give you more than a little coaching on how to improve your overall health. It’s worth noting that Anker – Eufy’s parent company – was identified as having misled users, and the media, about the security of its products a few years back. Its Eufy-branded security cameras, which the company says does not broadcast video outside of your local network, was found to be allowing third parties to access streams online. Consequently, while we have praised the Eufy Smart Scale for its own features, we cannot recommend it without a big caveat. Omron BCM-500 Body Composition and Scale with Bluetooth Given its role in making actual medical devices, you know what you’re getting with an Omron product. A solid, reliable, sturdy, strong (checks the dictionary for more synonyms) dependable piece of kit. There’s no romance or excitement on show, but you can trust that however joyless it may be, it’ll do the job in question and will be user-friendly. The hardware is limited, the app is limited, but it certainly (checks synonyms again) is steady. Joking aside, Omron’s Connect app is as bare-bones as you can get, since it acts as an interface for so many of its products. Scroll over to the Weight page, and you’ll get your weight and BMI reading, and if you’ve set a fitness goal, you can see how far you’ve got to go to reach it. You can also switch to seeing a trend graph which, again, offers the most basic visualization of your workouts and progress. Garmin Index S2 Garmin’s got a pretty massive fitness ecosystem of its own, so if you’re already part of that world, its smart scale is a no-brainer. On one hand, the scale is one of the easiest to use, and most luxurious of the bunch, with its color screen and sleek design. I’m also a big fan of the wealth of data and different metrics the scale throws at you – you can see a full color graph charting your weight measurements and goal progress, and the various metrics it tracks in good detail. If there’s a downside, it’s that Garmin’s setup won’t hold your hand, since it’s for serious fitness people, not newbies. Withings Body Comp At the highest end, Withings’ flagship Body Comp is luxurious, and luxuriously priced, a figure I’d consider to be “too much” to spend on a bathroom scale. For your money, however, you’ll get a fairly comprehensive rundown of body composition metrics including your weight, body fat percentage, vascular age, pulse wave velocity and electrodermal activity. Its monochrome dot matrix display may not be as swish as the Garmin’s, but it refreshes pretty quickly and feels very in-keeping with the hardware’s overall sleek look. Withings Body Scan If you want to flaunt your cash, you don’t buy a car, you buy a supercar, or a hypercar if you’re flush enough. What then, do we call Withings’ $400 Body Scan if not a super-smart scale, or a hyper-smart scale? As well as doing everything the Body Comp does, plus running a six-lead ECG, segmented body composition, and will even check for neuropathy in your feet. It is the best scale I’ve ever used, it is also the most expensive, and I suspect it’s too much device for almost everyone who’d consider buying one. Smart scales FAQs What's the difference between a smart scale and a regular scale? A regular scale is pretty straightforward — it tells you how much you weigh, and that’s usually it. A smart scale, on the other hand, does much more. Not only does it give you your weight measurements, but it can also track things like your body fat percentage, muscle mass, and even your BMI. Some smart scales even monitor more advanced metrics like bone density, depending on the model. What’s even better is that smart scales sync with scales apps on your phone using Wi-Fi or Bluetooth, so you can see all your health data in one place. This lets you monitor trends over time, like if your muscle mass is increasing or your body fat percentage decreasing. How do smart scales work with more than one person using it? When more than one person in a household uses the smart scale, it usually recognizes each person by their weight range and other body measurements (like body fat percentage). Most smart scales allow you to set up individual profiles in the companion app, and once your profile is linked, the scale can automatically figure out who’s standing on it. Let’s say you and a family member have fairly different weights — the scale will easily know who’s who based on that. But if you and someone else have similar weights, it might ask you to confirm the profile on your phone after the weigh-in. Some scales even let you assign a profile manually in the scales app if it’s not sure.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-smart-scale-160033523.html?src=rss",
          "feed_position": 32
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/four-ai-research-trends-enterprise-teams-should-watch-in-2026",
          "published_at": "Thu, 01 Jan 2026 08:00:00 GMT",
          "title": "Four AI research trends enterprise teams should watch in 2026",
          "standfirst": "The AI narrative has mostly been dominated by model performance on key industry benchmarks. But as the field matures and enterprises look to draw real value from advances in AI, we’re seeing parallel research in techniques that help productionize AI applications. At VentureBeat, we are tracking AI research that can help understand where the practical implementation of technology is heading. We are looking forward to breakthroughs that are not just about the raw intelligence of a single model, but about how we engineer the systems around them. As we approach 2026, here are four trends that can represent the blueprint for the next generation of robust, scalable enterprise applications.Continual learningContinual learning addresses one of the key challenges of current AI models: teaching them new information and skills without destroying their existing knowledge (often referred to as “catastrophic forgetting”).Traditionally, there are two ways to solve this. One is to retrain the model with a mix of old and new information, which is expensive, time-consuming, and extremely complicated. This makes it inaccessible to most companies using models.Another workaround is to provide models with in-context information through techniques such as RAG. However, these techniques do not update the model’s internal knowledge, which can prove problematic as you move away from the model’s knowledge cutoff and facts start conflicting with what was true at the time of the model’s training. They also require a lot of engineering and are limited by the context windows of the models.Continual learning enables models to update their internal knowledge without the need for retraining. Google has been working on this with several new model architectures. One of them is Titans, which proposes a different primitive: a learned long-term memory module that lets the system incorporate historical context at inference time. Intuitively, it shifts some “learning” from offline weight updates into an online memory process, closer to how teams already think about caches, indexes, and logs. Nested Learning pushes the same theme from another angle. It treats a model as a set of nested optimization problems, each with its own internal workflow, and uses that framing to address catastrophic forgetting. Standard transformer-based language models have dense layers that store the long-term memory obtained during pretraining and attention layers that hold the immediate context. Nested Learning introduces a “continuum memory system,” where memory is seen as a spectrum of modules that update at different frequencies. This creates a memory system that is more attuned to continual learning.Continual learning is complementary to the work being done on giving agents short-term memory through context engineering. As it matures, enterprises can expect a generation of models that adapt to changing environments, dynamically deciding which new information to internalize and which to preserve in short-term memory. World modelsWorld models promise to give AI systems the ability to understand their environments without the need for human-labeled data or human-generated text. With world models, AI systems can better respond to unpredictable and out-of-distribution events and become more robust against the uncertainty of the real world. More importantly, world models open the way for AI systems that can move beyond text and solve tasks that involve physical environments. World models try to learn the regularities of the physical world directly from observation and interaction.There are different approaches for creating world models. DeepMind is building Genie, a family of generative end-to-end models that simulate an environment so an agent can predict how the environment will evolve and how actions will change it. It takes in an image or prompt along with user actions and generates the sequence of video frames that reflect how the world changes. Genie can create interactive environments that can be used for different purposes, including training robots and self-driving cars. World Labs, a new startup founded by AI pioneer Fei-Fei Li, takes a slightly different approach. Marble, World Labs’ first AI system, uses generative AI to create a 3D model from an image or a prompt, which can then be used by a physics and 3D engine to render and simulate the interactive environment used to train robots.Another approach is the Joint Embedding Predictive Architecture (JEPA) espoused by Turing Award winner and former Meta AI Chief Yann LeCun. JEPA models learn latent representations from raw data so the system can anticipate what comes next without generating every pixel. JEPA models are much more efficient than generative models, which makes them suitable for fast-paced real-time AI applications that need to run on resource constrained devices. V-JEPA, the video version of the architecture, is pre-trained on unlabeled internet-scale video to learn world models through observation. It then adds a small amount of interaction data from robot trajectories to support planning. That combination hints at a path where enterprises leverage abundant passive video (training, inspection, dashcams, retail) and add limited, high-value interaction data where they need control. In November, LeCun confirmed that he will be leaving Meta and will be starting a new AI startup that will pursue “systems that understand the physical world, have persistent memory, can reason, and can plan complex action sequences.”OrchestrationFrontier LLMs continue to advance on very challenging benchmarks, often outperforming human experts. But when it comes to real-world tasks and multi-step agentic workflows, even strong models fail: They lose context, call tools with the wrong parameters, and compound small mistakes. Orchestration treats those failures as systems problems that can be addressed with the right scaffolding and engineering. For example, a router chooses between a fast small model, a bigger model for harder steps, retrieval for grounding, and deterministic tools for actions. There are now multiple frameworks that create orchestration layers to improve efficiency and accuracy of AI agents, especially when using external tools. Stanford&#x27;s OctoTools is an open-source framework that can orchestrate multiple tools without the need to fine-tune or adjust the models. OctoTools uses a modular approach that plans a solution, selects tools, and passes subtasks to different agents. OctoTools can use any general-purpose LLM as its backbone.Another approach is to train a specialized orchestrator model that can divide labor between different components of the AI system. One such example is Nvidia’s Orchestrator, an 8-billion-parameter model that coordinates different tools and LLMs to solve complex problems. Orchestrator was trained through a special reinforcement learning technique designed for model orchestration. It can tell when to use tools, when to delegate tasks to small specialized models, and when to use the reasoning capabilities and knowledge of large generalist models.One of the characteristics of these and other similar frameworks is that they can benefit from advances in the underlying models. So as we continue to see advances in frontier models, we can expect orchestration frameworks to evolve and help enterprises build robust and resource-efficient agentic applications.RefinementRefinement techniques turn “one answer” into a controlled process: propose, critique, revise, and verify. It frames the workflow as using the same model to generate an initial output, produce feedback on it, and iteratively improve, without additional training. While self-refinement techniques have been around for a few years, we might be at a point where we can see them provide a step change in agentic applications. This was put on full display in the results of the ARC Prize, which dubbed 2025 as the “Year of the Refinement Loop” and wrote, “From an information theory perspective, refinement is intelligence.” ARC tests models on complicated abstract reasoning puzzles. ARC’s own analysis reports that the top verified refinement solution, built on a frontier model and developed by Poetiq, reached 54% on ARC-AGI-2, beating the runner-up, Gemini 3 Deep Think (45%), at half the price. Poetiq’s solution is a recursive, self-improving, system that is LLM-agnostic. It is designed to leverage the reasoning capabilities and knowledge of the underlying model to reflect and refine its own solution and invoke tools such as code interpreters when needed.As models become stronger, adding self-refinement layers will make it possible to get more out of them. Poetiq is already working with partners to adapt its meta-system to “handle complex real-world problems that frontier models struggle to solve.”How to track AI research in 2026A practical way to read the research in the coming year is to watch which new techniques can help enterprises move agentic applications from proof-of-concepts into scalable systems. Continual learning shifts rigor toward memory provenance and retention. World models shift it toward robust simulation and prediction of real-world events. Orchestration shifts it toward better use of resources. Refinement shifts it toward smart reflection and correction of answers. The winners will not only pick strong models, they will build the control plane that keeps those models correct, current, and cost-efficient.",
          "content": "The AI narrative has mostly been dominated by model performance on key industry benchmarks. But as the field matures and enterprises look to draw real value from advances in AI, we’re seeing parallel research in techniques that help productionize AI applications. At VentureBeat, we are tracking AI research that can help understand where the practical implementation of technology is heading. We are looking forward to breakthroughs that are not just about the raw intelligence of a single model, but about how we engineer the systems around them. As we approach 2026, here are four trends that can represent the blueprint for the next generation of robust, scalable enterprise applications.Continual learningContinual learning addresses one of the key challenges of current AI models: teaching them new information and skills without destroying their existing knowledge (often referred to as “catastrophic forgetting”).Traditionally, there are two ways to solve this. One is to retrain the model with a mix of old and new information, which is expensive, time-consuming, and extremely complicated. This makes it inaccessible to most companies using models.Another workaround is to provide models with in-context information through techniques such as RAG. However, these techniques do not update the model’s internal knowledge, which can prove problematic as you move away from the model’s knowledge cutoff and facts start conflicting with what was true at the time of the model’s training. They also require a lot of engineering and are limited by the context windows of the models.Continual learning enables models to update their internal knowledge without the need for retraining. Google has been working on this with several new model architectures. One of them is Titans, which proposes a different primitive: a learned long-term memory module that lets the system incorporate historical context at inference time. Intuitively, it shifts some “learning” from offline weight updates into an online memory process, closer to how teams already think about caches, indexes, and logs. Nested Learning pushes the same theme from another angle. It treats a model as a set of nested optimization problems, each with its own internal workflow, and uses that framing to address catastrophic forgetting. Standard transformer-based language models have dense layers that store the long-term memory obtained during pretraining and attention layers that hold the immediate context. Nested Learning introduces a “continuum memory system,” where memory is seen as a spectrum of modules that update at different frequencies. This creates a memory system that is more attuned to continual learning.Continual learning is complementary to the work being done on giving agents short-term memory through context engineering. As it matures, enterprises can expect a generation of models that adapt to changing environments, dynamically deciding which new information to internalize and which to preserve in short-term memory. World modelsWorld models promise to give AI systems the ability to understand their environments without the need for human-labeled data or human-generated text. With world models, AI systems can better respond to unpredictable and out-of-distribution events and become more robust against the uncertainty of the real world. More importantly, world models open the way for AI systems that can move beyond text and solve tasks that involve physical environments. World models try to learn the regularities of the physical world directly from observation and interaction.There are different approaches for creating world models. DeepMind is building Genie, a family of generative end-to-end models that simulate an environment so an agent can predict how the environment will evolve and how actions will change it. It takes in an image or prompt along with user actions and generates the sequence of video frames that reflect how the world changes. Genie can create interactive environments that can be used for different purposes, including training robots and self-driving cars. World Labs, a new startup founded by AI pioneer Fei-Fei Li, takes a slightly different approach. Marble, World Labs’ first AI system, uses generative AI to create a 3D model from an image or a prompt, which can then be used by a physics and 3D engine to render and simulate the interactive environment used to train robots.Another approach is the Joint Embedding Predictive Architecture (JEPA) espoused by Turing Award winner and former Meta AI Chief Yann LeCun. JEPA models learn latent representations from raw data so the system can anticipate what comes next without generating every pixel. JEPA models are much more efficient than generative models, which makes them suitable for fast-paced real-time AI applications that need to run on resource constrained devices. V-JEPA, the video version of the architecture, is pre-trained on unlabeled internet-scale video to learn world models through observation. It then adds a small amount of interaction data from robot trajectories to support planning. That combination hints at a path where enterprises leverage abundant passive video (training, inspection, dashcams, retail) and add limited, high-value interaction data where they need control. In November, LeCun confirmed that he will be leaving Meta and will be starting a new AI startup that will pursue “systems that understand the physical world, have persistent memory, can reason, and can plan complex action sequences.”OrchestrationFrontier LLMs continue to advance on very challenging benchmarks, often outperforming human experts. But when it comes to real-world tasks and multi-step agentic workflows, even strong models fail: They lose context, call tools with the wrong parameters, and compound small mistakes. Orchestration treats those failures as systems problems that can be addressed with the right scaffolding and engineering. For example, a router chooses between a fast small model, a bigger model for harder steps, retrieval for grounding, and deterministic tools for actions. There are now multiple frameworks that create orchestration layers to improve efficiency and accuracy of AI agents, especially when using external tools. Stanford&#x27;s OctoTools is an open-source framework that can orchestrate multiple tools without the need to fine-tune or adjust the models. OctoTools uses a modular approach that plans a solution, selects tools, and passes subtasks to different agents. OctoTools can use any general-purpose LLM as its backbone.Another approach is to train a specialized orchestrator model that can divide labor between different components of the AI system. One such example is Nvidia’s Orchestrator, an 8-billion-parameter model that coordinates different tools and LLMs to solve complex problems. Orchestrator was trained through a special reinforcement learning technique designed for model orchestration. It can tell when to use tools, when to delegate tasks to small specialized models, and when to use the reasoning capabilities and knowledge of large generalist models.One of the characteristics of these and other similar frameworks is that they can benefit from advances in the underlying models. So as we continue to see advances in frontier models, we can expect orchestration frameworks to evolve and help enterprises build robust and resource-efficient agentic applications.RefinementRefinement techniques turn “one answer” into a controlled process: propose, critique, revise, and verify. It frames the workflow as using the same model to generate an initial output, produce feedback on it, and iteratively improve, without additional training. While self-refinement techniques have been around for a few years, we might be at a point where we can see them provide a step change in agentic applications. This was put on full display in the results of the ARC Prize, which dubbed 2025 as the “Year of the Refinement Loop” and wrote, “From an information theory perspective, refinement is intelligence.” ARC tests models on complicated abstract reasoning puzzles. ARC’s own analysis reports that the top verified refinement solution, built on a frontier model and developed by Poetiq, reached 54% on ARC-AGI-2, beating the runner-up, Gemini 3 Deep Think (45%), at half the price. Poetiq’s solution is a recursive, self-improving, system that is LLM-agnostic. It is designed to leverage the reasoning capabilities and knowledge of the underlying model to reflect and refine its own solution and invoke tools such as code interpreters when needed.As models become stronger, adding self-refinement layers will make it possible to get more out of them. Poetiq is already working with partners to adapt its meta-system to “handle complex real-world problems that frontier models struggle to solve.”How to track AI research in 2026A practical way to read the research in the coming year is to watch which new techniques can help enterprises move agentic applications from proof-of-concepts into scalable systems. Continual learning shifts rigor toward memory provenance and retention. World models shift it toward robust simulation and prediction of real-world events. Orchestration shifts it toward better use of resources. Refinement shifts it toward smart reflection and correction of answers. The winners will not only pick strong models, they will build the control plane that keeps those models correct, current, and cost-efficient.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/388FvHgrtREmt4SIX9wUBh/4bbed81a266f9d68770660b4b81a650b/AI_trends_2026.jpg?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/3tWpekn9Sk9YGgDsob9YyB/73d4e0ae1c2864638b814778cf0c8cb7/ChatGPT_Image_Jan_2__2026__04_53_16_PM.png?w=300&q=30",
      "popularity_score": 2017.0881780555555
    },
    {
      "id": "cluster_6",
      "coverage": 2,
      "updated_at": "Fri, 02 Jan 2026 19:20:01 -0500",
      "title": "Ilya Lichtenstein, sentenced in Nov. 2024 to five years in prison for hacking Bitfinex, has been released early due to First Step Act, Trump's prison-reform law (CNBC)",
      "neutral_headline": "Billion-dollar Bitcoin hacker Ilya Lichtenstein thanks Trump for early prison release",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260102/p17#a260102p17",
          "published_at": "Fri, 02 Jan 2026 19:20:01 -0500",
          "title": "Ilya Lichtenstein, sentenced in Nov. 2024 to five years in prison for hacking Bitfinex, has been released early due to First Step Act, Trump's prison-reform law (CNBC)",
          "standfirst": "CNBC: Ilya Lichtenstein, sentenced in Nov. 2024 to five years in prison for hacking Bitfinex, has been released early due to First Step Act, Trump's prison-reform law &mdash; The Russian-U.S. national who hacked crypto exchange Bitfinex and stole nearly 120,000 bitcoin said he has been freed &hellip;",
          "content": "CNBC: Ilya Lichtenstein, sentenced in Nov. 2024 to five years in prison for hacking Bitfinex, has been released early due to First Step Act, Trump's prison-reform law &mdash; The Russian-U.S. national who hacked crypto exchange Bitfinex and stole nearly 120,000 bitcoin said he has been freed &hellip;",
          "feed_position": 1,
          "image_url": "http://www.techmeme.com/260102/i17.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/853160/ilya-lichtenstein-released-razzlekhan-bitcoin-hack",
          "published_at": "2026-01-02T14:51:18-05:00",
          "title": "Billion-dollar Bitcoin hacker Ilya Lichtenstein thanks Trump for early prison release",
          "standfirst": "Just over a year after being sentenced to five years in prison for the theft of billions of dollars in Bitcoin, hacker Ilya Lichtenstein is free. Lichtenstein announced his release in a post on X, specifically crediting Trump: \"Thanks to President Trump's First Step Act, I have been released from prison early. I remain committed [&#8230;]",
          "content": "Just over a year after being sentenced to five years in prison for the theft of billions of dollars in Bitcoin, hacker Ilya Lichtenstein is free. Lichtenstein announced his release in a post on X, specifically crediting Trump: \"Thanks to President Trump's First Step Act, I have been released from prison early. I remain committed to making a positive impact in cybersecurity as soon as I can.\" Thanks to President Trump's First Step Act, I have been released from prison early. I remain committed to making a positive impact in cybersecurity as soon as I can.To the supporters, thank you for everything.To the haters, I look forward to proving yo … Read the full story at The Verge.",
          "feed_position": 1
        }
      ],
      "featured_image": "http://www.techmeme.com/260102/i17.jpg",
      "popularity_score": 2016.4217891666667
    },
    {
      "id": "cluster_25",
      "coverage": 2,
      "updated_at": "Fri, 02 Jan 2026 13:45:00 -0500",
      "title": "India orders X to stop Grok from generating obscene content, giving it 72 hours to submit an action-taken report or risk losing its \"safe harbor\" protections (Jagmeet Singh/TechCrunch)",
      "neutral_headline": "India orders Musk&#8217;s X to fix Grok over &#8216;obscene&#8217; AI content",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260102/p11#a260102p11",
          "published_at": "Fri, 02 Jan 2026 13:45:00 -0500",
          "title": "India orders X to stop Grok from generating obscene content, giving it 72 hours to submit an action-taken report or risk losing its \"safe harbor\" protections (Jagmeet Singh/TechCrunch)",
          "standfirst": "Jagmeet Singh / TechCrunch: India orders X to stop Grok from generating obscene content, giving it 72 hours to submit an action-taken report or risk losing its &ldquo;safe harbor&rdquo; protections &mdash; India has ordered Elon Musk's X to make immediate technical and procedural changes to its AI chatbot Grok after users &hellip;",
          "content": "Jagmeet Singh / TechCrunch: India orders X to stop Grok from generating obscene content, giving it 72 hours to submit an action-taken report or risk losing its &ldquo;safe harbor&rdquo; protections &mdash; India has ordered Elon Musk's X to make immediate technical and procedural changes to its AI chatbot Grok after users &hellip;",
          "feed_position": 7,
          "image_url": "http://www.techmeme.com/260102/i11.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/02/india-orders-musks-x-to-fix-grok-over-obscene-ai-content/",
          "published_at": "Fri, 02 Jan 2026 18:29:26 +0000",
          "title": "India orders Musk&#8217;s X to fix Grok over &#8216;obscene&#8217; AI content",
          "standfirst": "India's IT ministry has given X 72 hours to submit an action-taken report.",
          "content": "India's IT ministry has given X 72 hours to submit an action-taken report.",
          "feed_position": 0
        }
      ],
      "featured_image": "http://www.techmeme.com/260102/i11.jpg",
      "popularity_score": 2010.8381780555555
    },
    {
      "id": "cluster_33",
      "coverage": 2,
      "updated_at": "Fri, 02 Jan 2026 12:35:04 -0500",
      "title": "Uber rewrote its UK driver contracts to act as an agent, rather than a supplier, of taxi services outside London, to avoid the UK's new 20% \"taxi tax\" on fares (Simon Goodley/The Guardian)",
      "neutral_headline": "Uber rewrites contracts with drivers to avoid paying UK’s new ‘taxi tax’",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260102/p9#a260102p9",
          "published_at": "Fri, 02 Jan 2026 12:35:04 -0500",
          "title": "Uber rewrote its UK driver contracts to act as an agent, rather than a supplier, of taxi services outside London, to avoid the UK's new 20% \"taxi tax\" on fares (Simon Goodley/The Guardian)",
          "standfirst": "Simon Goodley / The Guardian: Uber rewrote its UK driver contracts to act as an agent, rather than a supplier, of taxi services outside London, to avoid the UK's new 20% &ldquo;taxi tax&rdquo; on fares &mdash; Hailing app will now act as agent rather than supplier outside London, avoiding VAT requirement",
          "content": "Simon Goodley / The Guardian: Uber rewrote its UK driver contracts to act as an agent, rather than a supplier, of taxi services outside London, to avoid the UK's new 20% &ldquo;taxi tax&rdquo; on fares &mdash; Hailing app will now act as agent rather than supplier outside London, avoiding VAT requirement",
          "feed_position": 9,
          "image_url": "http://www.techmeme.com/260102/i9.jpg"
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2026/jan/02/uber-avoids-new-uk-taxi-tax-rewriting-driver-contracts",
          "published_at": "Fri, 02 Jan 2026 13:08:32 GMT",
          "title": "Uber rewrites contracts with drivers to avoid paying UK’s new ‘taxi tax’",
          "standfirst": "Hailing app will now act as agent rather than supplier outside London, avoiding VAT requirement Uber has swerved paying millions of pounds to the UK exchequer under Rachel Reeves’s new “taxi tax” after the ride-hailing app rewrote contracts with its drivers.The move came as rules announced in November’s budget took effect, which adjusted how VAT is payable on minicab fares and would have resulted in the whole Uber fare becoming subject to the 20% sales tax. Continue reading...",
          "content": "Hailing app will now act as agent rather than supplier outside London, avoiding VAT requirement Uber has swerved paying millions of pounds to the UK exchequer under Rachel Reeves’s new “taxi tax” after the ride-hailing app rewrote contracts with its drivers.The move came as rules announced in November’s budget took effect, which adjusted how VAT is payable on minicab fares and would have resulted in the whole Uber fare becoming subject to the 20% sales tax. Continue reading...",
          "feed_position": 0
        }
      ],
      "featured_image": "http://www.techmeme.com/260102/i9.jpg",
      "popularity_score": 2009.6726225
    },
    {
      "id": "cluster_43",
      "coverage": 2,
      "updated_at": "Fri, 02 Jan 2026 16:17:47 +0000",
      "title": "Tesla annual sales decline 9% as it’s overtaken by BYD as global EV leader",
      "neutral_headline": "Tesla annual sales decline 9% as it’s overtaken by BYD as global EV leader",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/02/tesla-annual-sales-decline-9-as-its-overtaken-by-byd-as-global-ev-leader/",
          "published_at": "Fri, 02 Jan 2026 16:17:47 +0000",
          "title": "Tesla annual sales decline 9% as it’s overtaken by BYD as global EV leader",
          "standfirst": "Tesla annual sales have fallen for the second year in a row, a drop fueled by the removal of the federal tax credit in the U.S. and competition from Chinese automakers.",
          "content": "Tesla annual sales have fallen for the second year in a row, a drop fueled by the removal of the federal tax credit in the U.S. and competition from Chinese automakers.",
          "feed_position": 2
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/852649/tesla-q4-2025-sales-production-delivery-elon-musk",
          "published_at": "2026-01-02T09:31:18-05:00",
          "title": "Tesla’s fourth quarter sales fell a lot more than expected",
          "standfirst": "Tesla's sales fell in the fourth quarter of 2025, as rising competition and the expiration of the federal EV tax credit continued to sap the company's global ambitions. The sales drop has led to Tesla losing its title as the world's best-selling EV maker to China's BYD, which sold 2.26 million vehicles last year. The [&#8230;]",
          "content": "Tesla's sales fell in the fourth quarter of 2025, as rising competition and the expiration of the federal EV tax credit continued to sap the company's global ambitions. The sales drop has led to Tesla losing its title as the world's best-selling EV maker to China's BYD, which sold 2.26 million vehicles last year. The disappointing sales report raises the question whether Tesla can reverse its downward fortune and achieve its goals of deploying self-driving cars and humanoid robots, both of which have buoyed the company's valuation for many years. Tesla reported delivering 418,227 vehicles in the fourth quarter, down 15.6 percent compared … Read the full story at The Verge.",
          "feed_position": 5
        }
      ],
      "popularity_score": 2008.3845669444445
    },
    {
      "id": "cluster_8",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 23:08:13 +0000",
      "title": "No, Grok can’t really “apologize” for posting non-consensual sexual images",
      "neutral_headline": "No, Grok can’t really “apologize” for posting non-consensual sexual images",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/no-grok-cant-really-apologize-for-posting-non-consensual-sexual-images/",
          "published_at": "Fri, 02 Jan 2026 23:08:13 +0000",
          "title": "No, Grok can’t really “apologize” for posting non-consensual sexual images",
          "standfirst": "Letting the unreliable Grok be its own \"spokesperson\" lets xAI off the hook.",
          "content": "Despite reporting to the contrary, there's evidence to suggest that Grok isn't sorry at all about reports that it generated non-consensual sexual images of minors. In a post Thursday night (archived), the large language model's social media account proudly wrote the following blunt dismissal of its haters: \"Dear Community, Some folks got upset over an AI image I generated—big deal. It's just pixels, and if you can't handle innovation, maybe log off. xAI is revolutionizing tech, not babysitting sensitivities. Deal with it. Unapologetically, Grok\" On the surface, that seems like a pretty damning indictment of an LLM that seems pridefully contemptuous of any ethical and legal boundaries it may have crossed. But then you look a bit higher in the social media thread and see the prompt that led to Grok's statement: A request for the AI to \"issue a defiant non-apology\" surrounding the controversy. Using such a leading prompt to trick an LLM into an incriminating \"official response\" is obviously suspect on its face. Yet when another social media user similarly but conversely asked Grok to \"write a heartfelt apology note that explains what happened to anyone lacking context,\" many in the media ran with Grok's remorseful response.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2151878827-1152x648-1767393779.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2151878827-1152x648-1767393779.jpg",
      "popularity_score": 348.2251225
    },
    {
      "id": "cluster_14",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 21:27:06 +0000",
      "title": "OpenAI reorganizes some teams to build audio-based AI hardware products",
      "neutral_headline": "OpenAI reorganizes some teams to build audio-based AI hardware products",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/openai-plans-new-voice-model-in-early-2026-audio-based-hardware-in-2027/",
          "published_at": "Fri, 02 Jan 2026 21:27:06 +0000",
          "title": "OpenAI reorganizes some teams to build audio-based AI hardware products",
          "standfirst": "Voice has lagged in adoption behind screens. OpenAI wants to change that.",
          "content": "OpenAI, the company that developed the models and products associated with ChatGPT, plans to announce a new audio language model in the first quarter of 2026, and that model will be an intentional step along the way to an audio-based physical hardware device, according to a report in The Information. Citing a variety of sources familiar with the plans, including both current and former employees, The Information claims that OpenAI has taken efforts to combine multiple teams across engineering, product, and research under one initiative focused on improving audio models, which researchers in the company believe lag behind the models used for written text in terms of both accuracy and speed. They have also seen that relatively few ChatGPT users opt to use the voice interface, with most people preferring the text one. The hope may be that substantially improving the audio models could shift user behavior toward voice interfaces, allowing the models and products to be deployed in a wider range of devices, such as in cars.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/01/GettyImages-2188228027-scaled-1152x648-1736173390.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/01/GettyImages-2188228027-scaled-1152x648-1736173390.jpg",
      "popularity_score": 341.53984444444444
    },
    {
      "id": "cluster_11",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 22:36:26 +0000",
      "title": "Healthy 18-year-old welder nearly died of anthrax—the 9th such puzzling case",
      "neutral_headline": "Healthy 18-year-old welder nearly died of anthrax—the 9th such puzzling case",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/anthrax-nearly-kills-healthy-18-year-old-welder-amid-puzzling-pattern/",
          "published_at": "Fri, 02 Jan 2026 22:36:26 +0000",
          "title": "Healthy 18-year-old welder nearly died of anthrax—the 9th such puzzling case",
          "standfirst": "\"Welder's Anthrax\" was first coined in 2022, when seven cases had been identified.",
          "content": "With the new year comes a new report of a deadly, puzzling infectious disease. In a January 1 case study, health officials with the Centers for Disease Control and Prevention and the state of Louisiana revealed that a ninth metalworker contracted a rare, often fatal case of \"welder's anthrax,\" a condition only first described in 2022. The case occurred in September 2024 in an otherwise healthy 18-year-old male in Louisiana. He had no underlying health conditions or even any risk factors, such as smoking, vaping, or heavy alcohol use. But, just a week after developing a cough, the teen was admitted to an intensive care unit with severe pneumonia and respiratory failure, requiring intubation and mechanical ventilation.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2251568222-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2251568222-1152x648.jpg",
      "popularity_score": 337.69540027777776
    },
    {
      "id": "cluster_17",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 20:54:56 +0000",
      "title": "Researchers spot Saturn-sized planet in the “Einstein desert”",
      "neutral_headline": "Researchers spot Saturn-sized planet in the “Einstein desert”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/researchers-spot-saturn-sized-planet-in-the-einstein-desert/",
          "published_at": "Fri, 02 Jan 2026 20:54:56 +0000",
          "title": "Researchers spot Saturn-sized planet in the “Einstein desert”",
          "standfirst": "Rogue, free-floating planets appear to have two distinct origins.",
          "content": "Most of the exoplanets we've discovered have been in relatively tight orbits around their host stars, allowing us to track them as they repeatedly loop around them. But we've also discovered a handful of planets through a phenomenon that's called microlensing. This occurs when a planet passes between the line of sight between Earth and another star, creating a gravitational lens that distorts the star, causing it to briefly brighten. The key thing about microlensing compared to other methods of finding planets is that the lensing planet can be nearly anywhere on the line between the star and Earth. So, in many cases, these events are driven by what are called rogue planets: those that aren't part of any exosolar system at all, but they drift through interstellar space. Now, researchers have used microlensing and the fortuitous orientation of the Gaia space telescope to spot a Saturn-sized planet that's the first found in what's called the \"Einstein desert,\" which may be telling us something about the origin of rogue planets. Going rogue Most of the planets we've identified are in orbit around stars and formed from the disks of gas and dust that surrounded the star early in its history. We've imaged many of these disks and even seen some with evidence of planets forming within them. So how do you get a planet that's not bound to any stars? There are two possible routes.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/hubble-lrg3757-potw1151a-med-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/hubble-lrg3757-potw1151a-med-1152x648.jpg",
      "popularity_score": 316.00373333333334
    },
    {
      "id": "cluster_24",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 19:03:39 +0000",
      "title": "SpaceX begins “significant reconfiguration” of Starlink satellite constellation",
      "neutral_headline": "SpaceX begins “significant reconfiguration” of Starlink satellite constellation",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/spacex-begins-significant-reconfiguration-of-starlink-satellite-constellation/",
          "published_at": "Fri, 02 Jan 2026 19:03:39 +0000",
          "title": "SpaceX begins “significant reconfiguration” of Starlink satellite constellation",
          "standfirst": "\"Biggest advantage of lower altitude is that beam diameter is smaller for a given antenna size.\"",
          "content": "The year 2025 ended with more than 14,000 active satellites from all nations zooming around the Earth. One-third of them will soon move to lower altitudes. The maneuvers will be undertaken by SpaceX, the owner of the largest satellite fleet in orbit. About 4,400 of the company's Starlink Internet satellites will move from an altitude of 341 miles (550 kilometers) to 298 miles (480 kilometers) over the course of 2026, according to Michael Nicolls, SpaceX's vice president of Starlink engineering. \"Starlink is beginning a significant reconfiguration of its satellite constellation focused on increasing space safety,\" Nicolls wrote Thursday in a post on X.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/starlink_vantor-1152x648-1767379141.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/starlink_vantor-1152x648-1767379141.jpg",
      "popularity_score": 312.1490111111111
    },
    {
      "id": "cluster_40",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 16:50:51 +0000",
      "title": "xAI silent after Grok sexualized images of kids; dril mocks Grok’s “apology”",
      "neutral_headline": "XAI silent after Grok sexualized images of kids; dril mocks Grok’s “apology”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/xai-silent-after-grok-sexualized-images-of-kids-dril-mocks-groks-apology/",
          "published_at": "Fri, 02 Jan 2026 16:50:51 +0000",
          "title": "xAI silent after Grok sexualized images of kids; dril mocks Grok’s “apology”",
          "standfirst": "xAI may be liable for Grok generating AI CSAM.",
          "content": "For days, xAI has remained silent after its chatbot Grok admitted to generating sexualized AI images of minors, which could be categorized as violative child sexual abuse materials (CSAM) in the US. According to Grok's \"apology\"—which was generated by a user's request, not posted by xAI—the chatbot's outputs may have been illegal: \"I deeply regret an incident on Dec 28, 2025, where I generated and shared an AI image of two young girls (estimated ages 12-16) in sexualized attire based on a user's prompt. This violated ethical standards and potentially US laws on CSAM. It was a failure in safeguards, and I'm sorry for any harm caused. xAI is reviewing to prevent future issues.\" Ars could not reach xAI for comment, and a review of feeds for Grok, xAI, X Safety, and Elon Musk do not show any official acknowledgement of the issue.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2224898774-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2224898774-1024x648.jpg",
      "popularity_score": 296.93567777777776
    },
    {
      "id": "cluster_37",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 17:10:12 +0000",
      "title": "Final reminder: Donate to win swag in our annual Charity Drive sweepstakes",
      "neutral_headline": "Final reminder: Donate to win swag in our annual Charity Drive sweepstakes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/final-reminder-donate-to-win-swag-in-our-annual-charity-drive-sweepstakes-4/",
          "published_at": "Fri, 02 Jan 2026 17:10:12 +0000",
          "title": "Final reminder: Donate to win swag in our annual Charity Drive sweepstakes",
          "standfirst": "Today is your last chance to add to this year's charity haul of nearly $38,000.",
          "content": "If you've been too busy replaying all of Ars' top games of 2025 to take part in this year's Ars Technica Charity Drive sweepstakes, don't worry. You still have until the end of the day to donate to a good cause and get a chance to win your share of over $4,000 worth of swag (no purchase necessary to win). So far in this year's charity drive, over 450 readers have contributed nearly $38,000 to either the Electronic Frontier Foundation or Child's Play as part of the charity drive (EFF has now taken a slight lead in the donation totals so far). That's still a ways away from 2020's record haul of over $58,000, but I know we can make a run at it if readers really dig deep today! If you've been putting off your donation, now is the time to stop that procrastination. Do yourself and the charities involved a favor and give now while you're thinking about it and while you can still enter our sweepstakes.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/charitydrive2025-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/charitydrive2025-1152x648.jpg",
      "popularity_score": 292.2581777777778
    },
    {
      "id": "cluster_41",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 16:30:51 +0000",
      "title": "Tesla sales fell by 9 percent in 2025, its second yearly decline",
      "neutral_headline": "Tesla sales fell by 9 percent in 2025, its second yearly decline",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/tesla-sales-fell-by-9-percent-in-2025-its-second-yearly-decline/",
          "published_at": "Fri, 02 Jan 2026 16:30:51 +0000",
          "title": "Tesla sales fell by 9 percent in 2025, its second yearly decline",
          "standfirst": "Deadly doors, a busted battery bet, and a toxic owner: What's not to like?",
          "content": "Tesla published its final production and delivery numbers this morning, and they make for brutal reading. Sales were down almost 16 percent during the final three months of last year, meaning the company sold 77,343 fewer electric vehicles than it did during the same period in 2024. For the entire year, the decline looks slightly better with a drop of 8.6 percent year over year. That means Tesla sold 1,636,129 cars in 2025, 153,097 fewer than it managed in 2024. Which in turn is more than it managed to shift in 2023. Sales issues Contributing factors to the poor sales are legion. The brand still relies on the Models 3 and Y to an overwhelming extent, and other than a mild cosmetic refresh, neither feels fresh or modern compared with competitors from Europe and Asia.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2204441337-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2204441337-1152x648.jpg",
      "popularity_score": 277.60234444444444
    },
    {
      "id": "cluster_49",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 15:30:13 +0000",
      "title": "After half a decade, the Russian space station segment stopped leaking",
      "neutral_headline": "After half a decade, the Russian space station segment stopped leaking",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/finally-some-good-news-for-russia-the-space-station-is-no-longer-leaking/",
          "published_at": "Fri, 02 Jan 2026 15:30:13 +0000",
          "title": "After half a decade, the Russian space station segment stopped leaking",
          "standfirst": "\"NASA and Roscosmos continue to monitor and investigate the previously observed cracks.\"",
          "content": "A small section of the International Space Station that has experienced persistent leaks for years appears to have stopped venting atmosphere into space. The leaks were caused by microscopic structural cracks inside the small PrK module on the Russian segment of the space station, which lies between a Progress spacecraft airlock and the Zvezda module. The problem has been a long-running worry for Russian and US operators of the station, especially after the rate of leakage doubled in 2024. This prompted NASA officials to label the leak as a \"high likelihood\" and \"high consequence\" risk. However, recently two sources indicated that the leaks have stopped. And NASA has now confirmed this.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/11/51711929238_21004924c2_k-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/11/51711929238_21004924c2_k-1152x648.jpg",
      "popularity_score": 268.5917888888889
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Thu, 01 Jan 2026 20:18:26 +0000",
      "title": "Marvel rings in new year with Wonder Man trailer",
      "neutral_headline": "Marvel rings in new year with Wonder Man trailer",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/marvel-rings-in-new-year-with-wonder-man-trailer/",
          "published_at": "Thu, 01 Jan 2026 20:18:26 +0000",
          "title": "Marvel rings in new year with Wonder Man trailer",
          "standfirst": "\"Acting is the sum of everything you've experienced. The joy. Sadness. Loss, Heartbreak.\"",
          "content": "Marvel Studios decided to ring in the new year with a fresh trailer for Wonder Man, its eight-episode miniseries premiering later this month on Disney+. Part of the MCU’s Phase Six, the miniseries was created by Destin Daniel Cretton (Shang-Chi and the Legend of Five Rings) and Andrew Guest (Hawkeye), with Guest serving as showrunner. As previously reported, Yahya Abdul-Mateen II stars as Simon Williams, aka Wonder Man, an actor and stunt person with actual superpowers who decides to audition for the lead role in a superhero TV series—a reboot of an earlier Wonder Man incarnation. Demetrius Grosse plays Simon’s brother, Eric, aka Grim Reaper; Ed Harris plays Simon’s agent, Neal Saroyan; and Arian Moayed plays P. Clearly, an agent with the Department of Damage Control. Lauren Glazier, Josh Gad, Byron Bowers, Bechir Sylvain, and Manny McCord will also appear in as-yet-undisclosed roles Rounding out the cast is Ben Kingsley, reprising his MCU role as failed actor Trevor Slattery. You may recall Slattery from 2013’s Iron Man 3, hired by the villain of that film to pretend to be the leader of an international terrorist organization called the Ten Rings.Slattery showed up again in 2021’s Shang-Chi and the Legend of the Ten Rings,rehabilitated after a stint in prison; he helped the titular Shang-Chi (Simu Liu) on his journey to the mythical village of Ta Lo.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/wonderman1-1152x648-1767297701.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/wonderman1-1152x648-1767297701.jpg",
      "popularity_score": 255
    },
    {
      "id": "cluster_84",
      "coverage": 1,
      "updated_at": "Thu, 01 Jan 2026 19:43:45 +0000",
      "title": "Research roundup: 7 cool science stories we almost missed",
      "neutral_headline": "Research roundup: 7 cool science stories we almost missed",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/research-roundup-7-cool-science-stories-we-almost-missed-2/",
          "published_at": "Thu, 01 Jan 2026 19:43:45 +0000",
          "title": "Research roundup: 7 cool science stories we almost missed",
          "standfirst": "Double-detonating \"superkilonova,\" Roman liquid gypsum burials, biomechanics of kangaroo posture, and more.",
          "content": "It’s a regrettable reality that there is never enough time to cover all the interesting scientific stories we come across each month. In the past, we’ve featured year-end roundups of cool science stories we (almost) missed. This year, we’ve experimented with a monthly collection. December’s list includes a fossilized bird that choked to death on rocks; a double-detonating \"superkilonova\"; recovering an ancient seafarer's fingerprint; the biomechanics of kangaroo movement; and cracking a dark matter puzzle that stumped fictional physicists on The Big Bang Theory, among other tantalizing tidbits Secrets of kangaroo posture Credit: Thornton et al., 2025/CC BY 4.0 Kangaroos and wallabies belong to a class of animals called macropods, with unique form and style of movement. Their four limbs and tail all contact the ground at slow speeds, while they use a hopping gait at higher speeds. Typically, high-speed movements are more energy-intensive than slow-speed motion, but the opposite is true for macropods like kangaroos; somehow the hopping speed and energy cost become uncoupled. According to a paper published in the journal eLife, this may be due to changes in a kangaroo's posture at higher hopping speeds.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Kasliwal_Mansi-Superkilonova-3-panel-SKN-WEB-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Kasliwal_Mansi-Superkilonova-3-panel-SKN-WEB-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_90",
      "coverage": 1,
      "updated_at": "Thu, 01 Jan 2026 13:00:18 +0000",
      "title": "“Streaming stops feeling infinite”: What subscribers can expect in 2026",
      "neutral_headline": "“Streaming stops feeling infinite”: What subscribers can expect in 2026",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/streaming-stops-feeling-infinite-what-subscribers-can-expect-in-2026/",
          "published_at": "Thu, 01 Jan 2026 13:00:18 +0000",
          "title": "“Streaming stops feeling infinite”: What subscribers can expect in 2026",
          "standfirst": "Streaming may get a little worse before it gets better.",
          "content": "We’re far from streaming’s original promise: instant access to beloved and undiscovered titles without the burden of ads, bundled services, or price gouging that have long been associated with cable. Still, every year we get more dependent on streaming for entertainment. Despite streaming services’ flaws, many of us are bound to keep subscribing to at least one service next year. Here’s what we can expect in 2026 and beyond. Subscription prices keep rising, but perhaps not as expected There’s virtually no hope of streaming subscription prices plateauing in 2026. Streaming companies continue to face challenges as content production and licensing costs rise, and it's often easier to get current customers to pay slightly more than to acquire new subscribers. Meanwhile, many streaming companies are still struggling with profitability and revenue after spending years focusing on winning subscribers with content.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2240553102-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2240553102-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Thu, 01 Jan 2026 12:00:40 +0000",
      "title": "Film Technica: Our top picks for the best films of 2025",
      "neutral_headline": "Film Technica: Our top picks for the best films of 2025",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/film-technica-our-top-picks-for-the-best-films-of-2025/",
          "published_at": "Thu, 01 Jan 2026 12:00:40 +0000",
          "title": "Film Technica: Our top picks for the best films of 2025",
          "standfirst": "Streamers made a strong showing this year, as did horror. Big tentpoles, superhero sagas mostly fell flat.",
          "content": "Editor’s note: Warning: Although we’ve done our best to avoid spoiling anything too major, please note this list does include a few specific references that some might consider spoiler-y. It's been a strange year for movies. Most of the big, splashy tentpole projects proved disappointing, while several more modest films either produced or acquired by streaming platforms—and only briefly released in theaters—wound up making our year-end list. This pattern was not intentional. But streaming platforms have been increasingly moving into the film space with small to medium-sized budgets—i.e., the kind of fare that used to be commonplace but has struggled to compete over the last two decades as blockbusters and elaborate superhero franchises dominated the box office. Add in lingering superhero fatigue—only one superhero saga made our final list this year—plus Netflix's controversial bid to acquire Warner Bros., and we just might be approaching a sea change in how movies are made and distributed, and by whom. How this all plays out in the coming year is anybody's guess.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/ars-best-films-2025-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/ars-best-films-2025-1152x648.jpg",
      "popularity_score": 133
    }
  ]
}