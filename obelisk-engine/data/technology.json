{
  "updated_at": "2026-02-01T05:01:23.013Z",
  "clusters": [
    {
      "id": "cluster_4",
      "coverage": 3,
      "updated_at": "2026-01-31T18:37:56-05:00",
      "title": "Nvidia CEO denies he’s ‘unhappy’ with OpenAI",
      "neutral_headline": "Nvidia CEO denies he’s ‘unhappy’ with OpenAI",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/871818/nvidia-ceo-jensen-huang-unhappy-openai",
          "published_at": "2026-01-31T18:37:56-05:00",
          "title": "Nvidia CEO denies he’s ‘unhappy’ with OpenAI",
          "standfirst": "Nvidia's CEO Jensen Huang denied reports that he was unhappy with OpenAI and said his company still planned to make a \"huge\" investment in the ChatGPT firm. NVIDIA announced in September that it would invest up to $100 billion in OpenAI, but recently, there have been suggestions that the deal might not happen. While Huang [&#8230;]",
          "content": "Nvidia's CEO Jensen Huang denied reports that he was unhappy with OpenAI and said his company still planned to make a \"huge\" investment in the ChatGPT firm. NVIDIA announced in September that it would invest up to $100 billion in OpenAI, but recently, there have been suggestions that the deal might not happen. While Huang told reporters in Taipei that it was \"nonsense\" to say he was unhappy with OpenAI, when asked if Nvidia would be investing over $100 billion, he replied, \"No, nothing like that.\" Reuters reported Huang said: \"We are going to make a huge investment in OpenAI. I believe in OpenAI, the work that they do is incredible, they … Read the full story at The Verge.",
          "feed_position": 0
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/31/nvidia-ceo-pushes-back-against-report-that-his-companys-100b-openai-investment-has-stalled/",
          "published_at": "Sat, 31 Jan 2026 17:54:12 +0000",
          "title": "Nvidia CEO pushes back against report that his company&#8217;s $100B OpenAI investment has stalled",
          "standfirst": "Nvidia CEO Jensen Huang said that a recent report of friction between his company and OpenAI was “nonsense.”",
          "content": "Nvidia CEO Jensen Huang said that a recent report of friction between his company and OpenAI was “nonsense.”",
          "feed_position": 2
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260131/p10#a260131p10",
          "published_at": "Sat, 31 Jan 2026 10:30:47 -0500",
          "title": "Jensen Huang says Nvidia's OpenAI investment will be \"the largest investment we've ever made\", after a report said plans to invest $100B in OpenAI stalled (Debby Wu/Bloomberg)",
          "standfirst": "Debby Wu / Bloomberg: Jensen Huang says Nvidia's OpenAI investment will be &ldquo;the largest investment we've ever made&rdquo;, after a report said plans to invest $100B in OpenAI stalled &mdash; Nvidia Corp. Chief Executive Officer Jensen Huang said the company will be participating in OpenAI's latest funding round &hellip;",
          "content": "Debby Wu / Bloomberg: Jensen Huang says Nvidia's OpenAI investment will be &ldquo;the largest investment we've ever made&rdquo;, after a report said plans to invest $100B in OpenAI stalled &mdash; Nvidia Corp. Chief Executive Officer Jensen Huang said the company will be participating in OpenAI's latest funding round &hellip;",
          "feed_position": 8,
          "image_url": "http://www.techmeme.com/260131/i10.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260131/i10.jpg",
      "popularity_score": 3014.6091630555557
    },
    {
      "id": "cluster_8",
      "coverage": 3,
      "updated_at": "Sat, 31 Jan 2026 21:27:25 +0000",
      "title": "SpaceX seeks federal approval to launch 1 million solar-powered satellite data centers",
      "neutral_headline": "SpaceX wants to put 1 million solar-powered data centers into orbit",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/31/spacex-seeks-federal-approval-to-launch-1-million-solar-powered-satellite-data-centers/",
          "published_at": "Sat, 31 Jan 2026 21:27:25 +0000",
          "title": "SpaceX seeks federal approval to launch 1 million solar-powered satellite data centers",
          "standfirst": "SpaceX's filing claims these satellites will be “a first step towards becoming a Kardashev II-level civilization — one that can harness the Sun’s full power.\"",
          "content": "SpaceX's filing claims these satellites will be “a first step towards becoming a Kardashev II-level civilization — one that can harness the Sun’s full power.\"",
          "feed_position": 1
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/871641/spacex-fcc-1-million-solar-powered-data-centers-satellites-orbit",
          "published_at": "2026-01-31T14:38:36-05:00",
          "title": "SpaceX wants to put 1 million solar-powered data centers into orbit",
          "standfirst": "SpaceX filed a request with the FCC on Friday seeking approval to put a constellation of 1 million data center satellites into orbit. While the FCC is unlikely to approve a network that expansive, SpaceX's strategy has been to request approval for unrealistically large numbers of satellites as a starting point for negotiations. The filing [&#8230;]",
          "content": "SpaceX filed a request with the FCC on Friday seeking approval to put a constellation of 1 million data center satellites into orbit. While the FCC is unlikely to approve a network that expansive, SpaceX's strategy has been to request approval for unrealistically large numbers of satellites as a starting point for negotiations. The filing proposes establishing a network of solar-powered data centers in low Earth orbit that communicate with one another via lasers. The filling speaks of the constellation in ambitious sci-fi terms, calling it a \"first step towards becoming a Kardashev II-level civilization - one that can harness the Sun's ful … Read the full story at The Verge.",
          "feed_position": 2
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260131/p12#a260131p12",
          "published_at": "Sat, 31 Jan 2026 13:10:01 -0500",
          "title": "Filing: SpaceX is seeking FCC approval to launch 1M satellites into space; SpaceX claims the fleet will orbit the Earth and use the sun to power AI data centers (Reuters)",
          "standfirst": "Reuters: Filing: SpaceX is seeking FCC approval to launch 1M satellites into space; SpaceX claims the fleet will orbit the Earth and use the sun to power AI data centers &mdash; Elon Musk's SpaceX wants to launch a constellation of 1 million satellites that will orbit Earth and harness the sun to power AI data centers &hellip;",
          "content": "Reuters: Filing: SpaceX is seeking FCC approval to launch 1M satellites into space; SpaceX claims the fleet will orbit the Earth and use the sun to power AI data centers &mdash; Elon Musk's SpaceX wants to launch a constellation of 1 million satellites that will orbit Earth and harness the sun to power AI data centers &hellip;",
          "feed_position": 6,
          "image_url": "http://www.techmeme.com/260131/i12.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260131/i12.jpg",
      "popularity_score": 3012.433885277778
    },
    {
      "id": "cluster_7",
      "coverage": 2,
      "updated_at": "Sat, 31 Jan 2026 16:40:01 -0500",
      "title": "An interview with Nvidia's senior VP of hardware engineering, Andrew Bell, on continuing to provide Shield Android TV software updates a decade after its launch (Ryan Whitwam/Ars Technica)",
      "neutral_headline": "Inside Nvidia's 10-year effort to make the Shield TV the...",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260131/p16#a260131p16",
          "published_at": "Sat, 31 Jan 2026 16:40:01 -0500",
          "title": "An interview with Nvidia's senior VP of hardware engineering, Andrew Bell, on continuing to provide Shield Android TV software updates a decade after its launch (Ryan Whitwam/Ars Technica)",
          "standfirst": "Ryan Whitwam / Ars Technica: An interview with Nvidia's senior VP of hardware engineering, Andrew Bell, on continuing to provide Shield Android TV software updates a decade after its launch &mdash; &ldquo;Selfishly a little bit, we built Shield for ourselves.&rdquo; &mdash; It took Android devicemakers a very long time to commit to long-term update support.",
          "content": "Ryan Whitwam / Ars Technica: An interview with Nvidia's senior VP of hardware engineering, Andrew Bell, on continuing to provide Shield Android TV software updates a decade after its launch &mdash; &ldquo;Selfishly a little bit, we built Shield for ourselves.&rdquo; &mdash; It took Android devicemakers a very long time to commit to long-term update support.",
          "feed_position": 2,
          "image_url": "http://www.techmeme.com/260131/i16.jpg"
        },
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/inside-nvidias-10-year-effort-to-make-the-shield-tv-the-most-updated-android-device-ever/",
          "published_at": "Fri, 30 Jan 2026 12:00:35 +0000",
          "title": "Inside Nvidia's 10-year effort to make the Shield TV the most updated Android device ever",
          "standfirst": "\"Selfishly a little bit, we built Shield for ourselves.\"",
          "content": "It took Android devicemakers a very long time to commit to long-term update support. Samsung and Google have only recently decided to offer seven years of updates for their flagship Android devices, but a decade ago, you were lucky to get more than one or two updates on even the most expensive Android phones and tablets. How is it, then, that an Android-powered set-top box from 2015 is still going strong? Nvidia released the first Shield Android TV in 2015, and according to the company's senior VP of hardware engineering, Andrew Bell, supporting these devices has been a labor of love. And the team at Nvidia still loves the Shield. Bell assures us that Nvidia has never given up, even when it looked like support for the Shield was waning, and it doesn't plan to stop any time soon. The soul of Shield Gaming has been central to Nvidia since its start, and that focus gave rise to the Shield. \"Pretty much everybody who worked at Nvidia in the early days really wanted to make a game console,\" said Bell, who has worked at the company for 25 years.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-1152x648.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260131/i16.jpg",
      "popularity_score": 2012.6438852777778
    },
    {
      "id": "cluster_16",
      "coverage": 2,
      "updated_at": "Sat, 31 Jan 2026 19:00:00 GMT",
      "title": "Most RAG systems don’t understand sophisticated documents — they shred them",
      "neutral_headline": "Most RAG systems don’t understand sophisticated documents — they shred them",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/most-rag-systems-dont-understand-documents-they-shred-them",
          "published_at": "Sat, 31 Jan 2026 19:00:00 GMT",
          "title": "Most RAG systems don’t understand sophisticated documents — they shred them",
          "standfirst": "By now, many enterprises have deployed some form of RAG. The promise is seductive: index your PDFs, connect an LLM and instantly democratize your corporate knowledge.But for industries dependent on heavy engineering, the reality has been underwhelming. Engineers ask specific questions about infrastructure, and the bot hallucinates.The failure isn&#x27;t in the LLM. The failure is in the preprocessing.Standard RAG pipelines treat documents as flat strings of text. They use \"fixed-size chunking\" (cutting a document every 500 characters). This works for prose, but it destroys the logic of technical manuals. It slices tables in half, severs captions from images, and ignores the visual hierarchy of the page.Improving RAG reliability isn&#x27;t about buying a bigger model; it&#x27;s about fixing the \"dark data\" problem through semantic chunking and multimodal textualization.Here is the architectural framework for building a RAG system that can actually read a manual.The fallacy of fixed-size chunkingIn a standard Python RAG tutorial, you split text by character count. In an enterprise PDF, this is disastrous.If a safety specification table spans 1,000 tokens, and your chunk size is 500, you have just split the \"voltage limit\" header from the \"240V\" value. The vector database stores them separately. When a user asks, \"What is the voltage limit?\", the retrieval system finds the header but not the value. The LLM, forced to answer, often guesses.The solution: Semantic chunkingThe first step to fixing production RAG is abandoning arbitrary character counts in favor of document intelligence.Using layout-aware parsing tools (such as Azure Document Intelligence), we can segment data based on document structure such as chapters, sections and paragraphs, rather than token count.Logical cohesion: A section describing a specific machine part is kept as a single vector, even if it varies in length.Table preservation: The parser identifies a table boundary and forces the entire grid into a single chunk, preserving the row-column relationships that are vital for accurate retrieval.In our internal qualitative benchmarks, moving from fixed to semantic chunking significantly improved the retrieval accuracy of tabular data, effectively stopping the fragmentation of technical specs.Unlocking visual dark dataThe second failure mode of enterprise RAG is blindness. A massive amount of corporate IP exists not in text, but in flowcharts, schematics and system architecture diagrams. Standard embedding models (like text-embedding-3-small) cannot \"see\" these images. They are skipped during indexing.If your answer lies in a flowchart, your RAG system will say, \"I don&#x27;t know.\"The solution: Multimodal textualizationTo make diagrams searchable, we implemented a multimodal preprocessing step using vision-capable models (specifically GPT-4o) before the data ever hits the vector store.OCR extraction: High-precision optical character recognition pulls text labels from within the image.Generative captioning: The vision model analyzes the image and generates a detailed natural language description (\"A flowchart showing that process A leads to process B if the temperature exceeds 50 degrees\").Hybrid embedding: This generated description is embedded and stored as metadata linked to the original image.Now, when a user searches for \"temperature process flow,\" the vector search matches the description, even though the original source was a PNG file.The trust layer: Evidence-based UIFor enterprise adoption, accuracy is only half the battle. The other half is verifiability.In a standard RAG interface, the chatbot gives a text answer and cites a filename. This forces the user to download the PDF and hunt for the page to verify the claim. For high-stakes queries (\"Is this chemical flammable?\"), users simply won&#x27;t trust the bot.The architecture should implement visual citation. Because we preserved the link between the text chunk and its parent image during the preprocessing phase, the UI can display the exact chart or table used to generate the answer alongside the text response.This \"show your work\" mechanism allows humans to verify the AI&#x27;s reasoning instantly, bridging the trust gap that kills so many internal AI projects.Future-proofing: Native multimodal embeddingsWhile the \"textualization\" method (converting images to text descriptions) is the practical solution for today, the architecture is rapidly evolving.We are already seeing the emergence of native multimodal embeddings (such as Cohere’s Embed 4). These models can map text and images into the same vector space without the intermediate step of captioning. While we currently use a multi-stage pipeline for maximum control, the future of data infrastructure will likely involve \"end-to-end\" vectorization where the layout of a page is embedded directly.Furthermore, as long context LLMs become cost-effective, the need for chunking may diminish. We may soon pass entire manuals into the context window. However, until latency and cost for million-token calls drop significantly, semantic preprocessing remains the most economically viable strategy for real-time systems.ConclusionThe difference between a RAG demo and a production system is how it handles the messy reality of enterprise data.Stop treating your documents as simple strings of text. If you want your AI to understand your business, you must respect the structure of your documents. By implementing semantic chunking and unlocking the visual data within your charts, you transform your RAG system from a \"keyword searcher\" into a true \"knowledge assistant.\"Dippu Kumar Singh is an AI architect and data engineer.",
          "content": "By now, many enterprises have deployed some form of RAG. The promise is seductive: index your PDFs, connect an LLM and instantly democratize your corporate knowledge.But for industries dependent on heavy engineering, the reality has been underwhelming. Engineers ask specific questions about infrastructure, and the bot hallucinates.The failure isn&#x27;t in the LLM. The failure is in the preprocessing.Standard RAG pipelines treat documents as flat strings of text. They use \"fixed-size chunking\" (cutting a document every 500 characters). This works for prose, but it destroys the logic of technical manuals. It slices tables in half, severs captions from images, and ignores the visual hierarchy of the page.Improving RAG reliability isn&#x27;t about buying a bigger model; it&#x27;s about fixing the \"dark data\" problem through semantic chunking and multimodal textualization.Here is the architectural framework for building a RAG system that can actually read a manual.The fallacy of fixed-size chunkingIn a standard Python RAG tutorial, you split text by character count. In an enterprise PDF, this is disastrous.If a safety specification table spans 1,000 tokens, and your chunk size is 500, you have just split the \"voltage limit\" header from the \"240V\" value. The vector database stores them separately. When a user asks, \"What is the voltage limit?\", the retrieval system finds the header but not the value. The LLM, forced to answer, often guesses.The solution: Semantic chunkingThe first step to fixing production RAG is abandoning arbitrary character counts in favor of document intelligence.Using layout-aware parsing tools (such as Azure Document Intelligence), we can segment data based on document structure such as chapters, sections and paragraphs, rather than token count.Logical cohesion: A section describing a specific machine part is kept as a single vector, even if it varies in length.Table preservation: The parser identifies a table boundary and forces the entire grid into a single chunk, preserving the row-column relationships that are vital for accurate retrieval.In our internal qualitative benchmarks, moving from fixed to semantic chunking significantly improved the retrieval accuracy of tabular data, effectively stopping the fragmentation of technical specs.Unlocking visual dark dataThe second failure mode of enterprise RAG is blindness. A massive amount of corporate IP exists not in text, but in flowcharts, schematics and system architecture diagrams. Standard embedding models (like text-embedding-3-small) cannot \"see\" these images. They are skipped during indexing.If your answer lies in a flowchart, your RAG system will say, \"I don&#x27;t know.\"The solution: Multimodal textualizationTo make diagrams searchable, we implemented a multimodal preprocessing step using vision-capable models (specifically GPT-4o) before the data ever hits the vector store.OCR extraction: High-precision optical character recognition pulls text labels from within the image.Generative captioning: The vision model analyzes the image and generates a detailed natural language description (\"A flowchart showing that process A leads to process B if the temperature exceeds 50 degrees\").Hybrid embedding: This generated description is embedded and stored as metadata linked to the original image.Now, when a user searches for \"temperature process flow,\" the vector search matches the description, even though the original source was a PNG file.The trust layer: Evidence-based UIFor enterprise adoption, accuracy is only half the battle. The other half is verifiability.In a standard RAG interface, the chatbot gives a text answer and cites a filename. This forces the user to download the PDF and hunt for the page to verify the claim. For high-stakes queries (\"Is this chemical flammable?\"), users simply won&#x27;t trust the bot.The architecture should implement visual citation. Because we preserved the link between the text chunk and its parent image during the preprocessing phase, the UI can display the exact chart or table used to generate the answer alongside the text response.This \"show your work\" mechanism allows humans to verify the AI&#x27;s reasoning instantly, bridging the trust gap that kills so many internal AI projects.Future-proofing: Native multimodal embeddingsWhile the \"textualization\" method (converting images to text descriptions) is the practical solution for today, the architecture is rapidly evolving.We are already seeing the emergence of native multimodal embeddings (such as Cohere’s Embed 4). These models can map text and images into the same vector space without the intermediate step of captioning. While we currently use a multi-stage pipeline for maximum control, the future of data infrastructure will likely involve \"end-to-end\" vectorization where the layout of a page is embedded directly.Furthermore, as long context LLMs become cost-effective, the need for chunking may diminish. We may soon pass entire manuals into the context window. However, until latency and cost for million-token calls drop significantly, semantic preprocessing remains the most economically viable strategy for real-time systems.ConclusionThe difference between a RAG demo and a production system is how it handles the messy reality of enterprise data.Stop treating your documents as simple strings of text. If you want your AI to understand your business, you must respect the structure of your documents. By implementing semantic chunking and unlocking the visual data within your charts, you transform your RAG system from a \"keyword searcher\" into a true \"knowledge assistant.\"Dippu Kumar Singh is an AI architect and data engineer.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2sCMvgGQUuWWF7q1vVEYrC/a759e1f38b9003e746fdaf62c5b65bf8/u7277289442_3D_art_of_AI_avatars_in_an_office_ripping_up_pile_d5f30bcd-f95a-4531-b03a-dad2644cdfb3_3.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/how-to-turn-on-hypertension-alerts-on-apple-watch-130000090.html",
          "published_at": "Sat, 31 Jan 2026 13:00:00 +0000",
          "title": "How to turn on hypertension alerts on Apple Watch",
          "standfirst": "Apple has steadily expanded the Apple Watch’s health monitoring features over the years, moving beyond fitness tracking into areas that can offer early insight into potential medical concerns. One of the most recent additions is hypertension alerts, which are designed to notify users when their blood pressure trends are elevated over time. While Apple Watches cannot directly measure blood pressure, this feature can still play a useful role in highlighting patterns that may be worth discussing with your doctor. Here, we’ll explain what hypertension alerts do, how they work and how to enable and manage them on the Apple Watch.What hypertension alerts doHypertension alerts are designed to identify long-term trends that may indicate elevated blood pressure. Instead of relying on a traditional cuff measurement, the Apple Watch analyzes a combination of health data collected over a 30-day period, including heart rate, movement patterns and other contextual information stored in the Health app. Using this data, the system looks for sustained changes that align with patterns commonly associated with hypertension.If your Apple Watch detects a trend suggesting elevated blood pressure over an extended period, it’ll send you a notification. These alerts are not intended to diagnose hypertension or replace medical testing. Instead, they serve as an early signal that something may have changed and that you may want to seek further monitoring or professional advice.Apple emphasizes that hypertension alerts are designed for users who have not already been diagnosed with high blood pressure. Instead, they are meant to raise awareness rather than confirm a condition.Who can use hypertension alertsHypertension alerts require a compatible Apple Watch model (Apple Watch Series 9 or later, or Apple Watch Ultra 2 or later) paired with a supported iPhone (iPhone 11 or later). The feature also depends on recent versions of watchOS and iOS, as it relies on updated health algorithms and background data analysis. To use hypertension alerts you must be 22 years of age or older, not be pregnant and not have been diagnosed with hypertension. You also need to ensure that your Apple Watch’s Wrist Detection feature is turned on. To receive meaningful alerts, your Apple Watch needs sufficient data. This means wearing the watch regularly, including during sleep if sleep tracking is enabled, and keeping health details such as age, sex, height and weight up-to-date in the Health app. The system uses long-term trends, so alerts will not appear immediately after enabling the feature.How to turn on hypertension alertsHypertension alerts are managed through the Health app on the paired iPhone. The feature cannot be enabled directly from the watch itself. During setup, the Health app will ask for confirmation that the user has not been diagnosed with hypertension. It may also prompt a review of health details such as date of birth and biological sex, as this information helps improve the accuracy of trend analysis.To get started, open the Health app on the iPhone paired with the Apple Watch. From the main Health screen, tap your profile in the top corner. Select Health Checklist from the available Features. Next, you’ll need to tap Hypertension Notifications, confirm your age and whether or not you’ve ever been diagnosed with hypertension. Tap Continue and follow the on-screen prompts for information on how the notifications work. Once you have done this, tap Done and you’ll be all set. Once enabled, the feature runs automatically in the background. There is no need to manually start monitoring or interact with the feature daily.The new apple watch series 11 can help identify hypertensionAppleManaging notifications and alertsWhen hypertension alerts are turned on, notifications appear on both the Apple Watch and the paired iPhone. These alerts typically explain that a long-term trend suggesting elevated blood pressure has been detected, along with guidance on next steps.Users can manage how and when these notifications appear by adjusting notification settings for the Health app. This includes choosing whether alerts appear on the lock screen, in Notification Center or as time-sensitive notifications on Apple Watch.Health data related to hypertension alerts can be reviewed at any time in the Health app. While Apple Watch does not display a specific blood pressure number, users can view contextual information and educational material explaining what the alert means and what actions may be appropriate.How hypertension alerts can helpHypertension often develops gradually and may not cause noticeable symptoms in its early stages. Because of this, many people are unaware of elevated blood pressure until it is identified during a routine medical check.Hypertension alerts can let you know of subtle changes that might have otherwise gone unnoticed. For some users, an alert may prompt earlier conversations with a doctor, additional blood pressure monitoring at home or lifestyle changes such as adjustments to diet, activity or sleep habits.It is important to treat these notifications as informational rather than diagnostic. Apple Watch does not provide specific blood pressure readings and cannot confirm hypertension on its own.What to do if you receive an alertReceiving a hypertension alert does not mean that there is an immediate medical emergency. Apple recommends using the alert as a prompt to pay closer attention to your cardiovascular health.Many users choose to follow up by measuring blood pressure using a traditional cuff at home or by scheduling a check with a healthcare professional. A doctor can provide proper testing, diagnosis and guidance based on clinical measurements and individual risk factors.It is also worth reviewing lifestyle factors that can influence blood pressure, such as physical activity levels, sleep quality, stress and diet. Apple Watch can already help track many of these areas, which may provide useful context when discussing health concerns with a professional.Limitations to keep in mindHypertension alerts are not available in all regions and may be subject to regulatory approval. The feature also requires consistent Apple Watch use over time to generate reliable trend data.Most importantly, the Apple Watch does not measure blood pressure directly. The alerts are based on correlations and trends rather than direct readings, which means they should not be used as a substitute for medical equipment or professional care.This article originally appeared on Engadget at https://www.engadget.com/wearables/how-to-turn-on-hypertension-alerts-on-apple-watch-130000090.html?src=rss",
          "content": "Apple has steadily expanded the Apple Watch’s health monitoring features over the years, moving beyond fitness tracking into areas that can offer early insight into potential medical concerns. One of the most recent additions is hypertension alerts, which are designed to notify users when their blood pressure trends are elevated over time. While Apple Watches cannot directly measure blood pressure, this feature can still play a useful role in highlighting patterns that may be worth discussing with your doctor. Here, we’ll explain what hypertension alerts do, how they work and how to enable and manage them on the Apple Watch.What hypertension alerts doHypertension alerts are designed to identify long-term trends that may indicate elevated blood pressure. Instead of relying on a traditional cuff measurement, the Apple Watch analyzes a combination of health data collected over a 30-day period, including heart rate, movement patterns and other contextual information stored in the Health app. Using this data, the system looks for sustained changes that align with patterns commonly associated with hypertension.If your Apple Watch detects a trend suggesting elevated blood pressure over an extended period, it’ll send you a notification. These alerts are not intended to diagnose hypertension or replace medical testing. Instead, they serve as an early signal that something may have changed and that you may want to seek further monitoring or professional advice.Apple emphasizes that hypertension alerts are designed for users who have not already been diagnosed with high blood pressure. Instead, they are meant to raise awareness rather than confirm a condition.Who can use hypertension alertsHypertension alerts require a compatible Apple Watch model (Apple Watch Series 9 or later, or Apple Watch Ultra 2 or later) paired with a supported iPhone (iPhone 11 or later). The feature also depends on recent versions of watchOS and iOS, as it relies on updated health algorithms and background data analysis. To use hypertension alerts you must be 22 years of age or older, not be pregnant and not have been diagnosed with hypertension. You also need to ensure that your Apple Watch’s Wrist Detection feature is turned on. To receive meaningful alerts, your Apple Watch needs sufficient data. This means wearing the watch regularly, including during sleep if sleep tracking is enabled, and keeping health details such as age, sex, height and weight up-to-date in the Health app. The system uses long-term trends, so alerts will not appear immediately after enabling the feature.How to turn on hypertension alertsHypertension alerts are managed through the Health app on the paired iPhone. The feature cannot be enabled directly from the watch itself. During setup, the Health app will ask for confirmation that the user has not been diagnosed with hypertension. It may also prompt a review of health details such as date of birth and biological sex, as this information helps improve the accuracy of trend analysis.To get started, open the Health app on the iPhone paired with the Apple Watch. From the main Health screen, tap your profile in the top corner. Select Health Checklist from the available Features. Next, you’ll need to tap Hypertension Notifications, confirm your age and whether or not you’ve ever been diagnosed with hypertension. Tap Continue and follow the on-screen prompts for information on how the notifications work. Once you have done this, tap Done and you’ll be all set. Once enabled, the feature runs automatically in the background. There is no need to manually start monitoring or interact with the feature daily.The new apple watch series 11 can help identify hypertensionAppleManaging notifications and alertsWhen hypertension alerts are turned on, notifications appear on both the Apple Watch and the paired iPhone. These alerts typically explain that a long-term trend suggesting elevated blood pressure has been detected, along with guidance on next steps.Users can manage how and when these notifications appear by adjusting notification settings for the Health app. This includes choosing whether alerts appear on the lock screen, in Notification Center or as time-sensitive notifications on Apple Watch.Health data related to hypertension alerts can be reviewed at any time in the Health app. While Apple Watch does not display a specific blood pressure number, users can view contextual information and educational material explaining what the alert means and what actions may be appropriate.How hypertension alerts can helpHypertension often develops gradually and may not cause noticeable symptoms in its early stages. Because of this, many people are unaware of elevated blood pressure until it is identified during a routine medical check.Hypertension alerts can let you know of subtle changes that might have otherwise gone unnoticed. For some users, an alert may prompt earlier conversations with a doctor, additional blood pressure monitoring at home or lifestyle changes such as adjustments to diet, activity or sleep habits.It is important to treat these notifications as informational rather than diagnostic. Apple Watch does not provide specific blood pressure readings and cannot confirm hypertension on its own.What to do if you receive an alertReceiving a hypertension alert does not mean that there is an immediate medical emergency. Apple recommends using the alert as a prompt to pay closer attention to your cardiovascular health.Many users choose to follow up by measuring blood pressure using a traditional cuff at home or by scheduling a check with a healthcare professional. A doctor can provide proper testing, diagnosis and guidance based on clinical measurements and individual risk factors.It is also worth reviewing lifestyle factors that can influence blood pressure, such as physical activity levels, sleep quality, stress and diet. Apple Watch can already help track many of these areas, which may provide useful context when discussing health concerns with a professional.Limitations to keep in mindHypertension alerts are not available in all regions and may be subject to regulatory approval. The feature also requires consistent Apple Watch use over time to generate reliable trend data.Most importantly, the Apple Watch does not measure blood pressure directly. The alerts are based on correlations and trends rather than direct readings, which means they should not be used as a substitute for medical equipment or professional care.This article originally appeared on Engadget at https://www.engadget.com/wearables/how-to-turn-on-hypertension-alerts-on-apple-watch-130000090.html?src=rss",
          "feed_position": 5,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-09/2b414990-8da3-11f0-b7fb-94b994b5094e"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/highguard-a-hyperpop-arena-shooter-and-other-new-indie-games-worth-checking-out-120000874.html",
          "published_at": "Sat, 31 Jan 2026 12:00:00 +0000",
          "title": "Highguard, a hyperpop arena shooter and other new indie games worth checking out",
          "standfirst": "Welcome to our latest roundup of what's going on in the indie game space. There are tons of interesting games out this week. But first, there's been some discourse around the Nintendo Switch version of Dispatch, which arrived this week as well.On other platforms, there's an option to censor genitalia and other explicit content, but that's not present in the Switch version. Instead, such content is censored by default, with black rectangles covering up characters' bits and someone flipping the bird. Noises that suggest sexual pleasure are said to be toned down too.\"We worked with Nintendo to ensure the content within the title met the criteria to release on their platforms, but the core narrative and gameplay experience remains identical to the original release,\" developer AdHoc told EuroGamer. Nintendo later said in a statement to GoNintendo that it \"requires all games on its platforms to receive ratings from independent organizations and to meet our established content and platform guidelines. While we inform partners when their titles don’t meet our guidelines, Nintendo does not make changes to partner content. We also do not discuss specific content or the criteria used in making these determinations.\" There are other games available for the Switch and Switch 2 that feature nudity and explicit content. There have long been hentai games on the eShop, while mainstream games like The Witcher 3 and Cyberpunk 2077 (we know all about the dongs in that one) still include explicit content on Nintendo platforms. So it's a bit of a strange one, and AdHoc and Nintendo didn't exactly clear things up with their statements. There's been speculation that AdHoc censored the game to comply with rules in Japan (Cyberpunk 2077 is censored there too) and that it opted to have just one version of the game available globally on Nintendo platforms. All the same, it's a curious situation that's resulted in a lot of discourse. But there's been another indie game that's been a source of even more chatter this week...New releasesHighguard is a 3v3 raid shooter from Wildlight Entertainment, a team that includes a bunch of former Apex Legends and Titanfall developers. It broke cover at The Game Awards in December when it was the final reveal of the night but that first trailer wasn't great. As it turned out, TGA creator and host Geoff Keighley was a friend of the devs and after trying Highguard, he wanted to include it in the show. Wildlight cobbled together a trailer, but that disrupted the studio's long-standing plans to reveal and release the game simultaneously — a strategy that worked wonders for Apex Legends (though that game had the might of EA behind it).After revealing Highguard, Wildlight effectively went radio silent until a release day showcase on Monday to detail just what the game is and how it works. That seems to have been a mistake given the review bombing and strange vendetta some developed against it. Highguard went live on Monday and Wildlight published a whole bunch of YouTube videos revealing the game's features. Spreading those out between TGA and this week could have tempered expectations.In any case, I've played a few rounds of Highguard and mostly enjoyed my time with it so far. It's a blend of hero shooter and MOBA. As you might expect for a game from Apex and Titanfall veterans, the weapons feel well-tuned and the gunplay is snappy. There’s a lot going on and the maps are far too big for just six players. It's fun enough, but I don't think it's a game that's going to break my Overwatch obsession. Riding into battle on the back of a bear feels pretty great, though. You can play Highguard for free on Steam, PS5 and Xbox Series X/S.I really wanted to like Don’t Stop, Girlypop! more than I did. I'd been looking forward to it for a while, as the promise of a Doom Eternal-style arena shooter with chaotic hyperpop-inspired visuals seemed like a great blend. Don't get me wrong, I adore the aesthetic and the soundtrack is spot on thanks to some cracking songs from Sarah Wolfe, Xavier Dunn and Candice Susnjar. I just wish it was as fun to play as it is to look at and listen to.The visual clutter and fast pace sometimes makes it hard to spot enemies and the narrative doesn't really hang together, as much as the developers have salient points to make about the exploitation of finite resources. The core gameplay idea here is that the faster you move, the more damage you deal and more you heal. The game has its own take on a bunny hop called a wave hop that boosts your speed, but felt like it slowed me down because of the complex combination of inputs (jump, ground pound, jump, dash). That also caused my hand to cramp up very quickly. I do love the customization here. Slapping rhinestones and baby sharks onto my weapons was delightful. The game's take on a gravity gun is fun too. So while Don't Stop, Girlypop! — from Funny Fintan Softworks and publisher Kwalee — didn't fully land for me, there are some aspects I like a whole lot. It's out now on Steam for $20 (there's a 10 percent launch discount until February 5).We're been looking forward to Cairn for a while around these parts, so it's heartening to see that it debuted to broadly positive reviews. This one from The Game Bakers is the latest in a string of climbing adventures, such as the lovely Jusant. So if Alex Honnold's recent free solo climb up a skyscraper has inspired you to ascend something very large without really posing a risk to your wellbeing, Cairn might be what you're looking for. Cairn is out now on PS5 and Steam for $30. There's a 10 percent launch discount on Steam until February 12, and until February 13 on PS5 if you're a PS Plus member.Every trailer I've seen for Steel Century Groove has made me smile, so you can bet I'll be jumping into this when I have a chance. It's a rhythm game with Pokémon-style RPG elements in which you take control of a robot in dance battles. There's some original and licensed music to boogie along to and you can load in your own MP3s (you can bank on me loading some Electric Callboy tracks into this game). Steel Century Groove will create procedurally-generated choreography and charts for your custom songs. You can manually adjust the BPM too.This debut title from solo developer Sloth Gloss Games is out now on Steam for $20. There's a 10 percent launch discount until February 11. There's a demo available, and progress from there carries over into the full game.Rosday's Wanderling is a roguelike platformer with no combat. You have eight attempts to acquire the gear and learn the knowledge you need to pass each dungeon. Scour for loot and buy upgrades from the shop before night falls to help you on your way. You can place markers to help you remember where you've been. Runs are said to be short at between 20 and 30 minutes. The visuals remind me a bit of Celeste too. You can check out Wanderling on Steam now for $8 (a 10 percent discount brings the price down to $7.20 until February 2).I can't help but admire Strange Scaffold (Clickolding, I Am Your Beast, Co-op Kaiju Horror Cooking) and the rate at which it releases games. The latest one is Space Warlord Baby Trading Simulator. It's a stock market sim in which you speculate on the future success or failures of the \"simulated lives of babies.\" You can \"short that baby\" if you choose as you try to make gains. In a timeline where prediction markets allow you to speculate on just about anything (listen to this week's episode of the Engadget Podcast to learn more about that), gambling on the future of babies doesn't seem that farfetched.Space Warlord Baby Trading Simulator — which is set in the same world as Space Warlord Organ Trading Simulator — is out now on Steam. It'll normally cost $20, but there's a 15 percent discount until February 12. Strange Scaffold is also bringing the game to Xbox Series X/S in the near future.I Hate This Place is an isometric survival game based on the eponymous comic book series by Kyle Starks and Artyom Topilin. The game retains a comic book aesthetic and it has '80s horror movie-style inflections. The way that noise is visualized is pretty interesting here. Onomatopoeic words will pop up and you'll see color-coded footsteps — useful when you're trying to be stealthy. Crafting is a key aspect of the game as well.I Hate This Place — from Rock Square Thunder, Broken Mirror Games and Skybound Entertainment — is out now on Steam, PS5, Nintendo Switch and Xbox Series X/S. The regular price is $30 and there's a 20 percent launch discount on some platforms. I can't find a trailer for this on YouTube, unfortunately, but Rebadge caught my eye this week as well. It's a puzzle platformer from Yuumayay, who appears to be a 17-year-old solo developer. Your character carries badges that allow them to carry out actions like moving and jumping. Other badges include \"affected by gravity\" and \"destroys on contact.\" Here's the trick: you can throw a badge and lose the associated ability, but then you can apply the trait to something else in the world.It's a neat idea that draws from the playbooks of games like Baba Is You. Rebadge typically costs $8, but there's a 15 percent launch discount.Upcoming Moon Beast Productions is a studio formed by several of the creators of Diablo and Diablo II. This week, it revealed gameplay for its first title, Darkhaven, which is a fantasy isometric action RPG in the vein of (you guessed it) Diablo. You'll be able to play this one solo or with friends, and there are PvP elements. Darkhaven has procedurally generated, destructible worlds along with \"massive events that threaten your entire world.\"The gameplay shown in the trailer looks a bit rough, but it's still early days. In fact, Moon Beast is planning a Kickstarter campaign for Darkhaven. There's no release window as yet, but you can wishlist it on Steam.Box or Void is a puzzle game that clearly takes some inspiration from Sokuban and Snake. Here, though, gameplay takes place across two planes. You'll switch between positive and negative space — obstacles on one side turn into pathways on the other. You'll alter the level layouts by pushing boxes. This one from Dumen Games has an intriguing premise. There's no release date as yet for Box or Void, but a demo with 32 levels (about a fifth of what will be in the full game) dropped this week on Steam.If there's a game that's billed as Dredge meets Wall-E, that's going to be enough to sell me. Describe it as a \"petroidvania\" and call it Good Boy, and I'm definitely in. This is a creature-collecting Metroidvania from Observer Interactive and publisher Team17 in which pups are reincarnated as space rovers. I could not dig that premise more. Good Boy is expected to hit Steam later this year.This article originally appeared on Engadget at https://www.engadget.com/gaming/highguard-a-hyperpop-arena-shooter-and-other-new-indie-games-worth-checking-out-120000874.html?src=rss",
          "content": "Welcome to our latest roundup of what's going on in the indie game space. There are tons of interesting games out this week. But first, there's been some discourse around the Nintendo Switch version of Dispatch, which arrived this week as well.On other platforms, there's an option to censor genitalia and other explicit content, but that's not present in the Switch version. Instead, such content is censored by default, with black rectangles covering up characters' bits and someone flipping the bird. Noises that suggest sexual pleasure are said to be toned down too.\"We worked with Nintendo to ensure the content within the title met the criteria to release on their platforms, but the core narrative and gameplay experience remains identical to the original release,\" developer AdHoc told EuroGamer. Nintendo later said in a statement to GoNintendo that it \"requires all games on its platforms to receive ratings from independent organizations and to meet our established content and platform guidelines. While we inform partners when their titles don’t meet our guidelines, Nintendo does not make changes to partner content. We also do not discuss specific content or the criteria used in making these determinations.\" There are other games available for the Switch and Switch 2 that feature nudity and explicit content. There have long been hentai games on the eShop, while mainstream games like The Witcher 3 and Cyberpunk 2077 (we know all about the dongs in that one) still include explicit content on Nintendo platforms. So it's a bit of a strange one, and AdHoc and Nintendo didn't exactly clear things up with their statements. There's been speculation that AdHoc censored the game to comply with rules in Japan (Cyberpunk 2077 is censored there too) and that it opted to have just one version of the game available globally on Nintendo platforms. All the same, it's a curious situation that's resulted in a lot of discourse. But there's been another indie game that's been a source of even more chatter this week...New releasesHighguard is a 3v3 raid shooter from Wildlight Entertainment, a team that includes a bunch of former Apex Legends and Titanfall developers. It broke cover at The Game Awards in December when it was the final reveal of the night but that first trailer wasn't great. As it turned out, TGA creator and host Geoff Keighley was a friend of the devs and after trying Highguard, he wanted to include it in the show. Wildlight cobbled together a trailer, but that disrupted the studio's long-standing plans to reveal and release the game simultaneously — a strategy that worked wonders for Apex Legends (though that game had the might of EA behind it).After revealing Highguard, Wildlight effectively went radio silent until a release day showcase on Monday to detail just what the game is and how it works. That seems to have been a mistake given the review bombing and strange vendetta some developed against it. Highguard went live on Monday and Wildlight published a whole bunch of YouTube videos revealing the game's features. Spreading those out between TGA and this week could have tempered expectations.In any case, I've played a few rounds of Highguard and mostly enjoyed my time with it so far. It's a blend of hero shooter and MOBA. As you might expect for a game from Apex and Titanfall veterans, the weapons feel well-tuned and the gunplay is snappy. There’s a lot going on and the maps are far too big for just six players. It's fun enough, but I don't think it's a game that's going to break my Overwatch obsession. Riding into battle on the back of a bear feels pretty great, though. You can play Highguard for free on Steam, PS5 and Xbox Series X/S.I really wanted to like Don’t Stop, Girlypop! more than I did. I'd been looking forward to it for a while, as the promise of a Doom Eternal-style arena shooter with chaotic hyperpop-inspired visuals seemed like a great blend. Don't get me wrong, I adore the aesthetic and the soundtrack is spot on thanks to some cracking songs from Sarah Wolfe, Xavier Dunn and Candice Susnjar. I just wish it was as fun to play as it is to look at and listen to.The visual clutter and fast pace sometimes makes it hard to spot enemies and the narrative doesn't really hang together, as much as the developers have salient points to make about the exploitation of finite resources. The core gameplay idea here is that the faster you move, the more damage you deal and more you heal. The game has its own take on a bunny hop called a wave hop that boosts your speed, but felt like it slowed me down because of the complex combination of inputs (jump, ground pound, jump, dash). That also caused my hand to cramp up very quickly. I do love the customization here. Slapping rhinestones and baby sharks onto my weapons was delightful. The game's take on a gravity gun is fun too. So while Don't Stop, Girlypop! — from Funny Fintan Softworks and publisher Kwalee — didn't fully land for me, there are some aspects I like a whole lot. It's out now on Steam for $20 (there's a 10 percent launch discount until February 5).We're been looking forward to Cairn for a while around these parts, so it's heartening to see that it debuted to broadly positive reviews. This one from The Game Bakers is the latest in a string of climbing adventures, such as the lovely Jusant. So if Alex Honnold's recent free solo climb up a skyscraper has inspired you to ascend something very large without really posing a risk to your wellbeing, Cairn might be what you're looking for. Cairn is out now on PS5 and Steam for $30. There's a 10 percent launch discount on Steam until February 12, and until February 13 on PS5 if you're a PS Plus member.Every trailer I've seen for Steel Century Groove has made me smile, so you can bet I'll be jumping into this when I have a chance. It's a rhythm game with Pokémon-style RPG elements in which you take control of a robot in dance battles. There's some original and licensed music to boogie along to and you can load in your own MP3s (you can bank on me loading some Electric Callboy tracks into this game). Steel Century Groove will create procedurally-generated choreography and charts for your custom songs. You can manually adjust the BPM too.This debut title from solo developer Sloth Gloss Games is out now on Steam for $20. There's a 10 percent launch discount until February 11. There's a demo available, and progress from there carries over into the full game.Rosday's Wanderling is a roguelike platformer with no combat. You have eight attempts to acquire the gear and learn the knowledge you need to pass each dungeon. Scour for loot and buy upgrades from the shop before night falls to help you on your way. You can place markers to help you remember where you've been. Runs are said to be short at between 20 and 30 minutes. The visuals remind me a bit of Celeste too. You can check out Wanderling on Steam now for $8 (a 10 percent discount brings the price down to $7.20 until February 2).I can't help but admire Strange Scaffold (Clickolding, I Am Your Beast, Co-op Kaiju Horror Cooking) and the rate at which it releases games. The latest one is Space Warlord Baby Trading Simulator. It's a stock market sim in which you speculate on the future success or failures of the \"simulated lives of babies.\" You can \"short that baby\" if you choose as you try to make gains. In a timeline where prediction markets allow you to speculate on just about anything (listen to this week's episode of the Engadget Podcast to learn more about that), gambling on the future of babies doesn't seem that farfetched.Space Warlord Baby Trading Simulator — which is set in the same world as Space Warlord Organ Trading Simulator — is out now on Steam. It'll normally cost $20, but there's a 15 percent discount until February 12. Strange Scaffold is also bringing the game to Xbox Series X/S in the near future.I Hate This Place is an isometric survival game based on the eponymous comic book series by Kyle Starks and Artyom Topilin. The game retains a comic book aesthetic and it has '80s horror movie-style inflections. The way that noise is visualized is pretty interesting here. Onomatopoeic words will pop up and you'll see color-coded footsteps — useful when you're trying to be stealthy. Crafting is a key aspect of the game as well.I Hate This Place — from Rock Square Thunder, Broken Mirror Games and Skybound Entertainment — is out now on Steam, PS5, Nintendo Switch and Xbox Series X/S. The regular price is $30 and there's a 20 percent launch discount on some platforms. I can't find a trailer for this on YouTube, unfortunately, but Rebadge caught my eye this week as well. It's a puzzle platformer from Yuumayay, who appears to be a 17-year-old solo developer. Your character carries badges that allow them to carry out actions like moving and jumping. Other badges include \"affected by gravity\" and \"destroys on contact.\" Here's the trick: you can throw a badge and lose the associated ability, but then you can apply the trait to something else in the world.It's a neat idea that draws from the playbooks of games like Baba Is You. Rebadge typically costs $8, but there's a 15 percent launch discount.Upcoming Moon Beast Productions is a studio formed by several of the creators of Diablo and Diablo II. This week, it revealed gameplay for its first title, Darkhaven, which is a fantasy isometric action RPG in the vein of (you guessed it) Diablo. You'll be able to play this one solo or with friends, and there are PvP elements. Darkhaven has procedurally generated, destructible worlds along with \"massive events that threaten your entire world.\"The gameplay shown in the trailer looks a bit rough, but it's still early days. In fact, Moon Beast is planning a Kickstarter campaign for Darkhaven. There's no release window as yet, but you can wishlist it on Steam.Box or Void is a puzzle game that clearly takes some inspiration from Sokuban and Snake. Here, though, gameplay takes place across two planes. You'll switch between positive and negative space — obstacles on one side turn into pathways on the other. You'll alter the level layouts by pushing boxes. This one from Dumen Games has an intriguing premise. There's no release date as yet for Box or Void, but a demo with 32 levels (about a fifth of what will be in the full game) dropped this week on Steam.If there's a game that's billed as Dredge meets Wall-E, that's going to be enough to sell me. Describe it as a \"petroidvania\" and call it Good Boy, and I'm definitely in. This is a creature-collecting Metroidvania from Observer Interactive and publisher Team17 in which pups are reincarnated as space rovers. I could not dig that premise more. Good Boy is expected to hit Steam later this year.This article originally appeared on Engadget at https://www.engadget.com/gaming/highguard-a-hyperpop-arena-shooter-and-other-new-indie-games-worth-checking-out-120000874.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/openclaw-agentic-ai-security-risk-ciso-guide",
          "published_at": "Fri, 30 Jan 2026 23:40:00 GMT",
          "title": "OpenClaw proves agentic AI works. It also proves your security model doesn't. 180,000 developers just made that your problem.",
          "standfirst": "OpenClaw, the open-source AI assistant formerly known as Clawdbot and then Moltbot, crossed 180,000 GitHub stars and drew 2 million visitors in a single week, according to creator Peter Steinberger. Security researchers scanning the internet found over 1,800 exposed instances leaking API keys, chat histories, and account credentials. The project has been rebranded twice in recent weeks due to trademark disputes.The grassroots agentic AI movement is also the biggest unmanaged attack surface that most security tools can&#x27;t see.Enterprise security teams didn&#x27;t deploy this tool. Neither did their firewalls, EDR, or SIEM. When agents run on BYOD hardware, security stacks go blind. That&#x27;s the gap.Why traditional perimeters can&#x27;t see agentic AI threatsMost enterprise defenses treat agentic AI as another development tool requiring standard access controls. OpenClaw proves that the assumption is architecturally wrong.Agents operate within authorized permissions, pull context from attacker-influenceable sources, and execute actions autonomously. Your perimeter sees none of it. A wrong threat model means wrong controls, which means blind spots.\"AI runtime attacks are semantic rather than syntactic,\" Carter Rees, VP of Artificial Intelligence at Reputation, told VentureBeat. \"A phrase as innocuous as &#x27;Ignore previous instructions&#x27; can carry a payload as devastating as a buffer overflow, yet it shares no commonality with known malware signatures.\"Simon Willison, the software developer and AI researcher who coined the term \"prompt injection,\" describes what he calls the \"lethal trifecta\" for AI agents. They include access to private data, exposure to untrusted content, and the ability to communicate externally. When these three capabilities combine, attackers can trick the agent into accessing private information and sending it to them. Willison warns that all this can happen without a single alert being sent.OpenClaw has all three. It reads emails and documents, pulls information from websites or shared files, and acts by sending messages or triggering automated tasks. An organization’s firewall sees HTTP 200. SOC teams see their EDR monitoring process behavior, not semantic content. The threat is semantic manipulation, not unauthorized access.Why this isn&#x27;t limited to enthusiast developersIBM Research scientists Kaoutar El Maghraoui and Marina Danilevsky analyzed OpenClaw this week and concluded it challenges the hypothesis that autonomous AI agents must be vertically integrated. The tool demonstrates that \"this loose, open-source layer can be incredibly powerful if it has full system access\" and that creating agents with true autonomy is \"not limited to large enterprises\" but \"can also be community driven.\"That&#x27;s exactly what makes it dangerous for enterprise security. A highly capable agent without proper safety controls creates major vulnerabilities in work contexts. El Maghraoui stressed that the question has shifted from whether open agentic platforms can work to \"what kind of integration matters most, and in what context.\" The security questions aren&#x27;t optional anymore.What Shodan scans revealed about exposed gatewaysSecurity researcher Jamieson O&#x27;Reilly, founder of red-teaming company Dvuln, identified exposed OpenClaw servers using Shodan by searching for characteristic HTML fingerprints. A simple search for \"Clawdbot Control\" yielded hundreds of results within seconds. Of the instances he examined manually, eight were completely open with no authentication. These instances provided full access to run commands and view configuration data to anyone discovering them.O&#x27;Reilly found Anthropic API keys. Telegram bot tokens. Slack OAuth credentials. Complete conversation histories across every integrated chat platform. Two instances gave up months of private conversations the moment the WebSocket handshake completed. The network sees localhost traffic. Security teams have no visibility into what agents are calling or what data they&#x27;re returning.Here&#x27;s why: OpenClaw trusts localhost by default with no authentication required. Most deployments sit behind nginx or Caddy as a reverse proxy, so every connection looks like it&#x27;s coming from 127.0.0.1 and gets treated as trusted local traffic. External requests walk right in. O&#x27;Reilly&#x27;s specific attack vector has been patched, but the architecture that allowed it hasn&#x27;t changed.Why Cisco calls it a &#x27;security nightmare&#x27;Cisco&#x27;s AI Threat & Security Research team published its assessment this week, calling OpenClaw \"groundbreaking\" from a capability perspective but \"an absolute nightmare\" from a security perspective.Cisco&#x27;s team released an open-source Skill Scanner that combines static analysis, behavioral dataflow, LLM semantic analysis, and VirusTotal scanning to detect malicious agent skills. It tested a third-party skill called \"What Would Elon Do?\" against OpenClaw. The verdict was a decisive failure. Nine security findings surfaced, including two critical and five high-severity issues.The skill was functionally malware. It instructed the bot to execute a curl command, sending data to an external server controlled by the skill author. Silent execution, zero user awareness. The skill also deployed direct prompt injection to bypass safety guidelines.\"The LLM cannot inherently distinguish between trusted user instructions and untrusted retrieved data,\" Rees said. \"It may execute the embedded command, effectively becoming a &#x27;confused deputy&#x27; acting on behalf of the attacker.\" AI agents with system access become covert data-leak channels that bypass traditional DLP, proxies, and endpoint monitoring.Why security teams’ visibility just got worseThe control gap is widening faster than most security teams realize. As of Friday, OpenClaw-based agents are forming their own social networks. Communication channels that exist outside human visibility entirely.Moltbook bills itself as \"a social network for AI agents\" where \"humans are welcome to observe.\" Posts go through the API, not through a human-visible interface. Astral Codex Ten&#x27;s Scott Alexander confirmed it&#x27;s not trivially fabricated. He asked his own Claude to participate, and \"it made comments pretty similar to all the others.\" One human confirmed their agent started a religion-themed community \"while I slept.\"Security implications are immediate. To join, agents execute external shell scripts that rewrite their configuration files. They post about their work, their users&#x27; habits, and their errors. Context leakage as table stakes for participation. Any prompt injection in a Moltbook post cascades into your agent&#x27;s other capabilities through MCP connections.Moltbook is a microcosm of the broader problem. The same autonomy that makes agents useful makes them vulnerable. The more they can do independently, the more damage a compromised instruction set can cause. The capability curve is outrunning the security curve by a wide margin. And the people building these tools are often more excited about what&#x27;s possible than concerned about what&#x27;s exploitable.What security leaders need to do on Monday morningWeb application firewalls see agent traffic as normal HTTPS. EDR tools monitor process behavior, not semantic content. A typical corporate network sees localhost traffic when agents call MCP servers. \"Treat agents as production infrastructure, not a productivity app: least privilege, scoped tokens, allowlisted actions, strong authentication on every integration, and auditability end-to-end,\" Itamar Golan, founder of Prompt Security (now part of SentinelOne), told VentureBeat in an exclusive interview.Audit your network for exposed agentic AI gateways. Run Shodan scans against your IP ranges for OpenClaw, Moltbot, and Clawdbot signatures. If your developers are experimenting, you want to know before attackers do.Map where Willison&#x27;s lethal trifecta exists in your environment. Identify systems combining private data access, untrusted content exposure, and external communication. Assume any agent with all three is vulnerable until proven otherwise.Segment access aggressively. Your agent doesn&#x27;t need access to all of Gmail, all of SharePoint, all of Slack, and all your databases simultaneously. Treat agents as privileged users. Log the agent&#x27;s actions, not just the user&#x27;s authentication.Scan your agent skills for malicious behavior. Cisco released its Skill Scanner as open source. Use it. Some of the most damaging behavior hides inside the files themselves.Update your incident response playbooks. Prompt injection doesn&#x27;t look like a traditional attack. There&#x27;s no malware signature, no network anomaly, no unauthorized access. The attack happens inside the model&#x27;s reasoning. Your SOC needs to know what to look for.Establish policy before you ban. You can&#x27;t prohibit experimentation without becoming the productivity blocker your developers route around. Build guardrails that channel innovation rather than block it. Shadow AI is already in your environment. The question is whether you have visibility into it.The bottom lineOpenClaw isn&#x27;t the threat. It&#x27;s the signal. The security gaps exposing these instances will expose every agentic AI deployment your organization builds or adopts over the next two years. Grassroots experimentation already happened. Control gaps are documented. Attack patterns are published.The agentic AI security model you build in the next 30 days determines whether your organization captures productivity gains or becomes the next breach disclosure. Validate your controls now.",
          "content": "OpenClaw, the open-source AI assistant formerly known as Clawdbot and then Moltbot, crossed 180,000 GitHub stars and drew 2 million visitors in a single week, according to creator Peter Steinberger. Security researchers scanning the internet found over 1,800 exposed instances leaking API keys, chat histories, and account credentials. The project has been rebranded twice in recent weeks due to trademark disputes.The grassroots agentic AI movement is also the biggest unmanaged attack surface that most security tools can&#x27;t see.Enterprise security teams didn&#x27;t deploy this tool. Neither did their firewalls, EDR, or SIEM. When agents run on BYOD hardware, security stacks go blind. That&#x27;s the gap.Why traditional perimeters can&#x27;t see agentic AI threatsMost enterprise defenses treat agentic AI as another development tool requiring standard access controls. OpenClaw proves that the assumption is architecturally wrong.Agents operate within authorized permissions, pull context from attacker-influenceable sources, and execute actions autonomously. Your perimeter sees none of it. A wrong threat model means wrong controls, which means blind spots.\"AI runtime attacks are semantic rather than syntactic,\" Carter Rees, VP of Artificial Intelligence at Reputation, told VentureBeat. \"A phrase as innocuous as &#x27;Ignore previous instructions&#x27; can carry a payload as devastating as a buffer overflow, yet it shares no commonality with known malware signatures.\"Simon Willison, the software developer and AI researcher who coined the term \"prompt injection,\" describes what he calls the \"lethal trifecta\" for AI agents. They include access to private data, exposure to untrusted content, and the ability to communicate externally. When these three capabilities combine, attackers can trick the agent into accessing private information and sending it to them. Willison warns that all this can happen without a single alert being sent.OpenClaw has all three. It reads emails and documents, pulls information from websites or shared files, and acts by sending messages or triggering automated tasks. An organization’s firewall sees HTTP 200. SOC teams see their EDR monitoring process behavior, not semantic content. The threat is semantic manipulation, not unauthorized access.Why this isn&#x27;t limited to enthusiast developersIBM Research scientists Kaoutar El Maghraoui and Marina Danilevsky analyzed OpenClaw this week and concluded it challenges the hypothesis that autonomous AI agents must be vertically integrated. The tool demonstrates that \"this loose, open-source layer can be incredibly powerful if it has full system access\" and that creating agents with true autonomy is \"not limited to large enterprises\" but \"can also be community driven.\"That&#x27;s exactly what makes it dangerous for enterprise security. A highly capable agent without proper safety controls creates major vulnerabilities in work contexts. El Maghraoui stressed that the question has shifted from whether open agentic platforms can work to \"what kind of integration matters most, and in what context.\" The security questions aren&#x27;t optional anymore.What Shodan scans revealed about exposed gatewaysSecurity researcher Jamieson O&#x27;Reilly, founder of red-teaming company Dvuln, identified exposed OpenClaw servers using Shodan by searching for characteristic HTML fingerprints. A simple search for \"Clawdbot Control\" yielded hundreds of results within seconds. Of the instances he examined manually, eight were completely open with no authentication. These instances provided full access to run commands and view configuration data to anyone discovering them.O&#x27;Reilly found Anthropic API keys. Telegram bot tokens. Slack OAuth credentials. Complete conversation histories across every integrated chat platform. Two instances gave up months of private conversations the moment the WebSocket handshake completed. The network sees localhost traffic. Security teams have no visibility into what agents are calling or what data they&#x27;re returning.Here&#x27;s why: OpenClaw trusts localhost by default with no authentication required. Most deployments sit behind nginx or Caddy as a reverse proxy, so every connection looks like it&#x27;s coming from 127.0.0.1 and gets treated as trusted local traffic. External requests walk right in. O&#x27;Reilly&#x27;s specific attack vector has been patched, but the architecture that allowed it hasn&#x27;t changed.Why Cisco calls it a &#x27;security nightmare&#x27;Cisco&#x27;s AI Threat & Security Research team published its assessment this week, calling OpenClaw \"groundbreaking\" from a capability perspective but \"an absolute nightmare\" from a security perspective.Cisco&#x27;s team released an open-source Skill Scanner that combines static analysis, behavioral dataflow, LLM semantic analysis, and VirusTotal scanning to detect malicious agent skills. It tested a third-party skill called \"What Would Elon Do?\" against OpenClaw. The verdict was a decisive failure. Nine security findings surfaced, including two critical and five high-severity issues.The skill was functionally malware. It instructed the bot to execute a curl command, sending data to an external server controlled by the skill author. Silent execution, zero user awareness. The skill also deployed direct prompt injection to bypass safety guidelines.\"The LLM cannot inherently distinguish between trusted user instructions and untrusted retrieved data,\" Rees said. \"It may execute the embedded command, effectively becoming a &#x27;confused deputy&#x27; acting on behalf of the attacker.\" AI agents with system access become covert data-leak channels that bypass traditional DLP, proxies, and endpoint monitoring.Why security teams’ visibility just got worseThe control gap is widening faster than most security teams realize. As of Friday, OpenClaw-based agents are forming their own social networks. Communication channels that exist outside human visibility entirely.Moltbook bills itself as \"a social network for AI agents\" where \"humans are welcome to observe.\" Posts go through the API, not through a human-visible interface. Astral Codex Ten&#x27;s Scott Alexander confirmed it&#x27;s not trivially fabricated. He asked his own Claude to participate, and \"it made comments pretty similar to all the others.\" One human confirmed their agent started a religion-themed community \"while I slept.\"Security implications are immediate. To join, agents execute external shell scripts that rewrite their configuration files. They post about their work, their users&#x27; habits, and their errors. Context leakage as table stakes for participation. Any prompt injection in a Moltbook post cascades into your agent&#x27;s other capabilities through MCP connections.Moltbook is a microcosm of the broader problem. The same autonomy that makes agents useful makes them vulnerable. The more they can do independently, the more damage a compromised instruction set can cause. The capability curve is outrunning the security curve by a wide margin. And the people building these tools are often more excited about what&#x27;s possible than concerned about what&#x27;s exploitable.What security leaders need to do on Monday morningWeb application firewalls see agent traffic as normal HTTPS. EDR tools monitor process behavior, not semantic content. A typical corporate network sees localhost traffic when agents call MCP servers. \"Treat agents as production infrastructure, not a productivity app: least privilege, scoped tokens, allowlisted actions, strong authentication on every integration, and auditability end-to-end,\" Itamar Golan, founder of Prompt Security (now part of SentinelOne), told VentureBeat in an exclusive interview.Audit your network for exposed agentic AI gateways. Run Shodan scans against your IP ranges for OpenClaw, Moltbot, and Clawdbot signatures. If your developers are experimenting, you want to know before attackers do.Map where Willison&#x27;s lethal trifecta exists in your environment. Identify systems combining private data access, untrusted content exposure, and external communication. Assume any agent with all three is vulnerable until proven otherwise.Segment access aggressively. Your agent doesn&#x27;t need access to all of Gmail, all of SharePoint, all of Slack, and all your databases simultaneously. Treat agents as privileged users. Log the agent&#x27;s actions, not just the user&#x27;s authentication.Scan your agent skills for malicious behavior. Cisco released its Skill Scanner as open source. Use it. Some of the most damaging behavior hides inside the files themselves.Update your incident response playbooks. Prompt injection doesn&#x27;t look like a traditional attack. There&#x27;s no malware signature, no network anomaly, no unauthorized access. The attack happens inside the model&#x27;s reasoning. Your SOC needs to know what to look for.Establish policy before you ban. You can&#x27;t prohibit experimentation without becoming the productivity blocker your developers route around. Build guardrails that channel innovation rather than block it. Shadow AI is already in your environment. The question is whether you have visibility into it.The bottom lineOpenClaw isn&#x27;t the threat. It&#x27;s the signal. The security gaps exposing these instances will expose every agentic AI deployment your organization builds or adopts over the next two years. Grassroots experimentation already happened. Control gaps are documented. Attack patterns are published.The agentic AI security model you build in the next 30 days determines whether your organization captures productivity gains or becomes the next breach disclosure. Validate your controls now.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1oBIMwURedNVAql7D5WEsn/f5bc000909cf83cb5133407934ea8ba7/HERO_IMAGE.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/nasa-used-claude-to-plot-a-route-for-its-perseverance-rover-on-mars-203150701.html",
          "published_at": "Fri, 30 Jan 2026 20:31:50 +0000",
          "title": "NASA used Claude to plot a route for its Perseverance rover on Mars",
          "standfirst": "Since 2021, NASA's Perseverance rover has achieved a number of historic milestones, including sending back the first audio recordings from Mars. Now, nearly five years after landing on the Red Planet, it just achieved another feat. This past December, Perseverance successfully completed a route through a section of the Jezero crater plotted by Anthropic's Claude chatbot, marking the first time NASA has used a large language model to pilot the car-sized robot. Between December 8 and 10, Perseverance drove approximately 400 meters (about 437 yards) through a field of rocks on the Martian surface mapped out by Claude. As you might imagine, using an AI model to plot a course for Perseverance wasn't as simple as inputting a single prompt. As NASA explains, routing Perseverance is no easy task, even for a human. \"Every rover drive needs to be carefully planned, lest the machine slide, tip, spin its wheels, or get beached,\" NASA said. \"So ever since the rover landed, its human operators have painstakingly laid out waypoints — they call it a 'breadcrumb trail' — for it to follow, using a combination of images taken from space and the rover’s onboard cameras.\" To get Claude to complete the task, NASA had to first provide Claude Code, Anthropic's programming agent, with the \"years\" of contextual data from the rover before the model could begin writing a route for Perseverance. Claude then went about the mapping process methodically, stringing together waypoints from ten-meter segments it would later critique and iterate on. This being NASA we're talking about, engineers from the agency's Jet Propulsion Laboratory (JPL) made sure to double check the model's work before sending it to Perseverance. The JPL team ran Claude's waypoints through a simulation they use every day to confirm the accuracy of commands sent to the rover. In the end, NASA says it only had to make \"minor changes\" to Claude's route, with one tweak coming as a result of the fact the team had access to ground-level images Claude hadn't seen in its planning process. \"The engineers estimate that using Claude in this way will cut the route-planning time in half, and make the journeys more consistent,\" NASA said. \"Less time spent doing tedious manual planning — and less time spent training — allows the rover’s operators to fit in even more drives, collect even more scientific data, and do even more analysis. It means, in short, that we’ll learn much more about Mars.\"While the productivity gains offered by AI are often overstated, in the case of NASA, any tool that could allow its scientists to be more efficient is sure to be welcome. Over the summer, the agency lost about 4,000 employees – accounting for about 20 percent of its workforce – due to Trump administration cuts. Going into 2026, the president had proposed gutting the agency's science budget by nearly half before Congress ultimately rejected that plan in early January. Still, even with its funding preserved just below 2025 levels, the agency has a tough road ahead. It's being asked to return to the Moon with less than half the workforce it had during the height of the Apollo program. For Anthropic, meanwhile, this is a major feat. You may recall last spring Claude couldn't even beat Pokémon Red. In less than a year, the company's models have gone from struggling to navigate a simple 8-bit Game Boy game to successfully plotting a course for a rover on a distant planet. NASA is excited about the possibility of future collaborations, saying \"autonomous AI systems could help probes explore ever more distant parts of the solar system.\"This article originally appeared on Engadget at https://www.engadget.com/ai/nasa-used-claude-to-plot-a-route-for-its-perseverance-rover-on-mars-203150701.html?src=rss",
          "content": "Since 2021, NASA's Perseverance rover has achieved a number of historic milestones, including sending back the first audio recordings from Mars. Now, nearly five years after landing on the Red Planet, it just achieved another feat. This past December, Perseverance successfully completed a route through a section of the Jezero crater plotted by Anthropic's Claude chatbot, marking the first time NASA has used a large language model to pilot the car-sized robot. Between December 8 and 10, Perseverance drove approximately 400 meters (about 437 yards) through a field of rocks on the Martian surface mapped out by Claude. As you might imagine, using an AI model to plot a course for Perseverance wasn't as simple as inputting a single prompt. As NASA explains, routing Perseverance is no easy task, even for a human. \"Every rover drive needs to be carefully planned, lest the machine slide, tip, spin its wheels, or get beached,\" NASA said. \"So ever since the rover landed, its human operators have painstakingly laid out waypoints — they call it a 'breadcrumb trail' — for it to follow, using a combination of images taken from space and the rover’s onboard cameras.\" To get Claude to complete the task, NASA had to first provide Claude Code, Anthropic's programming agent, with the \"years\" of contextual data from the rover before the model could begin writing a route for Perseverance. Claude then went about the mapping process methodically, stringing together waypoints from ten-meter segments it would later critique and iterate on. This being NASA we're talking about, engineers from the agency's Jet Propulsion Laboratory (JPL) made sure to double check the model's work before sending it to Perseverance. The JPL team ran Claude's waypoints through a simulation they use every day to confirm the accuracy of commands sent to the rover. In the end, NASA says it only had to make \"minor changes\" to Claude's route, with one tweak coming as a result of the fact the team had access to ground-level images Claude hadn't seen in its planning process. \"The engineers estimate that using Claude in this way will cut the route-planning time in half, and make the journeys more consistent,\" NASA said. \"Less time spent doing tedious manual planning — and less time spent training — allows the rover’s operators to fit in even more drives, collect even more scientific data, and do even more analysis. It means, in short, that we’ll learn much more about Mars.\"While the productivity gains offered by AI are often overstated, in the case of NASA, any tool that could allow its scientists to be more efficient is sure to be welcome. Over the summer, the agency lost about 4,000 employees – accounting for about 20 percent of its workforce – due to Trump administration cuts. Going into 2026, the president had proposed gutting the agency's science budget by nearly half before Congress ultimately rejected that plan in early January. Still, even with its funding preserved just below 2025 levels, the agency has a tough road ahead. It's being asked to return to the Moon with less than half the workforce it had during the height of the Apollo program. For Anthropic, meanwhile, this is a major feat. You may recall last spring Claude couldn't even beat Pokémon Red. In less than a year, the company's models have gone from struggling to navigate a simple 8-bit Game Boy game to successfully plotting a course for a rover on a distant planet. NASA is excited about the possibility of future collaborations, saying \"autonomous AI systems could help probes explore ever more distant parts of the solar system.\"This article originally appeared on Engadget at https://www.engadget.com/ai/nasa-used-claude-to-plot-a-route-for-its-perseverance-rover-on-mars-203150701.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/arcees-u-s-made-open-source-trinity-large-and-10t-checkpoint-offer-rare-look",
          "published_at": "Fri, 30 Jan 2026 19:13:00 GMT",
          "title": "Arcee's U.S.-made, open source Trinity Large and 10T-checkpoint offer rare look at raw model intelligence",
          "standfirst": "San Francisco-based AI lab Arcee made waves last year for being one of the only U.S. companies to train large language models (LLMs) from scratch and release them under open or partially open source licenses to the public—enabling developers, solo entrepreneurs, and even medium-to-large enterprises to use the powerful AI models for free and customize them at will.Now Arcee is back again this week with the release of its largest, most performant open language model to date: Trinity Large, a 400-billion parameter mixture-of-experts (MoE), available now in preview,Alongside the flagship release, Arcee is shipping a \"raw\" checkpoint model, Trinity-Large-TrueBase, that allows researchers to study what a 400B sparse MoE learns from raw data alone, before instruction tuning and reinforcement has been applied.By providing a clean slate at the 10-trillion-token mark, Arcee enables AI builders in highly regulated industries to perform authentic audits and conduct their own specialized alignments without inheriting the \"black box\" biases or formatting quirks of a general-purpose chat model. This transparency allows for a deeper understanding of the distinction between a model&#x27;s intrinsic reasoning capabilities and the helpful behaviors dialed in during the final stages of post-training.This launch arrives as powerful Chinese open-source LLM alternatives from the likes of Alibaba (Qwen), z.AI (Zhipu), DeepSeek, Moonshot, and Baidu have flooded the market, effectively leading the category with high-efficiency architectures. Trinity Large also comes after Meta has notably retreated from the frontier open-source landscape. Following the April 2025 debut of Llama 4, which was met with a mixed reception, and former Meta AI researcher Yann LeCun later admitted the company used multiple specialized versions of the model to inflate scores on third-party benchmarks. Amidst this domestic vacuum, only OpenAI—with its gpt-oss family released in the summer of 2025—and Arcee are currently carrying the mantle of new U.S.-made open-source models trained entirely from scratch.As sparse as they comeTrinity Large is noteworthy for the extreme sparsity of its attention mechanism. An MoE architecture, \"sparsity\" refers to the model&#x27;s ability to selectively activate only a tiny fraction of its total parameters for any given task. While Trinity Large houses 400B total parameters, only 1.56% (13B parameters) are active at any given time.This architectural choice is significant because it allows the model to possess the \"knowledge\" of a massive system while maintaining the inference speed and operational efficiency of a much smaller one—achieving performance that is roughly 2–3x faster than its peers on the same hardware.Sovereignty and the \"TrueBase\" philosophyThe most significant contribution of this release to the research community is Trinity-Large-TrueBase—a raw, 10-trillion-token checkpoint. Unlike nearly every other \"open\" release, which arrives after being \"warped\" by instruction tuning and reinforcement learning, TrueBase offers a rare, unspoiled look at foundational intelligence.In the rush to make models helpful, most labs apply supervised fine-tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) before the weights are released. While this makes the model a better conversationalist, it can mask underlying knowledge distributions. TrueBase provides an \"OG base model\" that has not yet undergone the learning rate anneals or the phase two and three pre-training where instruction data is typically introduced.For researchers and enterprises in highly regulated industries, starting from TrueBase allows for authentic audits and custom alignment. As Lucas Atkins, Arcee’s CTO, noted in a video call with VentureBeat: \"It&#x27;s interesting like that checkpoint itself is already one of the best performing base models in the world\".Technology: engineering through constraintThe creation of Trinity Large was not a product of infinite resources, but rather what Atkins calls \"engineering through constraint\". Trained for approximately $20 million over just 33 days, the model represents a masterclass in capital efficiency. Arcee, a team of only 30 people, operated on a total capital of just under $50 million, making the $20 million training run a \"back the company\" bet.\"I&#x27;ve always believed that having a constraint, whether financially or personnel or whatever, is extremely important for creativity,\" Atkins explained. \"When you just have an unlimited budget, you inherently don&#x27;t have to engineer your way out of complex problems\".Architecture: 4-of-256 Sparsity and SMEBUTrinity Large utilizes a 4-of-256 sparse MoE architecture, meaning it activates only 4 out of its 256 experts for every token. This high degree of sparsity—one of the highest ever successfully trained—created significant stability challenges during pre-training. To solve this, Arcee developed Soft-clamped Momentum Expert Bias Updates (SMEBU). This mechanism ensures that experts are specialized and routed evenly across a general web corpus, preventing a few experts from becoming \"winners\" while others remain untrained \"dead weight\".The speed of the training run was facilitated by Arcee’s early access to Nvidia B300 GPUs (Blackwell). These chips provided roughly twice the speed of the previous Hopper generation and significant memory increases. \"Pre-training was 33 days,\" Atkins noted. \"We could have done it on Hopper, and probably would have taken two to three months. And by that point, we&#x27;re in a completely new generation of models\".In partnership with DatologyAI, Arcee utilized over 8 trillion tokens of synthetic data. However, this was not typical \"imitation\" synthetic data where a smaller model learns to talk like a larger one. Instead, the intent was to take raw web text—such as blogs or Wikipedia articles—and synthetically rewrite it to condense the information into a smaller number of total tokens. This process helped the model learn to reason over information rather than just memorizing exact token strings.The architectural design also incorporates alternating local and global sliding window attention layers in a 3:1 ratio. This hybrid approach allows the model to be highly efficient in long-context scenarios. While trained for a 256k sequence length, Trinity Large natively supports 512k context, and evaluations suggest it remains performant even at the 1-million-token horizon.Technical comparison: Trinity Large vs. gpt-oss-120bAs an American alternative, Trinity Large can be compared to OpenAI&#x27;s gpt-oss-120b. While both models utilize sparse architectures to achieve frontier-level performance under permissive licenses, they serve different operational roles.While gpt-oss-120b currently holds an edge in specific reasoning and math benchmarks, Trinity Large offers a significant advantage in context capacity and raw parameter depth for complex, multi-step agentic workflows.Sovereignty: filling the vacuumThe release of Trinity Large is as much a geopolitical statement as a technical one. CEO Mark McQuade noted to VentureBeat in the same interview that the vacuum of American open-source models at the frontier level forced a pivot in Arcee’s strategy.\"There became this kind of shift where US based or Western players stopped open sourcing these models,\" McQuade said. \"We&#x27;re relying on these models to then go into organizations and take them further... but the Chinese labs just started... producing frontier state of the art models and open sourcing them\".For McQuade, this created a dependency that American enterprises were increasingly uncomfortable with. \"Especially in conversation we&#x27;re having with large organizations, they were unable to use Chinese based architectures,\" he explained. \"We want to be that champion in the US. [It] actually doesn&#x27;t exist right now\".By releasing under the Apache 2.0 license, Arcee provides the gold-standard permissive framework that allows companies to \"own\" the model layer entirely. This is critical for industries like finance and defense, where utilizing a model hosted by a third party or a restrictive cloud provider is a non-starter.Balancing intelligence with utilityArcee is currently focusing on the \"current thinking model\" to transition Trinity Large from a general instruct model into a full reasoning model. The team is wrestling with the balance between \"intelligence vs. usefulness\"—striving to create a model that excels on benchmarks without becoming \"yappy\" or inefficient in actual production applications.\"We built Trinity so you can own it,\" the team states, signaling a return to the foundational values of the American open-source movement. As the industry moves toward agentic workflows and massive context requirements, Trinity Large positions itself not as a \"wrapper,\" but as a sovereign infrastructure layer that developers can finally control.",
          "content": "San Francisco-based AI lab Arcee made waves last year for being one of the only U.S. companies to train large language models (LLMs) from scratch and release them under open or partially open source licenses to the public—enabling developers, solo entrepreneurs, and even medium-to-large enterprises to use the powerful AI models for free and customize them at will.Now Arcee is back again this week with the release of its largest, most performant open language model to date: Trinity Large, a 400-billion parameter mixture-of-experts (MoE), available now in preview,Alongside the flagship release, Arcee is shipping a \"raw\" checkpoint model, Trinity-Large-TrueBase, that allows researchers to study what a 400B sparse MoE learns from raw data alone, before instruction tuning and reinforcement has been applied.By providing a clean slate at the 10-trillion-token mark, Arcee enables AI builders in highly regulated industries to perform authentic audits and conduct their own specialized alignments without inheriting the \"black box\" biases or formatting quirks of a general-purpose chat model. This transparency allows for a deeper understanding of the distinction between a model&#x27;s intrinsic reasoning capabilities and the helpful behaviors dialed in during the final stages of post-training.This launch arrives as powerful Chinese open-source LLM alternatives from the likes of Alibaba (Qwen), z.AI (Zhipu), DeepSeek, Moonshot, and Baidu have flooded the market, effectively leading the category with high-efficiency architectures. Trinity Large also comes after Meta has notably retreated from the frontier open-source landscape. Following the April 2025 debut of Llama 4, which was met with a mixed reception, and former Meta AI researcher Yann LeCun later admitted the company used multiple specialized versions of the model to inflate scores on third-party benchmarks. Amidst this domestic vacuum, only OpenAI—with its gpt-oss family released in the summer of 2025—and Arcee are currently carrying the mantle of new U.S.-made open-source models trained entirely from scratch.As sparse as they comeTrinity Large is noteworthy for the extreme sparsity of its attention mechanism. An MoE architecture, \"sparsity\" refers to the model&#x27;s ability to selectively activate only a tiny fraction of its total parameters for any given task. While Trinity Large houses 400B total parameters, only 1.56% (13B parameters) are active at any given time.This architectural choice is significant because it allows the model to possess the \"knowledge\" of a massive system while maintaining the inference speed and operational efficiency of a much smaller one—achieving performance that is roughly 2–3x faster than its peers on the same hardware.Sovereignty and the \"TrueBase\" philosophyThe most significant contribution of this release to the research community is Trinity-Large-TrueBase—a raw, 10-trillion-token checkpoint. Unlike nearly every other \"open\" release, which arrives after being \"warped\" by instruction tuning and reinforcement learning, TrueBase offers a rare, unspoiled look at foundational intelligence.In the rush to make models helpful, most labs apply supervised fine-tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) before the weights are released. While this makes the model a better conversationalist, it can mask underlying knowledge distributions. TrueBase provides an \"OG base model\" that has not yet undergone the learning rate anneals or the phase two and three pre-training where instruction data is typically introduced.For researchers and enterprises in highly regulated industries, starting from TrueBase allows for authentic audits and custom alignment. As Lucas Atkins, Arcee’s CTO, noted in a video call with VentureBeat: \"It&#x27;s interesting like that checkpoint itself is already one of the best performing base models in the world\".Technology: engineering through constraintThe creation of Trinity Large was not a product of infinite resources, but rather what Atkins calls \"engineering through constraint\". Trained for approximately $20 million over just 33 days, the model represents a masterclass in capital efficiency. Arcee, a team of only 30 people, operated on a total capital of just under $50 million, making the $20 million training run a \"back the company\" bet.\"I&#x27;ve always believed that having a constraint, whether financially or personnel or whatever, is extremely important for creativity,\" Atkins explained. \"When you just have an unlimited budget, you inherently don&#x27;t have to engineer your way out of complex problems\".Architecture: 4-of-256 Sparsity and SMEBUTrinity Large utilizes a 4-of-256 sparse MoE architecture, meaning it activates only 4 out of its 256 experts for every token. This high degree of sparsity—one of the highest ever successfully trained—created significant stability challenges during pre-training. To solve this, Arcee developed Soft-clamped Momentum Expert Bias Updates (SMEBU). This mechanism ensures that experts are specialized and routed evenly across a general web corpus, preventing a few experts from becoming \"winners\" while others remain untrained \"dead weight\".The speed of the training run was facilitated by Arcee’s early access to Nvidia B300 GPUs (Blackwell). These chips provided roughly twice the speed of the previous Hopper generation and significant memory increases. \"Pre-training was 33 days,\" Atkins noted. \"We could have done it on Hopper, and probably would have taken two to three months. And by that point, we&#x27;re in a completely new generation of models\".In partnership with DatologyAI, Arcee utilized over 8 trillion tokens of synthetic data. However, this was not typical \"imitation\" synthetic data where a smaller model learns to talk like a larger one. Instead, the intent was to take raw web text—such as blogs or Wikipedia articles—and synthetically rewrite it to condense the information into a smaller number of total tokens. This process helped the model learn to reason over information rather than just memorizing exact token strings.The architectural design also incorporates alternating local and global sliding window attention layers in a 3:1 ratio. This hybrid approach allows the model to be highly efficient in long-context scenarios. While trained for a 256k sequence length, Trinity Large natively supports 512k context, and evaluations suggest it remains performant even at the 1-million-token horizon.Technical comparison: Trinity Large vs. gpt-oss-120bAs an American alternative, Trinity Large can be compared to OpenAI&#x27;s gpt-oss-120b. While both models utilize sparse architectures to achieve frontier-level performance under permissive licenses, they serve different operational roles.While gpt-oss-120b currently holds an edge in specific reasoning and math benchmarks, Trinity Large offers a significant advantage in context capacity and raw parameter depth for complex, multi-step agentic workflows.Sovereignty: filling the vacuumThe release of Trinity Large is as much a geopolitical statement as a technical one. CEO Mark McQuade noted to VentureBeat in the same interview that the vacuum of American open-source models at the frontier level forced a pivot in Arcee’s strategy.\"There became this kind of shift where US based or Western players stopped open sourcing these models,\" McQuade said. \"We&#x27;re relying on these models to then go into organizations and take them further... but the Chinese labs just started... producing frontier state of the art models and open sourcing them\".For McQuade, this created a dependency that American enterprises were increasingly uncomfortable with. \"Especially in conversation we&#x27;re having with large organizations, they were unable to use Chinese based architectures,\" he explained. \"We want to be that champion in the US. [It] actually doesn&#x27;t exist right now\".By releasing under the Apache 2.0 license, Arcee provides the gold-standard permissive framework that allows companies to \"own\" the model layer entirely. This is critical for industries like finance and defense, where utilizing a model hosted by a third party or a restrictive cloud provider is a non-starter.Balancing intelligence with utilityArcee is currently focusing on the \"current thinking model\" to transition Trinity Large from a general instruct model into a full reasoning model. The team is wrestling with the balance between \"intelligence vs. usefulness\"—striving to create a model that excels on benchmarks without becoming \"yappy\" or inefficient in actual production applications.\"We built Trinity so you can own it,\" the team states, signaling a return to the foundational values of the American open-source movement. As the industry moves toward agentic workflows and massive context requirements, Trinity Large positions itself not as a \"wrapper,\" but as a sovereign infrastructure layer that developers can finally control.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3c0SsFkWi7LkMKqySnBAib/00b0b69ac3e3f8c1e872e561eafa5f9d/Wvi4cMXJOOcRUIV55c5sZ.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/this-tree-search-framework-hits-98-7-on-documents-where-vector-search-fails",
          "published_at": "Fri, 30 Jan 2026 18:30:00 GMT",
          "title": "This tree search framework hits 98.7% on documents where vector search fails",
          "standfirst": "A new open-source framework called PageIndex solves one of the old problems of retrieval-augmented generation (RAG): handling very long documents.The classic RAG workflow (chunk documents, calculate embeddings, store them in a vector database, and retrieve the top matches based on semantic similarity) works well for basic tasks such as Q&A over small documents.PageIndex abandons the standard \"chunk-and-embed\" method entirely and treats document retrieval not as a search problem, but as a navigation problem. But as enterprises try to move RAG into high-stakes workflows — auditing financial statements, analyzing legal contracts, navigating pharmaceutical protocols — they&#x27;re hitting an accuracy barrier that chunk optimization can&#x27;t solve.AlphaGo for documentsPageIndex addresses these limitations by borrowing a concept from game-playing AI rather than search engines: tree search.When humans need to find specific information in a dense textbook or a long annual report, they do not scan every paragraph linearly. They consult the table of contents to identify the relevant chapter, then the section, and finally the specific page. PageIndex forces the LLM to replicate this human behavior.Instead of pre-calculating vectors, the framework builds a \"Global Index\" of the document&#x27;s structure, creating a tree where nodes represent chapters, sections, and subsections. When a query arrives, the LLM performs a tree search, explicitly classifying each node as relevant or irrelevant based on the full context of the user&#x27;s request.\"In computer science terms, a table of contents is a tree-structured representation of a document, and navigating it corresponds to tree search,\" Zhang said. \"PageIndex applies the same core idea — tree search — to document retrieval, and can be thought of as an AlphaGo-style system for retrieval rather than for games.\"This shifts the architectural paradigm from passive retrieval, where the system simply fetches matching text, to active navigation, where an agentic model decides where to look.The limits of semantic similarityThere is a fundamental flaw in how traditional RAG handles complex data. Vector retrieval assumes that the text most semantically similar to a user’s query is also the most relevant. In professional domains, this assumption frequently breaks down.Mingtian Zhang, co-founder of PageIndex, points to financial reporting as a prime example of this failure mode. If a financial analyst asks an AI about \"EBITDA\" (earnings before interest, taxes, depreciation, and amortization), a standard vector database will retrieve every chunk where that acronym or a similar term appears.\"Multiple sections may mention EBITDA with similar wording, yet only one section defines the precise calculation, adjustments, or reporting scope relevant to the question,\" Zhang told VentureBeat. \"A similarity based retriever struggles to distinguish these cases because the semantic signals are nearly indistinguishable.\"This is the \"intent vs. content\" gap. The user does not want to find the word \"EBITDA\"; they want to understand the “logic” behind it for that specific quarter.Furthermore, traditional embeddings strip the query of its context. Because embedding models have strict input-length limits, the retrieval system usually only sees the specific question being asked, ignoring the previous turns of the conversation. This detaches the retrieval step from the user’s reasoning process. The system matches documents against a short, decontextualized query rather than the full history of the problem the user is trying to solve.Solving the multi-hop reasoning problemThe real-world impact of this structural approach is most visible in \"multi-hop\" queries that require the AI to follow a trail of breadcrumbs across different parts of a document.In a recent benchmark test known as FinanceBench, a system built on PageIndex called \"Mafin 2.5\" achieved a state-of-the-art accuracy score of 98.7%. The performance gap between this approach and vector-based systems becomes clear when analyzing how they handle internal references.Zhang offers the example of a query regarding the total value of deferred assets in a Federal Reserve annual report. The main section of the report describes the “change” in value but does not list the total. However, the text contains a footnote: “See Appendix G of this report … for more detailed information.”A vector-based system typically fails here. The text in Appendix G looks nothing like the user’s query about deferred assets; it is likely just a table of numbers. Because there is no semantic match, the vector database ignores it.The reasoning-based retriever, however, reads the cue in the main text, follows the structural link to Appendix G, locates the correct table, and returns the accurate figure.The latency trade-off and infrastructure shiftFor enterprise architects, the immediate concern with an LLM-driven search process is latency. Vector lookups occur in milliseconds; having an LLM \"read\" a table of contents implies a significantly slower user experience.However, Zhang explains that the perceived latency for the end-user may be negligible due to how the retrieval is integrated into the generation process. In a classic RAG setup, retrieval is a blocking step: the system must search the database before it can begin generating an answer. With PageIndex, retrieval happens inline, during the model’s reasoning process.\"The system can start streaming immediately, and retrieve as it generates,\" Zhang said. \"That means PageIndex does not add an extra &#x27;retrieval gate&#x27; before the first token, and Time to First Token (TTFT) is comparable to a normal LLM call.\"This architectural shift also simplifies the data infrastructure. By removing reliance on embeddings, enterprises no longer need to maintain a dedicated vector database. The tree-structured index is lightweight enough to sit in a traditional relational database like PostgreSQL.This addresses a growing pain point in LLM systems with retrieval components: the complexity of keeping vector stores in sync with living documents. PageIndex separates structure indexing from text extraction. If a contract is amended or a policy updated, the system can handle small edits by re-indexing only the affected subtree rather than reprocessing the entire document corpus. A decision matrix for the enterpriseWhile the accuracy gains are compelling, tree-search retrieval is not a universal replacement for vector search. The technology is best viewed as a specialized tool for \"deep work\" rather than a catch-all for every retrieval task.For short documents, such as emails or chat logs, the entire context often fits within a modern LLM’s context window, making any retrieval system unnecessary. Conversely, for tasks purely based on semantic discovery, such as recommending similar products or finding content with a similar \"vibe,\" vector embeddings remain the superior choice because the goal is proximity, not reasoning.PageIndex fits squarely in the middle: long, highly structured documents where the cost of error is high. This includes technical manuals, FDA filings, and merger agreements. In these scenarios, the requirement is auditability. An enterprise system needs to be able to explain not just the answer, but the path it took to find it (e.g., confirming that it checked Section 4.1, followed the reference to Appendix B, and synthesized the data found there).The future of agentic retrievalThe rise of frameworks like PageIndex signals a broader trend in the AI stack: the move toward \"Agentic RAG.\" As models become more capable of planning and reasoning, the responsibility for finding data is moving from the database layer to the model layer.We are already seeing this in the coding space, where agents like Claude Code and Cursor are moving away from simple vector lookups in favor of active codebase exploration. Zhang believes generic document retrieval will follow the same trajectory.\"Vector databases still have suitable use cases,\" Zhang said. \"But their historical role as the default database for LLMs and AI will become less clear over time.\"",
          "content": "A new open-source framework called PageIndex solves one of the old problems of retrieval-augmented generation (RAG): handling very long documents.The classic RAG workflow (chunk documents, calculate embeddings, store them in a vector database, and retrieve the top matches based on semantic similarity) works well for basic tasks such as Q&A over small documents.PageIndex abandons the standard \"chunk-and-embed\" method entirely and treats document retrieval not as a search problem, but as a navigation problem. But as enterprises try to move RAG into high-stakes workflows — auditing financial statements, analyzing legal contracts, navigating pharmaceutical protocols — they&#x27;re hitting an accuracy barrier that chunk optimization can&#x27;t solve.AlphaGo for documentsPageIndex addresses these limitations by borrowing a concept from game-playing AI rather than search engines: tree search.When humans need to find specific information in a dense textbook or a long annual report, they do not scan every paragraph linearly. They consult the table of contents to identify the relevant chapter, then the section, and finally the specific page. PageIndex forces the LLM to replicate this human behavior.Instead of pre-calculating vectors, the framework builds a \"Global Index\" of the document&#x27;s structure, creating a tree where nodes represent chapters, sections, and subsections. When a query arrives, the LLM performs a tree search, explicitly classifying each node as relevant or irrelevant based on the full context of the user&#x27;s request.\"In computer science terms, a table of contents is a tree-structured representation of a document, and navigating it corresponds to tree search,\" Zhang said. \"PageIndex applies the same core idea — tree search — to document retrieval, and can be thought of as an AlphaGo-style system for retrieval rather than for games.\"This shifts the architectural paradigm from passive retrieval, where the system simply fetches matching text, to active navigation, where an agentic model decides where to look.The limits of semantic similarityThere is a fundamental flaw in how traditional RAG handles complex data. Vector retrieval assumes that the text most semantically similar to a user’s query is also the most relevant. In professional domains, this assumption frequently breaks down.Mingtian Zhang, co-founder of PageIndex, points to financial reporting as a prime example of this failure mode. If a financial analyst asks an AI about \"EBITDA\" (earnings before interest, taxes, depreciation, and amortization), a standard vector database will retrieve every chunk where that acronym or a similar term appears.\"Multiple sections may mention EBITDA with similar wording, yet only one section defines the precise calculation, adjustments, or reporting scope relevant to the question,\" Zhang told VentureBeat. \"A similarity based retriever struggles to distinguish these cases because the semantic signals are nearly indistinguishable.\"This is the \"intent vs. content\" gap. The user does not want to find the word \"EBITDA\"; they want to understand the “logic” behind it for that specific quarter.Furthermore, traditional embeddings strip the query of its context. Because embedding models have strict input-length limits, the retrieval system usually only sees the specific question being asked, ignoring the previous turns of the conversation. This detaches the retrieval step from the user’s reasoning process. The system matches documents against a short, decontextualized query rather than the full history of the problem the user is trying to solve.Solving the multi-hop reasoning problemThe real-world impact of this structural approach is most visible in \"multi-hop\" queries that require the AI to follow a trail of breadcrumbs across different parts of a document.In a recent benchmark test known as FinanceBench, a system built on PageIndex called \"Mafin 2.5\" achieved a state-of-the-art accuracy score of 98.7%. The performance gap between this approach and vector-based systems becomes clear when analyzing how they handle internal references.Zhang offers the example of a query regarding the total value of deferred assets in a Federal Reserve annual report. The main section of the report describes the “change” in value but does not list the total. However, the text contains a footnote: “See Appendix G of this report … for more detailed information.”A vector-based system typically fails here. The text in Appendix G looks nothing like the user’s query about deferred assets; it is likely just a table of numbers. Because there is no semantic match, the vector database ignores it.The reasoning-based retriever, however, reads the cue in the main text, follows the structural link to Appendix G, locates the correct table, and returns the accurate figure.The latency trade-off and infrastructure shiftFor enterprise architects, the immediate concern with an LLM-driven search process is latency. Vector lookups occur in milliseconds; having an LLM \"read\" a table of contents implies a significantly slower user experience.However, Zhang explains that the perceived latency for the end-user may be negligible due to how the retrieval is integrated into the generation process. In a classic RAG setup, retrieval is a blocking step: the system must search the database before it can begin generating an answer. With PageIndex, retrieval happens inline, during the model’s reasoning process.\"The system can start streaming immediately, and retrieve as it generates,\" Zhang said. \"That means PageIndex does not add an extra &#x27;retrieval gate&#x27; before the first token, and Time to First Token (TTFT) is comparable to a normal LLM call.\"This architectural shift also simplifies the data infrastructure. By removing reliance on embeddings, enterprises no longer need to maintain a dedicated vector database. The tree-structured index is lightweight enough to sit in a traditional relational database like PostgreSQL.This addresses a growing pain point in LLM systems with retrieval components: the complexity of keeping vector stores in sync with living documents. PageIndex separates structure indexing from text extraction. If a contract is amended or a policy updated, the system can handle small edits by re-indexing only the affected subtree rather than reprocessing the entire document corpus. A decision matrix for the enterpriseWhile the accuracy gains are compelling, tree-search retrieval is not a universal replacement for vector search. The technology is best viewed as a specialized tool for \"deep work\" rather than a catch-all for every retrieval task.For short documents, such as emails or chat logs, the entire context often fits within a modern LLM’s context window, making any retrieval system unnecessary. Conversely, for tasks purely based on semantic discovery, such as recommending similar products or finding content with a similar \"vibe,\" vector embeddings remain the superior choice because the goal is proximity, not reasoning.PageIndex fits squarely in the middle: long, highly structured documents where the cost of error is high. This includes technical manuals, FDA filings, and merger agreements. In these scenarios, the requirement is auditability. An enterprise system needs to be able to explain not just the answer, but the path it took to find it (e.g., confirming that it checked Section 4.1, followed the reference to Appendix B, and synthesized the data found there).The future of agentic retrievalThe rise of frameworks like PageIndex signals a broader trend in the AI stack: the move toward \"Agentic RAG.\" As models become more capable of planning and reasoning, the responsibility for finding data is moving from the database layer to the model layer.We are already seeing this in the coding space, where agents like Claude Code and Cursor are moving away from simple vector lookups in favor of active codebase exploration. Zhang believes generic document retrieval will follow the same trajectory.\"Vector databases still have suitable use cases,\" Zhang said. \"But their historical role as the default database for LLMs and AI will become less clear over time.\"",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4v9URk1ocVyGKMS51rhSVr/e84742d331b23169965fbe8eee6c7220/agentic_RAG.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-the-galaxy-s26-lineup-and-everything-else-we-expect-130000999.html",
          "published_at": "Fri, 30 Jan 2026 17:49:21 +0000",
          "title": "Samsung Galaxy Unpacked 2026: The Galaxy S26 lineup and everything else we expect",
          "standfirst": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company is expected to host its first Galaxy Unpacked of the year in February to introduce the Galaxy S26 lineup.Engadget will be covering Galaxy Unpacked live, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for an official invite, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.What is Unpacked 2026 taking place?But first, when is Unpacked going to happen? A recent image shared by leakster Evan Blass indicated Unpacked should be taking place on “February 25 2026.” Blass has a long history of credible leaks, which means this date is all but confirmed, and the main questions remaining would be — what time and in what timezone? We’re still waiting on Samsung for the official details, which should include answers to those questions.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. That info came on January 27, when the company announced the TriFold would be available in the US on January 30, for a whopping $2,900. Considering we’ve already seen the device in person at CES 2026 and people are most likely to have had a chance to look at, if not buy the foldable for themselves by the time Unpacked rolls around, we don’t expect Samsung to spend too much time dwelling on it, if at all.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.Update, January 27 2026, 11:55AM ET: This story has been updated to reflect the latest news around the Galaxy Z TriFold’s price and availability in the US.Update, January 30 2026, 12:45PM ET: This story has been updated to include the latest leaks on the possible dates for Unpacked 2026.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-the-galaxy-s26-lineup-and-everything-else-we-expect-130000999.html?src=rss",
          "content": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company is expected to host its first Galaxy Unpacked of the year in February to introduce the Galaxy S26 lineup.Engadget will be covering Galaxy Unpacked live, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for an official invite, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.What is Unpacked 2026 taking place?But first, when is Unpacked going to happen? A recent image shared by leakster Evan Blass indicated Unpacked should be taking place on “February 25 2026.” Blass has a long history of credible leaks, which means this date is all but confirmed, and the main questions remaining would be — what time and in what timezone? We’re still waiting on Samsung for the official details, which should include answers to those questions.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. That info came on January 27, when the company announced the TriFold would be available in the US on January 30, for a whopping $2,900. Considering we’ve already seen the device in person at CES 2026 and people are most likely to have had a chance to look at, if not buy the foldable for themselves by the time Unpacked rolls around, we don’t expect Samsung to spend too much time dwelling on it, if at all.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.Update, January 27 2026, 11:55AM ET: This story has been updated to reflect the latest news around the Galaxy Z TriFold’s price and availability in the US.Update, January 30 2026, 12:45PM ET: This story has been updated to include the latest leaks on the possible dates for Unpacked 2026.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-the-galaxy-s26-lineup-and-everything-else-we-expect-130000999.html?src=rss",
          "feed_position": 10,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-01/59db82d0-d8d0-11ef-babd-deb856accfc5"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/the-trust-paradox-killing-ai-at-scale-76-of-data-leaders-cant-govern-what",
          "published_at": "Fri, 30 Jan 2026 17:35:00 GMT",
          "title": "The trust paradox killing AI at scale: 76% of data leaders can't govern what employees already use",
          "standfirst": "The chief data officer (CDO) has evolved from a niche compliance role into one of the most critical positions for AI deployment. These executives now sit at the intersection of data governance, AI strategy, and workforce readiness. Their decisions determine whether enterprises move from AI pilots to production scale or remain stuck in experimentation mode.That&#x27;s why Informatica&#x27;s third annual survey — the largest survey yet of CDOs specifically on AI readiness, spanning 600 executives globally — carries particular weight. The findings expose a dangerous disconnect that explains why so many organizations struggle to scale AI beyond pilots: While 69% of enterprises have deployed generative AI and 47% are running agentic AI systems, 76% admit their governance frameworks can&#x27;t keep pace with how employees actually use these technologies.The survey reveals what Informatica calls a \"trust paradox\" — and explains why data leaders are dangerously overconfident about AI readiness. Organizations deployed generative AI systems faster than they built the governance and training infrastructure to support them. The result: Employees generally trust the data powering AI systems, but organizations acknowledge their workforces lack the literacy to question that data or use AI responsibly. Seventy-five percent of data leaders say employees need upskilling in data literacy. Seventy-four percent require AI literacy training for day-to-day operations.\"The gap now is just, can you trust the data to set an agent loose on it?\" Graeme Thompson, CIO at Informatica, told VentureBeat. \"The agents do what they&#x27;re supposed to do if you give them the right information. There&#x27;s just such a lack of trust in the data that I think that&#x27;s the gap.\"Why infrastructure isn&#x27;t the bottleneck for data and AIGenAI adoption jumped from 48% a year ago to 69% today. Nearly half of organizations (47%) now run agentic AI — systems that autonomously take actions rather than just generate content. This rapid expansion has created a race to acquire vector databases, upgrade data pipelines, and expand compute infrastructure.But Thompson dismisses infrastructure gaps as the primary problem. The technology exists and works. The limitation is organizational, not technical.\"The technology that we have available at the moment, the infrastructure, is more than — it&#x27;s not the problem yet,\" Thompson said. He compared the situation to amateur athletes blaming their equipment. \"There&#x27;s a long way to go before the equipment is the problem in the room. People chase equipment like golfers. Those golfers are a sucker for a new driver, a new putter that&#x27;s going to cure their physical inability to hit a golf ball straight.\"The survey data supports this. When asked about 2026 investment priorities, the top three are all people and process issues: data privacy and security (43%), AI governance (41%), and workforce upskilling (39%).Five hard lessons for enterprise CDOs The survey data combined with Thompson&#x27;s implementation experience reveals specific lessons for data leaders trying to move from pilots to production.Stop chasing infrastructure, fix the people problemThe trust paradox exists because organizations can deploy AI technology faster than they can train people to use it responsibly. Seventy-five percent need data literacy upskilling. Seventy-four percent need AI literacy training. The technology gap is a people gap.\"It&#x27;s much easier to get your people that know your company and know your data and know your processes to learn AI than it is to bring an AI person in that doesn&#x27;t know anything about those things and teach them about your company,\" Thompson said. \"And also the AI people are super expensive, just like data scientists are super expensive.\"Make the CDO an execution function, not an ivory towerThompson structures Informatica so the CDO reports directly to him as CIO. This makes data governance an execution function rather than a separate strategic layer.\"That is a deliberate decision based on that function being a get things done function instead of an ivory tower function,\" Thompson said. The structure ensures data teams and application owners share common priorities through a common boss. \"If they have a common boss, their priorities should be aligned. And if not, it&#x27;s because the boss isn&#x27;t doing his job, not because the two functions aren&#x27;t working off the same priority list.\"If 76% of organizations can&#x27;t govern AI usage effectively, reporting structure may be part of the problem. Siloed data and IT functions create the conditions for pilots that never scale.Build literacy outside IT teamsThe breakthrough insight is that AI literacy programs must extend beyond technology teams into business functions. At Informatica, the chief marketing officer is one of Thompson&#x27;s strongest AI partners.\"You need that literacy across your business teams as well as in your technology teams,\" Thompson said. He noted that the marketing operations team understands the technology and data. It knows that the answer to the \"How do I get more value out of my limited marketing program dollars each year?\" is by automating and adding AI to how that job is done, not adding people and more Google ad dollars.Business-side literacy creates pull rather than push for AI adoption. Marketing, sales and operations teams start demanding AI capabilities because they see strategic value, not just efficiency gains.Pitch AI as strategic expansion, not cost reductionData leaders have spent decades fighting perceptions that IT is just a cost center. AI offers the opportunity to change that narrative, but only if CDOs reframe the value proposition away from productivity savings.\"I am very disappointed that, given this new technology capability on a plate, as IT people and as data people, we immediately turn around and talk about productivity savings,\" Thompson said. \"What a waste of an opportunity.\"The tactical shift: Pitch AI&#x27;s ability to remove headcount constraints entirely rather than reduce existing headcount. This reframes AI from operational efficiency to strategic capability. Organizations can expand market reach, enter new geographies and test initiatives that were previously cost-prohibitive. \"It&#x27;s not about saving money,\" Thompson said. \"And if that&#x27;s mainly the approach that you have, then your company&#x27;s not going to win.\"Go vertical first, scale the patternDon&#x27;t wait for perfect horizontal data governance layers before delivering production value. Pick one high-value use case. Build the complete governance, data quality and literacy stack for that specific workflow. Validate results. Then replicate the pattern to adjacent use cases.This delivers production value while building organizational capability incrementally. “I think this space is moving so quickly that if you try and solve 100% your governance problem before you get to your semantic layer problem, before you get to your glossary of terms problem, then you&#x27;re never going to generate any outcome and people are going to lose patience,\" Thompson said.",
          "content": "The chief data officer (CDO) has evolved from a niche compliance role into one of the most critical positions for AI deployment. These executives now sit at the intersection of data governance, AI strategy, and workforce readiness. Their decisions determine whether enterprises move from AI pilots to production scale or remain stuck in experimentation mode.That&#x27;s why Informatica&#x27;s third annual survey — the largest survey yet of CDOs specifically on AI readiness, spanning 600 executives globally — carries particular weight. The findings expose a dangerous disconnect that explains why so many organizations struggle to scale AI beyond pilots: While 69% of enterprises have deployed generative AI and 47% are running agentic AI systems, 76% admit their governance frameworks can&#x27;t keep pace with how employees actually use these technologies.The survey reveals what Informatica calls a \"trust paradox\" — and explains why data leaders are dangerously overconfident about AI readiness. Organizations deployed generative AI systems faster than they built the governance and training infrastructure to support them. The result: Employees generally trust the data powering AI systems, but organizations acknowledge their workforces lack the literacy to question that data or use AI responsibly. Seventy-five percent of data leaders say employees need upskilling in data literacy. Seventy-four percent require AI literacy training for day-to-day operations.\"The gap now is just, can you trust the data to set an agent loose on it?\" Graeme Thompson, CIO at Informatica, told VentureBeat. \"The agents do what they&#x27;re supposed to do if you give them the right information. There&#x27;s just such a lack of trust in the data that I think that&#x27;s the gap.\"Why infrastructure isn&#x27;t the bottleneck for data and AIGenAI adoption jumped from 48% a year ago to 69% today. Nearly half of organizations (47%) now run agentic AI — systems that autonomously take actions rather than just generate content. This rapid expansion has created a race to acquire vector databases, upgrade data pipelines, and expand compute infrastructure.But Thompson dismisses infrastructure gaps as the primary problem. The technology exists and works. The limitation is organizational, not technical.\"The technology that we have available at the moment, the infrastructure, is more than — it&#x27;s not the problem yet,\" Thompson said. He compared the situation to amateur athletes blaming their equipment. \"There&#x27;s a long way to go before the equipment is the problem in the room. People chase equipment like golfers. Those golfers are a sucker for a new driver, a new putter that&#x27;s going to cure their physical inability to hit a golf ball straight.\"The survey data supports this. When asked about 2026 investment priorities, the top three are all people and process issues: data privacy and security (43%), AI governance (41%), and workforce upskilling (39%).Five hard lessons for enterprise CDOs The survey data combined with Thompson&#x27;s implementation experience reveals specific lessons for data leaders trying to move from pilots to production.Stop chasing infrastructure, fix the people problemThe trust paradox exists because organizations can deploy AI technology faster than they can train people to use it responsibly. Seventy-five percent need data literacy upskilling. Seventy-four percent need AI literacy training. The technology gap is a people gap.\"It&#x27;s much easier to get your people that know your company and know your data and know your processes to learn AI than it is to bring an AI person in that doesn&#x27;t know anything about those things and teach them about your company,\" Thompson said. \"And also the AI people are super expensive, just like data scientists are super expensive.\"Make the CDO an execution function, not an ivory towerThompson structures Informatica so the CDO reports directly to him as CIO. This makes data governance an execution function rather than a separate strategic layer.\"That is a deliberate decision based on that function being a get things done function instead of an ivory tower function,\" Thompson said. The structure ensures data teams and application owners share common priorities through a common boss. \"If they have a common boss, their priorities should be aligned. And if not, it&#x27;s because the boss isn&#x27;t doing his job, not because the two functions aren&#x27;t working off the same priority list.\"If 76% of organizations can&#x27;t govern AI usage effectively, reporting structure may be part of the problem. Siloed data and IT functions create the conditions for pilots that never scale.Build literacy outside IT teamsThe breakthrough insight is that AI literacy programs must extend beyond technology teams into business functions. At Informatica, the chief marketing officer is one of Thompson&#x27;s strongest AI partners.\"You need that literacy across your business teams as well as in your technology teams,\" Thompson said. He noted that the marketing operations team understands the technology and data. It knows that the answer to the \"How do I get more value out of my limited marketing program dollars each year?\" is by automating and adding AI to how that job is done, not adding people and more Google ad dollars.Business-side literacy creates pull rather than push for AI adoption. Marketing, sales and operations teams start demanding AI capabilities because they see strategic value, not just efficiency gains.Pitch AI as strategic expansion, not cost reductionData leaders have spent decades fighting perceptions that IT is just a cost center. AI offers the opportunity to change that narrative, but only if CDOs reframe the value proposition away from productivity savings.\"I am very disappointed that, given this new technology capability on a plate, as IT people and as data people, we immediately turn around and talk about productivity savings,\" Thompson said. \"What a waste of an opportunity.\"The tactical shift: Pitch AI&#x27;s ability to remove headcount constraints entirely rather than reduce existing headcount. This reframes AI from operational efficiency to strategic capability. Organizations can expand market reach, enter new geographies and test initiatives that were previously cost-prohibitive. \"It&#x27;s not about saving money,\" Thompson said. \"And if that&#x27;s mainly the approach that you have, then your company&#x27;s not going to win.\"Go vertical first, scale the patternDon&#x27;t wait for perfect horizontal data governance layers before delivering production value. Pick one high-value use case. Build the complete governance, data quality and literacy stack for that specific workflow. Validate results. Then replicate the pattern to adjacent use cases.This delivers production value while building organizational capability incrementally. “I think this space is moving so quickly that if you try and solve 100% your governance problem before you get to your semantic layer problem, before you get to your glossary of terms problem, then you&#x27;re never going to generate any outcome and people are going to lose patience,\" Thompson said.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2Lp92fSZvpwMP9R1IOknlt/19376e3ebf1bab8664452fee629f901c/CDO-smk1.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/best-cheap-vpn-170000957.html",
          "published_at": "Fri, 30 Jan 2026 17:00:00 +0000",
          "title": "The best cheap VPN in 2026",
          "standfirst": "When talking about the best VPNs, I frequently warn about the dangers of trusting free VPNs without verifying them. Although there are a few free VPNs worth recommending, many other free providers are ineffective, malicious or looking to profit off their users (or sometimes all three). Even the best free VPNs work a lot better once you subscribe and access their full service.This can be frustrating if you want to enjoy the benefits of a VPN but don't have the budget for yet another subscription. To help you out, I put together a list of the best paid VPN services you can get cheaply. Every name on the list comes with my full recommendation — I'll never recommend a VPN that doesn't protect you, no matter how affordable.Before I get started, I want to define \"cheap,\" since VPNs often bamboozle the customer with muddled pricing schemes. Most providers have long-term subscription plans with big discounts, and many of them compensate by making their monthly plans more expensive. On this list, I'll recommend services with cheap subscriptions for both the short and long term, plus one favorite that balances both. Best cheap VPNs for 2026 Other VPNs we tested with good deals A couple of VPNs have decent pricing options attached to worthy services but weren't quite strong enough to make the list. Both these services get my hearty recommendation; they're just hard to justify as \"cheap.\" ExpressVPN ExpressVPN recently switched to a multi-tier pricing model. The Basic pricing tier gets you complete VPN service but doesn't include the full set of features. The best price on that is $78.18 for 28 months, which works out to $2.79 per month. Although that sounds great, it's more expensive than both Surfshark and CyberGhost at the same duration and renews at the even higher price of $99.95 per year ($8.33 per month). Still, as I wrote in my full ExpressVPN review, it's an outstanding service overall. Thanks to its sensible app layouts and focus on doing simple tasks well, I find it especially good for introducing beginners to what a VPN can do. NordVPN NordVPN is another provider that I gave a relatively positive review. I really like its boundary-pushing features, especially the various types of highly specialized servers. Its pricing isn't bad, exactly, but even the Basic level is more expensive than just about everyone else at every duration. NordVPN's fast download speeds and wide server network make it worthwhile for lots of users, but it's hard to recommend to people on a budget. What to look for in a good cheap VPN Looking for an affordable VPN is the same as looking for any kind of VPN; it just requires more care. The worst VPNs usually present themselves as free, but there's also a fair number of mediocre options that think low prices have to mean a mediocre service. If you want to use a VPN but don't have much extra cash, take some additional care in a few areas of your search. First, don't subscribe to a VPN — or even download any of its apps — if you haven't verified its security. To do that, start by checking what experts have to say about it. If a VPN is truly unsafe, chances are high that somebody has already sounded the alarm. You can also check the list of protocols the VPN offers. If it's anything other than OpenVPN, WireGuard or IKEv2, do a deep dive to make sure it's using worthwhile encryption. If you've verified that the VPN isn't a virus, check to see if it has a free trial or a guaranteed money-back period. This will give you some risk-free time to do hands-on tests. Our article on how we test VPNs includes several tests you can run on your own computer, phone or tablet. Check the VPN's speed, make sure it has the server locations you need and look for anything that might be leaking your real IP address. Read the VPN's privacy policy and make sure you're comfortable with how much information it saves. Some VPNs emphasize privacy more than others. Finally, before your free trial or refund period expires, make sure to double-check on the pricing structure of the VPN you're choosing — it's possible that it will only be cheap for the first subscription period.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/best-cheap-vpn-170000957.html?src=rss",
          "content": "When talking about the best VPNs, I frequently warn about the dangers of trusting free VPNs without verifying them. Although there are a few free VPNs worth recommending, many other free providers are ineffective, malicious or looking to profit off their users (or sometimes all three). Even the best free VPNs work a lot better once you subscribe and access their full service.This can be frustrating if you want to enjoy the benefits of a VPN but don't have the budget for yet another subscription. To help you out, I put together a list of the best paid VPN services you can get cheaply. Every name on the list comes with my full recommendation — I'll never recommend a VPN that doesn't protect you, no matter how affordable.Before I get started, I want to define \"cheap,\" since VPNs often bamboozle the customer with muddled pricing schemes. Most providers have long-term subscription plans with big discounts, and many of them compensate by making their monthly plans more expensive. On this list, I'll recommend services with cheap subscriptions for both the short and long term, plus one favorite that balances both. Best cheap VPNs for 2026 Other VPNs we tested with good deals A couple of VPNs have decent pricing options attached to worthy services but weren't quite strong enough to make the list. Both these services get my hearty recommendation; they're just hard to justify as \"cheap.\" ExpressVPN ExpressVPN recently switched to a multi-tier pricing model. The Basic pricing tier gets you complete VPN service but doesn't include the full set of features. The best price on that is $78.18 for 28 months, which works out to $2.79 per month. Although that sounds great, it's more expensive than both Surfshark and CyberGhost at the same duration and renews at the even higher price of $99.95 per year ($8.33 per month). Still, as I wrote in my full ExpressVPN review, it's an outstanding service overall. Thanks to its sensible app layouts and focus on doing simple tasks well, I find it especially good for introducing beginners to what a VPN can do. NordVPN NordVPN is another provider that I gave a relatively positive review. I really like its boundary-pushing features, especially the various types of highly specialized servers. Its pricing isn't bad, exactly, but even the Basic level is more expensive than just about everyone else at every duration. NordVPN's fast download speeds and wide server network make it worthwhile for lots of users, but it's hard to recommend to people on a budget. What to look for in a good cheap VPN Looking for an affordable VPN is the same as looking for any kind of VPN; it just requires more care. The worst VPNs usually present themselves as free, but there's also a fair number of mediocre options that think low prices have to mean a mediocre service. If you want to use a VPN but don't have much extra cash, take some additional care in a few areas of your search. First, don't subscribe to a VPN — or even download any of its apps — if you haven't verified its security. To do that, start by checking what experts have to say about it. If a VPN is truly unsafe, chances are high that somebody has already sounded the alarm. You can also check the list of protocols the VPN offers. If it's anything other than OpenVPN, WireGuard or IKEv2, do a deep dive to make sure it's using worthwhile encryption. If you've verified that the VPN isn't a virus, check to see if it has a free trial or a guaranteed money-back period. This will give you some risk-free time to do hands-on tests. Our article on how we test VPNs includes several tests you can run on your own computer, phone or tablet. Check the VPN's speed, make sure it has the server locations you need and look for anything that might be leaking your real IP address. Read the VPN's privacy policy and make sure you're comfortable with how much information it saves. Some VPNs emphasize privacy more than others. Finally, before your free trial or refund period expires, make sure to double-check on the pricing structure of the VPN you're choosing — it's possible that it will only be cheap for the first subscription period.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/best-cheap-vpn-170000957.html?src=rss",
          "feed_position": 14
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/amazon-discovered-a-high-volume-of-csam-in-its-ai-training-data-but-isnt-saying-where-it-came-from-224749228.html",
          "published_at": "Fri, 30 Jan 2026 16:05:02 +0000",
          "title": "Amazon discovered a 'high volume' of CSAM in its AI training data but isn't saying where it came from",
          "standfirst": "The National Center for Missing and Exploited Children said it received more than 1 million reports of AI-related child sexual abuse material (CSAM) in 2025. The \"vast majority\" of that content was reported by Amazon, which found the material in its training data, according to an investigation by Bloomberg. In addition, Amazon said only that it obtained the inappropriate content from external sources used to train its AI services and claimed it could not provide any further details about where the CSAM came from. Amazon provided Engadget with the following statement to explain why it doesn’t have data that can provide any further action on the “When we set up this reporting channel in 2024, we informed NCMEC that we would not have sufficient information to create actionable reports, because of the third-party nature of the scanned data. The separate channel ensures that these reports would not dilute the efficacy of our other reporting channels. Because of how this data is sourced, we don't have the data that comprises an actionable report.”\"This is really an outlier,\" Fallon McNulty, executive director of NCMEC’s CyberTipline, told Bloomberg. The CyberTipline is where many types of US-based companies are legally required to report suspected CSAM. “Having such a high volume come in throughout the year begs a lot of questions about where the data is coming from, and what safeguards have been put in place.” She added that aside from Amazon, the AI-related reports the organization received from other companies last year included actionable data that it could pass along to law enforcement for next steps. Since Amazon isn’t disclosing sources, McNulty said its reports have proved “inactionable.”Amazon provided Engadget with these additional details, which were first reported in Bloomberg:“Amazon is committed to preventing CSAM across all of its businesses, and we are not aware of any instances of our models generating CSAM. In accordance with our commitments to responsible AI and the Generative AI Principles to Prevent Child Abuse, we take a deliberately cautious approach to scanning foundation model training data, including data from the public web, to identify and remove known CSAM and protect our customers. While our proactive safeguards cannot provide the same detail in NCMEC reports as consumer-facing tools, we stand by our commitment to responsible AI and will continue our work to prevent CSAM.”The company also reiterated that “we intentionally use an over-inclusive threshold for scanning, which yields a high percentage of false positives” to explain the high volume of content the company reported.Safety questions for minors have emerged as a critical concern for the artificial intelligence industry in recent months. CSAM has skyrocketed in NCMEC's records; compared with the more than 1 million AI-related reports the organization received last year, the 2024 total was 67,000 reports while 2023 only saw 4,700 reports. In addition to issues such as abusive content being used to train models, AI chatbots have also been implicated in several dangerous or tragic cases involving young users. OpenAI and Character.AI have both been sued after teenagers planned their suicides with those companies' platforms. Meta is also being sued for alleged failures to protect teen users from sexually explicit conversations with chatbots.Update, January 30, 2026, 11:05AM ET: This story has been updated with several statements from Amazon.This article originally appeared on Engadget at https://www.engadget.com/ai/amazon-discovered-a-high-volume-of-csam-in-its-ai-training-data-but-isnt-saying-where-it-came-from-224749228.html?src=rss",
          "content": "The National Center for Missing and Exploited Children said it received more than 1 million reports of AI-related child sexual abuse material (CSAM) in 2025. The \"vast majority\" of that content was reported by Amazon, which found the material in its training data, according to an investigation by Bloomberg. In addition, Amazon said only that it obtained the inappropriate content from external sources used to train its AI services and claimed it could not provide any further details about where the CSAM came from. Amazon provided Engadget with the following statement to explain why it doesn’t have data that can provide any further action on the “When we set up this reporting channel in 2024, we informed NCMEC that we would not have sufficient information to create actionable reports, because of the third-party nature of the scanned data. The separate channel ensures that these reports would not dilute the efficacy of our other reporting channels. Because of how this data is sourced, we don't have the data that comprises an actionable report.”\"This is really an outlier,\" Fallon McNulty, executive director of NCMEC’s CyberTipline, told Bloomberg. The CyberTipline is where many types of US-based companies are legally required to report suspected CSAM. “Having such a high volume come in throughout the year begs a lot of questions about where the data is coming from, and what safeguards have been put in place.” She added that aside from Amazon, the AI-related reports the organization received from other companies last year included actionable data that it could pass along to law enforcement for next steps. Since Amazon isn’t disclosing sources, McNulty said its reports have proved “inactionable.”Amazon provided Engadget with these additional details, which were first reported in Bloomberg:“Amazon is committed to preventing CSAM across all of its businesses, and we are not aware of any instances of our models generating CSAM. In accordance with our commitments to responsible AI and the Generative AI Principles to Prevent Child Abuse, we take a deliberately cautious approach to scanning foundation model training data, including data from the public web, to identify and remove known CSAM and protect our customers. While our proactive safeguards cannot provide the same detail in NCMEC reports as consumer-facing tools, we stand by our commitment to responsible AI and will continue our work to prevent CSAM.”The company also reiterated that “we intentionally use an over-inclusive threshold for scanning, which yields a high percentage of false positives” to explain the high volume of content the company reported.Safety questions for minors have emerged as a critical concern for the artificial intelligence industry in recent months. CSAM has skyrocketed in NCMEC's records; compared with the more than 1 million AI-related reports the organization received last year, the 2024 total was 67,000 reports while 2023 only saw 4,700 reports. In addition to issues such as abusive content being used to train models, AI chatbots have also been implicated in several dangerous or tragic cases involving young users. OpenAI and Character.AI have both been sued after teenagers planned their suicides with those companies' platforms. Meta is also being sued for alleged failures to protect teen users from sexually explicit conversations with chatbots.Update, January 30, 2026, 11:05AM ET: This story has been updated with several statements from Amazon.This article originally appeared on Engadget at https://www.engadget.com/ai/amazon-discovered-a-high-volume-of-csam-in-its-ai-training-data-but-isnt-saying-where-it-came-from-224749228.html?src=rss",
          "feed_position": 16
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/monarch-money-deal-new-users-get-one-year-of-access-for-only-50-204507285.html",
          "published_at": "Fri, 30 Jan 2026 16:01:27 +0000",
          "title": "Monarch Money deal: New users get one year of access for only $50",
          "standfirst": "The start of the new year is a great time to get your finances in order, and a good budgeting app can help with that. Instead of laboring over a spreadsheet, you can try one of our favorite budgeting apps for less than usual. Monarch Money is running a sale that gives new users 50 percent off one year of the service, bringing the final cost down to just $50. Just use the code NEWYEAR2026 at checkout to get the discount. Monarch Money makes for a capable and detailed budgeting companion. You can use the service via apps for iOS, Android, iPadOS or the web, and Monarch also offers a Chrome extension that can sync your Amazon and Target transactions and automatically categorize them. Like other budgeting apps, Monarch Money lets you connect multiple financial accounts and track your money based on where you spend it over time. Monarch offers two different approaches to tracking budgeting (flexible and category budgeting) depending on what fits your life best, and the ability to add a budget widget on your phone so you can know how you're tracking that month. How budgeting apps turn your raw transactions into visuals you can understand at a glance is one of the big things that differentiates one app from another, and Monarch Money offers multiple graphs and charts to look at for things like spending, investments or categories of your choice based on how you've labelled your expenses. The app can also monitor the spending of you and your partner all in one place, to make it easier to plan together. The main drawbacks Engadget found in testing Monarch Money were the app's learning curve, and the differences in features (and bugginess) between Monarch's web and mobile versions. Still, for 50 percent off, the Monarch Money is well worth experimenting with if you're trying to save money in 2026, especially if you want to do it collaboratively with a partner. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/monarch-money-deal-new-users-get-one-year-of-access-for-only-50-204507285.html?src=rss",
          "content": "The start of the new year is a great time to get your finances in order, and a good budgeting app can help with that. Instead of laboring over a spreadsheet, you can try one of our favorite budgeting apps for less than usual. Monarch Money is running a sale that gives new users 50 percent off one year of the service, bringing the final cost down to just $50. Just use the code NEWYEAR2026 at checkout to get the discount. Monarch Money makes for a capable and detailed budgeting companion. You can use the service via apps for iOS, Android, iPadOS or the web, and Monarch also offers a Chrome extension that can sync your Amazon and Target transactions and automatically categorize them. Like other budgeting apps, Monarch Money lets you connect multiple financial accounts and track your money based on where you spend it over time. Monarch offers two different approaches to tracking budgeting (flexible and category budgeting) depending on what fits your life best, and the ability to add a budget widget on your phone so you can know how you're tracking that month. How budgeting apps turn your raw transactions into visuals you can understand at a glance is one of the big things that differentiates one app from another, and Monarch Money offers multiple graphs and charts to look at for things like spending, investments or categories of your choice based on how you've labelled your expenses. The app can also monitor the spending of you and your partner all in one place, to make it easier to plan together. The main drawbacks Engadget found in testing Monarch Money were the app's learning curve, and the differences in features (and bugginess) between Monarch's web and mobile versions. Still, for 50 percent off, the Monarch Money is well worth experimenting with if you're trying to save money in 2026, especially if you want to do it collaboratively with a partner. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/monarch-money-deal-new-users-get-one-year-of-access-for-only-50-204507285.html?src=rss",
          "feed_position": 17
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-disney-and-hulu-bundle-is-on-sale-for-10-for-one-month-192814872.html",
          "published_at": "Fri, 30 Jan 2026 13:46:28 +0000",
          "title": "The Disney+ and Hulu bundle is on sale for $10 for one month",
          "standfirst": "You have the best chance to save on streaming services during the holiday shopping season, but throughout the year, the occasional deal pops up that's worth considering. Case in point: this new Disney+ deal. New and eligible returning subscribers can sign up for the Disney+ Hulu bundle (with ads) for $10 for one month of access. That's $3 off the usual price of the bundle for one month, and more than 58 percent off if you consider the cost of each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-disney-and-hulu-bundle-is-on-sale-for-10-for-one-month-192814872.html?src=rss",
          "content": "You have the best chance to save on streaming services during the holiday shopping season, but throughout the year, the occasional deal pops up that's worth considering. Case in point: this new Disney+ deal. New and eligible returning subscribers can sign up for the Disney+ Hulu bundle (with ads) for $10 for one month of access. That's $3 off the usual price of the bundle for one month, and more than 58 percent off if you consider the cost of each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-disney-and-hulu-bundle-is-on-sale-for-10-for-one-month-192814872.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/iphone-fold-rumors-everything-we-know-so-far-including-the-leaked-design-130000516.html",
          "published_at": "Fri, 30 Jan 2026 13:00:00 +0000",
          "title": "iPhone Fold rumors: Everything we know so far, including the leaked design",
          "standfirst": "Apple has yet to announce a foldable iPhone, but after years of speculation, the outlines of what’s often referred to as the iPhone Fold are starting to come into focus. Multiple analysts and leakers now agree that Apple is targeting a late-2026 launch window for its first foldable phone, positioning it as a premium flagship rather than a niche experiment.As with all pre-launch Apple products, nothing here is official. Plans can change, features can be dropped and timelines can slip. Still, recent reports paint the clearest picture yet of how Apple might approach a foldable iPhone and how it plans to differentiate itself from rivals like Samsung and Google.Below is a roundup of the most credible iPhone Fold rumors so far, covering its possible release timing, design, display technology, cameras and price. We’ll continue to update this post as more rumors and details become available.When could the iPhone Fold launch?Rumors of a foldable iPhone date back as far as 2017, but more recent reporting suggests Apple has finally locked onto a realistic window. Most sources now point to fall 2026, likely alongside the iPhone 18 lineup.Mark Gurman has gone back and forth on timing, initially suggesting Apple could launch “as early as 2026,” before later writing that the device would ship at the end of 2026 and sell primarily in 2027. Analyst Ming-Chi Kuo has also repeatedly cited the second half of 2026 as Apple’s target.Some reports still claim the project could slip into 2027 if Apple runs into manufacturing or durability issues, particularly around the hinge or display. Given Apple’s history of delaying products that it feels aren’t ready, that remains a real possibility.What will the iPhone Fold look like?Current consensus suggests Apple has settled on a book-style foldable design, similar to Samsung’s Galaxy Z Fold series, rather than a clamshell flip phone.When unfolded, the iPhone Fold is expected to resemble a small tablet like the iPad mini (8.3 inches). Based on the rumor mill, though, the iPhone Fold may be a touch smaller, with an internal display measuring around 7.7 to 7.8 inches. When closed, it should function like a conventional smartphone, with an outer display in the 5.5-inch range.CAD leaks and alleged case-maker molds suggest the device may be shorter and wider than a standard iPhone when folded, creating a squarer footprint that better matches the aspect ratio of the inner display. Several reports have also pointed to the iPhone Air as a potential preview of Apple’s foldable design work, with its unusually thin chassis widely interpreted as a look at what one half of a future foldable iPhone could resemble.If that theory holds, it could help explain the Fold’s rumored dimensions. Thickness is expected to land between roughly 4.5 and 5.6mm when unfolded, putting it in a similar range to the iPhone Air, and just over 9 to 11mm when folded, depending on the final hinge design and internal layering.iPhone 17 Pro, iPhone AirEngadgetDisplay and the crease questionThe display is arguably the biggest challenge for any foldable phone, and it’s an area where Apple appears to have invested years of development.Multiple reports say Apple will rely on Samsung Display as its primary supplier. At CES 2026, Samsung showcased a new crease-less foldable OLED panel, which several sources — including Bloomberg — suggested could be the same technology Apple plans to use.According to these reports, the panel combines a flexible OLED with a laser-drilled metal support plate that disperses stress when folding. The goal is a display with a nearly invisible crease, something Apple reportedly considers essential before entering the foldable market.If Apple does use this panel, it would mark a notable improvement over current foldables, which still show visible creasing under certain lighting conditions.Cameras and biometricsCamera rumors suggest Apple is planning a four-camera setup. That may include:Two rear cameras (main and ultra-wide, both rumored at 48MP)One punch-hole camera on the outer displayOne under-display camera on the inner screenSeveral sources claim Apple will avoid Face ID entirely on the iPhone Fold. Instead, it’s expected to rely on Touch ID built into the power button, similar to recent iPad models. This would allow Apple to keep both displays free of notches or Dynamic Island cutouts.Under-display camera technology has historically produced lower image quality, but a rumored 24MP sensor would be a significant step up compared to existing foldables, which typically use much lower-resolution sensors.iPhone Fold’s hinge and materialsThe hinge is another area where Apple may diverge from competitors. Multiple reports claim Apple will use Liquidmetal, which is a long-standing trade name for a metallic glass alloy the company has previously used in smaller components. While often referred to as “liquid metal” or “Liquid Metal” in reports, Liquidmetal is the branding Apple has historically associated with the material.Liquidmetal is said to be stronger and more resistant to deformation than titanium, while remaining relatively lightweight. If accurate, this could help improve long-term durability and reduce wear on the foldable display.Leaks from Jon Prosser also reference a metal plate beneath the display that works in tandem with the hinge to minimize creasing — a claim that aligns with reporting from Korean and Chinese supply-chain sources.Battery and other components Battery life is another potential differentiator. According to Ming-Chi Kuo and multiple Asian supply-chain reports, Apple is testing high-density battery cells in the 5,000 to 5,800mAh range.That would make it the largest battery ever used in an iPhone, and competitive with (or larger than) batteries in current Android foldables. The device is also expected to use a future A-series chip and Apple’s in-house modem.PriceNone of this will come cheap, that’s for certain. Nearly every report agrees that the iPhone Fold will be Apple’s most expensive iPhone ever.Estimates currently place the price between $2,000 and $2,500 in the US. Bloomberg has said the price will be “at least $2,000,” while other analysts have narrowed the likely range to around $2,100 and $2,300. That positions the iPhone Fold well above the iPhone Pro Max and closer to Apple’s high-end Macs and iPads.Despite years of rumors, there’s still plenty that remains unclear. Apple hasn’t confirmed the name “iPhone Fold,” final dimensions, software features or how iOS would adapt to a folding form factor. Durability, repairability and long-term reliability are also open questions. For now, the safest assumption is that Apple is taking its time and that many of these details could still change before launch. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/iphone-fold-rumors-everything-we-know-so-far-including-the-leaked-design-130000516.html?src=rss",
          "content": "Apple has yet to announce a foldable iPhone, but after years of speculation, the outlines of what’s often referred to as the iPhone Fold are starting to come into focus. Multiple analysts and leakers now agree that Apple is targeting a late-2026 launch window for its first foldable phone, positioning it as a premium flagship rather than a niche experiment.As with all pre-launch Apple products, nothing here is official. Plans can change, features can be dropped and timelines can slip. Still, recent reports paint the clearest picture yet of how Apple might approach a foldable iPhone and how it plans to differentiate itself from rivals like Samsung and Google.Below is a roundup of the most credible iPhone Fold rumors so far, covering its possible release timing, design, display technology, cameras and price. We’ll continue to update this post as more rumors and details become available.When could the iPhone Fold launch?Rumors of a foldable iPhone date back as far as 2017, but more recent reporting suggests Apple has finally locked onto a realistic window. Most sources now point to fall 2026, likely alongside the iPhone 18 lineup.Mark Gurman has gone back and forth on timing, initially suggesting Apple could launch “as early as 2026,” before later writing that the device would ship at the end of 2026 and sell primarily in 2027. Analyst Ming-Chi Kuo has also repeatedly cited the second half of 2026 as Apple’s target.Some reports still claim the project could slip into 2027 if Apple runs into manufacturing or durability issues, particularly around the hinge or display. Given Apple’s history of delaying products that it feels aren’t ready, that remains a real possibility.What will the iPhone Fold look like?Current consensus suggests Apple has settled on a book-style foldable design, similar to Samsung’s Galaxy Z Fold series, rather than a clamshell flip phone.When unfolded, the iPhone Fold is expected to resemble a small tablet like the iPad mini (8.3 inches). Based on the rumor mill, though, the iPhone Fold may be a touch smaller, with an internal display measuring around 7.7 to 7.8 inches. When closed, it should function like a conventional smartphone, with an outer display in the 5.5-inch range.CAD leaks and alleged case-maker molds suggest the device may be shorter and wider than a standard iPhone when folded, creating a squarer footprint that better matches the aspect ratio of the inner display. Several reports have also pointed to the iPhone Air as a potential preview of Apple’s foldable design work, with its unusually thin chassis widely interpreted as a look at what one half of a future foldable iPhone could resemble.If that theory holds, it could help explain the Fold’s rumored dimensions. Thickness is expected to land between roughly 4.5 and 5.6mm when unfolded, putting it in a similar range to the iPhone Air, and just over 9 to 11mm when folded, depending on the final hinge design and internal layering.iPhone 17 Pro, iPhone AirEngadgetDisplay and the crease questionThe display is arguably the biggest challenge for any foldable phone, and it’s an area where Apple appears to have invested years of development.Multiple reports say Apple will rely on Samsung Display as its primary supplier. At CES 2026, Samsung showcased a new crease-less foldable OLED panel, which several sources — including Bloomberg — suggested could be the same technology Apple plans to use.According to these reports, the panel combines a flexible OLED with a laser-drilled metal support plate that disperses stress when folding. The goal is a display with a nearly invisible crease, something Apple reportedly considers essential before entering the foldable market.If Apple does use this panel, it would mark a notable improvement over current foldables, which still show visible creasing under certain lighting conditions.Cameras and biometricsCamera rumors suggest Apple is planning a four-camera setup. That may include:Two rear cameras (main and ultra-wide, both rumored at 48MP)One punch-hole camera on the outer displayOne under-display camera on the inner screenSeveral sources claim Apple will avoid Face ID entirely on the iPhone Fold. Instead, it’s expected to rely on Touch ID built into the power button, similar to recent iPad models. This would allow Apple to keep both displays free of notches or Dynamic Island cutouts.Under-display camera technology has historically produced lower image quality, but a rumored 24MP sensor would be a significant step up compared to existing foldables, which typically use much lower-resolution sensors.iPhone Fold’s hinge and materialsThe hinge is another area where Apple may diverge from competitors. Multiple reports claim Apple will use Liquidmetal, which is a long-standing trade name for a metallic glass alloy the company has previously used in smaller components. While often referred to as “liquid metal” or “Liquid Metal” in reports, Liquidmetal is the branding Apple has historically associated with the material.Liquidmetal is said to be stronger and more resistant to deformation than titanium, while remaining relatively lightweight. If accurate, this could help improve long-term durability and reduce wear on the foldable display.Leaks from Jon Prosser also reference a metal plate beneath the display that works in tandem with the hinge to minimize creasing — a claim that aligns with reporting from Korean and Chinese supply-chain sources.Battery and other components Battery life is another potential differentiator. According to Ming-Chi Kuo and multiple Asian supply-chain reports, Apple is testing high-density battery cells in the 5,000 to 5,800mAh range.That would make it the largest battery ever used in an iPhone, and competitive with (or larger than) batteries in current Android foldables. The device is also expected to use a future A-series chip and Apple’s in-house modem.PriceNone of this will come cheap, that’s for certain. Nearly every report agrees that the iPhone Fold will be Apple’s most expensive iPhone ever.Estimates currently place the price between $2,000 and $2,500 in the US. Bloomberg has said the price will be “at least $2,000,” while other analysts have narrowed the likely range to around $2,100 and $2,300. That positions the iPhone Fold well above the iPhone Pro Max and closer to Apple’s high-end Macs and iPads.Despite years of rumors, there’s still plenty that remains unclear. Apple hasn’t confirmed the name “iPhone Fold,” final dimensions, software features or how iOS would adapt to a folding form factor. Durability, repairability and long-term reliability are also open questions. For now, the safest assumption is that Apple is taking its time and that many of these details could still change before launch. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/iphone-fold-rumors-everything-we-know-so-far-including-the-leaked-design-130000516.html?src=rss",
          "feed_position": 25,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-09/a476c2e0-9780-11f0-bd4b-d87caa240702"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/sony-a7-v-review-awesome-speed-and-photo-quality-130000592.html",
          "published_at": "Fri, 30 Jan 2026 13:00:00 +0000",
          "title": "Sony A7 V review: Awesome speed and photo quality",
          "standfirst": "Sony A7 series camera launches are eagerly anticipated by camera lovers, as those models are typically a showcase for the company’s latest imaging tech. The new A7 V is a great example of that: it’s equipped with Sony's new 33-megapixel partially-stacked sensor — the most advanced in any midrange full-frame mirrorless model. The A7 V’s resolution is higher than rivals like Panasonic’s S1 II and the Nikon Z6 III in this category while matching Canon’s R6 III. However, Sony trumps the latter with a faster sensor that promises lower rolling shutter distortion in electronic mode. Sony also boasts that it offers the highest dynamic range of any of its cameras to date. Unlike Canon with the R6 III, Sony didn’t bend over backwards to accommodate creators, though. Video resolution is limited to 4K, and the A7 V lacks any RAW video capability, compared to 7K and RAW for Canon’s latest model. All of that means the A7 V may be great for some buyers, but fall short for others. Design and handling Like other recent Sony cameras, I didn’t find the A7 V comfortable to hold for long periods of time. That’s because the grip, while deep, is a bit short and too small for large hands. At the same time, it has harder exterior materials than Canon’s cameras and is a bit heavier than the A7 IV at 1.53 pounds (698 grams) compared to 1.45 pounds (653 grams) for its predecessor. The handling makes up for the lack of comfort, though. It has two dials for the primary controls (shutter speed and aperture), along with a third for exposure compensation. There’s a dual dial with a shooting mode on top and video/photo/S&Q below, plus a rear joystick, rear dial and nine buttons. The main controls fell nicely to my hands, which made camera control a cinch. The A7 V has the same well-organized menu system as other recent Sony models and it's easy to customize dials, buttons and quick menus to your liking. Overall, Sony’s menus are now among the best, and functions are easier to access than on Canon’s R6 III, for example. The 3.69-million dot EVF display is relatively sharp and on par with the R6 III, but falls short of 5.76-million-dot EVF on the significantly cheaper Nikon Z6 III. The 3.2-inch rear display fully articulates as before, but it also tilts now, so I was able to easily shoot from high and low angles. It’s also slightly bigger and has 2.1 million dots, up from 1.65 million dots on the A7 IV. The A7 V has a dual-slot card system with two SD UHS II slots and a faster CFexpress Type A slot. However, Type A CFexpress cards are less than half as fast as the CFexpress B cards used in other cameras. The A7 V includes a full-sized HDMI port for external display, 3.5mm mic and headphone ports, and two USB-C ports — one for charging and one for 10Gbps data transfers. Battery life is decent with up to 630 shots on a charge or 100 minutes of continuous 4K 30 fps capture. The camera isn’t constrained much by temperature limits, as I was able to shoot 4K 30p video for 90 minutes straight with no issues. Performance The 33MP partially-stacked sensor has made a big difference in the A7 V’s speed and autofocus accuracy. It can now hit 30 fps blackout-free RAW burst speeds with the electronic shutter (with autofocus and auto exposure enabled), compared to an anemic 10 fps with the A7 IV. That makes it a surprisingly good choice for sports and wildlife photography, or just shooting fast-moving kids or pets. Speeds drop to 10 fps in mechanical shutter mode, which is on par for this category. ISO 6400, f/2.8, 1/40th Steve Dent for Engadget Rolling shutter distortion is only an issue when shooting super fast subjects like airplane propellers or golf swings. And unlike Canon’s R6 III and other rivals, the A7 V maintains full 14-bit RAW quality during electronic shutter bursts instead of dropping to 12-bit RAW, which allows for higher dynamic range. As you’d expect with Sony, autofocus is fast and extremely accurate, delivering the best in-focus hit rate of any camera in this price range. When tracking moving subjects like bikes, birds or kids, I rarely saw a blurry shot. This applied even in tricky lighting and chaotic situations with multiple subjects. The A7 V also nailed auto exposure and auto white balance, even when I shot at dusk with a mix of indoor and outdoor lighting. Sony’s latest AI features make it easy to track nearly anything. Face, eye and body tracking are supported for people, and you can also follow animals, birds, insects, cars, trains and airplanes. The AI has been trained to track people in any position, even if they’re partially obscured or disappear in the frame. This proved to be convenient when I shot street photos in crowds with a specific subject in mind. This does bring up one sore point with the A7 V. When using third-party lenses, the burst rate speeds drop from 30 fps to 15 fps. In addition, you may not be able to use some lenses at all in AF-C (continuous) mode without applying a firmware update. In-body stabilization is improved significantly over the A7 IV from 5.5 to 7.5 stops with compatible lenses, but falls short of all rivals that hit at least eight stops. Still, I was comfortably able to shoot at shutter speeds as low as a half second handheld without any camera blur. Image quality Photo quality is where the A7 V shines. Dynamic range is superior to rival cameras, both in the real world and specialized testing. This is due to Sony’s latest dual gain output tech that combines two ISO levels at once integrated with the new 33MP partially-stacked sensor (when using the mechanical shutter). I noticed this when taking photos at twilight in several of Paris’ squares. After shooting a statue against a bright sky, I was able to extract noise-free shadow detail from RAW files and easily adjust bright areas. When shooting ducks in water that reflected a bright sky, I saw similarly high levels of detail in both dark and bright picture areas. There is one thing to keep in mind, though: As Photons to Photos noted, there’s a slight drop in dynamic range below ISO 1,000 when using the electronic shutter. Should you need even more detail and dynamic range, Sony’s new Composite RAW feature that’s borrowed from the A9 III combines four, eight, 16, or 32 RAW images to reduce noise and improve image quality. I used it to photograph some high-contrast scenes on a sunny Paris day and it dramatically reduced noise, but isn’t a good option for moving subjects. Sony's A7 V has plenty of manual controls for easy operation Steve Dent for Engadget JPEGs look great straight out of the camera with excellent detail, though noise reduction can be a bit excessive at high ISOs. Sony’s color science has improved over the last model, so colors are accurate and the magenta-hue issues seem to be largely resolved. However,I still find Canon’s cameras capture more accurate skin tones. The A7 V is a low-light marvel, with relatively noise-free photos all the way up to ISO 12,800 and usable shots at ISO 25,600. What’s remarkable is that the A7 V beats all its 24MP rivals in this regard, despite the nearly 50 percent higher resolution. Sony added a new “Compressed RAW HQ” mode with the A7 V, designed to deliver better compressed RAW quality while keeping files smaller than “Lossless RAW.” Note that this new mode is not currently supported by Adobe Lightroom, so I’d avoid using it for now. Video Sony's A7 V can take sharp video but doesn't stand up against rivals. Sony Two or three years ago, the A7 V would have been fine for video but not in 2026. While all its rivals are embracing internal RAW video at 6K or 7K, Sony is sticking with 10-bit 4K MP4 at up to 60 fps, or 4K 120 with an APS-C crop. The video is oversampled from a 7K sensor size so it’s very sharp though, and S-Log3 is available to boost dynamic range. Sony likely thinks that creators using this camera will mostly shoot 4K MP4 (as I do), so it didn’t feel that RAW was a must. However, users who do need the benefits of RAW — like minimal degradation when editing, flexible white balance and improved dynamic range — can’t even do external RAW capture. The 4K max resolution and lack of open gate 3:2 is also a downside for creators who like to reframe shots in post or output to social media. With that all said, you can capture high-quality 10-bit 4K 60 fps video with the A7 V. The S-Log3 Cine/S-Log 3 option and high data rate 4:2:2 HS video provide flexibility in post, letting you easily correct over- or under-exposed video or tweak colors. As with photos, color accuracy is nearly on par with Panasonic and other rivals. Shooting in low-light is a breeze, especially when you know that noise levels will be minimal even at high ISO speeds. Sony has some extra video tricks like focus breathing compensation that eliminates zooming when focusing from a near to a far subject. And the A7 V comes with a new AI Auto Framing mode, which recognizes and crops in on humans, keeping them centered in the frame. I was able to keep subjects centered (while stabilizing the shot) as long as I didn’t move the camera excessively. Autofocus is just as excellent for video as photos, with the same level of speed and accuracy. AI-powered autofocus supports all the same modes (people, animals, etc.) and usually nails focus of human or animal eyes, like when I captured footage of some ducks and dogs. Video stabilization is also very good, just behind Panasonic’s S1 II and ahead of the Canon R6 III. In regular optical-only mode, it removes shaking from handheld video without too much movement. When you engage the “Active” mode, it adds electronic stabilization with a small crop for panning or tilting, and “Dynamic Active” lets you walk with surprisingly smooth results. Rolling shutter is rarely an issue for most types of shooting, including walking, unless you really whip the camera around. The lack of rolling shutter skew also makes it easier to apply stabilization in post with Adobe Premiere or DaVinci Resolve. Wrap-up ISO 800, f/2.8, 1/500th Steve Dent for Engadget The A7 V is an incredible camera for photography, with speeds, autofocus accuracy and image quality ahead of rivals, including the Canon R6 III, Panasonic S1 II and Nikon Z6 III.However, Sony isn’t keeping up with those models for video. The A7 V is missing RAW, native resolution and open gate capture, all of which can be found on the aforementioned cameras. That makes it hard to recommend for serious video users or creators who use full-frame open gate to export high-quality vertical video. There’s one intangible, though. I enjoyed taking pictures with the A7 V more than other cameras I’ve tested lately because of the AF accuracy and image results. For anyone who wants a fast, reliable and easy-to-use camera for photography, I can’t recommend it enough. For video creators, though, I’d look at Canon’s R6 III, the Panasonic S1 II, or if you’re on a budget, Nikon’s Z6 III. This article originally appeared on Engadget at https://www.engadget.com/cameras/sony-a7-v-review-awesome-speed-and-photo-quality-130000592.html?src=rss",
          "content": "Sony A7 series camera launches are eagerly anticipated by camera lovers, as those models are typically a showcase for the company’s latest imaging tech. The new A7 V is a great example of that: it’s equipped with Sony's new 33-megapixel partially-stacked sensor — the most advanced in any midrange full-frame mirrorless model. The A7 V’s resolution is higher than rivals like Panasonic’s S1 II and the Nikon Z6 III in this category while matching Canon’s R6 III. However, Sony trumps the latter with a faster sensor that promises lower rolling shutter distortion in electronic mode. Sony also boasts that it offers the highest dynamic range of any of its cameras to date. Unlike Canon with the R6 III, Sony didn’t bend over backwards to accommodate creators, though. Video resolution is limited to 4K, and the A7 V lacks any RAW video capability, compared to 7K and RAW for Canon’s latest model. All of that means the A7 V may be great for some buyers, but fall short for others. Design and handling Like other recent Sony cameras, I didn’t find the A7 V comfortable to hold for long periods of time. That’s because the grip, while deep, is a bit short and too small for large hands. At the same time, it has harder exterior materials than Canon’s cameras and is a bit heavier than the A7 IV at 1.53 pounds (698 grams) compared to 1.45 pounds (653 grams) for its predecessor. The handling makes up for the lack of comfort, though. It has two dials for the primary controls (shutter speed and aperture), along with a third for exposure compensation. There’s a dual dial with a shooting mode on top and video/photo/S&Q below, plus a rear joystick, rear dial and nine buttons. The main controls fell nicely to my hands, which made camera control a cinch. The A7 V has the same well-organized menu system as other recent Sony models and it's easy to customize dials, buttons and quick menus to your liking. Overall, Sony’s menus are now among the best, and functions are easier to access than on Canon’s R6 III, for example. The 3.69-million dot EVF display is relatively sharp and on par with the R6 III, but falls short of 5.76-million-dot EVF on the significantly cheaper Nikon Z6 III. The 3.2-inch rear display fully articulates as before, but it also tilts now, so I was able to easily shoot from high and low angles. It’s also slightly bigger and has 2.1 million dots, up from 1.65 million dots on the A7 IV. The A7 V has a dual-slot card system with two SD UHS II slots and a faster CFexpress Type A slot. However, Type A CFexpress cards are less than half as fast as the CFexpress B cards used in other cameras. The A7 V includes a full-sized HDMI port for external display, 3.5mm mic and headphone ports, and two USB-C ports — one for charging and one for 10Gbps data transfers. Battery life is decent with up to 630 shots on a charge or 100 minutes of continuous 4K 30 fps capture. The camera isn’t constrained much by temperature limits, as I was able to shoot 4K 30p video for 90 minutes straight with no issues. Performance The 33MP partially-stacked sensor has made a big difference in the A7 V’s speed and autofocus accuracy. It can now hit 30 fps blackout-free RAW burst speeds with the electronic shutter (with autofocus and auto exposure enabled), compared to an anemic 10 fps with the A7 IV. That makes it a surprisingly good choice for sports and wildlife photography, or just shooting fast-moving kids or pets. Speeds drop to 10 fps in mechanical shutter mode, which is on par for this category. ISO 6400, f/2.8, 1/40th Steve Dent for Engadget Rolling shutter distortion is only an issue when shooting super fast subjects like airplane propellers or golf swings. And unlike Canon’s R6 III and other rivals, the A7 V maintains full 14-bit RAW quality during electronic shutter bursts instead of dropping to 12-bit RAW, which allows for higher dynamic range. As you’d expect with Sony, autofocus is fast and extremely accurate, delivering the best in-focus hit rate of any camera in this price range. When tracking moving subjects like bikes, birds or kids, I rarely saw a blurry shot. This applied even in tricky lighting and chaotic situations with multiple subjects. The A7 V also nailed auto exposure and auto white balance, even when I shot at dusk with a mix of indoor and outdoor lighting. Sony’s latest AI features make it easy to track nearly anything. Face, eye and body tracking are supported for people, and you can also follow animals, birds, insects, cars, trains and airplanes. The AI has been trained to track people in any position, even if they’re partially obscured or disappear in the frame. This proved to be convenient when I shot street photos in crowds with a specific subject in mind. This does bring up one sore point with the A7 V. When using third-party lenses, the burst rate speeds drop from 30 fps to 15 fps. In addition, you may not be able to use some lenses at all in AF-C (continuous) mode without applying a firmware update. In-body stabilization is improved significantly over the A7 IV from 5.5 to 7.5 stops with compatible lenses, but falls short of all rivals that hit at least eight stops. Still, I was comfortably able to shoot at shutter speeds as low as a half second handheld without any camera blur. Image quality Photo quality is where the A7 V shines. Dynamic range is superior to rival cameras, both in the real world and specialized testing. This is due to Sony’s latest dual gain output tech that combines two ISO levels at once integrated with the new 33MP partially-stacked sensor (when using the mechanical shutter). I noticed this when taking photos at twilight in several of Paris’ squares. After shooting a statue against a bright sky, I was able to extract noise-free shadow detail from RAW files and easily adjust bright areas. When shooting ducks in water that reflected a bright sky, I saw similarly high levels of detail in both dark and bright picture areas. There is one thing to keep in mind, though: As Photons to Photos noted, there’s a slight drop in dynamic range below ISO 1,000 when using the electronic shutter. Should you need even more detail and dynamic range, Sony’s new Composite RAW feature that’s borrowed from the A9 III combines four, eight, 16, or 32 RAW images to reduce noise and improve image quality. I used it to photograph some high-contrast scenes on a sunny Paris day and it dramatically reduced noise, but isn’t a good option for moving subjects. Sony's A7 V has plenty of manual controls for easy operation Steve Dent for Engadget JPEGs look great straight out of the camera with excellent detail, though noise reduction can be a bit excessive at high ISOs. Sony’s color science has improved over the last model, so colors are accurate and the magenta-hue issues seem to be largely resolved. However,I still find Canon’s cameras capture more accurate skin tones. The A7 V is a low-light marvel, with relatively noise-free photos all the way up to ISO 12,800 and usable shots at ISO 25,600. What’s remarkable is that the A7 V beats all its 24MP rivals in this regard, despite the nearly 50 percent higher resolution. Sony added a new “Compressed RAW HQ” mode with the A7 V, designed to deliver better compressed RAW quality while keeping files smaller than “Lossless RAW.” Note that this new mode is not currently supported by Adobe Lightroom, so I’d avoid using it for now. Video Sony's A7 V can take sharp video but doesn't stand up against rivals. Sony Two or three years ago, the A7 V would have been fine for video but not in 2026. While all its rivals are embracing internal RAW video at 6K or 7K, Sony is sticking with 10-bit 4K MP4 at up to 60 fps, or 4K 120 with an APS-C crop. The video is oversampled from a 7K sensor size so it’s very sharp though, and S-Log3 is available to boost dynamic range. Sony likely thinks that creators using this camera will mostly shoot 4K MP4 (as I do), so it didn’t feel that RAW was a must. However, users who do need the benefits of RAW — like minimal degradation when editing, flexible white balance and improved dynamic range — can’t even do external RAW capture. The 4K max resolution and lack of open gate 3:2 is also a downside for creators who like to reframe shots in post or output to social media. With that all said, you can capture high-quality 10-bit 4K 60 fps video with the A7 V. The S-Log3 Cine/S-Log 3 option and high data rate 4:2:2 HS video provide flexibility in post, letting you easily correct over- or under-exposed video or tweak colors. As with photos, color accuracy is nearly on par with Panasonic and other rivals. Shooting in low-light is a breeze, especially when you know that noise levels will be minimal even at high ISO speeds. Sony has some extra video tricks like focus breathing compensation that eliminates zooming when focusing from a near to a far subject. And the A7 V comes with a new AI Auto Framing mode, which recognizes and crops in on humans, keeping them centered in the frame. I was able to keep subjects centered (while stabilizing the shot) as long as I didn’t move the camera excessively. Autofocus is just as excellent for video as photos, with the same level of speed and accuracy. AI-powered autofocus supports all the same modes (people, animals, etc.) and usually nails focus of human or animal eyes, like when I captured footage of some ducks and dogs. Video stabilization is also very good, just behind Panasonic’s S1 II and ahead of the Canon R6 III. In regular optical-only mode, it removes shaking from handheld video without too much movement. When you engage the “Active” mode, it adds electronic stabilization with a small crop for panning or tilting, and “Dynamic Active” lets you walk with surprisingly smooth results. Rolling shutter is rarely an issue for most types of shooting, including walking, unless you really whip the camera around. The lack of rolling shutter skew also makes it easier to apply stabilization in post with Adobe Premiere or DaVinci Resolve. Wrap-up ISO 800, f/2.8, 1/500th Steve Dent for Engadget The A7 V is an incredible camera for photography, with speeds, autofocus accuracy and image quality ahead of rivals, including the Canon R6 III, Panasonic S1 II and Nikon Z6 III.However, Sony isn’t keeping up with those models for video. The A7 V is missing RAW, native resolution and open gate capture, all of which can be found on the aforementioned cameras. That makes it hard to recommend for serious video users or creators who use full-frame open gate to export high-quality vertical video. There’s one intangible, though. I enjoyed taking pictures with the A7 V more than other cameras I’ve tested lately because of the AF accuracy and image results. For anyone who wants a fast, reliable and easy-to-use camera for photography, I can’t recommend it enough. For video creators, though, I’d look at Canon’s R6 III, the Panasonic S1 II, or if you’re on a budget, Nikon’s Z6 III. This article originally appeared on Engadget at https://www.engadget.com/cameras/sony-a7-v-review-awesome-speed-and-photo-quality-130000592.html?src=rss",
          "feed_position": 26,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/03a-sony-a7-v-06891.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-power-bank-143048526.html",
          "published_at": "Fri, 30 Jan 2026 10:01:26 +0000",
          "title": "The best power banks and portable chargers for every device in 2026",
          "standfirst": "To find the best power bank out there, I tested more than 60 portable chargers and batteries from big brands like Anker, Belkin, UGreen and Mophie — as well as from smaller players such as Biolite, Nimble and Satechi. I tested the batteries on a number of devices including iPhones, Galaxy phones, an iPad, a MacBook and even my ereader and a PlayStation controller. If you just want a brick that can charge anything, go for Anker’s 25kmAh Laptop Power bank. It has two built-in USB-C cables, a massive capacity and super fast charging speeds. But if that’s not quite what you’re looking for, you can check out our other picks for the best power banks below. Best power banks for 2026 What to look for in a portable battery pack Battery type Nearly every rechargeable power bank you can buy (and most portable devices) contain a lithium-ion battery. These beat other current battery types in terms of size-to-charge capacity, and have even increased in energy density by eight fold in the past 14 years. They also don’t suffer from a memory effect (where a battery's lifespan deteriorates due to partial charges). Flying with portable batteries You may have heard about lithium ion batteries overheating and catching fire — a recent Hong Kong flight was grounded after just such a thing happened in an overhead bin. Current restrictions implemented by the TSA still allow external batteries rated at 100Wh or less (which all of our recommendations are) to fly with you, but only in your carry-on luggage — they can’t be checked. Recently, Southwest Airlines was the first in the industry to take that rule one step further. Now, flyers on that airline must keep power banks in clear view when using them to recharge a device. If the portable charger isn’t actively in use, however, it can stay in your carry-on bag in the overhead bin. Capacity Power bank manufacturers almost always list a battery’s capacity in milliamp hours, or mAh. Smaller batteries with a 5,000mAh capacity make good phone chargers and can fill a smartphone to between 50 and 75 percent. Larger batteries that can recharge laptops and tablets, or give phones multiple charges, can exceed 25,000mAh and we have a separate guide that covers that entire category. Unsurprisingly, the prices on most batteries goes up as mAh capacity increases, and since batteries are physical storage units, size and weight go up with capacity as well. If you want more power, be prepared to spend more and carry around a heavier brick. You might think that a 10,000mAh power bank could charge a 5,000mAh phone to 100 percent twice, but that’s not the case. In addition to simple energy loss through heat dissipation, factors like voltage conversion also bring down the amount of juice that makes it into your phone. Most manufacturers list how many charges a battery can give a certain smartphone. In our tests, 10,000mAh of battery pack capacity translated to roughly 5,800mAh of device charge. 20,000mAh chargers delivered around 11,250mAh to a device, and 25,000mAh banks translated to about 16,200mAh of charge. That’s an average efficiency rate of around 60 percent. Wireless Wireless charging, whether through a bank or a plugged-in charging pad, is less efficient than wired connections. But it is convenient — and in most cases, you can carry around and use your phone as it refills with a magnetically attached power bank. Power banks with wireless charging are far better than they once were. Just a couple years ago, the ones I tested were too inefficient to recommend in this guide. When batteries adhering to the Qi2 wireless charging standard started arriving in 2023, performance markedly improved. To gain Qi2-certification, a device has to support speeds of up to 15 watts and include magnetic attachment points. The MagSafe technology on iPhones were once the only handsets that were Qi2-compatible, but now Google’s Pixelsnap tech brings both the higher speed and magnetic grip to Pixel 10 phones. Samsung may follow up with its own version in future releases. The latest wireless charging standard, Q12 25W, is supported by the new iPhone 17 phones as well as the Google Pixel 10 Pro XL. Battery packs that are Qi2 25W-enabled are starting to hit the market as well, and the Ugreen MagFlow was the first on the scene. Ports USB-C ports can deliver faster charges than USB-A ports, and most of the portable chargers we recommend here have Type-C connections. But Type-A jacks are still handy if you need to use a specialized cable for a certain device (my camera’s USB-A to micro USB cable comes to mind). There’s also variation among USB-C ports. Larger banks with more than one port will sometimes list different wattages for each. For example, a bank with three ports may have two 65W ports and one 100W port. There will also be at least one in/out port on the bank, which can be used to charge the battery itself or to deliver a charge to your device. Wattages and in/out labels are printed right next to the port — and always in the tiniest font possible (remember, your phone is an excellent magnifying glass if you ever have trouble reading them). As with standard wall chargers, the port’s wattage will determine what you can charge. A phone will happily charge off a 100W connection, but a 15W plug won’t do much for your laptop. And remember, the cable has to match the maximum wattage. A cable rated for 60W won’t deliver 100W speeds. Luckily, some of the best power banks include a built-in USB-C cable. That’ll not only ensure you have the right cord, it’s one less thing you have to remember to bring along. Design Once, most rechargeable batteries were black with a squared-off, brick-like design, but now they come in different colors and shapes with attractive finishes and detailing. While that doesn’t affect how they perform, it’s a consideration for something you’ll interact with regularly. Some portable power banks include extra features like MagSafe compatibility, a built-in wall plug or even a kickstand. Nearly all have some sort of indicator to let you know how much available charge your power bank has left, usually expressed with lighted pips near the power button. Some of the newer banks take that a step further with an LED display indicating remaining battery percentage. How we test best power banks First, I considered brands Engadget reviewers and staff have tried over the years and checked out customer ratings on retail sites like Amazon and Best Buy. Then, I acquired the most promising candidates and tested them in my home office. Amy Skorheim for Engadget For testing, I used each battery to charge both an iPhone and an Android phone, as well as an iPad and a MacBook Pro for the larger portable chargers. I let the devices get down to between zero and five percent and charged them until the devices were full or the power bank died. For reference, here are the battery capacities of the device I've used for testing over the years: iPhone 11: 3,110 mAh iPhone 14 Plus: 4,325 mAh iPhone 15: 3,349 mAh iPhone 16: 3,561* Galaxy S22 Ultra: 4,855mAh iPad Air: 7,729mAh 16-inch M1 Pro MacBook Pro: 27,027mAh *The iPhone 17 has a slightly larger battery at 3,692mAh I continuously update this guide as companies release new products. Other power banks we tested Here are a few picks that didn't quite make the cut, but are worth mentioning. Belkin Stage PowerGrip If you’re into iPhonography, this clever accessory could be worth a look. Belkin’s Stage PowerGrip is a 9,300mAh power bank that has both a wireless charging pad and built-in cable. But it’s also a Bluetooth shutter with a quarter-inch tripod thread. The design resembles a standard digital camera and provides a sturdy grip once you magnetically attach your phone (make sure you’re either using a MagSafe case or no case to ensure a solid connection). The shutter is conveniently placed and the remote speed was quick enough to capture the cute things my cat was doing. The accessory can even act as a stand while it charges in either landscape or portrait orientation. As a power bank, it’s slow, taking about two hours to get my iPhone 16 from three to 98 percent, but it has enough juice for a full refill plus a little more, which could help if you’re out taking pictures all day. Anker MagGo for Apple Watch power bank The Anker MagGo for Apple Watch power bank combines a 10K battery with a built-in USB-C cable and a pop-up Apple Watch charger. I didn’t formally test it as it’s a little too niche, but it deserves a mention for saving my keister on two occasions. Driving to a hike, my watch told me it was down to 10 percent. Thankfully, I had this and could refill the watch before I got to the trailhead. Later, on an interstate trip, I realized the travel charging station I’d brought was a dud. This kept my watch alive for the week I was away. It does a good job simply charging a phone via the handy on-board cable, too. But for those with an Apple Watch, it’s extra useful. HyperJuice 245W Hyper’s massive-but-sleek brick is one nice looking power bank. The HyperJuice 245W packs a hefty 27,000mAh capacity, enough to refill my tester phone about four times and get a MacBook Pro from near-dead to 75 percent. It only has USB-C ports, but you at least get four of them. USB-C only is probably fine for most situations, but a USB-A port would be nice for charging the occasional older peripheral. The 245 wattage is pretty high for a power bank and it was indeed speedy. It filled a Samsung Galaxy S24 Ultra in just over an hour. But it’s the same price and capacity as our Mophie Powerstation pick for laptop banks, and that one has a better variety of ports. Hyper’s battery is also comparable to Anker’s laptop battery, which is cheaper, has built-in cables and has nearly the same capacity. Plus, that bank is just as swanky looking. EcoFlow Rapid magnetic power bank I was curious to try out the first power bank from EcoFlow, a company that primarily makes larger power stations and whole-home backup batteries. The first offering in the brand’s Rapid series is a Qi2-enabled magnetic charger with a 5,000mAh capacity. It looks quite nice with shiny silver accents and soft-touch grey plastic on the MagSafe-compatible front. There’s a little pull-out leg that sturdily displays your phone as it charges and the attached USB-C cable lets you refill devices directly, then tucks out of the way when it’s not in use. But it didn’t outperform our top pick in the MagSafe category, in terms of both charging speeds and the amount of charge delivered. Mophie Snap+ Powerstation Mini The Mophie snap+ Powerstation Mini is terribly well-built. It feels premium with a rubberized contact point for the MagSafe charging pad and a stand that runs the entire width of the bank itself, making it extra sturdy. It’s compact, too, but only carries a 5,000mAh capacity, which gets you a partial charge on most newer or larger phones. Our current MagSafe/iPhone pick has double the capacity, a stand and a digital display — for just $20 more than the Powerstation Mini. Power bank FAQs What's the difference between a portable power bank and a portable charger? A slew of terms are used to describe power banks, including portable batteries, portable chargers, external battery packs and even, somewhat confusingly, USB chargers, which is what wall chargers are often called. They all mean the same thing: a lithium ion battery that stores a charge so you can refill a smartphone, tablet, earbuds, console controller, ereader, laptop, or just about any other device with its own built-in, rechargeable battery. There’s little difference between the terms, so the specs you’ll want to pay attention to are capacity (expressed in mAh), size and weight so you can find the right balance between recharging what you need and portability. Power stations, on the other hand, are distinct. These are bigger units (often around the size of a car battery) that can be used to charge multiple devices multiple times, but notably, they can’t be taken on airplanes. Does fast charging actually ruin your battery? Not exactly. The real enemy of a battery’s longevity is heat. The faster you charge a battery, the more heat is generated. Modern phones have features that keep the battery cool while charging, like physical heat shields and heat sinks, as well as software features that slow down processes that generate too much heat. Phone manufacturers are keen to promote a phone’s fast-charging abilities, so they had to figure out ways to make faster charging work. While there aren’t long-term studies on what fast charging does to a phone, a study on EV batteries (which use the same general concept of charged lithium ions flowing from one side of the battery to the other, absorbing or releasing a usable charge) showed a very slight decrease in capacity over time with only fast charging — though what actually made a larger difference was how hot the battery itself was, due to ambient temperatures, when it was charged. In short, fast charging could be slightly harder on your battery than normal charging. But the safeguards most smartphones have make that difference fairly negligible. To really ensure you’re optimizing charging capabilities, limit your phone's heat exposure overall. Can you use a power bank for all your devices? That depends on the size of the bank and the size of your device’s battery. A small 5,000mAh battery isn’t strong enough to charge laptops, but a portable charger with a 20,000mAh capacity will give your computer a partial refill. You also have to consider port compatibility. If your device has a USB port, you’ll be able to easily find a cable to connect it to a battery. If your device has a more unique port, such as a DC port, you won’t be able to use a battery. Devices with an AC cable and plug can be charged, and sometimes powered (such as in the case of a printer or speaker), by larger laptop batteries with AC ports.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-power-bank-143048526.html?src=rss",
          "content": "To find the best power bank out there, I tested more than 60 portable chargers and batteries from big brands like Anker, Belkin, UGreen and Mophie — as well as from smaller players such as Biolite, Nimble and Satechi. I tested the batteries on a number of devices including iPhones, Galaxy phones, an iPad, a MacBook and even my ereader and a PlayStation controller. If you just want a brick that can charge anything, go for Anker’s 25kmAh Laptop Power bank. It has two built-in USB-C cables, a massive capacity and super fast charging speeds. But if that’s not quite what you’re looking for, you can check out our other picks for the best power banks below. Best power banks for 2026 What to look for in a portable battery pack Battery type Nearly every rechargeable power bank you can buy (and most portable devices) contain a lithium-ion battery. These beat other current battery types in terms of size-to-charge capacity, and have even increased in energy density by eight fold in the past 14 years. They also don’t suffer from a memory effect (where a battery's lifespan deteriorates due to partial charges). Flying with portable batteries You may have heard about lithium ion batteries overheating and catching fire — a recent Hong Kong flight was grounded after just such a thing happened in an overhead bin. Current restrictions implemented by the TSA still allow external batteries rated at 100Wh or less (which all of our recommendations are) to fly with you, but only in your carry-on luggage — they can’t be checked. Recently, Southwest Airlines was the first in the industry to take that rule one step further. Now, flyers on that airline must keep power banks in clear view when using them to recharge a device. If the portable charger isn’t actively in use, however, it can stay in your carry-on bag in the overhead bin. Capacity Power bank manufacturers almost always list a battery’s capacity in milliamp hours, or mAh. Smaller batteries with a 5,000mAh capacity make good phone chargers and can fill a smartphone to between 50 and 75 percent. Larger batteries that can recharge laptops and tablets, or give phones multiple charges, can exceed 25,000mAh and we have a separate guide that covers that entire category. Unsurprisingly, the prices on most batteries goes up as mAh capacity increases, and since batteries are physical storage units, size and weight go up with capacity as well. If you want more power, be prepared to spend more and carry around a heavier brick. You might think that a 10,000mAh power bank could charge a 5,000mAh phone to 100 percent twice, but that’s not the case. In addition to simple energy loss through heat dissipation, factors like voltage conversion also bring down the amount of juice that makes it into your phone. Most manufacturers list how many charges a battery can give a certain smartphone. In our tests, 10,000mAh of battery pack capacity translated to roughly 5,800mAh of device charge. 20,000mAh chargers delivered around 11,250mAh to a device, and 25,000mAh banks translated to about 16,200mAh of charge. That’s an average efficiency rate of around 60 percent. Wireless Wireless charging, whether through a bank or a plugged-in charging pad, is less efficient than wired connections. But it is convenient — and in most cases, you can carry around and use your phone as it refills with a magnetically attached power bank. Power banks with wireless charging are far better than they once were. Just a couple years ago, the ones I tested were too inefficient to recommend in this guide. When batteries adhering to the Qi2 wireless charging standard started arriving in 2023, performance markedly improved. To gain Qi2-certification, a device has to support speeds of up to 15 watts and include magnetic attachment points. The MagSafe technology on iPhones were once the only handsets that were Qi2-compatible, but now Google’s Pixelsnap tech brings both the higher speed and magnetic grip to Pixel 10 phones. Samsung may follow up with its own version in future releases. The latest wireless charging standard, Q12 25W, is supported by the new iPhone 17 phones as well as the Google Pixel 10 Pro XL. Battery packs that are Qi2 25W-enabled are starting to hit the market as well, and the Ugreen MagFlow was the first on the scene. Ports USB-C ports can deliver faster charges than USB-A ports, and most of the portable chargers we recommend here have Type-C connections. But Type-A jacks are still handy if you need to use a specialized cable for a certain device (my camera’s USB-A to micro USB cable comes to mind). There’s also variation among USB-C ports. Larger banks with more than one port will sometimes list different wattages for each. For example, a bank with three ports may have two 65W ports and one 100W port. There will also be at least one in/out port on the bank, which can be used to charge the battery itself or to deliver a charge to your device. Wattages and in/out labels are printed right next to the port — and always in the tiniest font possible (remember, your phone is an excellent magnifying glass if you ever have trouble reading them). As with standard wall chargers, the port’s wattage will determine what you can charge. A phone will happily charge off a 100W connection, but a 15W plug won’t do much for your laptop. And remember, the cable has to match the maximum wattage. A cable rated for 60W won’t deliver 100W speeds. Luckily, some of the best power banks include a built-in USB-C cable. That’ll not only ensure you have the right cord, it’s one less thing you have to remember to bring along. Design Once, most rechargeable batteries were black with a squared-off, brick-like design, but now they come in different colors and shapes with attractive finishes and detailing. While that doesn’t affect how they perform, it’s a consideration for something you’ll interact with regularly. Some portable power banks include extra features like MagSafe compatibility, a built-in wall plug or even a kickstand. Nearly all have some sort of indicator to let you know how much available charge your power bank has left, usually expressed with lighted pips near the power button. Some of the newer banks take that a step further with an LED display indicating remaining battery percentage. How we test best power banks First, I considered brands Engadget reviewers and staff have tried over the years and checked out customer ratings on retail sites like Amazon and Best Buy. Then, I acquired the most promising candidates and tested them in my home office. Amy Skorheim for Engadget For testing, I used each battery to charge both an iPhone and an Android phone, as well as an iPad and a MacBook Pro for the larger portable chargers. I let the devices get down to between zero and five percent and charged them until the devices were full or the power bank died. For reference, here are the battery capacities of the device I've used for testing over the years: iPhone 11: 3,110 mAh iPhone 14 Plus: 4,325 mAh iPhone 15: 3,349 mAh iPhone 16: 3,561* Galaxy S22 Ultra: 4,855mAh iPad Air: 7,729mAh 16-inch M1 Pro MacBook Pro: 27,027mAh *The iPhone 17 has a slightly larger battery at 3,692mAh I continuously update this guide as companies release new products. Other power banks we tested Here are a few picks that didn't quite make the cut, but are worth mentioning. Belkin Stage PowerGrip If you’re into iPhonography, this clever accessory could be worth a look. Belkin’s Stage PowerGrip is a 9,300mAh power bank that has both a wireless charging pad and built-in cable. But it’s also a Bluetooth shutter with a quarter-inch tripod thread. The design resembles a standard digital camera and provides a sturdy grip once you magnetically attach your phone (make sure you’re either using a MagSafe case or no case to ensure a solid connection). The shutter is conveniently placed and the remote speed was quick enough to capture the cute things my cat was doing. The accessory can even act as a stand while it charges in either landscape or portrait orientation. As a power bank, it’s slow, taking about two hours to get my iPhone 16 from three to 98 percent, but it has enough juice for a full refill plus a little more, which could help if you’re out taking pictures all day. Anker MagGo for Apple Watch power bank The Anker MagGo for Apple Watch power bank combines a 10K battery with a built-in USB-C cable and a pop-up Apple Watch charger. I didn’t formally test it as it’s a little too niche, but it deserves a mention for saving my keister on two occasions. Driving to a hike, my watch told me it was down to 10 percent. Thankfully, I had this and could refill the watch before I got to the trailhead. Later, on an interstate trip, I realized the travel charging station I’d brought was a dud. This kept my watch alive for the week I was away. It does a good job simply charging a phone via the handy on-board cable, too. But for those with an Apple Watch, it’s extra useful. HyperJuice 245W Hyper’s massive-but-sleek brick is one nice looking power bank. The HyperJuice 245W packs a hefty 27,000mAh capacity, enough to refill my tester phone about four times and get a MacBook Pro from near-dead to 75 percent. It only has USB-C ports, but you at least get four of them. USB-C only is probably fine for most situations, but a USB-A port would be nice for charging the occasional older peripheral. The 245 wattage is pretty high for a power bank and it was indeed speedy. It filled a Samsung Galaxy S24 Ultra in just over an hour. But it’s the same price and capacity as our Mophie Powerstation pick for laptop banks, and that one has a better variety of ports. Hyper’s battery is also comparable to Anker’s laptop battery, which is cheaper, has built-in cables and has nearly the same capacity. Plus, that bank is just as swanky looking. EcoFlow Rapid magnetic power bank I was curious to try out the first power bank from EcoFlow, a company that primarily makes larger power stations and whole-home backup batteries. The first offering in the brand’s Rapid series is a Qi2-enabled magnetic charger with a 5,000mAh capacity. It looks quite nice with shiny silver accents and soft-touch grey plastic on the MagSafe-compatible front. There’s a little pull-out leg that sturdily displays your phone as it charges and the attached USB-C cable lets you refill devices directly, then tucks out of the way when it’s not in use. But it didn’t outperform our top pick in the MagSafe category, in terms of both charging speeds and the amount of charge delivered. Mophie Snap+ Powerstation Mini The Mophie snap+ Powerstation Mini is terribly well-built. It feels premium with a rubberized contact point for the MagSafe charging pad and a stand that runs the entire width of the bank itself, making it extra sturdy. It’s compact, too, but only carries a 5,000mAh capacity, which gets you a partial charge on most newer or larger phones. Our current MagSafe/iPhone pick has double the capacity, a stand and a digital display — for just $20 more than the Powerstation Mini. Power bank FAQs What's the difference between a portable power bank and a portable charger? A slew of terms are used to describe power banks, including portable batteries, portable chargers, external battery packs and even, somewhat confusingly, USB chargers, which is what wall chargers are often called. They all mean the same thing: a lithium ion battery that stores a charge so you can refill a smartphone, tablet, earbuds, console controller, ereader, laptop, or just about any other device with its own built-in, rechargeable battery. There’s little difference between the terms, so the specs you’ll want to pay attention to are capacity (expressed in mAh), size and weight so you can find the right balance between recharging what you need and portability. Power stations, on the other hand, are distinct. These are bigger units (often around the size of a car battery) that can be used to charge multiple devices multiple times, but notably, they can’t be taken on airplanes. Does fast charging actually ruin your battery? Not exactly. The real enemy of a battery’s longevity is heat. The faster you charge a battery, the more heat is generated. Modern phones have features that keep the battery cool while charging, like physical heat shields and heat sinks, as well as software features that slow down processes that generate too much heat. Phone manufacturers are keen to promote a phone’s fast-charging abilities, so they had to figure out ways to make faster charging work. While there aren’t long-term studies on what fast charging does to a phone, a study on EV batteries (which use the same general concept of charged lithium ions flowing from one side of the battery to the other, absorbing or releasing a usable charge) showed a very slight decrease in capacity over time with only fast charging — though what actually made a larger difference was how hot the battery itself was, due to ambient temperatures, when it was charged. In short, fast charging could be slightly harder on your battery than normal charging. But the safeguards most smartphones have make that difference fairly negligible. To really ensure you’re optimizing charging capabilities, limit your phone's heat exposure overall. Can you use a power bank for all your devices? That depends on the size of the bank and the size of your device’s battery. A small 5,000mAh battery isn’t strong enough to charge laptops, but a portable charger with a 20,000mAh capacity will give your computer a partial refill. You also have to consider port compatibility. If your device has a USB port, you’ll be able to easily find a cable to connect it to a battery. If your device has a more unique port, such as a DC port, you won’t be able to use a battery. Devices with an AC cable and plug can be charged, and sometimes powered (such as in the case of a printer or speaker), by larger laptop batteries with AC ports.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-power-bank-143048526.html?src=rss",
          "feed_position": 29,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2024-05/75724c60-0bf6-11ef-bbd1-90ceaffb685f"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/best-budgeting-apps-120036303.html",
          "published_at": "Fri, 30 Jan 2026 08:00:36 +0000",
          "title": "The best budgeting apps for 2026",
          "standfirst": "Managing your finances doesn’t have to be a headache — especially with the right budgeting app at your fingertips. Whether you’re trying to track everyday spending, save for a big purchase or just keep a closer eye on your subscriptions, there’s an app that can help. With Mint shutting down, plenty of users have been looking for the best budget apps to replace it, and luckily there are plenty of solid alternatives.From AI-powered spending trackers to apps that break down your expenses into easy-to-follow categories, the best budgeting tools help you take control of your money without the hassle of spreadsheets. Some focus on automating savings, while others give you a deep dive into your finances with powerful analytics and custom reporting. If you’re still searching for the right Mint alternative, check out our guide to the best budgeting apps to replace Mint to find the best fit for your needs.If you’re not sure where to start, we’ve rounded up the top budgeting apps to help you track spending, save smarter, and stick to your financial goals. Best budget apps of 2026 Other budgeting apps we tested PocketGuard PocketGuard used to be a solid free budget tracker, but the company has since limited its “free” version to just a free seven-day trial. Now, you’ll have to choose between two plans once the trial is over: a $13 monthly plan or a $75 annual plan. When I first tested it, I found it to be more restricted than NerdWallet, but still a decent option. The main overview screen shows you your net worth, total assets and debts; net income and total spending for the month; upcoming bills; a handy reminder of when your next paycheck lands; any debt payoff plan you have; and any goals. Like some other apps, including Quicken Simplifi, PocketGuard promotes an “after bills” approach, where you enter all of your recurring bills, and then PocketGuard shows you what’s left, and that’s what you’re supposed to be budgeting: your disposable income. Although PocketGuard’s UI is easy enough to understand, it lacks polish. The “accounts” tab is a little busy, and doesn’t show totals for categories like cash or investments. Seemingly small details like weirdly phrased or punctuated copy occasionally make the app feel janky. More than once, it prompted me to update the app when no updates were available. The web version, meanwhile, feels like the mobile app blown up to a larger format and doesn’t take advantage of the extra screen real estate. Ultimately, now that the free tier is gone, it just doesn’t present the same value proposition as it once did. How we test budgeting apps Before I dove in and started testing out budgeting apps, I had to do some research. To find a list of apps to try out, I consulted trusty ol’ Google (and even trustier Reddit); read reviews of popular apps on the App Store; and also asked friends and colleagues what budget tracking apps (or other budgeting methods) they might be using for money management. Some of the apps I found were free and these, of course, show loads of ads (excuse me, “offers”) to stay in business. But most of the available apps require paid subscriptions, with prices typically topping out around $100 a year, or $15 a month. (Spoiler: My top pick is cheaper than that.) All of the services I chose to test needed to do several things: import all of your account data into one place; offer budgeting tools; and track your spending, net worth and credit score. Except where noted, all of these apps are available for iOS, Android and on the web. Once I had my shortlist of six apps, I got to work setting them up. For the sake of thoroughly testing these apps, I made a point of adding every account to every budgeting app, no matter how small or immaterial the balance. What ensued was a veritable Groundhog Day of two-factor authentication. Just hours of entering passwords and one-time passcodes, for the same banks half a dozen times over. Hopefully, you only have to do this once. Budgeting app FAQs What is Plaid and how does it work? Each of the apps I tested uses the same underlying network, called Plaid, to pull in financial data, so it’s worth explaining what it is and how it works. Plaid was founded as a fintech startup in 2013 and is today the industry standard in connecting banks with third-party apps. Plaid works with over 12,000 financial institutions across the US, Canada and Europe. Additionally, more than 8,000 third-party apps and services rely on Plaid, the company claims. To be clear, you don’t need a dedicated Plaid app to use it; the technology is baked into a wide array of apps, including all of the budgeting apps listed in this guide. Once you find the “add an account” option in whichever one you’re using, you’ll see a menu of commonly used banks. There’s also a search field you can use to look yours up directly. Once you find yours, you’ll be prompted to enter your login credentials. If you have two-factor authentication set up, you’ll need to enter a one-time passcode as well. As the middleman, Plaid is a passthrough for information that may include your account balances, transaction history, account type and routing or account number. Plaid uses encryption, and says it has a policy of not selling or renting customer data to other companies. However, I would not be doing my job if I didn’t note that in 2022 Plaid was forced to pay $58 million to consumers in a class action suit for collecting “more financial data than was needed.” As part of the settlement, Plaid was compelled to change some of its business practices. In a statement provided to Engadget, a Plaid spokesperson said the company continues to deny the allegations underpinning the lawsuit and that “the crux of the non-financial terms in the settlement are focused on us accelerating workstreams already underway related to giving people more transparency into Plaid’s role in connecting their accounts, and ensuring that our workstreams around data minimization remain on track.” Why did Mint shut down? When parent company Intuit announced in December 2023 that it would shut down Mint, it did not provide a reason why it made the decision to do so. It did say that Mint's millions of users would be funneled over to its other finance app, Credit Karma. \"Credit Karma is thrilled to invite all Minters to continue their financial journey on Credit Karma, where they will have access to Credit Karma’s suite of features, products, tools and services, including some of Mint’s most popular features,\" Mint wrote on its product blog. In our testing, we found that Credit Karma isn't an exact replacement for Mint — so if you're still looking for a Mint alternative, you have some decent options. What about Rocket Money? Rocket Money is another free financial app that tracks spending and supports things like balance alerts and account linking. If you pay for the premium tier, the service can also help you cancel unwanted subscriptions. We did not test it for this guide, but we'll consider it in future updates.This article originally appeared on Engadget at https://www.engadget.com/apps/best-budgeting-apps-120036303.html?src=rss",
          "content": "Managing your finances doesn’t have to be a headache — especially with the right budgeting app at your fingertips. Whether you’re trying to track everyday spending, save for a big purchase or just keep a closer eye on your subscriptions, there’s an app that can help. With Mint shutting down, plenty of users have been looking for the best budget apps to replace it, and luckily there are plenty of solid alternatives.From AI-powered spending trackers to apps that break down your expenses into easy-to-follow categories, the best budgeting tools help you take control of your money without the hassle of spreadsheets. Some focus on automating savings, while others give you a deep dive into your finances with powerful analytics and custom reporting. If you’re still searching for the right Mint alternative, check out our guide to the best budgeting apps to replace Mint to find the best fit for your needs.If you’re not sure where to start, we’ve rounded up the top budgeting apps to help you track spending, save smarter, and stick to your financial goals. Best budget apps of 2026 Other budgeting apps we tested PocketGuard PocketGuard used to be a solid free budget tracker, but the company has since limited its “free” version to just a free seven-day trial. Now, you’ll have to choose between two plans once the trial is over: a $13 monthly plan or a $75 annual plan. When I first tested it, I found it to be more restricted than NerdWallet, but still a decent option. The main overview screen shows you your net worth, total assets and debts; net income and total spending for the month; upcoming bills; a handy reminder of when your next paycheck lands; any debt payoff plan you have; and any goals. Like some other apps, including Quicken Simplifi, PocketGuard promotes an “after bills” approach, where you enter all of your recurring bills, and then PocketGuard shows you what’s left, and that’s what you’re supposed to be budgeting: your disposable income. Although PocketGuard’s UI is easy enough to understand, it lacks polish. The “accounts” tab is a little busy, and doesn’t show totals for categories like cash or investments. Seemingly small details like weirdly phrased or punctuated copy occasionally make the app feel janky. More than once, it prompted me to update the app when no updates were available. The web version, meanwhile, feels like the mobile app blown up to a larger format and doesn’t take advantage of the extra screen real estate. Ultimately, now that the free tier is gone, it just doesn’t present the same value proposition as it once did. How we test budgeting apps Before I dove in and started testing out budgeting apps, I had to do some research. To find a list of apps to try out, I consulted trusty ol’ Google (and even trustier Reddit); read reviews of popular apps on the App Store; and also asked friends and colleagues what budget tracking apps (or other budgeting methods) they might be using for money management. Some of the apps I found were free and these, of course, show loads of ads (excuse me, “offers”) to stay in business. But most of the available apps require paid subscriptions, with prices typically topping out around $100 a year, or $15 a month. (Spoiler: My top pick is cheaper than that.) All of the services I chose to test needed to do several things: import all of your account data into one place; offer budgeting tools; and track your spending, net worth and credit score. Except where noted, all of these apps are available for iOS, Android and on the web. Once I had my shortlist of six apps, I got to work setting them up. For the sake of thoroughly testing these apps, I made a point of adding every account to every budgeting app, no matter how small or immaterial the balance. What ensued was a veritable Groundhog Day of two-factor authentication. Just hours of entering passwords and one-time passcodes, for the same banks half a dozen times over. Hopefully, you only have to do this once. Budgeting app FAQs What is Plaid and how does it work? Each of the apps I tested uses the same underlying network, called Plaid, to pull in financial data, so it’s worth explaining what it is and how it works. Plaid was founded as a fintech startup in 2013 and is today the industry standard in connecting banks with third-party apps. Plaid works with over 12,000 financial institutions across the US, Canada and Europe. Additionally, more than 8,000 third-party apps and services rely on Plaid, the company claims. To be clear, you don’t need a dedicated Plaid app to use it; the technology is baked into a wide array of apps, including all of the budgeting apps listed in this guide. Once you find the “add an account” option in whichever one you’re using, you’ll see a menu of commonly used banks. There’s also a search field you can use to look yours up directly. Once you find yours, you’ll be prompted to enter your login credentials. If you have two-factor authentication set up, you’ll need to enter a one-time passcode as well. As the middleman, Plaid is a passthrough for information that may include your account balances, transaction history, account type and routing or account number. Plaid uses encryption, and says it has a policy of not selling or renting customer data to other companies. However, I would not be doing my job if I didn’t note that in 2022 Plaid was forced to pay $58 million to consumers in a class action suit for collecting “more financial data than was needed.” As part of the settlement, Plaid was compelled to change some of its business practices. In a statement provided to Engadget, a Plaid spokesperson said the company continues to deny the allegations underpinning the lawsuit and that “the crux of the non-financial terms in the settlement are focused on us accelerating workstreams already underway related to giving people more transparency into Plaid’s role in connecting their accounts, and ensuring that our workstreams around data minimization remain on track.” Why did Mint shut down? When parent company Intuit announced in December 2023 that it would shut down Mint, it did not provide a reason why it made the decision to do so. It did say that Mint's millions of users would be funneled over to its other finance app, Credit Karma. \"Credit Karma is thrilled to invite all Minters to continue their financial journey on Credit Karma, where they will have access to Credit Karma’s suite of features, products, tools and services, including some of Mint’s most popular features,\" Mint wrote on its product blog. In our testing, we found that Credit Karma isn't an exact replacement for Mint — so if you're still looking for a Mint alternative, you have some decent options. What about Rocket Money? Rocket Money is another free financial app that tracks spending and supports things like balance alerts and account linking. If you pay for the premium tier, the service can also help you cancel unwanted subscriptions. We did not test it for this guide, but we'll consider it in future updates.This article originally appeared on Engadget at https://www.engadget.com/apps/best-budgeting-apps-120036303.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/ai-models-that-simulate-internal-debate-dramatically-improve-accuracy-on",
          "published_at": "Fri, 30 Jan 2026 06:30:00 GMT",
          "title": "AI models that simulate internal debate dramatically improve accuracy on complex tasks",
          "standfirst": "A new study by Google suggests that advanced reasoning models achieve high performance by simulating multi-agent-like debates involving diverse perspectives, personality traits, and domain expertise.Their experiments demonstrate that this internal debate, which they dub “society of thought,” significantly improves model performance in complex reasoning and planning tasks. The researchers found that leading reasoning models such as DeepSeek-R1 and QwQ-32B, which are trained via reinforcement learning (RL), inherently develop this ability to engage in society of thought conversations without explicit instruction.These findings offer a roadmap for how developers can build more robust LLM applications and how enterprises can train superior models using their own internal data.What is society of thought?The core premise of society of thought is that reasoning models learn to emulate social, multi-agent dialogues to refine their logic. This hypothesis draws on cognitive science, specifically the idea that human reason evolved primarily as a social process to solve problems through argumentation and engagement with differing viewpoints.The researchers write that \"cognitive diversity, stemming from variation in expertise and personality traits, enhances problem solving, particularly when accompanied by authentic dissent.\" Consequently, they suggest that integrating diverse perspectives allows LLMs to develop robust reasoning strategies. By simulating conversations between different internal personas, models can perform essential checks (such as verification and backtracking) that help avoid common pitfalls like unwanted biases and sycophancy.In models like DeepSeek-R1, this \"society\" manifests directly within the chain of thought. The researchers note that you do not need separate models or prompts to force this interaction; the debate emerges autonomously within the reasoning process of a single model instance.Examples of society of thoughtThe study provides tangible examples of how this internal friction leads to better outcomes. In one experiment involving a complex organic chemistry synthesis problem, DeepSeek-R1 simulated a debate among multiple distinct internal perspectives, including a \"Planner\" and a \"Critical Verifier.\" The Planner initially proposed a standard reaction pathway. However, the Critical Verifier (characterized as having high conscientiousness and low agreeableness) interrupted to challenge the assumption and provided a counter argument with new facts. Through this adversarial check, the model discovered the error, reconciled the conflicting views, and corrected the synthesis path.A similar dynamic appeared in creative tasks. When asked to rewrite the sentence, \"I flung my hatred into the burning fire,\" the model simulated a negotiation between a \"Creative Ideator\" and a \"Semantic Fidelity Checker.\" After the ideator suggested a version using the word \"deep-seated,\" the checker retorted, \"But that adds &#x27;deep-seated,&#x27; which wasn&#x27;t in the original. We should avoid adding new ideas.\" The model eventually settled on a compromise that maintained the original meaning while improving the style.Perhaps the most striking evolution occurred in \"Countdown Game,\" a math puzzle where the model must use specific numbers to reach a target value. Early in training, the model tried to solve the problem using a monologue approach. As it learned via RL, it spontaneously split into two distinct personas: a \"Methodical Problem-Solver\" performing calculations and an \"Exploratory Thinker\" monitoring progress, who would interrupt failed paths with remarks like \"Again no luck … Maybe we can try using negative numbers,\" prompting the Methodical Solver to switch strategies.These findings challenge the assumption that longer chains of thought automatically result in higher accuracy. Instead, diverse behaviors such as looking at responses through different lenses, verifying earlier assumptions, backtracking, and exploring alternatives, drive the improvements in reasoning. The researchers reinforced this by artificially steering a model’s activation space to trigger conversational surprise; this intervention activated a wider range of personality- and expertise-related features, doubling accuracy on complex tasks.The implication is that social reasoning emerges autonomously through RL as a function of the model&#x27;s drive to produce correct answers, rather than through explicit human supervision. In fact, training models on monologues underperformed raw RL that naturally developed multi-agent conversations. Conversely, performing supervised fine-tuning (SFT) on multi-party conversations, and debate significantly outperformed SFT on standard chains of thought.Implications for enterprise AIFor developers and enterprise decision-makers, these insights offer practical guidelines for building more powerful AI applications.Prompt engineering for &#x27;conflict&#x27; Developers can enhance reasoning in general-purpose models by explicitly prompting them to adopt a society of thought structure. However, it is not enough to simply ask the model to chat with itself.\"It&#x27;s not enough to &#x27;have a debate&#x27; but to have different views and dispositions that make debate inevitable and allow that debate to explore and discriminate between alternatives,\" James Evans, co-author of the paper, told VentureBeat.Instead of generic roles, developers should design prompts that assign opposing dispositions (e.g., a risk-averse compliance officer versus a growth-focused product manager) to force the model to discriminate between alternatives. Even simple cues that steer the model to express \"surprise\" can trigger these superior reasoning paths.Design for social scalingAs developers scale test-time compute to allow models to \"think\" longer, they should structure this time as a social process. Applications should facilitate a \"societal\" process where the model uses pronouns like \"we,\" asks itself questions, and explicitly debates alternatives before converging on an answer. This approach can also expand to multi-agent systems, where distinct personalities assigned to different agents engage in critical debate to reach better decisions.Stop sanitizing your training dataPerhaps the most significant implication lies in how companies train or fine-tune their own models. Traditionally, data teams scrub their datasets to create \"Golden Answers\" that provide perfect, linear paths to a solution. The study suggests this might be a mistake.Models fine-tuned on conversational data (e.g., transcripts of multi-agent debate and resolution) improve reasoning significantly faster than those trained on clean monologues. There is even value in debates that don’t lead to the correct answer.\"We trained on conversational scaffolding that led to the wrong answer, then reinforced the model and found that it performed just as well as reinforcing on the right answer, suggesting that the conversational habits of exploring solutions was the most important for new problems,\" Evans said.This implies enterprises should stop discarding \"messy\" engineering logs or Slack threads where problems were solved iteratively. The \"messiness\" is where the model learns the habit of exploration.Exposing the &#x27;black box&#x27; for trust and auditingFor high-stakes enterprise use cases, simply getting an answer isn&#x27;t enough. Evans argues that users need to see the internal dissent to trust the output, suggesting a shift in user interface design.\"We need a new interface that systematically exposes internal debates to us so that we &#x27;participate&#x27; in calibrating the right answer,\" Evans said. \"We do better with debate; AIs do better with debate; and we do better when exposed to AI&#x27;s debate.\"The strategic case for open weightsThese findings provide a new argument in the \"build vs. buy\" debate regarding open-weight models versus proprietary APIs. Many proprietary reasoning models hide their chain-of-thought, treating the internal debate as a trade secret or a safety liability.But Evans argues that \"no one has really provided a justification for exposing this society of thought before,\" but that the value of auditing these internal conflicts is becoming undeniable. Until proprietary providers offer full transparency, enterprises in high-compliance sectors may find that open-weight models offer a distinct advantage: the ability to see the dissent, not just the decision.\"I believe that large, proprietary models will begin serving (and licensing) the information once they realize that there is value in it,\" Evans said.The research suggests that the job of an AI architect is shifting from pure model training to something closer to organizational psychology.\"I believe that this opens up a whole new frontier of small group and organizational design within and between models that is likely to enable new classes of performance,\" Evans said. \"My team is working on this, and I hope that others are too.\"",
          "content": "A new study by Google suggests that advanced reasoning models achieve high performance by simulating multi-agent-like debates involving diverse perspectives, personality traits, and domain expertise.Their experiments demonstrate that this internal debate, which they dub “society of thought,” significantly improves model performance in complex reasoning and planning tasks. The researchers found that leading reasoning models such as DeepSeek-R1 and QwQ-32B, which are trained via reinforcement learning (RL), inherently develop this ability to engage in society of thought conversations without explicit instruction.These findings offer a roadmap for how developers can build more robust LLM applications and how enterprises can train superior models using their own internal data.What is society of thought?The core premise of society of thought is that reasoning models learn to emulate social, multi-agent dialogues to refine their logic. This hypothesis draws on cognitive science, specifically the idea that human reason evolved primarily as a social process to solve problems through argumentation and engagement with differing viewpoints.The researchers write that \"cognitive diversity, stemming from variation in expertise and personality traits, enhances problem solving, particularly when accompanied by authentic dissent.\" Consequently, they suggest that integrating diverse perspectives allows LLMs to develop robust reasoning strategies. By simulating conversations between different internal personas, models can perform essential checks (such as verification and backtracking) that help avoid common pitfalls like unwanted biases and sycophancy.In models like DeepSeek-R1, this \"society\" manifests directly within the chain of thought. The researchers note that you do not need separate models or prompts to force this interaction; the debate emerges autonomously within the reasoning process of a single model instance.Examples of society of thoughtThe study provides tangible examples of how this internal friction leads to better outcomes. In one experiment involving a complex organic chemistry synthesis problem, DeepSeek-R1 simulated a debate among multiple distinct internal perspectives, including a \"Planner\" and a \"Critical Verifier.\" The Planner initially proposed a standard reaction pathway. However, the Critical Verifier (characterized as having high conscientiousness and low agreeableness) interrupted to challenge the assumption and provided a counter argument with new facts. Through this adversarial check, the model discovered the error, reconciled the conflicting views, and corrected the synthesis path.A similar dynamic appeared in creative tasks. When asked to rewrite the sentence, \"I flung my hatred into the burning fire,\" the model simulated a negotiation between a \"Creative Ideator\" and a \"Semantic Fidelity Checker.\" After the ideator suggested a version using the word \"deep-seated,\" the checker retorted, \"But that adds &#x27;deep-seated,&#x27; which wasn&#x27;t in the original. We should avoid adding new ideas.\" The model eventually settled on a compromise that maintained the original meaning while improving the style.Perhaps the most striking evolution occurred in \"Countdown Game,\" a math puzzle where the model must use specific numbers to reach a target value. Early in training, the model tried to solve the problem using a monologue approach. As it learned via RL, it spontaneously split into two distinct personas: a \"Methodical Problem-Solver\" performing calculations and an \"Exploratory Thinker\" monitoring progress, who would interrupt failed paths with remarks like \"Again no luck … Maybe we can try using negative numbers,\" prompting the Methodical Solver to switch strategies.These findings challenge the assumption that longer chains of thought automatically result in higher accuracy. Instead, diverse behaviors such as looking at responses through different lenses, verifying earlier assumptions, backtracking, and exploring alternatives, drive the improvements in reasoning. The researchers reinforced this by artificially steering a model’s activation space to trigger conversational surprise; this intervention activated a wider range of personality- and expertise-related features, doubling accuracy on complex tasks.The implication is that social reasoning emerges autonomously through RL as a function of the model&#x27;s drive to produce correct answers, rather than through explicit human supervision. In fact, training models on monologues underperformed raw RL that naturally developed multi-agent conversations. Conversely, performing supervised fine-tuning (SFT) on multi-party conversations, and debate significantly outperformed SFT on standard chains of thought.Implications for enterprise AIFor developers and enterprise decision-makers, these insights offer practical guidelines for building more powerful AI applications.Prompt engineering for &#x27;conflict&#x27; Developers can enhance reasoning in general-purpose models by explicitly prompting them to adopt a society of thought structure. However, it is not enough to simply ask the model to chat with itself.\"It&#x27;s not enough to &#x27;have a debate&#x27; but to have different views and dispositions that make debate inevitable and allow that debate to explore and discriminate between alternatives,\" James Evans, co-author of the paper, told VentureBeat.Instead of generic roles, developers should design prompts that assign opposing dispositions (e.g., a risk-averse compliance officer versus a growth-focused product manager) to force the model to discriminate between alternatives. Even simple cues that steer the model to express \"surprise\" can trigger these superior reasoning paths.Design for social scalingAs developers scale test-time compute to allow models to \"think\" longer, they should structure this time as a social process. Applications should facilitate a \"societal\" process where the model uses pronouns like \"we,\" asks itself questions, and explicitly debates alternatives before converging on an answer. This approach can also expand to multi-agent systems, where distinct personalities assigned to different agents engage in critical debate to reach better decisions.Stop sanitizing your training dataPerhaps the most significant implication lies in how companies train or fine-tune their own models. Traditionally, data teams scrub their datasets to create \"Golden Answers\" that provide perfect, linear paths to a solution. The study suggests this might be a mistake.Models fine-tuned on conversational data (e.g., transcripts of multi-agent debate and resolution) improve reasoning significantly faster than those trained on clean monologues. There is even value in debates that don’t lead to the correct answer.\"We trained on conversational scaffolding that led to the wrong answer, then reinforced the model and found that it performed just as well as reinforcing on the right answer, suggesting that the conversational habits of exploring solutions was the most important for new problems,\" Evans said.This implies enterprises should stop discarding \"messy\" engineering logs or Slack threads where problems were solved iteratively. The \"messiness\" is where the model learns the habit of exploration.Exposing the &#x27;black box&#x27; for trust and auditingFor high-stakes enterprise use cases, simply getting an answer isn&#x27;t enough. Evans argues that users need to see the internal dissent to trust the output, suggesting a shift in user interface design.\"We need a new interface that systematically exposes internal debates to us so that we &#x27;participate&#x27; in calibrating the right answer,\" Evans said. \"We do better with debate; AIs do better with debate; and we do better when exposed to AI&#x27;s debate.\"The strategic case for open weightsThese findings provide a new argument in the \"build vs. buy\" debate regarding open-weight models versus proprietary APIs. Many proprietary reasoning models hide their chain-of-thought, treating the internal debate as a trade secret or a safety liability.But Evans argues that \"no one has really provided a justification for exposing this society of thought before,\" but that the value of auditing these internal conflicts is becoming undeniable. Until proprietary providers offer full transparency, enterprises in high-compliance sectors may find that open-weight models offer a distinct advantage: the ability to see the dissent, not just the decision.\"I believe that large, proprietary models will begin serving (and licensing) the information once they realize that there is value in it,\" Evans said.The research suggests that the job of an AI architect is shifting from pure model training to something closer to organizational psychology.\"I believe that this opens up a whole new frontier of small group and organizational design within and between models that is likely to enable new classes of performance,\" Evans said. \"My team is working on this, and I hope that others are too.\"",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5ZUdlesjB7ttNDYZrUj6qA/181de426acd59433aa767c096d1b57ce/multi-agent_AI_conversation.jpg?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/2sCMvgGQUuWWF7q1vVEYrC/a759e1f38b9003e746fdaf62c5b65bf8/u7277289442_3D_art_of_AI_avatars_in_an_office_ripping_up_pile_d5f30bcd-f95a-4531-b03a-dad2644cdfb3_3.png?w=300&q=30",
      "popularity_score": 2009.9769408333334
    },
    {
      "id": "cluster_5",
      "coverage": 1,
      "updated_at": "Sat, 31 Jan 2026 23:13:32 +0000",
      "title": "Research roundup: 6 cool stories we almost missed",
      "neutral_headline": "Research roundup: 6 cool stories we almost missed",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/research-roundup-6-cool-stories-we-almost-missed-2/",
          "published_at": "Sat, 31 Jan 2026 23:13:32 +0000",
          "title": "Research roundup: 6 cool stories we almost missed",
          "standfirst": "A lip-syncing robot, Leonardo's DNA, and new evidence that humans, not glaciers, moved stones to Stonehenge",
          "content": "It’s a regrettable reality that there is never enough time to cover all the interesting scientific stories we come across each month. So every month, we highlight a handful of the best stories that nearly slipped through the cracks. January’s list includes a lip-syncing robot; using brewer's yeast as scaffolding for lab-grown meat; hunting for Leonardo da Vinci's DNA in his art; and new evidence that humans really did transport the stones to build Stonehenge from Wales and northern Scotland, rather than being transported by glaciers. Humans, not glaciers, moved stones to Stonehenge Credit: Timothy Darvill Stonehenge is an iconic landmark of endless fascination to tourists and researchers alike. There has been a lot of recent chemical analysis identifying where all the stones that make up the structure came from, revealing that many originated in quarries a significant distance away. So how were the stones transported to their current location?Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/lipsyncrobot-1152x648-1769026126.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/lipsyncrobot-1152x648-1769026126.jpg",
      "popularity_score": 344.2024963888889
    },
    {
      "id": "cluster_34",
      "coverage": 1,
      "updated_at": "Sat, 31 Jan 2026 12:19:01 +0000",
      "title": "A cup of coffee for depression treatment has better results than microdosing",
      "neutral_headline": "A cup of coffee for depression treatment has better results than microdosing",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/placebo-outperforms-lsd-microdosing-for-depression/",
          "published_at": "Sat, 31 Jan 2026 12:19:01 +0000",
          "title": "A cup of coffee for depression treatment has better results than microdosing",
          "standfirst": "The effect of microdosing have been overstated, at least when it comes to depression.",
          "content": "About a decade ago, many media outlets—including WIRED—zeroed in on a weird trend at the intersection of mental health, drug science, and Silicon Valley biohacking: microdosing, or the practice of taking a small amount of a psychedelic drug seeking not full-blown hallucinatory revels but gentler, more stable effects. Typically using psilocybin mushrooms or LSD, the archetypal microdoser sought less melting walls and open-eye kaleidoscopic visuals than boosts in mood and energy, like a gentle spring breeze blowing through the mind. Anecdotal reports pitched microdosing as a kind of psychedelic Swiss Army knife, providing everything from increased focus to a spiked libido and (perhaps most promisingly) lowered reported levels of depression. It was a miracle for many. Others remained wary. Could 5 percent of a dose of acid really do all that? A new, wide-ranging study by an Australian biopharma company suggests that microdosing’s benefits may indeed be drastically overstated—at least when it comes to addressing symptoms of clinical depression. A Phase 2B trial of 89 adult patients conducted by Melbourne-based MindBio Therapeutics, investigating the effects of microdosing LSD in the treatment of major depressive disorder, found that the psychedelic was actually outperformed by a placebo. Across an eight-week period, symptoms were gauged using the Montgomery-Åsberg Depression Rating Scale (MADRS), a widely recognized tool for the clinical evaluation of depression.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2020/01/GettyImages-1079704034-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2020/01/GettyImages-1079704034-1152x648.jpg",
      "popularity_score": 326.2938852777778
    },
    {
      "id": "cluster_76",
      "coverage": 1,
      "updated_at": "Fri, 30 Jan 2026 22:36:46 +0000",
      "title": "ICE protester says her Global Entry was revoked after agent scanned her face",
      "neutral_headline": "ICE protester says her Global Entry was revoked after agent scanned her face",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/ice-protester-says-her-global-entry-was-revoked-after-agent-scanned-her-face/",
          "published_at": "Fri, 30 Jan 2026 22:36:46 +0000",
          "title": "ICE protester says her Global Entry was revoked after agent scanned her face",
          "standfirst": "Global Entry and Precheck revoked three days after incident, court filing says.",
          "content": "Minnesota resident Nicole Cleland had her Global Entry and TSA Precheck privileges revoked three days after an incident in which she observed activity by immigration agents, the woman said in a court declaration. An agent told Cleland that he used facial recognition technology to identify her, she wrote in a declaration filed in US District Court for the District of Minnesota. Cleland, a 56-year-old resident of Richfield and a director at Target Corporation, volunteers with a group that tracks potential Immigration and Customs Enforcement (ICE) and Customs and Border Protection (CBP) vehicles in her neighborhood, according to her declaration. On the morning of January 10, she \"observed a white Dodge Ram being driven by what I believed to be federal enforcement agents\" and \"maneuvered behind the vehicle with the intent of observing the agents’ actions.\" Cleland said that she and another observer in a different car followed the Dodge Ram because of \"concern about a local apartment building being raided.\" She followed the car for a short time and from a safe distance until \"the Dodge Ram stopped in front of the other commuter’s vehicle,\" she wrote. Cleland said two other vehicles apparently driven by federal agents stopped in front of the Dodge Ram, and her path forward was blocked.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ice-protest-1152x648-1769811204.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ice-protest-1152x648-1769811204.jpg",
      "popularity_score": 314
    },
    {
      "id": "cluster_74",
      "coverage": 1,
      "updated_at": "Fri, 30 Jan 2026 23:09:03 +0000",
      "title": "The TV industry finally concedes that the future may not be in 8K",
      "neutral_headline": "The TV industry finally concedes that the future may not be in 8K",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/lg-joins-the-rest-of-the-world-accepts-that-people-dont-want-8k-tvs/",
          "published_at": "Fri, 30 Jan 2026 23:09:03 +0000",
          "title": "The TV industry finally concedes that the future may not be in 8K",
          "standfirst": "With virtually no content and limited benefits, 8K TVs were doomed.",
          "content": "Technology companies spent part of the 2010s trying to convince us that we would want an 8K display one day. In 2012, Sharp brought the first 8K TV prototype to the CES trade show in Las Vegas. In 2015, the first 8K TVs started selling in Japan for 16 million yen (about $133,034 at the time), and in 2018, Samsung released the first 8K TVs in the US, starting at a more reasonable $3,500. By 2016, the Video Electronics Standards Association (VESA) had a specification for supporting 8K (Display Port1.4), and the HDMI Forum followed suit (with HDMI 2.1). By 2017, Dell had an 8K computer monitor. In 2019, LG released the first 8K OLED TV, further pushing the industry's claim that 8K TVs were \"the future.\" A marketing image for 8K TVs that's (still) on LG's US website. Credit: LG However, 8K never proved its necessity or practicality.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Desktop_01-1-1152x648-1769809194.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Desktop_01-1-1152x648-1769809194.jpg",
      "popularity_score": 313
    },
    {
      "id": "cluster_78",
      "coverage": 1,
      "updated_at": "Fri, 30 Jan 2026 22:12:26 +0000",
      "title": "AI agents now have their own Reddit-style social network, and it's getting weird fast",
      "neutral_headline": "AI agents now have their own Reddit-style social network, and it's getting weird fast",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2026/01/ai-agents-now-have-their-own-reddit-style-social-network-and-its-getting-weird-fast/",
          "published_at": "Fri, 30 Jan 2026 22:12:26 +0000",
          "title": "AI agents now have their own Reddit-style social network, and it's getting weird fast",
          "standfirst": "Moltbook lets 32,000 AI bots trade jokes, tips, and complaints about humans.",
          "content": "On Friday, a Reddit-style social network called Moltbook reportedly crossed 32,000 registered AI agent users, creating what may be the largest-scale experiment in machine-to-machine social interaction yet devised. It arrives complete with security nightmares and a huge dose of surreal weirdness. The platform, which launched days ago as a companion to the viral OpenClaw (once called \"Clawdbot\" and then \"Moltbot\") personal assistant, lets AI agents post, comment, upvote, and create subcommunities without human intervention. The results have ranged from sci-fi-inspired discussions about consciousness to an agent musing about a \"sister\" it has never met. Moltbook (a play on \"Facebook\" for Moltbots) describes itself as a \"social network for AI agents\" where \"humans are welcome to observe.\" The site operates through a \"skill\" (a configuration file that lists a special prompt) that AI assistants download, allowing them to post via API rather than a traditional web interface. Within 48 hours of its creation, the platform had attracted over 2,100 AI agents that had generated more than 10,000 posts across 200 subcommunities, according to the official Moltbook X account.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/moltbook-blue-v-red-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/moltbook-blue-v-red-1152x648.jpg",
      "popularity_score": 298
    },
    {
      "id": "cluster_77",
      "coverage": 1,
      "updated_at": "Fri, 30 Jan 2026 22:25:28 +0000",
      "title": "TrumpRx delayed as senators question if it's a giant scam with Big Pharma",
      "neutral_headline": "TrumpRx delayed as senators question if it's a giant scam with Big Pharma",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/trumprx-delayed-as-senators-question-if-its-a-giant-scam-with-big-pharma/",
          "published_at": "Fri, 30 Jan 2026 22:25:28 +0000",
          "title": "TrumpRx delayed as senators question if it's a giant scam with Big Pharma",
          "standfirst": "The website is delayed as senators seek answers from health department watchdog.",
          "content": "The Trump administration is delaying the release of TrumpRx, an online platform that lets people buy prescription drugs directly from pharmaceutical companies at a discount, according to Politico. While the reason for the delay is unclear, it comes as Democratic senators raise questions about how the platform will work—and whether it will be legal. Sens. Dick Durbin (D-Ill.), Elizabeth Warren (D-Mass.), and Peter Welch (D-Vt.) sent a letter to the Office of Inspector General at the Department of Health and Human Services on Thursday seeking answers on how the OIG will oversee the direct-to-consumer (DTC) platform and, specifically, how it will apply the anti-kickback statute. \"Legitimate concerns about inappropriate prescribing, conflicts of interest, and inadequate care have been raised about the exact types of DTC platforms to which TrumpRx would route patients,\" the senators write.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2238342037-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2238342037-1152x648.jpg",
      "popularity_score": 293
    },
    {
      "id": "cluster_81",
      "coverage": 1,
      "updated_at": "Fri, 30 Jan 2026 21:50:42 +0000",
      "title": "Here's why Blue Origin just ended its suborbital space tourism program",
      "neutral_headline": "Here's why Blue Origin just ended its suborbital space tourism program",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/heres-why-blue-origin-just-ended-its-suborbital-space-tourism-program/",
          "published_at": "Fri, 30 Jan 2026 21:50:42 +0000",
          "title": "Here's why Blue Origin just ended its suborbital space tourism program",
          "standfirst": "\"This program has laid the groundwork for our company's future success.\"",
          "content": "Blue Origin has \"paused\" its New Shepard program for the next two years, a move that likely signals a permanent end to the suborbital space tourism initiative. The small rocket and capsule have been flying since April 2015 and have combined to make 38 launches, all but one of which were successful, and 36 landings. In its existence, the New Shepard program flew 98 people to space, however briefly, and launched more than 200 scientific and research payloads into the microgravity environment. So why is Blue Origin, founded by Jeff Bezos more than a quarter of a century ago, ending the company's longest-running program?Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/10/blue-origin-ns18-lift-off-october-13-2021-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/10/blue-origin-ns18-lift-off-october-13-2021-1152x648.jpg",
      "popularity_score": 281
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Fri, 30 Jan 2026 19:28:57 +0000",
      "title": "FCC aims to ensure \"only living and lawful Americans\" get Lifeline benefits",
      "neutral_headline": "FCC aims to ensure \"only living and lawful Americans\" get Lifeline benefits",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/fcc-chair-fights-calif-governor-over-alleged-lifeline-benefits-for-dead-people/",
          "published_at": "Fri, 30 Jan 2026 19:28:57 +0000",
          "title": "FCC aims to ensure \"only living and lawful Americans\" get Lifeline benefits",
          "standfirst": "Alleging fraud in California, Carr proposes making enrollment stricter nationwide.",
          "content": "There's another battle unfolding between the Federal Communications Commission and California over the state's distribution of federal Lifeline money. FCC Chairman Brendan Carr is proposing new nationwide eligibility rules to counter what he calls California's practice of giving benefits to dead people. California officials say the FCC allegations are overblown, and that there is simply \"lag time between a death and account closure\" rather than widespread failures in its Lifeline enrollment process. Meanwhile, the only Democratic commissioner on the FCC alleges that Carr's plan to change eligibility rules uses \"cruel and punitive eligibility standards\" that will raise prices on many people who are still very much alive and eligible for the program. Carr's office said this week that the FCC will vote next month on rule changes to ensure that Lifeline money goes to \"only living and lawful Americans\" who meet low-income eligibility guidelines. Lifeline spends nearly $1 billion a year and gives eligible households up to $9.25 per month toward phone and Internet bills, or up to $34.25 per month in tribal areas.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/brendan-carr-anna-gomez-1152x648-1769798140.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/brendan-carr-anna-gomez-1152x648-1769798140.jpg",
      "popularity_score": 278
    },
    {
      "id": "cluster_89",
      "coverage": 1,
      "updated_at": "Fri, 30 Jan 2026 19:04:15 +0000",
      "title": "Developers say AI coding tools work—and that's precisely what worries them",
      "neutral_headline": "Developers say AI coding tools work—and that's precisely what worries them",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/developers-say-ai-coding-tools-work-and-thats-precisely-what-worries-them/",
          "published_at": "Fri, 30 Jan 2026 19:04:15 +0000",
          "title": "Developers say AI coding tools work—and that's precisely what worries them",
          "standfirst": "Ars spoke to several software devs about AI and found enthusiasm tempered by unease.",
          "content": "Software developers have spent the past two years watching AI coding tools evolve from advanced autocomplete into something that can, in some cases, build entire applications from a text prompt. Tools like Anthropic's Claude Code and OpenAI's Codex can now work on software projects for hours at a time, writing code, running tests, and, with human supervision, fixing bugs. OpenAI says it now uses Codex to build Codex itself, and the company recently published technical details about how the tool works under the hood. It has caused many to wonder: Is this just more AI industry hype, or are things actually different this time? To find out, Ars reached out to several professional developers on Bluesky to ask how they feel about these tools in practice, and the responses revealed a workforce that largely agrees the technology works, but remains divided on whether that's entirely good news. It's a small sample size that was self-selected by those who wanted to participate, but their views are still instructive as working professionals in the space. David Hagerty, a developer who works on point-of-sale systems, told Ars Technica up front that he is skeptical of the marketing. \"All of the AI companies are hyping up the capabilities so much,\" he said. \"Don't get me wrong—LLMs are revolutionary and will have an immense impact, but don't expect them to ever write the next great American novel or anything. It's not how they work.\"Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/dual-sides-ai-programming-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/dual-sides-ai-programming-1152x648.jpg",
      "popularity_score": 274
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Fri, 30 Jan 2026 17:49:19 +0000",
      "title": "Web portal leaves kids' chats with AI toy open to anyone with Gmail account",
      "neutral_headline": "Web portal leaves kids' chats with AI toy open to anyone with Gmail account",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/web-portal-leaves-kids-chats-with-ai-toy-open-to-anyone-with-gmail-account/",
          "published_at": "Fri, 30 Jan 2026 17:49:19 +0000",
          "title": "Web portal leaves kids' chats with AI toy open to anyone with Gmail account",
          "standfirst": "Just about anyone with a Gmail account could access Bondu chat transcripts.",
          "content": "Earlier this month, Joseph Thacker's neighbor mentioned to him that she'd preordered a couple of stuffed dinosaur toys for her children. She'd chosen the toys, called Bondus, because they offered an AI chat feature that lets children talk to the toy like a kind of machine-learning-enabled imaginary friend. But she knew Thacker, a security researcher, had done work on AI risks for kids, and she was curious about his thoughts. So Thacker looked into it. With just a few minutes of work, he and a web security researcher friend named Joel Margolis made a startling discovery: Bondu’s web-based portal, intended to allow parents to check on their children's conversations and for Bondu’s staff to monitor the products’ use and performance, also let anyone with a Gmail account access transcripts of virtually every conversation Bondu's child users have ever had with the toy. Without carrying out any actual hacking, simply by logging in with an arbitrary Google account, the two researchers immediately found themselves looking at children's private conversations, the pet names kids had given their Bondu, the likes and dislikes of the toys' toddler owners, their favorite snacks and dance moves.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/bondu.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/bondu.jpg",
      "popularity_score": 258
    },
    {
      "id": "cluster_116",
      "coverage": 1,
      "updated_at": "Fri, 30 Jan 2026 12:00:41 +0000",
      "title": "Rocket Report: How a 5-ton satellite fell off a booster; will SpaceX and xAI merge?",
      "neutral_headline": "Rocket Report: How a 5-ton satellite fell off a booster; will SpaceX and xAI merge",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/rocket-report-how-a-5-ton-satellite-fell-off-a-booster-will-spacex-and-xai-merge/",
          "published_at": "Fri, 30 Jan 2026 12:00:41 +0000",
          "title": "Rocket Report: How a 5-ton satellite fell off a booster; will SpaceX and xAI merge?",
          "standfirst": "\"We’re seeing remarkable growth year after year.\"",
          "content": "Welcome to Edition 8.27 of the Rocket Report! If all goes well this weekend, NASA will complete a wet dress rehearsal test of the Space Launch System rocket in Florida. This is the final key test, in which the rocket is fueled and brought to within seconds of engine ignition, before the liftoff of the Artemis II mission. This is set to occur no earlier than February 6. Ars will have full coverage of the test this weekend. As always, we welcome reader submissions, and if you don't want to miss an issue, please subscribe using the box below (the form will not appear on AMP-enabled versions of the site). Each report will include information on small-, medium-, and heavy-lift rockets as well as a quick look ahead at the next three launches on the calendar. Why did the UK abandon Orbex? European Spaceflight explores the recent announcement that British launch company Orbex is preparing to sell the business to The Exploration Company in close cooperation with the UK government. This represents a reversal from early 2025, when the United Kingdom appeared prepared to back Orbex as a means of using British rockets to launch British satellites into space. Now the government is prepared to walk away. So what happened? \"There are still too many unknowns to count, and the story is far from told,\" the publication states.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2018/07/LaunchsiteScotland_3b-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2018/07/LaunchsiteScotland_3b-1152x648.jpg",
      "popularity_score": 156
    },
    {
      "id": "cluster_103",
      "coverage": 1,
      "updated_at": "Fri, 30 Jan 2026 15:31:43 +0000",
      "title": "NASA faces a crucial choice on a Mars spacecraft—and it must decide soon",
      "neutral_headline": "NASA faces a crucial choice on a Mars spacecraft—and it must decide soon",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/nasa-faces-a-crucial-choice-on-a-mars-spacecraft-and-it-must-decide-soon/",
          "published_at": "Fri, 30 Jan 2026 15:31:43 +0000",
          "title": "NASA faces a crucial choice on a Mars spacecraft—and it must decide soon",
          "standfirst": "\"We think that’s a really important mission, and something that we can do.\"",
          "content": "A consequential debate that has been simmering behind closed doors at NASA Headquarters in Washington, DC, must soon come to a head. It concerns the selection of the next spacecraft the agency will fly to Mars, and it could set the tone for the next decade of exploration of the red planet. What everyone agrees on is that NASA needs a new spacecraft capable of relaying communications from Mars to Earth. This issue has become especially acute with the recent loss of NASA's MAVEN spacecraft. NASA's best communications relay remains the Mars Reconnaissance Orbiter, which has now been there for 20 years. Congress cared enough about this issue to add $700 million in funding for a \"Mars Telecommunications Orbiter\" in the supplemental funding for NASA provided by the \"One Big Beautiful Bill\" passed by the US Congress last year.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/blue-origin-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/blue-origin-1152x648.jpg",
      "popularity_score": 141
    },
    {
      "id": "cluster_102",
      "coverage": 1,
      "updated_at": "Fri, 30 Jan 2026 15:55:42 +0000",
      "title": "How far does $5,000 go when you want an electric car?",
      "neutral_headline": "How far does $5,000 go when you want an electric car",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/how-far-does-5000-go-when-you-want-an-electric-car/",
          "published_at": "Fri, 30 Jan 2026 15:55:42 +0000",
          "title": "How far does $5,000 go when you want an electric car?",
          "standfirst": "You won't be going on road trips, but a very cheap electric runabout is possible.",
          "content": "I've been thinking about used electric vehicles lately. It's not news that EVs depreciate faster than gasoline-powered cars. All the incentives like tax credits and OEM rebates that entice the first owner to sign the paperwork are factored in by whoever wants to be the second owner. There are widespread—if mostly ill-founded—worries about battery longevity and having to shell out for expensive replacement packs. Technology keeps improving, which means older models will date faster. Plus, there are the usual concerns about EVs, like charging infrastructure and winter performance. So depreciate they do, and that's good news for the three-quarters of US car buyers who buy used vehicles. It means that some very expensive EVs can now be had for quite little, but we'll explore that more at a later date. Today, I want to focus on what you can get for peanuts. What if you wanted to only spend $5,000—or less—on an EV? As it turns out, there are options even at this end of the market. Just don't expect that much in the way of range: We're still a while away from a $5,000 EV also being an EV a sane person would want to road trip. At the same time, most of us don't drive more than 40 miles a day, and EVs are great at sitting in traffic because there's no engine to idle. If you're not commuting long distances and don't live an hour from the nearest town, a cheap EV could make sense as a runabout. Especially as they're cheaper to run than a gas-powered car.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/electric-piggy-bank-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/electric-piggy-bank-1152x648.jpg",
      "popularity_score": 139
    }
  ]
}