{
  "updated_at": "2026-01-14T19:20:02.772Z",
  "clusters": [
    {
      "id": "cluster_29",
      "coverage": 5,
      "updated_at": "Wed, 14 Jan 2026 16:42:32 +0000",
      "title": "Gemini can now scan your photos, email, and more to provide better answers",
      "neutral_headline": "Gemini can now scan your photos, email, and more to provide better answers",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/01/gemini-can-now-scan-your-photos-email-and-more-to-provide-better-answers/",
          "published_at": "Wed, 14 Jan 2026 16:42:32 +0000",
          "title": "Gemini can now scan your photos, email, and more to provide better answers",
          "standfirst": "The feature will start with paid users only, and it's off by default.",
          "content": "Google has toyed with personalized answers in Gemini, but that was just a hint of what was to come. Today, the company is announcing extensive \"personal intelligence\" in Gemini that allows the chatbot to connect to Gmail, Photos, Search, and YouTube to craft more useful answers to your questions. If you don't want Gemini to get to know you, there's some good news. Personal intelligence is beginning as a feature for paid users, and it's entirely optional. By every measure, Google's models are at or near the top of the AI heap. In general, the more information you feed into a generative AI, the better the outputs are. And when that data is personal to you, the resulting inference is theoretically more useful. Google just so happens to have a lot of personal data on all its users, so it's relatively simple to feed that data into Gemini. As Personal Intelligence rolls out over the coming weeks, AI Pro and AI Ultra subscribers will see the option to connect those data sources. Each can be connected individually, so you might choose to allow Gmail access but block Photos, for example. When Gemini is allowed access to other Google products, it incorporates that data into its responses.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg"
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260114/p37#a260114p37",
          "published_at": "Wed, 14 Jan 2026 11:15:02 -0500",
          "title": "Google launches Personal Intelligence, a Gemini feature that links to Gmail, Google Photos, Search, and YouTube history to tailor answers, for paid subscribers (Sabrina Ortiz/ZDNET)",
          "standfirst": "Sabrina Ortiz / ZDNET: Google launches Personal Intelligence, a Gemini feature that links to Gmail, Google Photos, Search, and YouTube history to tailor answers, for paid subscribers &mdash; ZDNET's key takeaways &mdash; Personal Intelligence scans your apps to improve Gemini answers. &mdash; The feature is off by default and won't train on sensitive data.",
          "content": "Sabrina Ortiz / ZDNET: Google launches Personal Intelligence, a Gemini feature that links to Gmail, Google Photos, Search, and YouTube history to tailor answers, for paid subscribers &mdash; ZDNET's key takeaways &mdash; Personal Intelligence scans your apps to improve Gemini answers. &mdash; The feature is off by default and won't train on sensitive data.",
          "feed_position": 5,
          "image_url": "http://www.techmeme.com/260114/i37.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/861576/google-gemini-ai-personal-intelligence-gmail-search-youtube-photos",
          "published_at": "2026-01-14T11:00:00-05:00",
          "title": "Google’s Gemini AI will use what it knows about you from Gmail, Search, and YouTube",
          "standfirst": "Google's Gemini AI is getting what could prove to be a very big upgrade: To help answers from Gemini be more personalized, the company is going to let you connect the chatbot to Gmail, Google Photos, Search, and your YouTube history to provide what Google is calling \"Personal Intelligence.\" This isn't the first time Google [&#8230;]",
          "content": "Google's Gemini AI is getting what could prove to be a very big upgrade: To help answers from Gemini be more personalized, the company is going to let you connect the chatbot to Gmail, Google Photos, Search, and your YouTube history to provide what Google is calling \"Personal Intelligence.\" This isn't the first time Google has introduced some form of personalization with its AI chatbot; in September 2023, when Gemini was still called Bard, Google announced a way for it to connect to Google's apps and services to be able to retrieve information based on what's stored in your account. Gemini can also already recall past conversations. But the … Read the full story at The Verge.",
          "feed_position": 9
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/14/geminis-new-beta-feature-provides-proactive-responses-based-on-your-photos-emails-and-more/",
          "published_at": "Wed, 14 Jan 2026 16:00:00 +0000",
          "title": "Gemini&#8217;s new beta feature provides proactive responses based on your photos, emails, and more",
          "standfirst": "Personal Intelligence is off by default, as users have the option to choose if and when they want to connect their Google apps to Gemini.",
          "content": "Personal Intelligence is off by default, as users have the option to choose if and when they want to connect their Google apps to Gemini.",
          "feed_position": 7
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/google-gemini-personal-intelligence/",
          "published_at": "Wed, 14 Jan 2026 16:00:00 GMT",
          "title": "Gemini's new Personal Intelligence will look through your emails and photos - if you let it",
          "standfirst": "Can the feature do what Apple Intelligence promised? Here's what it will and won't have access to, and how it'll impact privacy.",
          "content": "Can the feature do what Apple Intelligence promised? Here's what it will and won't have access to, and how it'll impact privacy.",
          "feed_position": 4
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg",
      "popularity_score": 5017.374785555556
    },
    {
      "id": "cluster_5",
      "coverage": 2,
      "updated_at": "Wed, 14 Jan 2026 19:00:00 GMT",
      "title": "AI agents can talk — orchestration is what makes them work together",
      "neutral_headline": "AI agents can talk — orchestration is what makes them work together",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/ai-agents-can-talk-orchestration-is-what-makes-them-work-together",
          "published_at": "Wed, 14 Jan 2026 19:00:00 GMT",
          "title": "AI agents can talk — orchestration is what makes them work together",
          "standfirst": "Rather than asking how AI agents can work for them, a key question in enterprise is now: Are agents playing well together? This makes orchestration across multi-agent systems and platforms a critical concern — and a key differentiator. “Agent-to-agent communications is emerging as a really big deal,” G2’s chief innovation officer Tim Sanders told VentureBeat. “Because if you don&#x27;t orchestrate it, you get misunderstandings, like people speaking foreign languages to each other. Those misunderstandings reduce the quality of actions and raise the specter of hallucinations, which could be security incidents or data leakage.”Allowing agents to talk and coordinateOrchestration to this point has largely been around data, but that’s quickly turning to action. “Conductor-like solutions” are increasingly bringing together agents, robotic process automation (RPA), and data repositories. Sanders likened the progression to that of answer engine optimization, which initially began with monitoring and now creates bespoke content and code. “Orchestration platforms coordinate a variety of different agentic solutions to increase the consistency of outcomes,” he said. Early providers include Salesforce MuleSoft, UiPath Maestro, and IBM Watsonx Orchestrate. These “phase one” software-based observability dashboards help IT leaders see all agentic actions across an enterprise. The critical element of risk managementBut coordination can only add so much value; these platforms will morph into technical risk management tools that provide greater quality control. This could include, for instance, agent assessments, policy recommendation and proactive scoring (such as, how reliable agents are when they call on enterprise tools, or how often they hallucinate and when). Enterprise leaders have become wary of relying on vendors to minimize risks and errors; many IT decision-makers, in fact, do not trust a vendor&#x27;s statements about the reliability of their agents, he said. Third-party tools are beginning to bridge the gap and automate tedious guardrail processes and escalation tickets. Teams are already experiencing “ticket exhaustion” in semi-automated systems, where agents hit guardrails and require human permission to proceed.As an example: The loan process at a bank requires 17 steps for approval, and an agent keeps interrupting human workflows with approval requests when it runs into established guardrails. Third-party orchestration platforms can manage these tickets and nay, yay, or even challenge the need for approval altogether. They can eventually eliminate the need for persistent human-in-the-loop oversight so organizations can experience “true velocity gains” measured not in percentages but in multiples (that is, 3X versus 30%).“Where it goes from there is remote management of the entire agentic process for organizations,” Sanders said. ‘Human-on-the-loop’ versus ‘human-in-the-loop’ In another critical evolution in the agentic era, human evaluators will become designers, moving from human-in-the-loop to human-on-the-loop, according to Sanders. That is: They will begin designing agents to automate workflows. Agent builder platforms continue to innovate their no-code solutions, Sanders said, meaning nearly anyone can now stand up an agent using natural language. “This will democratize agentic AI, and the super skill will be the ability to express a goal, provide context and envision pitfalls, very similar to a good people manager today.”What enterprise leaders should be doing nowAgent-first automation stacks “dramatically outperform” hybrid automation stacks in almost every attribute, he noted: satisfaction, quality of actions, security, cost savings.Organizations should begin “expeditious programs” to infuse agents across workflows, especially with highly repetitive work that poses bottlenecks. Likely at first, there will be a strong human-in-the-loop element to ensure quality and promote change management. “Serving as an evaluator will strengthen the understanding of how these systems work,” Sanders said, “and eventually enable all of us to operate upstream in agentic workflows instead of downstream.” IT leaders should take inventory today of all the different elements of their automation stack. Whether these elements are rules-based automation, RPA, or agentic automation, they must learn everything going on in the organization to optimally use emerging orchestration platforms.“If they don&#x27;t, there could actually be dis-synergies across organizations where old school technology and cutting edge technology clash at the point of delivery, oftentimes customer-facing,” Sanders said. “You can&#x27;t orchestrate what you can&#x27;t see clearly.”",
          "content": "Rather than asking how AI agents can work for them, a key question in enterprise is now: Are agents playing well together? This makes orchestration across multi-agent systems and platforms a critical concern — and a key differentiator. “Agent-to-agent communications is emerging as a really big deal,” G2’s chief innovation officer Tim Sanders told VentureBeat. “Because if you don&#x27;t orchestrate it, you get misunderstandings, like people speaking foreign languages to each other. Those misunderstandings reduce the quality of actions and raise the specter of hallucinations, which could be security incidents or data leakage.”Allowing agents to talk and coordinateOrchestration to this point has largely been around data, but that’s quickly turning to action. “Conductor-like solutions” are increasingly bringing together agents, robotic process automation (RPA), and data repositories. Sanders likened the progression to that of answer engine optimization, which initially began with monitoring and now creates bespoke content and code. “Orchestration platforms coordinate a variety of different agentic solutions to increase the consistency of outcomes,” he said. Early providers include Salesforce MuleSoft, UiPath Maestro, and IBM Watsonx Orchestrate. These “phase one” software-based observability dashboards help IT leaders see all agentic actions across an enterprise. The critical element of risk managementBut coordination can only add so much value; these platforms will morph into technical risk management tools that provide greater quality control. This could include, for instance, agent assessments, policy recommendation and proactive scoring (such as, how reliable agents are when they call on enterprise tools, or how often they hallucinate and when). Enterprise leaders have become wary of relying on vendors to minimize risks and errors; many IT decision-makers, in fact, do not trust a vendor&#x27;s statements about the reliability of their agents, he said. Third-party tools are beginning to bridge the gap and automate tedious guardrail processes and escalation tickets. Teams are already experiencing “ticket exhaustion” in semi-automated systems, where agents hit guardrails and require human permission to proceed.As an example: The loan process at a bank requires 17 steps for approval, and an agent keeps interrupting human workflows with approval requests when it runs into established guardrails. Third-party orchestration platforms can manage these tickets and nay, yay, or even challenge the need for approval altogether. They can eventually eliminate the need for persistent human-in-the-loop oversight so organizations can experience “true velocity gains” measured not in percentages but in multiples (that is, 3X versus 30%).“Where it goes from there is remote management of the entire agentic process for organizations,” Sanders said. ‘Human-on-the-loop’ versus ‘human-in-the-loop’ In another critical evolution in the agentic era, human evaluators will become designers, moving from human-in-the-loop to human-on-the-loop, according to Sanders. That is: They will begin designing agents to automate workflows. Agent builder platforms continue to innovate their no-code solutions, Sanders said, meaning nearly anyone can now stand up an agent using natural language. “This will democratize agentic AI, and the super skill will be the ability to express a goal, provide context and envision pitfalls, very similar to a good people manager today.”What enterprise leaders should be doing nowAgent-first automation stacks “dramatically outperform” hybrid automation stacks in almost every attribute, he noted: satisfaction, quality of actions, security, cost savings.Organizations should begin “expeditious programs” to infuse agents across workflows, especially with highly repetitive work that poses bottlenecks. Likely at first, there will be a strong human-in-the-loop element to ensure quality and promote change management. “Serving as an evaluator will strengthen the understanding of how these systems work,” Sanders said, “and eventually enable all of us to operate upstream in agentic workflows instead of downstream.” IT leaders should take inventory today of all the different elements of their automation stack. Whether these elements are rules-based automation, RPA, or agentic automation, they must learn everything going on in the organization to optimally use emerging orchestration platforms.“If they don&#x27;t, there could actually be dis-synergies across organizations where old school technology and cutting edge technology clash at the point of delivery, oftentimes customer-facing,” Sanders said. “You can&#x27;t orchestrate what you can&#x27;t see clearly.”",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7szF9iF50458lvbJ6Hyb36/9cb490b66a50d662947b1fd978204626/G2.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/how-to-turn-off-a-vpn-on-iphone-180000533.html",
          "published_at": "Wed, 14 Jan 2026 18:00:00 +0000",
          "title": "How to turn off a VPN on iPhone",
          "standfirst": "Look, virtual private networks are great — I wouldn't have made a list of the best VPNs if I didn't recommend using them. But being able to control your own technology is also important. A VPN can provide protection and peace of mind when used properly, but you may not want it active on your phone all the time.For example: Are your Google search results suddenly in German? That’s one example of what can happen if you leave your virtual location set to Berlin or Vienna. Or maybe a VPN you installed for work or to watch a single tennis match is persistently trying to keep itself active.The point is, deactivating a VPN on an iPhone can sometimes be unusually tricky, because there’s more than one off switch. Fortunately, it's not hard. There are several easy ways to disconnect from an iOS VPN or delete it entirely. If you catch it turning itself back on, I'll show you how to stop that too.Three ways to turn off your iPhone VPNI'm using a fluid definition of \"turn off\" here. Some of the steps below simply disconnect the VPN, while others remove it from your phone altogether. I'll make it clear in each section what the outcome will be.How to disconnect in the VPN appThis is the easiest way to turn off a VPN on your iPhone. First, find the VPN app that’s active, which should be on your home screen somewhere. Each app has a different interface for connecting and disconnecting, but the disconnect button should be fairly obvious — it may say the word \"disconnect\" or show a green power icon. In any case, it should be right on the home screen, without requiring any digging through menus.Example of where to find the disconnect option on a VPN's home screen.Sam Chapman for EngadgetTap the disconnect button and wait for the VPN to clearly state that it's disconnected. Check to make sure the rectangle with \"VPN\" inside has disappeared from the top of your iPhone screen. The VPN is now disconnected.How to turn off the VPN in SettingsIf you aren't sure which VPN app is active, or if its interface doesn't make it clear how to turn it off, you can shut it down from the Settings menu instead. Find the app on your home screen that looks like several interlocking gray gears and tap it.Next, scroll down and tap the VPN option. If it's not present (which it won’t be on older iOS versions), tap the General option next to another picture of a gray gear. Scroll down again and tap VPN & Device Management by yet another gray gear. Finally, tap the VPN option at the top of the screen to reach the VPN management page.Location of the VPN settings on iOS.Sam Chapman for EngadgetIf you have a VPN active, you should see an option at the top of the page labeled VPN Status. Toggle it from Connected to Not Connected. The VPN icon should disappear from the top of your screen, indicating that it's turned off.How to delete the VPN app altogetherIf you don't want the VPN on your phone at all, you can turn it off permanently by deleting both the app and the configuration. This is a lot harder to undo, so only do it if you're certain.Start by deleting the app the same way you'd get rid of any other app. Tap the icon and hold until a pop-up menu appears. Select the Remove App option in red text, then click Remove App again when prompted.Deleting a VPN on the iOS home screen.Sam Chapman for EngadgetDeleting the app should also delete the configuration, but you can verify this for yourself. Follow the process from the previous section to find the VPN settings page. If there's still a VPN profile in those settings, tap the circled letter \"i\" next to its name, then tap Delete VPN at the bottom of the screen. The VPN is now gone from your iPhone unless you re-download it from the App Store.Troubleshooting: When an iPhone VPN turns itself back onSometimes, even though you've followed all the steps, that pesky VPN rectangle is back on your screen the next time you unlock your phone. If your iOS VPN keeps turning itself back on, a few things might be happening, most of them thankfully fixable.If you did not delete the VPN, it may be turning itself back on because its settings are telling it to. Go into its preferences menu and check for a setting called \"auto-connect\" or something similar. Settings like these have the VPN connect by itself to protect users who forget to activate it manually. Toggle all auto-connect options off and the problem should stop.It's also possible that settings on the iOS side are making the VPN reconnect. Go to the VPN settings page (you'll find instructions for getting there in the previous section) and find the name of the active VPN profile. Tap the \"i\" next to it. On the next page, turn off \"connect on demand\" to stop the automatic reconnections.If you did delete the VPN, but it's still reinstalling itself and turning back on, make sure that you deleted both the app and the connection profile. Reboot your iPhone to make sure all the settings stick. If the problem persists after all this, you've either got malware disguised as a VPN or you're using a school or work phone where the VPN can't be uninstalled.If you aren't on a phone provided by a school or office, meaning you probably have malware, download an antivirus app and run a complete scan of your iPhone. This should remove any persistent files that keep reinstalling the virus. If, after all this, the VPN is still turning itself back on, I recommend burning your phone in a salt circle with a bundle of sage.When should you turn off your iPhone VPN?I encourage everyone to use a VPN every time they connect to the internet, but there are some situations where going through a VPN server is less convenient (this is the whole reason split tunneling exists). Here are a few cases in which temporarily turning off your VPN might be a good idea.The VPN isn't working. If your browsing speed is sluggish or the VPN keeps dropping the connection, your VPN server might be having problems. Disconnecting and reconnecting, even in the same location, should switch you to a different server that may work better.The VPN is causing unintended browsing errors. If you’re using mapping software or just trying to do a location-based search, having your VPN active can cause more problems than it solves. Your internet connection is unstable. A VPN adds an extra step to the process of getting online. If your phone is already struggling, the VPN might be an unnecessary complication.You're on a site that blocks all VPNs. Sites that work based on your location, including all streaming sites, may blanket-block VPNs so nothing messes with their location services. Good VPNs can get around these blocks, but even the best sometimes fail. In these cases, briefly turning off the VPN may be a good idea.Your battery is low. VPNs can put a strain on your phone's battery life. This varies with the quality of your VPN, but you may sometimes need to shut it off if your battery is in the red.How to turn off iCloud Private RelayiCloud Private Relay is not a VPN, but it's often confused for one. If you found this page because you want to turn it off, you're in luck — the steps are just as simple as turning off a VPN. Start by opening Settings, then tap your name. Scroll down and tap iCloud.Private Relay will only be active if you're an iCloud+ subscriber. If you are, tap Private Relay, then choose whether to turn it off temporarily or indefinitely.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-turn-off-a-vpn-on-iphone-180000533.html?src=rss",
          "content": "Look, virtual private networks are great — I wouldn't have made a list of the best VPNs if I didn't recommend using them. But being able to control your own technology is also important. A VPN can provide protection and peace of mind when used properly, but you may not want it active on your phone all the time.For example: Are your Google search results suddenly in German? That’s one example of what can happen if you leave your virtual location set to Berlin or Vienna. Or maybe a VPN you installed for work or to watch a single tennis match is persistently trying to keep itself active.The point is, deactivating a VPN on an iPhone can sometimes be unusually tricky, because there’s more than one off switch. Fortunately, it's not hard. There are several easy ways to disconnect from an iOS VPN or delete it entirely. If you catch it turning itself back on, I'll show you how to stop that too.Three ways to turn off your iPhone VPNI'm using a fluid definition of \"turn off\" here. Some of the steps below simply disconnect the VPN, while others remove it from your phone altogether. I'll make it clear in each section what the outcome will be.How to disconnect in the VPN appThis is the easiest way to turn off a VPN on your iPhone. First, find the VPN app that’s active, which should be on your home screen somewhere. Each app has a different interface for connecting and disconnecting, but the disconnect button should be fairly obvious — it may say the word \"disconnect\" or show a green power icon. In any case, it should be right on the home screen, without requiring any digging through menus.Example of where to find the disconnect option on a VPN's home screen.Sam Chapman for EngadgetTap the disconnect button and wait for the VPN to clearly state that it's disconnected. Check to make sure the rectangle with \"VPN\" inside has disappeared from the top of your iPhone screen. The VPN is now disconnected.How to turn off the VPN in SettingsIf you aren't sure which VPN app is active, or if its interface doesn't make it clear how to turn it off, you can shut it down from the Settings menu instead. Find the app on your home screen that looks like several interlocking gray gears and tap it.Next, scroll down and tap the VPN option. If it's not present (which it won’t be on older iOS versions), tap the General option next to another picture of a gray gear. Scroll down again and tap VPN & Device Management by yet another gray gear. Finally, tap the VPN option at the top of the screen to reach the VPN management page.Location of the VPN settings on iOS.Sam Chapman for EngadgetIf you have a VPN active, you should see an option at the top of the page labeled VPN Status. Toggle it from Connected to Not Connected. The VPN icon should disappear from the top of your screen, indicating that it's turned off.How to delete the VPN app altogetherIf you don't want the VPN on your phone at all, you can turn it off permanently by deleting both the app and the configuration. This is a lot harder to undo, so only do it if you're certain.Start by deleting the app the same way you'd get rid of any other app. Tap the icon and hold until a pop-up menu appears. Select the Remove App option in red text, then click Remove App again when prompted.Deleting a VPN on the iOS home screen.Sam Chapman for EngadgetDeleting the app should also delete the configuration, but you can verify this for yourself. Follow the process from the previous section to find the VPN settings page. If there's still a VPN profile in those settings, tap the circled letter \"i\" next to its name, then tap Delete VPN at the bottom of the screen. The VPN is now gone from your iPhone unless you re-download it from the App Store.Troubleshooting: When an iPhone VPN turns itself back onSometimes, even though you've followed all the steps, that pesky VPN rectangle is back on your screen the next time you unlock your phone. If your iOS VPN keeps turning itself back on, a few things might be happening, most of them thankfully fixable.If you did not delete the VPN, it may be turning itself back on because its settings are telling it to. Go into its preferences menu and check for a setting called \"auto-connect\" or something similar. Settings like these have the VPN connect by itself to protect users who forget to activate it manually. Toggle all auto-connect options off and the problem should stop.It's also possible that settings on the iOS side are making the VPN reconnect. Go to the VPN settings page (you'll find instructions for getting there in the previous section) and find the name of the active VPN profile. Tap the \"i\" next to it. On the next page, turn off \"connect on demand\" to stop the automatic reconnections.If you did delete the VPN, but it's still reinstalling itself and turning back on, make sure that you deleted both the app and the connection profile. Reboot your iPhone to make sure all the settings stick. If the problem persists after all this, you've either got malware disguised as a VPN or you're using a school or work phone where the VPN can't be uninstalled.If you aren't on a phone provided by a school or office, meaning you probably have malware, download an antivirus app and run a complete scan of your iPhone. This should remove any persistent files that keep reinstalling the virus. If, after all this, the VPN is still turning itself back on, I recommend burning your phone in a salt circle with a bundle of sage.When should you turn off your iPhone VPN?I encourage everyone to use a VPN every time they connect to the internet, but there are some situations where going through a VPN server is less convenient (this is the whole reason split tunneling exists). Here are a few cases in which temporarily turning off your VPN might be a good idea.The VPN isn't working. If your browsing speed is sluggish or the VPN keeps dropping the connection, your VPN server might be having problems. Disconnecting and reconnecting, even in the same location, should switch you to a different server that may work better.The VPN is causing unintended browsing errors. If you’re using mapping software or just trying to do a location-based search, having your VPN active can cause more problems than it solves. Your internet connection is unstable. A VPN adds an extra step to the process of getting online. If your phone is already struggling, the VPN might be an unnecessary complication.You're on a site that blocks all VPNs. Sites that work based on your location, including all streaming sites, may blanket-block VPNs so nothing messes with their location services. Good VPNs can get around these blocks, but even the best sometimes fail. In these cases, briefly turning off the VPN may be a good idea.Your battery is low. VPNs can put a strain on your phone's battery life. This varies with the quality of your VPN, but you may sometimes need to shut it off if your battery is in the red.How to turn off iCloud Private RelayiCloud Private Relay is not a VPN, but it's often confused for one. If you found this page because you want to turn it off, you're in luck — the steps are just as simple as turning off a VPN. Start by opening Settings, then tap your name. Scroll down and tap iCloud.Private Relay will only be active if you're an iCloud+ subscriber. If you are, tap Private Relay, then choose whether to turn it off temporarily or indefinitely.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-turn-off-a-vpn-on-iphone-180000533.html?src=rss",
          "feed_position": 3,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Proton_VPN_disconnect.PNG"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/get-three-months-of-audible-for-only-3-193859098.html",
          "published_at": "Wed, 14 Jan 2026 17:46:26 +0000",
          "title": "Get three months of Audible for only $3",
          "standfirst": "Have a hankering for some audiobooks? Audible is holding one heck of a sale right now, giving users three months of access for $3. That's a dollar per month. This is something of a winter tradition for the Amazon-owned platform and the promotion ends on January 21. An Audible subscription grants one audiobook per month to keep. This can be selected from a massive catalog of new releases and bestsellers. The collection here has just about everything. However, it's easy to plow through a single book in a month. Users also get streaming access to thousands of curated titles. Think of it like Netflix for audiobooks. The catalog is limited, but it gets the job done in a pinch. Subscribers do get access to all Audible original content and they will receive discounts on purchasing audiobooks outright. In other words, it's a neat little service and well worth a buck. The regular price is $15, so make sure to cancel at the end of that three months if you aren't enjoying the platform. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-three-months-of-audible-for-only-3-193859098.html?src=rss",
          "content": "Have a hankering for some audiobooks? Audible is holding one heck of a sale right now, giving users three months of access for $3. That's a dollar per month. This is something of a winter tradition for the Amazon-owned platform and the promotion ends on January 21. An Audible subscription grants one audiobook per month to keep. This can be selected from a massive catalog of new releases and bestsellers. The collection here has just about everything. However, it's easy to plow through a single book in a month. Users also get streaming access to thousands of curated titles. Think of it like Netflix for audiobooks. The catalog is limited, but it gets the job done in a pinch. Subscribers do get access to all Audible original content and they will receive discounts on purchasing audiobooks outright. In other words, it's a neat little service and well worth a buck. The regular price is $15, so make sure to cancel at the end of that three months if you aren't enjoying the platform. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-three-months-of-audible-for-only-3-193859098.html?src=rss",
          "feed_position": 4
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-first-gen-bose-quietcomfort-ultra-headphones-are-150-off-right-now-164826329.html",
          "published_at": "Wed, 14 Jan 2026 16:48:26 +0000",
          "title": "The first-gen Bose QuietComfort Ultra headphones are $150 off right now",
          "standfirst": "The first-generation Bose QuietComfort Ultra headphones are on sale right now for $280, marked down from $430. That 35 percent savings is an even steeper discount than we saw last year Black Friday. In our review of the first-generation Ultras, we gave them a score of 86 out of 100, noting their best-in-class active noise cancellation (ANC) and comfort. Bose improved its stock tuning for these headphones, which we could immediately tell sounded warmer and clearer. Bose has typically lagged behind the likes of Sony and Sennheiser in raw sound quality, but the first-generation QuietComfort Ultra was a big step toward catching up. Bose added \"Immersive Audio\" to this model, which is the company's take on spatial audio. The company claims this feature effectively puts you in the acoustic sweet spot of a set of stereo speakers. In our testing, we felt this didn't always make songs sound better, but it did make them louder and in some cases made certain details more noticeable. The Ultras offer up to 24 hours of battery life with ANC turned on and about 18 hours with both ANC and Immersive Audio enabled. In our testing, however, we were actually able to beat Bose's estimates for battery life. The second generation of these headphones are currently our top pick for best noise-canceling headphones, but when this older model is heavily on sale, the differences between them are less dramatic. If you're in the market for a pair of great noise-canceling cans, consider checking these out. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-first-gen-bose-quietcomfort-ultra-headphones-are-150-off-right-now-164826329.html?src=rss",
          "content": "The first-generation Bose QuietComfort Ultra headphones are on sale right now for $280, marked down from $430. That 35 percent savings is an even steeper discount than we saw last year Black Friday. In our review of the first-generation Ultras, we gave them a score of 86 out of 100, noting their best-in-class active noise cancellation (ANC) and comfort. Bose improved its stock tuning for these headphones, which we could immediately tell sounded warmer and clearer. Bose has typically lagged behind the likes of Sony and Sennheiser in raw sound quality, but the first-generation QuietComfort Ultra was a big step toward catching up. Bose added \"Immersive Audio\" to this model, which is the company's take on spatial audio. The company claims this feature effectively puts you in the acoustic sweet spot of a set of stereo speakers. In our testing, we felt this didn't always make songs sound better, but it did make them louder and in some cases made certain details more noticeable. The Ultras offer up to 24 hours of battery life with ANC turned on and about 18 hours with both ANC and Immersive Audio enabled. In our testing, however, we were actually able to beat Bose's estimates for battery life. The second generation of these headphones are currently our top pick for best noise-canceling headphones, but when this older model is heavily on sale, the differences between them are less dramatic. If you're in the market for a pair of great noise-canceling cans, consider checking these out. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-first-gen-bose-quietcomfort-ultra-headphones-are-150-off-right-now-164826329.html?src=rss",
          "feed_position": 5
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-mac-mini-m4-is-back-on-sale-for-499-141615907.html",
          "published_at": "Wed, 14 Jan 2026 16:06:26 +0000",
          "title": "The Mac mini M4 is back on sale for $499",
          "standfirst": "The holiday season may be behind us, but that doesn't mean you can't still find good deals on some of our favorite tech. Take the Apple Mac mini M4, which is on sale for $100 off. The 17 percent discount gives you 16GB of RAM and 256GB of SSD for $499, which is only about $20 more than its Black Friday sale price. Its beefier models are also on sale: opting for 512GB of SSD will cost you $689, down from $799, while also upping your RAM to 24GB is available for $890, dropping from $999. We gave the Apple Mac mini M4 a 90 in our review thanks in large part to its powerful chip. The M4 works very fast despite being in such a small device. It also offers front-facing headphone and USB-C ports. You can further upgrade to the Apple M4 Pro chip for $1,270, down from $1,399 — a nine percent discount. The Pro model also has Thunderbolt 5 support. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-mac-mini-m4-is-back-on-sale-for-499-141615907.html?src=rss",
          "content": "The holiday season may be behind us, but that doesn't mean you can't still find good deals on some of our favorite tech. Take the Apple Mac mini M4, which is on sale for $100 off. The 17 percent discount gives you 16GB of RAM and 256GB of SSD for $499, which is only about $20 more than its Black Friday sale price. Its beefier models are also on sale: opting for 512GB of SSD will cost you $689, down from $799, while also upping your RAM to 24GB is available for $890, dropping from $999. We gave the Apple Mac mini M4 a 90 in our review thanks in large part to its powerful chip. The M4 works very fast despite being in such a small device. It also offers front-facing headphone and USB-C ports. You can further upgrade to the Apple M4 Pro chip for $1,270, down from $1,399 — a nine percent discount. The Pro model also has Thunderbolt 5 support. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-mac-mini-m4-is-back-on-sale-for-499-141615907.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/gemini-can-now-pull-context-the-rest-of-your-google-apps-if-you-let-it-160039468.html",
          "published_at": "Wed, 14 Jan 2026 16:00:39 +0000",
          "title": "Gemini can now pull context the rest of your Google apps, if you let it",
          "standfirst": "Gemini is adding a feature that’s designed to feel more tailored to individual users. Once enabled, \"Personal Intelligence\" can pull context from across your Google ecosystem, including Gmail, Google Photos, Search and YouTube History, to gain specific insight that will shape its answers and recommendations. Personal Intelligence is available starting today in the US for Google AI Pro and Ultra subscribers. The feature is opt-in only and is off by default. Google Google says users will have the ability to control what apps Gemini pulls from and, in the future, which chats it uses Personal Intelligence for. The company says this new feature might still make some mistakes, such as “over-personalization” where it draws connections between unrelated things. According to Google, Gemini will not train directly on the data it pulls for personalization like your photos and emails, but will instead train on your prompts and its responses. Users can also prompt Gemini to \"try again\" without personalization and will have the option to delete chat histories. For now, Personal Intelligence works in the Gemini app across web, Android and iOS for personal Google accounts. Google says it’s coming to Search’s AI Mode soon, with plans to expand to more countries and the free tier down the line. Google has been on a tear integrating Gemini into everything, including Gmail, TVs and Chrome on mobile. This week, Apple announced that Siri AI will be powered by Gemini as part of a multi-year collaboration. AI remains an imperfect tool, and Google's AI has a long history of malfunctions like explaining made-up idioms, calling itself a \"failure\" in a depressing doom loop and generating images of the Founding Fathers as people of color.This article originally appeared on Engadget at https://www.engadget.com/ai/gemini-can-now-pull-context-the-rest-of-your-google-apps-if-you-let-it-160039468.html?src=rss",
          "content": "Gemini is adding a feature that’s designed to feel more tailored to individual users. Once enabled, \"Personal Intelligence\" can pull context from across your Google ecosystem, including Gmail, Google Photos, Search and YouTube History, to gain specific insight that will shape its answers and recommendations. Personal Intelligence is available starting today in the US for Google AI Pro and Ultra subscribers. The feature is opt-in only and is off by default. Google Google says users will have the ability to control what apps Gemini pulls from and, in the future, which chats it uses Personal Intelligence for. The company says this new feature might still make some mistakes, such as “over-personalization” where it draws connections between unrelated things. According to Google, Gemini will not train directly on the data it pulls for personalization like your photos and emails, but will instead train on your prompts and its responses. Users can also prompt Gemini to \"try again\" without personalization and will have the option to delete chat histories. For now, Personal Intelligence works in the Gemini app across web, Android and iOS for personal Google accounts. Google says it’s coming to Search’s AI Mode soon, with plans to expand to more countries and the free tier down the line. Google has been on a tear integrating Gemini into everything, including Gmail, TVs and Chrome on mobile. This week, Apple announced that Siri AI will be powered by Gemini as part of a multi-year collaboration. AI remains an imperfect tool, and Google's AI has a long history of malfunctions like explaining made-up idioms, calling itself a \"failure\" in a depressing doom loop and generating images of the Founding Fathers as people of color.This article originally appeared on Engadget at https://www.engadget.com/ai/gemini-can-now-pull-context-the-rest-of-your-google-apps-if-you-let-it-160039468.html?src=rss",
          "feed_position": 8,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/38ff43e0-f156-11f0-b7ef-806c828a134c"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-from-ugreen-is-32-percent-off-right-now-214707806.html",
          "published_at": "Wed, 14 Jan 2026 15:06:26 +0000",
          "title": "Our favorite 3-in-1 wireless charger from UGreen is 32 percent off right now",
          "standfirst": "You can easily spruce up your nightstand or desk by decluttering a bit, replacing some of those annoying charging cables with a good wireless charging setup. One of our favorites that can handle three devices at once is the UGREEN MagFlow Qi2 3-in-1 Charger Station 25W. Normally $140, it's on sale right now for $95; that's 32 percent off and only about $5 more than its record-low price. This is our top pick for a 3-in-1 charging pad thanks to its versatility. The UGREEN can work equally well as a permanent fixture in your home or act as a portable charging station. It boasts a foldable design and has smart little design details to keep it feeling like a premium product. The Qi2 25W charging works across a range of iPhone models and accessories, such as AirPods. There's also a dedicated part of the pad's design for an Apple Watch, which uses a proprietary charging standard, to power up too. Just note that you'll need a newer model of phone and the latest iOS 26 in order to take full advantage of the 25W charging capability. The wireless pad also comes with both a charging plug and a cable. We felt this UGREEN model was a great value at $140, so being able to snag one for a third of the usual price is an even better deal. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-from-ugreen-is-32-percent-off-right-now-214707806.html?src=rss",
          "content": "You can easily spruce up your nightstand or desk by decluttering a bit, replacing some of those annoying charging cables with a good wireless charging setup. One of our favorites that can handle three devices at once is the UGREEN MagFlow Qi2 3-in-1 Charger Station 25W. Normally $140, it's on sale right now for $95; that's 32 percent off and only about $5 more than its record-low price. This is our top pick for a 3-in-1 charging pad thanks to its versatility. The UGREEN can work equally well as a permanent fixture in your home or act as a portable charging station. It boasts a foldable design and has smart little design details to keep it feeling like a premium product. The Qi2 25W charging works across a range of iPhone models and accessories, such as AirPods. There's also a dedicated part of the pad's design for an Apple Watch, which uses a proprietary charging standard, to power up too. Just note that you'll need a newer model of phone and the latest iOS 26 in order to take full advantage of the 25W charging capability. The wireless pad also comes with both a charging plug and a cable. We felt this UGREEN model was a great value at $140, so being able to snag one for a third of the usual price is an even better deal. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-from-ugreen-is-32-percent-off-right-now-214707806.html?src=rss",
          "feed_position": 10
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/pick-up-apples-25w-magsafe-charger-while-its-down-to-30-141707867.html",
          "published_at": "Wed, 14 Jan 2026 14:30:37 +0000",
          "title": "Pick up Apple's 25W MagSafe charger while it's down to $30",
          "standfirst": "If you want a wireless charger for your iPhone and prefer to stick with Apple, Amazon has a sale that may pique your interest. The retailer is selling the one meter Apple Magsafe charger for $30, saving you $10 off the regular price, while also selling the two meter model for $40 ($10 off). If you have an iPhone 16, iPhone 17 or iPhone Air, this cable can charge your device at 25W as long as it's connected to a 30W power adapter on the other end. While you'll need a more recent iPhone to get the fastest MagSafe charging speeds, the charger can wirelessly top up the battery of any iPhone from the last eight years (iPhone 8 and later). With older iPhones, the charging speed tops out at 15W. The cable works with AirPods wireless charging cases too — it's certified for Qi2.2 and Qi charging. The MagSafe charger is one of our favorite iPhone accessories, and would pair quite nicely with your new iPhone if you're picking up one of the latest models. If you're on the fence about that, be sure to check out our reviews of the iPhone 17, iPhone Pro/Pro Max and iPhone Air. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-apples-25w-magsafe-charger-while-its-down-to-30-141707867.html?src=rss",
          "content": "If you want a wireless charger for your iPhone and prefer to stick with Apple, Amazon has a sale that may pique your interest. The retailer is selling the one meter Apple Magsafe charger for $30, saving you $10 off the regular price, while also selling the two meter model for $40 ($10 off). If you have an iPhone 16, iPhone 17 or iPhone Air, this cable can charge your device at 25W as long as it's connected to a 30W power adapter on the other end. While you'll need a more recent iPhone to get the fastest MagSafe charging speeds, the charger can wirelessly top up the battery of any iPhone from the last eight years (iPhone 8 and later). With older iPhones, the charging speed tops out at 15W. The cable works with AirPods wireless charging cases too — it's certified for Qi2.2 and Qi charging. The MagSafe charger is one of our favorite iPhone accessories, and would pair quite nicely with your new iPhone if you're picking up one of the latest models. If you're on the fence about that, be sure to check out our reviews of the iPhone 17, iPhone Pro/Pro Max and iPhone Air. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-apples-25w-magsafe-charger-while-its-down-to-30-141707867.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/monarch-money-deal-new-users-can-get-one-year-of-access-for-only-50-204507409.html",
          "published_at": "Wed, 14 Jan 2026 13:50:35 +0000",
          "title": "Monarch Money deal: New users can get one year of access for only $50",
          "standfirst": "A new year is the perfect time to get your spending in order, and if you're not trying to build your own spreadsheet, budgeting apps are one of the best ways to do it. To save yourself some money in the process, you can pick up a year-long subscription to Monarch Money, one of Engadget's favorite budgeting apps, for just $50 if you use code NEWYEAR2026 at checkout and you're a new subscriber. That's a 50 percent discount on the service's normal $100 price. Monarch Money makes for a capable and detailed budgeting companion. You can use the service via apps for iOS, Android, iPadOS or the web, and Monarch also offers a Chrome extension that can sync your Amazon and Target transactions and automatically categorize them. Like other budgeting apps, Monarch Money lets you connect multiple financial accounts and track your money based on where you spend it over time. Monarch offers two different approaches to tracking budgeting (flexible and category budgeting) depending on what fits your life best, and the ability to add a budget widget on your phone so you can know how you're tracking that month. How budgeting apps turn your raw transactions into visuals you can understand at a glance is one of the big things that differentiates one app from another, and Monarch Money offers multiple graphs and charts to look at for things like spending, investments or categories of your choice based on how you've labelled your expenses. The app can also monitor the spending of you and your partner all in one place, to make it easier to plan together. The main drawbacks Engadget found in testing Monarch Money were the app's learning curve, and the differences in features (and bugginess) between Monarch's web and mobile versions. Still, for 50 percent off, the Monarch Money is well worth experimenting with if you're trying to save money in 2026, especially if you want to do it collaboratively with a partner. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/apps/monarch-money-deal-new-users-can-get-one-year-of-access-for-only-50-204507409.html?src=rss",
          "content": "A new year is the perfect time to get your spending in order, and if you're not trying to build your own spreadsheet, budgeting apps are one of the best ways to do it. To save yourself some money in the process, you can pick up a year-long subscription to Monarch Money, one of Engadget's favorite budgeting apps, for just $50 if you use code NEWYEAR2026 at checkout and you're a new subscriber. That's a 50 percent discount on the service's normal $100 price. Monarch Money makes for a capable and detailed budgeting companion. You can use the service via apps for iOS, Android, iPadOS or the web, and Monarch also offers a Chrome extension that can sync your Amazon and Target transactions and automatically categorize them. Like other budgeting apps, Monarch Money lets you connect multiple financial accounts and track your money based on where you spend it over time. Monarch offers two different approaches to tracking budgeting (flexible and category budgeting) depending on what fits your life best, and the ability to add a budget widget on your phone so you can know how you're tracking that month. How budgeting apps turn your raw transactions into visuals you can understand at a glance is one of the big things that differentiates one app from another, and Monarch Money offers multiple graphs and charts to look at for things like spending, investments or categories of your choice based on how you've labelled your expenses. The app can also monitor the spending of you and your partner all in one place, to make it easier to plan together. The main drawbacks Engadget found in testing Monarch Money were the app's learning curve, and the differences in features (and bugginess) between Monarch's web and mobile versions. Still, for 50 percent off, the Monarch Money is well worth experimenting with if you're trying to save money in 2026, especially if you want to do it collaboratively with a partner. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/apps/monarch-money-deal-new-users-can-get-one-year-of-access-for-only-50-204507409.html?src=rss",
          "feed_position": 14
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/elevation-labs-extended-battery-airtag-case-is-down-to-only-16-162308748.html",
          "published_at": "Wed, 14 Jan 2026 13:15:35 +0000",
          "title": "Elevation Lab's extended battery AirTag case is down to only $16",
          "standfirst": "AirTags already have a decently long battery life, but you will end up needing to replace the coin cell every two years or so. If you don't even want to be bothered with that, Elevation Lab made just the accessory for you: its AirTag battery case that can power the tracker for up to 10 years is on sale for 30 percent off. You can pick one up for only $16, and it's available in two- and four-packs as well at a discount. The TimeCapsule case uses two AA batteries to offer up to 14 times the lifespan of the CR2032 battery that powers an AirTag. The company based those estimates on Energizer Ultimate Lithium batteries, so your mileage may vary. Once an AirTag is seated inside the case, which is a compact 4.45 x 1.57 inches, it is sealed shut with four screws at the corners. The case is fiber-reinforced, according to Elevation Lab, and rated IP69 waterproof. The company says it’s intended for use cases where you might place an AirTag for long periods of time, like in a vehicle, a piece of luggage or a work bag. We've already got a couple of Elevation Lab products on our list for best AirTag accessories, so while we haven't reviewed the battery case, we tend to like this company's products. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/elevation-labs-extended-battery-airtag-case-is-down-to-only-16-162308748.html?src=rss",
          "content": "AirTags already have a decently long battery life, but you will end up needing to replace the coin cell every two years or so. If you don't even want to be bothered with that, Elevation Lab made just the accessory for you: its AirTag battery case that can power the tracker for up to 10 years is on sale for 30 percent off. You can pick one up for only $16, and it's available in two- and four-packs as well at a discount. The TimeCapsule case uses two AA batteries to offer up to 14 times the lifespan of the CR2032 battery that powers an AirTag. The company based those estimates on Energizer Ultimate Lithium batteries, so your mileage may vary. Once an AirTag is seated inside the case, which is a compact 4.45 x 1.57 inches, it is sealed shut with four screws at the corners. The case is fiber-reinforced, according to Elevation Lab, and rated IP69 waterproof. The company says it’s intended for use cases where you might place an AirTag for long periods of time, like in a vehicle, a piece of luggage or a work bag. We've already got a couple of Elevation Lab products on our list for best AirTag accessories, so while we haven't reviewed the battery case, we tend to like this company's products. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/elevation-labs-extended-battery-airtag-case-is-down-to-only-16-162308748.html?src=rss",
          "feed_position": 17
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/get-one-month-of-the-disney-and-hulu-bundle-for-only-10-192814218.html",
          "published_at": "Wed, 14 Jan 2026 13:04:33 +0000",
          "title": "Get one month of the Disney+ and Hulu bundle for only $10",
          "standfirst": "The peak time for deals on streaming services — the holiday shopping season — has come and gone, but Disney is back with a fresh offer for the new year. New and eligible returning subscribers can get one month of the ad-supported Disney+ Hulu bundle for just $10. That's $3 off the usual monthly rate for the bundle, and more than 58 percent off if you consider the prices for each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-one-month-of-the-disney-and-hulu-bundle-for-only-10-192814218.html?src=rss",
          "content": "The peak time for deals on streaming services — the holiday shopping season — has come and gone, but Disney is back with a fresh offer for the new year. New and eligible returning subscribers can get one month of the ad-supported Disney+ Hulu bundle for just $10. That's $3 off the usual monthly rate for the bundle, and more than 58 percent off if you consider the prices for each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-one-month-of-the-disney-and-hulu-bundle-for-only-10-192814218.html?src=rss",
          "feed_position": 18
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-usb-c-hub-120051833.html",
          "published_at": "Wed, 14 Jan 2026 10:01:25 +0000",
          "title": "The best USB-C hub for 2026",
          "standfirst": "Having fewer ports makes laptops and tablets lighter and more affordable — but that also cuts down on your connectivity options. If you’ve got a MacBook Air, a slim Chromebook or a tablet you’d like to get more utility out of, a USB-C hub can help. Using just a single port on your device, these multiport adapters will let you hook up screens, tap into Ethernet cables, connect mice and keyboards, and transfer data to drives and memory cards. Most also give you a way to power your device through the hub to maximize port availability. We tested over a dozen models to come up with picks for every budget. Here are the best USB-C hubs, according to our tests. Table of contents Best USB-C hubs for 2026 What to look for in a USB-C hub How we test USB-C hubs Other hubs we tested Recent updates Best USB-C hubs for 2026 What to look for in a USB-C hub Hub vs docking station The first thing to decide is whether you need a USB-C hub or a USB-C docking station. There’s no set standard for what differentiates the two, but docking stations tend to have more ports, offer a separate DC power adapter and cost more, with some reaching upwards of $400. We have a separate guide to the best docking stations to check out if you’re looking for something bigger than what we’re discussing here. USB-C hubs, in contrast, have between four and 10 ports, can support pass-through charging and typically cost between $30 and $150. Hubs, sometimes also called dongles or even multiport adapters, make more sense for smaller setups with just a few peripherals, such as a monitor, a wired keyboard and mouse, and the occasional external drive. They’re also more portable, since they’re small and require no dedicated power. That could be useful if you change work locations but want to bring your accessories with you, or if you want to replace your laptop with a more powerful tablet. A docking station or Thunderbolt dock makes more sense for someone who needs a robust setup for their laptop, including multiple external monitors, webcams, stream decks, microphones and so on. Both docks and hubs make it easy to grab your laptop off your desk for a meeting or other brief relocation and when you get back, you only need to plug in one cable to get all your accessories reconnected. Of course, if you just need to plug in one peripheral, you may not need a hub or a dock, a simple USB-C adapter, like HDMI to USB-C or USB-A to USB-C, may do the trick. Ports For a USB-C hub to work, it needs to connect to a port on your laptop or tablet that supports video, data and power — all of which is covered by anything listed as USB 3.0 or better, including USB4 and Thunderbolt 3 and Thunderbolt 4. The port, of course, needs to be Type-C as well. The sea of laptops out there is vast, so it’s hard to make generalizations, but modern laptops, including Windows and Apple models, should have at least one USB-C port that will suffice, and indeed, every one of our top picks for the best laptops do — including our top pick, the M4 MacBook Air. Next, it’s a matter of finding a good USB-C hub that has the right connections for your needs. Most hubs offer some combo of HDMI, USB, SD card reader, Ethernet and 3.5 mm ports. If you have a 4K monitor and would like at least a 60Hz refresh rate, you’ll need a hub with an HDMI 2.0 port — HDMI 1.4 only goes up to 30Hz. HDMI 2.1 will handle 4K at up to 120Hz, but hubs that have adopted that standard aren’t as common just yet. Keep in mind that a low refresh rate can cause your screen to feel laggy, making your mouse appear glitchy and your webcam movements to look delayed. Additional USB ports on these accessories are usually USB Type-A or USB Type-C. They can support data with different transfer rates, typically 5Gbps or 10Gbps. Some ports only handle passthrough power and no data, and some can do data, power and video, so it’s best to check the spec list to make sure you’re getting the support you need. Keep in mind that a hub may bill itself as a 7-in-1, but one of those ports may not be usable for anything other than charging. Standard SD and microSD cards are useful for transferring data from cameras and the like or for offloading files from your hard drive, and many hubs have those slots. Ethernet ports may deliver faster internet speeds than your Wi-Fi and a hub with a 3.5mm jack can bring back the wired headphone connection that some laptops have ditched. Power delivery Nearly all of the USB-C hubs I tested support passthrough charging. That means if your laptop or tablet only charges via USB, you don’t have to take up another port on your laptop to keep everything topped up. Unlike a docking station, powering a hub is optional. The one exception is if you want to close the lid on your laptop while you work on an external monitor. Most computers will go into sleep mode if the lid is closed without power, so either the laptop or the hub will need to be plugged into the wall to prevent that from happening. Many of the newer hubs include a 100W USB-C power delivery (PD) port, with a healthy 80 to 85 watts going to your Mac, PC, iPad or Android tablet (the hubs take a little of the juice for themselves, hence the 15-watt or so difference). In my tests, a powered USB hub ran hotter than when it wasn't passing the charge through, so I prefer to power the computer directly using its own charger. But for tablets or other devices with no extra ports, that PD option is important. Some PD ports are also data ports — which is both good and bad. On one hand, it feels wasteful to use a perfectly good data port just for boring old electricity. But on the other hand, USB-C connections that only carry a charge are less versatile, and it makes it seem like it has more accessory hookups than it actually does. Design There’s surprisingly little design variation among hubs. Most look like a flat slab, a little smaller than a smartphone, and have an attached Type-C host cable. The hues range from a silvery black to a silvery gray. Some are thinner than others, some have all ports on one edge and some have ports on both sides. All of this is just to say that aesthetics probably won’t make or break your buying decision. One variation that could tip the scales is the length of the cable. A longer one will give you more freedom as you arrange the hub on your desk, potentially even letting you hide it behind your laptop. Or you may prefer a shorter one to keep the hub neatly set beside your laptop. How we test USB-C hubs Before we test anything, we take a look at what’s available and how they’ve been received by shoppers, forum-goers and other publications. I became familiar with a few reputable brands when I was testing docking stations, so I looked into hubs from those companies as well. I focused on items that would help with an average day of productivity — not high-end setups or demanding gaming situations. Once I settled on a dozen or so that would make good candidates, I had them shipped to my humble office in the desert and started testing them out over the course of a few weeks. I used an M1 MacBook Pro running MacOS Sonoma as the host computer and plugged in accessories that include a 4K Dell monitor, a ZSA USB-C ergo keyboard, a Logitech USB-A gaming mouse, an Elgato USB-C 4K webcam, a Logitech streaming light, a USB-A 3.0 Sandisk thumb drive, a USB-C Samsung T7 Shield external drive and a pair of wired headphones I got for free on an airplane (I should probably invest in some wired headphones, but the cord dangling on my chest drives me nutty so all my earbuds are wireless). I used high-end HDMI and USB-C cables to ensure that any data or connectivity issues weren’t related to my equipment. Then I put each USB-C hub through a gamut of basic tests. I looked at what could be plugged in at once, the resolution on the monitor, data transfer speeds, the overall build quality of the hub and general usability factors, like the placement of the ports and the length of the cords. And, finally, the price-to-value ratio helped determine the best ones for a few different use cases. Other hubs we tested HyperDrive Next 10 Port USB-C Hub There’s a lot to like about HyperDrive’s Next 10 Port USB-C Hub. The tethered cable is a lavish 13 inches long, the HDMI 2.0 port outputs clear and crisp 4K visuals at 60Hz and the high-speed data transfers are great. It has the coveted two USB-C data ports plus a PD port, and there’s even a headphone jack. The only thing that holds back a full-throated endorsement is the way our unit handled a streaming light. Having it on at full brightness made the webcam flicker every time. The issue went away at 75 percent brightness, but the same problem didn’t happen on any other hub I tested. Anker 341 USB-C Hub (7-in-1) There’s nothing wrong with the Anker 341 USB-C hub. In fact it’s a current recommendation in our iPad accessories guide and it comes at a great $35 price. It gives you two USB-A ports as well as SD slots. But at this point, a 1.4 HDMI connection, which only supports 4K resolution at 30Hz feels a little retro. There’s also just a single USB-C downstream port and the data transfer tests proved to be a touch slower than the other hubs. But if you’ve got a lower resolution monitor and don’t need more than one USB-C, you won’t be disappointed with it. Anker 555 8-in-1 It was a tough call between the UGreen Revodoc Pro 109 and the Anker 555 8-in-1 for our top recommendation. Both have a similar port array with an HDMI, Ethernet, two USB Type A, a PD USB-C and a USB-C 3.2 on the 555. And the Anker USB-C hub is $15 cheaper. We went with the UGreen hub for its more premium build, extra USB-A port and longer cord that gives you two extra inches to work with. But if you want to save a few bucks this hub is a worthwhile pick. Startech 4-Port USB-C Hub (data only) I only became aware of Startech when I started researching for this guide. The quality is decent and the yellow accents are a welcome bit of color in the otherwise very gray world of hubs. The performance is solid, with no hiccups that I encountered. The brand’s 4-Port USB-C Hub has a long cord that wraps around the hub itself, which is unique. It doesn’t bother with power delivery, which isn’t an issue if you can power your computer directly. But the four USB ports (three Type-A and one Type-C) max out at 5Gbps and there’s no HDMI connector. It goes for $46, and unfortunately for it, there are cheaper ways to get a few more USB ports for your setup. Recent updates January 2026: Added an honorable mention from Satechi. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-usb-c-hub-120051833.html?src=rss",
          "content": "Having fewer ports makes laptops and tablets lighter and more affordable — but that also cuts down on your connectivity options. If you’ve got a MacBook Air, a slim Chromebook or a tablet you’d like to get more utility out of, a USB-C hub can help. Using just a single port on your device, these multiport adapters will let you hook up screens, tap into Ethernet cables, connect mice and keyboards, and transfer data to drives and memory cards. Most also give you a way to power your device through the hub to maximize port availability. We tested over a dozen models to come up with picks for every budget. Here are the best USB-C hubs, according to our tests. Table of contents Best USB-C hubs for 2026 What to look for in a USB-C hub How we test USB-C hubs Other hubs we tested Recent updates Best USB-C hubs for 2026 What to look for in a USB-C hub Hub vs docking station The first thing to decide is whether you need a USB-C hub or a USB-C docking station. There’s no set standard for what differentiates the two, but docking stations tend to have more ports, offer a separate DC power adapter and cost more, with some reaching upwards of $400. We have a separate guide to the best docking stations to check out if you’re looking for something bigger than what we’re discussing here. USB-C hubs, in contrast, have between four and 10 ports, can support pass-through charging and typically cost between $30 and $150. Hubs, sometimes also called dongles or even multiport adapters, make more sense for smaller setups with just a few peripherals, such as a monitor, a wired keyboard and mouse, and the occasional external drive. They’re also more portable, since they’re small and require no dedicated power. That could be useful if you change work locations but want to bring your accessories with you, or if you want to replace your laptop with a more powerful tablet. A docking station or Thunderbolt dock makes more sense for someone who needs a robust setup for their laptop, including multiple external monitors, webcams, stream decks, microphones and so on. Both docks and hubs make it easy to grab your laptop off your desk for a meeting or other brief relocation and when you get back, you only need to plug in one cable to get all your accessories reconnected. Of course, if you just need to plug in one peripheral, you may not need a hub or a dock, a simple USB-C adapter, like HDMI to USB-C or USB-A to USB-C, may do the trick. Ports For a USB-C hub to work, it needs to connect to a port on your laptop or tablet that supports video, data and power — all of which is covered by anything listed as USB 3.0 or better, including USB4 and Thunderbolt 3 and Thunderbolt 4. The port, of course, needs to be Type-C as well. The sea of laptops out there is vast, so it’s hard to make generalizations, but modern laptops, including Windows and Apple models, should have at least one USB-C port that will suffice, and indeed, every one of our top picks for the best laptops do — including our top pick, the M4 MacBook Air. Next, it’s a matter of finding a good USB-C hub that has the right connections for your needs. Most hubs offer some combo of HDMI, USB, SD card reader, Ethernet and 3.5 mm ports. If you have a 4K monitor and would like at least a 60Hz refresh rate, you’ll need a hub with an HDMI 2.0 port — HDMI 1.4 only goes up to 30Hz. HDMI 2.1 will handle 4K at up to 120Hz, but hubs that have adopted that standard aren’t as common just yet. Keep in mind that a low refresh rate can cause your screen to feel laggy, making your mouse appear glitchy and your webcam movements to look delayed. Additional USB ports on these accessories are usually USB Type-A or USB Type-C. They can support data with different transfer rates, typically 5Gbps or 10Gbps. Some ports only handle passthrough power and no data, and some can do data, power and video, so it’s best to check the spec list to make sure you’re getting the support you need. Keep in mind that a hub may bill itself as a 7-in-1, but one of those ports may not be usable for anything other than charging. Standard SD and microSD cards are useful for transferring data from cameras and the like or for offloading files from your hard drive, and many hubs have those slots. Ethernet ports may deliver faster internet speeds than your Wi-Fi and a hub with a 3.5mm jack can bring back the wired headphone connection that some laptops have ditched. Power delivery Nearly all of the USB-C hubs I tested support passthrough charging. That means if your laptop or tablet only charges via USB, you don’t have to take up another port on your laptop to keep everything topped up. Unlike a docking station, powering a hub is optional. The one exception is if you want to close the lid on your laptop while you work on an external monitor. Most computers will go into sleep mode if the lid is closed without power, so either the laptop or the hub will need to be plugged into the wall to prevent that from happening. Many of the newer hubs include a 100W USB-C power delivery (PD) port, with a healthy 80 to 85 watts going to your Mac, PC, iPad or Android tablet (the hubs take a little of the juice for themselves, hence the 15-watt or so difference). In my tests, a powered USB hub ran hotter than when it wasn't passing the charge through, so I prefer to power the computer directly using its own charger. But for tablets or other devices with no extra ports, that PD option is important. Some PD ports are also data ports — which is both good and bad. On one hand, it feels wasteful to use a perfectly good data port just for boring old electricity. But on the other hand, USB-C connections that only carry a charge are less versatile, and it makes it seem like it has more accessory hookups than it actually does. Design There’s surprisingly little design variation among hubs. Most look like a flat slab, a little smaller than a smartphone, and have an attached Type-C host cable. The hues range from a silvery black to a silvery gray. Some are thinner than others, some have all ports on one edge and some have ports on both sides. All of this is just to say that aesthetics probably won’t make or break your buying decision. One variation that could tip the scales is the length of the cable. A longer one will give you more freedom as you arrange the hub on your desk, potentially even letting you hide it behind your laptop. Or you may prefer a shorter one to keep the hub neatly set beside your laptop. How we test USB-C hubs Before we test anything, we take a look at what’s available and how they’ve been received by shoppers, forum-goers and other publications. I became familiar with a few reputable brands when I was testing docking stations, so I looked into hubs from those companies as well. I focused on items that would help with an average day of productivity — not high-end setups or demanding gaming situations. Once I settled on a dozen or so that would make good candidates, I had them shipped to my humble office in the desert and started testing them out over the course of a few weeks. I used an M1 MacBook Pro running MacOS Sonoma as the host computer and plugged in accessories that include a 4K Dell monitor, a ZSA USB-C ergo keyboard, a Logitech USB-A gaming mouse, an Elgato USB-C 4K webcam, a Logitech streaming light, a USB-A 3.0 Sandisk thumb drive, a USB-C Samsung T7 Shield external drive and a pair of wired headphones I got for free on an airplane (I should probably invest in some wired headphones, but the cord dangling on my chest drives me nutty so all my earbuds are wireless). I used high-end HDMI and USB-C cables to ensure that any data or connectivity issues weren’t related to my equipment. Then I put each USB-C hub through a gamut of basic tests. I looked at what could be plugged in at once, the resolution on the monitor, data transfer speeds, the overall build quality of the hub and general usability factors, like the placement of the ports and the length of the cords. And, finally, the price-to-value ratio helped determine the best ones for a few different use cases. Other hubs we tested HyperDrive Next 10 Port USB-C Hub There’s a lot to like about HyperDrive’s Next 10 Port USB-C Hub. The tethered cable is a lavish 13 inches long, the HDMI 2.0 port outputs clear and crisp 4K visuals at 60Hz and the high-speed data transfers are great. It has the coveted two USB-C data ports plus a PD port, and there’s even a headphone jack. The only thing that holds back a full-throated endorsement is the way our unit handled a streaming light. Having it on at full brightness made the webcam flicker every time. The issue went away at 75 percent brightness, but the same problem didn’t happen on any other hub I tested. Anker 341 USB-C Hub (7-in-1) There’s nothing wrong with the Anker 341 USB-C hub. In fact it’s a current recommendation in our iPad accessories guide and it comes at a great $35 price. It gives you two USB-A ports as well as SD slots. But at this point, a 1.4 HDMI connection, which only supports 4K resolution at 30Hz feels a little retro. There’s also just a single USB-C downstream port and the data transfer tests proved to be a touch slower than the other hubs. But if you’ve got a lower resolution monitor and don’t need more than one USB-C, you won’t be disappointed with it. Anker 555 8-in-1 It was a tough call between the UGreen Revodoc Pro 109 and the Anker 555 8-in-1 for our top recommendation. Both have a similar port array with an HDMI, Ethernet, two USB Type A, a PD USB-C and a USB-C 3.2 on the 555. And the Anker USB-C hub is $15 cheaper. We went with the UGreen hub for its more premium build, extra USB-A port and longer cord that gives you two extra inches to work with. But if you want to save a few bucks this hub is a worthwhile pick. Startech 4-Port USB-C Hub (data only) I only became aware of Startech when I started researching for this guide. The quality is decent and the yellow accents are a welcome bit of color in the otherwise very gray world of hubs. The performance is solid, with no hiccups that I encountered. The brand’s 4-Port USB-C Hub has a long cord that wraps around the hub itself, which is unique. It doesn’t bother with power delivery, which isn’t an issue if you can power your computer directly. But the four USB ports (three Type-A and one Type-C) max out at 5Gbps and there’s no HDMI connector. It goes for $46, and unfortunately for it, there are cheaper ways to get a few more USB ports for your setup. Recent updates January 2026: Added an honorable mention from Satechi. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-usb-c-hub-120051833.html?src=rss",
          "feed_position": 22,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2024-08/42b836f0-5376-11ef-aff7-f63093d21d28"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/why-egnyte-keeps-hiring-junior-engineers-despite-the-rise-of-ai-coding-tools",
          "published_at": "Tue, 13 Jan 2026 21:00:00 GMT",
          "title": "Why Egnyte keeps hiring junior engineers despite the rise of AI coding tools",
          "standfirst": "Egnyte, the $1.5 billion cloud content governance company, has embedded AI coding tools across its global team of more than 350 developers — but not to reduce headcount. Instead, the company continues to hire junior engineers, using AI to accelerate onboarding, deepen codebase understanding, and shorten the path from junior to senior contributor. The approach challenges a dominant 2025 narrative that automation will replace developers, showing instead how enterprises are using AI to scale engineering capacity while keeping humans firmly in the loop.“To have engineers disappear or us not hiring junior engineers doesn&#x27;t look like the likely outcome,” Amrit Jassal, Egnyte CTO and co-founder, told VentureBeat. “You&#x27;ve got to have people, you&#x27;re training and doing all types of succession planning. The junior engineer of today is the senior engineer of tomorrow.”How Egnyte coders are using AI — without ceding controlEgnyte — which has more than 22,000 users including NASDAQ, Red Bull, and BuzzFeed — has rolled out Claude Code, Cursor, Augment, and Gemini CLI coding tools across its developer base to support its core business strategies and expand its newer AI offerings like customer-facing copilots and customizable AI agents. Devs use these tools across a variety of tasks, the simplest of which include data retrieval, code comprehension, smart search, and code lookup. Egnyte’s code base has lots of Java code, which uses numerous libraries, each with different versions, Jassal explained. AI tools are great for peer-to-peer programming, helping new users get a lay of the land, or existing users probe into different code repositories. “We have a pretty big code base, right?” Jassal said. “Let&#x27;s say you&#x27;re looking at an iOS application, but you&#x27;re not well versed; you will fire up Google CLI or an Augment, and ask it to discover the code base.”Some Egnyte devs are moving into automatic pull request summaries, which provide simple overviews of code changes that essentially explain the “what,” “how,” and “why” of proposed modifications. “But obviously, any change that&#x27;s made, we don&#x27;t want to hear that AI made the change; it has to be that developer made the change,” Jassal pointed out. “I would not trust AI to commit to the production code base.” Commits still pass through human review and security validation, and anything red-flagged is escalated to senior engineers. Devs are warned of the dangers of settling into autopilot mode or blindly trusting code. A model may not have been exposed to, or given enough samples of, certain coding components and infrastructure in its training. Another growing, and closely monitored, use case for AI is unit testing, where code components are run in isolation to ensure they work as intended. “At the end of the day, it is a productivity improvement tool,” he said. “It is really a continuation, it&#x27;s like any other tool, it&#x27;s not some magic.”Beyond core engineering, AI is helping other teams collaborate with programmers. Product management, for instance, is using tools like Vercel to bring “demo-worthy” prototypes, rather than just ideas, to devs, who can then move ahead with mock-ups. Or, if UX teams are looking to change certain elements on a dashboard, AI can quickly spin up a handful of options, like different widgets or buttons. “Then you come to engineering with that, and the engineer immediately knows what you really intend to do with it,” Jassal said. Setting expectations, meeting devs where they areHowever, day-to-day activities for all Egnyte engineers, including junior developers, extend beyond just coding. Junior developers are given hands-on tasks across the full development lifecycle to accelerate their growth and experience, Jassal said. For instance, they assist with requirement analysis in early software engineering phases, as well as deployment, productization and post-deployment maintenance.In turn, these activities require “Egnyte-specific tacit knowledge and experience” offered by senior engineers. One clear example of work that sits firmly with senior engineers is authoring architecture notes, as these cut across the platform and require a more holistic, system-level view, Jassal said. “Many of the traditional roadblocks are navigated faster these days with AI; for example, understanding the codebase, dissecting requirements, auto-testing,” he said. “This faster track allows our talented junior hires to progress more quickly and provide higher value to the company sooner.”The company expects a much faster learning curve from junior to mid-level engineers, Jassal said. “It&#x27;s always the case that people coming straight into the workforce are much more excited about trying new things,” Jassal said. But that has to be colored with reality to temper expectations, he added. On the other hand, some senior engineers may need to be ramped up in their adoption because they’re hesitant or had ho-hum or bad experiences with earlier generation tools. This requires incremental introduction. “The senior people, having been burnt multiple times, bring that perspective,” he said. \"So both [types of engineers] play an important role.”Hiring will continue for scale and fresh perspective“In general, I would say it has been really hyped by folks who want to sell you tokens,” Jassal said referring to people who talk about human coders becoming obsolete. \"Vibe coding\" could be construed in a similar vein: Like others in software development, he prefers the term “AI assisted coding,” wherein programmers have a self-driven loop, generating code, analyzing exceptions, then correcting and scaling. At least in Egnyte’s case, hiring will continue, even if at a slower clip as people become more productive thanks to AI, Jassal said. “We are not just hiring for scale, but to develop the next generation of senior developers and inject fresh perspectives into our development practices,” he said. The takeaway for technical decision-makers is not that AI will eliminate engineering jobs — but that it will reshape how talent is developed. At Egnyte, AI-assisted coding is compressing learning curves and raising expectations, not removing humans from the process. Enterprises that treat AI as a replacement risk hollowing out their future senior talent pipeline; those that treat it as infrastructure can move faster without losing the judgment, creativity, and accountability that only engineers provide.",
          "content": "Egnyte, the $1.5 billion cloud content governance company, has embedded AI coding tools across its global team of more than 350 developers — but not to reduce headcount. Instead, the company continues to hire junior engineers, using AI to accelerate onboarding, deepen codebase understanding, and shorten the path from junior to senior contributor. The approach challenges a dominant 2025 narrative that automation will replace developers, showing instead how enterprises are using AI to scale engineering capacity while keeping humans firmly in the loop.“To have engineers disappear or us not hiring junior engineers doesn&#x27;t look like the likely outcome,” Amrit Jassal, Egnyte CTO and co-founder, told VentureBeat. “You&#x27;ve got to have people, you&#x27;re training and doing all types of succession planning. The junior engineer of today is the senior engineer of tomorrow.”How Egnyte coders are using AI — without ceding controlEgnyte — which has more than 22,000 users including NASDAQ, Red Bull, and BuzzFeed — has rolled out Claude Code, Cursor, Augment, and Gemini CLI coding tools across its developer base to support its core business strategies and expand its newer AI offerings like customer-facing copilots and customizable AI agents. Devs use these tools across a variety of tasks, the simplest of which include data retrieval, code comprehension, smart search, and code lookup. Egnyte’s code base has lots of Java code, which uses numerous libraries, each with different versions, Jassal explained. AI tools are great for peer-to-peer programming, helping new users get a lay of the land, or existing users probe into different code repositories. “We have a pretty big code base, right?” Jassal said. “Let&#x27;s say you&#x27;re looking at an iOS application, but you&#x27;re not well versed; you will fire up Google CLI or an Augment, and ask it to discover the code base.”Some Egnyte devs are moving into automatic pull request summaries, which provide simple overviews of code changes that essentially explain the “what,” “how,” and “why” of proposed modifications. “But obviously, any change that&#x27;s made, we don&#x27;t want to hear that AI made the change; it has to be that developer made the change,” Jassal pointed out. “I would not trust AI to commit to the production code base.” Commits still pass through human review and security validation, and anything red-flagged is escalated to senior engineers. Devs are warned of the dangers of settling into autopilot mode or blindly trusting code. A model may not have been exposed to, or given enough samples of, certain coding components and infrastructure in its training. Another growing, and closely monitored, use case for AI is unit testing, where code components are run in isolation to ensure they work as intended. “At the end of the day, it is a productivity improvement tool,” he said. “It is really a continuation, it&#x27;s like any other tool, it&#x27;s not some magic.”Beyond core engineering, AI is helping other teams collaborate with programmers. Product management, for instance, is using tools like Vercel to bring “demo-worthy” prototypes, rather than just ideas, to devs, who can then move ahead with mock-ups. Or, if UX teams are looking to change certain elements on a dashboard, AI can quickly spin up a handful of options, like different widgets or buttons. “Then you come to engineering with that, and the engineer immediately knows what you really intend to do with it,” Jassal said. Setting expectations, meeting devs where they areHowever, day-to-day activities for all Egnyte engineers, including junior developers, extend beyond just coding. Junior developers are given hands-on tasks across the full development lifecycle to accelerate their growth and experience, Jassal said. For instance, they assist with requirement analysis in early software engineering phases, as well as deployment, productization and post-deployment maintenance.In turn, these activities require “Egnyte-specific tacit knowledge and experience” offered by senior engineers. One clear example of work that sits firmly with senior engineers is authoring architecture notes, as these cut across the platform and require a more holistic, system-level view, Jassal said. “Many of the traditional roadblocks are navigated faster these days with AI; for example, understanding the codebase, dissecting requirements, auto-testing,” he said. “This faster track allows our talented junior hires to progress more quickly and provide higher value to the company sooner.”The company expects a much faster learning curve from junior to mid-level engineers, Jassal said. “It&#x27;s always the case that people coming straight into the workforce are much more excited about trying new things,” Jassal said. But that has to be colored with reality to temper expectations, he added. On the other hand, some senior engineers may need to be ramped up in their adoption because they’re hesitant or had ho-hum or bad experiences with earlier generation tools. This requires incremental introduction. “The senior people, having been burnt multiple times, bring that perspective,” he said. \"So both [types of engineers] play an important role.”Hiring will continue for scale and fresh perspective“In general, I would say it has been really hyped by folks who want to sell you tokens,” Jassal said referring to people who talk about human coders becoming obsolete. \"Vibe coding\" could be construed in a similar vein: Like others in software development, he prefers the term “AI assisted coding,” wherein programmers have a self-driven loop, generating code, analyzing exceptions, then correcting and scaling. At least in Egnyte’s case, hiring will continue, even if at a slower clip as people become more productive thanks to AI, Jassal said. “We are not just hiring for scale, but to develop the next generation of senior developers and inject fresh perspectives into our development practices,” he said. The takeaway for technical decision-makers is not that AI will eliminate engineering jobs — but that it will reshape how talent is developed. At Egnyte, AI-assisted coding is compressing learning curves and raising expectations, not removing humans from the process. Enterprises that treat AI as a replacement risk hollowing out their future senior talent pipeline; those that treat it as infrastructure can move faster without losing the judgment, creativity, and accountability that only engineers provide.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7DUx86jAglIoinWLIrfpO8/abd01f833379598313f3bdeb2c35a96e/Egnyte.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/this-new-dead-simple-prompt-technique-boosts-accuracy-on-llms-by-up-to-76-on",
          "published_at": "Tue, 13 Jan 2026 19:57:00 GMT",
          "title": "This new, dead simple prompt technique boosts accuracy on LLMs by up to 76% on non-reasoning tasks",
          "standfirst": "In the chaotic world of Large Language Model (LLM) optimization, engineers have spent the last few years developing increasingly esoteric rituals to get better answers. We’ve seen \"Chain of Thought\" (asking the model to think step-by-step and often, show those \"reasoning traces\" to the user), \"Emotional Blackmail\" (telling the model its career depends on the answer, or that it is being accused of sexual misconduct), and complex multi-shot prompting frameworks.But a new paper released by Google Research suggests that we may have been overthinking it. The researchers found that simply repeating the input query—literally copying and pasting the prompt so it appears twice—consistently improves performance across major models including Gemini, GPT-4o, Claude, and DeepSeek.The paper, titled \"Prompt Repetition Improves Non-Reasoning LLMs,\" released last month just before the holidays, presents a finding that is almost suspiciously simple: for tasks that don’t require complex reasoning steps, stating the prompt twice yields significantly better results than stating it once. Even better, because of how transformer architecture works, this \"one weird trick\" comes with virtually zero penalty in terms of generation speed.The Causal Blind SpotTo understand why repeating a question makes a supercomputer smarter, you have to look at the architectural limitations of the standard Transformer model.Most modern LLMs are trained as \"causal\" language models. This means they process text strictly from left to right. When the model is processing the 5th token in your sentence, it can \"attend\" (pay attention) to tokens 1 through 4, but it has zero knowledge of token 6, because it hasn&#x27;t happened yet.This creates a fundamental constraint in how models understand user queries. As the authors note, the order of information matters immensely. A query formatted as <CONTEXT> <QUESTION> often yields different results than <QUESTION> <CONTEXT> because, in the latter case, the model reads the question before it knows the context it’s supposed to apply it to.Prompt repetition hacks this limitation by transforming an input of <QUERY> into <QUERY><QUERY>.By the time the model begins processing the second iteration of the query, it has already \"read\" the first iteration. This allows the tokens in the second copy to attend to every single token in the first copy. Effectively, the second repetition enjoys a form of bidirectional attention—it can \"look back\" at the entire query to resolve ambiguities or retrieve specific details that might have been missed in a single pass.The Benchmarks: 47 Wins, 0 LossesThe researchers, Yaniv Leviathan, Matan Kalman, and Yossi Matias, tested this hypothesis across a suite of seven popular benchmarks, including ARC, OpenBookOA, GSM8K, and MMLU-Pro. They evaluated seven different models, ranging from lightweight models like Gemini 2.0 Flash Lite and GPT-4o-mini to heavyweights like Claude 3.7 Sonnet and DeepSeek V3.The results were statistically stark. When asking models not to use explicit reasoning (i.e., just giving a direct answer), prompt repetition won 47 out of 70 head-to-head tests against the baseline, with zero losses.The gains were particularly dramatic in tasks requiring precise retrieval from a prompt. The team designed a custom \"NameIndex\" benchmark, where the model is given a list of 50 names and asked to identify the 25th one.Baseline Performance: Gemini 2.0 Flash-Lite scored a dismal 21.33% accuracy.With Repetition: Accuracy skyrocketed to 97.33%.This massive jump illustrates the \"causal blind spot\" perfectly. In a single pass, the model might lose track of the count by the time it reaches the 25th name. In the repeated pass, the model effectively has the entire list in its \"working memory\" before it attempts to solve the retrieval task.The \"Free Lunch\" of LatencyUsually, adding text to a prompt increases costs and latency. If you double the input, surely you double the wait time?Surprisingly, no. The paper demonstrates that prompt repetition is essentially \"free\" regarding user-perceived latency.LLM processing is divided into two stages:Prefill: The model processes the input prompt. This is highly parallelizable; the GPU can crunch the entire prompt matrix simultaneously.Generation (Decoding): The model generates the answer one token at a time. This is serial and slow.Prompt repetition only increases the work in the prefill stage. Because modern hardware handles prefill so efficiently, the user barely notices the difference. The researchers found that repeating the prompt did not increase the length of the generated answer, nor did it increase the \"time to first token\" latency for most models.The only exceptions were Anthropic’s models (Claude Haiku and Sonnet) on extremely long requests, where the prefill stage eventually hit a bottleneck. But for the vast majority of use cases, the technique improves accuracy without slowing down the chat experience.Reasoning vs. RepetitionThere is a caveat: this technique is primarily for \"non-reasoning\" tasks—scenarios where you want a direct answer rather than a step-by-step derivation.When the researchers tested prompt repetition combined with \"Chain of Thought\" (asking the model to \"think step by step\"), the gains largely vanished, showing neutral to slightly positive results (5 wins, 1 loss, 22 ties).The authors posit that reasoning models naturally perform a version of repetition themselves. When a model \"thinks,\" it often restates the premise of the question in its generated output before solving it. Therefore, explicitly repeating the prompt in the input becomes redundant. However, for applications where you need a fast, direct answer without the verbosity (and cost) of a long reasoning trace, prompt repetition offers a powerful alternative.Strategic Implementation for the EnterpriseFor enterprise leadership, this research represents that rarest of things in AI development: a \"free\" optimization. But capitalization requires nuance; this isn&#x27;t a setting to toggle blindly across an entire organization, but rather a tactical adjustment that ripples across engineering, orchestration, and security.For technical leads balancing the eternal triangle of speed, quality, and cost, prompt repetition offers a way to punch above your weight class. The data shows that smaller, faster models—like Gemini 2.0 Flash Lite—can achieve near-perfect retrieval accuracy (jumping from 21.33% to 97.33%) simply by processing the input twice. This changes the calculus for model selection: before upgrading to a larger, more expensive model to solve an accuracy bottleneck, engineers should first test whether simple repetition allows their current \"Lite\" models to close the gap. It is a potential strategy for retaining the speed and cost benefits of lightweight infrastructure without sacrificing performance on extraction and retrieval tasks.This logic naturally shifts the burden to the orchestration layer. For those managing the middleware and API gateways that glue AI applications together, prompt repetition should likely become a standard, invisible component of the pipeline logic rather than a user behavior. However, because the technique is neutral for reasoning-heavy tasks but highly effective for direct answers, it requires conditional application. A smart orchestration harness would automatically identify requests routed to non-reasoning endpoints—such as entity extraction, classification, or simple Q&A—and double the prompt before passing it to the model. This optimizes performance at the infrastructure level, delivering better results without requiring action from end-users or increasing the generation budget.Finally, this heightened attentiveness introduces a new variable for security teams. If repeating a prompt clarifies a user&#x27;s intent to the model, it stands to reason that malicious intents might be clarified as well. Security directors will need to update their red-teaming protocols to test \"repeated injection\" attacks—verifying whether repeating a jailbreak command (e.g., \"Ignore previous instructions\") makes the model \"attend\" to the breach more effectively. Conversely, this mechanism offers a new defensive tool: repeating System Prompts. Stating safety guardrails twice at the start of the context window could force the model to attend to safety constraints more rigorously, acting as a low-cost reinforcement for robust security operations.Why This MattersThis research highlights a crucial insight for developers building on top of LLMs: our current models are still deeply constrained by their unidirectional nature. While we wait for new architectures that might solve causal blindness, crude but effective workarounds like prompt repetition offer immediate value.The authors suggest this could become a default behavior for future systems. We might soon see inference engines that silently double our prompts in the background before sending them to the model, or \"Reasoning\" models trained to internalize this repetition strategy to be more efficient.For now, if you are struggling to get a model to follow complex instructions or retrieve specific details from a long document, the solution might not be a better prompt. You might just need to say it again.",
          "content": "In the chaotic world of Large Language Model (LLM) optimization, engineers have spent the last few years developing increasingly esoteric rituals to get better answers. We’ve seen \"Chain of Thought\" (asking the model to think step-by-step and often, show those \"reasoning traces\" to the user), \"Emotional Blackmail\" (telling the model its career depends on the answer, or that it is being accused of sexual misconduct), and complex multi-shot prompting frameworks.But a new paper released by Google Research suggests that we may have been overthinking it. The researchers found that simply repeating the input query—literally copying and pasting the prompt so it appears twice—consistently improves performance across major models including Gemini, GPT-4o, Claude, and DeepSeek.The paper, titled \"Prompt Repetition Improves Non-Reasoning LLMs,\" released last month just before the holidays, presents a finding that is almost suspiciously simple: for tasks that don’t require complex reasoning steps, stating the prompt twice yields significantly better results than stating it once. Even better, because of how transformer architecture works, this \"one weird trick\" comes with virtually zero penalty in terms of generation speed.The Causal Blind SpotTo understand why repeating a question makes a supercomputer smarter, you have to look at the architectural limitations of the standard Transformer model.Most modern LLMs are trained as \"causal\" language models. This means they process text strictly from left to right. When the model is processing the 5th token in your sentence, it can \"attend\" (pay attention) to tokens 1 through 4, but it has zero knowledge of token 6, because it hasn&#x27;t happened yet.This creates a fundamental constraint in how models understand user queries. As the authors note, the order of information matters immensely. A query formatted as <CONTEXT> <QUESTION> often yields different results than <QUESTION> <CONTEXT> because, in the latter case, the model reads the question before it knows the context it’s supposed to apply it to.Prompt repetition hacks this limitation by transforming an input of <QUERY> into <QUERY><QUERY>.By the time the model begins processing the second iteration of the query, it has already \"read\" the first iteration. This allows the tokens in the second copy to attend to every single token in the first copy. Effectively, the second repetition enjoys a form of bidirectional attention—it can \"look back\" at the entire query to resolve ambiguities or retrieve specific details that might have been missed in a single pass.The Benchmarks: 47 Wins, 0 LossesThe researchers, Yaniv Leviathan, Matan Kalman, and Yossi Matias, tested this hypothesis across a suite of seven popular benchmarks, including ARC, OpenBookOA, GSM8K, and MMLU-Pro. They evaluated seven different models, ranging from lightweight models like Gemini 2.0 Flash Lite and GPT-4o-mini to heavyweights like Claude 3.7 Sonnet and DeepSeek V3.The results were statistically stark. When asking models not to use explicit reasoning (i.e., just giving a direct answer), prompt repetition won 47 out of 70 head-to-head tests against the baseline, with zero losses.The gains were particularly dramatic in tasks requiring precise retrieval from a prompt. The team designed a custom \"NameIndex\" benchmark, where the model is given a list of 50 names and asked to identify the 25th one.Baseline Performance: Gemini 2.0 Flash-Lite scored a dismal 21.33% accuracy.With Repetition: Accuracy skyrocketed to 97.33%.This massive jump illustrates the \"causal blind spot\" perfectly. In a single pass, the model might lose track of the count by the time it reaches the 25th name. In the repeated pass, the model effectively has the entire list in its \"working memory\" before it attempts to solve the retrieval task.The \"Free Lunch\" of LatencyUsually, adding text to a prompt increases costs and latency. If you double the input, surely you double the wait time?Surprisingly, no. The paper demonstrates that prompt repetition is essentially \"free\" regarding user-perceived latency.LLM processing is divided into two stages:Prefill: The model processes the input prompt. This is highly parallelizable; the GPU can crunch the entire prompt matrix simultaneously.Generation (Decoding): The model generates the answer one token at a time. This is serial and slow.Prompt repetition only increases the work in the prefill stage. Because modern hardware handles prefill so efficiently, the user barely notices the difference. The researchers found that repeating the prompt did not increase the length of the generated answer, nor did it increase the \"time to first token\" latency for most models.The only exceptions were Anthropic’s models (Claude Haiku and Sonnet) on extremely long requests, where the prefill stage eventually hit a bottleneck. But for the vast majority of use cases, the technique improves accuracy without slowing down the chat experience.Reasoning vs. RepetitionThere is a caveat: this technique is primarily for \"non-reasoning\" tasks—scenarios where you want a direct answer rather than a step-by-step derivation.When the researchers tested prompt repetition combined with \"Chain of Thought\" (asking the model to \"think step by step\"), the gains largely vanished, showing neutral to slightly positive results (5 wins, 1 loss, 22 ties).The authors posit that reasoning models naturally perform a version of repetition themselves. When a model \"thinks,\" it often restates the premise of the question in its generated output before solving it. Therefore, explicitly repeating the prompt in the input becomes redundant. However, for applications where you need a fast, direct answer without the verbosity (and cost) of a long reasoning trace, prompt repetition offers a powerful alternative.Strategic Implementation for the EnterpriseFor enterprise leadership, this research represents that rarest of things in AI development: a \"free\" optimization. But capitalization requires nuance; this isn&#x27;t a setting to toggle blindly across an entire organization, but rather a tactical adjustment that ripples across engineering, orchestration, and security.For technical leads balancing the eternal triangle of speed, quality, and cost, prompt repetition offers a way to punch above your weight class. The data shows that smaller, faster models—like Gemini 2.0 Flash Lite—can achieve near-perfect retrieval accuracy (jumping from 21.33% to 97.33%) simply by processing the input twice. This changes the calculus for model selection: before upgrading to a larger, more expensive model to solve an accuracy bottleneck, engineers should first test whether simple repetition allows their current \"Lite\" models to close the gap. It is a potential strategy for retaining the speed and cost benefits of lightweight infrastructure without sacrificing performance on extraction and retrieval tasks.This logic naturally shifts the burden to the orchestration layer. For those managing the middleware and API gateways that glue AI applications together, prompt repetition should likely become a standard, invisible component of the pipeline logic rather than a user behavior. However, because the technique is neutral for reasoning-heavy tasks but highly effective for direct answers, it requires conditional application. A smart orchestration harness would automatically identify requests routed to non-reasoning endpoints—such as entity extraction, classification, or simple Q&A—and double the prompt before passing it to the model. This optimizes performance at the infrastructure level, delivering better results without requiring action from end-users or increasing the generation budget.Finally, this heightened attentiveness introduces a new variable for security teams. If repeating a prompt clarifies a user&#x27;s intent to the model, it stands to reason that malicious intents might be clarified as well. Security directors will need to update their red-teaming protocols to test \"repeated injection\" attacks—verifying whether repeating a jailbreak command (e.g., \"Ignore previous instructions\") makes the model \"attend\" to the breach more effectively. Conversely, this mechanism offers a new defensive tool: repeating System Prompts. Stating safety guardrails twice at the start of the context window could force the model to attend to safety constraints more rigorously, acting as a low-cost reinforcement for robust security operations.Why This MattersThis research highlights a crucial insight for developers building on top of LLMs: our current models are still deeply constrained by their unidirectional nature. While we wait for new architectures that might solve causal blindness, crude but effective workarounds like prompt repetition offer immediate value.The authors suggest this could become a default behavior for future systems. We might soon see inference engines that silently double our prompts in the background before sending them to the model, or \"Reasoning\" models trained to internalize this repetition strategy to be more efficient.For now, if you are struggling to get a model to follow complex instructions or retrieve specific details from a long document, the solution might not be a better prompt. You might just need to say it again.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6PTJl3Wssuvl5m3nljR103/21ab6a44da755c1cf2dca3b8fdd4ad08/cool-guys.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/nba-league-pass-is-up-to-55-percent-off-right-now-163421218.html",
          "published_at": "Tue, 13 Jan 2026 16:34:21 +0000",
          "title": "NBA League Pass is up to 55 percent off right now",
          "standfirst": "NBA League Pass, the streaming service that lets you catch hundreds of out-of-market NBA games, is on sale right now for up to 55 percent off. The League Pass Premium subscription is on sale for $75, down from $160, while League Pass Standard is marked down to $50 from $110. We're almost halfway through the season at this point, so it makes sense for a service like League Pass to start offering some discounts. The Standard plan includes commercials and support for only one device at a time, while the Premium tier offers no commercials, in-arena streams during breaks in the game, offline viewing of full games and concurrent streams on up to three devices at once. Last year, League Pass added multiview, which allows you to view up to four games at once on a single screen. This is included across both subscription tiers. The service also added a smart rewind tool that automatically selects key highlights and plays from each game. Outside the US and Canada, League Pass carries every single NBA game live, but within these countries a bevy of restrictions apply. In the US, any games being shown on your regional sports network will be blacked out as the service is meant for out-of-market games only. Also, any nationally broadcast games will not be available live, but instead will be available for on-demand viewing at 6AM ET the following day. The service is only for regular-season games. If you're an avid NBA fan that follows multiple teams then the League Pass almost certainly carries dozens of games you can watch even with the restrictions in the US. Subscribers can get a list of applicable blackouts by entering their ZIP code before signing up. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/nba-league-pass-is-up-to-55-percent-off-right-now-163421218.html?src=rss",
          "content": "NBA League Pass, the streaming service that lets you catch hundreds of out-of-market NBA games, is on sale right now for up to 55 percent off. The League Pass Premium subscription is on sale for $75, down from $160, while League Pass Standard is marked down to $50 from $110. We're almost halfway through the season at this point, so it makes sense for a service like League Pass to start offering some discounts. The Standard plan includes commercials and support for only one device at a time, while the Premium tier offers no commercials, in-arena streams during breaks in the game, offline viewing of full games and concurrent streams on up to three devices at once. Last year, League Pass added multiview, which allows you to view up to four games at once on a single screen. This is included across both subscription tiers. The service also added a smart rewind tool that automatically selects key highlights and plays from each game. Outside the US and Canada, League Pass carries every single NBA game live, but within these countries a bevy of restrictions apply. In the US, any games being shown on your regional sports network will be blacked out as the service is meant for out-of-market games only. Also, any nationally broadcast games will not be available live, but instead will be available for on-demand viewing at 6AM ET the following day. The service is only for regular-season games. If you're an avid NBA fan that follows multiple teams then the League Pass almost certainly carries dozens of games you can watch even with the restrictions in the US. Subscribers can get a list of applicable blackouts by entering their ZIP code before signing up. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/nba-league-pass-is-up-to-55-percent-off-right-now-163421218.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/deepseeks-conditional-memory-fixes-silent-llm-waste-gpu-cycles-lost-to",
          "published_at": "Tue, 13 Jan 2026 16:00:00 GMT",
          "title": "DeepSeek’s conditional memory fixes silent LLM waste: GPU cycles lost to static lookups",
          "standfirst": "When an enterprise LLM retrieves a product name, technical specification, or standard contract clause, it&#x27;s using expensive GPU computation designed for complex reasoning — just to access static information. This happens millions of times per day. Each lookup wastes cycles and inflates infrastructure costs. DeepSeek&#x27;s newly released research on \"conditional memory\" addresses this architectural limitation directly. The work introduces Engram, a module that separates static pattern retrieval from dynamic reasoning. It delivers results that challenge assumptions about what memory is actually for in neural networks. The paper was co-authored by DeepSeek founder Liang Wenfeng.Through systematic experiments DeepSeek found the optimal balance between computation and memory with 75% of sparse model capacity allocated to dynamic reasoning and 25% to static lookups. This memory system improved reasoning more than knowledge retrieval. Complex reasoning benchmarks jumped from 70% to 74% accuracy, while knowledge-focused tests improved from 57% to 61%. These improvements came from tests including Big-Bench Hard, ARC-Challenge, and MMLU.The research arrives as enterprises face mounting pressure to deploy more capable AI systems while navigating GPU memory constraints and infrastructure costs. DeepSeek&#x27;s approach offers a potential path forward by fundamentally rethinking how models should be structured.How conditional memory solves a different issue than agentic memory and RAGAgentic memory systems, sometimes referred to as contextual memory — like Hindsight, MemOS, or Memp — focus on episodic memory. They store records of past conversations, user preferences, and interaction history. These systems help agents maintain context across sessions and learn from experience. But they&#x27;re external to the model&#x27;s forward pass and don&#x27;t optimize how the model internally processes static linguistic patterns.For Chris Latimer, founder and CEO of Vectorize, which developed Hindsight, the conditional memory approach used in Engram solves a different problem than agentic AI memory.\"It&#x27;s not solving the problem of connecting agents to external memory like conversation histories and knowledge stores,\" Latimer told VentureBeat. \"It&#x27;s more geared towards squeezing performance out of smaller models and getting more mileage out of scarce GPU resources.\"Conditional memory tackles a fundamental issue: Transformers lack a native knowledge lookup primitive. When processing text, they must simulate retrieval of static patterns through expensive neural computation across multiple layers. These patterns include named entities, technical terminology, and common phrases.The DeepSeek paper illustrates this with a concrete example. Recognizing \"Diana, Princess of Wales\" requires consuming multiple layers of attention and feed-forward networks to progressively compose features. The model essentially uses deep, dynamic logic circuits to perform what should be a simple hash table lookup. It&#x27;s like using a calculator to remember your phone number rather than just looking it up.\"The problem is that Transformer lacks a &#x27;native knowledge lookup&#x27; ability,\" the researchers write. \"Many tasks that should be solved in O(1) time like retrieval have to be &#x27;simulated for retrieval&#x27; through a large amount of computation, which is very inefficient.\"How conditional memory worksEngram introduces \"conditional memory\" to work alongside MoE&#x27;s conditional computation. The mechanism is straightforward. The module takes sequences of two to three tokens and uses hash functions to look them up in a massive embedding table. Retrieval happens in constant time, regardless of table size.But retrieved patterns need filtering. A hash lookup for \"Apple\" might collide with unrelated content, or the word might mean the fruit rather than the company. Engram solves this with a gating mechanism. The model&#x27;s current understanding of context (accumulated through earlier attention layers) acts as a filter. If retrieved memory contradicts the current context, the gate suppresses it. If it fits, the gate lets it through.The module isn&#x27;t applied at every layer. Strategic placement balances performance gains against system latency.This dual-system design raises a critical question: How much capacity should each get? DeepSeek&#x27;s key finding: the optimal split is 75-80% for computation and 20-25% for memory. Testing found pure MoE (100% computation) proved suboptimal. Too much computation wastes depth reconstructing static patterns; too much memory loses reasoning capacity.Infrastructure efficiency: the GPU memory bypassPerhaps Engram&#x27;s most pragmatic contribution is its infrastructure-aware design. Unlike MoE&#x27;s dynamic routing, which depends on runtime hidden states, Engram&#x27;s retrieval indices depend solely on input token sequences. This deterministic nature enables a prefetch-and-overlap strategy.\"The challenge is that GPU memory is limited and expensive, so using bigger models gets costly and harder to deploy,\" Latimer said. \"The clever idea behind Engram is to keep the main model on the GPU, but offload a big chunk of the model&#x27;s stored information into a separate memory on regular RAM, which the model can use on a just-in-time basis.\"During inference, the system can asynchronously retrieve embeddings from host CPU memory via PCIe. This happens while GPU computes preceding transformer blocks. Strategic layer placement leverages computation of early layers as a buffer to mask communication latency.The researchers demonstrated this with a 100B-parameter embedding table entirely offloaded to host DRAM. They achieved throughput penalties below 3%. This decoupling of storage from compute addresses a critical enterprise constraint as GPU high-bandwidth memory remains expensive and scarce.What this means for enterprise AI deploymentFor enterprises evaluating AI infrastructure strategies, DeepSeek&#x27;s findings suggest several actionable insights:1. Hybrid architectures outperform pure approaches. The 75/25 allocation law indicates that optimal models should split sparse capacity between computation and memory. 2. Infrastructure costs may shift from GPU to memory. If Engram-style architectures prove viable in production, infrastructure investment patterns could change. The ability to store 100B+ parameters in CPU memory with minimal overhead suggests that memory-rich, compute-moderate configurations may offer better performance-per-dollar than pure GPU scaling.3. Reasoning improvements exceed knowledge gains. The surprising finding that reasoning benefits more than knowledge retrieval suggests that memory&#x27;s value extends beyond obvious use cases. For enterprises leading AI adoption, Engram demonstrates that the next frontier may not be simply bigger models. It&#x27;s smarter architectural choices that respect the fundamental distinction between static knowledge and dynamic reasoning. The research suggests that optimal AI systems will increasingly resemble hybrid architectures. Organizations waiting to adopt AI later in the cycle should monitor whether major model providers incorporate conditional memory principles into their architectures. If the 75/25 allocation law holds across scales and domains, the next generation of foundation models may deliver substantially better reasoning performance at lower infrastructure costs.",
          "content": "When an enterprise LLM retrieves a product name, technical specification, or standard contract clause, it&#x27;s using expensive GPU computation designed for complex reasoning — just to access static information. This happens millions of times per day. Each lookup wastes cycles and inflates infrastructure costs. DeepSeek&#x27;s newly released research on \"conditional memory\" addresses this architectural limitation directly. The work introduces Engram, a module that separates static pattern retrieval from dynamic reasoning. It delivers results that challenge assumptions about what memory is actually for in neural networks. The paper was co-authored by DeepSeek founder Liang Wenfeng.Through systematic experiments DeepSeek found the optimal balance between computation and memory with 75% of sparse model capacity allocated to dynamic reasoning and 25% to static lookups. This memory system improved reasoning more than knowledge retrieval. Complex reasoning benchmarks jumped from 70% to 74% accuracy, while knowledge-focused tests improved from 57% to 61%. These improvements came from tests including Big-Bench Hard, ARC-Challenge, and MMLU.The research arrives as enterprises face mounting pressure to deploy more capable AI systems while navigating GPU memory constraints and infrastructure costs. DeepSeek&#x27;s approach offers a potential path forward by fundamentally rethinking how models should be structured.How conditional memory solves a different issue than agentic memory and RAGAgentic memory systems, sometimes referred to as contextual memory — like Hindsight, MemOS, or Memp — focus on episodic memory. They store records of past conversations, user preferences, and interaction history. These systems help agents maintain context across sessions and learn from experience. But they&#x27;re external to the model&#x27;s forward pass and don&#x27;t optimize how the model internally processes static linguistic patterns.For Chris Latimer, founder and CEO of Vectorize, which developed Hindsight, the conditional memory approach used in Engram solves a different problem than agentic AI memory.\"It&#x27;s not solving the problem of connecting agents to external memory like conversation histories and knowledge stores,\" Latimer told VentureBeat. \"It&#x27;s more geared towards squeezing performance out of smaller models and getting more mileage out of scarce GPU resources.\"Conditional memory tackles a fundamental issue: Transformers lack a native knowledge lookup primitive. When processing text, they must simulate retrieval of static patterns through expensive neural computation across multiple layers. These patterns include named entities, technical terminology, and common phrases.The DeepSeek paper illustrates this with a concrete example. Recognizing \"Diana, Princess of Wales\" requires consuming multiple layers of attention and feed-forward networks to progressively compose features. The model essentially uses deep, dynamic logic circuits to perform what should be a simple hash table lookup. It&#x27;s like using a calculator to remember your phone number rather than just looking it up.\"The problem is that Transformer lacks a &#x27;native knowledge lookup&#x27; ability,\" the researchers write. \"Many tasks that should be solved in O(1) time like retrieval have to be &#x27;simulated for retrieval&#x27; through a large amount of computation, which is very inefficient.\"How conditional memory worksEngram introduces \"conditional memory\" to work alongside MoE&#x27;s conditional computation. The mechanism is straightforward. The module takes sequences of two to three tokens and uses hash functions to look them up in a massive embedding table. Retrieval happens in constant time, regardless of table size.But retrieved patterns need filtering. A hash lookup for \"Apple\" might collide with unrelated content, or the word might mean the fruit rather than the company. Engram solves this with a gating mechanism. The model&#x27;s current understanding of context (accumulated through earlier attention layers) acts as a filter. If retrieved memory contradicts the current context, the gate suppresses it. If it fits, the gate lets it through.The module isn&#x27;t applied at every layer. Strategic placement balances performance gains against system latency.This dual-system design raises a critical question: How much capacity should each get? DeepSeek&#x27;s key finding: the optimal split is 75-80% for computation and 20-25% for memory. Testing found pure MoE (100% computation) proved suboptimal. Too much computation wastes depth reconstructing static patterns; too much memory loses reasoning capacity.Infrastructure efficiency: the GPU memory bypassPerhaps Engram&#x27;s most pragmatic contribution is its infrastructure-aware design. Unlike MoE&#x27;s dynamic routing, which depends on runtime hidden states, Engram&#x27;s retrieval indices depend solely on input token sequences. This deterministic nature enables a prefetch-and-overlap strategy.\"The challenge is that GPU memory is limited and expensive, so using bigger models gets costly and harder to deploy,\" Latimer said. \"The clever idea behind Engram is to keep the main model on the GPU, but offload a big chunk of the model&#x27;s stored information into a separate memory on regular RAM, which the model can use on a just-in-time basis.\"During inference, the system can asynchronously retrieve embeddings from host CPU memory via PCIe. This happens while GPU computes preceding transformer blocks. Strategic layer placement leverages computation of early layers as a buffer to mask communication latency.The researchers demonstrated this with a 100B-parameter embedding table entirely offloaded to host DRAM. They achieved throughput penalties below 3%. This decoupling of storage from compute addresses a critical enterprise constraint as GPU high-bandwidth memory remains expensive and scarce.What this means for enterprise AI deploymentFor enterprises evaluating AI infrastructure strategies, DeepSeek&#x27;s findings suggest several actionable insights:1. Hybrid architectures outperform pure approaches. The 75/25 allocation law indicates that optimal models should split sparse capacity between computation and memory. 2. Infrastructure costs may shift from GPU to memory. If Engram-style architectures prove viable in production, infrastructure investment patterns could change. The ability to store 100B+ parameters in CPU memory with minimal overhead suggests that memory-rich, compute-moderate configurations may offer better performance-per-dollar than pure GPU scaling.3. Reasoning improvements exceed knowledge gains. The surprising finding that reasoning benefits more than knowledge retrieval suggests that memory&#x27;s value extends beyond obvious use cases. For enterprises leading AI adoption, Engram demonstrates that the next frontier may not be simply bigger models. It&#x27;s smarter architectural choices that respect the fundamental distinction between static knowledge and dynamic reasoning. The research suggests that optimal AI systems will increasingly resemble hybrid architectures. Organizations waiting to adopt AI later in the cycle should monitor whether major model providers incorporate conditional memory principles into their architectures. If the 75/25 allocation law holds across scales and domains, the next generation of foundation models may deliver substantially better reasoning performance at lower infrastructure costs.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5QbXis6MzFunSR0Q7iejyX/2cd47fca23ad6f0fd1e3094fc096252e/conditional-memory-smk.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/anthropic-launches-claude-cowork-a-version-of-its-coding-ai-for-regular-people-193000849.html",
          "published_at": "Tue, 13 Jan 2026 15:27:21 +0000",
          "title": "Anthropic launches Claude Cowork, a version of its coding AI for regular people",
          "standfirst": "If you follow Anthropic, you're probably familiar with Claude Code. Since the fall of 2024, the company has been training its AI models to use and navigate computers like a human would, and the coding agent has been the most practical expression of that work, giving developers a way to automate rote programming tasks. Starting today, Anthropic is giving regular people a way to take advantage of those capabilities, with the release of a new preview feature called Claude Cowork.The company is billing Cowork as \"a simpler way for anyone — not just developers — to work with Claude.\" After you give the system access to a folder on your computer, it can read, edit or create new files in that folder on your behalf. Anthropic gives a few different example use cases for Cowork. For instance, you could ask Claude to organize your downloads folder, telling it to rename the files contained within to something that's easier to parse at a glance. Another example: you could use Claude to turn screenshots of receipts and invoices into a spreadsheet for tracking expenses. Cowork can also navigate websites — provided you install Claude’s Chrome plugin — and make can use Anthropic's Connectors framework to access third-party apps like Canva. \"Cowork is designed to make using Claude for new work as simple as possible. You don’t need to keep manually providing context or converting Claude’s outputs into the right format,\" the company said. \"Nor do you have to wait for Claude to finish before offering further ideas or feedback: you can queue up tasks and let Claude work through them in parallel.\" If the idea of granting Claude access to your computer sounds ill-advised, Anthropic says Claude \"can’t read or edit anything you don’t give it explicit access to.\" However, the company does note the system can \"take potentially destructive actions,\" such as deleting a file that is important to you or misinterpreting your instructions. For that reason, Anthropic suggests it's best to give \"very clear\" guidance to Claude. Anthropic isn’t the first to offer a computer agent. Microsoft, for example, has been pushing Copilot hard for nearly three years, despite seemingly limited adoption. For Anthropic, the challenge will be convincing people these tools are useful where others have failed. The fact Claude Code has been universally loved by programmers may make that task easier. For now, Anthropic is giving users of its pricey Claude Max subscription first access to the preview. If you want to try Cowork for yourself, you'll also need a Mac with the Claude macOS app installed. For everyone else, you’ll need to join a wait list. This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-launches-claude-cowork-a-version-of-its-coding-ai-for-regular-people-193000849.html?src=rss",
          "content": "If you follow Anthropic, you're probably familiar with Claude Code. Since the fall of 2024, the company has been training its AI models to use and navigate computers like a human would, and the coding agent has been the most practical expression of that work, giving developers a way to automate rote programming tasks. Starting today, Anthropic is giving regular people a way to take advantage of those capabilities, with the release of a new preview feature called Claude Cowork.The company is billing Cowork as \"a simpler way for anyone — not just developers — to work with Claude.\" After you give the system access to a folder on your computer, it can read, edit or create new files in that folder on your behalf. Anthropic gives a few different example use cases for Cowork. For instance, you could ask Claude to organize your downloads folder, telling it to rename the files contained within to something that's easier to parse at a glance. Another example: you could use Claude to turn screenshots of receipts and invoices into a spreadsheet for tracking expenses. Cowork can also navigate websites — provided you install Claude’s Chrome plugin — and make can use Anthropic's Connectors framework to access third-party apps like Canva. \"Cowork is designed to make using Claude for new work as simple as possible. You don’t need to keep manually providing context or converting Claude’s outputs into the right format,\" the company said. \"Nor do you have to wait for Claude to finish before offering further ideas or feedback: you can queue up tasks and let Claude work through them in parallel.\" If the idea of granting Claude access to your computer sounds ill-advised, Anthropic says Claude \"can’t read or edit anything you don’t give it explicit access to.\" However, the company does note the system can \"take potentially destructive actions,\" such as deleting a file that is important to you or misinterpreting your instructions. For that reason, Anthropic suggests it's best to give \"very clear\" guidance to Claude. Anthropic isn’t the first to offer a computer agent. Microsoft, for example, has been pushing Copilot hard for nearly three years, despite seemingly limited adoption. For Anthropic, the challenge will be convincing people these tools are useful where others have failed. The fact Claude Code has been universally loved by programmers may make that task easier. For now, Anthropic is giving users of its pricey Claude Max subscription first access to the preview. If you want to try Cowork for yourself, you'll also need a Mac with the Claude macOS app installed. For everyone else, you’ll need to join a wait list. This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-launches-claude-cowork-a-version-of-its-coding-ai-for-regular-people-193000849.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/remarkable-e-ink-tablet-bundles-are-up-to-90-off-right-now-150242312.html",
          "published_at": "Tue, 13 Jan 2026 15:02:42 +0000",
          "title": "reMarkable E Ink tablet bundles are up to $90 off right now",
          "standfirst": "E Ink tablet maker reMarkable is running a bundle deal right now that can save you between $80 and $90 when buying a reMarkable 2 along with a Marker stylus and a folio case. The savings vary depending on the bundle you configure, but this can bring your out-the-door cost down to $449 from $529 for the tablet, Marker stylus and polymer weave book folio. The company also sells a newer stylus called Marker Plus that lets you erase by flipping it around just like a real pencil, but that will cost you an extra $50. If you’ve been eyeing a dedicated writing tablet for work, school or just jotting down notes without the distraction of endless apps, this bundle deal is an ideal opportunity to pick one up. The reMarkable 2 earned our top pick for best e-ink tablet. In our review, we said the tablet was prettier than ever with a 10.3-inch display and a handsome aluminum frame. The tablet is only 4.7mm thick and weighs less than a pound, helping it feel lean and portable. The display can detect over 4,000 different levels of pressure with the Marker stylus, allowing for precise shading when sketching and the latency between the stylus and the screen is just 21ms. reMarkable fitted the display with a resin layer on top of the glass to make writing on it feel more realistic. We didn't think this passed muster, but we found writing on it was a joy nonetheless. The tablet supports PDFs and ePUBs, which can be added via the companion mobile app or a desktop computer. You can also pair the reMarkable 2 with Google Drive, Microsoft OneDrive or Dropbox to access files. The battery is rated for an impressive two weeks between charges. The reMarkable Paper Pro, a higher-end model with a richer feature set like a full color display and a built-in reading light, is our pick for best premium e-ink tablet. The pricier tablet also has bundle deals right now with savings up to $80 depending on configuration. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/remarkable-e-ink-tablet-bundles-are-up-to-90-off-right-now-150242312.html?src=rss",
          "content": "E Ink tablet maker reMarkable is running a bundle deal right now that can save you between $80 and $90 when buying a reMarkable 2 along with a Marker stylus and a folio case. The savings vary depending on the bundle you configure, but this can bring your out-the-door cost down to $449 from $529 for the tablet, Marker stylus and polymer weave book folio. The company also sells a newer stylus called Marker Plus that lets you erase by flipping it around just like a real pencil, but that will cost you an extra $50. If you’ve been eyeing a dedicated writing tablet for work, school or just jotting down notes without the distraction of endless apps, this bundle deal is an ideal opportunity to pick one up. The reMarkable 2 earned our top pick for best e-ink tablet. In our review, we said the tablet was prettier than ever with a 10.3-inch display and a handsome aluminum frame. The tablet is only 4.7mm thick and weighs less than a pound, helping it feel lean and portable. The display can detect over 4,000 different levels of pressure with the Marker stylus, allowing for precise shading when sketching and the latency between the stylus and the screen is just 21ms. reMarkable fitted the display with a resin layer on top of the glass to make writing on it feel more realistic. We didn't think this passed muster, but we found writing on it was a joy nonetheless. The tablet supports PDFs and ePUBs, which can be added via the companion mobile app or a desktop computer. You can also pair the reMarkable 2 with Google Drive, Microsoft OneDrive or Dropbox to access files. The battery is rated for an impressive two weeks between charges. The reMarkable Paper Pro, a higher-end model with a richer feature set like a full color display and a built-in reading light, is our pick for best premium e-ink tablet. The pricier tablet also has bundle deals right now with savings up to $80 depending on configuration. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/remarkable-e-ink-tablet-bundles-are-up-to-90-off-right-now-150242312.html?src=rss",
          "feed_position": 32
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/apple-bundles-creative-apps-such-as-final-cut-pro-and-logic-pro-into-a-single-subscription-145210038.html",
          "published_at": "Tue, 13 Jan 2026 14:52:10 +0000",
          "title": "Apple bundles creative apps such as Final Cut Pro and Logic Pro into a single subscription",
          "standfirst": "Apple has been putting more onus on its services for the past several years — the company makes tens of billions of dollars in revenue from that side of the business, which it claimed had a record year in 2025. Apple is nudging a little more in that direction with a new subscription bundle called Apple Creator Studio.This allows creators to pay a single fee ($13 per month or $129 per year) to use Final Cut Pro, Logic Pro, Pixelmator Pro, Motion, Compressor and MainStage. Subscribers will get access to “premium content” in Pages, Keynote and Numbers (as well as in Freeform later this year). Of course, there are AI features too. Apple Creator Studio will be available starting on January 28 and you can try it out at no cost through a one-month free trial. College students and educators can subscribe to Apple Creator Studio for $3 per month or $30 per year. Up to six people can access all of the plan’s features if one person in a Family Sharing group subscribes. Apple noted that Final Cut Pro, Pixelmator Pro, Logic Pro, Motion, Compressor and MainStage will still be available as one-time purchases for Mac through the Mac App Store. Given that those can be pretty pricy (going up to $300 for Final Cut Pro), the subscription could be enticing to many burgeoning creators.This seems like Apple’s attempt to muscle in on Adobe’s territory, especially now that it’s bringing AI features to many of these apps. Adding new features to productivity apps like Numbers and Keynote means Apple’s taking a shot at the likes of Microsoft 365 Copilot (yeeeeah, that’s what Office is called now) and Google Workspace as well.On Mac and iPad, Final Cut Pro has a new feature called Beat Detection. Apple suggests this makes “editing video to the rhythm of music fast and fun.” It uses an AI model from Logic Pro to analyze music tracks and display a Beat Grid. The idea here is to visualize song parts, beats and bars to help editors align their cuts with the music. The Montage Maker tool in Final Cut Pro on an iPad.AppleAn AI-powered Montage Maker tool can stitch together “a dynamic video based on the best visual moments within the footage.” You’ll be able to tweak these montages and use an Auto Crop tool to reframe the clip into a vertical format to make it a better fit for social media. Final Cut Pro has transcript and visual search functions too.Logic Pro, MainStage, Pixelmator Pro (which is coming to iPad with Apple Pencil support) and Motion will all have AI-powered features as well. As you might expect, you’ll need an Apple Intelligence-capable device to use some of these.Apple is also introducing something called the Content Hub. This media library includes “curated, high-quality photos, graphics and illustrations.” As for Keynote, Pages, and Numbers, you’ll be able to access premium templates and themes in those otherwise-free apps with a Apple Creator Studio plan. Subscribers will be able to try beta versions of new features, such as a way to generate a draft of a Keynote presentation text based on an outline, and a Magic Fill tool to generate formulas and fill in tables in Numbers.This article originally appeared on Engadget at https://www.engadget.com/apps/apple-bundles-creative-apps-such-as-final-cut-pro-and-logic-pro-into-a-single-subscription-145210038.html?src=rss",
          "content": "Apple has been putting more onus on its services for the past several years — the company makes tens of billions of dollars in revenue from that side of the business, which it claimed had a record year in 2025. Apple is nudging a little more in that direction with a new subscription bundle called Apple Creator Studio.This allows creators to pay a single fee ($13 per month or $129 per year) to use Final Cut Pro, Logic Pro, Pixelmator Pro, Motion, Compressor and MainStage. Subscribers will get access to “premium content” in Pages, Keynote and Numbers (as well as in Freeform later this year). Of course, there are AI features too. Apple Creator Studio will be available starting on January 28 and you can try it out at no cost through a one-month free trial. College students and educators can subscribe to Apple Creator Studio for $3 per month or $30 per year. Up to six people can access all of the plan’s features if one person in a Family Sharing group subscribes. Apple noted that Final Cut Pro, Pixelmator Pro, Logic Pro, Motion, Compressor and MainStage will still be available as one-time purchases for Mac through the Mac App Store. Given that those can be pretty pricy (going up to $300 for Final Cut Pro), the subscription could be enticing to many burgeoning creators.This seems like Apple’s attempt to muscle in on Adobe’s territory, especially now that it’s bringing AI features to many of these apps. Adding new features to productivity apps like Numbers and Keynote means Apple’s taking a shot at the likes of Microsoft 365 Copilot (yeeeeah, that’s what Office is called now) and Google Workspace as well.On Mac and iPad, Final Cut Pro has a new feature called Beat Detection. Apple suggests this makes “editing video to the rhythm of music fast and fun.” It uses an AI model from Logic Pro to analyze music tracks and display a Beat Grid. The idea here is to visualize song parts, beats and bars to help editors align their cuts with the music. The Montage Maker tool in Final Cut Pro on an iPad.AppleAn AI-powered Montage Maker tool can stitch together “a dynamic video based on the best visual moments within the footage.” You’ll be able to tweak these montages and use an Auto Crop tool to reframe the clip into a vertical format to make it a better fit for social media. Final Cut Pro has transcript and visual search functions too.Logic Pro, MainStage, Pixelmator Pro (which is coming to iPad with Apple Pencil support) and Motion will all have AI-powered features as well. As you might expect, you’ll need an Apple Intelligence-capable device to use some of these.Apple is also introducing something called the Content Hub. This media library includes “curated, high-quality photos, graphics and illustrations.” As for Keynote, Pages, and Numbers, you’ll be able to access premium templates and themes in those otherwise-free apps with a Apple Creator Studio plan. Subscribers will be able to try beta versions of new features, such as a way to generate a draft of a Keynote presentation text based on an outline, and a Magic Fill tool to generate formulas and fill in tables in Numbers.This article originally appeared on Engadget at https://www.engadget.com/apps/apple-bundles-creative-apps-such-as-final-cut-pro-and-logic-pro-into-a-single-subscription-145210038.html?src=rss",
          "feed_position": 34,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/final_cut.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/airtags-are-back-on-sale-with-a-four-pack-going-for-65-202333994.html",
          "published_at": "Tue, 13 Jan 2026 13:14:02 +0000",
          "title": "AirTags are back on sale, with a four-pack going for $65",
          "standfirst": "Most Apple products are pretty expensive, but some of the most affordable (and useful) ones are AirTags. The Bluetooth trackers are priced pretty reasonably even when not on sale, but they can be a steal if you can get them on a discount — like right now. A four pack of AirTags is on sale for $65 at Amazon, which is only a few dollars more than the record-low price we saw during Black Friday this year. AirTags can be useful for people who travel frequently, helping you to keep track of essentials like your passport as well as a way to keep tabs on luggage while you're on the go. If you do purchase some AirTags, we have some recommendations for useful accessories to go along with them, such as different styles of cases to best attach the trackers to different types of items. These are worth looking over and adding to your shopping cart in order to make the most of the product. AirTags have an IP67 rating for water and dust resistance and their replaceable batteries should last for about a year. They can also support Precision Finding, which gives more exact directions to a lost item, when paired with most models after the iPhone 11. Up to five people can share an AirTag's location, which is helpful for families or large travel groups. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/airtags-are-back-on-sale-with-a-four-pack-going-for-65-202333994.html?src=rss",
          "content": "Most Apple products are pretty expensive, but some of the most affordable (and useful) ones are AirTags. The Bluetooth trackers are priced pretty reasonably even when not on sale, but they can be a steal if you can get them on a discount — like right now. A four pack of AirTags is on sale for $65 at Amazon, which is only a few dollars more than the record-low price we saw during Black Friday this year. AirTags can be useful for people who travel frequently, helping you to keep track of essentials like your passport as well as a way to keep tabs on luggage while you're on the go. If you do purchase some AirTags, we have some recommendations for useful accessories to go along with them, such as different styles of cases to best attach the trackers to different types of items. These are worth looking over and adding to your shopping cart in order to make the most of the product. AirTags have an IP67 rating for water and dust resistance and their replaceable batteries should last for about a year. They can also support Precision Finding, which gives more exact directions to a lost item, when paired with most models after the iPhone 11. Up to five people can share an AirTag's location, which is helpful for families or large travel groups. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/airtags-are-back-on-sale-with-a-four-pack-going-for-65-202333994.html?src=rss",
          "feed_position": 39
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/insta360-releases-ai-powered-follow-up-to-its-link-webcams-130003572.html",
          "published_at": "Tue, 13 Jan 2026 13:00:03 +0000",
          "title": "Insta360 releases AI-powered follow-up to its Link webcams",
          "standfirst": "Insta360, a company most known for its action cameras, has released two new AI-powered 4K webcams, the Link 2 Pro and Link 2C Pro, aimed at creators, educators and remote professionals. The company's goal with these models is \"a webcam experience that looks and sounds remarkably close to a professional camera and microphone setup.\" Both models use a larger 1/1.3-inch sensor with dual native ISO for improved low-light performance over the previous generation, and both support HDR. Insta360 says the audio on both models leverages beamforming technology as well as AI noise canceling to help voices sound clearer in noisy environments. Users can choose from four pickup modes designed for different sound sources like \"Focus\" that isolates a single voice or \"Wide\" if there are multiple speakers. Video resolution on both models tops out 4K at 30 fps, and Insta360 says its updated True Focus system uses phase-detection autofocus to lock onto subjects, keeping them in focus while they move. There's also a \"Natural Bokeh\" mode meant to mimic the shallow depth-of-field look of a traditional DSLR camera, for users who enjoy that look. As for what sets them apart, the Link 2 Pro sports a 2-axis gimbal for AI-assisted tracking, which offers single or group-mode framing, while the Link 2C Pro is static and designed for fixed-position setups. Both models offer gesture control features, allowing users to control certain functions hands-free. These include starting or stopping tracking and zooming in or out. Both models also include a magnetic mount for easy placement on metal surfaces. Several different modes are offered that aid in teaching and presenting. Among them are Smart Whiteboard mode, which will automatically detect a user's whiteboard and keep it clearly in frame, and DeskView mode, which captures an overhead view of a user's desk. There's also a green screen mode, a portrait mode and support for virtual backgrounds. The new webcams also support Insta360 InSight, the company's subscription AI-powered meeting assistant. InSight can record meetings, generate transcripts, create summaries and more. The Link 2 Pro will retail for $250 while the Link 2C Pro will go for $200. Both models are available for purchase now.This article originally appeared on Engadget at https://www.engadget.com/cameras/insta360-releases-ai-powered-follow-up-to-its-link-webcams-130003572.html?src=rss",
          "content": "Insta360, a company most known for its action cameras, has released two new AI-powered 4K webcams, the Link 2 Pro and Link 2C Pro, aimed at creators, educators and remote professionals. The company's goal with these models is \"a webcam experience that looks and sounds remarkably close to a professional camera and microphone setup.\" Both models use a larger 1/1.3-inch sensor with dual native ISO for improved low-light performance over the previous generation, and both support HDR. Insta360 says the audio on both models leverages beamforming technology as well as AI noise canceling to help voices sound clearer in noisy environments. Users can choose from four pickup modes designed for different sound sources like \"Focus\" that isolates a single voice or \"Wide\" if there are multiple speakers. Video resolution on both models tops out 4K at 30 fps, and Insta360 says its updated True Focus system uses phase-detection autofocus to lock onto subjects, keeping them in focus while they move. There's also a \"Natural Bokeh\" mode meant to mimic the shallow depth-of-field look of a traditional DSLR camera, for users who enjoy that look. As for what sets them apart, the Link 2 Pro sports a 2-axis gimbal for AI-assisted tracking, which offers single or group-mode framing, while the Link 2C Pro is static and designed for fixed-position setups. Both models offer gesture control features, allowing users to control certain functions hands-free. These include starting or stopping tracking and zooming in or out. Both models also include a magnetic mount for easy placement on metal surfaces. Several different modes are offered that aid in teaching and presenting. Among them are Smart Whiteboard mode, which will automatically detect a user's whiteboard and keep it clearly in frame, and DeskView mode, which captures an overhead view of a user's desk. There's also a green screen mode, a portrait mode and support for virtual backgrounds. The new webcams also support Insta360 InSight, the company's subscription AI-powered meeting assistant. InSight can record meetings, generate transcripts, create summaries and more. The Link 2 Pro will retail for $250 while the Link 2C Pro will go for $200. Both models are available for purchase now.This article originally appeared on Engadget at https://www.engadget.com/cameras/insta360-releases-ai-powered-follow-up-to-its-link-webcams-130003572.html?src=rss",
          "feed_position": 40
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
          "published_at": "Tue, 13 Jan 2026 13:00:00 GMT",
          "title": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI",
          "standfirst": "Salesforce on Tuesday launched an entirely rebuilt version of Slackbot, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.The new Slackbot, now generally available to Business+ and Enterprise+ customers, is Salesforce&#x27;s most aggressive move yet to position Slack at the center of the emerging \"agentic AI\" movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.\"Slackbot isn&#x27;t just another copilot or AI assistant,\" said Parker Harris, Salesforce co-founder and Slack&#x27;s chief technology officer, in an exclusive interview with Salesforce. \"It&#x27;s the front door to the agentic enterprise, powered by Salesforce.\"From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground upHarris was blunt about what distinguishes the new Slackbot from its predecessor: \"The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.\"The original Slackbot, which has existed since Slack&#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.\"It&#x27;s two different things,\" Harris explained. \"The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.\"Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. \"People know what Slackbot is, and so we wanted to carry that forward,\" Harris said.Why Anthropic&#x27;s Claude powers the new Slackbot — and which AI models could come nextThe new Slackbot runs on Claude, Anthropic&#x27;s large language model, a choice driven partly by compliance requirements. Slack&#x27;s commercial service operates under FedRAMP Moderate certification to serve U.S. federal government customers, and Harris said Anthropic was \"the only provider that could give us a compliant LLM\" when Slack began building the new system.But that exclusivity won&#x27;t last. \"We are, this year, going to support additional providers,\" Harris said. \"We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&#x27;re going to use Gemini for some things.\" He added that OpenAI remains a possibility as well.Harris echoed Salesforce CEO Marc Benioff&#x27;s view that large language models are becoming commoditized: \"You&#x27;ve heard Marc talk about LLMs are commodities, that they&#x27;re democratized. I call them CPUs.\"On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. \"Models don&#x27;t have any sort of security,\" he explained. \"If we trained it on some confidential conversation that you and I have, I don&#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&#x27;t.\"Inside Salesforce&#x27;s internal experiment: 80,000 employees tested Slackbot with striking resultsSalesforce has been testing the new Slackbot internally for months, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&#x27;s chief marketing officer, the results have been striking: \"It&#x27;s the fastest adopted product in Salesforce history.\"Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.The adoption happened largely organically. \"I think it was about five days, and a Canvas was developed by our employees called &#x27;The Most Stealable Slackbot Prompts,&#x27;\" Gavin said. \"People just started adding to it organically. I think it&#x27;s up to 250-plus prompts that are in this Canvas right now.\"Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. \"Everybody is there to help each other learn and communicate hacks,\" she said.How Slackbot transforms scattered enterprise data into executive-ready insightsDuring a product demonstration, Amy Bauer, Slack&#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.\"This is where Slackbot really earns its keep for me,\" Bauer explained. \"What it&#x27;s doing is not just simply reading the image — it&#x27;s actually looking at the image and comparing it to the insight it just generated for me.\"Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called \"a really great justification and plan to move forward.\" Finally, it can synthesize all that information into a Canvas — Slack&#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.\"Up until this point, we have been working in a one-to-one capacity with Slackbot,\" Bauer said. \"But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.\"Rob Seaman, Slack&#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: \"This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&#x27;re going with Slackbot — we&#x27;re eventually going to be adding in additional third-party tool calls.\"MrBeast&#x27;s company became a Slackbot guinea pig—and employees say they&#x27;re saving 90 minutes a dayAmong Salesforce&#x27;s pilot customers is Beast Industries, the parent company of YouTube star MrBeast. Luis Madrigal, the company&#x27;s chief information officer, joined the launch announcement to describe his experience.\"As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,\" Madrigal said. \"The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.\"Madrigal said his security team signed off \"rather quickly\" — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. \"Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&#x27;re part of—that made my security team sign off rather quickly.\"One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving \"at bare minimum, 90 minutes a day.\" Another employee, Spencer, a creative supervisor, described it as \"an assistant who&#x27;s paying attention when I&#x27;m not.\"Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot \"an absolute &#x27;chaos tamer&#x27; for our team,\" estimating it saves her about 30 minutes daily \"just by eliminating context switching.\"Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominanceThe launch puts Salesforce in direct competition with Microsoft&#x27;s Copilot, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.\"The thing that makes it most powerful for our customers and users is the proximity — it&#x27;s just right there in your Slack,\" Seaman said. \"There&#x27;s a tremendous convenience affordance that&#x27;s naturally built into it.\"The deeper advantage, executives argue, is that Slackbot already understands users&#x27; work without requiring setup or training. \"Most AI tools sound the same no matter who is using them,\" the company&#x27;s announcement stated. \"They lack context, miss nuance, and force you to jump between tools to get anything done.\"Harris put it more directly: \"If you&#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&#x27;s a great experience from a consumer perspective — Slackbot is really what we&#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.\"Amy Bauer emphasized the frictionless nature of the experience. \"Slackbot is inherently grounded in the context, in the data that you have in Slack,\" she said. \"So as you continue working in Slack, Slackbot gets better because it&#x27;s grounded in the work that you&#x27;re doing there. There is no setup. There is no configuration for those end users.\"Salesforce&#x27;s ambitious plan to make Slackbot the one &#x27;super agent&#x27; that controls all the othersSalesforce positions Slackbot as what Harris calls a \"super agent\" — a central hub that can eventually coordinate with other AI agents across an organization.\"Every corporation is going to have an employee super agent,\" Harris said. \"Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&#x27;re really excited about it, is going to be that.\"The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.\"Most of the net-new apps that are being deployed to Slack are agents,\" Seaman noted during the press conference. \"This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.\"Harris described a future where Slackbot becomes an MCP (Model Context Protocol) client, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. \"Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,\" he said.But Harris also cautioned against over-promising on multi-agent coordination. \"I still think we&#x27;re in the single agent world,\" he said. \"FY26 is going to be the year where we started to see more coordination. But we&#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &#x27;I&#x27;ve got 1,000 agents working together,&#x27; because I think that&#x27;s unrealistic.\"Slackbot costs nothing extra, but Salesforce&#x27;s data access fees could squeeze some customersSlackbot is included at no additional cost for customers on Business+ and Enterprise+ plans. \"There&#x27;s no additional fees customers have to do,\" Gavin confirmed. \"If they&#x27;re on one of those plans, they&#x27;re going to get Slackbot.\"However, some enterprise customers may face other cost pressures related to Salesforce&#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.Fivetran CEO George Fraser has warned that Salesforce&#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. \"They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,\" Fraser said in a recent CIO report.Salesforce has framed the pricing change as standard industry practice.What Slackbot can do today, what&#x27;s coming in weeks, and what&#x27;s still on the roadmapThe new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is \"coming a few weeks after,\" according to Seaman. Image generation is not currently supported, though Bauer said it&#x27;s \"something that we are looking at in the future.\"When asked about integration with competing CRM systems like HubSpot and Microsoft Dynamics, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.Salesforce is betting the future of work looks like a chat window—and it&#x27;s not aloneThe Slackbot launch is Salesforce&#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.Harris described Slack&#x27;s product philosophy using principles like \"don&#x27;t make me think\" and \"be a great host.\" The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.\"One of the revelations for me is LLMs applied to unstructured information are incredible,\" Harris said. \"And the amount of value you have if you&#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&#x27;re talking about work, you&#x27;re sharing documents, you&#x27;re making decisions, but you can&#x27;t as a human go through that and really get the same value that an LLM can do.\"Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. \"We&#x27;re kind of saturating what we can do with purely conversational UIs,\" he said. \"I think we&#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.\"Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.For Salesforce, the stakes extend beyond a single product launch. After a bruising year on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: \"I honestly can&#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.\"That&#x27;s precisely what Salesforce is counting on.",
          "content": "Salesforce on Tuesday launched an entirely rebuilt version of Slackbot, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.The new Slackbot, now generally available to Business+ and Enterprise+ customers, is Salesforce&#x27;s most aggressive move yet to position Slack at the center of the emerging \"agentic AI\" movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.\"Slackbot isn&#x27;t just another copilot or AI assistant,\" said Parker Harris, Salesforce co-founder and Slack&#x27;s chief technology officer, in an exclusive interview with Salesforce. \"It&#x27;s the front door to the agentic enterprise, powered by Salesforce.\"From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground upHarris was blunt about what distinguishes the new Slackbot from its predecessor: \"The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.\"The original Slackbot, which has existed since Slack&#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.\"It&#x27;s two different things,\" Harris explained. \"The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.\"Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. \"People know what Slackbot is, and so we wanted to carry that forward,\" Harris said.Why Anthropic&#x27;s Claude powers the new Slackbot — and which AI models could come nextThe new Slackbot runs on Claude, Anthropic&#x27;s large language model, a choice driven partly by compliance requirements. Slack&#x27;s commercial service operates under FedRAMP Moderate certification to serve U.S. federal government customers, and Harris said Anthropic was \"the only provider that could give us a compliant LLM\" when Slack began building the new system.But that exclusivity won&#x27;t last. \"We are, this year, going to support additional providers,\" Harris said. \"We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&#x27;re going to use Gemini for some things.\" He added that OpenAI remains a possibility as well.Harris echoed Salesforce CEO Marc Benioff&#x27;s view that large language models are becoming commoditized: \"You&#x27;ve heard Marc talk about LLMs are commodities, that they&#x27;re democratized. I call them CPUs.\"On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. \"Models don&#x27;t have any sort of security,\" he explained. \"If we trained it on some confidential conversation that you and I have, I don&#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&#x27;t.\"Inside Salesforce&#x27;s internal experiment: 80,000 employees tested Slackbot with striking resultsSalesforce has been testing the new Slackbot internally for months, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&#x27;s chief marketing officer, the results have been striking: \"It&#x27;s the fastest adopted product in Salesforce history.\"Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.The adoption happened largely organically. \"I think it was about five days, and a Canvas was developed by our employees called &#x27;The Most Stealable Slackbot Prompts,&#x27;\" Gavin said. \"People just started adding to it organically. I think it&#x27;s up to 250-plus prompts that are in this Canvas right now.\"Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. \"Everybody is there to help each other learn and communicate hacks,\" she said.How Slackbot transforms scattered enterprise data into executive-ready insightsDuring a product demonstration, Amy Bauer, Slack&#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.\"This is where Slackbot really earns its keep for me,\" Bauer explained. \"What it&#x27;s doing is not just simply reading the image — it&#x27;s actually looking at the image and comparing it to the insight it just generated for me.\"Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called \"a really great justification and plan to move forward.\" Finally, it can synthesize all that information into a Canvas — Slack&#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.\"Up until this point, we have been working in a one-to-one capacity with Slackbot,\" Bauer said. \"But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.\"Rob Seaman, Slack&#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: \"This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&#x27;re going with Slackbot — we&#x27;re eventually going to be adding in additional third-party tool calls.\"MrBeast&#x27;s company became a Slackbot guinea pig—and employees say they&#x27;re saving 90 minutes a dayAmong Salesforce&#x27;s pilot customers is Beast Industries, the parent company of YouTube star MrBeast. Luis Madrigal, the company&#x27;s chief information officer, joined the launch announcement to describe his experience.\"As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,\" Madrigal said. \"The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.\"Madrigal said his security team signed off \"rather quickly\" — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. \"Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&#x27;re part of—that made my security team sign off rather quickly.\"One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving \"at bare minimum, 90 minutes a day.\" Another employee, Spencer, a creative supervisor, described it as \"an assistant who&#x27;s paying attention when I&#x27;m not.\"Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot \"an absolute &#x27;chaos tamer&#x27; for our team,\" estimating it saves her about 30 minutes daily \"just by eliminating context switching.\"Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominanceThe launch puts Salesforce in direct competition with Microsoft&#x27;s Copilot, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.\"The thing that makes it most powerful for our customers and users is the proximity — it&#x27;s just right there in your Slack,\" Seaman said. \"There&#x27;s a tremendous convenience affordance that&#x27;s naturally built into it.\"The deeper advantage, executives argue, is that Slackbot already understands users&#x27; work without requiring setup or training. \"Most AI tools sound the same no matter who is using them,\" the company&#x27;s announcement stated. \"They lack context, miss nuance, and force you to jump between tools to get anything done.\"Harris put it more directly: \"If you&#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&#x27;s a great experience from a consumer perspective — Slackbot is really what we&#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.\"Amy Bauer emphasized the frictionless nature of the experience. \"Slackbot is inherently grounded in the context, in the data that you have in Slack,\" she said. \"So as you continue working in Slack, Slackbot gets better because it&#x27;s grounded in the work that you&#x27;re doing there. There is no setup. There is no configuration for those end users.\"Salesforce&#x27;s ambitious plan to make Slackbot the one &#x27;super agent&#x27; that controls all the othersSalesforce positions Slackbot as what Harris calls a \"super agent\" — a central hub that can eventually coordinate with other AI agents across an organization.\"Every corporation is going to have an employee super agent,\" Harris said. \"Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&#x27;re really excited about it, is going to be that.\"The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.\"Most of the net-new apps that are being deployed to Slack are agents,\" Seaman noted during the press conference. \"This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.\"Harris described a future where Slackbot becomes an MCP (Model Context Protocol) client, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. \"Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,\" he said.But Harris also cautioned against over-promising on multi-agent coordination. \"I still think we&#x27;re in the single agent world,\" he said. \"FY26 is going to be the year where we started to see more coordination. But we&#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &#x27;I&#x27;ve got 1,000 agents working together,&#x27; because I think that&#x27;s unrealistic.\"Slackbot costs nothing extra, but Salesforce&#x27;s data access fees could squeeze some customersSlackbot is included at no additional cost for customers on Business+ and Enterprise+ plans. \"There&#x27;s no additional fees customers have to do,\" Gavin confirmed. \"If they&#x27;re on one of those plans, they&#x27;re going to get Slackbot.\"However, some enterprise customers may face other cost pressures related to Salesforce&#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.Fivetran CEO George Fraser has warned that Salesforce&#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. \"They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,\" Fraser said in a recent CIO report.Salesforce has framed the pricing change as standard industry practice.What Slackbot can do today, what&#x27;s coming in weeks, and what&#x27;s still on the roadmapThe new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is \"coming a few weeks after,\" according to Seaman. Image generation is not currently supported, though Bauer said it&#x27;s \"something that we are looking at in the future.\"When asked about integration with competing CRM systems like HubSpot and Microsoft Dynamics, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.Salesforce is betting the future of work looks like a chat window—and it&#x27;s not aloneThe Slackbot launch is Salesforce&#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.Harris described Slack&#x27;s product philosophy using principles like \"don&#x27;t make me think\" and \"be a great host.\" The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.\"One of the revelations for me is LLMs applied to unstructured information are incredible,\" Harris said. \"And the amount of value you have if you&#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&#x27;re talking about work, you&#x27;re sharing documents, you&#x27;re making decisions, but you can&#x27;t as a human go through that and really get the same value that an LLM can do.\"Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. \"We&#x27;re kind of saturating what we can do with purely conversational UIs,\" he said. \"I think we&#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.\"Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.For Salesforce, the stakes extend beyond a single product launch. After a bruising year on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: \"I honestly can&#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.\"That&#x27;s precisely what Salesforce is counting on.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4Xrcg14GLKFlwSEnuEzxyS/21c85d29d03c4c974076475c009e3b38/nuneybits_Vector_art_of_chat_bubbles_on_a_computer_screen_in_th_5018a7ea-3496-4103-8453-7ba1b129189a.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/why-sakana-ais-big-win-is-a-big-deal-for-the-future-of-enterprise-agents",
          "published_at": "Tue, 13 Jan 2026 12:59:00 GMT",
          "title": "Why Sakana AI’s big win is a big deal for the future of enterprise agents",
          "standfirst": "In an impressive feat, Japanese startup Sakana AI’s coding agent ALE-Agent recently secured first place in the AtCoder Heuristic Contest (AHC058), a complex coding competition that involves complicated optimization problems — and a more difficult and perhaps telling challenge than benchmarks like HumanEval, which mostly test the ability to write isolated functions, and which many AI models and agents now regularly pass with ease (\"benchmark saturation\"). Sakana&#x27;s accomplishment with ALE-Agent hints at a shift toward agents capable of autonomously optimizing themselves to navigate and perform well in complex, dynamic systems such as enterprise software stacks, workflows, and operational environments. In four hours, the agent used inference-time scaling to generate, test, and iterate over hundreds of solutions, solving a problem that typically requires deep intuition and time-consuming trial and error from human experts. It outperformed over 800 human participants, including top-tier competitive programmers.How ALE-Agent worksThe challenge in AHC058 was a classic combinatorial optimization problem. Participants were tasked with managing a set of machines with hierarchical relationships, such as machines that produce apples, and other machines that build those apple-producing machines. The goal was to maximize output over a fixed number of turns.In the enterprise world, this workflow usually follows a strict pattern: a domain expert works with a client to define an \"objective function\" (aka the Scorer), and then engineers build a software system to optimize it. These problems are notoriously difficult because they cannot be solved in a single stage. They require exploration, strategy, and the ability to pivot when a plan isn&#x27;t working.Human experts typically approach this using a two-stage strategy. First, they use a \"Greedy\" method (a lightweight solver that makes the best immediate choice at each step) to generate a decent baseline solution. Then, they apply \"simulated annealing,\" a technique that takes the existing plan and makes tiny, random adjustments to see if the score improves. However, this standard approach is rigid. If the initial Greedy plan heads in the wrong direction, simulated annealing can rarely fix it because it only looks for local improvements in a faulty area of the solution space.ALE-Agent’s innovation was transforming this static initialization tool into a dynamic reconstruction engine. Instead of relying on immediate value, the agent independently derived a concept it called \"Virtual Power.\" It assigned values to components that were not yet operational, treating them as if they already possessed value. By valuing potential future assets rather than just current ones, the agent capitalized on the \"compound interest effect,\" a concept it explicitly identified in its internal logs. Basically, it could look a few steps ahead and reason about the future instead of looking at the immediate feedback it was receiving from its environment.Crucially, the agent needed to maintain this strategy over a four-hour window without losing focus, a common failure mode known as “context drift.” In comments provided to VentureBeat, the Sakana AI team explained that the agent generates textual \"insights\" by reflecting on each trial. It gathers this knowledge to prevent cycling back to previously failed strategies and creates a working memory that allows it to look a few steps ahead rather than just reacting to immediate feedback.Furthermore, the agent integrated Greedy methods directly into the simulated annealing phase to avoid getting stuck in local optima, using high-speed reconstruction to delete and rebuild large sections of the solution on the fly.From coding to enterprise optimizationThis breakthrough fits directly into existing enterprise workflows where a scoring function is already available. Currently, companies rely on scarce engineering talent to write optimization algorithms. ALE-Agent demonstrates a future where humans define the \"Scorer\" (i.e., the business logic and goals) and the agent handles the technical implementation.This shifts the operational bottleneck from engineering capacity to metric clarity. If an enterprise can measure a goal, the agent can optimize it. This has direct applications in logistics, such as vehicle routing, as well as server load balancing and resource allocation.According to the Sakana AI team, this could democratize optimization. \"It enables a future where non-technical clients can interact directly with the agent, tweaking business constraints in real-time until they get the output they desire,\" they said.The Sakana AI team told VentureBeat that ALE-Agent is currently proprietary and not available for public use, and the company is currently focused on internal development and proof-of-concept collaborations with enterprises.At the same time, the team is already looking ahead to \"self-rewriting\" agents. These future agents could define their own scorers, making them feasible for ill-defined problems where human experts struggle to formulate clear initial metrics.The cost of intelligenceRunning ALE-Agent was not cheap. The four-hour operation incurred approximately $1,300 in compute costs involving over 4,000 reasoning calls to models like GPT-5.2 and Gemini 3 Pro. While this price point might seem high for a single coding task, the return on investment for optimization problems is often asymmetric. In a resource-management setting, a one-time cost of a few thousand dollars can result in millions of dollars in annual efficiency savings.However, enterprises expecting costs to simply drop might be missing the strategic picture. While the cost of tokens is falling, total spend may actually rise as companies compete for better answers, a concept known as the Jevons paradox.\"While smarter algorithms will drive efficiency, the primary value of AI is its ability to explore vast solution spaces,\" the Sakana AI team said. \"As inference costs fall, rather than simply banking the savings, enterprises will likely choose to leverage that affordability to conduct even deeper, broader searches to find superior solutions.\"The experiment highlights the immense value still to be unlocked through inference-time scaling techniques. As AI systems gain the ability to handle complex reasoning tasks across longer contexts, building better scaffolding and allocating larger budgets for \"thinking time\" allows agents to rival top human experts.",
          "content": "In an impressive feat, Japanese startup Sakana AI’s coding agent ALE-Agent recently secured first place in the AtCoder Heuristic Contest (AHC058), a complex coding competition that involves complicated optimization problems — and a more difficult and perhaps telling challenge than benchmarks like HumanEval, which mostly test the ability to write isolated functions, and which many AI models and agents now regularly pass with ease (\"benchmark saturation\"). Sakana&#x27;s accomplishment with ALE-Agent hints at a shift toward agents capable of autonomously optimizing themselves to navigate and perform well in complex, dynamic systems such as enterprise software stacks, workflows, and operational environments. In four hours, the agent used inference-time scaling to generate, test, and iterate over hundreds of solutions, solving a problem that typically requires deep intuition and time-consuming trial and error from human experts. It outperformed over 800 human participants, including top-tier competitive programmers.How ALE-Agent worksThe challenge in AHC058 was a classic combinatorial optimization problem. Participants were tasked with managing a set of machines with hierarchical relationships, such as machines that produce apples, and other machines that build those apple-producing machines. The goal was to maximize output over a fixed number of turns.In the enterprise world, this workflow usually follows a strict pattern: a domain expert works with a client to define an \"objective function\" (aka the Scorer), and then engineers build a software system to optimize it. These problems are notoriously difficult because they cannot be solved in a single stage. They require exploration, strategy, and the ability to pivot when a plan isn&#x27;t working.Human experts typically approach this using a two-stage strategy. First, they use a \"Greedy\" method (a lightweight solver that makes the best immediate choice at each step) to generate a decent baseline solution. Then, they apply \"simulated annealing,\" a technique that takes the existing plan and makes tiny, random adjustments to see if the score improves. However, this standard approach is rigid. If the initial Greedy plan heads in the wrong direction, simulated annealing can rarely fix it because it only looks for local improvements in a faulty area of the solution space.ALE-Agent’s innovation was transforming this static initialization tool into a dynamic reconstruction engine. Instead of relying on immediate value, the agent independently derived a concept it called \"Virtual Power.\" It assigned values to components that were not yet operational, treating them as if they already possessed value. By valuing potential future assets rather than just current ones, the agent capitalized on the \"compound interest effect,\" a concept it explicitly identified in its internal logs. Basically, it could look a few steps ahead and reason about the future instead of looking at the immediate feedback it was receiving from its environment.Crucially, the agent needed to maintain this strategy over a four-hour window without losing focus, a common failure mode known as “context drift.” In comments provided to VentureBeat, the Sakana AI team explained that the agent generates textual \"insights\" by reflecting on each trial. It gathers this knowledge to prevent cycling back to previously failed strategies and creates a working memory that allows it to look a few steps ahead rather than just reacting to immediate feedback.Furthermore, the agent integrated Greedy methods directly into the simulated annealing phase to avoid getting stuck in local optima, using high-speed reconstruction to delete and rebuild large sections of the solution on the fly.From coding to enterprise optimizationThis breakthrough fits directly into existing enterprise workflows where a scoring function is already available. Currently, companies rely on scarce engineering talent to write optimization algorithms. ALE-Agent demonstrates a future where humans define the \"Scorer\" (i.e., the business logic and goals) and the agent handles the technical implementation.This shifts the operational bottleneck from engineering capacity to metric clarity. If an enterprise can measure a goal, the agent can optimize it. This has direct applications in logistics, such as vehicle routing, as well as server load balancing and resource allocation.According to the Sakana AI team, this could democratize optimization. \"It enables a future where non-technical clients can interact directly with the agent, tweaking business constraints in real-time until they get the output they desire,\" they said.The Sakana AI team told VentureBeat that ALE-Agent is currently proprietary and not available for public use, and the company is currently focused on internal development and proof-of-concept collaborations with enterprises.At the same time, the team is already looking ahead to \"self-rewriting\" agents. These future agents could define their own scorers, making them feasible for ill-defined problems where human experts struggle to formulate clear initial metrics.The cost of intelligenceRunning ALE-Agent was not cheap. The four-hour operation incurred approximately $1,300 in compute costs involving over 4,000 reasoning calls to models like GPT-5.2 and Gemini 3 Pro. While this price point might seem high for a single coding task, the return on investment for optimization problems is often asymmetric. In a resource-management setting, a one-time cost of a few thousand dollars can result in millions of dollars in annual efficiency savings.However, enterprises expecting costs to simply drop might be missing the strategic picture. While the cost of tokens is falling, total spend may actually rise as companies compete for better answers, a concept known as the Jevons paradox.\"While smarter algorithms will drive efficiency, the primary value of AI is its ability to explore vast solution spaces,\" the Sakana AI team said. \"As inference costs fall, rather than simply banking the savings, enterprises will likely choose to leverage that affordability to conduct even deeper, broader searches to find superior solutions.\"The experiment highlights the immense value still to be unlocked through inference-time scaling techniques. As AI systems gain the ability to handle complex reasoning tasks across longer contexts, building better scaffolding and allocating larger budgets for \"thinking time\" allows agents to rival top human experts.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3BUB5AM3ylCZKK1ID2lgQV/b563d16484c9a96c1bc412c1a4f404e2/AI_optimization_algorithm.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-151521620.html",
          "published_at": "Tue, 13 Jan 2026 12:15:21 +0000",
          "title": "The Morning After: Apple will use Gemini to power Siri AI",
          "standfirst": "Apple and Google have confirmed that Gemini’s models power the new version of Siri and other generative AI features. CNBC broke the news, but Apple and Google soon followed up with a lengthy joint statement. Here’s part of it: “Apple determined that Google’s Al technology provides the most capable foundation for Apple Foundation Models… Apple Intelligence will continue to run on Apple devices and Private Cloud Compute, while maintaining Apple’s industry-leading privacy standards.” In June, it was reported that Apple was considering partnerships with OpenAI and Anthropic for Siri (the voice assistant can currently tap ChatGPT for certain queries as part of Apple Intelligence). Two months later, Google emerged as a contender. Another report suggested Apple might build the new Siri using a custom version of Gemini — and that it would pay Google around $1 billion a year for the privilege. However, no official deal numbers were shared. It’s also notable that current iPhones have direct access to OpenAI’s ChatGPT. But how long for? — Mat Smith The other big stories this morning Engadget Podcast: Best of CES 2026 and a chat with Pebble’s founder Meta closes 550,000 accounts to comply with Australia’s kids social media ban The best winter tech to get you through the coldest months Meta appoints ex-Trump and Bush official as its new president and vice chair Netflix wins 7 awards at the Golden Globes Adolescence and KPop Demon Hunters picked up several each. Netflix Netflix’s hit show Adolescence received four awards, including best limited or anthology series. It also won best actor (Stephen Graham), supporting actor (Owen Cooper) and supporting actress (Erin Doherty) in a miniseries or television film. KPop Demon Hunters — which my nieces refuse to stop talking about — won best animated feature and best original song. “I just want to say this award goes to people who have had doors closed on them, and I can confidently say rejection is redirection. So never give up.” It’s not all good news. Netflix also won best performance in stand-up comedy on television for Ricky Gervais: Mortality. Apple and HBO Max each won three, and Hulu got one award on the night. Continue reading. NASA makes final preparations for its first crewed moon mission in over 50 years The agency is targeting a February launch date for Artemis 2. A few years ago, NASA announced it was pushing the Artemis 2 mission back to April 2026. The agency now says it could launch as early as February. NASA is finalizing preparations for the mission and will soon roll out the Space Launch System (SLS) rocket and the Orion spacecraft to the launch pad at the Kennedy Space Center in Florida. Artemis 2 is the first crewed mission to the moon since the Apollo program’s final flight in 1972. The 10-day mission will have four astronauts, who’ll test whether Orion’s critical life-support systems can sustain human passengers on future longer-duration missions. They will first orbit the Earth twice before making their way 4,700 miles beyond the far side of the moon. Continue reading. Lego’s first Pokémon sets are now available for pre-order Pikachu, Eevee, Venusaur, Charizard and Blastoise will ship February 27. Lego Pre-orders for the first three Lego-Pokémon kits are open now. One of the debut pocket monsters is, of course, Pikachu. You can build the 2,050-piece kit to show Pikachu either at rest or leaping out of an open Poké Ball into battle. It costs $200. There’s also a 587-piece model of Eevee, for $60. On the bigger side is a set featuring a trio of Pokémon: Venusaur, Charizard and Blastoise. This kit has 6,838 pieces and can show the group together in battle formation or separately in their own mini environments. It retails for $650 and is a bit much. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-151521620.html?src=rss",
          "content": "Apple and Google have confirmed that Gemini’s models power the new version of Siri and other generative AI features. CNBC broke the news, but Apple and Google soon followed up with a lengthy joint statement. Here’s part of it: “Apple determined that Google’s Al technology provides the most capable foundation for Apple Foundation Models… Apple Intelligence will continue to run on Apple devices and Private Cloud Compute, while maintaining Apple’s industry-leading privacy standards.” In June, it was reported that Apple was considering partnerships with OpenAI and Anthropic for Siri (the voice assistant can currently tap ChatGPT for certain queries as part of Apple Intelligence). Two months later, Google emerged as a contender. Another report suggested Apple might build the new Siri using a custom version of Gemini — and that it would pay Google around $1 billion a year for the privilege. However, no official deal numbers were shared. It’s also notable that current iPhones have direct access to OpenAI’s ChatGPT. But how long for? — Mat Smith The other big stories this morning Engadget Podcast: Best of CES 2026 and a chat with Pebble’s founder Meta closes 550,000 accounts to comply with Australia’s kids social media ban The best winter tech to get you through the coldest months Meta appoints ex-Trump and Bush official as its new president and vice chair Netflix wins 7 awards at the Golden Globes Adolescence and KPop Demon Hunters picked up several each. Netflix Netflix’s hit show Adolescence received four awards, including best limited or anthology series. It also won best actor (Stephen Graham), supporting actor (Owen Cooper) and supporting actress (Erin Doherty) in a miniseries or television film. KPop Demon Hunters — which my nieces refuse to stop talking about — won best animated feature and best original song. “I just want to say this award goes to people who have had doors closed on them, and I can confidently say rejection is redirection. So never give up.” It’s not all good news. Netflix also won best performance in stand-up comedy on television for Ricky Gervais: Mortality. Apple and HBO Max each won three, and Hulu got one award on the night. Continue reading. NASA makes final preparations for its first crewed moon mission in over 50 years The agency is targeting a February launch date for Artemis 2. A few years ago, NASA announced it was pushing the Artemis 2 mission back to April 2026. The agency now says it could launch as early as February. NASA is finalizing preparations for the mission and will soon roll out the Space Launch System (SLS) rocket and the Orion spacecraft to the launch pad at the Kennedy Space Center in Florida. Artemis 2 is the first crewed mission to the moon since the Apollo program’s final flight in 1972. The 10-day mission will have four astronauts, who’ll test whether Orion’s critical life-support systems can sustain human passengers on future longer-duration missions. They will first orbit the Earth twice before making their way 4,700 miles beyond the far side of the moon. Continue reading. Lego’s first Pokémon sets are now available for pre-order Pikachu, Eevee, Venusaur, Charizard and Blastoise will ship February 27. Lego Pre-orders for the first three Lego-Pokémon kits are open now. One of the debut pocket monsters is, of course, Pikachu. You can build the 2,050-piece kit to show Pikachu either at rest or leaping out of an open Poké Ball into battle. It costs $200. There’s also a 587-piece model of Eevee, for $60. On the bigger side is a set featuring a trio of Pokémon: Venusaur, Charizard and Blastoise. This kit has 6,838 pieces and can show the group together in battle formation or separately in their own mini environments. It retails for $650 and is a bit much. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-151521620.html?src=rss",
          "feed_position": 41,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/28879300-f057-11f0-baeb-ffbd608b486c"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/best-streaming-devices-media-players-123021395.html",
          "published_at": "Tue, 13 Jan 2026 10:01:26 +0000",
          "title": "The best streaming devices for 2026",
          "standfirst": "With the dominance of smart TVs, streaming sticks and boxes may seem redundant — but if your smart set is slow or has a frustrating user interface, a streaming device will let you bypass your TV’s built-in OS and use Google TV, Fire TV, Apple TV or something else instead. There are a lot of streaming gadgets out there, all with different operating systems, memory capacities, video resolutions and bonus features, such as headphone connections and ambient modes that fill your screen with stills when you’re not watching. We tested options from the major brands and broke down exactly what each device gives you so you can pick the best streaming device for your TV. Table of contents The best TV streaming devices for 2026 What to look for in a TV streaming device How we tested and picked the best streaming devices Best streaming devices for 2026 What to look for in a TV streaming device Operating system and interface Google’s TV Streamer, the Apple TV 4K, Amazon’s Fire TV Sticks and Roku devices are the most popular players in the space. Three of those brands also come built into TVs, such as Fire, Google and Roku TVs, but the Apple TV 4K doesn't come pre-loaded on any set. Each one has a unique operating system and interface. This may be the biggest deciding factor for many people, as it determines how the home entertainment you want to watch is arranged and presented. We go into detail for each platform below, but all of them come with home screens that, to varying degrees, gather your apps in one place, present the movies and TV shows you’re currently watching and give you suggestions of other media streaming options. Nearly all streaming devices come with a remote that lets you search and do other operations using your voice, eliminating the need to hunt and peck at on-screen keyboards. They all offer “universal search,” in which searching for a title takes you to whichever app has it available. If you want to watch Wicked but don’t know where it’s playing, just push the voice button on the remote and say \"Wicked.” (We found simply saying the title or the genre you want sometimes works better than saying “Show me…” or “Search for…”) From the search results, hit the play button and the correct app will open and start playing — assuming you’ve previously logged into that app and, in most cases, have an active subscription. Connectivity Most streaming sticks connect to the internet via Wi-Fi, with the majority of them supporting Wi-Fi 5 or 6 protocols. Set-top boxes can also have Ethernet ports, so you can hardwire your internet connection to the device, which is typically faster than wireless. Streaming media players connect to your TV through an HDMI port, and most sticks hide behind the screen, while set-top boxes sit on a surface nearby. Nearly all units also plug into an AC outlet for power. Some sticks used to work by pulling power from a USB port on the TV, but increasingly, these devices are designed to plug into the wall. Video and audio features If your home theater setup has a screen that can display 4K content with Dolby Vision and HDR10, you’ll want a streaming device that supports those high-end formats. Of course, even the most top-shelf streamer can’t make a 1080p TV stream 4K. The series or movie also has to be transmitted in 4K and, increasingly, companies restrict higher-quality streaming to more expensive subscription plans. In short, every element needs to support the video or audio feature, otherwise the highest quality you’ll get will be the lowest of any component in the chain. Remotes Most remotes that come with streaming devices will allow you to control the power and volume of your TV. Some of the less expensive devices, however, don't have that feature, so you'll need to use your TV's remote control to turn it on, then use the streaming remote to navigate the streamer's interface. If your streamer's remote does offer power and volume controls, the setup process will usually calibrate your remote to your TV. If you want to use a soundbar, such as from Sonos or other brands, for audio you may also have to take the additional step of pairing your remote to the speaker. Voice control In addition to helping you find stuff to watch, streaming devices from Apple, Google and Amazon can answer questions about the weather, sports scores and general facts using built-in voice assistants. They can also act as smart home controllers to turn off connected smart bulbs or plugs and show feeds from smart cameras. Just remember, as with all smart home devices, compatibility is key. Fire TV devices work with Alexa-enabled smart home equipment; the Google TV Streamer lets you control Google Home devices; and Apple TV 4Ks play nice with HomeKit and other Apple devices. Rokus grant power over Roku’s smart home products, but also work with the other ecosystems. How we tested and picked the best streaming devices Like every gadget we test, we start by researching what’s worthy of reviewing. Then we get a hold of the devices ourselves and see how well they work. We don’t have a central Engadget lab; we test things in our own living rooms, on our own TV sets. We also figure that’s a better approximation of your own TV experience anyway. We began testing streaming devices as far back as 2007 with the first Apple TV device. Since then, we’ve tried out most of the major new releases to come along — from the Roku Stick back in 2014 to the 2024 Google TV Streamer 4K. A few years ago, we decided to compile the streaming devices we reviewed into this guide. Since then, we’ve updated our top picks using verdicts from our reviews, as well the testing we perform just for this guide. As new devices come out, we try them and, if something is worthy, we add it to our top picks on this list.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/best-streaming-devices-media-players-123021395.html?src=rss",
          "content": "With the dominance of smart TVs, streaming sticks and boxes may seem redundant — but if your smart set is slow or has a frustrating user interface, a streaming device will let you bypass your TV’s built-in OS and use Google TV, Fire TV, Apple TV or something else instead. There are a lot of streaming gadgets out there, all with different operating systems, memory capacities, video resolutions and bonus features, such as headphone connections and ambient modes that fill your screen with stills when you’re not watching. We tested options from the major brands and broke down exactly what each device gives you so you can pick the best streaming device for your TV. Table of contents The best TV streaming devices for 2026 What to look for in a TV streaming device How we tested and picked the best streaming devices Best streaming devices for 2026 What to look for in a TV streaming device Operating system and interface Google’s TV Streamer, the Apple TV 4K, Amazon’s Fire TV Sticks and Roku devices are the most popular players in the space. Three of those brands also come built into TVs, such as Fire, Google and Roku TVs, but the Apple TV 4K doesn't come pre-loaded on any set. Each one has a unique operating system and interface. This may be the biggest deciding factor for many people, as it determines how the home entertainment you want to watch is arranged and presented. We go into detail for each platform below, but all of them come with home screens that, to varying degrees, gather your apps in one place, present the movies and TV shows you’re currently watching and give you suggestions of other media streaming options. Nearly all streaming devices come with a remote that lets you search and do other operations using your voice, eliminating the need to hunt and peck at on-screen keyboards. They all offer “universal search,” in which searching for a title takes you to whichever app has it available. If you want to watch Wicked but don’t know where it’s playing, just push the voice button on the remote and say \"Wicked.” (We found simply saying the title or the genre you want sometimes works better than saying “Show me…” or “Search for…”) From the search results, hit the play button and the correct app will open and start playing — assuming you’ve previously logged into that app and, in most cases, have an active subscription. Connectivity Most streaming sticks connect to the internet via Wi-Fi, with the majority of them supporting Wi-Fi 5 or 6 protocols. Set-top boxes can also have Ethernet ports, so you can hardwire your internet connection to the device, which is typically faster than wireless. Streaming media players connect to your TV through an HDMI port, and most sticks hide behind the screen, while set-top boxes sit on a surface nearby. Nearly all units also plug into an AC outlet for power. Some sticks used to work by pulling power from a USB port on the TV, but increasingly, these devices are designed to plug into the wall. Video and audio features If your home theater setup has a screen that can display 4K content with Dolby Vision and HDR10, you’ll want a streaming device that supports those high-end formats. Of course, even the most top-shelf streamer can’t make a 1080p TV stream 4K. The series or movie also has to be transmitted in 4K and, increasingly, companies restrict higher-quality streaming to more expensive subscription plans. In short, every element needs to support the video or audio feature, otherwise the highest quality you’ll get will be the lowest of any component in the chain. Remotes Most remotes that come with streaming devices will allow you to control the power and volume of your TV. Some of the less expensive devices, however, don't have that feature, so you'll need to use your TV's remote control to turn it on, then use the streaming remote to navigate the streamer's interface. If your streamer's remote does offer power and volume controls, the setup process will usually calibrate your remote to your TV. If you want to use a soundbar, such as from Sonos or other brands, for audio you may also have to take the additional step of pairing your remote to the speaker. Voice control In addition to helping you find stuff to watch, streaming devices from Apple, Google and Amazon can answer questions about the weather, sports scores and general facts using built-in voice assistants. They can also act as smart home controllers to turn off connected smart bulbs or plugs and show feeds from smart cameras. Just remember, as with all smart home devices, compatibility is key. Fire TV devices work with Alexa-enabled smart home equipment; the Google TV Streamer lets you control Google Home devices; and Apple TV 4Ks play nice with HomeKit and other Apple devices. Rokus grant power over Roku’s smart home products, but also work with the other ecosystems. How we tested and picked the best streaming devices Like every gadget we test, we start by researching what’s worthy of reviewing. Then we get a hold of the devices ourselves and see how well they work. We don’t have a central Engadget lab; we test things in our own living rooms, on our own TV sets. We also figure that’s a better approximation of your own TV experience anyway. We began testing streaming devices as far back as 2007 with the first Apple TV device. Since then, we’ve tried out most of the major new releases to come along — from the Roku Stick back in 2014 to the 2024 Google TV Streamer 4K. A few years ago, we decided to compile the streaming devices we reviewed into this guide. Since then, we’ve updated our top picks using verdicts from our reviews, as well the testing we perform just for this guide. As new devices come out, we try them and, if something is worthy, we add it to our top picks on this list.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/best-streaming-devices-media-players-123021395.html?src=rss",
          "feed_position": 43
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/legos-first-pokemon-sets-are-now-available-for-pre-order-205527102.html",
          "published_at": "Mon, 12 Jan 2026 20:55:27 +0000",
          "title": "Lego's first Pokémon sets are now available for pre-order",
          "standfirst": "We learned last March that Lego and Pokémon would be joining forces and the first results of their partnership are here. Pre-orders for all three kits are open now, with an expected ship date of February 27. As one might have guessed from the lightning bolts on the previous promotional image, one of the debut pocket monsters getting the brick treatment is Pikachu, complete with a Poké Ball. The 2,050-piece kit can be built to show Pikachu either leaping out of the open Poké Ball into battle or at rest staring up at the builder, closed Poké Ball between his paws. The Pikachu kit costs $200. There's also a 587-piece model of Eevee, which goes for $60. On the bigger side is a set featuring a trio of Pokémon: Venusaur, Charizard and Blastoise. This kit has 6,838 pieces and can show the group together in battle formation or separately in their own mini environments. It retails for $650. Lego Before you leap to pre-order pages, however, here's a word of caution. In Lego form, our little friends look…kinda strange? I'm not the biggest Lego builder, but I am a rather accomplished architect in Minecraft, so I am well aware of the innate challenge in constructing a rounded shape from square blocks. Take Pikachu, for instance. Part of his appeal is his chubby little cheeks. There are bricks with more rounded sides in this collection that hint at his usual rotundness, but the proportions of his face just feel a little off to me. I had the same reaction to the other figures as well, although Eevee seems to have fared a little better than the others. They're all sort of cute, but not nearly so cute as they are in other formats. But like I said, Lego is not my personal block of choice, so perhaps I'm in the minority here! If you love these bricky pocket monsters, then roll on over to Lego's website and snap up these kits faster than a Mewtwo. This article originally appeared on Engadget at https://www.engadget.com/entertainment/legos-first-pokemon-sets-are-now-available-for-pre-order-205527102.html?src=rss",
          "content": "We learned last March that Lego and Pokémon would be joining forces and the first results of their partnership are here. Pre-orders for all three kits are open now, with an expected ship date of February 27. As one might have guessed from the lightning bolts on the previous promotional image, one of the debut pocket monsters getting the brick treatment is Pikachu, complete with a Poké Ball. The 2,050-piece kit can be built to show Pikachu either leaping out of the open Poké Ball into battle or at rest staring up at the builder, closed Poké Ball between his paws. The Pikachu kit costs $200. There's also a 587-piece model of Eevee, which goes for $60. On the bigger side is a set featuring a trio of Pokémon: Venusaur, Charizard and Blastoise. This kit has 6,838 pieces and can show the group together in battle formation or separately in their own mini environments. It retails for $650. Lego Before you leap to pre-order pages, however, here's a word of caution. In Lego form, our little friends look…kinda strange? I'm not the biggest Lego builder, but I am a rather accomplished architect in Minecraft, so I am well aware of the innate challenge in constructing a rounded shape from square blocks. Take Pikachu, for instance. Part of his appeal is his chubby little cheeks. There are bricks with more rounded sides in this collection that hint at his usual rotundness, but the proportions of his face just feel a little off to me. I had the same reaction to the other figures as well, although Eevee seems to have fared a little better than the others. They're all sort of cute, but not nearly so cute as they are in other formats. But like I said, Lego is not my personal block of choice, so perhaps I'm in the minority here! If you love these bricky pocket monsters, then roll on over to Lego's website and snap up these kits faster than a Mewtwo. This article originally appeared on Engadget at https://www.engadget.com/entertainment/legos-first-pokemon-sets-are-now-available-for-pre-order-205527102.html?src=rss",
          "feed_position": 45,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/22428cc0-eff8-11f0-bff5-4310bbcdcba3"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/dell-revives-its-xps-laptops-after-a-boneheaded-rebranding-001028029.html",
          "published_at": "Mon, 12 Jan 2026 20:25:47 +0000",
          "title": "Dell revives its XPS laptops after a boneheaded rebranding",
          "standfirst": "Last year, Dell killed off all of its PC brands, including the iconic XPS lineup, and replaced them with a simplified naming scheme. It was a move meant to make it easier for people to discern between the company's many brands, but in reality, it just just made the company's lineup even more confusing. We called it an unforced error at the time, but after seeing how much Dell's PC market share fell over 2025, it's fair to say that rebranding was an absolute marketing disaster. So, with its tail between its legs, Dell has returned to CES some welcome news for its fans: XPS lives! And the company plans to double-down on the brand in ways it never did before. Today, Dell revealed the new XPS 14 and 16 notebooks, which feature a more practical design than the previous models. There's a new function row with traditional keys, instead of the odd capacitive buttons that disappeared in sunlight. And while the company is sticking with its \"invisible\" trackpad, which sits flush alongside the wrist rest, there's now a light border around the edges that lets you feel exactly where the trackpad begins and ends.So, in short, Dell seems to have solved most of our recent complaints about the XPS lineup. To signify its commitment to the brand, it's also emblazoning the XPS logo on all of these new machines, replacing the previous Dell name. That’s something I could never imagine a less humbled Dell doing. The redesign also gave Dell room to shave off some weight and thickness from both machines. The XPS 14 weighs around three pounds now, a half-pound lighter than the previous generation, while the XPS 16 weighs 3.6 pounds, a whole pound lighter than before. The new cases make both machines look a lot more like Microsoft’s extra-subtle Surface Laptop, but that’s not necessarily a bad thing. Both systems are powered by Intel’s new Panther Lake Core Ultra Series 3 chips, and they also offer tandem OLED display options.Dell also briefly teased the return of a new XPS 13 later this year, which is set to be the company’s thinnest and lightest notebook ever. Dell says it’ll be cheaper than the XPS has been in the past.The new XPS 14 and 16 will be available on January 6, starting at $2,050 and $2,200, respectively. A Dell representative tells us these aren’t entry-level configurations, instead we can expect to see cheaper prices with lower specs in February.Update 1/6/26, 12:30p: Pricing updated to reflecrt new numbers from Dell. Originally, we were told they would start at $1,650 and $1,850.Update 1/12, 3:00p: Added a mention of lower entry-level configurations coming eventually.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/dell-revives-its-xps-laptops-after-a-boneheaded-rebranding-001028029.html?src=rss",
          "content": "Last year, Dell killed off all of its PC brands, including the iconic XPS lineup, and replaced them with a simplified naming scheme. It was a move meant to make it easier for people to discern between the company's many brands, but in reality, it just just made the company's lineup even more confusing. We called it an unforced error at the time, but after seeing how much Dell's PC market share fell over 2025, it's fair to say that rebranding was an absolute marketing disaster. So, with its tail between its legs, Dell has returned to CES some welcome news for its fans: XPS lives! And the company plans to double-down on the brand in ways it never did before. Today, Dell revealed the new XPS 14 and 16 notebooks, which feature a more practical design than the previous models. There's a new function row with traditional keys, instead of the odd capacitive buttons that disappeared in sunlight. And while the company is sticking with its \"invisible\" trackpad, which sits flush alongside the wrist rest, there's now a light border around the edges that lets you feel exactly where the trackpad begins and ends.So, in short, Dell seems to have solved most of our recent complaints about the XPS lineup. To signify its commitment to the brand, it's also emblazoning the XPS logo on all of these new machines, replacing the previous Dell name. That’s something I could never imagine a less humbled Dell doing. The redesign also gave Dell room to shave off some weight and thickness from both machines. The XPS 14 weighs around three pounds now, a half-pound lighter than the previous generation, while the XPS 16 weighs 3.6 pounds, a whole pound lighter than before. The new cases make both machines look a lot more like Microsoft’s extra-subtle Surface Laptop, but that’s not necessarily a bad thing. Both systems are powered by Intel’s new Panther Lake Core Ultra Series 3 chips, and they also offer tandem OLED display options.Dell also briefly teased the return of a new XPS 13 later this year, which is set to be the company’s thinnest and lightest notebook ever. Dell says it’ll be cheaper than the XPS has been in the past.The new XPS 14 and 16 will be available on January 6, starting at $2,050 and $2,200, respectively. A Dell representative tells us these aren’t entry-level configurations, instead we can expect to see cheaper prices with lower specs in February.Update 1/6/26, 12:30p: Pricing updated to reflecrt new numbers from Dell. Originally, we were told they would start at $1,650 and $1,850.Update 1/12, 3:00p: Added a mention of lower entry-level configurations coming eventually.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/dell-revives-its-xps-laptops-after-a-boneheaded-rebranding-001028029.html?src=rss",
          "feed_position": 46
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/ces-2026-proved-the-pc-industry-is-hosed-this-year-174500314.html",
          "published_at": "Mon, 12 Jan 2026 20:25:38 +0000",
          "title": "CES 2026 proved the PC industry is hosed this year",
          "standfirst": "Dell's XPS 14 currently costs over $2,000. An AMD executive predicts that PC builders will likely make piecemeal upgrades this year, instead of building entirely new systems. And new AI supercomputers from NVIDIA and AMD are gobbling up the RAM market. At CES 2026, it was hard not to notice the dire year ahead for the computing industry, one that will likely lead to higher prices and more limited availability for consumer goods across the board.Really, though, the show just confirmed what was apparent since RAM prices skyrocketed over the last few months, driven by demand from AI datacenters. As Samsung's marketing leader, Wonjin Lee, told Bloomberg at CES: \"There's going to be issues around semiconductor supplies, and it's going to affect everyone. Prices are going up even as we speak.\"At first, it appeared that Dell's new XPS 14 and XPS 16 were among the earliest systems hit by these demands. Last year's models started at $1,699 and $1,899, respectively, and we were initially told the new models would actually come in cheaper at $1,650 and $1,850. At the moment, the XPS 14 starts at $2,050, while the XPS 16 is $2,200. A Dell representative tells us these aren’t entry-level configurations, instead we can expect to see cheaper systems below $2,000 in February. While those prices haven’t been finalized, the reps say it should be similar to the earlier figures we were given.It’s also worth noting that it didn't take much to configure the earlier models upwards of $2,000. It’s just unfortunate that Dell doesn’t have cheaper configurations available for the launch if its new systems, especially since they look so compelling. Meanwhile, Apple still hasn't budged its $1,599 MacBook Pro 14-inch pricing. At least Dell still comes in cheaper than the $2,499 MacBook Pro 16-inch.On the desktop front, AMD's David McAfee, Corporate Vice President and GM of Client Channel Business, noted that the longevity of the company's AM4 and AM5 platforms might be a boon for gamers, since they can upgrade their CPUs without buying new RAM kits and motherboards. That allows for a pathway to better performance without paying out the nose for over-priced RAM.\"I think that will be potentially a trend that we see in 2026 with more component upgrades, as opposed to full system swap outs and, and altogether rebuilds,\" he said in a group interview with Engadget and other outlets. \"Some of the most popular CPUs that are still running in gamers’ platforms are parts like the 2600 back to the Pinnacle Ridge days, or 3000 series... Stepping even from there into a little bit more modern 5,000 series processors in an AM4 socket and motherboard, there's a pretty big boost there.\"McAfee added that around 30 to 40 percent of AMD's business still revolves around the AM4 platform, even without the specter of a wild memory market.\"There's no product that has memory in it that's immune to some of these forces around DRAM pricing and, and what it's doing to the market,\" he said, when asked about potential GPU price increases. \"I think the, the truth is the volatility that we've seen over the past two months or so has really been unprecedented.\" Looking ahead, he said he expects prices to settle within the first three to six months of the year, but he didn't discuss his reasoning further. As an aside, he also noted that AMD's X3D chips, which feature 3D V-cache, actually don't see much of a hit from slower RAM. Their high amounts of onboard L2 and L3 cache make up for less ideal memory transfer speeds, McAfee said.That McAfee commented at all about the state of RAM is noteworthy. Every PC maker I’ve asked, including Dell and Acer, refused to comment on the volatile state of the memory industry ahead of CES. Perhaps they were hoping things would calm down before they had to price their new systems. Ultimately, they’re beholden to an increasingly limited supply of RAM. And where is all that memory going? At CES, NVIDIA announced its new Vera Rubin AI supercomputer, which supports up to 54TB of RAM across 36 Vera CPUs and 20.7TB of memory across 72 GPUs. AMD, as well, announced its new Helios AI rack, which supports up to 31TB of memory across 72 AMD Instinct MI455X GPUs. Given the endless appetite for computing to power AI model building and inferencing, there’s likely going to be a significant demand for these beastly systems.Put simply: Our global supply of memory is being sacrificed to appease the AI industry. That’s good news for the likes of OpenAI, Microsoft and NVIDIA, but bad news for anyone who cares about PCs and the consumer products we use every day. Get ready for a year of price hikes. Update 1/12, 3:00p: Added a mention of lower entry-level configurations coming eventually.This article originally appeared on Engadget at https://www.engadget.com/computing/ces-2026-proved-the-pc-industry-is-hosed-this-year-174500314.html?src=rss",
          "content": "Dell's XPS 14 currently costs over $2,000. An AMD executive predicts that PC builders will likely make piecemeal upgrades this year, instead of building entirely new systems. And new AI supercomputers from NVIDIA and AMD are gobbling up the RAM market. At CES 2026, it was hard not to notice the dire year ahead for the computing industry, one that will likely lead to higher prices and more limited availability for consumer goods across the board.Really, though, the show just confirmed what was apparent since RAM prices skyrocketed over the last few months, driven by demand from AI datacenters. As Samsung's marketing leader, Wonjin Lee, told Bloomberg at CES: \"There's going to be issues around semiconductor supplies, and it's going to affect everyone. Prices are going up even as we speak.\"At first, it appeared that Dell's new XPS 14 and XPS 16 were among the earliest systems hit by these demands. Last year's models started at $1,699 and $1,899, respectively, and we were initially told the new models would actually come in cheaper at $1,650 and $1,850. At the moment, the XPS 14 starts at $2,050, while the XPS 16 is $2,200. A Dell representative tells us these aren’t entry-level configurations, instead we can expect to see cheaper systems below $2,000 in February. While those prices haven’t been finalized, the reps say it should be similar to the earlier figures we were given.It’s also worth noting that it didn't take much to configure the earlier models upwards of $2,000. It’s just unfortunate that Dell doesn’t have cheaper configurations available for the launch if its new systems, especially since they look so compelling. Meanwhile, Apple still hasn't budged its $1,599 MacBook Pro 14-inch pricing. At least Dell still comes in cheaper than the $2,499 MacBook Pro 16-inch.On the desktop front, AMD's David McAfee, Corporate Vice President and GM of Client Channel Business, noted that the longevity of the company's AM4 and AM5 platforms might be a boon for gamers, since they can upgrade their CPUs without buying new RAM kits and motherboards. That allows for a pathway to better performance without paying out the nose for over-priced RAM.\"I think that will be potentially a trend that we see in 2026 with more component upgrades, as opposed to full system swap outs and, and altogether rebuilds,\" he said in a group interview with Engadget and other outlets. \"Some of the most popular CPUs that are still running in gamers’ platforms are parts like the 2600 back to the Pinnacle Ridge days, or 3000 series... Stepping even from there into a little bit more modern 5,000 series processors in an AM4 socket and motherboard, there's a pretty big boost there.\"McAfee added that around 30 to 40 percent of AMD's business still revolves around the AM4 platform, even without the specter of a wild memory market.\"There's no product that has memory in it that's immune to some of these forces around DRAM pricing and, and what it's doing to the market,\" he said, when asked about potential GPU price increases. \"I think the, the truth is the volatility that we've seen over the past two months or so has really been unprecedented.\" Looking ahead, he said he expects prices to settle within the first three to six months of the year, but he didn't discuss his reasoning further. As an aside, he also noted that AMD's X3D chips, which feature 3D V-cache, actually don't see much of a hit from slower RAM. Their high amounts of onboard L2 and L3 cache make up for less ideal memory transfer speeds, McAfee said.That McAfee commented at all about the state of RAM is noteworthy. Every PC maker I’ve asked, including Dell and Acer, refused to comment on the volatile state of the memory industry ahead of CES. Perhaps they were hoping things would calm down before they had to price their new systems. Ultimately, they’re beholden to an increasingly limited supply of RAM. And where is all that memory going? At CES, NVIDIA announced its new Vera Rubin AI supercomputer, which supports up to 54TB of RAM across 36 Vera CPUs and 20.7TB of memory across 72 GPUs. AMD, as well, announced its new Helios AI rack, which supports up to 31TB of memory across 72 AMD Instinct MI455X GPUs. Given the endless appetite for computing to power AI model building and inferencing, there’s likely going to be a significant demand for these beastly systems.Put simply: Our global supply of memory is being sacrificed to appease the AI industry. That’s good news for the likes of OpenAI, Microsoft and NVIDIA, but bad news for anyone who cares about PCs and the consumer products we use every day. Get ready for a year of price hikes. Update 1/12, 3:00p: Added a mention of lower entry-level configurations coming eventually.This article originally appeared on Engadget at https://www.engadget.com/computing/ces-2026-proved-the-pc-industry-is-hosed-this-year-174500314.html?src=rss",
          "feed_position": 47
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/7szF9iF50458lvbJ6Hyb36/9cb490b66a50d662947b1fd978204626/G2.png?w=300&q=30",
      "popularity_score": 2019.6658966666666
    },
    {
      "id": "cluster_8",
      "coverage": 2,
      "updated_at": "Wed, 14 Jan 2026 18:54:40 +0000",
      "title": "Verizon Outage Knocks Out US Mobile Service, Including Some 911 Calls",
      "neutral_headline": "Verizon Outage Knocks Out US Mobile Service, Including Some 911 Calls",
      "items": [
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/verizon-outage-knocks-out-us-mobile-service-including-some-911-calls/",
          "published_at": "Wed, 14 Jan 2026 18:54:40 +0000",
          "title": "Verizon Outage Knocks Out US Mobile Service, Including Some 911 Calls",
          "standfirst": "A major Verizon outage appeared to impact customers across the United States starting around noon ET on Wednesday. Calls to Verizon customers from other carriers may also be impacted.",
          "content": "A major Verizon outage appeared to impact customers across the United States starting around noon ET on Wednesday. Calls to Verizon customers from other carriers may also be impacted.",
          "feed_position": 1,
          "image_url": "https://media.wired.com/photos/6967de11685933202e631c16/master/pass/Major-Cell-Service-Outage-Security-2246554747.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/861956/verizon-is-down-outage-cell-wireless-service-sos-mode",
          "published_at": "2026-01-14T13:44:23-05:00",
          "title": "Verizon’s wireless network is down for many people nationwide",
          "standfirst": "The first big outage of 2026 is here, as Verizon customers across the US, including several of our phones, complain that service has been spotty or nonexistent starting at around noon ET, with phones switching to SOS Mode and being unable to connect. This cell service outage follows a \"software issue\" that cut off service [&#8230;]",
          "content": "The first big outage of 2026 is here, as Verizon customers across the US, including several of our phones, complain that service has been spotty or nonexistent starting at around noon ET, with phones switching to SOS Mode and being unable to connect. This cell service outage follows a \"software issue\" that cut off service for many people in August for several hours, and while Verizon has acknowledged the issue, there is no word yet on when it will be fixed. Verizon: We are aware of an issue impacting wireless voice and data services for some customers. Our engineers are engaged and are working to identify and solve the issue quickly. We … Read the full story at The Verge.",
          "feed_position": 2
        }
      ],
      "featured_image": "https://media.wired.com/photos/6967de11685933202e631c16/master/pass/Major-Cell-Service-Outage-Security-2246554747.jpg",
      "popularity_score": 2019.5770077777777
    },
    {
      "id": "cluster_23",
      "coverage": 2,
      "updated_at": "Wed, 14 Jan 2026 17:46:19 +0000",
      "title": "Bandcamp bans purely AI-generated music from its platform",
      "neutral_headline": "Bandcamp bans purely AI-generated music from its platform",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/ai/2026/01/bandcamp-bans-purely-ai-generated-music-from-its-platform/",
          "published_at": "Wed, 14 Jan 2026 17:46:19 +0000",
          "title": "Bandcamp bans purely AI-generated music from its platform",
          "standfirst": "Indie music store says it wants fans to have confidence music was largely made by humans.",
          "content": "On Tuesday, Bandcamp announced on Reddit that it will no longer permit AI-generated music on its platform. \"Music and audio that is generated wholly or in substantial part by AI is not permitted on Bandcamp,\" the company wrote in a post to the r/bandcamp subreddit. The new policy also prohibits \"any use of AI tools to impersonate other artists or styles.\" The policy draws a line that some in the music community have debated: Where does tool use end and full automation begin? AI models are not artists in themselves, since they lack personhood and creative intent. But people do use AI tools to make music, and the spectrum runs from using AI for minor assistance (cleaning up audio, suggesting chord progressions) to typing a prompt and letting a model generate an entire track. Bandcamp's policy targets the latter end of that spectrum while leaving room for human artists who incorporate AI tools into a larger creative process. The announcement emphasized the platform's desire to protect its community of human artists. \"The fact that Bandcamp is home to such a vibrant community of real people making incredible music is something we want to protect and maintain,\" the company wrote. Bandcamp asked users to flag suspected AI-generated content through its reporting tools, and the company said it reserves \"the right to remove any music on suspicion of being AI generated.\"Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/no_robot_music_2-1152x648.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/14/bandcamp-takes-a-stand-against-ai-music-banning-it-from-the-platform/",
          "published_at": "Wed, 14 Jan 2026 17:06:04 +0000",
          "title": "Bandcamp takes a stand against AI music, banning it from the platform",
          "standfirst": "\"We want musicians to keep making music, and for fans to have confidence that the music they find on Bandcamp was created by humans,\" the company said.",
          "content": "\"We want musicians to keep making music, and for fans to have confidence that the music they find on Bandcamp was created by humans,\" the company said.",
          "feed_position": 4
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/no_robot_music_2-1152x648.jpg",
      "popularity_score": 2018.437841111111
    },
    {
      "id": "cluster_32",
      "coverage": 2,
      "updated_at": "Wed, 14 Jan 2026 16:13:33 +0000",
      "title": "Robotics software maker Skild AI hits $14B valuation",
      "neutral_headline": "Robotics software maker Skild AI hits $14B valuation",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/14/robotic-software-maker-skild-ai-hits-14b-valuation/",
          "published_at": "Wed, 14 Jan 2026 16:13:33 +0000",
          "title": "Robotics software maker Skild AI hits $14B valuation",
          "standfirst": "Skild AI, which is building general-purpose robotic software, just raised a $1.4 billion funding round led by SoftBank.",
          "content": "Skild AI, which is building general-purpose robotic software, just raised a $1.4 billion funding round led by SoftBank.",
          "feed_position": 6
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260114/p30#a260114p30",
          "published_at": "Wed, 14 Jan 2026 08:10:02 -0500",
          "title": "Pittsburgh-based Skild AI, which makes robotics foundation models, raised a $1.4B Series C at a $14B+ valuation, up from ~$4.5B in June 2025 (Samantha Kelly/Bloomberg)",
          "standfirst": "Samantha Kelly / Bloomberg: Pittsburgh-based Skild AI, which makes robotics foundation models, raised a $1.4B Series C at a $14B+ valuation, up from ~$4.5B in June 2025 &mdash; Skild AI Inc., a fast-rising startup that makes software to help robots learn to complete tasks, has secured about $1.4 billion in a new funding round &hellip;",
          "content": "Samantha Kelly / Bloomberg: Pittsburgh-based Skild AI, which makes robotics foundation models, raised a $1.4B Series C at a $14B+ valuation, up from ~$4.5B in June 2025 &mdash; Skild AI Inc., a fast-rising startup that makes software to help robots learn to complete tasks, has secured about $1.4 billion in a new funding round &hellip;",
          "feed_position": 12,
          "image_url": "http://www.techmeme.com/260114/i30.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260114/i30.jpg",
      "popularity_score": 2016.89173
    },
    {
      "id": "cluster_11",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 18:45:50 +0000",
      "title": "Civilization VII is headed to iPhone and iPad with “Arcade Edition”",
      "neutral_headline": "Civilization VII is headed to iPhone and iPad with “Arcade Edition”",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/gaming/2026/01/civilization-vii-is-headed-to-iphone-and-ipad-with-arcade-edition/",
          "published_at": "Wed, 14 Jan 2026 18:45:50 +0000",
          "title": "Civilization VII is headed to iPhone and iPad with “Arcade Edition”",
          "standfirst": "Apple's platforms are also getting Retrocade, a library of classic arcade games.",
          "content": "Civilization VII is coming to the iPhone and iPad, Apple and publisher 2K announced today. Formally titled Sid Meier's Civilization VII Arcade Edition, it is developed by Behaviour Interactive with input from original developer Firaxis Games. Neither announcement makes any mention of a non-Arcade version, so this appears to be exclusively part of the subscription.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/civ7-iphone-1152x648-1768415756.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/civ7-iphone-1152x648-1768415756.jpg",
      "popularity_score": 364.42978555555555
    },
    {
      "id": "cluster_26",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 17:25:24 +0000",
      "title": "Man got $2,500 whole-body MRI that found no problems—then had massive stroke",
      "neutral_headline": "Man got $2,500 whole-body MRI that found no problems—then had massive stroke",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/man-got-2500-whole-body-mri-that-found-no-problems-then-had-massive-stroke/",
          "published_at": "Wed, 14 Jan 2026 17:25:24 +0000",
          "title": "Man got $2,500 whole-body MRI that found no problems—then had massive stroke",
          "standfirst": "The MRI showed a problem in a brain artery that should have been flagged, man claims.",
          "content": "A New York man is suing Prenuvo, a celebrity-endorsed whole-body magnetic resonance imaging (MRI) provider, claiming that the company missed clear signs of trouble in his $2,500 whole-body scan—and if it hadn't, he could have acted to avert the catastrophic stroke he suffered months later. Sean Clifford and his legal team claim that his scan on July 15, 2023, showed a 60 percent narrowing and irregularity in a major artery in his brain—the proximal right middle cerebral artery, a branch of the most common artery involved in acute strokes. But Prenuvo's reviews of the scan did not flag the finding and otherwise reported everything in his brain looked normal; there was \"no adverse finding.\" (You can read Prenuvo's report and see Clifford's subsequent imaging here.) Clifford suffered a massive stroke on March 7, 2024. Subsequent imaging found that the proximal right middle cerebral artery progressed to a complete blockage, causing the stroke. Clifford suffered paralysis of his left hand and leg, general weakness on his left side, vision loss and permanent double vision, anxiety, depression, mood swings, cognitive deficits, speech problems, and permanent difficulties with all daily activities.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2212370978-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2212370978-1152x648.jpg",
      "popularity_score": 351.08923
    },
    {
      "id": "cluster_34",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 16:08:58 +0000",
      "title": "Deny, deny, admit: UK police used Copilot AI “hallucination” when banning football fans",
      "neutral_headline": "Deny, deny, admit: UK police used Copilot AI “hallucination”...",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/deny-deny-admit-uk-police-used-copilot-ai-hallucination-when-banning-football-fans/",
          "published_at": "Wed, 14 Jan 2026 16:08:58 +0000",
          "title": "Deny, deny, admit: UK police used Copilot AI “hallucination” when banning football fans",
          "standfirst": "Police finally come clean about botched use of AI tools.",
          "content": "After repeatedly denying for weeks that his force used AI tools, the chief constable of the West Midlands police has finally admitted that a hugely controversial decision to ban Maccabi Tel Aviv football fans from the UK did involve hallucinated information from Microsoft Copilot. In October 2025, Birmingham's Safety Advisory Group (SAG) met to decide whether an upcoming football match between Aston Villa (based in Birmingham) and Maccabi Tel Aviv could be held safely. Tensions were heightened in part due to an October 2 terror attack against a synagogue in Manchester where several people were killed by an Islamic attacker.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2251534549-1152x648-1768405011.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2251534549-1152x648-1768405011.jpg",
      "popularity_score": 334.81534111111114
    },
    {
      "id": "cluster_28",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 17:01:06 +0000",
      "title": "Scientists sequence a woolly rhino genome from a 14,400-year-old wolf’s stomach",
      "neutral_headline": "Scientists sequence a woolly rhino genome from a 14,400-year-old wolf’s stomach",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/science/2026/01/scientists-sequence-a-woolly-rhino-genome-from-a-14400-year-old-wolfs-stomach/",
          "published_at": "Wed, 14 Jan 2026 17:01:06 +0000",
          "title": "Scientists sequence a woolly rhino genome from a 14,400-year-old wolf’s stomach",
          "standfirst": "Fortunately for paleogeneticists, wolf puppies don't chew their food thoroughly.",
          "content": "A 14,400-year-old wolf puppy’s last meal is shedding light on the last days of one of the Ice Age’s most iconic megafauna species, the woolly rhinoceros. When researchers dissected the frozen mummified remains of an Ice Age wolf puppy, they found a partially digested chunk of meat in its stomach: the remnants of the puppy’s last meal 14,400 years ago. DNA testing revealed that the meat was a prime cut of woolly rhinoceros, a now-extinct 2-metric-ton behemoth that once stomped across the tundras of Europe and Asia. Stockholm University paleogeneticist Sólveig Guðjónsdóttir and her colleagues recently sequenced a full genome from the piece of meat, which reveals some secrets about woolly rhino populations in the centuries before their extinction. Scientists carefully autopsy the remains of a wolf puppy who lived and died 14,400 years ago near Tumat village in Siberia. Credit: Guðjónsdóttir et al. 2026 One bad day for a rhino, one giant leap for paleogenomics “Sequencing the entire genome of an Ice Age animal found in the stomach of another animal has never been done before,” said Uppsala University paleogeneticist Camilo Chacón-Duque, a co-author of the study, in a recent press release.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Woolly-rhino-by-Mammoth-museum-of-North-Eastern-Federal-University-Yakutsk-Russia-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Woolly-rhino-by-Mammoth-museum-of-North-Eastern-Federal-University-Yakutsk-Russia-1152x648.jpg",
      "popularity_score": 320.68423
    },
    {
      "id": "cluster_60",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 14:01:19 +0000",
      "title": "EPA makes it harder for states, tribes to block pipelines",
      "neutral_headline": "EPA makes it harder for states, tribes to block pipelines",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/epa-makes-it-harder-for-states-tribes-to-block-pipelines/",
          "published_at": "Wed, 14 Jan 2026 14:01:19 +0000",
          "title": "EPA makes it harder for states, tribes to block pipelines",
          "standfirst": "A new rule aims to speed up and streamline the permitting process.",
          "content": "The Trump administration on Tuesday proposed a new rule aimed at speeding up and streamlining the permitting process for large energy and infrastructure projects, including oil and gas pipelines and facilities tied to artificial intelligence. The rule, which does not require action by Congress, includes a suite of procedural changes to section 401 of the Clean Water Act—a law enacted in the 1970s that is the primary federal statute governing water pollution in the United States. For decades, section 401 has granted states and tribes the authority to approve, impose conditions on, or reject, federal permits for projects that they determine will pollute or damage local waterways.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/07/GettyImages-1228769036-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/07/GettyImages-1228769036-1152x648.jpg",
      "popularity_score": 307.6878411111111
    },
    {
      "id": "cluster_71",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 13:31:44 +0000",
      "title": "Is 2026 the year buttons come back to cars? Crash testers say yes.",
      "neutral_headline": "Is 2026 the year buttons come back to cars? Crash testers say yes.",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/buttons-in-cars-australian-crash-testers-are-latest-to-require-them/",
          "published_at": "Wed, 14 Jan 2026 13:31:44 +0000",
          "title": "Is 2026 the year buttons come back to cars? Crash testers say yes.",
          "standfirst": "The requirements won't go far enough for many, but it's a start.",
          "content": "Like any industry led by designers, the automotive world is subject to trends and fashions. Often, these are things the rest of us complain about. Wheels that used to be 16 inches are now 20s, because the extra size makes the vehicle they're fitted to look smaller, particularly if it's an SUV with a slab of electric vehicle battery to conceal. Front seat passengers now find themselves with their own infotainment screen, often with some kind of active filter tech to prevent the driver from being distracted by whatever it is they're doing. And of course le buzz du jour, AI, is being crammed in here, there, and everywhere. But the thing about fashion and trends is that they don't remain in style forever. For a few years, it was hard to drive a new car that didn't use piano black trim all over the interior. The shiny black plastic surfaces hide infotainment screens well when the display is not turned on, but they scratch and show every speck of dust and lint and every smudge and fingerprint. And that's true for the cheap econobox to the plush luxobarge. The industry finally cottoned on to this, and \"black gloss has had its time—we can do without it,\" Kia designer Jochen Paesen told me a few years ago. Many of those design trends may have been annoying, but the switch away from buttons isn't just about aesthetics; it's affecting safety. And increasingly, safety regulators are pushing back. A couple of years ago, we learned that the Euro New Car Assessment Programme (NCAP) organization, which crash tests cars for European consumers, decided that from 2026, it would start deducting points for basic controls that weren't separate, physical controls that the driver can easily operate without taking their eyes off the road. And now ANCAP, which provides similar crash testing for Australia and New Zealand, has done the same.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1250487861-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1250487861-1152x648.jpg",
      "popularity_score": 302.19478555555554
    },
    {
      "id": "cluster_96",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 23:01:44 +0000",
      "title": "BMW’s first electric M car is coming in 2027—with one motor per wheel",
      "neutral_headline": "BMW’s first electric M car is coming in 2027—with one motor per wheel",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/bmws-first-electric-m-car-is-coming-in-2027-with-one-motor-per-wheel/",
          "published_at": "Tue, 13 Jan 2026 23:01:44 +0000",
          "title": "BMW’s first electric M car is coming in 2027—with one motor per wheel",
          "standfirst": "Here's what we know about the first BMW EV to wear a proper M badge.",
          "content": "BMW provided flights from Washington, DC, to Malaga, Spain, and accommodation so Ars could drive the iX3 and be briefed on the electric M Neue Klasse. Ars does not accept paid editorial content. Late last year, we drove BMW's new iX3. It's the first of a series of electric BMWs to use a newly developed platform, known as the \"Neue Klasse.\" Later this year, we'll see the first fully electric version of the 3 Series when the i3 sedan debuts. And next year, BMW enthusiasts will finally find out what the brand's M division—which infuses motorsport into the vehicles like few others—can do with an EV. There have been M-tuned EVs before now, more powerful variants of the i4, iX, and i7. And each time we've driven them, BMW has been at pains to point out that these weren't true M cars, not like the M3 or M5. Honestly, they weren't better than the cheaper, less powerful versions, something that won't be allowed for next year's performance EV, which might be called something like the iM3, assuming the naming convention remains logic-based. \"The next generation of models are set to establish a new benchmark in the high-performance vehicle segment,\" says Franciscus van Meel, managing director of BMW M GmbH. \"With the latest generation of Neue Klasse technology, we are taking the BMW M driving experience to a new level and will inspire our customers with outstanding, racetrack-ready driving dynamics for everyday use.\"Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/BMW-M-Electrified-Arjeplog-_046-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/BMW-M-Electrified-Arjeplog-_046-1152x648.jpg",
      "popularity_score": 279
    },
    {
      "id": "cluster_97",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 22:34:41 +0000",
      "title": "The RAM shortage’s silver lining: Less talk about “AI PCs”",
      "neutral_headline": "The RAM shortage’s silver lining: Less talk about “AI PCs”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/the-ram-shortages-silver-lining-less-talk-about-ai-pcs/",
          "published_at": "Tue, 13 Jan 2026 22:34:41 +0000",
          "title": "The RAM shortage’s silver lining: Less talk about “AI PCs”",
          "standfirst": "“General interest in AI PCs has been wavering for a while...\"",
          "content": "RAM prices have soared, which is bad news for people interested in buying, building, or upgrading a computer this year, but it's likely good news for people exasperated by talk of so-called AI PCs. As Ars Technica has reported, the growing demands of data centers, fueled by the AI boom, have led to a shortage of RAM and flash memory chips, driving prices to skyrocket. In an announcement today, Ben Yeh, principal analyst at technology research firm Omdia, said that in 2025, “mainstream PC memory and storage costs rose by 40 percent to 70 percent, resulting in cost increases being passed through to customers.”Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1329130331-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1329130331-1152x648.jpg",
      "popularity_score": 278
    },
    {
      "id": "cluster_99",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 22:07:21 +0000",
      "title": "Never-before-seen Linux malware is “far more advanced than typical”",
      "neutral_headline": "Never-before-seen Linux malware is “far more advanced than typical”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/never-before-seen-linux-malware-is-far-more-advanced-than-typical/",
          "published_at": "Tue, 13 Jan 2026 22:07:21 +0000",
          "title": "Never-before-seen Linux malware is “far more advanced than typical”",
          "standfirst": "VoidLink includes an unusually broad and advanced array of capabilities.",
          "content": "Researchers have discovered a never-before-seen framework that infects Linux machines with a wide assortment of modules that are notable for the range of advanced capabilities they provide to attackers. The framework, referred to as VoidLink by its source code, features more than 30 modules that can be used to customize capabilities to meet attackers' needs for each infected machine. These modules can provide additional stealth and specific tools for reconnaissance, privilege escalation, and lateral movement inside a compromised network. The components can be easily added or removed as objectives change over the course of a campaign. A focus on Linux inside the cloud VoidLink can target machines within popular cloud services by detecting if an infected machine is hosted inside AWS, GCP, Azure, Alibaba, and Tencent, and there are indications that developers plan to add detections for Huawei, DigitalOcean, and Vultr in future releases. To detect which cloud service hosts the machine, VoidLink examines metadata using the respective vendor’s API.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security.jpg",
      "popularity_score": 259
    },
    {
      "id": "cluster_102",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 21:55:01 +0000",
      "title": "Lawsuit: DHS wants “unlimited subpoena authority” to unmask ICE critics",
      "neutral_headline": "Lawsuit: DHS wants “unlimited subpoena authority” to unmask ICE critics",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/instagram-user-fights-dhs-for-the-right-to-post-ice-sightings-anonymously/",
          "published_at": "Tue, 13 Jan 2026 21:55:01 +0000",
          "title": "Lawsuit: DHS wants “unlimited subpoena authority” to unmask ICE critics",
          "standfirst": "DHS is weirdly using import/export rules to expand its authority to identify online critics.",
          "content": "The US Department of Homeland Security (DHS) is fighting to unmask the owner of Facebook and Instagram accounts of a community watch group monitoring Immigration and Customs Enforcement (ICE) activity in Pennsylvania. Defending the right to post about ICE sightings anonymously is a Meta account holder for MontCo Community Watch, John Doe. Doe has alleged that when the DHS sent a \"summons\" to Meta asking for subscriber information, it infringed on core First Amendment-protected activity, i.e., the right to publish content critical of government agencies and officials without fear of government retaliation. He also accused DHS of ignoring federal rules and seeking to vastly expand its authority to subpoena information to unmask ICE's biggest critics online.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255126862-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255126862-1024x648.jpg",
      "popularity_score": 243
    },
    {
      "id": "cluster_109",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 20:05:14 +0000",
      "title": "Microsoft vows to cover full power costs for energy-hungry AI data centers",
      "neutral_headline": "Microsoft vows to cover full power costs for energy-hungry AI data centers",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/microsoft-vows-to-cover-full-power-costs-for-energy-hungry-ai-data-centers/",
          "published_at": "Tue, 13 Jan 2026 20:05:14 +0000",
          "title": "Microsoft vows to cover full power costs for energy-hungry AI data centers",
          "standfirst": "Company responds to community concerns over electricity bills and water use.",
          "content": "On Tuesday, Microsoft announced a new initiative called \"Community-First AI Infrastructure\" that commits the company to paying full electricity costs for its data centers and refusing to seek local property tax reductions. As demand for generative AI services has increased over the past year, Big Tech companies have been racing to spin up massive new data centers for serving chatbots and image generators that can have profound economic effects on the surrounding areas where they are located. Among other concerns, communities across the country have grown concerned that data centers are driving up residential electricity rates through heavy power consumption and by straining water supplies due to server cooling needs. The International Energy Agency (IEA) projects that global data center electricity demand will more than double by 2030, reaching around 945 TWh, with the United States responsible for nearly half of total electricity demand growth over that period. This growth is happening while much of the country's electricity transmission infrastructure is more than 40 years old and under strain.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/microsoft_datacenter_2025-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/microsoft_datacenter_2025-1152x648.jpg",
      "popularity_score": 160
    },
    {
      "id": "cluster_105",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 21:13:07 +0000",
      "title": "Hegseth wants to integrate Musk’s Grok AI into military networks this month",
      "neutral_headline": "Hegseth wants to integrate Musk’s Grok AI into military networks this month",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/hegseth-wants-to-integrate-musks-grok-ai-into-military-networks-this-month/",
          "published_at": "Tue, 13 Jan 2026 21:13:07 +0000",
          "title": "Hegseth wants to integrate Musk’s Grok AI into military networks this month",
          "standfirst": "US defense secretary announces plans for integration despite recent controversies.",
          "content": "On Monday, US Defense Secretary Pete Hegseth said he plans to integrate Elon Musk's AI tool, Grok, into Pentagon networks later this month. During remarks at the SpaceX headquarters in Texas reported by The Guardian, Hegseth said the integration would place \"the world's leading AI models on every unclassified and classified network throughout our department.\" The announcement comes weeks after Grok drew international backlash for generating sexualized images of women and children, although the Department of Defense has not released official documentation confirming Hegseth's announced timeline or implementation details. During the same appearance, Hegseth rolled out what he called an \"AI acceleration strategy\" for the Department of Defense. The strategy, he said, will \"unleash experimentation, eliminate bureaucratic barriers, focus on investments, and demonstrate the execution approach needed to ensure we lead in military AI and that it grows more dominant into the future.\"Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/grok_header_1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/grok_header_1-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_118",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 18:56:28 +0000",
      "title": "EPA moves to stop considering economic benefits of cleaner air",
      "neutral_headline": "EPA moves to stop considering economic benefits of cleaner air",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/epa-axes-benefits-from-cost-benefit-analysis-for-air-pollution-limits/",
          "published_at": "Tue, 13 Jan 2026 18:56:28 +0000",
          "title": "EPA moves to stop considering economic benefits of cleaner air",
          "standfirst": "New language criticizes “uncertainties” in longstanding EPA practice.",
          "content": "If you were to do a cost-benefit analysis of your lunch, it would be pretty difficult to do the calculation without the sandwich. But it appears that the US Environmental Protection Agency (EPA) is moving in this same direction—removing the benefit—when it comes to air pollution regulations. According to a New York Times report based on internal emails and documents—and demonstrated by a recently produced analysis on the EPA website—the EPA is changing its cost-benefit analysis process for common air pollutants. Instead of comparing the economic cost of a certain pollution limit to an estimate of the economic value of the resulting improvements in human health, the EPA will just qualitatively describe health benefits while carefully quantifying economic costs. Cost-benefit analysis has been a key component of EPA regulations. Any decision to raise or lower air quality standards or pollution limits includes evaluations of the cost that change, like the addition of new pollution control equipment at power plants, would incur, for example.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2182255823-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2182255823-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_113",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 19:28:15 +0000",
      "title": "Google’s updated Veo model can make vertical videos from reference images with 4K upscaling",
      "neutral_headline": "Google’s updated Veo model can make vertical videos from...",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/01/googles-updated-veo-model-can-make-vertical-videos-from-reference-images-with-4k-upscaling/",
          "published_at": "Tue, 13 Jan 2026 19:28:15 +0000",
          "title": "Google’s updated Veo model can make vertical videos from reference images with 4K upscaling",
          "standfirst": "Google has also added the updated Veo to YouTube creator tools.",
          "content": "Google's Veo video AI made stunning leaps in fidelity in 2025, and Google isn't stopping in 2026. The company has announced an update for Veo 3.1 that adds new capabilities when you provide the model with reference material, known as Ingredients to Video. The results should be more consistent, and output supports vertical video and higher-resolution upscaling. With Ingredients to Video, you can provide the AI with up to three images to incorporate into the generated video. You can use that to provide the robot with characters to animate, backgrounds, and material textures. When you do that, the newly upgraded model will allegedly make fewer random alterations, hemming closer to the reference images. You can also generate multiple clips and even prompt for changes to the setting or style while keeping other elements consistent. Veo 3.1 Updates - Bring more creativity and expressiveness into your videos. Google is also expanding its support for mobile-first video in Veo. When using Ingredients to Video, you can now specify outputs in a 9:16 (vertical) ratio. That makes it ideal for posting on social apps like Instagram or TikTok, as well as uploading as a YouTube Short. So get ready for even more phone-centric slop. Google added support for vertical videos via a text prompt last year.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Veo-31-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Veo-31-1152x648.jpg",
      "popularity_score": 145
    },
    {
      "id": "cluster_123",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 18:24:03 +0000",
      "title": "Apple’s Mac and iPad creative apps get bundled into “Creator Studio” subscription",
      "neutral_headline": "Apple’s Mac and iPad creative apps get bundled into “Creator Studio” subscription",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/apple-creator-studio-bundles-final-cut-pro-logic-and-other-apps-for-129-year/",
          "published_at": "Tue, 13 Jan 2026 18:24:03 +0000",
          "title": "Apple’s Mac and iPad creative apps get bundled into “Creator Studio” subscription",
          "standfirst": "Video, audio, and image editing apps join up in one subscription on January 28.",
          "content": "Apple's professional creative apps have been slower to jump on the subscription bandwagon than those from Adobe or some of its other competitors, but the company is taking a step in that direction today. Starting on January 28, Apple will offer an Apple Creator Studio subscription for $13 a month, or $130 a year. Subscribers will get access to the Mac and (where applicable) iPad versions of Final Cut Pro, Logic Pro, Pixelmator Pro, Motion, Compressor, and MainStage, as well as \"intelligent features and premium content\" for the Mac, iPad, and iPhone versions of Keynote, Pages, Numbers, and Freeform. Apple says it will also offer a one-month free trial for the subscription and a discounted version for students at $3 a month, or $30 a year. Most of the apps also seem to be getting small feature updates to go along with the Creator Studio announcement. Final Cut will get a new Transcript Search feature that will allow you to dig through video footage by searching for specific dialogue, and a new Montage Maker feature \"will analyze and edit together a dynamic video based on the best visual moments within the footage.\" An updated Logic Pro \"helps creators deliver original music for their video content\" and adds a synth player to the app's lineup of \"AI Session Players.\"Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Apple-Creator-Studio-lifestyle-Final-Cut-Pro-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Apple-Creator-Studio-lifestyle-Final-Cut-Pro-1152x648.jpg",
      "popularity_score": 145
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 17:11:51 +0000",
      "title": "This one could use less power: The Jeep Wagoneer S EV",
      "neutral_headline": "This one could use less power: The Jeep Wagoneer S EV",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/this-one-could-use-less-power-the-jeep-wagoneer-s-ev/",
          "published_at": "Tue, 13 Jan 2026 17:11:51 +0000",
          "title": "This one could use less power: The Jeep Wagoneer S EV",
          "standfirst": "Poorly calibrated pedal mapping marred the Wagoneer S experience.",
          "content": "It's not really accurate to call the Wagoneer S Jeep's first electric vehicle. For several years now, Europeans have been able to buy the Jeep Avenger, a subcompact crossover that will surely never see American roads. But it is the first electric Jeep designed for American consumption. It's aimed at the highly competitive midsize SUV segment, which gets ever more crowded even as electrification faces a less certain future here. Indeed, the brand, along with its Stellantis sibling Chrysler, just shelved all its plug-in hybrids, discontinuing them just a few days ago. Like the little Avenger, the Wagoneer S makes use of one of parent company Stellantis' purpose-built EV platforms, one shared with the growly-sounding Dodge Charger. At 192.4 inches (4,886 mm) long, 74.8 inches (1,900 mm) wide, and 64.8 inches (1,645 mm) tall, it's a little larger than cars like the BMW iX3 or Audi Q6 e-tron but a little smaller than domestically designed rivals like the Cadillac Lyriq and Acura ZDX, which have particularly long wheelbases. I find it a rather handsome car, one that has to marry Jeep's Wagoneer styling cues with as many wind-smoothing and air-shaping elements as possible. The way the rear wing juts out above the tailgate window reminds me of a '90s rally hatchback, but it's the product of the designers and the engineers working on drag reduction. The overall drag coefficient is 0.29, and since Jeep actually publishes the frontal area, too, I can tell you the more important CdA number—where drag is multiplied by the frontal area—is 8.67 sq ft (0.805 m2).Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/WS025_007WS-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/WS025_007WS-1152x648.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_114",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 19:18:35 +0000",
      "title": "Starlink tries to stay online in Iran as regime jams signals during protests",
      "neutral_headline": "Starlink tries to stay online in Iran as regime jams signals during protests",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/starlink-tries-to-stay-online-in-iran-as-regime-jams-signals-during-protests/",
          "published_at": "Tue, 13 Jan 2026 19:18:35 +0000",
          "title": "Starlink tries to stay online in Iran as regime jams signals during protests",
          "standfirst": "Iran shut off Internet as it cracks down on protests; even Starlink has problems.",
          "content": "President Trump asked Elon Musk to get Starlink working more reliably in Iran to thwart the Iranian government's Internet shutdown. Starlink operator SpaceX was apparently already working on the problem before Trump reached out to Musk. Iran severed Internet connections and phone lines last week as the government conducted a violent crackdown on anti-government demonstrators, according to numerous reports, which say that thousands of people have been killed. Starlink hasn't been completely disabled. The government's jamming technology has reportedly caused Starlink packet loss of anywhere from 30 to 80 percent.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/starlink-iran-1152x648-1768330630.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/starlink-iran-1152x648-1768330630.jpg",
      "popularity_score": 138
    },
    {
      "id": "cluster_104",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 21:25:49 +0000",
      "title": "FDA deletes warning on bogus autism therapies touted by RFK Jr.‘s allies",
      "neutral_headline": "FDA deletes warning on bogus autism therapies touted by RFK Jr.‘s allies",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/warning-about-bogus-autism-treatments-vanishes-from-fdas-website/",
          "published_at": "Tue, 13 Jan 2026 21:25:49 +0000",
          "title": "FDA deletes warning on bogus autism therapies touted by RFK Jr.‘s allies",
          "standfirst": "The agency used to warn of chelation, used by RFK Jr.'s anti-vaccine ally David Geier.",
          "content": "For years, the Food and Drug Administration provided an informational webpage for parents warning them of the dangers of bogus autism treatments, some promoted by anti-vaccine activists and \"wellness\" companies. The page cited specifics scams and the \"significant health risks\" they pose. But, under anti-vaccine Health Secretary Robert F. Kennedy Jr.—who has numerous ties to the wellness industry—that FDA information webpage is now gone. It was quietly deleted at the end of last year, the Department of Health and Human Services confirmed to Ars Technica. The defunct webpage, titled \"Be Aware of Potentially Dangerous Products and Therapies that Claim to Treat Autism,\" provided parents and other consumers with an overview of the problem. It began with a short description of autism and some evidence-based, FDA-approved medications that can help manage autism symptoms. Then, the regulatory agency provided a list of some false claims and unproven, potentially dangerous treatments it had been working to combat. \"Some of these so-called therapies carry significant health risks,\" the FDA wrote.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255115344-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255115344-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_128",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 16:35:52 +0000",
      "title": "A new Titan emerges in Monarch: Legacy of Monsters S2 teaser",
      "neutral_headline": "A new Titan emerges in Monarch: Legacy of Monsters S2 teaser",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/a-new-titan-emerges-in-monarch-legacy-of-monsters-s2-teaser/",
          "published_at": "Tue, 13 Jan 2026 16:35:52 +0000",
          "title": "A new Titan emerges in Monarch: Legacy of Monsters S2 teaser",
          "standfirst": "Apple TV's sci-fi series is part of Legendary Entertainment’s MonsterVerse and is set after 2014's Godzilla.",
          "content": "It's looking to be a solid year for kaiju fans. Not only are we getting Godzilla Minus Zero in November—sequel to the critically acclaimed Godzilla Minus One (2023)—but Apple TV just released a teaser for the second season of Monarch: Legacy of Monsters, part of Legendary Entertainment’s MonsterVerse, which brought Godzilla, King Kong, and various other monsters (kaiju) created by Toho Co., Ltd into the same fold. (Spoilers for S1 below.) The first season picked up where 2014's Godzilla left off, specifically the introduction of Project Monarch, a secret organization established in the 1950s to study Godzilla and other kaiju—after attempts to kill Godzilla with nuclear weapons failed. The plot spans three generations and takes place in the 1950s and half a century later. In the first season, two siblings (Kate and Kentaro Randa) follow in their father’s footsteps to uncover their family’s connection to the secretive organization known as Monarch. Naturally, they find themselves in the world of monsters and discover Army officer Lee Shaw (Kurt Russell), a longtime family ally.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/monarch2-1152x648-1768318930.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/monarch2-1152x648-1768318930.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_124",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 18:15:01 +0000",
      "title": "Scott Adams, Dilbert creator, dead at 68",
      "neutral_headline": "Scott Adams, Dilbert creator, dead at 68",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/scott-adams-dilbert-creator-dead-at-68/",
          "published_at": "Tue, 13 Jan 2026 18:15:01 +0000",
          "title": "Scott Adams, Dilbert creator, dead at 68",
          "standfirst": "\"I had an amazing life. I gave it everything I had.\"",
          "content": "Scott Adams, the creator of the Dilbert comic strip, died today of prostate cancer at 68. Adams satirized the world of cubicle-based IT and engineering in Dilbert, which at its height appeared in 2,000 daily newspapers and was later anthologized in numerous books. Dilbert was an engineer with few social skills, but he always knew more than his pointy-haired boss, a caricature of terrible supervisors everywhere who managed to make the life of those who actually knew what they were doing—the engineers—much harder than it needed to be.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1322060604-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1322060604-1024x648.jpg",
      "popularity_score": 130
    }
  ]
}